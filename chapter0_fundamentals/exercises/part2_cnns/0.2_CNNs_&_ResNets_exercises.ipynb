{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_iswa50jBUB"
      },
      "source": [
        "# [0.2] - CNNs & ResNets (exercises)\n",
        "\n",
        "> **ARENA [Streamlit Page](https://arena-chapter0-fundamentals.streamlit.app/02_[0.2]_CNNs_&_ResNets)**\n",
        ">\n",
        "> **Colab: [exercises](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_exercises.ipynb?t=20250316) | [solutions](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_solutions.ipynb?t=20250316)**\n",
        "\n",
        "Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-2zick19fl-6GY1yoGaoUozyM3wObwmnQ), and ask any questions on the dedicated channels for this chapter of material.\n",
        "\n",
        "You can collapse each section so only the headers are visible, by clicking the arrow symbol on the left hand side of the markdown header cells.\n",
        "\n",
        "Links to all other chapters: [(0) Fundamentals](https://arena-chapter0-fundamentals.streamlit.app/), [(1) Transformer Interpretability](https://arena-chapter1-transformer-interp.streamlit.app/), [(2) RL](https://arena-chapter2-rl.streamlit.app/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KReTy3YXjBUD"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/headers/header-02.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjDs7AnnjBUD"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IteXpvwkjBUE"
      },
      "source": [
        "This section is designed to get you familiar with basic neural networks: how they are structured, the basic operations like linear layers and convolutions which go into making them, and why they work as well as they do. You'll start by making very simple neural networks, and by the end of today you'll build up to assembling ResNet34, a comparatively much more complicated architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ56L21GjBUE"
      },
      "source": [
        "## Content & Learning Objectives\n",
        "\n",
        "### 1️⃣ Making your own modules\n",
        "\n",
        "In the first set of exercises, we'll cover the general structure of modules in PyTorch. You'll also implement your own basic modules, including for ReLU and Linear layers. You'll finish by assembling a very simple neural network.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn how to create your own modules in PyTorch, by inheriting from `nn.Module`\n",
        "> - Assemble the pieces together to create a simple fully-connected network, to classify MNIST digits\n",
        "\n",
        "### 2️⃣ Training Neural Networks\n",
        "\n",
        "Here, you'll learn how to write a training loop in PyTorch. We'll keep it simple for today (and later on we'll experiment with more modular and extensible designs).\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand how to work with transforms, datasets and dataloaders\n",
        "> - Understand the basic structure of a training loop\n",
        "> - Learn how to write your own validation loop\n",
        "\n",
        "### 3️⃣ Convolutions\n",
        "\n",
        "In this section, you'll read about convolutions, and implement them as an `nn.Module` (not from scratch; we leave that to the bonus exercises). You'll also learn about maxpooling, and implement that as well.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn how convolutions work, and why they are useful for vision models\n",
        "> * Implement your own convolutions, and maxpooling layers\n",
        "\n",
        "### 4️⃣ ResNets\n",
        "\n",
        "Here, you'll combine all the pieces you've learned so far to assemble ResNet34, a much more complex architecture used for image classification.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn about skip connections, and how they help overcome the degradation problem\n",
        "> * Learn about batch normalization, and why it is used in training\n",
        "> * Assemble your own ResNet, and load in weights from PyTorch's ResNet implementation\n",
        "\n",
        "### ☆ Bonus - Feature Extraction\n",
        "\n",
        "In this section, you'll learn how to repurpose your ResNet to perform a different task than it was designed for, using feature extraction.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand the difference between feature extraction and finetuning\n",
        "> * Perform feature extraction on a pre-trained ResNet\n",
        "\n",
        "### ☆ Bonus - Convolutions From Scratch\n",
        "\n",
        "This section takes you through the low-level details of how to actually implement convolutions. It's not necessary to understand this section to complete the exercises, but it's a good way to get a deeper understanding of how convolutions work.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand how array strides work, and why they're important for efficient linear operations\n",
        "> * Learn how to use `as_strided` to perform simple linear operations like trace and matrix multiplication\n",
        "> * Implement your own convolutions and maxpooling functions using stride-based methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xpzt7ZBjBUE"
      },
      "source": [
        "## Setup code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "X3SaGqsSjBUE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "repo = \"ARENA_3.0\"\n",
        "branch = \"main\"\n",
        "\n",
        "# Install dependencies\n",
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    %pip install torchinfo jaxtyping\n",
        "\n",
        "# Get root directory, handling 3 different cases: (1) Colab, (2) notebook not in ARENA repo, (3) notebook in ARENA repo\n",
        "root = (\n",
        "    \"/content\"\n",
        "    if IN_COLAB\n",
        "    else \"/root\"\n",
        "    if repo not in os.getcwd()\n",
        "    else str(next(p for p in Path.cwd().parents if p.name == repo))\n",
        ")\n",
        "\n",
        "if Path(root).exists() and not Path(f\"{root}/{chapter}\").exists():\n",
        "    if not IN_COLAB:\n",
        "        !sudo apt-get install unzip\n",
        "        %pip install jupyter ipython --upgrade\n",
        "\n",
        "    if not os.path.exists(f\"{root}/{chapter}\"):\n",
        "        !wget -P {root} https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/{branch}.zip\n",
        "        !unzip {root}/{branch}.zip '{repo}-{branch}/{chapter}/exercises/*' -d {root}\n",
        "        !mv {root}/{repo}-{branch}/{chapter} {root}/{chapter}\n",
        "        !rm {root}/{branch}.zip\n",
        "        !rmdir {root}/{repo}-{branch}\n",
        "\n",
        "\n",
        "if f\"{root}/{chapter}/exercises\" not in sys.path:\n",
        "    sys.path.append(f\"{root}/{chapter}/exercises\")\n",
        "\n",
        "os.chdir(f\"{root}/{chapter}/exercises\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "J760KjlEjBUF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "from collections import namedtuple\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import einops\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchinfo\n",
        "from IPython.display import display\n",
        "from jaxtyping import Float, Int\n",
        "from PIL import Image\n",
        "from rich import print as rprint\n",
        "from rich.table import Table\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Make sure exercises are in the path\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "section = \"part2_cnns\"\n",
        "root_dir = next(p for p in Path.cwd().parents if (p / chapter).exists())\n",
        "exercises_dir = root_dir / chapter / \"exercises\"\n",
        "section_dir = exercises_dir / section\n",
        "if str(exercises_dir) not in sys.path:\n",
        "    sys.path.append(str(exercises_dir))\n",
        "\n",
        "\n",
        "import part2_cnns.tests as tests\n",
        "import part2_cnns.utils as utils\n",
        "from plotly_utils import line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt1-bUz3jBUF"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I get a NumPy-related error</summary>\n",
        "\n",
        "This is an annoying colab-related issue which I haven't been able to find a satisfying fix for. If you restart runtime (but don't delete runtime), and run just the imports cell above again (but not the `%pip install` cell), the problem should go away.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlzN3uFYjBUF"
      },
      "source": [
        "# 1️⃣ Making your own modules\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn how to create your own modules in PyTorch, by inheriting from `nn.Module`\n",
        "> - Assemble the pieces together to create a simple fully-connected network, to classify MNIST digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amANK1ZwjBUF"
      },
      "source": [
        "Note - from this point on we'll start referring to the PyTorch documentation pages quite a lot. We will also include a lot of content within this material if we want to highlight it for you, however it's also an important skill to be able to use documentation pages to find answers to specific questions & assist you in debugging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u7TDJr8jBUF"
      },
      "source": [
        "## Subclassing `nn.Module`\n",
        "\n",
        "One of the most basic parts of PyTorch that you will see over and over is the `nn.Module` class. All types of neural net components inherit from it, from the simplest `nn.Relu` to the most complex `nn.Transformer`. Often, a complex `nn.Module` will have sub-`Module`s which implement smaller pieces of its functionality.\n",
        "\n",
        "Other common `Module`s  you'll see include\n",
        "\n",
        "- `nn.Linear`, for fully-connected layers with or without a bias\n",
        "- `nn.Conv2d`, for a two-dimensional convolution (we'll see more of these in a future section)\n",
        "- `nn.Softmax`, which implements the [softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) function\n",
        "\n",
        "The list goes on, including activation functions, normalizations, pooling, attention, and more. You can see all the `Module`s that PyTorch provides [here](https://pytorch.org/docs/stable/nn.html). You can also create your own `Module`s, as we will do often!\n",
        "\n",
        "The `Module` class provides a lot of functionality, but we'll only cover a little bit of it here.\n",
        "\n",
        "In this section, we'll add another layer of abstraction to all the linear operations we've done in previous sections, by packaging them inside `nn.Module` objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd35tEeHjBUF"
      },
      "source": [
        "### `__init__` and `forward`\n",
        "\n",
        "A subclass of `nn.Module` usually looks something like this:\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, arg1, arg2, ...):\n",
        "        super().__init__()\n",
        "        # Initialization code\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        # Forward pass code\n",
        "```\n",
        "\n",
        "The initialization sets up attributes that will be used for the life of the `Module`, like its parameters, hyperparameters, or other sub-`Module`s it might need to use. These are usually added to the instance with something like `self.attribute = attr`, where `attr` might be provided as an argument. Some modules are simple enough that they don't need any persistent attributes, and in this case you can skip the `__init__`.\n",
        "\n",
        "The `forward` method is called on each forward pass of the `Module`, possibly using the attributes that were set up in the `__init__`. It should take in the input, do whatever it's supposed to do, and return the result. Subclassing `nn.Module` automatically makes instances of your class callable, so you can do `model(x)` on an input `x` to invoke the `forward` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR3NHdlijBUF"
      },
      "source": [
        "### The `nn.Parameter` class\n",
        "\n",
        "A `nn.Parameter` is a special type of `Tensor`. Basically, this is the class that torch has provided for storing the weights and biases of a `Module`. It has some special properties for doing this:\n",
        "\n",
        "- If a `Parameter` is set as an attribute of a `Module`, it will be auto-detected by torch and returned when you call `module.parameters()` (along with all the other `Parameters` associated with the `Module`, or any of the `Module`'s sub-modules!).\n",
        "- This makes it easy to pass all the parameters of a model into an optimizer and update them all at once.\n",
        "\n",
        "When you create a `Module` that has weights or biases, be sure to wrap them in `nn.Parameter` so that torch can detect and update them appropriately:\n",
        "\n",
        "```python\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, weights: t.Tensor, biases: t.Tensor):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(weights) # wrapping a tensor in nn.Parameter\n",
        "        self.biases = nn.Parameter(biases)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygSJWmByjBUF"
      },
      "source": [
        "### Printing information with `extra_repr`\n",
        "\n",
        "Another useful method is called `extra_repr`. This allows you to format the string representation of your `Module` in a way that's more informative than the default. For example, the following:\n",
        "\n",
        "```python\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, arg1, arg2, ...):\n",
        "        super().__init__()\n",
        "        # Initialization code\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"arg1={self.arg1}, arg2={self.arg2}, ...\"\n",
        "```\n",
        "\n",
        "will result in the output `\"MyModule(arg1=arg1, arg2=arg2, ...)\"` when you print an instance of this module. You might want to take this opportunity to print out useful invariant information about the module. The Python built-in function `getattr` might be helpful here (it can be used e.g. as `getattr(self, \"arg1\")`, which returns the same as `self.arg1` would). For simple modules, it's fine not to implement `extra_repr`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Tq7dwBjBUF"
      },
      "source": [
        "## ReLU\n",
        "\n",
        "The first module you should implement is `ReLU`. This will relatively simple, since it doesn't involve any argument (so we only need to implement `forward`). Make sure you look at the PyTorch documentation page for [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) so that you're comfortable with how they work.\n",
        "\n",
        "ReLU is defined as the element-wise maximum between the input and a tensor of zeros. It's one of the simplest types of **nonlinear activation functions**. These are essential because linear operations compose to make more linear operations, which is very limiting. On the other hand, the **universal approximation theorem** tells us that we can approximate any continuous function using a sufficiently large neural network, if we use nonlinear activation functions. It's worth emphasizing that the theory of the UAT and what networks look like in practice are very different - in particular, many versions of the UAT are based on a shallow but extremely wide neural network, on the other hand most of the power of modern neural networks comes from their ability to compose between layers: feeding the output of one layer into the input of another, and create increasingly expressive functions. We'll explore this idea more when we study circuits in next week's interpretability material."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmarEv11jBUF"
      },
      "source": [
        "### Exercise - implement `ReLU`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should fill in the `forward` method of the `ReLU` class below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9sfqUqfjBUF",
        "outputId": "01b1c52b-32ae-450a-dba0-6f242400b986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.6427, -0.3723, -0.9161,  0.7578, -0.2064, -1.8567,  0.4777,  0.0463,\n",
            "         0.2753,  1.1506])\n",
            "All tests in `test_relu` passed!\n"
          ]
        }
      ],
      "source": [
        "class ReLU(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "      print(x)\n",
        "      return t.max(t.tensor(0.0), x)\n",
        "\n",
        "\n",
        "tests.test_relu(ReLU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHxhtlaRjBUF"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ReLU(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return t.maximum(x, t.tensor(0.0))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNQObgqGjBUF"
      },
      "source": [
        "## Linear\n",
        "\n",
        "Now implement your own `Linear` module. This applies a simple linear transformation, with a weight matrix and optional bias vector. The PyTorch documentation page is [here](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html). Note that this is the first `Module` you'll implement that has learnable weights and biases.\n",
        "\n",
        "<details>\n",
        "<summary>Question - what type do you think these variables should be?</summary>\n",
        "\n",
        "They have to be `torch.Tensor` objects wrapped in `nn.Parameter` in order for `nn.Module` to recognize them. If you forget to do this, `module.parameters()` won't include your `Parameter`, which prevents an optimizer from being able to modify it during training.\n",
        "        \n",
        "Also, in tomorrow's exercises we'll be building a ResNet and loading in weights from a pretrained model, and this is hard to do if you haven't registered all your parameters!\n",
        "</details>\n",
        "\n",
        "For any layer, initialization is very important for the stability of training: with a bad initialization, your model will take much longer to converge or may completely fail to learn anything. The default PyTorch behavior isn't necessarily optimal and you can often improve performance by using something more custom, but we'll follow it for today because it's simple and works decently well.\n",
        "\n",
        "Each float in the weight and bias tensors are drawn independently from the uniform distribution on the interval:\n",
        "\n",
        "$$\n",
        "\\bigg[-\\frac{1}{\\sqrt{N_{in}}}, \\frac{1}{\\sqrt{N_{in}}}\\bigg]\n",
        "$$\n",
        "\n",
        "where $N_{in}$ is the number of inputs contributing to each output value. The rough intuition for this is that it keeps the variance of the activations at each layer constant, since each one is calculated by taking the sum over $N_{in}$ inputs multiplied by the weights (and standard deviation of the sum of independent random variables scales as the square root of number of variables).\n",
        "\n",
        "This initialization technique is called **uniform Kaiming initialization**. A few last notes on initialization methods:\n",
        "\n",
        "- Kaiming often has a different constant in the numerator depending on what the target variance is, also there are uniform & normal variants of it (we'll only be using the uniform variant)\n",
        "- **Xavier initialization** is the other well-known technique, and differs in that it uses $N_{in} + N_{out}$ in the denominator (this makes sense when also considering variance scaling of backward passes as well as forward passes - see the next dropdown for technical details)\n",
        "\n",
        "<details>\n",
        "<summary>Technical details (derivation of distribution)</summary>\n",
        "\n",
        "The key intuition behind Kaiming initialisation (and others like it) is that we want the variance of our activations to be the same through all layers of the model when we initialize. Suppose $x$ and $y$ are activations from two adjacent layers, and $w$ are the weights connecting them (so we have $y_i = \\sum_j w_{ij} x_j + b_i$, where $b$ is the bias). With $N_{x}$ as the number of neurons in layer $x$, we have:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\operatorname{Var}\\left(y_i\\right)=\\sigma_x^2 & =\\operatorname{Var}\\left(\\sum_j w_{i j} x_j\\right) \\\\\n",
        "& =\\sum_j \\operatorname{Var}\\left(w_{i j} x_j\\right) \\quad \\text { Inputs and weights are independent of each other } \\\\\n",
        "& =\\sum_j \\operatorname{Var}\\left(w_{i j}\\right) \\cdot \\operatorname{Var}\\left(x_j\\right) \\quad \\text { Variance of product of independent RVs with zero mean is product of variances } \\\\\n",
        "& = N_x \\cdot \\sigma_x^2 \\cdot \\operatorname{Var}\\left(w_{i j}\\right) \\quad \\text { Variance equal for all } N_x \\text { neurons, call this value } \\sigma_x^2\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "For this to be the same as $\\sigma_x^2$, we need $\\operatorname{Var}(w_{ij}) = \\frac{1}{N_x}$, so the standard deviation is $\\frac{1}{\\sqrt{N_x}}$.\n",
        "\n",
        "This is not exactly the case for the Kaiming uniform distribution (which has variance $\\frac{12}{(2 \\sqrt{N_x})^2} = \\frac{3}{N_x}$), and as far as I'm aware there's no principled reason why PyTorch does this. But the most important thing is that the variance scales as $O(1 / N_x)$, rather than what the exact scaling constant is.\n",
        "\n",
        "There are other initializations with some theoretical justification. For instance, **Xavier initialization** has a uniform distribution in the interval:\n",
        "\n",
        "$$\n",
        "\\bigg[-\\frac{\\sqrt{6}}{\\sqrt{N_{in} + N_{out} + 1}}, \\frac{\\sqrt{6}}{\\sqrt{N_{in} + N_{out} + 1}}\\bigg]\n",
        "$$\n",
        "\n",
        "which is motivated by the idea of both keeping the variance of activations constant and keeping the ***gradients*** constant when we backpropagate.\n",
        "\n",
        "However, you don't need to worry about any of this here, just implement Kaiming He uniform with a bound of $\\frac{1}{\\sqrt{N_{in}}}$!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sayc08FRjBUG"
      },
      "source": [
        "### Exercise - implement `Linear`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Remember, you should define the weights (and bias, if `bias=True`) in the `__init__` block. Also, make sure not to mix up `bias` (which is the boolean parameter to `__init__`) and `self.bias` (which should either be the actual bias tensor, or `None` if `bias` is false).\n",
        "\n",
        "You should also fill in `forward` (which will multiply the input by the weight matrix and add the bias, if present).\n",
        "\n",
        "Lastly, you should fill in `extra_repr` to give a string representation of the `Linear` module. There are no tests for this method, you should just make sure it's suitably informative (this will help when printing out your model later on)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_XQjEHcjBUG",
        "outputId": "3d62eb8f-3ccc-4fd3-e6df-7c08c0982f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_linear_parameters` passed!\n",
            "All tests in `test_linear_parameters` passed!\n",
            "All tests in `test_linear_forward` passed!\n",
            "All tests in `test_linear_forward` passed!\n"
          ]
        }
      ],
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
        "        \"\"\"\n",
        "        A simple linear (technically, affine) transformation.\n",
        "\n",
        "        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n",
        "        If `bias` is False, set `self.bias` to None.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.bias = bias\n",
        "        self.weight = nn.Parameter(nn.init.kaiming_uniform_(t.empty(out_features, in_features)))\n",
        "        if bias:\n",
        "          self.bias = nn.Parameter(t.zeros(out_features))\n",
        "        else:\n",
        "          self.bias = None\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (*, in_features)\n",
        "        Return: shape (*, out_features)\n",
        "        \"\"\"\n",
        "        x = einops.einsum(x, self.weight, 'batch input, output input -> batch output')\n",
        "        if self.bias is not None:\n",
        "            x += self.bias  # Add the bias if it exists\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"input_shape={self.in_features}, output_shape={self.out_features}\"\n",
        "\n",
        "\n",
        "tests.test_linear_parameters(Linear, bias=False)\n",
        "tests.test_linear_parameters(Linear, bias=True)\n",
        "tests.test_linear_forward(Linear, bias=False)\n",
        "tests.test_linear_forward(Linear, bias=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTo8VirAjBUG"
      },
      "source": [
        "<details>\n",
        "<summary>Help - when I print my Linear module, it also prints a large tensor.</summary>\n",
        "\n",
        "This is because you've (correctly) defined `self.bias` as either `torch.Tensor` or `None`, rather than set it to the boolean value of `bias` used in initialisation.\n",
        "        \n",
        "To fix this, you will need to change `extra_repr` so that it prints the boolean value of `bias` rather than the value of `self.bias`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
        "        \"\"\"\n",
        "        A simple linear (technically, affine) transformation.\n",
        "\n",
        "        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n",
        "        If `bias` is False, set `self.bias` to None.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.bias = bias\n",
        "\n",
        "        sf = 1 / np.sqrt(in_features)\n",
        "\n",
        "        weight = sf * (2 * t.rand(out_features, in_features) - 1)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "\n",
        "        if bias:\n",
        "            bias = sf * (2 * t.rand(out_features) - 1)\n",
        "            self.bias = nn.Parameter(bias)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (*, in_features)\n",
        "        Return: shape (*, out_features)\n",
        "        \"\"\"\n",
        "        x = einops.einsum(x, self.weight, \"... in_feats, out_feats in_feats -> ... out_feats\")\n",
        "        if self.bias is not None:\n",
        "            x += self.bias\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        # note, we need to use `self.bias is not None`, because `self.bias` is either a tensor or None, not bool\n",
        "        return f\"in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}\"\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GmLM-WkjBUG"
      },
      "source": [
        "## Flatten\n",
        "\n",
        "Lastly, we've given you the `Flatten` module rather than including it as an exercise (because it's simple but quite finnicky to implement). This is a standardised way to rearrange our tensors so that they can be fed into a linear layer. It's a bit like `einops.rearrange`, but more specialised and less flexible (it flattens over some contiguous range of dimensions, rather than allowing for general reshape operations). By default we use `Flatten(start_dim=1, end_dim=-1)` which means flattening over the dimensions from `input.shape[1:]`, in other words over all except the batch dimension.\n",
        "\n",
        "Make sure you understand what this module is doing before moving on.\n",
        "\n",
        "<!-- <details>\n",
        "<summary>Help - I can't figure out what shape the output should be in Flatten.</summary>\n",
        "\n",
        "If `input.shape = (n0, n1, ..., nk)`, and the `Flatten` module has `start_dim=i, end_dim=j`, then the new shape should be `(n0, n1, ..., ni*...*nj, ..., nk)`. This is because we're **flattening** over the dimensions `(ni, ..., nj)`.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I can't see why my Flatten module is failing the tests.</summary>\n",
        "\n",
        "The most common reason is failing to correctly handle indices. Make sure that:\n",
        "* You're indexing up to **and including** `end_dim`.\n",
        "* You're correctly managing the times when `end_dim` is negative (e.g. if `input` is an nD tensor, and `end_dim=-1`, this should be interpreted as `end_dim=n-1`).\n",
        "</details> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kJ8_fjZ3jBUG"
      },
      "outputs": [],
      "source": [
        "class Flatten(nn.Module):\n",
        "    def __init__(self, start_dim: int = 1, end_dim: int = -1) -> None:\n",
        "        super().__init__()\n",
        "        self.start_dim = start_dim\n",
        "        self.end_dim = end_dim\n",
        "\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Flatten out dimensions from start_dim to end_dim, inclusive of both.\n",
        "        \"\"\"\n",
        "        shape = input.shape\n",
        "\n",
        "        # Get start & end dims, handling negative indexing for end dim\n",
        "        start_dim = self.start_dim\n",
        "        end_dim = self.end_dim if self.end_dim >= 0 else len(shape) + self.end_dim\n",
        "\n",
        "        # Get the shapes to the left / right of flattened dims, as well as the size of the flattened middle\n",
        "        shape_left = shape[:start_dim]\n",
        "        shape_right = shape[end_dim + 1 :]\n",
        "        shape_middle = t.prod(t.tensor(shape[start_dim : end_dim + 1])).item()\n",
        "\n",
        "        return t.reshape(input, shape_left + (shape_middle,) + shape_right)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in [\"start_dim\", \"end_dim\"]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = t.rand((2,3,4))\n",
        "print(test.shape)\n",
        "test_flat = Flatten(0, 1)(test)\n",
        "print(test_flat.shape)"
      ],
      "metadata": {
        "id": "dsCF-TbI1GfW",
        "outputId": "c263a03c-9f8d-404e-bbaf-9f676ef67bbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n",
            "torch.Size([6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVmSiz4CjBUG"
      },
      "source": [
        "## Simple Multi-Layer Perceptron\n",
        "\n",
        "Now, we can put together these two modules to create a neural network. We'll create one of the simplest networks which can be used to separate data that is non-linearly separable: a single linear layer, followed by a nonlinear function (ReLU), followed by another linear layer. This type of architecture (alternating linear layers and nonlinear functions) is often called a **multi-layer perceptron** (MLP).\n",
        "\n",
        "The output of this network will have 10 dimensions, corresponding to the 10 classes of MNIST digits. We can then use the **softmax function** $x_i \\to \\frac{e^{x_i}}{\\sum_i e^{x_i}}$ to turn these values into probabilities. However, it's common practice for the output of a neural network to be the values before we take softmax, rather than after. We call these pre-softmax values the **logits**.\n",
        "\n",
        "<details>\n",
        "<summary>Question - can you see what makes logits non-unique (i.e. why any given set of probabilities might correspond to several different possible sets of logits)?</summary>\n",
        "\n",
        "Logits are **translation invariant**. If you add some constant $c$ to all logits $x_i$, then the new probabilities are:\n",
        "\n",
        "$$\n",
        "p_i' = \\frac{e^{x_i + c}}{\\sum_j e^{x_j + c}} = \\frac{e^{x_i}}{\\sum_j e^{x_j}} = p_i\n",
        "$$\n",
        "\n",
        "in other words, the probabilities don't change.\n",
        "\n",
        "We can define **logprobs** as the log of the probabilities, i.e. $y_i = \\log p_i$. Unlike logits, these are uniquely defined.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKzRBaB8jBUG"
      },
      "source": [
        "### Exercise - implement the simple MLP\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to ~20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "The diagram below shows what your MLP should look like:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mlp-mermaid.svg\" width=\"170\">\n",
        "\n",
        "Please ask a TA (or message the Slack group) if any part of this diagram is unclear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-Iaj1re_jBUG",
        "outputId": "fdc83fad-b5d8-412f-9036-22a53e8b69ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleMLP(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Linear(input_shape=784, output_shape=100)\n",
            "  (relu): ReLU()\n",
            "  (linear2): Linear(input_shape=100, output_shape=10)\n",
            ")\n",
            "All tests in `test_mlp_module` passed!\n",
            "tensor([[-4.3049e-01,  5.6839e-01,  1.9522e-01,  3.6895e-01, -9.1937e-02,\n",
            "          2.8753e-01,  2.8758e-01, -7.6440e-01,  3.4583e-01,  3.6565e-01,\n",
            "         -6.1319e-01, -2.6964e-01, -2.8655e-02,  1.5208e-01, -5.2526e-01,\n",
            "         -3.1165e-01, -4.9636e-01, -1.7967e-01,  4.4281e-01,  9.7358e-03,\n",
            "          3.6954e-03, -6.1794e-01,  8.5527e-02, -1.8080e-01,  1.3657e-02,\n",
            "          7.3168e-03, -7.7994e-02,  2.0905e-01,  3.8518e-01, -6.4995e-02,\n",
            "         -3.9671e-01, -3.7956e-01, -2.0269e-01, -5.9752e-02,  2.1296e-01,\n",
            "         -1.5577e-01,  7.9493e-04, -6.6965e-01,  3.5269e-01,  4.7821e-01,\n",
            "         -1.8762e-01, -3.0233e-01,  3.9555e-01,  1.5879e-01,  1.2332e-02,\n",
            "          2.6899e-01, -4.6126e-01, -3.6104e-01,  2.3096e-01,  7.8349e-01,\n",
            "          4.7058e-01,  1.7547e-01, -7.9396e-01, -4.0862e-01, -1.7627e-02,\n",
            "         -1.7076e-02,  1.8468e-01, -1.3232e-01,  3.5588e-01,  1.0624e-01,\n",
            "          1.2158e-01,  4.9695e-01, -3.5111e-01,  1.8549e-01,  2.1276e-01,\n",
            "          2.5804e-01,  4.6137e-01,  2.1224e-01,  4.2611e-01,  5.4121e-01,\n",
            "         -4.9172e-02,  1.2715e-01, -2.9845e-02,  2.9249e-01,  3.3307e-01,\n",
            "          9.4810e-02,  2.8001e-01, -1.2704e-01, -1.7603e-01, -2.6509e-01,\n",
            "         -6.4323e-01,  3.0026e-02,  5.1694e-03, -3.8642e-02,  9.6482e-02,\n",
            "          3.4271e-01,  1.2146e-01,  1.4760e-01,  4.6254e-01, -4.8605e-02,\n",
            "          2.0503e-01, -8.4091e-03, -6.5314e-02, -5.8966e-01, -3.9450e-03,\n",
            "         -1.6939e-01, -6.1559e-01, -2.3291e-01, -1.8322e-01,  6.3190e-01],\n",
            "        [ 1.6021e-01,  1.9474e-01,  5.6833e-02,  5.0447e-01,  2.8718e-01,\n",
            "          5.3135e-01,  6.2672e-01, -3.3353e-01,  2.8755e-01, -3.0058e-01,\n",
            "         -3.0791e-01, -2.0010e-01,  1.5174e-01,  1.8780e-01, -1.7343e-01,\n",
            "         -1.4768e-01, -4.2306e-01, -1.9161e-01,  3.3856e-01,  2.9166e-02,\n",
            "          3.6155e-01, -1.4301e-01,  1.3707e-01, -3.1346e-01, -2.5541e-01,\n",
            "          9.1642e-02,  2.2210e-01,  1.2910e-01,  1.7569e-01, -2.4438e-01,\n",
            "         -5.5793e-02, -5.1531e-01,  1.4819e-01, -2.4180e-01,  1.2525e-01,\n",
            "         -3.4487e-01,  1.0297e-01, -3.1350e-01,  1.1671e+00,  5.1348e-01,\n",
            "         -1.9117e-01, -2.5029e-01,  1.9064e-01,  2.3191e-01, -1.9366e-01,\n",
            "          2.3345e-01, -2.2838e-01, -5.1790e-01, -5.0078e-02,  8.8539e-01,\n",
            "          8.4871e-02,  5.3562e-01, -5.3411e-01,  1.5352e-02, -1.0170e-01,\n",
            "         -1.3094e-01,  5.8153e-01, -9.4442e-02,  2.4094e-01,  2.8393e-01,\n",
            "          6.5105e-01,  4.7015e-01, -4.4521e-01,  2.5088e-01,  2.1072e-01,\n",
            "         -9.0470e-03,  4.5855e-01,  4.4257e-01, -1.0136e-01,  1.8069e-01,\n",
            "          1.5736e-01,  3.9903e-02, -1.4163e-01,  2.4737e-01,  4.6573e-01,\n",
            "          4.3711e-01,  6.5352e-01, -4.4588e-01,  6.9569e-02, -1.9079e-01,\n",
            "         -7.2105e-01, -1.3404e-01,  3.4366e-01, -1.7957e-01,  2.7434e-01,\n",
            "          1.8806e-02, -1.6779e-01, -1.0302e-01, -3.8161e-02, -6.3511e-01,\n",
            "          2.1256e-01, -1.0157e-01, -2.4281e-02, -4.2052e-01,  3.0028e-01,\n",
            "         -5.2174e-02, -2.3245e-01, -1.9726e-01, -3.3610e-01,  1.8822e-01],\n",
            "        [-1.3391e-01,  2.7216e-01,  2.9218e-01,  2.3734e-01,  1.0518e-01,\n",
            "          4.1568e-01,  6.9419e-02, -4.7994e-01,  2.6914e-01, -3.1237e-01,\n",
            "         -3.8125e-01, -3.2676e-01, -7.3225e-02, -1.1625e-02, -3.5353e-01,\n",
            "          4.9401e-02, -7.0067e-01, -1.8989e-01,  3.6123e-01,  2.1722e-01,\n",
            "          1.8202e-01, -2.2609e-01,  2.0500e-01,  1.6352e-01, -5.9580e-01,\n",
            "         -2.8655e-01,  3.4162e-01,  8.6566e-02,  3.1755e-01, -1.2673e-01,\n",
            "         -2.8562e-01, -5.7596e-01,  1.5766e-01, -2.9405e-01, -8.0901e-02,\n",
            "         -3.7746e-01,  2.3180e-01, -5.3801e-01,  3.3585e-01,  5.0546e-01,\n",
            "         -2.0067e-01, -1.3213e-01,  8.0487e-02,  2.1718e-01,  1.4688e-01,\n",
            "         -1.3484e-03, -1.8069e-01, -1.7836e-01,  1.2633e-01,  6.2610e-01,\n",
            "          2.4648e-01,  3.1993e-02, -6.1488e-01, -5.4575e-01,  1.3983e-01,\n",
            "          3.7007e-02,  6.2878e-02,  2.8219e-02,  2.5529e-02, -1.4724e-02,\n",
            "          3.8010e-01,  5.9237e-01, -1.2807e-01,  2.4372e-01,  1.3758e-01,\n",
            "         -4.3633e-01,  5.4168e-01,  1.5339e-01,  3.9168e-01,  4.5079e-01,\n",
            "         -1.4988e-01,  8.3184e-02, -1.8876e-01,  1.7163e-01,  3.0917e-01,\n",
            "         -1.0458e-01,  1.7415e-01, -3.9422e-01,  3.6644e-02, -1.3280e-01,\n",
            "         -8.1118e-01,  2.6099e-01,  3.5724e-02,  2.6041e-01,  8.7493e-02,\n",
            "          2.2414e-01,  2.5881e-01,  6.6409e-02, -2.0218e-01, -3.5401e-01,\n",
            "          2.3277e-01, -2.6538e-04, -1.6925e-01,  1.1205e-01,  1.5169e-02,\n",
            "         -9.9590e-02, -3.6578e-01,  3.1992e-01, -2.9830e-01,  5.0788e-01],\n",
            "        [-4.5117e-02,  2.8810e-01,  1.4954e-01,  3.8848e-01, -6.3887e-02,\n",
            "          5.9290e-01,  9.9592e-02, -5.6326e-01,  2.1908e-01,  2.2999e-01,\n",
            "         -4.8917e-01, -7.1460e-01,  8.6356e-02,  2.4086e-01, -1.2550e-01,\n",
            "          2.2272e-01, -4.2536e-01, -1.4225e-01,  1.7619e-01,  3.8531e-01,\n",
            "          2.6295e-01, -1.1513e-01,  2.3711e-01,  1.1844e-01, -1.0195e-01,\n",
            "         -4.9922e-02,  1.0798e-01,  2.4698e-01,  1.4439e-01, -6.2678e-02,\n",
            "          1.8578e-01, -5.0156e-01, -5.2185e-02, -2.0394e-01, -9.6494e-02,\n",
            "         -7.0146e-01, -1.2982e-01, -2.8562e-01,  7.5002e-01,  3.8803e-03,\n",
            "         -2.4743e-01, -4.9961e-02,  2.8656e-01,  1.1320e-01, -1.6479e-01,\n",
            "          3.3195e-01, -2.4176e-01, -2.8620e-01,  3.8889e-02,  7.1306e-01,\n",
            "          2.6283e-01,  1.7679e-01, -9.6071e-01, -3.5314e-02,  1.1645e-01,\n",
            "          3.7079e-01,  3.9851e-01,  5.4402e-04,  7.5219e-02,  2.1211e-01,\n",
            "          6.0199e-01,  6.3805e-01, -3.8256e-01,  2.3465e-01,  2.3423e-01,\n",
            "         -8.4640e-02,  8.3493e-01,  1.8171e-01,  8.8104e-02, -1.2984e-01,\n",
            "          3.5269e-02,  2.1983e-02, -1.5065e-01,  4.8886e-02,  2.3145e-01,\n",
            "          6.5778e-01,  2.2411e-01, -4.0015e-02,  2.3371e-01, -3.6220e-01,\n",
            "         -8.8665e-01, -1.6585e-01,  3.1342e-03,  2.9380e-02,  3.8697e-01,\n",
            "          3.0314e-01, -2.5111e-01,  3.1724e-01, -1.5066e-01, -1.7469e-01,\n",
            "          1.5860e-02,  1.3040e-01,  6.5568e-02, -2.1452e-01, -1.3974e-01,\n",
            "         -2.9864e-01, -5.9276e-01, -1.6349e-04,  1.4929e-03,  9.5667e-01],\n",
            "        [ 1.1601e-01,  1.6570e-01,  3.8596e-02,  4.2874e-01,  6.8029e-02,\n",
            "          5.9814e-01,  5.4477e-02, -4.7198e-01,  4.6753e-01,  7.5631e-02,\n",
            "         -7.7180e-01, -1.9406e-01,  1.3424e-01,  1.8213e-01, -1.8774e-01,\n",
            "          1.8505e-01, -5.4002e-01, -1.8710e-01, -5.2718e-02,  3.1636e-01,\n",
            "          3.3182e-01, -3.4187e-01,  1.3390e-01, -1.5024e-01, -3.0902e-02,\n",
            "         -2.4706e-01, -1.7900e-01,  1.4289e-01, -5.3154e-02,  1.7396e-01,\n",
            "          9.4632e-02, -4.1490e-01, -2.1913e-02, -3.9534e-01,  2.1156e-01,\n",
            "         -9.4039e-02,  4.4104e-01, -3.4126e-01,  1.0453e+00,  1.8106e-01,\n",
            "         -1.2754e-02, -3.3439e-01,  1.9672e-01,  1.4867e-01, -2.5499e-01,\n",
            "          6.2152e-01, -5.8364e-02, -2.0283e-01,  1.7601e-01,  6.5844e-01,\n",
            "          4.8419e-02,  1.0220e-01, -7.0592e-01, -1.4603e-01, -2.1020e-01,\n",
            "          3.3264e-01,  1.2776e-01,  2.6231e-01,  1.7024e-01,  1.4641e-01,\n",
            "          7.2470e-01,  4.1686e-01, -1.3081e-01,  2.9789e-01,  3.0752e-01,\n",
            "         -3.9775e-02,  2.3347e-01,  5.4122e-01,  1.2800e-01,  2.8829e-01,\n",
            "         -1.4977e-01,  2.4317e-01, -2.3199e-01,  1.7070e-01,  5.8903e-01,\n",
            "          2.0525e-01,  5.0867e-01, -2.5568e-01, -1.2125e-01, -6.2999e-01,\n",
            "         -4.7429e-01, -3.0868e-01,  2.2178e-02, -1.3370e-01, -1.4426e-01,\n",
            "          4.3163e-01,  1.7587e-01, -1.1368e-01, -8.8717e-02, -3.2743e-01,\n",
            "          8.2569e-02, -2.6222e-02, -1.2201e-01, -3.0190e-01, -1.0407e-01,\n",
            "         -4.5561e-01, -2.6232e-01,  9.3772e-02,  1.3694e-01,  3.7363e-01],\n",
            "        [-1.7723e-02,  2.6572e-01,  2.1783e-01,  6.6275e-01,  2.5892e-01,\n",
            "          4.7593e-01,  3.9568e-01, -3.0995e-01,  7.5336e-02, -1.4600e-01,\n",
            "         -5.8914e-01, -4.9704e-01,  1.7672e-01, -1.8493e-01, -2.7504e-01,\n",
            "          1.1576e-02, -5.3953e-01, -9.9230e-02,  4.0158e-01,  5.7055e-01,\n",
            "          2.4004e-01, -5.8854e-01,  1.3077e-01,  1.5312e-01, -2.0089e-01,\n",
            "         -1.9157e-01,  8.5479e-02,  2.7071e-01,  2.7337e-01,  1.3685e-01,\n",
            "         -2.4749e-01, -3.9778e-01, -2.9478e-01, -1.0136e-01,  2.7214e-01,\n",
            "         -5.0505e-01,  1.2158e-01, -5.0013e-01,  1.0280e+00,  3.3197e-01,\n",
            "         -2.3169e-01, -1.1909e-01,  1.4253e-01,  2.0905e-01, -1.9065e-01,\n",
            "          1.9444e-01, -2.9820e-01, -4.7653e-01,  1.5451e-01,  9.7731e-01,\n",
            "          2.9410e-01,  2.5119e-01, -1.0554e+00, -1.5447e-01,  2.4330e-01,\n",
            "          2.7600e-01,  1.1213e-01, -2.4759e-01,  3.6191e-01, -7.0671e-02,\n",
            "          9.2218e-01,  5.6332e-01, -4.8492e-01,  1.7038e-01, -2.5481e-01,\n",
            "         -2.0622e-01,  7.7700e-01,  2.5021e-01,  7.8830e-02,  2.1096e-01,\n",
            "          9.1359e-02, -1.3669e-01, -2.1418e-01,  2.0444e-01,  1.5783e-01,\n",
            "          2.1039e-01,  2.1426e-01, -9.5738e-02,  4.3575e-02, -2.5053e-01,\n",
            "         -4.4233e-01,  1.8074e-01,  2.8177e-03, -3.9688e-01,  4.1965e-02,\n",
            "          3.1487e-01, -1.6034e-01, -3.6377e-01, -3.6343e-01, -1.2782e-01,\n",
            "         -1.7594e-01,  1.0784e-01,  1.9505e-02, -3.1341e-01, -2.9579e-01,\n",
            "         -1.8049e-02, -4.7256e-01,  1.0776e-01,  9.0436e-02,  4.7556e-01],\n",
            "        [ 7.8983e-02,  3.6883e-01,  2.5244e-01,  4.3882e-01, -1.4892e-01,\n",
            "          6.6341e-01,  3.4310e-01, -5.2297e-01,  3.6177e-01,  4.7816e-01,\n",
            "         -5.4511e-01, -1.5069e-01,  8.5438e-02,  6.5656e-02, -2.0867e-01,\n",
            "         -3.4326e-01, -1.6671e-01, -9.0008e-02, -8.4308e-02,  2.1738e-01,\n",
            "          5.9549e-01, -2.4443e-01,  2.1557e-01, -1.3177e-01, -2.2890e-01,\n",
            "         -1.7924e-01,  3.0862e-01,  3.6335e-03,  3.8844e-01,  1.8770e-01,\n",
            "          6.4691e-02, -8.1750e-01,  3.1022e-02, -2.2886e-01,  2.4056e-01,\n",
            "         -2.7979e-01, -9.5012e-02, -2.8296e-01,  1.0804e+00,  5.2365e-01,\n",
            "         -3.0292e-01, -7.5463e-01, -4.9986e-03, -5.9778e-02, -3.7212e-01,\n",
            "          3.5583e-01, -1.7295e-01, -1.9562e-01,  3.1669e-01,  9.2996e-01,\n",
            "          1.8992e-01,  2.0362e-01, -5.9610e-01,  1.4413e-02,  7.6880e-02,\n",
            "          2.8335e-01,  2.5004e-01, -5.0313e-01,  2.9817e-01,  2.3280e-01,\n",
            "          5.9504e-01,  7.3869e-01, -1.2510e-01,  6.5085e-02,  8.4634e-02,\n",
            "         -1.0092e-01,  4.2331e-01,  3.2382e-01,  1.1038e-01,  3.5717e-01,\n",
            "         -2.2733e-01,  9.3278e-02, -3.2138e-01,  1.4511e-01,  4.3098e-01,\n",
            "          3.7449e-01,  4.7203e-01, -2.1823e-01,  2.0216e-01, -3.7455e-01,\n",
            "         -6.7153e-01, -1.0564e-02, -2.7158e-01,  1.4469e-01, -7.7453e-02,\n",
            "          4.7762e-01, -4.1198e-01,  2.8787e-02,  1.1201e-01, -3.2897e-01,\n",
            "          6.8628e-02,  1.1390e-01, -2.2885e-01, -1.0113e-01,  3.8687e-01,\n",
            "          8.4891e-02, -3.8804e-01, -1.8409e-01,  1.3196e-01,  4.5359e-01],\n",
            "        [-3.2439e-01,  7.2007e-01,  2.9241e-01,  6.8808e-01, -2.2282e-01,\n",
            "          7.3018e-01,  1.9816e-01, -4.8661e-01,  9.6084e-02,  1.0584e-04,\n",
            "         -2.2744e-01, -2.1678e-01, -1.5997e-01,  8.8907e-02, -3.1393e-01,\n",
            "         -1.8378e-01, -5.3909e-01, -1.3726e-02, -1.2387e-02, -3.7682e-02,\n",
            "          1.4603e-01, -1.8634e-01,  4.3204e-01,  1.0868e-01,  1.8102e-01,\n",
            "         -1.5313e-01,  2.0775e-01,  1.0556e-01, -4.2911e-02,  1.0508e-01,\n",
            "         -1.2803e-01, -4.5092e-01, -8.7449e-02, -2.9486e-01,  2.3509e-02,\n",
            "         -2.6730e-01, -1.2459e-01, -8.6392e-01,  7.9636e-01,  2.6627e-01,\n",
            "         -2.7172e-01, -5.5420e-01,  3.1018e-01, -6.5682e-03, -5.6775e-01,\n",
            "          6.9478e-01,  2.5768e-02, -2.7514e-01,  1.7204e-01,  7.0449e-01,\n",
            "          2.5679e-01,  1.1003e-02, -8.0617e-01, -1.3060e-01, -1.1326e-01,\n",
            "         -1.1732e-01,  4.3818e-01, -2.4105e-02,  1.8230e-01,  2.9269e-01,\n",
            "          7.1559e-01,  4.8429e-01, -1.1444e-01,  2.6645e-01,  4.7627e-02,\n",
            "         -1.8563e-01,  4.8258e-01,  1.3164e-01,  1.5452e-01,  3.1633e-01,\n",
            "          1.7114e-02,  1.9062e-01, -2.2851e-01, -1.0285e-02,  4.3017e-01,\n",
            "          4.1430e-01,  1.1025e-01, -4.3336e-01,  2.2510e-02, -6.4883e-01,\n",
            "         -4.9816e-01, -9.4510e-02, -2.9080e-01, -1.1188e-02,  1.9369e-01,\n",
            "          3.5489e-01, -6.7976e-04,  4.6701e-02, -2.0296e-02, -3.2094e-01,\n",
            "          2.3975e-01,  2.5706e-01, -5.6834e-02, -2.9311e-01,  6.9560e-03,\n",
            "         -1.3111e-01, -3.2615e-02, -3.0941e-01, -9.0663e-02,  7.6137e-01],\n",
            "        [-4.9472e-02,  2.7610e-01,  1.0813e-01,  4.0317e-01,  2.6899e-01,\n",
            "          5.7756e-01,  2.5945e-01, -4.3670e-01,  4.2233e-01,  1.3170e-02,\n",
            "         -2.1845e-01, -2.1517e-01, -8.7136e-02, -5.9881e-02,  1.2751e-01,\n",
            "          1.1984e-01, -8.1562e-01, -1.6826e-01,  3.0750e-01,  3.0570e-01,\n",
            "          2.9389e-01, -6.5602e-01,  1.2307e-01, -3.0070e-01, -1.1234e-02,\n",
            "         -2.5162e-01,  4.2771e-01,  1.6276e-01,  3.1392e-02,  1.4993e-01,\n",
            "         -3.6263e-01, -7.6128e-01, -1.5888e-01, -3.9155e-01,  4.4850e-02,\n",
            "         -4.6364e-01,  5.1346e-02, -6.1534e-01,  7.6115e-01,  4.3123e-01,\n",
            "         -3.7240e-01, -4.8470e-01,  4.5063e-02, -2.3052e-02, -3.8283e-01,\n",
            "          1.7389e-01, -7.6698e-02, -2.3643e-01,  1.2343e-01,  1.1550e+00,\n",
            "          2.3618e-01,  3.8162e-02, -9.1121e-01, -8.8336e-02, -1.4644e-01,\n",
            "          1.5078e-01,  3.3558e-01, -1.4086e-01,  7.8357e-02,  5.0839e-01,\n",
            "          6.2386e-01,  2.1909e-01, -1.9778e-01,  3.2772e-01,  1.1808e-01,\n",
            "         -2.4897e-01,  3.7746e-01,  4.5269e-01,  1.5498e-01,  2.8614e-01,\n",
            "         -3.0568e-01,  1.6283e-01, -2.8737e-01,  1.4296e-01,  3.9666e-01,\n",
            "          3.6703e-01,  1.4956e-01, -9.6225e-02, -2.4744e-01, -1.8410e-01,\n",
            "         -4.7214e-01, -1.2287e-01,  8.3755e-02,  9.9811e-02,  2.1094e-01,\n",
            "          2.5298e-01,  1.0288e-01, -1.9961e-01, -1.6919e-01, -4.4303e-01,\n",
            "          6.9627e-02,  2.0899e-01,  2.1903e-01, -3.4594e-01,  3.3874e-02,\n",
            "         -2.4454e-01, -5.8695e-01,  5.8760e-02, -1.6515e-01,  3.7680e-01],\n",
            "        [ 9.3073e-02,  7.3858e-01,  3.6983e-01,  4.0607e-01,  3.8117e-01,\n",
            "          7.8565e-01,  4.2008e-01, -5.0753e-01, -1.7177e-01, -9.0517e-02,\n",
            "         -2.7030e-01, -2.8686e-01,  1.2572e-03, -1.2554e-01,  8.0069e-02,\n",
            "         -3.4553e-01, -6.3833e-01, -4.7897e-02,  2.7462e-01,  2.6562e-01,\n",
            "          5.5356e-01, -3.5313e-01,  4.0707e-01, -5.4025e-02, -2.4003e-01,\n",
            "         -4.8390e-02,  1.9380e-01,  2.7440e-01,  2.4858e-01, -1.2293e-01,\n",
            "         -1.1538e-01, -5.1225e-01, -7.3435e-02, -1.2057e-02, -1.7682e-01,\n",
            "         -1.1172e-01, -1.2752e-01, -5.5562e-01,  9.4800e-01,  2.1586e-01,\n",
            "         -3.1598e-01, -2.2883e-01, -8.5875e-02, -1.5439e-01, -4.4419e-01,\n",
            "          4.3818e-02, -2.1855e-01, -5.0797e-01, -2.5813e-02,  7.9855e-01,\n",
            "          4.9961e-01,  2.6777e-01, -9.7014e-01,  1.2362e-02,  1.7651e-01,\n",
            "         -1.4423e-01,  2.6096e-01, -6.2863e-02,  5.1711e-01,  1.5791e-01,\n",
            "          4.4070e-01,  5.6904e-01, -2.8924e-01,  1.5846e-01,  3.0153e-01,\n",
            "         -5.1635e-02,  3.8636e-01,  3.5536e-01,  7.5101e-02,  2.0912e-01,\n",
            "          8.9985e-02, -1.0545e-02, -3.1434e-01,  3.3116e-02,  3.8000e-01,\n",
            "          3.2930e-01,  2.8124e-01, -3.9281e-01, -2.9663e-02, -4.5729e-01,\n",
            "         -5.8309e-01,  9.1122e-02,  2.6410e-02,  2.1074e-01,  3.0180e-01,\n",
            "          1.9965e-01, -8.0667e-02,  7.2069e-02,  1.1676e-01, -3.0820e-01,\n",
            "         -1.1908e-01, -1.3812e-01, -1.8380e-01, -3.2751e-01, -3.7799e-01,\n",
            "         -6.7859e-02, -4.7456e-01, -5.3671e-02, -3.1006e-02,  6.3831e-01]],\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "All tests in `test_mlp_forward` passed!\n"
          ]
        }
      ],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = Flatten()\n",
        "        self.linear1 = Linear(in_features=28**2, out_features=100)\n",
        "        self.relu = ReLU()\n",
        "        self.linear2 = Linear(in_features=100, out_features=10)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        logits = self.linear2(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = SimpleMLP()\n",
        "print(model)\n",
        "tests.test_mlp_module(SimpleMLP)\n",
        "tests.test_mlp_forward(SimpleMLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wFEVgZWjBUG"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = Flatten()\n",
        "        self.linear1 = Linear(in_features=28 * 28, out_features=100)\n",
        "        self.relu = ReLU()\n",
        "        self.linear2 = Linear(in_features=100, out_features=10)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.linear2(self.relu(self.linear1(self.flatten(x))))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUsPcuGNjBUG"
      },
      "source": [
        "In the next section, we'll learn how to train and evaluate our model on real data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pual9hHjBUG"
      },
      "source": [
        "# 2️⃣ Training Neural Networks\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand how to work with transforms, datasets and dataloaders\n",
        "> - Understand the basic structure of a training loop\n",
        "> - Learn how to write your own validation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgkKLYK2jBUG"
      },
      "source": [
        "## Transforms, Datasets & DataLoaders\n",
        "\n",
        "Before we use this model to make any predictions, we first need to think about our input data. Below is a block of code to fetch and process MNIST data. We will go through it line by line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "EG9SNl8UjBUG",
        "outputId": "fe9754e5-7dc8-43c8-af7a-1323ffb0c2ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_batch.shape=torch.Size([64, 1, 28, 28])\n",
            "label_batch.shape=torch.Size([64])\n",
            "\n",
            "img.shape=torch.Size([1, 28, 28])\n",
            "label=7\n",
            "\n"
          ]
        }
      ],
      "source": [
        "MNIST_TRANSFORM = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(0.1307, 0.3081),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def get_mnist(trainset_size: int = 10_000, testset_size: int = 1_000) -> tuple[Subset, Subset]:\n",
        "    \"\"\"Returns a subset of MNIST training data.\"\"\"\n",
        "\n",
        "    # Get original datasets, which are downloaded to \"chapter0_fundamentals/exercises/data\" for future use\n",
        "    mnist_trainset = datasets.MNIST(exercises_dir / \"data\", train=True, download=True, transform=MNIST_TRANSFORM)\n",
        "    mnist_testset = datasets.MNIST(exercises_dir / \"data\", train=False, download=True, transform=MNIST_TRANSFORM)\n",
        "\n",
        "    # # Return a subset of the original datasets\n",
        "    mnist_trainset = Subset(mnist_trainset, indices=range(trainset_size))\n",
        "    mnist_testset = Subset(mnist_testset, indices=range(testset_size))\n",
        "\n",
        "    return mnist_trainset, mnist_testset\n",
        "\n",
        "\n",
        "mnist_trainset, mnist_testset = get_mnist()\n",
        "mnist_trainloader = DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
        "mnist_testloader = DataLoader(mnist_testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Get the first batch of test data, by starting to iterate over `mnist_testloader`\n",
        "for img_batch, label_batch in mnist_testloader:\n",
        "    print(f\"{img_batch.shape=}\\n{label_batch.shape=}\\n\")\n",
        "    break\n",
        "\n",
        "# Get the first datapoint in the test set, by starting to iterate over `mnist_testset`\n",
        "for img, label in mnist_testset:\n",
        "    print(f\"{img.shape=}\\n{label=}\\n\")\n",
        "    break\n",
        "\n",
        "t.testing.assert_close(img, img_batch[0])\n",
        "assert label == label_batch[0].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZPruRoVjBUG"
      },
      "source": [
        "The `torchvision` package consists of popular datasets, model architectures, and common image transformations for computer vision, and `torchvision.transforms` provides access to a suite of functions for preprocessing data. We define a transform for the MNIST data (which is applied to each image in the dataset) by composing `ToTensor` (which converts a `PIL.Image` object into a PyTorch tensor) and `Normalize` (which takes arguments for the mean and standard deviation, and performs the linear transformation `x -> (x - mean) / std`). For the latter, we use `0.1307` and `0.3081` which are the empirical mean & std of the raw data (so after this transformation, the data will have mean 0 and variance 1).\n",
        "\n",
        "Next, we define our datasets using `torchvision.datasets`. The first argument tells us where to save our data to (so that when we run this in the future we won't have to re-save it), and `transform=MNIST_TRANSFORM` tells us that we should apply our previously defined `transform` to each element in our dataset. We also use `Subset` which allows us to return a slice of the dataset rather than the whole thing (because our model won't need much data to train!).\n",
        "\n",
        "Finally, since our dataset only allows for iteration over individual datapoints, we wrap it in `DataLoader` which enables iteration over **batches**. It also provides useful arguments like `shuffle`, which determine whether we randomize the order after each epoch. The code above demonstrates iteration over the dataset & dataloader respectively, showing how the first element in the dataloader's first batch equals the first element in the dataset (note that this wouldn't be true for the training set, because we've shuffled it).\n",
        "\n",
        "<details>\n",
        "<summary>Aside - why batch sizes are often powers of 2</summary>\n",
        "\n",
        "It's common to see batch sizes which are powers of two. The motivation is for efficient GPU utilisation, since processor architectures are normally organised around powers of 2, and computational efficiency is often increased by having the items in each batch split across processors. Or at least, that's the idea. The truth is a bit more complicated, and some studies dispute whether it actually saves time, so at this point it's more of a standard convention than a hard rule which will always lead to more efficient training.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScJ71Ki8jBUG"
      },
      "source": [
        "Before proceeding, try and answer the following questions:\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Question - can you explain why we include a data normalization function in <code>torchvision.transforms</code> ?</summary>\n",
        "\n",
        "One consequence of unnormalized data is that you might find yourself stuck in a very flat region of the domain, and gradient descent may take much longer to converge.\n",
        "\n",
        "Normalization isn't strictly necessary for this reason, because any rescaling of an input vector can be effectively undone by the network learning different weights and biases. But in practice, it does usually help speed up convergence.\n",
        "\n",
        "Normalization also helps avoid numerical issues.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Question - what is the benefit of using <code>shuffle=True</code> when defining our dataloaders? What might the problem be if we didn't do this?</summary>\n",
        "\n",
        "Shuffling is done during the training to make sure we aren't exposing our model to the same cycle (order) of data in every epoch. It is basically done to ensure the model isn't adapting its learning to any kind of spurious pattern.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iTKJ-PCjBUG"
      },
      "source": [
        "### Aside - `tqdm`\n",
        "\n",
        "You might have seen some blue progress bars running when you first downloaded your MNIST data. These were generated using a library called `tqdm`, which is also a really useful tool when training models or running any process that takes a long period of time.\n",
        "\n",
        "The `tqdm` function wraps around an iterable, and displays a progress bar as you iterate through it. The code below shows a minimal example:\n",
        "\n",
        "```python\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "for i in tqdm(range(100)):\n",
        "    time.sleep(0.1)\n",
        "```\n",
        "\n",
        "There are some more advanced features of `tqdm` too, for example:\n",
        "\n",
        "- If you define the progress bar `pbar = tqdm(...)` before your iteration, then you have the option of adding extra information to it using `pbar.set_description` or `pbar.set_postfix`\n",
        "- You can specify the total number of iterations with `tqdm(iterable, total=...)`; this is actually very important when the iterable is something like `enumerate(...)` which doesn't have a length attribute, since tqdm will usually try and infer the total from calling `len` on the iterable you pass it.\n",
        "\n",
        "Here's some code that demonstrates these extra features:\n",
        "\n",
        "```python\n",
        "word = \"hello!\"\n",
        "pbar = tqdm(enumerate(word), total=len(word))\n",
        "t0 = time.time()\n",
        "\n",
        "for i, letter in pbar:\n",
        "    time.sleep(1.0)\n",
        "    pbar.set_postfix(i=i, letter=letter, time=f\"{time.time()-t0:.3f}\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "word = \"hello!\"\n",
        "pbar = tqdm(enumerate(word), total=len(word))\n",
        "t0 = time.time()\n",
        "\n",
        "for i, letter in pbar:\n",
        "    time.sleep(1.0)\n",
        "    pbar.set_postfix(i=i, letter=letter, time=f\"{time.time()-t0:.3f}\")"
      ],
      "metadata": {
        "id": "Ym7-7RaEHc19",
        "outputId": "5902584c-d29b-4fb3-c231-d729398fbac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0dfb59a99d334be79295eb8b7867b33e",
            "f60f1550aef947929790b23d53fb2214",
            "f601fc08052c4d6bb3a406c0a1e3871d",
            "09920f80665a40be843961e5c018685d",
            "f01ca72e651149e69035da348dd18f49",
            "6aac21b6bf594cb790475e082c8d9b7e",
            "dcedc6167cee4a4fa83b4e03715c8e72",
            "e5b687e2a86b4110b7f7ba6f27457f7f",
            "97b22c3d1591425caa0cb075cad17c84",
            "367bf383c9324f5e9f9a07d7ca00200d",
            "87f818029d06461c8b923fde45aabfc2"
          ]
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dfb59a99d334be79295eb8b7867b33e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfRC2yXljBUG"
      },
      "source": [
        "### Aside - `device`\n",
        "\n",
        "One last thing to discuss before we move onto training our model: **GPUs**. We'll discuss this in more detail in later exercises. For now, [this page](https://wandb.ai/wandb/common-ml-errors/reports/How-To-Use-GPU-with-PyTorch---VmlldzozMzAxMDk) should provide a basic overview of how to use your GPU. A few things to be aware of here:\n",
        "\n",
        "* The `to` method is really useful here - it can move objects between different devices (i.e. CPU and GPU) *as well as* changing a tensor's datatype.\n",
        "    * Note that `to` is never inplace for tensors (i.e. you have to call `x = x.to(device)`), but when working with models, calling `model = model.to(device)` or `model.to(device)` are both perfectly valid.\n",
        "* Errors from having one tensor on cpu and another on cuda are very common. Some useful practices to avoid this:\n",
        "    * Throw in assert statements, to make sure tensors are on the same device\n",
        "    * Remember that when you initialise an array (e.g. with `t.zeros` or `t.arange`), it will be on CPU by default.\n",
        "    * Tensor methods like [`new_zeros`](https://pytorch.org/docs/stable/generated/torch.Tensor.new_zeros.html) or [`new_full`](https://pytorch.org/docs/stable/generated/torch.Tensor.new_full.html) are useful, because they'll create tensors which match the device and dtype of the base tensor.\n",
        "\n",
        "It's common practice to put a line like this at the top of your file, defining a global variable which you can use in subsequent modules and functions (excluding the print statement):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pEYxzx0HjBUG",
        "outputId": "e9a6f765-6f68-4ab7-c64f-ffa07a24bd5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# If this is CPU, we recommend figuring out how to get cuda access (or MPS if you're on a Mac).\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMTdW3bGjBUG"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Below is a very simple training loop, which you can run to train your model.\n",
        "\n",
        "In later exercises, we'll try to **modularize** our training loops. This will involve things like creating a `Trainer` class which wraps around our model, and giving it methods like `training_step` and `validation_step` which correspond to different parts of the training loop. This will make it easier to add features like logging and validation, and will also make our code more readable and easier to refactor. However, for now we've kept things simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TaV3wfVgjBUO",
        "collapsed": true,
        "outputId": "17c9ef7c-900c-451d-ad7f-96aa74b40b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "967a628fc674412fa6d7447d9b46d5df",
            "bd41724d6200454b854bb838ea4a7a16",
            "6e34a3a5b9f945418cfc57aa039a05df",
            "6bbb7be75c7f4e07a5ff795e97aa98d7",
            "cd473b454a034157a5d400feaf6ac250",
            "57b034f7dac44a13816ddceedb665633",
            "ee98792456284a9cae8c02c7ca96f765",
            "02ad7964756e477f87a3512418bd0b20",
            "f2de6043c3ff404ead03cf3eb6406396",
            "cb8a45c6caa14777a58c145ab152658b",
            "250a2c27d4d442c2a0000b6875102a5d",
            "96cfe2de9bbc4e4a9f5d0bfce6c0fd9b",
            "b56918497d9547e3a6084ddff8bcf6db",
            "eef3d968a24d4c1c9da3c290db46b40f",
            "2764620e9033405bb52b4514f59c0d87",
            "a9d387ed255445fabe16dea48bce42fb",
            "a486a6efac68481580910a65d8a18476",
            "5cc08aba9dad4e2b9fa40796ef86fb08",
            "db6b3e5d43574b758b961929e29b2002",
            "18a297df2f1d462aac8663b0a1c82bc1",
            "05e55c5a1b454a36a4e8603d56578e98",
            "c627d1e65ba848f280cf2daeef06cd21",
            "0bc6662daec245c5a144716069e5a592",
            "ee5f92c05b964f19b5ae40743b2ba193",
            "a61f2e72d0a5414aae874c46fd3ce13a",
            "10a321e61d014dfca73ae0a1ac784251",
            "0cae7a0bfab64c11907ea4943d473c28",
            "7837facfe13a491086140a373f3a1f2c",
            "f90f8703785847dfbd6a8a9eee542c9d",
            "c6ba1e2ffc0446e9b6a22addaee74f1c",
            "fc0c14e4586f42799045f1a7428861a6",
            "80441d3c7893458abf71623ccc4b7c0a",
            "572ac257e2ff4174b2505173a88610a1"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "967a628fc674412fa6d7447d9b46d5df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4079, -2.6411, -1.7088,  ...,  0.7921,  0.2561,  0.1907],\n",
            "        [-0.7254,  0.0204,  0.0176,  ...,  0.3028,  0.5593,  0.3790],\n",
            "        [-0.1405, -0.2943,  0.9912,  ...,  0.0866,  1.8165, -0.5992],\n",
            "        ...,\n",
            "        [-0.7776, -0.7297, -2.0879,  ...,  2.6735, -0.2392, -0.1389],\n",
            "        [-0.7771,  0.4950, -1.2194,  ...,  0.7557,  0.0576, -0.2396],\n",
            "        [-0.8301, -0.4803, -0.1491,  ...,  0.9232,  0.0816, -0.4634]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4210, -0.9927, -2.4792,  ...,  0.6098,  0.8426,  1.4679],\n",
            "        [ 1.2769, -1.6637,  0.2108,  ...,  0.8863,  2.3101, -0.7593],\n",
            "        [-0.2102, -1.1030, -1.1056,  ...,  0.4897,  1.7734, -1.2272],\n",
            "        ...,\n",
            "        [-1.0071, -0.8717,  0.9309,  ..., -0.8688,  0.5095, -1.5989],\n",
            "        [ 1.1855, -1.2067,  0.6447,  ..., -0.4789,  3.3231,  0.3436],\n",
            "        [-1.8789, -1.1968, -0.0507,  ...,  1.5769,  0.3488,  0.6369]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2205, -0.9604,  0.2874,  ..., -0.6698,  1.4189, -1.4417],\n",
            "        [-0.4538, -3.0587,  0.6064,  ..., -0.1091,  1.3481, -0.6449],\n",
            "        [ 1.2752, -2.9118, -1.9549,  ...,  1.7242,  3.1390,  1.0189],\n",
            "        ...,\n",
            "        [-0.8064, -0.6732, -0.0246,  ...,  3.2554, -0.9660,  0.2808],\n",
            "        [-2.2141, -1.0129, -0.0478,  ...,  2.0861, -0.4365, -0.1406],\n",
            "        [ 2.9132, -0.7824, -0.9569,  ..., -1.2680,  1.6969, -0.1889]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0712, -1.9315, -0.2022,  ...,  0.5916,  0.3447,  0.7565],\n",
            "        [-1.2476, -0.9535,  0.2346,  ...,  0.4872,  1.5640, -1.0880],\n",
            "        [ 1.4876, -1.2235, -0.4436,  ..., -0.3893,  3.0288, -1.3847],\n",
            "        ...,\n",
            "        [ 0.1866, -3.3272, -1.8283,  ...,  1.7364,  2.0160,  1.1604],\n",
            "        [-1.3690, -0.0216, -0.4447,  ..., -0.0762,  1.2267,  0.0707],\n",
            "        [-0.2945, -3.7665,  0.7394,  ...,  2.2288,  0.7230,  0.8255]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6941, -0.7452, -0.0748,  ...,  0.2528, -0.0319,  0.5636],\n",
            "        [ 0.1609,  0.1509, -0.2058,  ...,  1.0253,  1.1275, -0.0327],\n",
            "        [-1.3940, -2.0672, -0.1338,  ...,  1.5597,  0.4613,  1.2840],\n",
            "        ...,\n",
            "        [-0.8551, -1.9183,  1.2744,  ...,  1.3413,  1.0794,  0.3275],\n",
            "        [-2.1513, -1.7954,  0.4191,  ...,  0.6896,  1.0084,  0.1494],\n",
            "        [ 0.7662, -2.8609, -0.4627,  ...,  1.5368,  1.2194, -0.1249]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7924, -0.4706,  3.5099,  ...,  0.1460,  0.2228,  2.7191],\n",
            "        [-0.6622, -0.9055, -0.8105,  ...,  1.4642,  1.0542,  1.0395],\n",
            "        [-1.0264, -2.5282, -0.7494,  ...,  1.8757,  3.6225,  1.2714],\n",
            "        ...,\n",
            "        [-1.9674, -1.3725,  0.9952,  ...,  1.3579,  4.2800, -1.2445],\n",
            "        [-1.3797, -0.9393, -0.1663,  ...,  3.8696, -0.1786,  0.1661],\n",
            "        [-1.8823, -0.8837,  0.6430,  ...,  2.7018,  1.6822, -0.3566]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5386, -3.6532,  0.4855,  ...,  0.4308,  1.0228, -0.5532],\n",
            "        [-0.6285, -2.7314,  0.1393,  ...,  1.0404,  0.7694,  1.0839],\n",
            "        [-1.9894, -1.1026,  0.7378,  ...,  2.0213,  0.9492,  4.0967],\n",
            "        ...,\n",
            "        [-0.7496, -3.9823, -0.5345,  ...,  1.3341,  2.9191, -0.4609],\n",
            "        [-1.5017, -1.7390, -0.6798,  ...,  2.5311,  3.4728,  0.9703],\n",
            "        [-0.0341, -3.5158,  1.8969,  ...,  2.1178,  0.5839,  0.5995]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1486,  0.2832, -1.6168,  ...,  0.8262,  0.1806,  1.3396],\n",
            "        [-0.7114, -3.7631, -0.1376,  ...,  2.1319,  3.4140,  1.2201],\n",
            "        [-3.7151, -1.9797,  0.7652,  ...,  2.1464,  2.1869,  1.8220],\n",
            "        ...,\n",
            "        [-2.1851, -1.6634,  1.1875,  ...,  0.8684,  0.3972, -0.2047],\n",
            "        [-0.6744, -3.9815,  0.7853,  ...,  1.2218,  3.2400,  0.0842],\n",
            "        [-0.2525, -2.8430,  0.0941,  ...,  0.1661,  0.3501,  1.6440]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0356, -3.5245,  0.4763,  ..., -1.2587,  1.4251, -0.9666],\n",
            "        [-1.2270, -1.7552, -0.4487,  ...,  0.8706,  0.5463,  1.8309],\n",
            "        [-2.5411, -2.7623,  1.7868,  ...,  1.1991,  1.0707,  0.3712],\n",
            "        ...,\n",
            "        [-1.0609, -1.8076,  0.8483,  ...,  2.1966, -0.3760,  1.2141],\n",
            "        [-1.2635, -2.2208,  0.4740,  ...,  0.6832,  2.7973, -0.1456],\n",
            "        [-0.3620, -4.8261,  1.3685,  ...,  1.1195,  3.8773,  1.0125]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1051, -2.4102, -1.7366,  ...,  0.1253, -0.2590,  1.2633],\n",
            "        [-0.4899, -2.3564,  1.6554,  ...,  0.8021,  0.9847,  0.0469],\n",
            "        [-2.0315, -1.2968,  2.9995,  ...,  1.0792,  1.1818,  0.5585],\n",
            "        ...,\n",
            "        [-0.5155, -2.9286,  0.1358,  ...,  0.1505,  2.3694, -0.5694],\n",
            "        [-2.6460, -1.4110,  2.1117,  ...,  1.0622,  3.3300,  0.7263],\n",
            "        [-2.0846, -0.7993,  0.0918,  ...,  2.5233, -0.8343,  2.7319]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1737, -1.2027, -1.5322,  ..., -1.3178,  4.4738, -1.1365],\n",
            "        [ 0.6022, -3.3035,  0.9678,  ...,  2.2316, -0.2713,  1.7923],\n",
            "        [-2.6859, -2.7899, -0.1027,  ...,  0.3789,  3.2381, -0.7678],\n",
            "        ...,\n",
            "        [-1.1495, -2.4206,  1.2442,  ...,  2.5632,  0.1122,  0.9515],\n",
            "        [-1.6315, -1.0408,  0.0745,  ...,  1.1628, -0.6927,  2.7505],\n",
            "        [-3.0707, -2.5436,  0.5706,  ...,  1.7641, -0.2912, -1.6206]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0521, -1.5781,  3.1263,  ...,  0.1835,  5.2753, -0.7323],\n",
            "        [-0.9773, -3.6188,  3.0428,  ...,  1.2617,  0.8235,  0.0728],\n",
            "        [-3.8919, -2.4866,  0.8759,  ..., -0.8727, -0.0342,  0.1328],\n",
            "        ...,\n",
            "        [-1.1214, -0.8859,  0.8967,  ...,  1.1884, -0.4035,  2.5767],\n",
            "        [-1.1861, -1.7275, -0.1929,  ...,  2.6477,  0.8301,  1.1097],\n",
            "        [-1.6224, -2.0622,  2.4117,  ...,  0.9538,  2.6274,  1.1718]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8579, -2.3015,  1.3367,  ...,  0.1896,  3.9259,  0.5078],\n",
            "        [-1.2754, -1.6055,  1.4671,  ...,  0.9296, -0.2712,  1.9334],\n",
            "        [-0.4688, -1.6667,  1.7675,  ...,  2.7863, -0.3113,  2.3514],\n",
            "        ...,\n",
            "        [ 0.3751, -1.9927,  0.3689,  ...,  0.7414,  1.0775,  1.8995],\n",
            "        [-1.2717, -1.8810, -0.0224,  ...,  1.3516, -0.5839,  3.4997],\n",
            "        [-2.9887, -2.5136,  2.4135,  ..., -1.3744,  3.2200, -1.3886]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8009, -2.4210,  3.2130,  ...,  2.4242,  1.5899,  1.5883],\n",
            "        [-0.9275, -2.3056, -0.5381,  ...,  0.5270, -0.2048,  2.9584],\n",
            "        [-0.1654, -3.5960,  1.8256,  ...,  1.4075,  1.2148,  1.7607],\n",
            "        ...,\n",
            "        [-1.1879, -2.3884, -2.1850,  ..., -0.1617,  2.5478, -0.6208],\n",
            "        [-1.6021, -6.1398,  2.8339,  ...,  1.4811,  0.5703,  0.3917],\n",
            "        [-1.8398, -2.1349,  1.2959,  ...,  1.3270, -1.6430,  2.1773]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7665, -2.4360,  3.2516,  ...,  1.6513,  2.2945,  1.0277],\n",
            "        [-2.7278, -1.5129,  1.5128,  ...,  0.8480,  1.9195,  2.3557],\n",
            "        [-1.0068, -3.6121,  2.8617,  ...,  0.9276,  0.5808,  2.0925],\n",
            "        ...,\n",
            "        [-1.1333, -1.9759,  4.4056,  ...,  1.8573, -0.0372,  0.9780],\n",
            "        [-0.5101, -1.6770,  2.5970,  ...,  1.4699,  1.6085,  2.3141],\n",
            "        [-0.9696, -1.4141,  0.3304,  ...,  1.0389,  2.3165,  1.0255]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5589, -4.4378,  2.9751,  ...,  0.6021,  1.8917,  0.6585],\n",
            "        [-2.7213, -3.0711,  2.3855,  ..., -1.5581,  1.2320, -0.5373],\n",
            "        [-2.3295, -2.6632,  3.7540,  ...,  1.7068, -0.0598,  1.6809],\n",
            "        ...,\n",
            "        [ 0.0295, -0.3891, -0.1250,  ..., -0.3340,  3.1057,  2.1324],\n",
            "        [-0.8896, -3.2170,  2.7825,  ...,  0.7118,  0.2858, -1.3509],\n",
            "        [-0.0915, -1.0273,  1.5572,  ...,  2.7028, -0.0683,  3.6210]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5846, -4.0119, -0.0960,  ...,  2.1901,  2.5859, -1.6954],\n",
            "        [-2.6230, -4.9173,  5.0138,  ...,  0.6738,  3.0939,  0.5131],\n",
            "        [-0.8599, -1.5437,  1.6790,  ...,  1.5640,  1.6725,  2.1676],\n",
            "        ...,\n",
            "        [-2.4209, -4.7105,  1.1504,  ...,  4.6256,  0.0326,  0.8689],\n",
            "        [-4.3615, -1.6621,  2.5255,  ...,  0.2366,  2.4392, -0.5640],\n",
            "        [-0.7060, -2.2320,  0.8250,  ...,  0.1112, -0.4886,  2.5589]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0519, -3.1838,  3.4976,  ...,  1.9188,  1.9546,  2.0155],\n",
            "        [-1.6112, -3.9153,  3.1647,  ...,  0.7227,  1.3295,  2.4039],\n",
            "        [-3.3518, -2.6893, -0.0987,  ..., -1.2143,  3.8535,  0.1796],\n",
            "        ...,\n",
            "        [-2.6658, -1.6690,  1.9617,  ..., -0.2343,  2.1199, -0.2642],\n",
            "        [-2.8666, -2.4869,  3.4935,  ...,  0.9472,  1.4105,  0.8943],\n",
            "        [-0.6737, -1.8007,  0.7726,  ...,  1.6120,  2.8656,  1.2697]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5345, -3.1720,  1.8434,  ...,  1.3781,  0.0126,  2.4691],\n",
            "        [-2.4160, -5.9570, -0.1629,  ...,  2.7919,  3.7342,  0.3534],\n",
            "        [-5.4804, -3.1218,  2.9925,  ...,  0.0708,  4.5875, -1.0519],\n",
            "        ...,\n",
            "        [-2.1459, -2.7040,  2.6622,  ...,  3.0519, -1.9204,  1.9584],\n",
            "        [-2.3528, -2.3734, -0.2840,  ...,  0.3873,  3.7842,  0.1907],\n",
            "        [-1.9990, -2.6881,  2.3125,  ...,  1.6168,  2.1459,  1.4867]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4376, -2.8909,  2.3613,  ..., -1.4767,  1.5578,  3.4900],\n",
            "        [ 0.1674, -4.8139,  2.4047,  ...,  1.4612,  2.4025,  1.2349],\n",
            "        [-4.2413, -3.5052,  2.4569,  ..., -1.0206,  3.6881,  0.1304],\n",
            "        ...,\n",
            "        [ 0.4819, -2.4965,  4.1603,  ...,  2.5406,  0.3823,  3.3415],\n",
            "        [-3.4640, -2.0969,  1.4011,  ..., -0.1417,  3.4933,  0.9086],\n",
            "        [-1.1249, -3.4565,  0.9828,  ...,  3.1011,  1.7399,  0.3576]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2143, -2.4263,  3.6488,  ..., -2.1157,  0.6180,  1.3766],\n",
            "        [-0.8825, -3.9529,  1.5965,  ...,  1.6296,  4.0723,  3.2294],\n",
            "        [-2.1718, -3.8252,  2.0446,  ...,  1.6671,  0.9557,  1.9305],\n",
            "        ...,\n",
            "        [-0.6305, -3.5987,  2.1540,  ...,  3.0054,  1.4858,  2.9246],\n",
            "        [-2.7531, -3.3514,  2.1833,  ...,  0.7036,  0.2488, -0.0235],\n",
            "        [-4.3166, -2.4341,  0.9937,  ...,  1.3735,  2.5121,  1.1106]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6730, -5.3255,  1.7319,  ...,  0.1756,  7.6813, -0.5063],\n",
            "        [-2.9490, -3.1770,  0.7366,  ..., -0.5622,  7.1113, -0.9275],\n",
            "        [-1.8686, -3.0749,  2.1186,  ...,  2.4185, -0.0610,  2.7795],\n",
            "        ...,\n",
            "        [-0.3070, -2.8161,  2.5333,  ..., -0.3294,  0.8441,  3.4600],\n",
            "        [ 0.4399, -2.5107,  2.1278,  ...,  2.5276, -0.2962,  2.4263],\n",
            "        [-2.6615, -2.4570,  3.6568,  ..., -1.4896,  2.9548,  0.4340]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2603, -3.2351,  2.1247,  ...,  2.2491,  5.0001,  1.8186],\n",
            "        [-1.3842, -2.5816,  0.8071,  ...,  2.1876, -0.3505,  3.5377],\n",
            "        [-0.5887, -3.2259,  3.1670,  ...,  2.5040,  1.1970,  0.8474],\n",
            "        ...,\n",
            "        [ 0.6331, -2.2620,  0.7352,  ...,  2.1153,  0.2566,  3.0254],\n",
            "        [-2.2326, -2.7878,  1.6249,  ...,  3.0539, -0.8326,  2.9340],\n",
            "        [-3.2632, -3.1229,  1.0777,  ...,  1.0286, -0.6820,  0.4366]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8350, -3.0368, -1.2811,  ...,  3.2781,  7.0863, -1.8097],\n",
            "        [-0.2950, -3.9338,  2.2241,  ...,  0.7218,  1.2359,  1.4766],\n",
            "        [-1.1178, -2.9144,  1.9386,  ...,  2.2923,  2.8259,  2.5379],\n",
            "        ...,\n",
            "        [-0.2785, -4.1964,  3.1735,  ...,  4.7440,  2.4928,  0.7122],\n",
            "        [-3.3053, -3.7760,  2.1556,  ...,  1.2959, -1.1881,  1.1697],\n",
            "        [ 0.3996, -3.9126,  1.8337,  ...,  2.2757,  1.4993,  3.7496]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7757, -2.9643,  0.6925,  ...,  2.2760,  0.7163,  4.1999],\n",
            "        [-2.8783, -2.7487,  2.6595,  ...,  3.4810,  0.1601,  1.8642],\n",
            "        [-1.0481, -2.3841,  1.6529,  ...,  3.4725, -0.8769,  2.4340],\n",
            "        ...,\n",
            "        [-1.6644, -5.8785,  1.7587,  ...,  0.0885,  1.5896,  1.9541],\n",
            "        [ 0.0944, -5.4081,  1.2123,  ...,  0.4299,  2.1956,  2.3596],\n",
            "        [-2.9805, -1.3988,  3.7897,  ...,  3.3074,  2.1049, -0.6120]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.9329, -2.0698,  2.5673,  ...,  1.1433,  2.7271, -0.5685],\n",
            "        [-1.7435, -0.8017,  2.8764,  ...,  3.3592,  0.6411,  1.4223],\n",
            "        [-2.6517, -2.6197,  2.6627,  ...,  0.9801,  6.3373,  0.2755],\n",
            "        ...,\n",
            "        [-1.8413, -1.4516,  4.4155,  ...,  4.1415,  0.6794,  2.6936],\n",
            "        [-3.5629, -5.2314,  4.4921,  ...,  0.1359,  2.5625,  0.1542],\n",
            "        [-2.4591, -2.5037,  1.8769,  ...,  1.1709,  2.3016,  0.4732]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7857, -2.3503,  1.4799,  ...,  0.1361,  1.3053,  2.9534],\n",
            "        [-2.9845, -3.1908,  3.6273,  ...,  1.4162,  2.9726,  0.2775],\n",
            "        [-4.1479, -3.6979,  2.0751,  ...,  1.1912,  1.0400,  1.6580],\n",
            "        ...,\n",
            "        [-3.9448, -2.2918,  4.2946,  ...,  1.2708,  0.8493,  1.1578],\n",
            "        [-1.6652, -3.5289,  0.6698,  ...,  0.1444,  3.4282,  2.9391],\n",
            "        [-0.9787, -1.1905,  3.8412,  ...,  1.5188, -0.2887,  0.6661]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3801, -1.9665,  4.7507,  ..., -0.1389,  0.6713,  1.0289],\n",
            "        [-0.6321, -4.0492,  3.6497,  ...,  0.5469,  1.8520,  0.8406],\n",
            "        [-3.0244, -1.3535, -1.0394,  ..., -2.3756,  0.3939,  1.9995],\n",
            "        ...,\n",
            "        [-2.3212, -2.5607,  4.1065,  ...,  1.1322,  2.4295,  0.1980],\n",
            "        [-3.5472, -4.0725,  4.0415,  ..., -0.6510,  3.9872,  0.3502],\n",
            "        [-2.2540, -2.5942,  1.0305,  ...,  1.8908,  6.5744, -0.2566]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0509, -2.1976,  2.8492,  ...,  2.8407,  0.7905,  2.6195],\n",
            "        [-2.3432, -6.0440,  0.8707,  ...,  2.7084,  4.5930,  1.4261],\n",
            "        [-3.9955, -2.3258,  2.4867,  ...,  0.4656,  3.6540, -0.1904],\n",
            "        ...,\n",
            "        [-1.6735, -3.6673,  3.6380,  ...,  1.1494,  0.0904,  1.5784],\n",
            "        [-3.6796, -3.9737,  3.7552,  ...,  2.0908, -0.1764,  0.4032],\n",
            "        [-2.3203, -1.9081,  2.7011,  ..., -0.7617,  1.1994,  1.1186]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0076, -2.4442, -0.4315,  ..., -1.9226,  4.4379,  0.0933],\n",
            "        [-2.4429, -3.6345,  0.8640,  ...,  3.9528,  2.3236,  0.5350],\n",
            "        [-1.6977, -3.8597,  3.8868,  ...,  0.0586,  5.0602,  0.1581],\n",
            "        ...,\n",
            "        [-2.3912, -3.4696,  3.1297,  ...,  2.3715,  4.6506, -0.1739],\n",
            "        [-2.6098, -0.7203,  2.5465,  ...,  2.2948,  3.6706,  1.1264],\n",
            "        [ 0.7477, -4.3703,  1.1502,  ...,  4.1049, -0.3420,  3.3291]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5226, -3.0010,  1.1912,  ...,  2.3771,  1.1266,  1.0094],\n",
            "        [-2.9423, -4.3013,  2.5313,  ...,  2.9085,  0.6423,  1.1568],\n",
            "        [-4.7278, -2.8690, -0.1305,  ...,  0.5309,  5.9199,  1.0222],\n",
            "        ...,\n",
            "        [-0.0633, -4.2428,  2.4020,  ...,  1.8916,  2.6902,  1.7222],\n",
            "        [-2.5047, -2.0141,  4.7214,  ..., -0.2758,  1.9572,  1.8616],\n",
            "        [-1.1004, -2.3728,  2.0736,  ...,  3.0221, -0.8613,  2.5301]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3609, -3.8882,  3.0893,  ...,  3.4495, -0.6834,  1.6840],\n",
            "        [-2.1795, -2.4190,  2.6638,  ..., -0.1109,  3.9720, -0.6172],\n",
            "        [-4.8121, -2.9965,  3.9988,  ...,  0.1443,  0.8683, -1.0086],\n",
            "        ...,\n",
            "        [-5.8877, -4.4462,  2.0999,  ...,  0.9522,  6.2776, -2.6570],\n",
            "        [-0.5866, -2.1120,  1.7857,  ...,  1.4535,  0.5432,  2.5633],\n",
            "        [-1.7578, -4.5721,  2.0430,  ...,  0.6023,  2.6775, -0.7106]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4128, -2.9893,  2.1276,  ...,  1.6699,  0.5749,  0.6185],\n",
            "        [-3.6245, -3.0198,  2.1181,  ...,  0.1218,  5.5404, -1.5359],\n",
            "        [-1.5627, -2.4715,  1.4523,  ...,  1.5391, -0.1274,  2.8744],\n",
            "        ...,\n",
            "        [-2.5383, -2.7059,  0.1189,  ...,  1.0097,  6.2451, -0.7606],\n",
            "        [-3.8179, -4.7460,  3.8056,  ...,  0.4717,  2.9815,  0.0709],\n",
            "        [-1.8006, -3.3513,  1.3175,  ...,  1.8125, -0.8203,  1.6679]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0362, -4.7239,  4.4030,  ...,  1.3462,  5.0042,  1.2135],\n",
            "        [-2.9969, -2.7055,  4.5178,  ..., -0.1612,  1.2365,  0.3740],\n",
            "        [-1.2123, -4.1806,  4.0078,  ...,  0.9714,  0.2801,  1.4551],\n",
            "        ...,\n",
            "        [-3.4711, -5.7356,  3.3159,  ...,  3.9272,  6.0711, -0.6227],\n",
            "        [-0.6996, -2.2611,  1.1206,  ...,  0.6307,  1.1529,  2.3437],\n",
            "        [-1.1834, -1.8009,  0.7827,  ...,  2.2774,  0.9270, -0.7082]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9890, -2.0563,  4.4029,  ..., -0.7471,  0.5155,  0.3512],\n",
            "        [-0.9189, -2.2968,  3.1655,  ...,  0.2838,  1.0647,  1.6103],\n",
            "        [-1.9634, -2.0193,  1.2717,  ...,  1.6878, -1.3558,  3.5429],\n",
            "        ...,\n",
            "        [-1.3444, -2.4939,  4.6874,  ...,  1.2527, -0.9271,  1.3914],\n",
            "        [-3.2521, -2.9154,  2.3385,  ...,  0.7975,  2.0379,  2.4168],\n",
            "        [-1.6446, -2.0511,  1.9669,  ...,  0.6547, -0.3921,  3.7888]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8273, -1.8840,  4.8105,  ...,  1.4399,  0.6993,  0.9714],\n",
            "        [-3.6553, -2.5818,  1.0667,  ..., -0.7811,  7.9365, -0.7514],\n",
            "        [-1.3256, -1.5962,  1.8635,  ...,  1.8497, -1.4955,  3.4021],\n",
            "        ...,\n",
            "        [-1.6761, -2.8970,  1.7050,  ...,  1.2833,  0.1989,  2.2057],\n",
            "        [-0.4149, -3.1553,  3.4201,  ...,  1.1887,  1.0516,  2.4733],\n",
            "        [ 0.6617, -4.0238,  4.1641,  ..., -0.7279,  0.6601,  1.6277]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7516, -2.4305,  1.4792,  ...,  1.4276, -1.4314,  3.9395],\n",
            "        [-0.4370, -3.0748,  2.8294,  ...,  1.5873,  1.9957,  3.8620],\n",
            "        [-0.6358, -1.7878,  2.8908,  ...,  3.2208,  1.4920,  3.8089],\n",
            "        ...,\n",
            "        [-1.2508, -1.2425,  1.9197,  ...,  0.8099,  0.7004,  1.9135],\n",
            "        [-1.5056, -2.8359,  4.3999,  ...,  2.2113,  1.3264,  2.2895],\n",
            "        [-3.6278, -2.3267,  1.7597,  ...,  0.1736,  2.1934, -0.2281]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2709, -3.7441,  3.3472,  ..., -2.6608,  3.2068,  0.0512],\n",
            "        [-1.4619, -1.2258,  3.4390,  ...,  1.5406,  0.3546, -0.4476],\n",
            "        [-2.7175, -1.2306,  4.6961,  ...,  1.5854, -0.2772,  3.3168],\n",
            "        ...,\n",
            "        [-4.0208, -3.8392, -0.2904,  ..., -2.5173,  7.4047,  0.5428],\n",
            "        [-1.4988, -2.5618,  2.0949,  ...,  3.1317, -0.2855,  2.2616],\n",
            "        [-2.8214, -3.2718,  1.8926,  ...,  2.2247,  0.9475, -0.7240]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8133, -3.1283,  1.3091,  ...,  2.8385, -0.8259,  3.1593],\n",
            "        [-1.1780, -2.9142,  1.7412,  ..., -0.3595, -0.2660,  1.7005],\n",
            "        [-2.2224, -2.8994, -0.1938,  ...,  1.0435, -0.1774,  2.4712],\n",
            "        ...,\n",
            "        [-3.3762, -4.3398,  3.1791,  ..., -1.1544,  2.5259,  1.9562],\n",
            "        [-1.1563, -3.5619,  3.7054,  ...,  2.1713,  0.8291,  2.0935],\n",
            "        [ 1.4464, -1.6805,  2.8736,  ..., -1.0485,  2.8901,  0.3329]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0600, -3.4624,  1.1575,  ...,  3.0184,  2.5293,  1.7274],\n",
            "        [-3.1831, -2.9912,  0.9715,  ...,  1.1437,  0.4034, -0.2704],\n",
            "        [-2.4404, -2.9259,  5.8293,  ...,  0.4446, -0.3148,  1.7508],\n",
            "        ...,\n",
            "        [-3.2689, -0.8998,  3.9207,  ...,  1.4527,  0.9542,  3.7816],\n",
            "        [-2.0364, -2.1657,  1.8377,  ...,  0.3645,  6.5816,  1.7539],\n",
            "        [-1.3997, -2.5499,  0.8721,  ...,  2.6040,  1.4062,  2.7384]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6267, -3.1634, -1.9144,  ..., -1.5416,  2.5106,  0.4270],\n",
            "        [-0.5373, -3.8066,  0.2099,  ...,  0.2213,  2.8729,  1.1719],\n",
            "        [-1.8820, -4.1693,  2.2279,  ...,  3.4244,  0.9059,  0.0626],\n",
            "        ...,\n",
            "        [-0.9540, -1.8720,  4.9548,  ...,  1.9710,  1.1171,  2.1151],\n",
            "        [-3.2027, -5.1150,  2.5542,  ..., -0.7140,  3.1568,  1.7260],\n",
            "        [-2.7971, -3.1843,  2.7872,  ..., -0.9468,  5.1673, -1.5649]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5537, -3.2173,  2.7226,  ...,  0.3682,  1.3653,  1.7789],\n",
            "        [-2.2203, -1.3389,  1.9893,  ...,  1.5082,  0.3602,  3.8013],\n",
            "        [-0.5510, -5.5335,  3.0174,  ...,  1.7038,  3.6405,  2.3768],\n",
            "        ...,\n",
            "        [-2.2227, -2.4168,  3.8058,  ..., -1.0767,  1.3061, -0.1691],\n",
            "        [-1.2294, -2.9714, -1.5976,  ...,  2.3724,  3.7159, -0.8802],\n",
            "        [-5.3148, -4.3557,  1.9979,  ...,  1.2803,  4.6791,  0.3502]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7388, -1.4892,  0.8266,  ...,  0.8643,  3.8730,  0.4771],\n",
            "        [-0.4930, -5.0779,  4.8346,  ...,  2.2163,  1.2989,  2.4225],\n",
            "        [-3.2462, -4.0313,  3.0959,  ...,  1.2617,  3.0195,  3.1171],\n",
            "        ...,\n",
            "        [-0.4505, -5.6814,  4.8959,  ...,  0.8934,  4.9134,  0.1258],\n",
            "        [-0.4760, -3.0400,  1.8796,  ...,  0.7622, -0.1218,  0.9543],\n",
            "        [-0.7014, -4.9314,  0.1078,  ...,  2.3990,  0.4328,  2.8099]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0985, -3.5251,  3.0542,  ...,  0.1775,  6.5464,  0.6909],\n",
            "        [-3.6089, -5.1445,  0.4563,  ...,  2.4386,  3.6675, -1.4054],\n",
            "        [-0.5489, -2.7094,  1.5511,  ...,  1.0460,  2.6639,  0.8551],\n",
            "        ...,\n",
            "        [-1.4333, -0.3611,  1.9134,  ...,  0.9857,  0.7236,  1.3770],\n",
            "        [-2.8156, -4.7868,  2.1967,  ...,  1.1660,  3.6075,  0.5153],\n",
            "        [-0.2431, -1.9919,  4.0125,  ...,  0.7239, -0.5170,  4.3760]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4790, -4.0441,  2.3186,  ..., -0.5194,  4.5583,  0.9307],\n",
            "        [-0.5804, -2.5507, -0.4683,  ...,  1.5060, -0.4487,  1.7111],\n",
            "        [-2.4404, -2.3279,  0.9157,  ...,  2.1023, -0.8746,  4.7235],\n",
            "        ...,\n",
            "        [-0.8061, -2.4656,  4.5375,  ...,  3.1139, -0.1249,  1.9332],\n",
            "        [-3.5274, -4.4905,  0.8286,  ...,  4.6998,  4.5809, -2.2842],\n",
            "        [-3.6344, -3.2737,  2.8465,  ...,  1.3564,  0.7326,  4.4668]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1380, -4.6001,  3.0891,  ...,  0.8222,  1.1304,  1.1468],\n",
            "        [-3.0137, -1.2594,  2.4918,  ...,  1.7731,  2.1048,  1.0874],\n",
            "        [-2.1924, -3.9860,  3.8508,  ...,  0.4915,  1.9998,  3.0929],\n",
            "        ...,\n",
            "        [-3.0638, -2.6426,  4.9849,  ...,  0.7567,  0.8541,  1.2947],\n",
            "        [-2.1586, -2.7189,  0.5207,  ...,  1.9677, -0.6615,  4.4014],\n",
            "        [ 0.0450, -3.7185,  3.8752,  ...,  1.0436,  3.0082,  0.1680]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7278, -3.1255,  3.8287,  ...,  2.9664, -0.2529,  2.8911],\n",
            "        [-2.8314, -4.1924,  5.7406,  ..., -0.2642,  3.9208,  0.2362],\n",
            "        [-3.6434, -6.4051,  2.0073,  ...,  3.0307,  1.6763,  1.2582],\n",
            "        ...,\n",
            "        [-1.4389, -4.2807,  5.0173,  ...,  0.9312,  2.2747,  0.8404],\n",
            "        [-1.2324, -3.1934,  5.4772,  ...,  1.0649,  1.9482,  1.5030],\n",
            "        [-0.7087, -2.3052, -1.1538,  ...,  0.4689, -0.1859,  2.2103]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0622, -4.0888,  2.7024,  ...,  2.4729,  2.4944,  2.1682],\n",
            "        [-1.3419, -2.9877,  4.4888,  ..., -0.6019,  3.0182,  1.0597],\n",
            "        [-2.6884, -3.4908,  3.1271,  ...,  1.4239, -1.2615,  1.0729],\n",
            "        ...,\n",
            "        [-1.5204, -3.8063,  0.4838,  ..., -2.7238,  7.4909, -0.9041],\n",
            "        [-3.5544, -2.0204,  1.9480,  ...,  2.1044, -0.0584,  1.6476],\n",
            "        [-1.0307, -2.9238, -0.0088,  ...,  3.9342,  0.0458,  0.8858]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7276, -1.7511,  2.6624,  ...,  2.5402,  1.1774,  3.1831],\n",
            "        [-1.6311, -4.0832,  1.4744,  ...,  1.7173, -0.0404,  2.4535],\n",
            "        [-2.4360, -4.0516,  1.3049,  ...,  2.6997, -0.4419,  0.2048],\n",
            "        ...,\n",
            "        [-3.4520, -3.9148,  7.0172,  ...,  0.1752,  3.1838,  1.2276],\n",
            "        [-3.0758, -3.3048,  4.2953,  ...,  1.4368,  2.0783, -0.8447],\n",
            "        [-2.4389, -4.1864, -0.5972,  ...,  3.1081,  4.4157,  0.7505]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7038, -2.7203,  0.0857,  ...,  1.6905, -0.9076,  1.1112],\n",
            "        [-0.7990, -1.7135,  0.4357,  ...,  4.5881,  1.1429,  0.6269],\n",
            "        [-5.3440, -5.0786,  2.1092,  ...,  1.9768,  1.4812, -2.6224],\n",
            "        ...,\n",
            "        [-3.0427, -1.7723,  2.5461,  ...,  0.8469,  1.4077, -0.5611],\n",
            "        [-0.9160, -3.3165,  4.3410,  ...,  1.5594,  3.2332,  0.2610],\n",
            "        [-1.2152, -3.5887,  1.6607,  ...,  2.3936, -0.1302,  3.2535]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9175, -3.0117,  1.5998,  ...,  2.9556, -0.4100,  2.3370],\n",
            "        [-1.0512, -2.4797,  5.8711,  ...,  0.9900,  0.9068,  1.9670],\n",
            "        [-1.1702, -2.3271,  2.4243,  ...,  2.8212, -1.2508,  3.0779],\n",
            "        ...,\n",
            "        [-2.3629, -2.4413,  2.8882,  ...,  2.1271,  1.7484, -0.5052],\n",
            "        [-0.7966, -2.2449,  4.4741,  ...,  2.5653,  0.0335,  1.9445],\n",
            "        [-0.1696, -2.4079,  4.9800,  ...,  2.6354, -0.2266,  3.7254]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4880, -2.2222,  5.4974,  ...,  0.3934,  3.0123,  0.4879],\n",
            "        [-0.1381, -1.8136,  3.7960,  ..., -0.7709,  2.3524,  2.7253],\n",
            "        [-5.1428, -4.1982,  2.9801,  ..., -0.8670,  0.9996,  0.1141],\n",
            "        ...,\n",
            "        [-2.0801, -2.7972,  1.4944,  ...,  1.8681, -0.9366,  3.5562],\n",
            "        [ 0.1182, -2.2910,  4.6497,  ...,  1.1110,  1.3693,  0.5786],\n",
            "        [-1.5639, -3.3597,  1.2930,  ...,  2.1050, -0.5850,  3.4927]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1166, -2.2479,  2.1756,  ...,  2.0524, -0.1548,  2.3100],\n",
            "        [ 0.3790, -3.5039,  2.9698,  ...,  1.7530,  0.5417,  2.5040],\n",
            "        [-0.3993, -4.1399,  0.2799,  ...,  2.1849,  8.1453, -0.3857],\n",
            "        ...,\n",
            "        [-1.8003, -2.9727,  3.3764,  ...,  2.3430,  5.5942,  1.0328],\n",
            "        [-4.3232, -3.6505,  2.4265,  ..., -0.2597,  5.8164, -1.8435],\n",
            "        [-3.9740, -3.8602,  1.3236,  ..., -2.7584,  5.8071, -1.0891]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6720, -1.3972,  1.8726,  ...,  2.0402,  0.0238,  3.2562],\n",
            "        [-2.7433, -2.7346,  4.1446,  ...,  0.6398,  2.7177,  0.7048],\n",
            "        [-3.4056, -2.9371, -0.8337,  ..., -0.1529,  6.5352, -1.3808],\n",
            "        ...,\n",
            "        [-2.2674, -2.7680,  5.1012,  ...,  2.4296,  2.4634,  1.1359],\n",
            "        [-0.2212, -1.0798,  2.5972,  ...,  1.8029, -0.2620,  2.9405],\n",
            "        [ 0.7416, -1.9241,  2.9365,  ..., -1.2117,  1.5848,  1.5152]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4869, -4.6307,  4.6317,  ...,  1.6168,  0.5802,  0.7326],\n",
            "        [ 2.5403, -2.2593,  2.1777,  ..., -0.5430,  1.5851,  4.1643],\n",
            "        [-1.8741, -1.2922,  5.1786,  ...,  2.4383,  0.1747,  1.7124],\n",
            "        ...,\n",
            "        [-1.2878, -4.2735,  3.5387,  ...,  2.4306,  1.4036,  1.7685],\n",
            "        [-2.9465, -3.7997,  2.6354,  ...,  0.1049,  4.4788,  0.3669],\n",
            "        [-1.9848, -4.0335,  1.9249,  ...,  2.3005, -0.0614,  0.9354]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7654, -3.0081,  1.7377,  ..., -0.2319,  5.2094,  1.0476],\n",
            "        [ 0.3431, -3.3863,  5.4783,  ...,  1.2996,  1.3520,  0.1150],\n",
            "        [-1.6988, -3.4537,  1.8702,  ...,  0.9597, -0.1004,  3.2081],\n",
            "        ...,\n",
            "        [-1.1291, -3.2448,  2.2462,  ...,  1.5487,  1.5419,  0.0947],\n",
            "        [-0.3441, -5.7836,  3.8882,  ...,  3.1238,  2.6075,  2.5717],\n",
            "        [-1.7872, -5.8275,  3.4148,  ...,  0.2344,  1.4376,  0.2905]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1587, -3.3058,  2.1302,  ...,  1.7477,  0.9878,  2.1738],\n",
            "        [-1.6846, -2.7126,  2.8145,  ...,  0.8852,  0.3151,  1.6041],\n",
            "        [-1.3183, -3.4547,  4.2485,  ...,  1.8334,  0.8062,  2.6210],\n",
            "        ...,\n",
            "        [-4.9091, -4.4463,  2.8274,  ...,  0.7801,  1.9647, -0.5882],\n",
            "        [-1.8459, -3.5528,  3.6866,  ...,  1.1309,  2.6787,  2.8567],\n",
            "        [-0.9720, -3.0289,  4.8122,  ..., -0.2802,  1.0124,  0.0668]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6019, -6.5791,  5.9012,  ...,  0.3370,  6.0604,  0.0825],\n",
            "        [-3.2810, -4.3134, -1.4995,  ...,  1.4054,  0.8363,  0.8756],\n",
            "        [-3.7275, -3.1559,  5.2892,  ...,  0.0308,  1.7651, -0.1958],\n",
            "        ...,\n",
            "        [-2.7745, -4.4915,  3.3112,  ...,  0.0400,  3.8314, -0.2567],\n",
            "        [-2.7547, -4.2082,  3.0839,  ..., -0.0727, -0.0844,  0.9780],\n",
            "        [-1.8813, -4.2443,  4.0828,  ...,  0.5791, -0.7679,  0.0144]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9223, -3.9205, -0.1252,  ..., -3.0176,  5.0527,  1.1564],\n",
            "        [-1.6164, -3.3748,  4.5326,  ...,  1.0675,  1.5367,  3.9005],\n",
            "        [-2.5391, -1.8733,  0.7185,  ...,  0.1558, -0.6685,  1.5587],\n",
            "        ...,\n",
            "        [-4.2585, -4.8754,  4.2811,  ...,  0.2730,  0.9981, -0.5103],\n",
            "        [-3.7511, -3.1122, -0.6919,  ...,  1.2272,  5.7564, -0.8418],\n",
            "        [-0.8272, -2.4848,  4.7812,  ...,  0.2767,  1.8715,  1.0540]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9783, -1.4413,  3.6580,  ...,  2.2736,  3.0220,  0.5933],\n",
            "        [-0.3713, -3.8443,  3.4321,  ...,  1.2235,  1.5320,  1.6834],\n",
            "        [-1.9223, -2.9789,  4.8868,  ...,  2.4671,  4.0294,  2.0465],\n",
            "        ...,\n",
            "        [-3.1557, -6.3420,  0.1642,  ...,  3.2523,  6.0103, -1.2408],\n",
            "        [-4.0589, -4.0003, -0.5286,  ..., -4.3085,  7.5808, -2.3494],\n",
            "        [-2.1182, -1.4720,  6.3507,  ...,  1.7000, -0.0196,  1.5617]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5139, -3.2818,  1.9534,  ...,  2.7547, -0.1414,  2.9713],\n",
            "        [-1.7425, -3.7447,  3.3821,  ...,  2.4135, -1.0487,  1.2681],\n",
            "        [-0.9075, -3.9155,  2.9250,  ...,  2.5538,  1.8946, -0.0974],\n",
            "        ...,\n",
            "        [-1.9070, -2.6677,  2.8503,  ...,  0.9753,  0.1623,  3.4632],\n",
            "        [-0.0779, -3.1592, -0.1290,  ...,  0.3952, -0.3905,  2.9467],\n",
            "        [ 0.2929, -2.0610,  1.3339,  ...,  2.1910, -0.8032,  3.1982]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4811, -5.3589,  5.0570,  ..., -1.6549,  3.3744,  1.1878],\n",
            "        [-2.0261, -3.3860,  5.1328,  ...,  2.5557, -0.8704,  1.9003],\n",
            "        [-3.3537, -4.6566, -0.4429,  ...,  5.4762,  1.6604, -0.8454],\n",
            "        ...,\n",
            "        [-2.5194, -3.5393,  2.8912,  ..., -0.8714,  3.7188,  0.0884],\n",
            "        [-4.9183, -3.0926,  2.4272,  ...,  0.6945,  0.8689, -0.4266],\n",
            "        [-0.8625, -1.8505,  2.3072,  ...,  3.5645, -0.7886,  3.4789]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6812, -2.6957,  3.1413,  ...,  2.7588,  4.8261,  1.7031],\n",
            "        [ 0.3227, -3.5374,  2.5511,  ...,  3.0772, -0.6687,  2.4436],\n",
            "        [-1.5627, -4.1949,  3.4021,  ..., -0.2162,  0.8353,  1.4014],\n",
            "        ...,\n",
            "        [ 0.7928, -3.5481,  3.5413,  ...,  1.6996,  4.9929,  1.0539],\n",
            "        [-0.6090, -3.1637,  3.4114,  ...,  1.2918,  0.7161,  1.0719],\n",
            "        [-0.3669, -1.1131,  4.3561,  ...,  1.4075,  1.4355,  0.9166]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6376, -2.3603,  0.6395,  ...,  4.8657, -1.4890,  1.1659],\n",
            "        [-3.0414, -0.9829,  4.9401,  ...,  1.9243,  2.8205,  0.8630],\n",
            "        [-1.5512, -2.3817, -0.4445,  ...,  4.6216,  3.9261,  0.4068],\n",
            "        ...,\n",
            "        [-0.8346, -1.2730,  4.0360,  ...,  1.7960, -0.2699,  2.0422],\n",
            "        [ 0.2123, -3.6694,  3.6600,  ...,  1.5458,  1.3584,  1.6000],\n",
            "        [-2.2394, -2.8526,  1.7787,  ...,  0.8822, -0.0148,  3.2295]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1723, -4.3353, -0.3343,  ...,  4.2246,  3.1915,  2.4333],\n",
            "        [-3.5214, -3.9261,  3.6555,  ...,  0.3014,  2.2200, -0.1872],\n",
            "        [-1.1746, -3.8567,  5.1656,  ...,  1.5675,  2.0656,  0.9787],\n",
            "        ...,\n",
            "        [-3.6856, -4.3121,  1.9783,  ...,  2.2818,  5.0987, -1.2192],\n",
            "        [-2.5779, -4.3268,  5.9592,  ..., -1.1771,  4.1039, -0.2616],\n",
            "        [-1.3114, -2.7174,  1.6171,  ...,  4.2167, -0.2057,  2.2358]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0253, -3.1240,  5.7680,  ...,  2.5996,  2.2050,  1.2244],\n",
            "        [-0.8057, -3.8316,  1.4753,  ...,  1.7150, -0.3181,  2.8148],\n",
            "        [-1.5430, -1.3632,  1.9924,  ...,  0.2746,  0.0825,  0.9138],\n",
            "        ...,\n",
            "        [-1.1999, -4.7126,  3.2338,  ..., -2.5770,  2.6608, -1.9964],\n",
            "        [ 0.4581, -2.3974,  2.0076,  ..., -1.6984,  2.8461,  3.2624],\n",
            "        [ 0.8206, -2.7535,  3.3682,  ...,  2.0686,  0.6164,  2.3703]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4284, -2.7042,  0.4430,  ...,  2.9350,  0.1378,  0.5959],\n",
            "        [-0.6026, -3.2389,  2.7732,  ...,  1.4021,  0.5390,  0.7683],\n",
            "        [-1.4970, -2.6775,  4.6777,  ...,  1.2508,  0.6894,  2.9164],\n",
            "        ...,\n",
            "        [-0.5920, -3.1863,  2.4519,  ...,  3.5096, -0.8411,  1.9176],\n",
            "        [-1.3636, -2.6955,  1.3223,  ...,  2.6947,  0.1221,  2.9119],\n",
            "        [-3.2261, -3.3943,  0.8140,  ...,  1.2480,  2.7459, -1.5504]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5740, -3.0623,  1.6384,  ...,  2.4442,  3.9428,  2.0932],\n",
            "        [-0.7102, -2.0555,  2.3185,  ...,  1.3892,  4.8092,  1.8904],\n",
            "        [-1.7121, -1.0853,  2.0566,  ...,  0.7613, -0.3433,  0.5745],\n",
            "        ...,\n",
            "        [-3.0845, -2.6031,  0.3875,  ...,  1.5505,  3.7967,  0.1688],\n",
            "        [-1.8402, -2.4935,  3.8114,  ..., -0.5180,  2.6149,  1.0380],\n",
            "        [ 0.1210, -2.2860,  3.0040,  ...,  0.1264,  0.7345,  3.0050]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9712, -2.8350,  3.9489,  ..., -1.4107,  2.3428,  2.1322],\n",
            "        [-4.6206, -3.4358,  1.3640,  ...,  0.6941,  2.0542, -0.8942],\n",
            "        [ 0.1815, -3.0367,  4.7892,  ...,  0.4232,  1.7437,  2.0278],\n",
            "        ...,\n",
            "        [-0.8300, -3.1319,  1.6995,  ...,  1.2362,  0.8631,  1.9428],\n",
            "        [ 0.2179, -3.5774,  0.8448,  ...,  0.9302,  0.2832, -0.1958],\n",
            "        [-2.6676, -2.9399, -2.7407,  ..., -2.8279,  2.9731,  1.2562]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6699, -3.1888,  2.0503,  ...,  0.8633,  1.5866,  1.0330],\n",
            "        [-0.4414, -3.2536,  1.5904,  ...,  1.1946,  4.8057,  0.9118],\n",
            "        [-3.8589, -3.7835,  1.9264,  ..., -3.6809,  6.1926, -1.4367],\n",
            "        ...,\n",
            "        [-0.5705, -2.2323,  3.6286,  ...,  0.7751,  5.6595, -0.3859],\n",
            "        [-1.7754, -4.5180, -0.6227,  ...,  3.8704,  6.4585, -0.0545],\n",
            "        [-0.0929, -4.0333,  1.8716,  ...,  1.2103,  1.5538,  1.8927]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9700, -3.8208,  2.5090,  ..., -1.1907,  9.5486, -3.2843],\n",
            "        [ 0.6035, -2.7635,  2.6585,  ...,  2.4350,  2.9318,  0.4550],\n",
            "        [-1.5656, -4.0224,  2.5057,  ...,  3.4829, -0.4710,  2.2315],\n",
            "        ...,\n",
            "        [-0.4382, -3.5717,  2.9170,  ..., -0.3138,  2.1348,  3.0350],\n",
            "        [-1.5035, -1.2847,  3.5577,  ...,  2.0738,  2.3460,  3.3325],\n",
            "        [-1.5459, -1.9505,  3.9501,  ...,  1.4435,  0.7637,  0.9200]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1239, -2.1283,  6.4323,  ...,  2.7034,  1.0311,  2.2314],\n",
            "        [-2.1837, -4.7153,  3.1134,  ...,  1.2515,  0.1069, -0.4340],\n",
            "        [-0.7873, -1.3992,  2.7069,  ...,  2.3313,  2.1008,  2.7935],\n",
            "        ...,\n",
            "        [-0.7922, -2.6208, -0.3848,  ..., -1.2750,  6.4890,  0.1099],\n",
            "        [-0.3306, -0.9546, -2.6972,  ...,  0.5502,  1.8263,  1.4154],\n",
            "        [-0.0408, -4.0723,  0.8206,  ...,  1.8261, -1.4552,  0.3819]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1766, -2.2610,  0.6676,  ...,  2.0613, -0.0169,  3.4835],\n",
            "        [ 0.4224, -2.3463,  1.8449,  ...,  0.7772,  0.4360,  0.8382],\n",
            "        [-1.7571, -4.8921,  3.5120,  ...,  1.6304,  0.3725,  1.1178],\n",
            "        ...,\n",
            "        [ 0.4875, -2.1684,  4.4815,  ..., -1.8532,  1.2404,  1.9452],\n",
            "        [ 0.2254, -2.3271,  3.5768,  ...,  0.8188,  1.0509,  1.7267],\n",
            "        [-1.4350, -4.0083, -0.9818,  ...,  2.6666,  2.9156, -1.2967]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7462, -2.7317,  3.1146,  ...,  1.0989, -0.4367,  3.2335],\n",
            "        [-0.7415, -2.5006,  3.8121,  ..., -0.5312,  3.0618,  0.5416],\n",
            "        [-1.7313, -2.6420,  2.8191,  ..., -1.3718,  0.1254,  1.3214],\n",
            "        ...,\n",
            "        [-0.0363, -4.8566,  3.9972,  ...,  3.7007,  1.9769,  1.7925],\n",
            "        [ 0.2998, -3.0363,  2.4142,  ...,  1.1865,  0.5468,  3.3199],\n",
            "        [ 0.0506, -2.1326,  2.0476,  ...,  0.6074,  0.3041,  1.0818]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0978, -2.6415,  2.9044,  ..., -0.2852,  1.2592,  0.5835],\n",
            "        [-2.4384, -4.7365,  0.1578,  ...,  3.9322,  2.8402, -1.2575],\n",
            "        [-0.2766, -4.5494,  2.3166,  ...,  1.2252,  1.1936,  2.4550],\n",
            "        ...,\n",
            "        [ 0.1338, -1.7008,  3.1701,  ...,  1.5886,  2.6620,  2.2079],\n",
            "        [ 0.8081, -1.8393,  4.0911,  ...,  0.1356, -0.1840,  2.3984],\n",
            "        [-1.2346, -3.9067,  2.5588,  ...,  4.5222,  1.0033,  0.1475]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7980, -1.2406,  3.6670,  ...,  1.5864,  0.5297,  2.5214],\n",
            "        [-1.0472, -2.7375, -0.5182,  ..., -2.3942,  4.4701,  1.1897],\n",
            "        [ 0.1237, -2.9646,  1.3465,  ...,  2.4417,  4.2700,  1.4096],\n",
            "        ...,\n",
            "        [-1.0205, -4.6790,  3.5583,  ...,  0.2357,  0.8307,  0.6787],\n",
            "        [ 1.4831, -3.2943,  6.2426,  ...,  0.1379,  1.3617,  0.2553],\n",
            "        [-1.4592, -4.2969, -2.3368,  ...,  3.8749,  4.2721, -2.1675]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7325, -3.6246,  2.9766,  ...,  0.8642,  2.6734,  1.5303],\n",
            "        [ 0.0759, -3.8722,  0.6719,  ...,  2.3299, -1.1614,  2.5500],\n",
            "        [ 1.4835, -4.2658,  0.5355,  ...,  1.0085,  7.4575, -0.1055],\n",
            "        ...,\n",
            "        [ 2.4324, -4.7068,  2.0376,  ...,  4.4207,  2.3883,  1.2699],\n",
            "        [ 1.8807, -3.8674,  3.0412,  ...,  1.5005, -1.6661,  4.1137],\n",
            "        [ 1.2553, -3.5863,  3.4638,  ...,  0.8798,  2.4520,  2.8232]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9319, -3.1203,  4.7712,  ...,  2.6081,  3.6259,  1.0324],\n",
            "        [-1.1792, -2.2366,  4.0428,  ..., -1.2872,  0.9520,  1.8978],\n",
            "        [-1.5881, -2.5558,  3.1664,  ...,  0.6097,  3.3731, -0.5072],\n",
            "        ...,\n",
            "        [-1.1875, -5.1442,  1.9937,  ..., -0.7702,  0.7854, -1.1624],\n",
            "        [ 0.2001, -2.7844,  2.1417,  ...,  1.6121, -0.1585,  2.9666],\n",
            "        [-2.4557, -2.9202,  4.8289,  ..., -0.1494,  6.2550,  1.7687]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4538, -1.8986,  3.5913,  ...,  2.5858,  4.8080,  0.9989],\n",
            "        [-1.1885, -1.9709,  5.1411,  ...,  1.2601,  1.7003,  3.3862],\n",
            "        [ 0.3343, -3.0974,  3.1811,  ...,  2.3872,  3.3071,  2.3276],\n",
            "        ...,\n",
            "        [-1.8729, -4.8662,  3.7835,  ..., -2.7767,  2.6299,  0.8118],\n",
            "        [-1.6817, -3.4882,  0.0913,  ...,  2.4560,  4.1977, -0.6315],\n",
            "        [ 0.0757, -1.7513,  1.3175,  ..., -0.8935,  5.2129,  0.4236]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96cfe2de9bbc4e4a9f5d0bfce6c0fd9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2116, -5.0512, -1.0902,  ...,  1.6602,  1.2490,  1.0449],\n",
            "        [-1.0178, -2.2562,  1.2935,  ...,  1.2929,  0.1866,  4.2337],\n",
            "        [-1.0408, -3.7466,  0.0103,  ...,  3.7197,  4.0542, -2.8079],\n",
            "        ...,\n",
            "        [-2.5221, -2.1684, -0.4985,  ...,  4.2474,  5.0875, -0.2057],\n",
            "        [-1.1308, -1.4960,  0.5901,  ...,  0.5875,  2.1232,  2.8213],\n",
            "        [ 0.4879, -4.0846, -0.3052,  ...,  2.3867, -1.8300,  4.7473]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2468, -3.2758,  2.5920,  ...,  1.5746,  0.4744,  3.0147],\n",
            "        [ 1.3637, -1.8850,  1.6855,  ...,  0.8874,  0.8823,  1.5828],\n",
            "        [-1.7786, -3.6679,  3.3498,  ...,  1.6285,  2.2305,  2.0582],\n",
            "        ...,\n",
            "        [-1.0128, -3.1002,  3.5665,  ..., -0.5917,  1.5353,  3.1725],\n",
            "        [-2.3522, -4.5660, -0.6708,  ...,  2.7687, -1.0277,  0.9000],\n",
            "        [-2.1135, -2.8559,  2.6535,  ..., -0.6489,  2.7297, -0.1024]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6719, -2.6316,  5.5659,  ...,  1.3409,  1.6456,  0.3136],\n",
            "        [-0.5058, -3.9042,  5.2480,  ...,  1.7710,  2.9954,  1.0890],\n",
            "        [-1.6357, -2.9534,  4.9932,  ..., -0.0543,  2.0249, -0.1764],\n",
            "        ...,\n",
            "        [ 0.0523, -1.9714,  4.6931,  ...,  0.7416,  1.5962,  1.5410],\n",
            "        [-2.7254, -3.8378,  3.3552,  ...,  1.8006,  5.6367, -1.6926],\n",
            "        [ 3.0861, -1.1183,  0.5723,  ...,  0.7709,  2.1061,  2.2712]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3437, -5.2421,  1.1459,  ...,  1.9004,  8.9704,  1.6214],\n",
            "        [-1.0219, -2.9247,  4.5722,  ..., -1.6324,  0.6632,  1.4514],\n",
            "        [-2.5855, -1.6837, -2.0168,  ...,  0.9071, -0.5561,  2.3703],\n",
            "        ...,\n",
            "        [ 1.9390, -3.7119,  4.9212,  ...,  0.2187,  1.4203,  1.3457],\n",
            "        [-0.7469, -2.0485,  2.8110,  ...,  3.6682, -0.3825,  2.3525],\n",
            "        [-0.0134, -4.2807,  1.6928,  ...,  0.5123,  5.1376, -0.7988]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3154, -2.6168,  0.7316,  ...,  0.2716,  2.2463,  2.5127],\n",
            "        [-1.2837, -2.2286,  2.3413,  ...,  1.7422,  1.6224,  2.8182],\n",
            "        [-4.9592, -3.0653,  3.5161,  ..., -2.5586,  0.6121,  0.7771],\n",
            "        ...,\n",
            "        [ 1.0473, -1.6368,  1.5681,  ..., -2.3311,  6.8537,  2.5076],\n",
            "        [-1.2602, -4.8403,  5.5858,  ..., -0.4033,  4.7682, -0.1515],\n",
            "        [-1.3907, -3.5949,  2.7207,  ..., -0.5497,  7.1294, -1.0797]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1990, -3.4074,  3.4760,  ..., -0.8932,  2.3693, -0.0289],\n",
            "        [-0.4299, -4.1569,  4.0457,  ...,  1.3550,  0.3247,  1.5746],\n",
            "        [-0.1316, -4.2830,  7.0328,  ..., -0.1932,  0.8934,  0.7584],\n",
            "        ...,\n",
            "        [-0.7664, -2.2556,  1.8174,  ...,  1.3192,  0.3959,  2.0669],\n",
            "        [-1.8538, -4.2282,  3.4847,  ...,  3.0501,  5.4130, -0.9100],\n",
            "        [-2.4794, -4.8819,  2.1986,  ..., -0.2871,  6.0133, -0.6642]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4636, -2.1321, -1.4380,  ...,  0.6925,  0.6189,  1.0198],\n",
            "        [-0.3717, -2.9338,  1.5683,  ...,  3.7301,  3.6929,  1.7602],\n",
            "        [ 1.7287, -5.1611,  2.5811,  ...,  1.6696,  2.5181,  2.3962],\n",
            "        ...,\n",
            "        [-0.0707, -3.9508,  3.1189,  ...,  2.4496,  4.8150,  3.3342],\n",
            "        [-1.3515, -2.6087,  4.6046,  ...,  1.2344,  1.1542,  2.9836],\n",
            "        [-3.3033, -5.3922, -0.4957,  ...,  4.3636,  4.5700, -2.4144]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4299, -6.5273, -1.1580,  ...,  2.3189,  4.2238, -1.0796],\n",
            "        [-3.2825, -3.9828,  6.3388,  ...,  0.3337,  4.6764,  1.9168],\n",
            "        [-2.8651, -3.5061,  1.7206,  ...,  1.8443,  5.8753, -0.5666],\n",
            "        ...,\n",
            "        [-0.6768, -2.4748,  2.9535,  ..., -0.5668,  2.1039,  0.5387],\n",
            "        [ 0.8768, -2.1531,  1.9005,  ...,  3.4136,  4.9746,  2.8117],\n",
            "        [-2.8144, -2.5760, -0.5735,  ...,  1.0229,  0.6185,  2.2475]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6477, -3.3039, -0.8624,  ...,  2.8994,  4.2506, -0.5915],\n",
            "        [-4.1257, -5.5551, -0.5216,  ..., -0.2577,  3.8652, -1.0975],\n",
            "        [ 1.3286, -3.8950,  0.2195,  ...,  1.2156, -1.6460,  1.1416],\n",
            "        ...,\n",
            "        [-1.4943, -2.5354,  2.0856,  ...,  0.3134, -0.0997,  4.0661],\n",
            "        [-2.6532, -5.6522,  0.7425,  ...,  4.7608,  5.2440,  0.4136],\n",
            "        [-0.4262, -3.1197, -0.4043,  ...,  2.2853, -0.3661,  2.2087]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5161e+00, -4.1794e+00, -1.8123e+00,  ...,  3.2921e+00,\n",
            "          5.3184e+00, -1.5400e+00],\n",
            "        [-4.8035e-01, -3.8924e+00,  1.2863e+00,  ...,  2.1427e-01,\n",
            "          5.9901e-01,  1.1970e+00],\n",
            "        [ 8.9714e-01, -2.8635e+00,  4.1216e+00,  ..., -4.5424e-01,\n",
            "          5.1206e-01,  3.0197e+00],\n",
            "        ...,\n",
            "        [-1.2564e+00, -2.8305e+00,  1.8730e+00,  ...,  1.8487e+00,\n",
            "         -9.9385e-01,  4.3266e+00],\n",
            "        [-8.8810e-01, -4.2895e+00,  1.6236e+00,  ...,  1.8648e+00,\n",
            "          6.5519e-01,  1.9197e+00],\n",
            "        [-1.1200e+00, -3.0712e+00,  3.5467e+00,  ...,  4.2284e-01,\n",
            "          8.7172e+00,  5.3181e-04]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8751, -2.9380,  0.3150,  ..., -1.5877,  3.2150,  0.6357],\n",
            "        [-1.1251, -1.7132,  4.0888,  ...,  1.8302,  3.9460,  2.3930],\n",
            "        [-2.9699, -3.0804, -1.1959,  ...,  1.4551,  5.9034, -0.9807],\n",
            "        ...,\n",
            "        [-4.3627, -2.9787,  3.3009,  ..., -1.0479,  4.0883, -0.1214],\n",
            "        [-1.0412, -2.7500,  4.6398,  ..., -0.7915,  0.7757,  3.4447],\n",
            "        [-1.5598, -2.8664,  1.3823,  ...,  0.1973, -0.7812,  3.1122]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8489, -3.7806,  4.6717,  ...,  2.4671,  2.4582,  1.3245],\n",
            "        [-2.1035, -2.3531,  4.9509,  ...,  0.6369, -0.2828,  1.4175],\n",
            "        [-0.6699, -2.5380,  0.5419,  ...,  1.3867,  0.1193,  2.8819],\n",
            "        ...,\n",
            "        [-0.4361, -3.3460,  4.4541,  ...,  1.0720,  1.4554,  1.2214],\n",
            "        [-0.7764, -1.6824,  3.5210,  ...,  1.0428,  3.9773,  1.7403],\n",
            "        [-1.4079, -3.0748,  1.7767,  ...,  2.4758, -0.5043,  3.2978]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0389, -1.3733,  2.9252,  ...,  1.0786,  1.9887,  2.0087],\n",
            "        [-1.4041, -2.9938,  2.4097,  ...,  0.0234,  3.1712,  0.2179],\n",
            "        [-1.9308, -2.3514,  2.0896,  ...,  2.2393, -1.3960,  2.9909],\n",
            "        ...,\n",
            "        [ 0.3415, -4.4293,  3.8087,  ...,  2.4011,  3.9689,  1.8974],\n",
            "        [ 1.8448, -4.3833, -1.0352,  ..., -1.8274,  5.7512,  3.1034],\n",
            "        [-0.4534, -2.7367,  3.1826,  ...,  0.5956,  3.0574,  2.2911]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2043, -1.9883,  5.9531,  ...,  2.3683, -0.3971,  3.5635],\n",
            "        [-5.5211, -2.7297,  3.6048,  ..., -0.7263,  3.2779,  0.4968],\n",
            "        [ 1.0569, -3.4275,  3.2663,  ...,  1.6583,  0.6195,  3.1274],\n",
            "        ...,\n",
            "        [-2.4364, -2.5209,  3.0158,  ..., -1.6177,  4.4551,  2.8234],\n",
            "        [ 1.0309, -1.2792,  2.8400,  ..., -1.9547,  7.2471,  2.3148],\n",
            "        [-2.2255, -3.7580,  1.9785,  ...,  0.7310,  0.4551,  0.8332]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8260, -2.6881,  1.3010,  ...,  2.7503,  1.6400,  1.0017],\n",
            "        [-0.2163, -1.9366,  3.5186,  ..., -0.1887,  1.2467,  2.8043],\n",
            "        [-1.5204, -1.5395,  1.6421,  ...,  2.0203, -0.2397,  3.7433],\n",
            "        ...,\n",
            "        [ 2.0170, -2.0756,  3.3903,  ..., -1.1156,  2.9618,  4.7028],\n",
            "        [-0.5789, -4.7131,  5.7752,  ...,  1.1909,  0.8800,  0.6857],\n",
            "        [-1.7199, -2.7391,  1.8514,  ...,  1.6226,  1.9126,  2.0302]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4824, -4.2967,  3.9832,  ...,  1.9823,  3.2018,  1.4537],\n",
            "        [-0.0520, -3.1425,  1.3712,  ..., -0.1349,  2.2035,  1.1532],\n",
            "        [ 0.4531, -1.6332,  3.6618,  ..., -0.0364,  3.2010,  2.9716],\n",
            "        ...,\n",
            "        [ 1.1969, -2.7425,  1.4743,  ...,  1.4362,  4.3276,  2.7342],\n",
            "        [ 0.0464, -4.4258,  3.6846,  ..., -0.8350,  1.0163,  1.4233],\n",
            "        [-1.3129, -3.4432,  4.6280,  ...,  0.1135, -0.2996, -1.2436]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0097, -1.7420,  5.0675,  ...,  0.7369, -0.0582,  3.1198],\n",
            "        [-1.0034, -2.6623,  1.7918,  ...,  0.6837, -0.0613,  3.0245],\n",
            "        [-0.1965, -2.2373,  4.0765,  ...,  0.3856,  1.4047,  1.9353],\n",
            "        ...,\n",
            "        [-1.7747, -5.0890,  3.9203,  ...,  0.2748,  5.6419, -0.6189],\n",
            "        [-0.5280, -2.5226,  2.5542,  ...,  2.0234, -1.0661,  4.1788],\n",
            "        [-0.8687, -1.1194,  1.4946,  ...,  1.0935,  2.6161, -0.0596]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8482, -2.6951,  3.4430,  ..., -0.7106,  3.6795, -0.4691],\n",
            "        [-1.8555, -3.4905,  2.6092,  ...,  1.5639,  3.9176, -0.2226],\n",
            "        [-1.3387, -2.7446,  1.2573,  ...,  0.7577, -0.4448,  3.1417],\n",
            "        ...,\n",
            "        [-3.3644, -3.0804,  3.1271,  ...,  1.0876,  0.8107,  1.9097],\n",
            "        [-1.2879, -3.4495,  3.1019,  ...,  1.0030,  1.2452,  3.7771],\n",
            "        [ 0.3137, -2.0617,  5.2838,  ...,  2.9097,  0.0266,  2.7836]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7101, -1.7876,  2.6172,  ..., -1.6161,  3.3033,  1.7961],\n",
            "        [-0.9796, -1.4866,  1.8387,  ...,  0.1785, -0.9509,  3.3116],\n",
            "        [-5.3786, -0.5706,  5.9881,  ..., -0.8217,  3.9504,  0.2814],\n",
            "        ...,\n",
            "        [-1.4934, -3.8623,  3.4419,  ...,  1.0187, -0.7195,  0.2715],\n",
            "        [ 0.5642, -2.2943,  0.9043,  ...,  3.0051,  4.6293,  0.7899],\n",
            "        [ 0.5715, -1.9521,  5.2780,  ...,  2.8693, -0.4430,  2.5904]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9124, -2.6943,  0.0353,  ...,  1.9970,  3.0012,  1.8744],\n",
            "        [-0.6731, -1.5713,  5.1591,  ...,  4.8017,  3.4333,  3.5382],\n",
            "        [-1.3573, -2.8844,  4.4961,  ...,  0.6632,  3.7843, -1.0771],\n",
            "        ...,\n",
            "        [-1.7818, -2.1588,  1.0473,  ...,  1.2837,  1.4754,  0.8562],\n",
            "        [-0.9895, -1.9758,  4.0964,  ..., -1.0161,  2.8635,  1.3559],\n",
            "        [-1.9555, -4.1969,  4.4110,  ..., -0.6563,  0.7742,  0.3467]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3137, -2.0491,  2.0717,  ...,  1.8655, -1.2257,  3.5735],\n",
            "        [-1.4081, -1.5119,  4.2510,  ...,  1.3819,  1.9371,  2.2919],\n",
            "        [ 0.0105, -3.3042,  4.8182,  ...,  2.6554,  1.1499,  2.8171],\n",
            "        ...,\n",
            "        [-2.5743, -3.6819,  4.0320,  ...,  0.4268,  0.6647,  1.4764],\n",
            "        [-2.6179, -3.4511,  6.7656,  ..., -2.6015,  1.7762,  3.2065],\n",
            "        [-1.4453, -2.4850,  6.1049,  ...,  1.2030,  3.6651,  0.9381]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1486, -2.1102,  1.2597,  ...,  1.3325, -1.2672,  4.1343],\n",
            "        [-2.1304, -0.9995,  1.9205,  ...,  1.4640, -0.7941,  4.0355],\n",
            "        [-1.3850, -2.7420,  2.0738,  ...,  2.5345, -0.5263,  3.4176],\n",
            "        ...,\n",
            "        [-0.7117, -2.3144,  2.6531,  ...,  2.2361, -0.2099,  4.1313],\n",
            "        [-1.2686, -2.8968,  4.6125,  ...,  1.6854,  5.1653,  1.1481],\n",
            "        [-1.3509, -2.1769,  2.1524,  ...,  0.3079,  1.2045,  1.0350]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7413, -2.6668,  0.1807,  ...,  4.5778,  3.0829,  1.5317],\n",
            "        [ 1.8239, -3.5866,  4.5177,  ...,  2.2391,  1.6156,  4.5382],\n",
            "        [ 0.4774, -3.4897,  4.6358,  ...,  1.6430,  2.8799,  0.9205],\n",
            "        ...,\n",
            "        [-1.2855, -2.8972,  1.3879,  ...,  2.0410, -1.3435,  4.0234],\n",
            "        [-2.4865, -1.0444,  1.9626,  ...,  0.1817,  0.7545,  0.7072],\n",
            "        [-0.9743, -2.9479,  2.5663,  ...,  1.3170,  4.7462, -0.5031]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-7.2841e-02, -3.0314e+00,  4.5646e+00,  ...,  1.9130e+00,\n",
            "          9.3355e-01,  1.2161e+00],\n",
            "        [-2.9044e+00, -2.9172e+00,  1.0164e+00,  ..., -1.8640e+00,\n",
            "          5.8429e+00, -9.3269e-02],\n",
            "        [-1.0193e+00, -3.0398e+00,  4.9148e+00,  ...,  2.1265e+00,\n",
            "          6.7228e+00,  1.6894e+00],\n",
            "        ...,\n",
            "        [-1.3471e+00, -1.6673e+00,  1.5668e+00,  ...,  1.3779e+00,\n",
            "         -8.4286e-01,  3.8046e+00],\n",
            "        [-1.4078e+00, -5.1210e+00,  3.2312e+00,  ...,  3.2617e-01,\n",
            "          2.2835e+00, -1.7019e-03],\n",
            "        [-1.6170e-01, -5.1885e+00,  3.6963e+00,  ...,  1.7909e+00,\n",
            "          5.0818e+00,  2.3893e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9365, -2.1790,  0.8439,  ...,  1.4909,  1.1927,  2.1879],\n",
            "        [-3.0245, -0.3672,  6.1043,  ...,  2.1961,  4.4667,  1.8213],\n",
            "        [-2.0710, -3.3697,  3.4961,  ...,  2.6730,  1.5485,  0.5297],\n",
            "        ...,\n",
            "        [-3.1311, -2.7040,  3.1954,  ..., -2.2577,  3.1710, -0.4264],\n",
            "        [-3.1844, -2.5718, -0.3733,  ...,  0.5497,  9.0852, -1.9687],\n",
            "        [-2.3434, -4.8388,  2.4916,  ..., -1.6077,  3.0940,  1.5091]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5061, -0.9194,  2.6374,  ..., -0.0508,  2.3949,  0.8207],\n",
            "        [-0.4775, -2.7038,  2.8393,  ...,  2.4454,  4.0329,  0.0290],\n",
            "        [ 2.1622, -2.0864,  2.5590,  ...,  2.1461, -1.4278,  2.3680],\n",
            "        ...,\n",
            "        [ 0.1539, -1.9826,  3.6459,  ...,  0.3818,  1.3667,  2.2702],\n",
            "        [-1.6838, -2.9444,  2.0273,  ...,  1.7739, -0.2377,  2.0990],\n",
            "        [-3.8709, -2.5993,  3.7969,  ..., -1.9968,  0.5553,  2.2575]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5802, -1.4678,  2.6514,  ...,  2.4183, -0.3540,  1.9565],\n",
            "        [-0.0747, -1.3587, -0.5036,  ...,  0.8055,  7.7208, -1.1298],\n",
            "        [-3.5623, -4.7028,  2.2229,  ...,  1.2629,  2.2612,  0.5130],\n",
            "        ...,\n",
            "        [-2.4308, -3.6481,  2.4370,  ...,  1.7042,  1.8750,  0.7111],\n",
            "        [-0.7439, -2.3333,  1.0428,  ...,  2.4425, -0.3916,  2.8848],\n",
            "        [-1.0751, -2.8755,  3.1670,  ...,  2.4080,  5.9655,  0.9659]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3569, -2.9317,  2.0008,  ...,  3.6256,  0.1310,  0.9313],\n",
            "        [ 2.7062, -2.9599,  5.0155,  ...,  1.9781,  2.8351,  1.9991],\n",
            "        [ 0.0977, -3.9754,  3.6846,  ...,  1.3275,  6.0317,  2.4112],\n",
            "        ...,\n",
            "        [ 0.2366, -4.2690, -0.8364,  ...,  2.1635,  2.7647, -2.1994],\n",
            "        [-0.6914, -0.0283,  1.7420,  ...,  0.7952,  0.3949,  1.7159],\n",
            "        [-3.7850, -4.4855,  1.3308,  ..., -2.3214,  0.9186, -1.5839]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3817, -3.4769,  4.1335,  ...,  2.8613,  0.4844,  1.6523],\n",
            "        [ 2.1943, -2.5643,  1.1847,  ...,  0.8638,  3.0100,  0.9331],\n",
            "        [-0.9236, -3.8858,  3.6743,  ..., -0.8498,  2.3821, -0.4445],\n",
            "        ...,\n",
            "        [-1.5694, -1.7763,  2.9867,  ...,  1.5073,  1.6633,  0.3523],\n",
            "        [-3.4064, -3.0668,  5.0869,  ...,  0.3405,  0.4505,  1.6222],\n",
            "        [-2.1282, -3.7269,  0.3039,  ...,  0.4803,  2.6586,  0.8415]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5072, -3.4518,  3.5767,  ...,  2.1353,  1.4660,  1.2800],\n",
            "        [-3.7882, -2.1411,  1.8383,  ..., -0.7492,  4.7321, -0.9576],\n",
            "        [-1.2506, -5.0879,  0.9848,  ...,  2.8773,  3.4954, -1.1313],\n",
            "        ...,\n",
            "        [ 0.1431, -3.9361,  2.0214,  ...,  4.0923,  2.4321,  1.3335],\n",
            "        [-0.3378, -0.5009,  2.5921,  ..., -2.1950, -0.5726,  1.9403],\n",
            "        [-0.9341, -2.5150,  5.2781,  ...,  0.9152,  0.4528,  1.1207]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5334, -5.5607,  2.7221,  ...,  1.9613,  2.5449,  2.6814],\n",
            "        [ 0.1834, -4.4510,  2.9391,  ...,  1.4833,  6.7069, -0.8515],\n",
            "        [-0.6997, -2.5651,  0.5712,  ...,  0.0479,  3.2862, -1.2238],\n",
            "        ...,\n",
            "        [-1.7800, -2.2190,  1.7582,  ...,  1.1183, -0.9633,  4.1090],\n",
            "        [-3.6102, -3.3943,  0.8616,  ...,  0.0964,  0.6613,  0.4518],\n",
            "        [-1.5008, -3.0087,  1.2412,  ...,  2.3447, -0.8472,  3.5133]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6905, -3.8325,  1.0344,  ...,  2.1323,  1.8806, -0.6905],\n",
            "        [-1.8987, -2.5914, -2.3339,  ...,  4.8097,  5.3720, -2.4369],\n",
            "        [-0.7324, -1.7942,  2.2975,  ...,  1.4469, -0.4421,  2.8987],\n",
            "        ...,\n",
            "        [-0.6107, -2.3718,  1.2485,  ...,  1.8831, -0.2914,  2.9145],\n",
            "        [-1.9718, -1.5876,  1.4689,  ...,  0.7990,  0.2794,  3.2193],\n",
            "        [-1.0706, -3.2406,  4.6938,  ...,  1.5087,  1.2845,  1.0090]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6962, -2.5250, -0.9898,  ...,  2.6576,  6.5627,  1.0699],\n",
            "        [-1.8466, -4.2203,  3.9504,  ..., -0.5187,  2.0232,  0.7003],\n",
            "        [ 1.4174, -4.3675,  2.0908,  ..., -1.1125,  5.6809,  0.5906],\n",
            "        ...,\n",
            "        [-1.8113, -4.3837,  4.9363,  ..., -1.7881,  5.0412, -1.1515],\n",
            "        [-2.2582, -3.0341, -0.0558,  ...,  2.1838,  4.1335,  0.3549],\n",
            "        [-0.9914, -2.8734,  1.3780,  ...,  2.0410,  0.4912, -3.2328]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4737, -4.2091,  4.6212,  ...,  0.6877,  0.0269,  2.1514],\n",
            "        [-0.9314, -2.5899,  1.8354,  ...,  0.6173, -0.0493,  2.7425],\n",
            "        [ 1.6398, -2.7391,  5.4020,  ...,  1.6316,  4.6870, -1.3623],\n",
            "        ...,\n",
            "        [ 1.1592,  0.0183,  2.6502,  ...,  1.0026, -0.7335,  2.1529],\n",
            "        [ 1.0140, -0.1292,  2.5178,  ...,  1.5510,  1.0282,  3.5580],\n",
            "        [-1.5284, -2.7382,  1.1652,  ...,  2.0972, -1.1956,  3.5636]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8427, -2.4263,  1.3334,  ...,  1.1640, -0.2798,  3.8408],\n",
            "        [-1.1535, -2.4371,  4.5304,  ...,  1.6836,  1.6591,  1.6986],\n",
            "        [ 0.3646, -3.2055,  4.1913,  ..., -1.9701,  1.8163,  0.5587],\n",
            "        ...,\n",
            "        [ 2.4770, -3.5977,  4.2779,  ...,  1.1767,  0.3554,  2.7032],\n",
            "        [ 0.2423, -2.4887,  3.7151,  ...,  3.5152, -2.1380,  2.9619],\n",
            "        [-0.6702, -4.5984, -0.6513,  ..., -3.5749,  6.8760,  0.4352]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5753, -5.5938,  3.8411,  ..., -0.0187,  1.9160,  1.1116],\n",
            "        [ 0.4814, -3.3888,  5.4355,  ...,  0.0331,  3.1137,  0.3452],\n",
            "        [-1.5639, -2.1465,  1.7181,  ...,  1.7068, -0.8730,  3.7882],\n",
            "        ...,\n",
            "        [-3.1036, -2.3378,  0.9245,  ..., -0.3140, -0.0229,  0.2058],\n",
            "        [ 1.4400, -2.7388,  3.7266,  ...,  0.5016,  4.4623, -1.0275],\n",
            "        [ 1.3463, -2.9224,  2.7889,  ...,  0.9306,  3.0444,  3.2245]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5822, -1.1877,  4.6021,  ...,  3.7081,  0.1064,  2.1004],\n",
            "        [-1.4538, -4.7121,  0.8342,  ..., -4.2291,  6.4733, -0.3096],\n",
            "        [ 1.3891, -2.3064,  5.4115,  ...,  1.2464,  1.7804,  2.8865],\n",
            "        ...,\n",
            "        [-0.9951, -4.7712,  5.1373,  ...,  1.3453,  4.7255, -1.0478],\n",
            "        [-1.1652, -2.5544,  2.1241,  ..., -1.5854,  4.5781, -1.2510],\n",
            "        [ 0.1509, -2.6521,  2.2301,  ...,  2.5347, -0.8404,  2.9543]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7358, -3.2197,  1.1899,  ...,  2.9251, -0.6061,  1.3586],\n",
            "        [ 1.4688, -4.2729,  2.5008,  ...,  1.3051,  2.1562,  0.9015],\n",
            "        [-2.3905, -4.8696,  1.9637,  ...,  0.2214,  9.0443, -2.9899],\n",
            "        ...,\n",
            "        [ 1.7223, -2.6537,  3.9703,  ...,  2.3986,  1.8308, -0.2734],\n",
            "        [-3.3499, -2.9898,  2.4300,  ..., -2.1049,  7.5167, -0.6014],\n",
            "        [-2.6176, -2.2024, -0.6010,  ...,  1.8638, -0.9505,  2.8984]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0435, -3.1776,  4.7392,  ...,  2.9441,  2.5010,  1.1584],\n",
            "        [-0.5317, -2.4647, -1.6268,  ..., -2.0156,  5.0848,  0.1668],\n",
            "        [-2.5682, -4.2433,  2.1036,  ...,  1.4875, -0.1749,  1.1969],\n",
            "        ...,\n",
            "        [-1.2255, -6.9918,  5.4327,  ...,  0.0917,  4.4797, -1.1761],\n",
            "        [ 0.1118, -2.8188,  2.6139,  ...,  2.7180, -1.0492,  2.3575],\n",
            "        [-1.5141, -4.2126,  2.2412,  ...,  1.3255,  6.3000, -1.1896]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1391, -3.0219,  0.1600,  ...,  2.3047, -1.2580,  1.4489],\n",
            "        [ 1.0530, -3.9524,  5.5224,  ..., -0.0901,  3.2070,  0.0543],\n",
            "        [-1.7838, -3.0191,  4.4265,  ..., -0.8653,  5.2045, -2.0691],\n",
            "        ...,\n",
            "        [-3.8859, -5.5564,  3.9739,  ...,  0.8107,  2.8885, -1.2530],\n",
            "        [-1.6098, -1.9563,  1.5952,  ...,  2.0582,  3.0188,  0.4745],\n",
            "        [ 1.0526, -1.6109,  6.7030,  ..., -0.0313,  0.7159,  1.0530]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7849, -2.8620,  3.5294,  ...,  1.3972,  1.1011,  2.7974],\n",
            "        [-0.2270, -1.8627,  1.8563,  ...,  2.3918, -0.0715,  1.8955],\n",
            "        [-0.1908, -5.3510,  4.0760,  ...,  0.5948,  1.6590, -0.4786],\n",
            "        ...,\n",
            "        [-0.1373, -2.3481,  2.1385,  ...,  2.7015, -0.3320,  2.8968],\n",
            "        [ 0.4106, -1.9465,  4.9351,  ...,  1.2333,  1.0553,  0.5144],\n",
            "        [ 0.4705, -2.4783,  3.9792,  ...,  1.8310,  3.6087,  1.3234]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2092, -2.4818,  3.4197,  ...,  1.5046, -1.0708,  1.4004],\n",
            "        [ 0.8769, -1.6462,  1.2543,  ...,  2.2958,  0.1420,  2.6420],\n",
            "        [-0.3555, -3.1553,  5.5005,  ...,  3.6357, -0.2927,  1.7279],\n",
            "        ...,\n",
            "        [ 0.1869, -3.5319,  3.7873,  ..., -1.6447,  6.0212, -1.0574],\n",
            "        [-1.1675, -3.6583,  4.6494,  ..., -1.2611,  5.5034,  0.5835],\n",
            "        [ 1.7698, -3.3178,  2.9956,  ..., -0.3545,  4.0782, -1.2850]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1597, -2.6649,  1.3036,  ...,  1.8257, -0.6107,  4.1950],\n",
            "        [-2.1039, -2.9834,  3.6954,  ...,  0.7698,  1.4603,  0.9286],\n",
            "        [ 3.0626, -2.5659,  2.7801,  ..., -1.2051,  2.4983,  2.2065],\n",
            "        ...,\n",
            "        [ 2.1305, -5.2769,  4.9111,  ...,  1.6251,  1.9452,  2.0746],\n",
            "        [ 0.9681, -0.9207,  6.3383,  ...,  3.1097,  1.2687,  2.3165],\n",
            "        [ 0.4953, -2.6844, -0.3675,  ...,  3.9239,  5.9843, -1.4122]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2032, -3.6155, -3.1794,  ..., -0.0780,  2.7198,  1.0028],\n",
            "        [-0.1624, -2.1271,  1.5470,  ...,  1.4296, -0.1275,  2.2371],\n",
            "        [-1.5359, -3.5156,  4.4920,  ..., -1.6320,  2.3511, -0.3290],\n",
            "        ...,\n",
            "        [ 0.6112, -1.9233,  1.2422,  ...,  1.7012,  0.5468,  2.9011],\n",
            "        [ 1.7252, -5.1207,  2.6031,  ...,  1.6700,  1.8022,  0.0068],\n",
            "        [ 0.2133, -3.2311,  3.9159,  ..., -0.3041,  0.3421,  1.9404]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2063, -4.6924,  3.2944,  ...,  2.5719,  3.5622,  3.0680],\n",
            "        [-0.7946, -3.2399, -0.3738,  ...,  2.3370,  5.9491,  0.7395],\n",
            "        [-0.6659, -3.4459,  3.5882,  ...,  0.9940,  6.3829, -1.0325],\n",
            "        ...,\n",
            "        [ 1.8716, -3.3561,  2.5458,  ...,  3.1080, -0.7453,  2.7469],\n",
            "        [-3.0339, -2.5981,  1.5002,  ..., -1.2618,  5.4813,  0.2151],\n",
            "        [ 1.6182, -1.6937,  4.7375,  ...,  2.5161, -0.4069,  4.1602]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8698, -2.5799,  2.1049,  ...,  1.6482, -1.0740,  4.2611],\n",
            "        [-1.2066, -4.5597,  3.4417,  ...,  0.0431,  1.8635,  1.4322],\n",
            "        [ 0.2449, -2.2235,  1.7472,  ...,  2.0358, -0.6708,  3.9935],\n",
            "        ...,\n",
            "        [-3.3188, -4.5603,  3.2218,  ...,  0.4130,  2.9717, -0.6548],\n",
            "        [ 1.6579, -4.8379,  0.6697,  ...,  1.9216,  2.8564, -2.9132],\n",
            "        [ 2.7067, -2.8900,  4.0869,  ...,  1.4233,  1.9420,  3.7787]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7496, -3.4318,  1.5333,  ...,  2.4898,  5.2466, -0.4443],\n",
            "        [ 0.9151, -3.6302,  2.7783,  ...,  1.7808,  5.8057,  1.5316],\n",
            "        [-0.0079, -4.2260,  1.8335,  ..., -0.4721,  4.5668, -1.2173],\n",
            "        ...,\n",
            "        [-1.0916, -3.5798, -2.7374,  ..., -2.4594,  3.7047,  2.0250],\n",
            "        [-0.3727, -2.4308,  6.7199,  ...,  0.3932,  1.0142,  1.4890],\n",
            "        [-0.4464, -5.0280,  0.6964,  ...,  3.2058, -1.3185, -0.3483]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4481, -1.9783,  2.0529,  ...,  1.9587, -0.5006,  2.6745],\n",
            "        [ 1.4097, -4.0310,  4.6381,  ...,  2.2217,  2.6435,  1.5900],\n",
            "        [ 0.7080, -2.5647, -0.6460,  ..., -0.7663,  5.5998,  1.2297],\n",
            "        ...,\n",
            "        [-0.0563, -3.5240,  1.2422,  ..., -0.2527,  4.4265,  1.0215],\n",
            "        [-1.5379, -3.7094,  0.2117,  ...,  4.0654, -3.1147,  1.1964],\n",
            "        [ 0.2924, -2.0556,  4.0450,  ..., -0.0565,  1.7107,  2.3479]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0148, -2.1778,  5.1623,  ...,  2.9741,  3.6620,  1.4864],\n",
            "        [-2.9897, -1.8925, -2.3987,  ..., -1.8522,  6.8763, -0.8018],\n",
            "        [ 0.8203, -2.7207,  4.0199,  ..., -2.6542,  3.7681,  0.1541],\n",
            "        ...,\n",
            "        [ 3.5188, -3.6888,  2.2492,  ...,  2.3140, -0.1608,  3.4650],\n",
            "        [ 0.3437, -3.8690,  2.4991,  ...,  2.7987, -0.3435,  2.4614],\n",
            "        [ 0.1333, -3.4055, -1.4466,  ...,  4.0467,  0.6646, -0.3351]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4995, -5.4548,  0.6765,  ...,  4.0904,  3.6340, -0.0129],\n",
            "        [-1.2553, -3.9081,  2.3234,  ...,  1.5635,  1.6783,  1.0751],\n",
            "        [-0.3218, -2.4264,  1.7206,  ...,  1.1653, -0.2769,  3.8850],\n",
            "        ...,\n",
            "        [ 0.6730, -2.6645,  4.8534,  ...,  0.6527,  1.8917,  1.9533],\n",
            "        [-1.0625, -4.5687,  1.3693,  ..., -0.5932,  3.2033,  1.0130],\n",
            "        [-1.3914, -2.8293,  4.6675,  ...,  0.2108,  3.1098, -0.2774]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3568, -3.1712,  1.0698,  ...,  2.2386,  0.5967, -0.1012],\n",
            "        [ 0.7358, -4.1728,  5.0442,  ...,  2.7516,  2.8458,  1.9351],\n",
            "        [ 1.0793, -2.1200,  4.7229,  ...,  2.1968,  0.0119,  2.7877],\n",
            "        ...,\n",
            "        [ 0.4265, -1.7065,  2.4158,  ...,  0.1407,  0.8324,  3.2326],\n",
            "        [-2.9605, -2.7653,  0.8802,  ...,  1.4826,  3.7727,  0.4826],\n",
            "        [-1.4201, -3.2120,  3.5469,  ..., -1.4568,  5.9226,  2.6235]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3135, -5.2813,  0.4556,  ...,  4.0426,  5.4391,  1.7866],\n",
            "        [-1.1977, -2.6530,  2.9549,  ...,  2.5672,  2.3803,  2.7172],\n",
            "        [-1.1365, -3.7754,  1.7869,  ...,  1.2418,  6.9721, -1.0914],\n",
            "        ...,\n",
            "        [ 2.3582, -6.1829,  4.9502,  ...,  2.3943,  3.4669,  1.2788],\n",
            "        [-0.3342, -2.2492,  0.8114,  ...,  0.4485,  1.4699,  0.6378],\n",
            "        [-0.6697, -5.4332, -1.7290,  ..., -2.6559,  5.6429, -0.1545]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1192, -3.6885,  4.4338,  ...,  1.5155,  2.9316, -0.2268],\n",
            "        [-1.9274, -2.3177,  5.1415,  ..., -1.1674,  2.5668,  1.0325],\n",
            "        [-0.6691, -5.3545,  4.2478,  ..., -0.4836,  2.8043, -0.2321],\n",
            "        ...,\n",
            "        [ 1.0876, -1.8095,  5.7092,  ...,  3.4260,  2.0694,  3.2121],\n",
            "        [-0.0500, -3.5837,  4.8308,  ...,  1.1431, -0.0648,  2.2324],\n",
            "        [ 1.0326, -3.9188,  6.7844,  ..., -0.5234,  3.6136,  0.3747]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7152, -5.8967,  3.3605,  ...,  2.7721,  6.5748,  2.8255],\n",
            "        [-3.8397, -4.5450,  4.1225,  ...,  0.9263,  0.9575,  0.2245],\n",
            "        [-0.9796, -1.2479,  0.2516,  ...,  1.6004,  0.5696,  0.8756],\n",
            "        ...,\n",
            "        [-1.8142, -2.1032,  2.4947,  ...,  0.3175,  3.3290,  2.0746],\n",
            "        [-2.1329, -3.0709,  3.0873,  ...,  2.0617,  6.0104, -0.6712],\n",
            "        [-0.2910, -4.9062,  4.2219,  ..., -2.0352, -1.6950,  1.2159]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1381, -1.1412,  2.9932,  ...,  0.6106,  1.6631, -0.7542],\n",
            "        [-0.0979, -2.7133,  0.9604,  ...,  1.0757,  0.5924,  3.4043],\n",
            "        [-0.9949, -1.9624,  0.5061,  ...,  4.4826,  1.3704,  1.1638],\n",
            "        ...,\n",
            "        [-1.0872, -2.4288,  5.7491,  ...,  2.0804,  2.3038,  2.6146],\n",
            "        [-1.7349, -2.0966, -0.2639,  ...,  4.7731,  6.8805, -1.9113],\n",
            "        [ 0.6863, -5.5819,  4.9479,  ...,  0.5209, -0.3775,  1.5796]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6375, -4.2451, -1.6502,  ...,  4.2053,  4.1794, -3.0841],\n",
            "        [ 2.4768, -2.5181,  2.2603,  ...,  0.0959,  2.4558,  1.4320],\n",
            "        [-0.4205, -3.6022,  3.0722,  ..., -4.6831,  5.2373, -0.6620],\n",
            "        ...,\n",
            "        [-1.6486, -1.3047,  4.7069,  ...,  1.7931,  2.7405,  3.8845],\n",
            "        [-0.4277, -4.3598, -2.2035,  ..., -3.1454,  3.3042,  2.8467],\n",
            "        [-4.8864, -2.8785, -0.2508,  ..., -1.4573,  1.2649,  1.0582]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7996, -5.1730,  2.6721,  ..., -0.8685,  5.3107,  2.4200],\n",
            "        [ 0.0718, -2.9381,  4.8326,  ...,  1.5422,  1.3941,  1.9183],\n",
            "        [-3.2941, -3.3338,  1.7479,  ..., -0.2559,  5.1757, -0.9093],\n",
            "        ...,\n",
            "        [-0.1919, -2.1938,  1.1208,  ...,  2.9803, -0.6191,  3.7897],\n",
            "        [ 0.8183, -3.3690,  5.2843,  ...,  0.6385,  3.4990, -0.6214],\n",
            "        [-1.3672, -2.7694,  3.3046,  ...,  4.6446,  4.9915,  1.5560]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1815, -3.4519,  1.4213,  ...,  2.4543, -0.4710,  1.7944],\n",
            "        [-5.7545, -4.5923, -2.0880,  ...,  0.5231,  6.4034, -0.5589],\n",
            "        [-1.1221, -3.7707,  0.3757,  ..., -2.5537,  5.5483,  2.5533],\n",
            "        ...,\n",
            "        [-0.7110, -3.5390,  0.2618,  ...,  1.2651,  0.3675,  1.8857],\n",
            "        [-1.4825, -3.8051,  2.1924,  ..., -0.8664,  4.9779,  1.1590],\n",
            "        [-2.5001, -3.6113, -2.4380,  ..., -0.5043,  2.5732, -0.8004]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6255, -1.7434,  3.9211,  ...,  1.9083,  0.8421,  2.4424],\n",
            "        [-0.9151, -2.5203, -0.1171,  ..., -2.2201,  2.7920,  1.1447],\n",
            "        [-0.7034, -3.0862,  4.9474,  ...,  1.4715,  5.5778,  1.0454],\n",
            "        ...,\n",
            "        [ 1.3540, -1.9030,  2.5600,  ...,  3.2461,  6.6005,  0.9294],\n",
            "        [-0.4862, -3.3321,  3.0804,  ..., -1.4386,  3.2571,  2.5324],\n",
            "        [-3.9390, -4.6146,  1.5407,  ...,  2.6581,  0.4844,  0.4086]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8436, -1.5910,  4.9652,  ..., -0.3446,  1.2939,  3.7632],\n",
            "        [-2.6012, -3.1560, -4.3436,  ...,  1.1810,  5.8081, -1.4617],\n",
            "        [-3.4812, -2.3301,  1.7475,  ..., -0.0667,  6.3928, -1.5074],\n",
            "        ...,\n",
            "        [ 1.1037, -2.9620,  5.3451,  ...,  3.0247, -0.7202,  3.8705],\n",
            "        [ 0.9602, -3.7349,  3.9202,  ...,  2.6978, -0.7025,  2.5874],\n",
            "        [ 0.4334, -3.5028,  4.0339,  ..., -1.1100,  2.9845,  2.5790]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2952, -2.6247,  0.7170,  ...,  1.0547,  0.6703,  4.4154],\n",
            "        [-2.8360, -3.1634,  3.1582,  ..., -0.4203,  5.8585, -2.2108],\n",
            "        [-0.4959, -1.1731,  3.3627,  ...,  2.5047,  3.0345,  4.8319],\n",
            "        ...,\n",
            "        [-3.2953, -3.0049, -1.2646,  ...,  2.2269,  5.7872,  0.4015],\n",
            "        [-0.4012, -3.1538,  0.9730,  ...,  1.0274, -0.0625,  4.5940],\n",
            "        [-1.7505, -1.6771,  1.7855,  ...,  0.7020,  1.5642,  3.9005]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9318, -3.4474,  4.3130,  ...,  2.8077,  0.4383,  4.8589],\n",
            "        [-2.0826, -3.2943,  0.8172,  ..., -3.0403,  2.8699,  1.6608],\n",
            "        [-1.8528, -2.2737,  1.2580,  ...,  1.0870,  0.0166,  1.0343],\n",
            "        ...,\n",
            "        [-2.5645, -2.8769,  1.3122,  ...,  1.1634, -0.8685,  2.3902],\n",
            "        [ 2.1979, -4.7008,  1.8126,  ...,  2.6576,  4.2284,  2.5271],\n",
            "        [ 1.3637, -2.5511,  0.6496,  ...,  3.6057,  5.2198,  1.1522]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0642, -4.5603,  4.5235,  ...,  1.9497,  3.0324,  2.8346],\n",
            "        [-1.3917, -1.3262,  1.8158,  ...,  1.1807, -0.3601,  3.9550],\n",
            "        [-1.9253, -5.9491,  0.8751,  ..., -0.8420, 10.4772, -1.3130],\n",
            "        ...,\n",
            "        [-3.2521, -3.2377,  2.2896,  ...,  0.9936,  5.2202, -1.9942],\n",
            "        [-1.1292, -2.3580,  5.2478,  ...,  0.1718, -0.3625,  1.1014],\n",
            "        [ 0.2056, -3.0428,  5.0229,  ..., -3.1056,  1.0682,  1.9603]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9845, -5.1221,  3.6466,  ..., -0.3968,  1.6917,  3.0585],\n",
            "        [-1.4145, -2.7628,  2.3309,  ...,  0.5722,  3.3146,  0.3187],\n",
            "        [-0.2478, -3.3426,  1.2435,  ...,  1.4812,  4.3302,  0.4318],\n",
            "        ...,\n",
            "        [ 0.1359, -3.5345,  4.0913,  ...,  1.1254, -0.4851,  3.6737],\n",
            "        [-6.5112, -4.9314,  4.4013,  ..., -0.2474,  5.4741, -2.1105],\n",
            "        [ 2.1356, -2.2442,  2.7232,  ...,  3.0718, -1.3193,  3.6322]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2805, -1.7228,  5.0295,  ...,  1.0160,  0.2799,  2.8333],\n",
            "        [ 1.1496, -1.5529,  1.0992,  ..., -1.0303,  4.2193,  2.5735],\n",
            "        [-2.1989, -3.1444,  0.6873,  ...,  0.1983,  4.1759, -1.4894],\n",
            "        ...,\n",
            "        [-2.2553, -2.6013,  1.2408,  ...,  1.8622,  0.3003,  2.7688],\n",
            "        [-3.0213, -2.5219, -1.2218,  ...,  3.3816, -2.9855,  0.9762],\n",
            "        [-1.5647, -2.9659,  3.2006,  ...,  0.8272,  3.7776, -0.5669]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3493, -3.0977,  3.5817,  ...,  0.5234,  4.1530, -1.2858],\n",
            "        [-1.0626, -1.8437,  5.7046,  ...,  1.4761,  2.0779,  3.8687],\n",
            "        [-2.3862, -1.3066,  1.0303,  ...,  1.4934, -1.7989,  4.2662],\n",
            "        ...,\n",
            "        [-2.7402, -2.5407,  3.3090,  ...,  0.9095,  2.9991,  0.2998],\n",
            "        [ 0.0150, -5.2873,  3.1020,  ...,  2.4066,  3.9523,  2.5522],\n",
            "        [-0.6741, -4.2979,  0.3822,  ...,  1.4297,  4.8892,  1.0630]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3140, -1.4734,  1.6646,  ...,  0.2364,  4.1854, -0.0709],\n",
            "        [-2.2066, -2.1601,  2.3215,  ...,  1.6543,  1.9593,  0.3228],\n",
            "        [-2.2456, -4.3373,  2.0768,  ...,  0.3634,  0.9045,  1.1095],\n",
            "        ...,\n",
            "        [ 0.1052, -3.8146,  1.1055,  ...,  0.6683,  2.7001,  0.2667],\n",
            "        [ 0.1333, -2.7498,  4.8166,  ...,  2.0923, -0.9291,  3.7737],\n",
            "        [-1.3000, -3.3390,  3.9025,  ...,  2.9994,  5.8447, -0.1718]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1574, -4.2046,  3.2780,  ...,  0.8459,  4.1273, -0.5939],\n",
            "        [-2.9850, -4.3590,  2.6711,  ..., -0.0713,  5.0566, -1.5108],\n",
            "        [-2.3745, -1.6487,  1.5038,  ...,  1.4604, -0.9319,  4.5513],\n",
            "        ...,\n",
            "        [-1.4722, -5.0780,  0.2050,  ...,  2.0200,  0.8334,  2.1097],\n",
            "        [-0.9538, -3.1855,  3.4768,  ...,  1.3270,  2.9646,  0.0387],\n",
            "        [-3.8385, -4.7077, -4.9468,  ...,  0.3697,  5.9033, -1.2925]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1148, -3.2792,  4.2337,  ...,  4.2363, -1.9818,  3.1102],\n",
            "        [-3.4725, -5.8446, -1.6510,  ...,  3.1687,  1.9483,  0.3742],\n",
            "        [ 1.3323, -1.2853,  0.6353,  ..., -1.2046,  3.1148,  2.3683],\n",
            "        ...,\n",
            "        [ 1.5091, -3.8416,  5.6519,  ..., -0.1539,  0.2735,  2.5034],\n",
            "        [-1.7522, -2.6713,  0.7797,  ...,  1.4897, -1.1900,  4.0697],\n",
            "        [-1.6031, -2.3608,  2.5766,  ..., -2.3201,  4.3681,  0.8779]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.2005, -2.0647,  3.8012,  ..., -0.5159,  3.7810, -0.7098],\n",
            "        [-2.8077, -3.6911, -1.7630,  ..., -3.8493,  2.6825,  2.7215],\n",
            "        [-0.3166, -3.4471,  2.2934,  ..., -2.0457,  2.9654,  2.6212],\n",
            "        ...,\n",
            "        [-4.7170, -4.6924,  3.5975,  ...,  0.6133, -1.2248,  0.0874],\n",
            "        [ 0.7539, -2.0585,  4.2981,  ...,  0.7003, -0.0395,  0.4537],\n",
            "        [-2.8223, -2.9134,  2.8885,  ...,  1.5382,  4.5754, -0.2800]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8084, -3.9604,  3.3514,  ...,  3.1491, -1.4249,  1.8492],\n",
            "        [-3.3156, -3.3483,  2.7755,  ...,  0.1017,  6.4543, -1.4761],\n",
            "        [-4.1048, -4.6928,  4.0672,  ..., -2.0237,  3.1499, -0.2375],\n",
            "        ...,\n",
            "        [-0.6672, -3.3971,  2.9545,  ...,  0.3658,  0.7307,  2.6505],\n",
            "        [-1.7794, -1.9990,  1.8332,  ..., -1.8374,  4.3298, -0.2972],\n",
            "        [-1.9425, -3.1951,  2.2101,  ...,  3.1419,  4.2624,  0.5035]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1845, -2.9595, -1.8004,  ...,  3.5331,  7.0429, -0.5867],\n",
            "        [-3.9407, -2.9040,  4.1778,  ..., -0.2377,  2.5866,  0.9407],\n",
            "        [-1.1167,  0.3885,  2.6878,  ...,  2.2564,  1.8323,  2.1478],\n",
            "        ...,\n",
            "        [ 1.0607, -2.9814,  6.4620,  ...,  2.9104,  1.1940,  2.0374],\n",
            "        [-0.9714, -2.6744,  3.9459,  ...,  1.1008,  1.7181,  2.4819],\n",
            "        [-0.0472, -4.7854,  3.1100,  ...,  3.4733,  1.0689,  3.7924]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5261, -2.6732,  7.5128,  ...,  0.5802,  0.1693,  1.9279],\n",
            "        [-0.1461, -2.6893,  0.8401,  ...,  1.3548, -0.1611,  3.5860],\n",
            "        [-1.7698, -2.3430,  1.9254,  ...,  2.6056, -1.7347,  4.7435],\n",
            "        ...,\n",
            "        [-1.4989, -0.9901, -0.2276,  ...,  0.6561,  0.6299,  2.3196],\n",
            "        [-1.7992, -1.1771,  1.2712,  ...,  1.8941, -0.8877,  4.4348],\n",
            "        [-1.8694, -3.3228,  3.1215,  ..., -1.5647,  2.3725, -0.7903]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2345, -3.0765,  3.3867,  ...,  0.0194,  5.5218,  0.6978],\n",
            "        [-0.1030, -4.3590, -1.7859,  ...,  1.4619,  4.6220,  0.3594],\n",
            "        [-0.2130, -5.1225,  4.7980,  ..., -0.3826,  3.7723,  1.7740],\n",
            "        ...,\n",
            "        [-0.1530, -3.9149,  4.8211,  ...,  2.8755, -0.5978,  2.9822],\n",
            "        [-0.7114, -1.4715,  2.5398,  ...,  0.9131,  2.3119,  2.7782],\n",
            "        [-1.1449, -3.0932,  1.7519,  ...,  3.3303, -1.3267,  3.9200]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1807, -2.3909,  0.8908,  ...,  3.2549,  0.4063,  3.5455],\n",
            "        [ 0.2753, -4.6234,  2.6748,  ...,  1.6104, 10.3757, -0.3124],\n",
            "        [-0.8101, -1.5814, -0.8715,  ..., -1.2407,  3.7669,  3.1112],\n",
            "        ...,\n",
            "        [-1.5419, -2.6948,  4.1631,  ...,  4.2795,  2.7105,  1.3789],\n",
            "        [-2.2930, -3.0898,  4.7573,  ...,  1.9303,  6.0884,  2.5783],\n",
            "        [ 0.9483, -5.5241,  0.8650,  ...,  3.5255,  2.2329,  1.6546]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7717, -3.9741,  2.9747,  ...,  1.4411,  0.1401,  3.4012],\n",
            "        [-1.0123, -4.4977,  1.7147,  ...,  4.3946,  2.1391,  0.1928],\n",
            "        [-1.3115, -4.0368,  2.0876,  ...,  0.9490, -0.6044,  2.0552],\n",
            "        ...,\n",
            "        [-0.5118, -1.7025,  4.6790,  ...,  2.8217,  2.8034,  4.4941],\n",
            "        [-0.5605, -5.3527,  1.6551,  ..., -1.0507,  4.0096,  1.1920],\n",
            "        [-1.5449, -2.6242,  2.3855,  ..., -1.9795,  1.5478,  1.9769]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7672, -2.5280,  2.6437,  ..., -0.9355,  1.7491,  2.2684],\n",
            "        [-4.4974, -3.3018,  4.6048,  ...,  0.9622,  2.6255,  1.0682],\n",
            "        [ 0.8682, -2.8771,  0.2232,  ...,  2.0971,  2.6941,  0.0102],\n",
            "        ...,\n",
            "        [-3.9636, -5.0574,  1.9276,  ...,  0.7904,  1.5642, -0.3063],\n",
            "        [-3.2330, -4.3091, -3.6883,  ...,  1.2281,  7.8752, -1.2040],\n",
            "        [ 0.1659,  0.1140,  2.9099,  ...,  2.3274,  1.1840,  4.2307]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7856, -2.6744,  1.7231,  ...,  2.2280, -0.7101,  3.7934],\n",
            "        [-0.1429, -2.3482,  3.3286,  ...,  2.0735,  0.2677,  3.7647],\n",
            "        [-0.1296, -3.5086,  4.4777,  ...,  1.5785,  1.6130,  2.8435],\n",
            "        ...,\n",
            "        [ 0.5034, -3.0954,  1.9460,  ...,  1.9308, -0.2247,  5.0074],\n",
            "        [-0.6986, -1.2355,  2.7788,  ...,  4.1135, -1.3219,  2.3255],\n",
            "        [ 0.9242, -4.4364,  0.2793,  ...,  2.7659,  1.7063,  1.1615]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7716, -4.9904,  2.1781,  ..., -0.0525,  4.6578, -0.9262],\n",
            "        [ 1.3420, -4.1630,  3.3158,  ...,  3.6970,  0.8290,  0.2205],\n",
            "        [ 0.5509, -2.4189,  1.0683,  ...,  3.0912,  4.2451,  1.6073],\n",
            "        ...,\n",
            "        [ 1.3557, -4.2088,  0.4767,  ...,  0.3812,  2.8653,  4.5477],\n",
            "        [-1.7916, -3.8547,  3.1259,  ..., -1.9118,  3.1923,  2.3071],\n",
            "        [-3.2084, -2.5330, -3.5832,  ...,  4.3978,  5.6650, -4.3409]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bc6662daec245c5a144716069e5a592"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.3355, -2.9122,  1.1125,  ..., -0.2699,  2.3126,  0.5535],\n",
            "        [-3.6885, -2.0576,  0.4030,  ...,  1.0457,  3.0301,  0.6614],\n",
            "        [-1.6648, -2.5740,  5.2700,  ...,  1.2941,  3.5185, -0.7118],\n",
            "        ...,\n",
            "        [-1.8197, -3.0540,  5.8943,  ..., -0.0068,  4.4229, -0.3709],\n",
            "        [-2.5058, -3.3073,  2.4472,  ..., -2.5246,  3.2169,  0.6453],\n",
            "        [ 0.2269, -5.2850,  0.1928,  ...,  2.4264,  3.0061, -0.6650]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7498e+00, -4.0538e+00,  4.8474e+00,  ...,  1.1717e-01,\n",
            "          2.0403e+00,  6.6951e-01],\n",
            "        [-2.0574e+00, -3.1734e+00,  4.2065e+00,  ...,  3.2524e-01,\n",
            "          8.7331e-05,  8.6742e-01],\n",
            "        [-1.0592e+00, -2.7577e+00,  4.0281e+00,  ...,  1.6322e+00,\n",
            "         -1.1184e+00,  3.1405e+00],\n",
            "        ...,\n",
            "        [-1.8772e+00, -3.5727e+00, -4.7917e-02,  ..., -1.9451e-01,\n",
            "          6.4783e+00, -4.5389e-01],\n",
            "        [-1.0890e+00, -1.1801e+00,  6.2807e+00,  ...,  3.6668e+00,\n",
            "          1.5214e+00,  3.4761e+00],\n",
            "        [ 1.2338e+00, -1.1193e-01,  1.7879e+00,  ...,  2.1257e+00,\n",
            "          2.3026e+00,  3.3228e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7896, -1.6783,  1.3441,  ...,  0.7358,  0.6822, -0.3471],\n",
            "        [ 0.3066, -1.0456, -0.6595,  ..., -2.0502,  1.4294,  3.3574],\n",
            "        [-5.7689, -3.1288, -0.2691,  ..., -2.0521, -2.0145, -0.2133],\n",
            "        ...,\n",
            "        [-0.3416, -1.4270, -0.9482,  ..., -1.9011,  1.9309,  1.9773],\n",
            "        [ 1.2177, -1.1261,  4.4921,  ..., -0.3630,  1.7988,  2.3030],\n",
            "        [-0.9537, -2.9816,  3.3145,  ...,  0.7186,  3.7792,  0.7109]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2901, -4.3632,  4.5644,  ...,  2.1173,  2.5166,  0.9617],\n",
            "        [-3.0544, -6.3033, -0.3337,  ...,  3.3303,  5.0893, -1.1645],\n",
            "        [-0.8883, -2.1240,  0.6899,  ...,  1.4466, -0.4856,  2.4294],\n",
            "        ...,\n",
            "        [-1.6224, -2.4312,  3.6522,  ...,  0.7389,  0.0552,  2.1976],\n",
            "        [-0.3628, -3.0612,  0.9479,  ...,  3.2038,  3.9654,  0.7259],\n",
            "        [ 0.3135, -3.7196,  3.6755,  ..., -2.6726, -0.2480,  1.1919]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7645, -5.5752,  1.5921,  ...,  3.5410,  4.4374,  0.8127],\n",
            "        [-2.1812, -3.5859,  2.6664,  ...,  1.6455, -1.2147,  0.1104],\n",
            "        [-0.9627, -3.5445,  0.2485,  ..., -4.6250,  3.7956,  1.9971],\n",
            "        ...,\n",
            "        [ 0.0367, -5.6780,  3.8349,  ...,  2.0815,  3.2678,  1.1688],\n",
            "        [ 0.6307, -4.3979,  3.2849,  ...,  1.9308,  1.4919,  1.4599],\n",
            "        [ 0.8119, -0.7020,  0.6704,  ...,  3.3492, -0.6180,  1.6080]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9834, -4.4962,  0.1019,  ...,  2.7521,  1.3846, -0.6441],\n",
            "        [-1.9451, -2.5453,  0.9921,  ...,  1.7703,  0.0784,  2.3296],\n",
            "        [-2.2403, -1.8743,  1.8006,  ...,  1.1442, -0.4058,  4.0591],\n",
            "        ...,\n",
            "        [-0.4289, -2.6607,  5.4558,  ...,  1.0618,  2.1415,  0.7546],\n",
            "        [ 2.2720, -3.9865,  3.4643,  ...,  1.4105,  3.1187,  0.9072],\n",
            "        [-1.0639, -4.6422,  4.2122,  ...,  0.7719,  0.1485,  1.4168]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6796, -2.1704,  1.2420,  ...,  2.9898, -0.9006,  2.5943],\n",
            "        [-1.7953, -4.1626,  3.0902,  ..., -0.0918,  3.3400,  2.5879],\n",
            "        [ 0.0598, -2.0712,  3.5133,  ...,  1.8561,  4.4022,  0.4246],\n",
            "        ...,\n",
            "        [-0.3992, -2.9584,  1.2570,  ...,  2.2959, -1.1194,  3.8618],\n",
            "        [-1.2584, -2.1896,  4.0659,  ...,  0.5588,  3.8359, -2.1936],\n",
            "        [ 1.5544, -1.7521,  2.8407,  ...,  2.7974, -0.2246,  2.7862]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0552, -3.6048,  3.0017,  ...,  1.2772, -0.3764,  3.1371],\n",
            "        [-1.6581, -2.3805,  1.0338,  ...,  2.4922, -1.2595,  3.4794],\n",
            "        [-2.0376, -2.3013,  6.0671,  ...,  1.4485, -0.1991,  0.6607],\n",
            "        ...,\n",
            "        [-2.2082, -3.6208,  0.8393,  ..., -1.0025, -0.3424,  0.9793],\n",
            "        [-3.6221, -3.2312,  1.7875,  ..., -0.8207,  4.9093, -1.5026],\n",
            "        [-2.4161, -4.8415,  2.1724,  ...,  1.8284, -1.7530,  0.6727]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1292, -3.3913,  1.4909,  ...,  0.7914,  2.3633,  0.1508],\n",
            "        [ 2.1081, -6.7091,  2.7770,  ...,  1.9087,  5.5065,  1.6159],\n",
            "        [-5.2390, -3.0537, -2.6054,  ..., -1.3989,  5.8311, -1.9660],\n",
            "        ...,\n",
            "        [ 0.3512, -3.9442,  4.0991,  ...,  1.2263,  0.6324,  2.1882],\n",
            "        [ 1.6648, -2.4491,  2.6706,  ...,  1.2163,  0.3623,  2.3642],\n",
            "        [ 1.6648, -3.7191,  2.0198,  ..., -0.1273,  4.7898,  1.5033]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4269, -2.6073,  1.4585,  ...,  1.2776, -0.1846,  3.9454],\n",
            "        [-0.7085, -2.5109,  3.4175,  ...,  4.3607,  4.4248,  2.1930],\n",
            "        [-0.3146, -2.9451, -0.1578,  ..., -3.1990,  5.0215,  1.5054],\n",
            "        ...,\n",
            "        [ 0.2902, -3.2551,  5.3825,  ...,  1.3514,  2.3474, -0.3745],\n",
            "        [-2.5038, -3.8814,  3.8366,  ..., -1.8483,  4.1870, -0.2513],\n",
            "        [-0.7518, -3.7382,  5.8066,  ..., -0.9633,  6.4672, -0.8519]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0679, -2.6066,  1.3468,  ...,  1.1840, -0.5566,  2.9430],\n",
            "        [-0.6554, -2.3011,  1.5379,  ...,  2.5783,  0.4783,  2.5003],\n",
            "        [-0.0267, -2.1545,  1.4740,  ...,  1.5728, -0.5696,  3.7051],\n",
            "        ...,\n",
            "        [-0.7937, -1.7993,  1.2990,  ...,  4.1183, -0.5498,  3.0383],\n",
            "        [-2.3992, -3.4447,  2.4829,  ...,  1.3074,  0.8980,  0.3404],\n",
            "        [-1.3124, -2.8420, -0.6425,  ...,  0.3428,  1.3568,  0.9208]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2824, -4.4241,  2.8444,  ..., -2.5126,  6.2772,  0.4900],\n",
            "        [ 1.8463, -4.3499, -1.3595,  ..., -1.6016,  5.8933,  1.9026],\n",
            "        [-0.4082, -2.1173, -0.0572,  ...,  2.7506,  0.9654,  2.9859],\n",
            "        ...,\n",
            "        [-0.0793, -3.0564,  2.3572,  ...,  1.0608, -0.3929,  3.4800],\n",
            "        [-0.2683, -2.0095,  4.4002,  ...,  3.3028,  5.2832,  2.0410],\n",
            "        [ 0.0453, -1.9731,  3.9746,  ...,  0.1062,  0.7963,  2.2030]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0981, -2.2316,  1.9789,  ...,  1.5099,  3.5201,  2.1331],\n",
            "        [-3.2801, -2.7162, -0.2257,  ...,  2.3262, -0.9331,  0.0619],\n",
            "        [ 1.8565, -2.2552, -0.8619,  ...,  1.6446, -0.9998,  1.7533],\n",
            "        ...,\n",
            "        [ 1.2725, -1.9267,  3.3825,  ...,  1.3586,  0.8371,  2.4270],\n",
            "        [ 0.0554, -1.3142,  3.2087,  ...,  4.0106, -0.7247,  3.1770],\n",
            "        [ 1.7684, -2.8323,  4.0215,  ...,  1.5454,  0.8545,  1.6194]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0349, -1.4201,  2.1219,  ...,  1.4238, -0.6445,  3.2537],\n",
            "        [-1.6972, -2.9930,  3.9977,  ..., -1.4644,  3.9245,  0.1325],\n",
            "        [ 2.2187, -1.3824,  1.8300,  ...,  3.5867, -0.1980,  3.0913],\n",
            "        ...,\n",
            "        [-0.7370, -1.9010,  1.9797,  ...,  1.1550,  0.5243,  2.0100],\n",
            "        [ 0.1931, -3.1676,  2.9961,  ...,  1.8763,  6.2832, -0.5051],\n",
            "        [-0.4137, -2.0019,  3.0047,  ...,  2.1211,  0.1804,  1.9323]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7981, -2.2038,  3.1411,  ..., -0.1499,  3.8940,  0.9345],\n",
            "        [-0.6862, -2.9910,  4.4683,  ...,  1.5405,  0.3046, -0.2921],\n",
            "        [-2.6275, -1.8611,  1.5452,  ...,  0.3852, -0.5713,  2.1533],\n",
            "        ...,\n",
            "        [ 1.5944, -4.2244,  0.8155,  ...,  3.3324,  3.0945,  0.6201],\n",
            "        [ 3.0331, -2.9541,  4.5391,  ...,  2.8327,  0.7973,  3.5934],\n",
            "        [-0.0632, -1.7842,  1.2093,  ...,  0.8156,  5.1680, -0.8147]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2316, -4.0087,  2.6957,  ...,  2.0537, -0.1906,  3.1826],\n",
            "        [-2.2388, -1.5584,  0.9487,  ..., -1.4251,  2.1482,  2.0595],\n",
            "        [ 0.0130, -2.3727,  6.4335,  ...,  1.1662,  2.6822,  4.0165],\n",
            "        ...,\n",
            "        [-1.9971, -2.3059,  3.1310,  ...,  0.4141,  0.4251,  1.5507],\n",
            "        [-2.5534, -1.3926,  5.4518,  ..., -0.4480,  3.1973, -1.5439],\n",
            "        [-1.9070, -0.9952,  1.7415,  ...,  1.5794, -0.7445,  3.5010]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1630, -1.6469,  1.0648,  ...,  0.8880,  3.9168,  0.0983],\n",
            "        [ 0.9272, -3.2635,  6.2329,  ...,  2.8507, -0.6238,  3.1064],\n",
            "        [-0.2594, -3.1131,  3.5536,  ..., -0.9986,  2.3630,  1.6977],\n",
            "        ...,\n",
            "        [ 0.6509, -2.0169,  5.0137,  ..., -0.9516,  0.8528,  0.4149],\n",
            "        [-1.4397, -2.8641,  1.7414,  ...,  1.2508, -0.7808, -1.3339],\n",
            "        [-1.2104, -4.0394,  0.2543,  ..., -0.1691,  3.8394,  1.5343]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3658, -2.7141,  4.2174,  ..., -0.6829,  1.9251,  2.0149],\n",
            "        [-2.9116, -4.7055,  5.1126,  ..., -1.3823,  3.7195, -1.3080],\n",
            "        [ 1.6446, -1.8373,  4.5287,  ...,  0.6960,  1.1104,  2.5020],\n",
            "        ...,\n",
            "        [ 0.6671, -2.7774,  1.6447,  ...,  0.9289,  4.9496, -1.2542],\n",
            "        [-1.1497, -2.5741,  6.1358,  ...,  0.9417,  1.0233, -0.0859],\n",
            "        [ 1.2846, -3.4414,  2.9195,  ...,  3.4130,  3.2811,  1.0384]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2746, -3.9857,  2.6381,  ...,  1.0672,  1.6683,  3.2127],\n",
            "        [ 0.3871, -3.4439,  1.9136,  ...,  3.4064,  4.9771, -0.2135],\n",
            "        [ 2.5470, -2.9599,  3.7100,  ...,  1.6814,  0.6940,  2.6767],\n",
            "        ...,\n",
            "        [-0.9198, -3.1525, -0.6253,  ...,  0.6516, -0.6130,  0.7834],\n",
            "        [ 3.3136, -4.8010,  2.5598,  ...,  4.9811,  2.1243,  0.3699],\n",
            "        [-3.0209, -3.4039, -0.8306,  ..., -0.1516,  1.5000, -1.6403]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8077, -3.9050,  4.9071,  ...,  0.8234,  3.7820,  0.2578],\n",
            "        [ 1.1711, -3.0350,  3.7316,  ...,  1.3129,  0.1536,  1.7636],\n",
            "        [ 2.5922, -3.0332,  4.5050,  ...,  1.4050,  1.8825,  3.3221],\n",
            "        ...,\n",
            "        [-3.3833, -2.3814,  4.5291,  ...,  1.2096, -2.6463,  1.8628],\n",
            "        [-1.2970, -4.2952,  6.1197,  ..., -1.4066,  2.2223, -0.2383],\n",
            "        [-4.2498, -3.4242,  1.2815,  ..., -1.2689,  5.0618, -2.0765]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1616, -3.2385,  3.9925,  ...,  1.0426,  4.7083,  0.5019],\n",
            "        [-2.5697, -3.6932,  0.3302,  ...,  1.1539,  5.9024, -1.5535],\n",
            "        [-1.7289, -1.4795,  1.7120,  ...,  2.2023, -0.6034,  2.4765],\n",
            "        ...,\n",
            "        [-0.8543, -3.2363, -2.1510,  ...,  1.0045, -1.7155,  1.2404],\n",
            "        [-3.2970, -3.5119, -2.8630,  ...,  3.0269, -1.8496, -2.6954],\n",
            "        [-1.1328, -4.6688,  5.0420,  ...,  0.6170,  2.6225, -0.1566]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8423, -2.2659,  1.0019,  ...,  0.9053, -0.6070,  3.3000],\n",
            "        [-5.0401, -2.8525,  1.4478,  ...,  0.6178,  5.2909, -2.8214],\n",
            "        [-3.8512, -4.7430,  0.5182,  ...,  0.8976,  7.5126, -2.5452],\n",
            "        ...,\n",
            "        [ 1.5232, -2.1736,  2.9937,  ...,  1.2347, -0.4428,  1.4071],\n",
            "        [-0.3150, -2.3111,  1.8540,  ...,  1.0209, -0.1467,  2.6204],\n",
            "        [ 1.8090, -4.7828,  3.7159,  ...,  2.4215,  1.8158,  0.8883]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8282, -2.9889, -0.1928,  ...,  4.8192,  5.0342,  0.6788],\n",
            "        [ 0.7764, -3.3975,  2.6462,  ..., -0.6613,  1.0738,  1.4477],\n",
            "        [-3.2596, -4.5052, -1.5381,  ..., -3.7939,  3.5304,  0.6039],\n",
            "        ...,\n",
            "        [-2.3886, -6.0720, -2.1911,  ...,  2.9944,  1.3526, -2.1937],\n",
            "        [ 2.1076, -3.4872,  4.1040,  ...,  1.8857,  3.1381,  2.2241],\n",
            "        [ 2.0081, -5.0594,  4.1417,  ...,  1.6374,  3.8242, -0.3798]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7772, -4.0764,  1.1435,  ...,  1.9277,  5.3518, -1.9000],\n",
            "        [-4.7322, -1.9000,  0.3362,  ..., -0.2504,  1.3466, -0.3066],\n",
            "        [-0.4417, -2.1000,  0.6768,  ...,  0.9360, -0.6747,  3.2912],\n",
            "        ...,\n",
            "        [ 1.0425, -2.0460,  2.9023,  ...,  3.0055, -1.6730,  3.1177],\n",
            "        [-0.9396, -2.1649,  2.9294,  ..., -0.5596,  1.5821, -0.0969],\n",
            "        [-0.3091, -4.2053,  1.7254,  ..., -0.8478,  4.4074, -1.7115]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4339, -1.5478,  0.9134,  ...,  1.6712,  0.0213,  2.9056],\n",
            "        [ 0.9341, -3.1692, -0.4682,  ..., -3.1671,  3.8160,  1.8785],\n",
            "        [-2.3183, -3.3092,  2.8248,  ..., -0.0070,  3.8097, -2.3486],\n",
            "        ...,\n",
            "        [ 2.0476, -4.5555,  3.8402,  ...,  1.1733,  0.4744,  2.6078],\n",
            "        [-1.9612, -2.7675,  0.5215,  ..., -2.6882,  2.1069, -0.2319],\n",
            "        [ 1.8843, -1.4441,  4.0309,  ...,  1.9034,  0.0652,  1.1414]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0304, -1.6540,  1.7639,  ...,  1.8497, -0.2884,  2.6271],\n",
            "        [-0.1248, -2.4827,  4.6931,  ...,  1.0978,  5.3027,  1.5283],\n",
            "        [ 1.6625, -4.0159,  4.3387,  ...,  2.2344,  2.7862,  1.3618],\n",
            "        ...,\n",
            "        [ 1.9006, -3.1081,  1.2063,  ...,  0.5005,  0.5459,  3.1181],\n",
            "        [ 2.3656, -4.1642,  5.2105,  ..., -0.2069,  5.7840,  1.2543],\n",
            "        [-0.8059, -2.8318,  3.9280,  ...,  0.3011,  2.3748, -0.1204]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6118, -4.9190,  3.4010,  ...,  1.8867,  2.2480,  1.9224],\n",
            "        [ 3.0239, -3.1629,  1.4166,  ...,  1.6588,  6.7587,  1.4332],\n",
            "        [ 2.4817, -2.1061,  3.3424,  ..., -0.9025,  2.2340,  2.3333],\n",
            "        ...,\n",
            "        [-1.6464, -3.1228,  2.8253,  ..., -0.3540,  0.9113,  1.8447],\n",
            "        [ 0.5394, -2.5177,  3.5515,  ...,  1.5700,  1.4823, -0.4036],\n",
            "        [ 0.8318, -2.6242,  1.5036,  ...,  1.6721,  0.0737,  3.4415]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.3533, -3.3173,  5.3967,  ..., -0.3273,  1.2910,  1.3059],\n",
            "        [-0.4830, -2.3564,  2.1189,  ...,  3.1433, -0.2718,  1.5479],\n",
            "        [-2.5949, -4.7128,  3.8232,  ..., -0.8632,  1.9959, -2.2042],\n",
            "        ...,\n",
            "        [-0.7933, -1.2003,  3.4211,  ..., -0.7581,  1.1123,  0.1030],\n",
            "        [-2.2104, -2.9129,  3.1384,  ..., -2.0066,  1.4815, -2.3915],\n",
            "        [-0.2912, -1.7057,  5.0922,  ...,  0.2923,  1.4307,  1.5585]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8943, -3.1656,  2.2628,  ...,  3.3468,  3.3726, -1.0995],\n",
            "        [-0.1464, -1.3347,  1.7894,  ...,  2.0727,  0.7815,  3.0673],\n",
            "        [-3.0022, -2.2305, -0.2316,  ...,  2.5434,  0.4627, -0.0155],\n",
            "        ...,\n",
            "        [-1.7964, -1.9013, -3.5911,  ..., -4.8930,  3.3366,  0.9672],\n",
            "        [ 3.2573, -1.6873,  3.5457,  ...,  1.9065,  0.5557,  2.1050],\n",
            "        [ 1.0154, -1.9573,  2.6924,  ...,  2.1800,  0.2223,  3.1662]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4642, -1.3763,  2.0298,  ...,  1.9901, -1.1234,  3.6330],\n",
            "        [ 0.3470, -2.5949,  3.4401,  ...,  0.1813,  2.7911, -0.0802],\n",
            "        [ 0.6078, -2.5446,  3.2389,  ...,  1.8321, -1.5975,  2.8932],\n",
            "        ...,\n",
            "        [ 0.2893, -3.3690,  1.9770,  ...,  2.2649, -1.8945,  3.0607],\n",
            "        [ 3.9821, -2.8317,  3.2829,  ...,  2.1565,  2.1472,  3.3131],\n",
            "        [ 1.2867, -2.6390, -0.4576,  ..., -2.6358,  4.1235,  2.7058]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9969e+00, -1.6213e+00,  6.2841e+00,  ..., -1.0838e+00,\n",
            "          4.6697e+00,  7.8138e-01],\n",
            "        [-1.8520e+00, -2.9973e+00,  2.0541e+00,  ..., -4.3208e-03,\n",
            "          3.9349e-01, -7.7658e-02],\n",
            "        [ 5.9919e-02, -1.5294e+00,  4.2085e+00,  ...,  1.7808e+00,\n",
            "          1.5253e+00,  2.3413e+00],\n",
            "        ...,\n",
            "        [-1.4846e+00, -1.8476e+00,  1.0029e+00,  ...,  3.0719e+00,\n",
            "          3.6700e-01,  1.4283e+00],\n",
            "        [-6.3358e-01, -1.1942e+00,  2.0776e-01,  ...,  1.2071e+00,\n",
            "          5.9708e+00,  1.1041e+00],\n",
            "        [-3.8644e-01, -2.1879e+00,  2.2214e+00,  ...,  3.5088e+00,\n",
            "         -1.9852e-01,  2.1767e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0953, -2.1131,  1.9277,  ...,  2.0916, -1.3142,  3.3717],\n",
            "        [-0.6356, -3.2041,  1.2475,  ..., -0.4719, -0.4199, -1.0239],\n",
            "        [ 2.1152, -1.6294,  5.4654,  ..., -0.6109,  1.6348,  2.7102],\n",
            "        ...,\n",
            "        [-2.8376, -2.6884,  2.6737,  ..., -3.4749, -0.7946,  0.6210],\n",
            "        [-1.1949, -3.6835,  3.9048,  ...,  1.0967, -0.6930,  1.1750],\n",
            "        [ 1.1743, -3.0817,  1.3469,  ...,  1.0768,  2.5252,  0.3954]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7892, -3.9197,  2.3490,  ...,  2.8642,  5.7841, -2.5016],\n",
            "        [-1.4808, -0.5958,  6.9176,  ...,  1.4812,  0.0745,  1.4382],\n",
            "        [-1.7417, -4.0542,  5.6332,  ...,  0.1146,  4.9930, -1.4217],\n",
            "        ...,\n",
            "        [-2.8214, -2.6005,  2.4531,  ...,  1.2255,  3.9555, -0.6594],\n",
            "        [ 0.9121, -4.9536,  1.0981,  ...,  1.6023,  4.9296, -2.7075],\n",
            "        [-1.4510, -0.9579,  2.9512,  ...,  0.9202,  1.0512, -0.0624]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.5419, -2.8457,  3.7160,  ..., -0.2697,  0.5461,  0.2991],\n",
            "        [-1.2641, -2.5606,  3.0171,  ..., -0.3732,  2.4482,  0.0529],\n",
            "        [ 1.4102, -2.1096,  7.7793,  ...,  2.7718,  1.7131,  2.4604],\n",
            "        ...,\n",
            "        [ 1.3623, -1.4627,  6.2590,  ...,  1.6541,  0.9152,  3.0272],\n",
            "        [ 0.3942, -3.0786, -1.9184,  ...,  2.3530,  4.0487, -1.3325],\n",
            "        [ 1.8212, -2.9770,  2.3430,  ...,  1.1295,  0.4338,  2.1275]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3707, -2.1611,  4.0619,  ...,  0.4450,  3.7270,  0.6537],\n",
            "        [-4.0712, -3.1638, -3.5845,  ..., -0.1212,  8.2423, -1.1710],\n",
            "        [ 1.2549, -2.5733,  2.6024,  ..., -1.4108,  2.6693,  1.2865],\n",
            "        ...,\n",
            "        [ 0.1567, -2.6192,  0.6185,  ...,  0.0231,  0.2842,  2.7206],\n",
            "        [ 0.7927, -4.8081,  3.0989,  ..., -2.4076,  1.3353,  1.0435],\n",
            "        [ 0.8406, -3.9720,  4.7404,  ...,  2.5544,  2.9586,  1.7888]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2088e-01, -1.9558e+00,  3.5449e+00,  ...,  1.0292e-01,\n",
            "          8.3349e+00, -2.5510e+00],\n",
            "        [-7.3733e-01, -1.5965e+00,  4.6853e+00,  ...,  2.9839e+00,\n",
            "          3.7270e+00,  1.4125e+00],\n",
            "        [-1.9740e+00, -3.0400e+00,  2.3425e+00,  ...,  2.5659e+00,\n",
            "          3.0071e-03, -1.0476e+00],\n",
            "        ...,\n",
            "        [ 3.0184e+00, -4.0663e+00,  1.6734e+00,  ...,  3.3633e+00,\n",
            "         -4.9630e-01,  1.8114e+00],\n",
            "        [ 6.3278e-01, -4.7903e+00, -1.1185e-01,  ...,  1.2239e+00,\n",
            "          2.2767e+00, -3.4049e+00],\n",
            "        [-1.4839e+00, -3.0543e+00,  3.2019e+00,  ..., -2.6457e+00,\n",
            "          4.8008e+00, -3.6303e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3735, -2.3537,  2.1838,  ...,  2.6227, -0.9646,  2.6114],\n",
            "        [-3.0341, -3.2561,  3.0109,  ...,  0.5709,  0.9067, -1.5052],\n",
            "        [-3.0734, -2.6622,  3.4250,  ..., -4.2965,  2.2223, -2.2438],\n",
            "        ...,\n",
            "        [-0.2934, -4.0691,  4.7464,  ..., -1.9034,  3.0303, -0.0570],\n",
            "        [ 2.3013, -2.4678,  3.0353,  ...,  1.2784,  3.8397,  1.6055],\n",
            "        [-4.6587, -2.0106,  1.6060,  ..., -2.1601,  3.3388, -1.8156]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7882e+00, -1.0692e+00,  3.4261e+00,  ..., -9.6875e-01,\n",
            "         -2.0892e+00,  8.9699e-01],\n",
            "        [-5.6986e+00, -2.5490e+00,  2.0431e+00,  ...,  3.6683e-03,\n",
            "          4.8629e-01,  1.5028e+00],\n",
            "        [-2.2727e+00, -6.9797e-01,  6.6643e+00,  ...,  8.9189e-01,\n",
            "          9.4645e-02,  1.6525e+00],\n",
            "        ...,\n",
            "        [-7.4861e-01, -2.6121e+00, -1.7646e+00,  ..., -1.0148e-01,\n",
            "         -7.5806e-01,  2.4075e+00],\n",
            "        [ 3.9610e-01, -3.1671e+00,  3.4950e+00,  ...,  1.4833e+00,\n",
            "          6.1667e+00,  1.0020e+00],\n",
            "        [ 1.4288e+00, -1.4102e+00,  1.8279e+00,  ...,  1.5611e+00,\n",
            "         -8.6741e-02,  3.3650e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1380, -3.2908,  0.3483,  ...,  4.5312,  0.3748,  1.1434],\n",
            "        [ 0.1336, -1.5292,  0.5658,  ...,  1.1174, -0.7065,  3.2101],\n",
            "        [ 2.9169, -0.8591,  4.5184,  ...,  0.2062,  3.3034,  2.5089],\n",
            "        ...,\n",
            "        [ 0.4894, -1.6590,  2.2517,  ...,  3.4236, -2.1130,  4.1816],\n",
            "        [-1.0116, -2.4462,  2.3021,  ...,  1.0311, -0.6496, -0.8676],\n",
            "        [-2.5262, -2.9333,  2.1099,  ..., -0.1013,  5.7111, -2.4781]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6525, -1.0690,  1.2851,  ...,  2.7161, -1.3052,  4.2701],\n",
            "        [-2.8915, -4.2787, -2.2188,  ..., -3.7971,  3.5718, -0.0352],\n",
            "        [ 3.6481, -2.3649,  2.0354,  ...,  2.4981, -1.3753,  3.3874],\n",
            "        ...,\n",
            "        [ 1.9651, -4.4674,  4.5205,  ...,  0.1810,  4.2208,  2.2909],\n",
            "        [ 3.4098, -2.1736,  3.8457,  ...,  0.7745,  1.7575,  4.5163],\n",
            "        [-0.2063, -1.5706,  3.2450,  ...,  1.2907, -1.0614,  2.4563]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9091, -3.3050,  2.8481,  ..., -0.6462,  7.5036, -1.5005],\n",
            "        [-0.0890, -2.7937,  4.7549,  ...,  3.4260,  3.1008,  1.7119],\n",
            "        [-5.6167, -2.7550,  0.8262,  ...,  1.7439, -2.0406, -0.4012],\n",
            "        ...,\n",
            "        [ 1.7365, -4.5547,  0.1247,  ...,  1.4029,  6.6736,  0.1325],\n",
            "        [ 0.2454, -3.7726,  2.4207,  ...,  3.1315,  0.9468,  2.4745],\n",
            "        [ 1.2741, -2.1197,  4.8043,  ...,  1.7644,  2.8745,  1.8357]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2066, -5.1458,  4.1569,  ...,  2.1074,  2.2817,  1.4499],\n",
            "        [ 0.1619, -3.8634,  5.7637,  ...,  1.5777,  6.2572,  0.0941],\n",
            "        [ 3.1573, -3.9655,  0.6453,  ..., -0.0587,  2.9408,  5.0150],\n",
            "        ...,\n",
            "        [ 1.7257, -2.9021,  2.9198,  ...,  1.9111, -0.9349,  3.9166],\n",
            "        [-3.6249, -2.7656,  1.7795,  ...,  1.1534,  3.9069, -1.0418],\n",
            "        [ 2.9730, -3.8010,  4.8471,  ...,  1.5935,  2.2668,  2.6022]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9971, -2.7638, -0.6402,  ..., -0.5977,  3.4920, -0.5961],\n",
            "        [-2.8123, -3.4222, -2.5051,  ..., -0.9469,  2.4940, -1.2894],\n",
            "        [-4.7312, -2.1125,  1.5041,  ..., -0.5132,  4.7004, -1.1880],\n",
            "        ...,\n",
            "        [-4.2464, -2.7273, -0.3400,  ...,  0.1502,  2.0874,  2.8236],\n",
            "        [-1.2673, -3.1947,  0.6788,  ...,  1.6178, -2.6131,  1.2584],\n",
            "        [ 0.0690, -2.3468,  0.9568,  ...,  1.2258, -0.7397,  4.1032]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3637, -3.2673,  2.7285,  ...,  1.9644,  0.0658,  2.7099],\n",
            "        [ 0.6137, -1.6586,  4.8568,  ...,  0.0069, -0.3752,  1.9543],\n",
            "        [-4.0046, -3.4783,  1.1568,  ..., -1.0520, -2.6130,  2.1543],\n",
            "        ...,\n",
            "        [-5.2475, -5.6302, -2.9762,  ..., -0.2219,  0.4081, -2.2344],\n",
            "        [-2.9553, -4.1174,  0.9919,  ..., -5.4366,  5.4224,  0.3649],\n",
            "        [ 0.5298, -2.0862,  4.8668,  ...,  1.1505,  2.5130,  2.1843]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9553, -1.7112,  6.2403,  ...,  1.9357, -0.4464,  1.8986],\n",
            "        [ 0.5957, -3.1909, -1.2330,  ...,  1.8702,  5.9303,  1.8481],\n",
            "        [ 0.3717, -3.4545,  2.9206,  ...,  1.0212, -0.3114,  2.1768],\n",
            "        ...,\n",
            "        [ 0.7428, -3.0387,  3.3121,  ...,  2.3561,  0.9153,  1.5296],\n",
            "        [ 0.9202, -3.6394,  1.0685,  ...,  0.8182,  2.9392, -0.2770],\n",
            "        [-4.2242, -2.5910,  5.0659,  ...,  0.5871,  3.0075,  0.7157]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5033, -2.9822, -1.5346,  ...,  3.1664,  0.2264, -2.1126],\n",
            "        [ 2.9405, -1.9984,  2.9586,  ..., -0.9440,  0.2935,  3.1996],\n",
            "        [-3.0260, -4.2021,  4.5165,  ...,  0.0884,  0.8371, -0.5046],\n",
            "        ...,\n",
            "        [ 2.3454, -4.6011,  5.2486,  ...,  2.4180,  2.2737,  2.0475],\n",
            "        [-3.1039, -3.1916,  2.5683,  ...,  0.5806, -1.8306,  0.7808],\n",
            "        [-0.5604, -1.8248,  2.2313,  ...,  1.9516,  6.5031, -0.0327]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7094, -2.9678,  1.0035,  ...,  1.6356, -1.7369,  0.7204],\n",
            "        [ 0.7859, -1.5814,  7.5254,  ...,  2.3411,  0.3023,  1.1825],\n",
            "        [ 0.5103, -3.3078, -0.2065,  ..., -4.0053,  3.6997,  1.4599],\n",
            "        ...,\n",
            "        [ 0.6004, -2.5657,  4.2674,  ...,  3.9392, -0.0236,  4.2433],\n",
            "        [-1.2074, -2.2204,  0.6325,  ...,  3.9115,  4.3968, -1.7184],\n",
            "        [ 1.7923, -2.6667,  4.3465,  ..., -0.3148,  0.7002,  2.9902]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8190, -2.3081,  2.4189,  ...,  1.8682,  3.1119,  1.6729],\n",
            "        [ 2.0708, -3.1121,  5.7614,  ...,  1.5303,  0.1659,  2.6948],\n",
            "        [-0.9095, -4.2301,  5.3455,  ..., -1.4698,  3.0647, -0.2579],\n",
            "        ...,\n",
            "        [ 1.5821, -4.0077,  4.0773,  ...,  1.8667,  1.5421,  1.6235],\n",
            "        [ 2.6670, -4.3458,  7.0554,  ...,  1.1727,  1.5325,  2.6908],\n",
            "        [-0.2766, -2.3930,  3.6054,  ...,  0.9381,  1.3534,  0.8869]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3121e-01, -1.5009e+00,  6.6606e+00,  ...,  5.9902e-01,\n",
            "          1.8878e+00, -4.7409e-01],\n",
            "        [ 1.1906e+00, -1.5763e+00,  5.3815e+00,  ...,  3.0941e+00,\n",
            "         -2.1837e-03,  3.3313e+00],\n",
            "        [-5.6797e-01, -2.1897e+00,  1.7832e+00,  ...,  2.4455e+00,\n",
            "         -1.5468e+00,  4.1703e+00],\n",
            "        ...,\n",
            "        [ 1.6577e+00, -3.6150e+00,  3.8280e+00,  ...,  1.6932e+00,\n",
            "          1.7331e+00,  1.7807e+00],\n",
            "        [ 5.7321e-02, -1.8524e+00,  1.2221e+00,  ..., -7.1026e-01,\n",
            "          5.0555e+00,  1.0746e+00],\n",
            "        [-4.0718e+00, -2.9496e+00,  2.5607e-01,  ..., -6.5524e-01,\n",
            "          6.9602e-01,  5.1471e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6089, -4.5320,  4.1008,  ...,  3.4141, -0.8570,  0.9224],\n",
            "        [-3.4285, -3.9837,  1.0069,  ...,  4.6983,  8.3234, -3.2008],\n",
            "        [-3.0853, -3.7011,  3.0060,  ..., -2.2576,  1.8166,  0.5544],\n",
            "        ...,\n",
            "        [ 1.9050, -1.7310,  3.5834,  ...,  2.8700, -0.3658,  3.4811],\n",
            "        [-3.6830, -3.3291, -1.5466,  ..., -1.9858,  6.8196, -0.7215],\n",
            "        [-0.0339, -1.9605,  2.3369,  ...,  1.6895,  2.9473,  0.4190]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1700, -3.1656,  0.8115,  ...,  2.7222,  0.8973,  2.5214],\n",
            "        [ 1.3874, -4.1755,  5.1681,  ...,  1.5259,  1.8756,  1.9048],\n",
            "        [ 2.1553, -2.7849,  4.2149,  ..., -0.1536,  0.5995,  3.6760],\n",
            "        ...,\n",
            "        [ 0.0792, -1.3849,  4.5480,  ...,  2.0950,  1.3367,  1.7576],\n",
            "        [-0.2405, -4.1531,  3.0863,  ...,  0.0851,  0.1561,  0.2951],\n",
            "        [-2.4660, -5.3755,  3.3816,  ...,  2.4254,  5.9535, -0.3577]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4966, -3.9696, -0.6164,  ...,  3.1274, -2.7675, -2.7239],\n",
            "        [-2.7773, -2.2285,  5.8852,  ...,  0.5458,  4.8396,  1.5610],\n",
            "        [ 0.8737, -5.1186,  4.9173,  ...,  0.5716, -0.4220,  1.4082],\n",
            "        ...,\n",
            "        [ 0.3622, -1.9622,  3.2728,  ...,  1.7943,  3.0355,  1.0304],\n",
            "        [ 2.5356, -3.3180,  1.1948,  ...,  2.6065, -0.7489,  3.2729],\n",
            "        [ 2.8864, -2.1856,  4.9507,  ...,  0.5733,  1.5566,  3.8013]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9586, -4.6998,  2.5596,  ...,  2.4679,  0.2041,  3.7372],\n",
            "        [ 0.3526, -1.3800,  1.0487,  ...,  2.9932,  0.3537,  2.8090],\n",
            "        [ 1.5803, -1.1994,  5.0822,  ...,  0.5082,  3.7633,  3.1673],\n",
            "        ...,\n",
            "        [-3.3043, -2.9546,  2.5942,  ..., -1.6487,  0.7362, -1.0859],\n",
            "        [-2.1175, -4.5107, -1.0201,  ...,  3.6746,  0.1040,  0.5690],\n",
            "        [-1.1291, -0.9702,  0.5524,  ...,  2.1002, -1.2081,  1.9146]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1019, -3.4991,  4.4878,  ...,  4.8554,  4.0529, -0.4701],\n",
            "        [-2.0137, -3.6803,  2.3360,  ..., -2.4198,  6.2216, -0.4653],\n",
            "        [-1.1955, -2.0785,  3.3557,  ...,  2.4226, -1.6935,  4.8757],\n",
            "        ...,\n",
            "        [-1.0174, -1.9437,  3.6317,  ...,  0.4996, -0.8783,  1.0152],\n",
            "        [ 0.7602, -3.5219,  2.4164,  ...,  3.2646,  4.8412, -0.8472],\n",
            "        [-4.6195, -6.2736,  1.3932,  ...,  3.5671,  2.8826, -4.2157]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8425, -2.7488,  2.9587,  ..., -1.0136,  1.1229,  3.4075],\n",
            "        [ 0.7605, -0.7034,  2.1695,  ...,  4.3735, -1.5531,  1.2901],\n",
            "        [-1.2260, -1.2958,  1.5830,  ...,  1.4740, -0.1986,  3.9255],\n",
            "        ...,\n",
            "        [-4.1216, -3.5655,  1.8026,  ...,  0.2770,  6.7430, -2.5515],\n",
            "        [-1.5043, -3.9804,  1.4645,  ...,  1.1106,  1.2738, -1.3770],\n",
            "        [-3.3456, -2.2952, -1.9623,  ...,  0.5774,  1.9731, -1.7388]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3788, -2.3146,  4.9199,  ..., -0.6175,  1.6071,  0.3906],\n",
            "        [-1.1532, -2.5926,  3.0356,  ..., -0.7588,  1.1016,  1.5858],\n",
            "        [-2.7491, -1.8371,  1.3046,  ...,  0.0912, -1.8701,  1.3662],\n",
            "        ...,\n",
            "        [ 2.0815, -2.0796,  7.2493,  ...,  2.9343,  0.5556,  2.8763],\n",
            "        [ 1.7699, -4.1859,  0.8663,  ...,  4.5320,  2.8703,  0.2147],\n",
            "        [ 0.6385, -3.3132,  5.8381,  ...,  0.2618,  3.2483,  2.0047]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0581, -1.7156, -0.5048,  ..., -1.9644,  4.8183, -0.0759],\n",
            "        [-2.4985, -5.4027, -0.1163,  ...,  3.0500,  6.7930, -2.2136],\n",
            "        [ 1.2478, -3.2977,  3.3237,  ...,  2.1280,  2.7328,  2.6990],\n",
            "        ...,\n",
            "        [-0.5693, -0.7897,  3.9150,  ...,  0.5696,  0.9645,  3.1596],\n",
            "        [-2.5378, -2.4390,  1.9683,  ..., -0.0255,  0.6439,  0.4773],\n",
            "        [-2.7279, -2.4411,  5.2060,  ..., -0.5457,  1.7317, -0.7160]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1146, -4.8869, -0.6532,  ...,  2.9050,  2.1169, -0.1945],\n",
            "        [ 2.3941, -1.4417,  4.0687,  ...,  1.9195,  1.1722,  3.2885],\n",
            "        [-3.4286, -4.0846, -0.8468,  ..., -0.7922,  6.2164, -2.7622],\n",
            "        ...,\n",
            "        [-0.7998, -2.7387,  1.3197,  ..., -0.1261,  1.4477,  0.8334],\n",
            "        [-2.6835, -2.6193,  2.5472,  ...,  0.2662,  2.1851, -1.6231],\n",
            "        [ 1.2688, -1.7773,  5.2377,  ...,  0.6497, -0.6624,  1.9706]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4842, -4.2730, -0.8258,  ...,  1.3472, -0.0403, -0.4697],\n",
            "        [-3.0476, -1.8687, -3.5843,  ..., -2.8266,  1.5716,  1.2347],\n",
            "        [ 1.9497, -2.5327,  4.2185,  ...,  1.3176,  1.0170,  0.5247],\n",
            "        ...,\n",
            "        [ 3.1992, -3.2987,  3.3999,  ...,  2.5483,  2.2908,  2.1725],\n",
            "        [-1.8495, -5.3797,  6.1014,  ...,  1.1915,  5.6295, -1.1080],\n",
            "        [ 0.5244, -3.8794,  4.3083,  ...,  2.1265,  0.4293,  0.8527]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4097, -2.9501,  1.9341,  ...,  1.9377,  2.4126,  1.3211],\n",
            "        [ 0.4805, -3.3391,  2.6437,  ..., -0.3358,  0.7967,  1.8068],\n",
            "        [ 4.3970, -4.7681,  0.0928,  ...,  3.1516, -0.2287,  4.2262],\n",
            "        ...,\n",
            "        [ 1.3908, -2.9766,  0.0940,  ...,  0.1132,  3.4447,  2.7890],\n",
            "        [ 0.1623, -1.9774,  0.3689,  ...,  1.2495, -0.1160,  1.4037],\n",
            "        [-1.3930, -2.9856,  3.7708,  ..., -0.7077,  1.2217,  0.8687]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9062, -0.7854,  1.6866,  ..., -2.3421, -0.0888, -0.0438],\n",
            "        [-0.2071, -3.7983,  2.8761,  ...,  1.0827, -0.8179,  0.0324],\n",
            "        [-0.4981, -2.4746,  1.2944,  ...,  1.1576, -0.2566,  2.8876],\n",
            "        ...,\n",
            "        [ 0.0685, -2.3087,  5.5927,  ...,  0.7897,  0.1294,  1.6266],\n",
            "        [-1.4256, -2.0470,  5.2697,  ...,  0.6040, -0.7816,  1.3472],\n",
            "        [-1.9063, -3.3075,  2.4562,  ...,  1.5320,  0.6845, -0.1292]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6771, -5.0004,  2.7540,  ..., -3.5980,  4.4591, -0.8789],\n",
            "        [-3.0217, -4.3753,  3.4943,  ...,  1.1880, -0.6802,  0.1871],\n",
            "        [-3.8687, -5.3692,  3.9570,  ..., -3.4767,  1.1587, -1.3627],\n",
            "        ...,\n",
            "        [-0.7072, -1.2002,  1.0567,  ...,  1.8500, -1.4762,  4.1791],\n",
            "        [-1.5684, -3.2543,  1.7767,  ...,  2.7339,  5.3392, -0.2038],\n",
            "        [ 0.1708, -3.5136,  5.1576,  ..., -0.1909,  2.7246,  2.1509]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0299, -2.0030,  1.3623,  ...,  1.6115, -1.3788,  4.5191],\n",
            "        [ 0.4973, -3.5484,  1.7227,  ...,  1.0557,  4.0827,  0.8346],\n",
            "        [ 3.2642, -5.5843,  1.0786,  ...,  2.5224,  2.2086,  2.3152],\n",
            "        ...,\n",
            "        [-2.8327, -1.6197,  2.0886,  ..., -0.4781,  2.6043, -0.2880],\n",
            "        [-0.8081, -2.7746,  3.3292,  ..., -0.1862, -0.9154,  1.1169],\n",
            "        [ 1.7910, -3.2659,  2.9246,  ...,  3.1785,  4.7555, -0.4240]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3236, -2.1792,  3.2237,  ...,  0.8209, -1.1311,  1.1267],\n",
            "        [ 0.4956, -3.5142,  3.2555,  ...,  3.7849, -0.4425,  2.7649],\n",
            "        [-3.9832, -3.8633,  2.2913,  ...,  0.1109,  7.4568, -3.4352],\n",
            "        ...,\n",
            "        [-0.2971, -3.6586,  3.7330,  ...,  1.5187,  1.7956,  0.0748],\n",
            "        [-0.2411, -4.4014,  3.7520,  ...,  0.5699,  0.5517,  0.9004],\n",
            "        [-3.0320, -3.6529,  3.8953,  ...,  0.0135,  1.5830,  0.3587]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0209, -3.3379,  1.1170,  ...,  0.3557, -1.1121, -1.4248],\n",
            "        [ 1.8466, -3.5110,  5.2714,  ...,  1.8660,  0.8435,  1.9962],\n",
            "        [-1.5175, -2.9278, -0.4123,  ...,  2.3848,  6.0970,  0.9210],\n",
            "        ...,\n",
            "        [-5.9780, -2.2633,  0.6900,  ..., -1.8103,  4.8670, -0.5794],\n",
            "        [ 0.3715, -1.3655,  0.2287,  ...,  2.7935,  0.7775, -0.6440],\n",
            "        [-1.6292, -2.8677,  4.5320,  ..., -1.0562,  1.7357, -0.4524]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1808, -1.6993,  0.9861,  ...,  1.6864, -1.1452,  4.0621],\n",
            "        [-2.5280, -2.1091, -1.4486,  ...,  3.4852, -3.3750,  0.5124],\n",
            "        [-2.7243, -3.5683,  2.7722,  ..., -0.4017,  2.9220,  0.0804],\n",
            "        ...,\n",
            "        [-4.8019, -4.5385, -1.3313,  ...,  2.3406,  7.6554, -2.2596],\n",
            "        [ 1.8795, -2.5569,  1.7549,  ...,  1.5114,  0.0913,  1.8988],\n",
            "        [-1.7218, -0.9654,  0.5828,  ...,  3.2504,  5.5891, -2.4371]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8976, -1.0502,  2.0660,  ...,  1.6986,  0.2513,  3.9050],\n",
            "        [ 1.6757, -2.5492,  3.4496,  ...,  1.3865,  2.0476,  2.7303],\n",
            "        [-3.9836, -4.3036,  3.6412,  ...,  1.0586,  2.1783, -0.9270],\n",
            "        ...,\n",
            "        [ 0.6780, -3.1331,  4.0289,  ..., -0.1561,  3.4635,  3.2126],\n",
            "        [-1.1118, -0.6342,  1.2976,  ...,  2.5780, -0.7980,  4.3351],\n",
            "        [-2.1817, -4.8647,  3.0590,  ..., -2.8659,  5.9773, -1.1744]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0326, -1.0631,  3.7145,  ...,  4.1301,  2.1323,  1.5519],\n",
            "        [-5.3991, -2.3517, -0.2375,  ..., -1.9614,  7.6828, -3.8434],\n",
            "        [-0.5426, -2.2777,  3.3773,  ...,  2.1122, -0.1031,  4.5362],\n",
            "        ...,\n",
            "        [-4.4659, -3.5672, -1.7197,  ..., -0.6798,  7.5126, -1.6378],\n",
            "        [-1.0619, -1.6119,  1.1899,  ...,  2.4819, -1.2776,  4.2782],\n",
            "        [-2.5353, -4.7531,  1.5086,  ...,  4.9789,  4.9600, -1.5683]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1903, -3.3034,  6.1301,  ...,  0.7974,  4.0413,  0.8546],\n",
            "        [-0.8934, -4.6167,  5.5850,  ..., -0.1113,  2.5463, -0.0758],\n",
            "        [-0.8843, -2.4814,  3.1905,  ...,  1.1096,  4.0206, -1.0311],\n",
            "        ...,\n",
            "        [ 1.0488, -2.9953,  4.8855,  ...,  1.5320,  1.4781,  1.1553],\n",
            "        [-1.4796, -4.0865,  1.7521,  ...,  0.6209,  8.4909, -2.5625],\n",
            "        [ 0.8131, -3.4401,  3.8732,  ...,  1.8990,  0.7846,  0.9606]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1218, -1.3820,  2.2978,  ...,  1.1754,  0.2019,  3.3723],\n",
            "        [-3.9583, -2.6151,  3.3118,  ...,  0.4176,  2.9771, -0.3155],\n",
            "        [ 0.9536, -4.3081,  2.8178,  ...,  3.7242,  3.1045,  3.6874],\n",
            "        ...,\n",
            "        [-0.1063, -1.1598,  6.2708,  ...,  1.1286, -0.2110,  1.8073],\n",
            "        [-0.9839, -2.0292,  2.6493,  ...,  0.1356,  1.7716,  1.0092],\n",
            "        [ 0.1858, -1.5029,  3.3982,  ...,  2.3816,  1.1703,  2.4051]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1712, -4.0597,  2.3573,  ..., -0.2422,  6.2413, -2.5564],\n",
            "        [-3.2373, -3.0322,  2.7891,  ...,  0.0106,  7.7050, -2.5145],\n",
            "        [-0.2248, -4.5272,  4.7587,  ...,  1.4803,  3.7144,  1.1490],\n",
            "        ...,\n",
            "        [-2.9887, -4.5361,  0.4598,  ...,  5.7369,  0.0229,  0.3943],\n",
            "        [ 1.2378, -2.1464,  4.2512,  ...,  2.4174, -0.5896,  2.8742],\n",
            "        [ 0.1741, -2.5733,  0.5844,  ...,  1.4757, -0.4368,  4.0427]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8177e+00, -3.7565e+00, -1.0834e+00,  ...,  2.1003e+00,\n",
            "         -2.4080e+00, -1.9276e-01],\n",
            "        [-1.0317e-01, -1.1535e+00,  1.0371e+00,  ...,  1.0530e+00,\n",
            "          2.7260e+00,  5.7277e-01],\n",
            "        [ 2.3267e+00, -5.3952e+00,  3.2766e+00,  ...,  1.9868e+00,\n",
            "          8.7307e+00,  8.4787e-01],\n",
            "        ...,\n",
            "        [ 5.2321e-03,  1.6552e-01,  4.2277e+00,  ...,  1.8596e+00,\n",
            "          1.7146e+00,  3.9063e+00],\n",
            "        [-2.6410e+00, -3.2126e+00,  2.1035e+00,  ...,  5.9716e-01,\n",
            "          8.5639e-01,  9.0054e-01],\n",
            "        [-3.0281e+00, -4.5513e+00,  1.0473e+00,  ..., -3.1837e+00,\n",
            "          3.3219e+00,  7.6511e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7341, -1.9105,  4.8566,  ...,  3.2871,  0.4200,  1.7352],\n",
            "        [-2.3169, -3.6121,  1.3620,  ...,  1.7920, -1.9607, -0.5342],\n",
            "        [ 2.6102, -6.3410, -1.6462,  ...,  3.5620,  5.8658,  0.3013],\n",
            "        ...,\n",
            "        [-0.7314, -1.1727,  1.0920,  ...,  3.5183, -0.1999,  3.2042],\n",
            "        [-0.5125, -2.0058,  4.1203,  ..., -2.1588,  4.8702,  0.2392],\n",
            "        [-0.3446, -4.7554,  2.0297,  ..., -1.1932,  5.4594, -0.4376]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1515e+00, -2.2899e+00, -2.2235e+00,  ..., -1.1496e+00,\n",
            "          1.9669e+00,  1.1242e+00],\n",
            "        [ 2.0770e+00, -3.0753e+00,  2.9232e+00,  ...,  1.0693e+00,\n",
            "          4.1639e+00, -4.5433e-01],\n",
            "        [ 1.0036e+00, -6.5364e+00,  1.5124e+00,  ...,  2.9451e+00,\n",
            "          9.8322e-01,  2.3486e+00],\n",
            "        ...,\n",
            "        [-2.3613e-02, -2.9599e+00,  4.4233e+00,  ...,  1.8451e+00,\n",
            "          1.1932e+00,  2.3876e+00],\n",
            "        [-5.7728e-01, -4.3519e-01,  7.0251e+00,  ...,  1.2998e+00,\n",
            "          4.6546e-01,  3.9504e-01],\n",
            "        [-5.9662e-01, -2.4662e+00,  2.1079e+00,  ...,  2.8028e+00,\n",
            "          6.1979e+00,  6.4589e-03]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4219, -4.3241,  3.9478,  ...,  1.7587,  1.2050,  1.4353],\n",
            "        [ 1.1038, -2.0207,  3.0199,  ...,  4.2910, -2.3858,  3.8268],\n",
            "        [ 2.6980, -5.5742,  2.0786,  ...,  6.8912,  3.0152,  0.8004],\n",
            "        ...,\n",
            "        [ 0.7046, -2.4454,  4.0940,  ..., -1.8318,  0.7798,  1.4980],\n",
            "        [ 2.1836, -2.3457,  3.4599,  ...,  3.5961, -1.1546,  3.7043],\n",
            "        [ 0.0452, -1.8142, -0.1957,  ...,  1.7917,  0.7792,  2.1591]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1840, -3.6463,  3.7553,  ...,  0.2367,  0.3331,  2.2774],\n",
            "        [-0.0141, -4.2561,  2.3028,  ...,  0.5603,  7.0660, -2.5761],\n",
            "        [ 0.7882, -2.6584, -0.0085,  ...,  0.5940,  5.7919,  0.6624],\n",
            "        ...,\n",
            "        [ 3.2752, -3.9489,  3.1369,  ...,  1.9472,  5.8714,  0.2722],\n",
            "        [-1.6357, -4.1427,  1.9533,  ...,  1.2050, -1.7315, -0.1880],\n",
            "        [-0.0695, -1.9219,  3.2095,  ...,  2.5485,  2.6555,  0.7001]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1226, -2.4222,  5.6207,  ...,  1.7202,  6.4851,  2.6081],\n",
            "        [-0.7954, -5.4931, -0.0218,  ...,  2.3855,  5.0077,  0.1000],\n",
            "        [-0.4389, -1.9907,  4.1443,  ...,  0.8614, -0.5855,  0.9173],\n",
            "        ...,\n",
            "        [-4.2774, -3.4520,  6.2866,  ..., -0.6643,  4.4614,  1.6752],\n",
            "        [-0.5656, -0.6386,  0.5592,  ..., -1.1032,  4.3688,  1.0351],\n",
            "        [-2.6428, -3.3152,  0.6001,  ...,  1.2519,  2.2015,  0.6251]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0652e+00, -1.7624e+00,  2.2252e+00,  ..., -1.8785e+00,\n",
            "          7.6723e+00, -4.8681e-03],\n",
            "        [-1.1303e+00, -1.6668e+00,  6.6120e+00,  ...,  5.9239e-01,\n",
            "          6.0739e-01,  1.7257e+00],\n",
            "        [-2.9885e+00, -4.2385e+00,  1.6449e+00,  ...,  1.2781e+00,\n",
            "          6.1657e+00, -2.8624e+00],\n",
            "        ...,\n",
            "        [-1.9679e-01, -4.2383e+00,  3.0757e+00,  ...,  1.8288e+00,\n",
            "         -1.8889e+00,  1.2926e+00],\n",
            "        [-5.5998e-01, -3.8926e+00,  2.6824e+00,  ...,  6.9681e-01,\n",
            "          5.1723e+00, -7.1775e-01],\n",
            "        [-3.8886e-01, -5.0181e-01,  1.7913e+00,  ..., -2.2634e+00,\n",
            "          5.0851e+00,  3.8200e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2295, -2.3372,  1.0503,  ...,  1.4879, -1.9848,  3.8473],\n",
            "        [-0.7252, -0.9129,  5.6999,  ..., -2.3720, -0.5673,  1.4677],\n",
            "        [-1.4218, -3.1465,  0.1261,  ..., -0.5510,  3.7345, -1.2018],\n",
            "        ...,\n",
            "        [-1.3062, -2.9022,  4.9357,  ...,  1.7305,  1.1253,  2.2325],\n",
            "        [-1.0598, -0.9266,  0.2263,  ...,  2.0358,  1.3083,  2.4703],\n",
            "        [ 1.0374, -1.0107,  3.0396,  ...,  3.7516, -0.0781,  3.4745]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = SimpleMLP().to(device)\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 3\n",
        "\n",
        "mnist_trainset, _ = get_mnist()\n",
        "mnist_trainloader = DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "optimizer = t.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    pbar = tqdm(mnist_trainloader)\n",
        "\n",
        "    for imgs, labels in pbar:\n",
        "        # Move data to device, perform forward pass\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        logits = model(imgs)\n",
        "\n",
        "        # Calculate loss, perform backward pass\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Update logs & progress bar\n",
        "        loss_list.append(loss.item())\n",
        "        pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VkiH-f3sjBUO",
        "outputId": "f8c0a287-2f72-402f-d777-a605f152c042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"987f8a97-d7ff-4427-b42d-53adf7f311d0\" class=\"plotly-graph-div\" style=\"height:525px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"987f8a97-d7ff-4427-b42d-53adf7f311d0\")) {                    Plotly.newPlot(                        \"987f8a97-d7ff-4427-b42d-53adf7f311d0\",                        [{\"hovertemplate\":\"Examples seen=%{x}\\u003cbr\\u003eCross entropy loss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,127.11864406779661,254.23728813559322,381.35593220338984,508.47457627118644,635.5932203389831,762.7118644067797,889.8305084745763,1016.9491525423729,1144.0677966101696,1271.1864406779662,1398.3050847457628,1525.4237288135594,1652.542372881356,1779.6610169491526,1906.7796610169491,2033.8983050847457,2161.0169491525426,2288.135593220339,2415.2542372881358,2542.3728813559323,2669.491525423729,2796.6101694915255,2923.728813559322,3050.8474576271187,3177.9661016949153,3305.084745762712,3432.2033898305085,3559.322033898305,3686.4406779661017,3813.5593220338983,3940.677966101695,4067.7966101694915,4194.9152542372885,4322.033898305085,4449.152542372882,4576.271186440678,4703.389830508475,4830.5084745762715,4957.627118644068,5084.745762711865,5211.864406779661,5338.983050847458,5466.1016949152545,5593.220338983051,5720.338983050848,5847.457627118644,5974.576271186441,6101.6949152542375,6228.813559322034,6355.932203389831,6483.050847457627,6610.169491525424,6737.28813559322,6864.406779661017,6991.525423728814,7118.64406779661,7245.762711864407,7372.881355932203,7500.0,7627.118644067797,7754.237288135593,7881.35593220339,8008.474576271186,8135.593220338983,8262.71186440678,8389.830508474577,8516.949152542373,8644.06779661017,8771.186440677966,8898.305084745763,9025.42372881356,9152.542372881357,9279.661016949152,9406.77966101695,9533.898305084746,9661.016949152543,9788.135593220339,9915.254237288136,10042.372881355932,10169.49152542373,10296.610169491525,10423.728813559323,10550.847457627118,10677.966101694916,10805.084745762711,10932.203389830509,11059.322033898305,11186.440677966102,11313.559322033898,11440.677966101695,11567.796610169491,11694.915254237289,11822.033898305084,11949.152542372882,12076.271186440677,12203.389830508475,12330.50847457627,12457.627118644068,12584.745762711864,12711.864406779661,12838.983050847457,12966.101694915254,13093.22033898305,13220.338983050848,13347.457627118643,13474.57627118644,13601.694915254237,13728.813559322034,13855.93220338983,13983.050847457627,14110.169491525423,14237.28813559322,14364.406779661016,14491.525423728814,14618.64406779661,14745.762711864407,14872.881355932202,15000.0,15127.118644067796,15254.237288135593,15381.355932203389,15508.474576271186,15635.593220338982,15762.71186440678,15889.830508474575,16016.949152542373,16144.067796610168,16271.186440677966,16398.305084745763,16525.42372881356,16652.542372881355,16779.661016949154,16906.77966101695,17033.898305084746,17161.01694915254,17288.13559322034,17415.254237288136,17542.372881355932,17669.491525423728,17796.610169491527,17923.728813559323,18050.84745762712,18177.966101694914,18305.084745762713,18432.20338983051,18559.322033898305,18686.4406779661,18813.5593220339,18940.677966101695,19067.79661016949,19194.915254237287,19322.033898305086,19449.15254237288,19576.271186440677,19703.389830508473,19830.508474576272,19957.627118644068,20084.745762711864,20211.86440677966,20338.98305084746,20466.101694915254,20593.22033898305,20720.338983050846,20847.457627118645,20974.57627118644,21101.694915254237,21228.813559322032,21355.93220338983,21483.050847457627,21610.169491525423,21737.28813559322,21864.406779661018,21991.525423728814,22118.64406779661,22245.762711864405,22372.881355932204,22500.0,22627.118644067796,22754.23728813559,22881.35593220339,23008.474576271186,23135.593220338982,23262.711864406778,23389.830508474577,23516.949152542373,23644.06779661017,23771.186440677964,23898.305084745763,24025.42372881356,24152.542372881355,24279.66101694915,24406.77966101695,24533.898305084746,24661.01694915254,24788.13559322034,24915.254237288136,25042.372881355932,25169.491525423728,25296.610169491527,25423.728813559323,25550.84745762712,25677.966101694914,25805.084745762713,25932.20338983051,26059.322033898305,26186.4406779661,26313.5593220339,26440.677966101695,26567.79661016949,26694.915254237287,26822.033898305086,26949.15254237288,27076.271186440677,27203.389830508473,27330.508474576272,27457.627118644068,27584.745762711864,27711.86440677966,27838.98305084746,27966.101694915254,28093.22033898305,28220.338983050846,28347.457627118645,28474.57627118644,28601.694915254237,28728.813559322032,28855.93220338983,28983.050847457627,29110.169491525423,29237.28813559322,29364.406779661018,29491.525423728814,29618.64406779661,29745.762711864405,29872.881355932204,30000.0],\"xaxis\":\"x\",\"y\":[2.8326265811920166,2.4012935161590576,2.1258721351623535,1.660960078239441,1.6117767095565796,1.5242118835449219,1.3711820840835571,1.1749309301376343,1.187349557876587,0.8683536052703857,0.9111106395721436,0.8138159513473511,0.8741384744644165,0.8202672004699707,0.8750988245010376,0.8953312635421753,0.647588312625885,0.7021141648292542,0.6507764458656311,0.5910298824310303,0.5463025569915771,0.5643222332000732,0.5544955730438232,0.4703066051006317,0.532025158405304,0.3746141791343689,0.4426923990249634,0.44626912474632263,0.4682457745075226,0.5274903774261475,0.43137016892433167,0.5281543135643005,0.36402755975723267,0.42034319043159485,0.48561838269233704,0.4719076156616211,0.4126090705394745,0.451036661863327,0.482403427362442,0.39092543721199036,0.4199061095714569,0.5034308433532715,0.4238894283771515,0.45600590109825134,0.4602183401584625,0.33607032895088196,0.28926777839660645,0.4416835308074951,0.2864131033420563,0.39006268978118896,0.6547856330871582,0.31289076805114746,0.3191209137439728,0.39390939474105835,0.3257817029953003,0.4364500641822815,0.5173946022987366,0.37899306416511536,0.34241968393325806,0.4734063148498535,0.26734182238578796,0.39078158140182495,0.29186269640922546,0.28908485174179077,0.2668418288230896,0.29269564151763916,0.282118022441864,0.36128872632980347,0.3789771497249603,0.3371834456920624,0.4188074767589569,0.3121647834777832,0.29653453826904297,0.3318667411804199,0.2748241722583771,0.2899101972579956,0.2269827425479889,0.2485123723745346,0.639600932598114,0.17185547947883606,0.25489485263824463,0.36854955554008484,0.22252468764781952,0.2905934154987335,0.20827937126159668,0.24801978468894958,0.29178711771965027,0.16753976047039032,0.27432164549827576,0.23127494752407074,0.15753231942653656,0.22578126192092896,0.3180360794067383,0.36133328080177307,0.2577466070652008,0.41900399327278137,0.2749243974685669,0.2963237464427948,0.29381096363067627,0.3559224307537079,0.31224679946899414,0.20291867852210999,0.2600798010826111,0.4133424162864685,0.33229321241378784,0.13218742609024048,0.2409025877714157,0.21610954403877258,0.4115832448005676,0.23642468452453613,0.24924929440021515,0.23082445561885834,0.2416491061449051,0.2753066122531891,0.24522356688976288,0.27862128615379333,0.1551642268896103,0.17443686723709106,0.3909909725189209,0.1947798877954483,0.3054148852825165,0.18759982287883759,0.23774681985378265,0.2556250989437103,0.1626920849084854,0.17989885807037354,0.3498494029045105,0.17176534235477448,0.21522122621536255,0.18282745778560638,0.2482791244983673,0.2873229682445526,0.23690097033977509,0.28795668482780457,0.36282259225845337,0.1353001743555069,0.15829376876354218,0.19421207904815674,0.30826494097709656,0.30454227328300476,0.23078107833862305,0.2879248559474945,0.31858840584754944,0.2638382613658905,0.29413554072380066,0.3152170777320862,0.30300840735435486,0.2023339569568634,0.2370322197675705,0.23019656538963318,0.29096877574920654,0.30312854051589966,0.18455719947814941,0.27146220207214355,0.2338482290506363,0.3662743866443634,0.24956555664539337,0.3174123466014862,0.2555508613586426,0.22591494023799896,0.23323100805282593,0.1316319704055786,0.15528690814971924,0.19904227554798126,0.4044736921787262,0.23296019434928894,0.19328249990940094,0.18720360100269318,0.27190375328063965,0.16723307967185974,0.10363809764385223,0.2990473508834839,0.1620030552148819,0.21337199211120605,0.18607351183891296,0.23324160277843475,0.2900930345058441,0.38433805108070374,0.2812991738319397,0.1431012600660324,0.18580584228038788,0.13799519836902618,0.2784707844257355,0.21685117483139038,0.20332790911197662,0.18945005536079407,0.21497468650341034,0.2138577550649643,0.199082151055336,0.19476968050003052,0.2436399906873703,0.2793343961238861,0.18697166442871094,0.11370757967233658,0.13496005535125732,0.2837495505809784,0.16641411185264587,0.206533282995224,0.196046382188797,0.12899456918239594,0.15318095684051514,0.15193939208984375,0.2711262106895447,0.19956745207309723,0.1518402397632599,0.22381456196308136,0.09479796886444092,0.12433088570833206,0.22635042667388916,0.1729205697774887,0.11816613376140594,0.23003911972045898,0.1043577492237091,0.11675646156072617,0.19949418306350708,0.1552954763174057,0.15638476610183716,0.17404574155807495,0.0859595462679863,0.1934211552143097,0.1324465125799179,0.1828075796365738,0.16611312329769135,0.15426315367221832,0.14184008538722992,0.24242758750915527,0.22914551198482513,0.16796845197677612,0.23119808733463287,0.23345696926116943,0.14047589898109436,0.24448490142822266,0.1840919554233551,0.13901054859161377,0.22875770926475525,0.17061708867549896,0.3777654767036438],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Examples seen\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Cross entropy loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"SimpleMLP training on MNIST\"},\"width\":700,\"hovermode\":\"x unified\"},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('987f8a97-d7ff-4427-b42d-53adf7f311d0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "line(\n",
        "    loss_list,\n",
        "    x_max=epochs * len(mnist_trainset),\n",
        "    labels={\"x\": \"Examples seen\", \"y\": \"Cross entropy loss\"},\n",
        "    title=\"SimpleMLP training on MNIST\",\n",
        "    width=700,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViY0EL5jjBUO"
      },
      "source": [
        "Let's break down the important parts of this code.\n",
        "\n",
        "The batch size is the number of samples in each batch (i.e. the number of samples we feed into the model at once). While training our model, we differentiate with respect to the average loss over all samples in the batch (so a smaller batch usually means the loss is more noisy). However, if you're working with large models, then often having a batch size too large will result in a memory error. This will be relevant for models later on in the course, but for now we're working with very small models so this isn't an issue.\n",
        "\n",
        "Next, we get our training set, via the helper function `get_mnist`. This helper function used `torchvision.datasets.MNIST` to load in data, and then (optionally) the `torch.utils.data.Subset` function to return a subset of this data. Don't worry about the details of this function, it's not the kind of thing you'll need to know by heart.\n",
        "\n",
        "We then define our optimizer, using `torch.optim.Adam`. The `torch.optim` module gives a wide variety of modules, such as Adam, SGD, and RMSProp. Adam is generally the most popular and seen as the most effective in the majority of cases. We'll discuss optimizers in more detail tomorrow, but for now it's enough to understand that the optimizer calculates the amount to update parameters by (as a function of those parameters' gradients, and sometimes other inputs), and performs this update step. The first argument passed to our optimizer is the parameters of our model (because these are the values that will be updated via gradient descent), and you can also pass keyword arguments to the optimizer which change its behaviour (e.g. the learning rate).\n",
        "\n",
        "Lastly, we have the actual training loop. We iterate through our training data, and for each batch we:\n",
        "\n",
        "1. Evaluate our model on the batch of data, to get the logits for our class predictions,\n",
        "2. Calculate the loss between our logits and the true class labels,\n",
        "3. Backpropagate the loss through our model (this step accumulates gradients in our model parameters),\n",
        "4. Step our optimizer, which is what actually updates the model parameters,\n",
        "5. Zero the gradients of our optimizer, ready for the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUesBrjkjBUO"
      },
      "source": [
        "### Cross entropy loss\n",
        "\n",
        "The formula for cross entropy loss over a batch of size $N$ is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "l &= \\frac{1}{N} \\sum_{n=1}^{N} l_n \\\\\n",
        "l_n &=-\\log p_{n, y_{n}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $p_{n, c}$ is the probability the model assigns to class $c$ for sample $n$, and $y_{n}$ is the true label for this sample.\n",
        "\n",
        "<details>\n",
        "<summary>See this dropdown, if you're still confused about this formula, and how this relates to the information-theoretic general formula for cross entropy.</summary>\n",
        "\n",
        "The cross entropy of a distribution $p$ relate to a distribution $q$ is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "H(q, p) &= -\\sum_{n} q(n) \\log p(n)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "In our case, $q$ is the true distribution (i.e. the one-hot encoded labels, which equals one for $n = y_n$, zero otherwise), and $p$ is our model's output. With these subsitutions, this formula becomes equivalent to the formula for $l$ given above.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>See this dropdown, if you're confused about how this is the same as the <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\">PyTorch definition</a>.</summary>\n",
        "\n",
        "The PyTorch definition of cross entropy loss is:\n",
        "\n",
        "$$\n",
        "\\ell(x, y)=\\frac{1}{N}\\sum_{n=1}^{N} l_n, \\quad l_n=-\\sum_{c=1}^C w_c \\log \\frac{\\exp \\left(x_{n, c}\\right)}{\\sum_{i=1}^C \\exp \\left(x_{n, i}\\right)} y_{n, c}\n",
        "$$\n",
        "\n",
        "$w_c$ are the weights (which all equal one by default), $p_{n, c} = \\frac{\\exp \\left(x_{n, c}\\right)}{\\sum_{i=1}^C \\exp \\left(x_{n, i}\\right)}$ are the probabilities, and $y_{n, c}$ are the true labels (which are one-hot encoded, i.e. their value is one at the correct label $c$ and zero everywhere else). With this, the formula for $l_n$ reduces to the one we see above (i.e. the mean of the negative log probabilities).\n",
        "\n",
        "</details>\n",
        "\n",
        "The function `torch.functional.cross_entropy` expects the **unnormalized logits** as its first input, rather than probabilities. We get probabilities from logits by applying the softmax function:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p_{n, c} &= \\frac{\\exp(x_{n, c})}{\\sum_{c'=1}^{C} \\exp(x_{n, c'})}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $x_{n, c}$ is the model's output for class $c$ and sample $n$, and $C$ is the number of classes (in the case of MNIST, $C = 10$).\n",
        "\n",
        "Some terminology notes:\n",
        "\n",
        "* When we say **logits**, we mean the output of the model before applying softmax. We can uniquely define a distribution with a set of logits, just like we can define a distribution with a set of probabilities (and sometimes it's easier to think of a distribution in terms of logits, as we'll see later in the course).\n",
        "\n",
        "* When we say **unnormalized**, we mean the denominator term $\\sum_{c'} \\exp(x_{n, c'})$ isn't necessarily equal to 1. We can add a constant value onto all the logits which makes this term 1 without changing any of the actual probabilities, then we have the relation $p_{n, c} = \\exp(-l_{n, c})$. Here, we call $-l_{n, c}$ the **log probabilities** (or log probs), since $-l_{n, c} = \\log p_{n, c}$.\n",
        "\n",
        "If you're interested in the intuition behind cross entropy as a loss function, see [this post on KL divergence](https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence) (note that KL divergence and cross entropy differ by an amount which is independent of our model's predictions, so minimizing cross entropy is equivalent to minimizing KL divergence). Also see these two videos:\n",
        "\n",
        "* [Intuitively Understanding the Cross Entropy Loss](https://www.youtube.com/watch?v=Pwgpl9mKars&amp;ab_channel=AdianLiusie)\n",
        "* [Intuitively Understanding the KL Divergence](https://www.youtube.com/watch?v=SxGYPqCgJWM&amp;ab_channel=AdianLiusie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nld1gt2XjBUO"
      },
      "source": [
        "### Aside - `dataclasses`\n",
        "\n",
        "Sometimes, when we have a lot of different input parameters to our model, it can be helpful to use dataclasses to keep track of them all. Dataclasses are a special kind of class which come with built-in methods for initialising and printing (i.e. no need to define an `__init__` or `__repr__`). Another advantage of using them is autocompletion: when you type in `args.` in VSCode, you'll get a dropdown of all your different dataclass attributes, which can be useful when you've forgotten what you called a variable!\n",
        "\n",
        "Here's an example of how we might rewrite our training code above using dataclasses. We've wrapped all the training code inside a single argument called `train`, which takes a `SimpleMLPTrainingArgs` object as its only argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Cffn85qGjBUO",
        "outputId": "47e34278-0be8-445d-ff57-6fba4862311a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "31a9dfa0cdee4d73974e7cdae2b90936",
            "e7583f45511f423e9b983f98a90c4f9c",
            "d441ae9a839b4e1c8fedad369b53d8bb",
            "819f245f0ec447bdb5b868f6e28c72a2",
            "9162b3509c6a4c31be1d30752ece5978",
            "de79430615534ffea7cbad8904b2ef51",
            "3dd7e5c9527f44e29d2852fb2b3c718e",
            "b4ea700bf68048f78c6e57a8c6f3888a",
            "977b203a07fa42c68899d97e1118556e",
            "bec8d813b87f4de483f18830dbc4c9c2",
            "90b4f3ee35964c0e8dd172d0cd9850d8",
            "53f3de93fd3d41aa8aca4c29941ea3d4",
            "4ff5da20c5434f0ba32d808a24545ad0",
            "605e8c23fad849f6a7764538eaaf2824",
            "96c006f563584809b73443c9904841dc",
            "f9a287e73ee44e19bddd141cec5d9494",
            "770ee75c8c45476fb65afa6713531390",
            "6f368401424e4049a832a15d2bc5c753",
            "e4fff127a480488f8ff611d9458ace23",
            "6e72a39505ef4f86b9c64e4010ffbcb2",
            "918f52de36a44f28920e70e758972c63",
            "3c0f8fcc13ae4ac8abaccdc21e0ce1db",
            "0196a2fe0d944ce085e6c817ddd8971f",
            "fe95bd97dd3f4aaab22fc4635308fdc6",
            "0de575497fa04a38b0ca117ad1b1dab7",
            "acc4c790aa7a4731a961fcf026571b33",
            "e40e8a9cef0a41238fd0b55e5a5a56d4",
            "e13ac616c8834025be04f2f249f3a2bb",
            "1f5185b11b6d49cda8a68a385c5b4a51",
            "308b67c905a249938b1bd9e890d74de8",
            "ec31335c71924671a8f97bb8a5671980",
            "c6be1dc9b9264a08bd84acc140c7b07c",
            "7906053bb71b4549a4a5c35708a0b948"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31a9dfa0cdee4d73974e7cdae2b90936"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3346,  1.8804, -0.6478,  ...,  1.1220,  1.7353,  0.6483],\n",
            "        [ 0.5759,  0.6775,  1.6925,  ..., -0.6617,  1.3677, -0.6610],\n",
            "        [ 1.3876,  0.7610,  1.2720,  ...,  0.0578,  0.7590,  1.2989],\n",
            "        ...,\n",
            "        [-0.5529,  0.5981, -1.2210,  ..., -0.1059,  2.1318,  0.5817],\n",
            "        [-0.7788,  2.2729, -0.3538,  ...,  1.7463,  3.1850,  2.3923],\n",
            "        [ 0.0768,  1.6156, -1.6679,  ...,  0.8809,  2.4065, -0.1754]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0095,  0.8166, -0.3202,  ..., -1.3192,  0.5742,  2.6809],\n",
            "        [-0.4460,  1.4121, -1.8739,  ..., -0.1444, -0.3897, -0.0044],\n",
            "        [-0.7479, -0.4538,  0.0470,  ...,  0.6190,  2.1993,  0.5825],\n",
            "        ...,\n",
            "        [ 0.8158, -2.3187,  2.3650,  ...,  1.6759,  0.2331, -1.8231],\n",
            "        [ 0.0996,  3.0877, -1.2629,  ...,  0.0151,  2.0492,  1.6575],\n",
            "        [-1.4911,  1.1922,  0.7077,  ..., -1.7503,  0.4506,  0.1240]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2275, -1.2993,  1.2644,  ...,  0.4837,  0.9053, -0.5737],\n",
            "        [ 0.5069,  2.8581, -2.3153,  ...,  0.4520,  1.2246,  0.8652],\n",
            "        [ 0.7795,  2.0161, -0.8987,  ...,  1.2246,  0.9255,  0.1385],\n",
            "        ...,\n",
            "        [ 2.8500,  1.6444, -2.0229,  ...,  0.4731,  1.0698, -1.2738],\n",
            "        [ 0.5786, -0.3040, -2.4410,  ...,  0.7996,  1.6081, -0.3125],\n",
            "        [ 1.2117,  1.4565, -1.4721,  ..., -0.6899,  3.1422,  1.7355]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2607,  1.3778, -0.5920,  ..., -0.8068, -0.0462,  0.8525],\n",
            "        [ 1.4481, -1.1128, -0.1391,  ...,  1.6241, -1.8267,  1.3089],\n",
            "        [-0.5869,  4.9450, -1.1080,  ..., -0.5773,  2.5292,  0.4948],\n",
            "        ...,\n",
            "        [ 1.6240,  2.5623, -3.2581,  ...,  0.8828,  0.7070, -0.4852],\n",
            "        [-1.7133,  0.0822, -1.1143,  ..., -1.2300, -0.3440, -0.0805],\n",
            "        [ 2.5471,  0.6392, -3.2638,  ...,  0.0517,  0.3615,  2.3706]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7296,  3.4027, -1.2369,  ...,  0.2186,  1.5982, -0.3018],\n",
            "        [ 0.3656,  3.5805, -1.1044,  ...,  1.2027,  1.8046, -0.0594],\n",
            "        [-0.4746,  4.3873, -1.2091,  ...,  0.3018, -0.1926,  1.7081],\n",
            "        ...,\n",
            "        [-0.3486,  4.2588, -3.1397,  ..., -0.0434,  0.3522, -0.2312],\n",
            "        [ 2.9177,  0.9965, -1.8581,  ..., -0.0511, -0.0899, -0.6238],\n",
            "        [ 0.0339,  0.4702,  0.4991,  ...,  0.3872,  0.6886,  0.6755]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5956,  2.0852, -2.0377,  ...,  0.3017, -0.9669, -0.8364],\n",
            "        [-1.3533,  1.9026, -1.5380,  ..., -2.4039,  0.4884, -1.5654],\n",
            "        [ 0.0165,  3.3729, -2.1463,  ...,  0.6632,  3.0520, -0.0298],\n",
            "        ...,\n",
            "        [ 0.3655,  4.9489,  0.1809,  ...,  0.6872,  1.6592,  2.1956],\n",
            "        [ 0.0520,  1.7651,  1.0233,  ...,  0.2503,  0.7148, -0.5794],\n",
            "        [ 0.7935,  2.5746, -2.1790,  ...,  0.8541,  1.1875,  0.1195]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4099,  2.6242, -1.6623,  ...,  0.2608,  1.0990, -2.3182],\n",
            "        [ 2.8097,  1.6235, -2.9865,  ...,  0.8081,  2.7552, -2.1750],\n",
            "        [ 0.8138,  5.4329, -0.8834,  ...,  0.9404,  1.6438,  1.9303],\n",
            "        ...,\n",
            "        [ 1.0592,  3.0488, -1.1130,  ...,  0.3388,  1.4692,  0.1153],\n",
            "        [ 0.6334,  2.4616, -2.5250,  ..., -0.2879,  1.8925, -0.5360],\n",
            "        [ 2.5964,  2.4800, -1.4972,  ..., -0.7894,  2.0501,  0.3202]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7694,  2.5686,  1.6485,  ...,  0.6353,  0.2793, -2.1151],\n",
            "        [ 1.7607,  4.3163, -1.9001,  ...,  0.4369,  0.9502,  2.6908],\n",
            "        [ 0.8567,  3.7067, -1.5502,  ...,  0.6902,  2.2214,  1.2249],\n",
            "        ...,\n",
            "        [ 2.3500,  1.7534,  0.0772,  ..., -0.3289,  1.3504, -0.0169],\n",
            "        [ 1.6911,  2.2584, -2.8462,  ..., -0.9159,  1.7900, -2.0813],\n",
            "        [-0.8222,  3.1252, -3.0924,  ...,  0.6098,  1.0011,  0.4794]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7479,  4.2450, -2.4304,  ...,  0.4881, -0.5023,  0.0225],\n",
            "        [ 1.1943,  1.3753,  0.4920,  ..., -2.5405,  1.1052, -0.8339],\n",
            "        [-0.4797,  5.6626, -1.6655,  ..., -1.0888, -0.0235,  0.1712],\n",
            "        ...,\n",
            "        [ 2.8588,  3.9936, -0.5887,  ..., -0.2108,  2.0806, -0.3109],\n",
            "        [-0.8742,  3.8510, -2.7998,  ..., -1.5560,  1.5713, -0.4734],\n",
            "        [ 2.0240,  3.8215, -3.1013,  ..., -1.5455,  0.7902,  0.5730]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6222e+00,  3.4991e+00, -5.9686e-01,  ..., -4.8103e-01,\n",
            "          6.5496e-01,  1.5880e+00],\n",
            "        [-2.0921e-01,  2.1763e+00,  1.6309e+00,  ..., -1.0361e+00,\n",
            "         -1.8744e-01,  2.6413e+00],\n",
            "        [-1.6096e-01, -2.1585e-03,  1.5753e+00,  ..., -3.2389e-01,\n",
            "          1.1769e+00, -5.6771e-01],\n",
            "        ...,\n",
            "        [ 8.6344e-01,  3.2290e+00, -1.1594e+00,  ..., -3.7715e-01,\n",
            "          5.2529e-01,  1.4019e+00],\n",
            "        [ 2.5332e+00,  2.1585e+00, -1.4983e+00,  ..., -3.9578e-01,\n",
            "          2.3624e+00, -8.1416e-01],\n",
            "        [ 7.8854e-01,  1.4330e+00,  7.8342e-01,  ...,  7.8712e-01,\n",
            "          1.3646e+00, -2.1740e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9481,  0.2744, -0.4233,  ..., -2.0339,  1.9293, -1.7510],\n",
            "        [ 0.4228, -0.4798, -1.0069,  ..., -0.2000, -0.2707, -1.4617],\n",
            "        [ 1.7681,  1.5803, -2.5314,  ..., -1.9302,  1.7334, -3.3274],\n",
            "        ...,\n",
            "        [ 1.5959,  1.2806, -2.0755,  ...,  0.9765,  2.2802,  0.5583],\n",
            "        [ 0.7300,  1.9186, -0.6257,  ..., -1.4707,  2.8208,  0.3362],\n",
            "        [ 1.1890,  3.2139, -1.0195,  ..., -0.1470,  0.9322,  4.3270]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3058,  1.4124, -2.5274,  ..., -1.0877,  1.7953, -2.3464],\n",
            "        [ 1.1172,  2.2019,  0.4980,  ..., -0.3673,  0.0280,  0.1380],\n",
            "        [ 1.6917,  1.5602, -0.0900,  ..., -1.8808,  3.3705,  0.9596],\n",
            "        ...,\n",
            "        [-0.8309,  2.0985,  0.4214,  ..., -0.5461, -0.0999,  2.1473],\n",
            "        [ 1.9734,  0.7996, -2.3840,  ..., -1.1825, -0.6214, -1.3356],\n",
            "        [ 0.5659,  4.5336, -1.0535,  ...,  0.1748,  1.9863,  0.3340]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9115,  2.5939, -1.0376,  ...,  0.6143, -1.4689,  0.4674],\n",
            "        [-0.4891,  2.7330, -2.1568,  ..., -2.1567,  0.1035, -1.1372],\n",
            "        [-0.4810,  4.7110,  2.3107,  ..., -1.5824,  2.3360,  2.1649],\n",
            "        ...,\n",
            "        [-0.2308,  2.9566, -1.4343,  ..., -0.9851,  0.5326,  1.4379],\n",
            "        [ 1.5256,  3.9657, -1.8661,  ..., -1.5572,  0.7367,  2.3969],\n",
            "        [ 3.1476,  1.9291, -0.6586,  ..., -1.6167, -0.5783,  0.6044]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4303, -2.6206,  3.2121,  ..., -2.3686,  0.8126, -0.2024],\n",
            "        [-0.5682,  1.2462, -1.0833,  ..., -0.4755,  3.2090,  1.1024],\n",
            "        [-0.3618,  2.4835, -0.7628,  ..., -1.2828,  3.0588,  0.6682],\n",
            "        ...,\n",
            "        [ 0.7777,  2.4852,  0.8266,  ..., -0.9171,  0.2474, -0.0932],\n",
            "        [ 0.1884,  3.7958,  1.1858,  ..., -0.2711,  1.6380,  0.4718],\n",
            "        [ 0.2658,  2.8034, -1.1381,  ..., -1.4320,  0.0725, -0.0778]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3954,  0.9918, -0.6405,  ..., -1.3062,  1.0364, -0.4762],\n",
            "        [ 2.8791, -0.4158, -1.1986,  ..., -0.8044,  0.1929, -1.3779],\n",
            "        [ 0.1250,  3.7430, -0.7307,  ...,  0.3508,  2.7522,  1.0031],\n",
            "        ...,\n",
            "        [-1.2142,  2.3662,  0.3036,  ..., -1.0299,  0.3631,  1.1874],\n",
            "        [ 0.5347,  0.9861,  0.4291,  ..., -1.1424,  1.8137,  1.5035],\n",
            "        [ 0.5276,  0.6885,  1.3740,  ..., -0.8116,  0.8517,  0.2652]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4453,  4.0110,  1.1126,  ..., -0.7694,  0.7873,  0.6246],\n",
            "        [ 2.8653,  1.2472, -3.2342,  ..., -0.6074,  2.0434, -2.8853],\n",
            "        [ 0.2605, -0.5732,  2.2658,  ...,  0.6201,  1.2100, -0.8576],\n",
            "        ...,\n",
            "        [ 0.8856, -0.1707,  1.9556,  ..., -2.1870,  2.4671,  1.1048],\n",
            "        [ 0.1483,  1.7879, -1.6222,  ..., -1.7589,  2.7653,  0.4895],\n",
            "        [-0.0617,  1.2178, -3.4826,  ..., -1.9700,  1.2969, -0.7781]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3360,  1.9016, -2.5325,  ..., -2.3888,  0.7309, -1.1854],\n",
            "        [ 1.1267,  3.5790,  0.6116,  ..., -0.5944,  0.0946, -0.0274],\n",
            "        [ 1.9236,  1.5413, -0.3566,  ..., -1.0280,  1.2633,  0.1616],\n",
            "        ...,\n",
            "        [ 2.7443,  1.4173, -2.3480,  ..., -1.0312,  2.1791, -3.3696],\n",
            "        [-0.9293,  1.5929, -0.3815,  ..., -2.1809,  0.0250, -1.1648],\n",
            "        [-1.7873,  1.6694,  1.2668,  ..., -1.3364,  3.4432,  1.4449]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8607,  2.8848, -2.4805,  ..., -1.9930,  1.5459, -0.1275],\n",
            "        [ 0.4136,  0.6310, -0.7245,  ..., -1.4773,  1.5667, -3.3959],\n",
            "        [-0.7382,  1.9013,  0.3809,  ..., -4.1296, -0.2699,  0.4232],\n",
            "        ...,\n",
            "        [-1.5657,  0.4550,  0.7305,  ..., -1.4312,  2.1814,  0.2914],\n",
            "        [ 1.0978,  2.9216, -2.2324,  ..., -1.2301,  1.2310, -2.3089],\n",
            "        [-0.5729,  1.8986,  0.7363,  ...,  0.1334,  1.5505,  1.5011]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7545,  1.2550, -0.3473,  ..., -0.8539,  3.6689, -0.3516],\n",
            "        [ 0.7319,  1.8690, -1.8763,  ..., -1.0818,  1.8694, -1.3020],\n",
            "        [ 0.6798,  1.3771, -2.0575,  ..., -4.1167,  0.2999, -0.0831],\n",
            "        ...,\n",
            "        [ 1.4082,  1.4076,  0.6926,  ..., -1.6928, -0.5219, -0.9623],\n",
            "        [-0.1660,  3.2828,  0.9410,  ...,  1.4548,  1.9403,  0.8735],\n",
            "        [-0.5991,  0.4798,  0.0564,  ..., -0.4636,  1.3485, -2.4039]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5220,  2.6576, -1.6167,  ..., -1.8698,  2.3152,  1.3689],\n",
            "        [-0.2705,  2.7667, -0.0208,  ..., -0.1796, -1.7204,  0.2717],\n",
            "        [ 0.2042,  1.5504,  1.0355,  ..., -0.4486,  2.0614, -1.2691],\n",
            "        ...,\n",
            "        [ 2.2932,  0.8752, -0.6044,  ..., -0.8906,  1.4890, -1.6663],\n",
            "        [ 0.3030,  0.6183, -2.4044,  ...,  0.0855,  1.1914, -0.6957],\n",
            "        [ 0.1772,  1.8145, -3.1261,  ..., -2.4318,  0.4644, -0.6006]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1243,  0.3923, -1.9392,  ..., -0.4990,  1.0230, -1.0748],\n",
            "        [-1.4889,  2.2300, -0.9053,  ..., -1.9286,  0.5370, -1.1974],\n",
            "        [ 1.9584,  2.1746, -2.6253,  ..., -1.4589, -0.8577, -0.1423],\n",
            "        ...,\n",
            "        [-1.2263,  1.4638, -1.1714,  ..., -2.1497,  0.4457, -1.2068],\n",
            "        [ 2.2992, -0.3157,  0.1561,  ..., -3.0396,  1.2494, -0.2462],\n",
            "        [ 0.3169,  1.3549, -1.3454,  ...,  0.5781,  0.8197, -0.8602]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8207,  3.7706, -1.7336,  ..., -0.6565,  0.9603,  1.2935],\n",
            "        [ 3.5701, -1.0554,  0.9108,  ..., -2.7269,  1.9870, -1.6604],\n",
            "        [-0.0230, -0.8167,  3.6934,  ..., -0.7031,  1.8593, -1.9778],\n",
            "        ...,\n",
            "        [ 0.1757,  1.2629, -1.3908,  ..., -1.0634,  0.1108, -1.0636],\n",
            "        [-0.1021,  3.1628, -3.4829,  ..., -2.1689,  2.5560, -0.1868],\n",
            "        [ 1.1399,  1.2425, -4.8715,  ..., -0.1918,  2.2002, -0.4554]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6657,  1.0845, -2.0943,  ..., -0.5999, -0.5210, -2.2714],\n",
            "        [-0.3838,  1.7435, -1.6499,  ..., -1.1582,  0.1720, -1.1228],\n",
            "        [ 1.6758, -0.3168,  0.4187,  ..., -0.1826,  1.7862, -1.7524],\n",
            "        ...,\n",
            "        [-0.2016, -0.0439, -0.0895,  ..., -1.9744,  0.3588, -1.2729],\n",
            "        [ 3.6580,  4.3647, -1.8929,  ..., -3.1564,  0.9343,  1.7154],\n",
            "        [ 0.5619,  2.2399, -1.6373,  ..., -0.1066, -0.0235,  0.2428]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3045,  1.3703,  1.5863,  ...,  0.4235,  0.7433, -1.6637],\n",
            "        [ 0.1489,  0.7229,  0.5622,  ...,  0.2268,  0.1317, -0.1763],\n",
            "        [ 1.3670,  4.0298, -1.4654,  ..., -1.2550,  1.2531,  0.7942],\n",
            "        ...,\n",
            "        [ 1.2673,  2.9918, -3.8930,  ...,  0.8579,  0.3090,  0.2188],\n",
            "        [ 0.4772, -1.0116, -0.5162,  ..., -0.9605,  1.3221, -2.1670],\n",
            "        [ 2.4225,  1.6136, -3.7504,  ..., -1.1754,  4.4920, -1.8404]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3791, -0.1821, -1.5805,  ..., -2.5314,  0.3497,  0.7805],\n",
            "        [ 3.2996,  0.4867, -1.7417,  ..., -0.3370,  1.4438, -1.8938],\n",
            "        [ 2.3846,  3.2894, -1.4571,  ...,  0.5076,  2.0402, -0.9618],\n",
            "        ...,\n",
            "        [ 2.1995,  2.2220, -3.0262,  ..., -1.6873,  3.2937, -1.5831],\n",
            "        [ 0.7659,  1.6635, -1.0227,  ..., -0.4838,  2.9431, -0.5016],\n",
            "        [ 0.9719,  3.7197, -1.4986,  ..., -1.7805,  1.7346, -0.0272]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3782,  2.7757,  0.5839,  ...,  0.9827,  1.8486, -0.1830],\n",
            "        [ 2.2481, -0.3890,  1.7474,  ..., -2.5331,  0.1873,  1.6591],\n",
            "        [ 0.2271,  1.1130, -1.8682,  ..., -0.8990,  2.1353, -0.2292],\n",
            "        ...,\n",
            "        [ 1.6275,  0.8329,  0.5594,  ..., -1.5812,  0.8713, -1.7367],\n",
            "        [ 0.4843,  3.7731, -4.7078,  ..., -1.5939,  2.1756, -0.7103],\n",
            "        [ 0.4024,  3.1592, -3.5261,  ..., -0.7283,  3.1641,  0.2784]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8211,  3.5931, -2.7104,  ..., -1.0292,  4.0507,  0.1943],\n",
            "        [ 0.2099,  2.2870, -2.2729,  ..., -0.5730, -0.1813, -0.0363],\n",
            "        [ 0.5087,  0.2601, -0.8652,  ...,  0.2069,  0.4825, -2.3866],\n",
            "        ...,\n",
            "        [ 6.4844,  2.2618, -1.2099,  ..., -1.7106, -1.0612,  1.4891],\n",
            "        [-0.9553,  1.4205,  0.7081,  ..., -1.6172,  3.1988,  1.1044],\n",
            "        [ 1.9060,  1.5101, -1.4896,  ..., -3.8235,  1.5269, -0.9835]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6297e+00,  2.6991e+00,  6.1635e-01,  ..., -1.2342e+00,\n",
            "         -7.2511e-01, -8.9058e-01],\n",
            "        [ 2.2330e+00,  1.6400e-01, -4.3468e-03,  ..., -6.1760e-02,\n",
            "          4.1314e+00, -1.6751e+00],\n",
            "        [ 2.0263e+00, -3.6855e-02, -6.9306e-01,  ..., -7.9091e-01,\n",
            "          2.3721e-01, -1.7256e+00],\n",
            "        ...,\n",
            "        [ 2.6110e+00,  4.3577e+00, -4.1866e+00,  ..., -2.2603e+00,\n",
            "          5.3366e-01, -1.0812e+00],\n",
            "        [-4.7268e-01,  4.5262e+00, -1.7289e+00,  ..., -2.4094e+00,\n",
            "          1.7295e+00, -3.2237e-01],\n",
            "        [ 1.7972e-01,  1.1159e+00, -2.2842e+00,  ..., -9.0405e-01,\n",
            "          4.3511e+00,  9.4629e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1369,  2.6914, -4.1652,  ..., -1.9650,  0.7307, -1.1653],\n",
            "        [ 1.1777,  1.3073, -3.1782,  ..., -1.3098,  3.4413, -1.2287],\n",
            "        [-0.7660,  2.0069,  1.1377,  ..., -1.5937,  2.1165,  1.7122],\n",
            "        ...,\n",
            "        [ 1.0790,  1.9757, -3.4696,  ..., -1.3527,  1.6702, -1.5824],\n",
            "        [ 2.8830,  1.1736, -0.7998,  ..., -1.1796,  0.0183, -1.6194],\n",
            "        [ 1.9076, -0.3270, -0.3544,  ..., -0.2903,  1.0367, -1.8375]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6241,  1.6161, -2.3385,  ..., -0.3686, -0.1584, -0.0502],\n",
            "        [ 1.4717,  0.2554, -0.7066,  ..., -1.4309, -0.2016, -1.2988],\n",
            "        [-0.6692,  1.0228, -1.0351,  ..., -0.9414,  1.0081, -1.2695],\n",
            "        ...,\n",
            "        [ 1.4327,  1.6475, -1.2173,  ...,  0.6567,  3.0941, -0.6984],\n",
            "        [ 1.7964,  0.3252, -0.3410,  ..., -0.3248,  1.3858, -1.9342],\n",
            "        [ 1.3315,  1.6403,  0.3018,  ..., -2.5308,  1.8676, -0.8538]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8854,  5.2390, -2.6210,  ..., -1.2985,  0.1755, -1.9511],\n",
            "        [ 0.4082,  0.6885,  2.2449,  ..., -1.4362,  0.2803,  0.6598],\n",
            "        [ 4.4884,  1.1576, -2.1168,  ..., -1.4213,  1.3469, -0.7961],\n",
            "        ...,\n",
            "        [ 0.1645, -0.3902,  2.2361,  ...,  0.0165, -0.2371, -0.4671],\n",
            "        [ 0.9656,  2.9394, -0.7286,  ..., -2.7876, -0.9418,  1.3922],\n",
            "        [ 3.7178, -0.1275,  1.1002,  ..., -0.4777,  0.2826,  0.5616]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5891e+00, -1.7696e+00, -2.9162e-01,  ...,  6.9841e-01,\n",
            "          1.3695e+00, -1.1591e+00],\n",
            "        [ 1.0144e+00,  3.0633e-01,  4.2809e-01,  ..., -1.3551e+00,\n",
            "          4.3593e+00, -1.2163e-01],\n",
            "        [-1.6748e-01,  2.8509e+00, -9.2675e-01,  ..., -2.0132e+00,\n",
            "          2.5801e+00,  1.0686e-01],\n",
            "        ...,\n",
            "        [-1.3046e+00,  3.0337e+00, -9.2367e-01,  ...,  1.4972e+00,\n",
            "          2.6980e-01, -3.0083e-03],\n",
            "        [ 1.1429e+00,  9.7202e-04, -6.9794e-01,  ..., -4.8403e-02,\n",
            "          3.9073e+00, -6.7247e-01],\n",
            "        [-3.8861e-01,  1.4667e+00, -1.2641e+00,  ..., -6.3125e-01,\n",
            "          1.2941e+00, -1.2152e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5759,  2.8228, -3.3156,  ..., -1.1977,  2.6086,  0.3578],\n",
            "        [ 3.1963,  2.8354, -3.7272,  ..., -3.4519,  0.0276, -1.8040],\n",
            "        [ 3.0914, -1.3680, -1.8053,  ..., -0.1563,  4.6862, -2.3898],\n",
            "        ...,\n",
            "        [ 1.3128,  0.4626, -0.1841,  ..., -0.3644,  2.1441, -0.2828],\n",
            "        [ 1.9178,  2.6862, -2.8361,  ..., -0.8803,  1.9791, -0.5366],\n",
            "        [ 1.0089, -2.2683, -1.2903,  ..., -1.2021,  2.3558, -1.0113]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0304,  0.4986,  1.7663,  ..., -0.5148,  2.1835, -0.0771],\n",
            "        [ 0.4390,  3.7439, -1.7960,  ..., -1.3066,  1.6596, -0.3499],\n",
            "        [ 2.1167,  0.6604, -2.1970,  ..., -0.8210,  1.2321, -1.8186],\n",
            "        ...,\n",
            "        [ 0.2534,  3.0676, -4.3640,  ..., -1.8190,  1.8623, -0.7681],\n",
            "        [ 1.7542,  1.7494, -1.8817,  ...,  1.2274,  0.9625, -0.7427],\n",
            "        [ 2.2474,  4.0842, -2.8354,  ..., -0.2828, -2.1601, -0.0184]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0551,  2.3050, -1.9368,  ..., -2.0608,  0.5560, -1.3412],\n",
            "        [ 3.9473,  0.5285, -0.0710,  ...,  0.2724,  0.5672,  0.6687],\n",
            "        [ 1.7792,  1.2907, -0.3736,  ..., -1.3562,  1.9443,  0.2786],\n",
            "        ...,\n",
            "        [ 1.9240,  0.0428, -1.9819,  ..., -1.0706,  0.8582, -2.5412],\n",
            "        [ 1.6341,  1.8233, -1.8215,  ..., -1.9584,  2.6814,  0.1712],\n",
            "        [ 0.5791,  3.3252,  1.3294,  ...,  0.5377,  1.6543,  0.1524]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.2015,  1.2115, -3.5028,  ..., -1.8949,  2.8356,  0.6673],\n",
            "        [ 2.5153,  5.4984, -2.0362,  ..., -1.6053,  1.0192,  1.0117],\n",
            "        [ 1.0797,  0.6115, -1.5683,  ...,  0.4281,  1.8119, -0.7204],\n",
            "        ...,\n",
            "        [ 0.8289,  4.9744, -2.7801,  ..., -0.3307,  3.4282,  0.4994],\n",
            "        [ 1.9830, -0.5481, -2.9454,  ...,  0.7921,  2.7823, -1.2431],\n",
            "        [ 2.8716,  2.0946, -0.6408,  ..., -2.7864, -0.4112, -0.8850]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6688,  3.7030, -2.5211,  ..., -3.7681, -1.4135, -0.4545],\n",
            "        [ 1.3896, -0.5641,  1.2604,  ..., -0.7092,  1.6712, -0.9292],\n",
            "        [ 0.6184,  6.4268, -2.1525,  ..., -1.5981, -0.2506,  1.8770],\n",
            "        ...,\n",
            "        [-0.2385,  2.2161, -2.4096,  ..., -1.9566,  0.8786, -1.2673],\n",
            "        [ 3.3678, -1.9570,  0.3828,  ..., -0.5945,  2.2973, -2.0800],\n",
            "        [ 0.0850,  2.6612, -3.0649,  ..., -2.5200,  0.3607, -1.8038]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5454,  1.0731, -0.9684,  ..., -0.5439,  2.4442, -0.8864],\n",
            "        [ 0.7285,  6.7547, -4.0334,  ..., -1.3438, -0.3005, -0.2575],\n",
            "        [ 3.6824,  2.0831,  0.3633,  ..., -3.6069,  0.2466,  0.7563],\n",
            "        ...,\n",
            "        [ 0.3155, -1.0572, -0.7545,  ..., -0.1426,  0.8174, -1.5794],\n",
            "        [-0.3426, -0.5674,  0.7313,  ..., -0.2331,  3.9207, -0.0402],\n",
            "        [-0.0719,  0.4725, -1.4229,  ..., -1.4935,  0.1783, -2.0086]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1773,  3.3684, -3.3185,  ..., -0.6212,  1.3733, -1.8338],\n",
            "        [ 0.0290,  2.4181, -3.4532,  ..., -1.7082,  0.4828, -1.8983],\n",
            "        [ 1.8394,  0.9125, -1.4868,  ..., -1.2839,  0.9961, -2.1640],\n",
            "        ...,\n",
            "        [ 1.2449,  1.4484, -1.0833,  ..., -1.2985,  2.8576,  2.6139],\n",
            "        [ 1.9927,  0.7110, -2.0672,  ..., -1.5361,  5.6776,  1.0711],\n",
            "        [ 0.4755,  2.1709, -1.1275,  ..., -0.0067,  0.8668, -0.5083]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4904,  0.2123,  1.2083,  ..., -4.9361,  0.7921,  0.1413],\n",
            "        [ 2.9772,  2.3325, -2.1978,  ..., -2.3825, -0.7333, -0.3478],\n",
            "        [-0.1232,  3.0889,  0.2661,  ..., -0.9313,  2.1307,  0.0219],\n",
            "        ...,\n",
            "        [ 0.7334,  0.1780,  1.8031,  ...,  0.0251,  2.3337, -2.6923],\n",
            "        [ 3.0597, -0.8827, -0.8870,  ..., -2.6353, -0.5768,  1.9475],\n",
            "        [ 2.2788, -1.6130, -0.7487,  ...,  0.1591,  2.1509, -2.0993]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3956,  2.8193, -4.0167,  ..., -2.4623,  3.3785,  2.6367],\n",
            "        [ 1.4547,  2.2856, -4.2925,  ..., -2.0189,  1.2411, -1.1828],\n",
            "        [ 2.0918,  0.5138, -1.1617,  ..., -4.8305,  0.8982,  1.4925],\n",
            "        ...,\n",
            "        [ 2.2814,  0.7275,  0.5413,  ..., -1.5163,  1.8005,  0.6698],\n",
            "        [ 0.9577,  0.6295, -0.8131,  ..., -0.4209,  0.0679, -0.8800],\n",
            "        [-0.3538,  2.2414, -0.6891,  ...,  0.0792,  1.8622, -1.3320]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1237,  1.3488,  1.6797,  ...,  0.6702, -0.0694,  0.0400],\n",
            "        [ 0.0342,  4.3345, -1.8429,  ..., -1.6826,  1.6740,  0.9192],\n",
            "        [ 1.5245, -0.1394,  2.9546,  ..., -1.8541,  2.0645, -3.3186],\n",
            "        ...,\n",
            "        [-0.5688,  0.3318, -0.8950,  ..., -0.5596,  0.2839, -1.9313],\n",
            "        [-0.1216,  1.8739, -2.2721,  ..., -1.9617,  0.9951, -1.3844],\n",
            "        [-0.3599,  0.3061, -0.2058,  ..., -0.5771,  0.2798, -2.0355]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4258,  2.1703, -3.7979,  ..., -1.8355,  0.9730, -1.3846],\n",
            "        [ 0.9837,  2.5247, -3.2199,  ..., -0.3197,  2.3715, -1.6668],\n",
            "        [ 2.3095,  1.0965, -0.1098,  ..., -0.2696,  0.8460,  0.1452],\n",
            "        ...,\n",
            "        [-0.8711,  4.1273, -3.7255,  ...,  0.2438,  0.6345,  0.4597],\n",
            "        [ 0.9635,  3.4886, -2.5903,  ..., -0.4607,  1.8509, -1.0593],\n",
            "        [ 1.7608,  1.6262, -4.3837,  ..., -0.8705,  3.8724,  0.3401]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0370,  0.8271,  2.9687,  ..., -0.1075,  1.0031,  2.9332],\n",
            "        [ 2.1435,  2.3690, -0.4208,  ..., -1.4334, -1.3006, -1.4153],\n",
            "        [-1.1470,  2.9401,  0.8763,  ...,  0.4252, -0.2570,  0.3924],\n",
            "        ...,\n",
            "        [ 0.5084,  5.8597, -1.8319,  ..., -4.9365,  1.7197,  0.1868],\n",
            "        [ 0.1136,  1.5960, -2.1206,  ..., -1.3388, -0.5046, -0.9482],\n",
            "        [-0.5146,  0.9225,  0.6079,  ..., -1.0480,  4.0108,  0.3189]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9057,  2.3585, -4.0901,  ...,  1.1329,  1.2633,  0.5738],\n",
            "        [-0.8353,  1.9633,  0.9702,  ..., -1.2231,  3.3063,  1.6742],\n",
            "        [-1.4844,  4.1262,  0.8839,  ...,  1.8117,  2.0845,  0.9758],\n",
            "        ...,\n",
            "        [ 2.3842,  3.8225,  0.7984,  ...,  0.2575,  2.9083, -0.0555],\n",
            "        [ 1.9508,  1.8757,  2.4384,  ..., -0.9826,  0.5123, -0.9898],\n",
            "        [ 0.1655,  0.8013, -1.1852,  ..., -1.6121,  2.0036, -1.3507]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4350,  2.8909,  1.0396,  ..., -0.5117, -0.8181,  1.2237],\n",
            "        [ 4.8467,  2.0075, -1.1904,  ...,  0.0618,  0.8200, -1.9804],\n",
            "        [ 2.1586,  2.2750, -3.7788,  ..., -1.4957,  3.1349, -1.3403],\n",
            "        ...,\n",
            "        [ 0.6076,  1.1901,  0.7248,  ..., -0.0110,  0.9010, -1.1130],\n",
            "        [ 1.0287, -1.7451,  3.1253,  ..., -1.1794,  2.9409, -2.4327],\n",
            "        [-0.4585,  1.3415, -0.2979,  ..., -1.2953,  2.5265, -0.4542]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8058,  0.1180,  1.3971,  ...,  1.6294,  0.9888, -1.4628],\n",
            "        [-1.9406,  3.1502, -0.4848,  ..., -1.2380,  3.2615, -0.0460],\n",
            "        [ 3.4360,  3.0353, -2.5193,  ..., -1.3356, -1.2828,  2.4209],\n",
            "        ...,\n",
            "        [ 1.0701,  0.2475, -2.2549,  ..., -0.2736,  0.7939, -1.1626],\n",
            "        [ 0.0613, -0.1654, -0.8555,  ..., -1.5975,  1.0324, -1.7265],\n",
            "        [ 0.7103,  0.1049, -0.8892,  ..., -0.8772, -0.8445,  0.0794]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4454,  3.7413, -1.8572,  ..., -0.3550,  1.9120,  1.5956],\n",
            "        [ 2.7299,  1.7004, -0.9320,  ..., -2.4264,  4.4592,  0.7697],\n",
            "        [ 1.4336,  5.5174, -3.6566,  ..., -0.9043,  1.5248, -0.8173],\n",
            "        ...,\n",
            "        [ 1.4110,  1.5328, -2.0295,  ..., -1.3351,  2.8806,  0.3333],\n",
            "        [ 1.0637,  1.2724,  3.4629,  ..., -1.7451, -0.1385, -0.0057],\n",
            "        [ 4.2858,  0.6220, -0.4180,  ..., -1.6693, -0.3244,  0.1012]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3363,  2.7547, -0.7624,  ..., -1.6490, -0.7582, -0.0895],\n",
            "        [ 0.2065,  0.5967, -1.9188,  ..., -0.8606,  0.6721, -1.1463],\n",
            "        [ 3.3106,  0.8171,  0.1635,  ..., -0.4939,  1.2501, -3.0677],\n",
            "        ...,\n",
            "        [ 1.2127,  0.4222, -1.2926,  ..., -0.9481,  1.2832, -1.3373],\n",
            "        [-1.3470,  3.2312, -2.2356,  ...,  0.7865,  3.9693,  0.3721],\n",
            "        [ 1.0735,  1.8904, -0.7963,  ..., -1.7920, -1.3555,  0.7639]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7865,  2.7502, -0.3407,  ..., -3.8373,  2.9248, -2.6067],\n",
            "        [ 1.9329,  2.7495,  0.1794,  ..., -2.2515, -2.3014,  0.1015],\n",
            "        [-0.4634, -0.0183,  0.0632,  ..., -4.2184,  2.3407, -0.8440],\n",
            "        ...,\n",
            "        [ 1.1213,  1.4165, -0.7654,  ...,  0.6129,  0.7129, -1.3951],\n",
            "        [ 1.6019, -0.2868, -0.5978,  ...,  0.2050,  2.0235, -1.4718],\n",
            "        [ 0.7447,  4.1094,  0.1370,  ..., -1.9853, -0.6216,  2.2238]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8216,  4.2344,  0.1866,  ...,  1.9711,  3.4269, -0.0240],\n",
            "        [ 2.2870,  0.2116,  0.5372,  ..., -2.3101,  5.3651, -0.4272],\n",
            "        [-0.3044,  2.1118, -1.4142,  ..., -1.4921, -0.0505, -2.0395],\n",
            "        ...,\n",
            "        [ 2.5426, -0.8843, -0.1964,  ..., -0.6563,  2.4462, -1.8316],\n",
            "        [ 3.6941,  2.0764, -4.2826,  ..., -1.6818,  5.0666, -0.4711],\n",
            "        [ 2.8253,  6.1296, -4.0594,  ..., -1.5052, -0.4267, -1.2578]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3138,  0.7024, -1.9172,  ...,  1.0336,  2.5003, -1.2300],\n",
            "        [ 1.0805,  0.8681,  1.8800,  ..., -0.8207,  2.5223, -2.0226],\n",
            "        [-0.4497,  1.2576, -0.6838,  ..., -0.9322,  0.1527, -1.8602],\n",
            "        ...,\n",
            "        [ 1.7113,  3.3417, -1.6120,  ..., -0.7274,  3.6936,  0.4433],\n",
            "        [ 0.5970,  2.5692, -2.7687,  ..., -1.7381,  1.0575, -1.8064],\n",
            "        [ 0.7687,  0.6239, -1.3847,  ..., -0.1439,  4.6375, -0.6778]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4311,  2.8696, -2.6827,  ..., -1.7061,  1.5889, -1.4327],\n",
            "        [ 0.4532,  2.9613, -0.6655,  ..., -1.0612,  1.2272, -0.7047],\n",
            "        [ 2.8166, -0.0685,  0.4586,  ..., -0.4409,  2.9286, -1.6669],\n",
            "        ...,\n",
            "        [ 1.3287,  2.5566, -2.7889,  ..., -0.2049,  3.5621,  1.4383],\n",
            "        [-0.4479,  3.0815,  0.1619,  ..., -0.1563,  4.5098,  0.7200],\n",
            "        [-0.4129,  1.2952,  2.3588,  ..., -2.6051,  0.4969, -0.5590]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0950,  5.2715, -1.9858,  ..., -2.1450,  0.4197, -2.7570],\n",
            "        [ 0.8292,  2.9933, -3.7059,  ..., -2.0535,  1.3237, -1.7399],\n",
            "        [ 1.3697, -0.0301, -1.1599,  ...,  0.1867,  4.8524,  0.6676],\n",
            "        ...,\n",
            "        [ 1.8278, -0.3547,  0.3143,  ..., -2.0840,  3.9089, -2.2537],\n",
            "        [ 1.0185,  1.1827, -1.6650,  ..., -1.9951,  1.0313, -1.9956],\n",
            "        [-0.2045,  0.5542, -0.1014,  ..., -0.4175,  1.7744, -0.8715]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2525, -2.6586,  0.6363,  ...,  0.1471,  1.1197, -1.3537],\n",
            "        [-0.1031,  2.7556, -2.8367,  ..., -1.7569,  1.8623, -1.0718],\n",
            "        [ 4.1251,  2.5124, -4.1763,  ..., -1.3212,  2.5889, -2.2267],\n",
            "        ...,\n",
            "        [ 2.5040,  0.2622, -1.5420,  ..., -1.6331,  3.6346, -1.6836],\n",
            "        [ 1.9528,  0.1757, -1.1697,  ..., -0.0490,  1.9017,  0.2265],\n",
            "        [ 3.6339,  1.9228,  0.4408,  ..., -1.4582,  0.2669, -0.3604]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4136,  0.4650, -3.2990,  ..., -1.1629, -0.3630, -0.7032],\n",
            "        [ 2.5696,  2.3072, -2.0148,  ..., -3.7129,  4.8172, -1.2984],\n",
            "        [ 0.3386,  3.3360, -3.7935,  ...,  0.1869, -0.0908,  0.1344],\n",
            "        ...,\n",
            "        [ 3.8832,  2.9549, -3.3324,  ..., -4.2910,  0.9260, -0.9920],\n",
            "        [ 2.8944,  5.9114, -5.2364,  ..., -2.4952, -0.5656, -0.8512],\n",
            "        [-0.4417,  4.6609, -2.4665,  ..., -1.2418,  0.1644, -0.3669]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0895,  2.3322, -2.3211,  ...,  0.9541,  2.1334, -1.0894],\n",
            "        [ 1.8318,  1.0604,  0.4322,  ..., -0.3224,  1.7714, -1.4068],\n",
            "        [ 0.3439,  1.6585, -1.8118,  ..., -0.0341,  3.2720, -0.2622],\n",
            "        ...,\n",
            "        [ 3.1683,  6.6933, -2.3455,  ..., -1.7008, -0.0177,  0.4299],\n",
            "        [ 1.4943,  1.6936, -0.6685,  ...,  0.6127,  2.6687,  0.8080],\n",
            "        [ 3.2789, -0.7112, -0.2540,  ..., -3.3008,  1.2220, -0.3336]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4043,  2.4728,  0.2767,  ..., -1.8094,  2.2130, -1.2168],\n",
            "        [-0.5213,  1.9320, -0.6621,  ...,  0.4545,  3.5507, -0.5375],\n",
            "        [ 2.0015, -0.6377,  1.7196,  ..., -0.7464,  2.3234, -1.3531],\n",
            "        ...,\n",
            "        [ 3.7012,  1.2893, -0.3835,  ..., -0.6986,  1.0491, -1.4795],\n",
            "        [ 1.0662,  4.0696, -1.7792,  ..., -0.9168,  2.3511, -0.7982],\n",
            "        [ 0.0612,  2.3840, -1.3586,  ..., -1.8733,  4.3636,  0.4854]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7364,  2.1306,  0.4545,  ..., -1.5388,  1.7192, -1.7319],\n",
            "        [ 0.4409,  2.5805, -2.4565,  ..., -1.8116,  1.7922, -0.8282],\n",
            "        [ 1.1852,  2.0055,  3.4104,  ..., -2.1635,  1.7091,  0.5927],\n",
            "        ...,\n",
            "        [ 1.6321,  1.3172,  2.3611,  ..., -0.4484,  1.0378,  0.5025],\n",
            "        [-0.1129,  1.9406,  0.3752,  ...,  1.2123,  0.6229, -0.3882],\n",
            "        [ 1.7177,  3.3972,  1.9020,  ..., -1.3304,  4.5144,  0.2978]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7534,  3.6728, -2.4763,  ..., -1.7471, -0.7264, -2.1920],\n",
            "        [ 0.3393,  4.5326,  2.2702,  ..., -1.6021,  0.7856,  1.3624],\n",
            "        [ 2.7570, -0.6993,  1.1477,  ..., -0.6452,  2.2662, -1.2911],\n",
            "        ...,\n",
            "        [ 3.3389,  5.4145,  1.7376,  ..., -0.7206, -0.8798,  0.5701],\n",
            "        [ 0.3771,  3.3440, -2.8800,  ..., -1.6987,  2.4723, -1.1580],\n",
            "        [ 1.2529,  2.4974, -2.6246,  ...,  0.1175,  2.8642,  0.9835]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0896,  1.3518, -0.0443,  ..., -3.4822,  1.1891, -0.7153],\n",
            "        [ 1.4467,  1.8413, -0.2070,  ..., -1.8930,  3.4553, -0.3760],\n",
            "        [ 1.2207,  0.7130, -0.2728,  ..., -1.3821, -0.1876, -1.7648],\n",
            "        ...,\n",
            "        [ 3.9668,  3.0550, -0.8455,  ...,  0.4456,  1.5875, -1.7188],\n",
            "        [ 4.2545,  2.4472, -1.9858,  ...,  0.4690,  1.3180, -1.5826],\n",
            "        [ 0.6163,  1.2962, -2.1898,  ...,  0.6069,  1.8880, -0.8585]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1834,  2.9462, -0.8157,  ...,  0.1055,  2.1309,  2.0204],\n",
            "        [ 0.7786, -0.5088,  1.4751,  ..., -1.1182,  3.9857, -0.1741],\n",
            "        [ 4.8223,  4.0388, -2.2212,  ..., -1.3282,  1.8951, -0.9152],\n",
            "        ...,\n",
            "        [ 1.5630,  3.0172, -0.9780,  ..., -0.7842,  3.2789,  0.7018],\n",
            "        [ 2.2333,  3.1267,  3.6662,  ..., -2.7059,  1.1496,  0.9283],\n",
            "        [ 1.2350, -0.2669,  0.4920,  ..., -2.0041,  1.6904, -3.2608]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.4594,  1.4206, -2.5974,  ..., -1.3067,  0.8181, -1.8835],\n",
            "        [ 0.1662,  2.6456, -3.6271,  ..., -1.8674,  0.6770, -1.7865],\n",
            "        [ 1.2931,  3.9257,  1.7303,  ...,  0.5247,  1.5216, -0.5660],\n",
            "        ...,\n",
            "        [ 1.0358, -1.0459,  2.8800,  ..., -0.9505,  3.4047, -1.1450],\n",
            "        [-0.0146,  2.1510, -2.4470,  ..., -1.8894,  0.5647, -1.1240],\n",
            "        [ 0.1573,  4.2138,  0.4364,  ..., -0.8289,  3.8483, -0.2718]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5096,  4.4559, -1.1954,  ..., -0.3647,  2.1032,  0.6324],\n",
            "        [ 2.5753,  0.8250, -2.5961,  ...,  0.5272,  0.4624, -1.1849],\n",
            "        [-0.1690,  1.9548, -1.9914,  ..., -2.3039, -0.5410, -2.0860],\n",
            "        ...,\n",
            "        [-2.8892,  2.5911, -1.0077,  ..., -1.4211,  3.5148,  0.5528],\n",
            "        [ 4.4411,  4.0955, -1.2383,  ..., -0.4565,  1.7185, -0.6641],\n",
            "        [ 1.6557,  2.0764, -1.6712,  ..., -0.4243,  2.0975,  0.5195]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4553,  1.6333,  3.8033,  ..., -0.8530,  4.0600,  0.8806],\n",
            "        [-1.2611,  0.9489,  0.8456,  ...,  0.4650,  4.4030,  0.0560],\n",
            "        [-0.8405, -0.7242,  4.0919,  ...,  1.4705,  4.2705, -1.7384],\n",
            "        ...,\n",
            "        [ 0.7122,  5.1165, -1.3937,  ..., -1.0638,  0.8846, -1.2555],\n",
            "        [ 2.2768,  4.8998, -4.4594,  ..., -1.4931, -1.2669,  0.3172],\n",
            "        [ 3.7292,  0.7371,  1.3342,  ..., -1.4064,  2.8205, -5.1231]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6742,  1.4855,  1.9365,  ..., -0.9652, -1.0405, -0.3782],\n",
            "        [ 1.7421,  1.0810, -1.5774,  ...,  0.0392,  1.9123, -1.0202],\n",
            "        [ 1.6116,  1.4468,  0.9999,  ..., -2.5336,  0.5780, -2.5221],\n",
            "        ...,\n",
            "        [ 3.0299,  1.3074, -0.5538,  ...,  1.1713,  3.1304, -1.0670],\n",
            "        [ 1.0723,  3.0790, -1.5787,  ...,  0.3847,  1.7274,  0.8438],\n",
            "        [ 2.3848,  0.4457,  0.0633,  ..., -0.1021,  2.5143, -2.1577]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3165,  4.1727, -3.0700,  ...,  0.3178,  0.3928,  0.1823],\n",
            "        [ 0.3419,  3.8003, -4.5222,  ..., -1.5428,  1.6866, -0.6294],\n",
            "        [ 1.0184,  2.6509, -3.1899,  ..., -1.3160,  2.9718,  0.4562],\n",
            "        ...,\n",
            "        [ 1.5374,  1.6923,  1.7666,  ..., -1.3845,  2.0594,  0.2919],\n",
            "        [ 5.3004,  5.5859, -1.1703,  ..., -1.0521, -1.3634, -0.0481],\n",
            "        [-1.5758,  2.1458, -0.3626,  ..., -0.4379,  3.8901,  0.3648]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0056,  2.3080, -0.2435,  ..., -0.3979,  2.3698,  0.6405],\n",
            "        [ 1.8952,  2.7920, -0.8549,  ..., -0.0286, -2.0240,  1.6102],\n",
            "        [-0.1174,  3.6355, -3.3161,  ..., -2.1127,  0.9280, -1.1597],\n",
            "        ...,\n",
            "        [ 2.2876,  3.4724,  2.0076,  ...,  0.0162,  1.6859, -0.3160],\n",
            "        [ 2.0589,  3.6414, -3.2264,  ..., -0.6191,  1.5475, -1.1961],\n",
            "        [ 1.2433,  2.8198,  2.3855,  ...,  2.6444,  2.6830,  1.1982]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5355,  2.8457, -0.8747,  ...,  0.6769,  4.2008, -0.8905],\n",
            "        [ 2.4788,  2.0469, -2.8539,  ..., -1.3051,  3.5000, -3.4430],\n",
            "        [-0.4732,  2.9618, -2.4319,  ..., -2.0735,  0.7817, -0.8416],\n",
            "        ...,\n",
            "        [ 1.1023,  2.8565, -4.3311,  ..., -2.0230,  2.6524,  0.1300],\n",
            "        [ 3.8121,  1.8802, -0.5478,  ...,  0.7789,  2.5924, -0.4121],\n",
            "        [ 2.1085, -0.4048,  1.8755,  ...,  2.0098,  3.1745, -0.4133]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.4007,  2.3811, -2.1331,  ..., -1.2076,  0.3530, -0.1508],\n",
            "        [ 0.1104,  3.1899, -1.2185,  ...,  0.8936,  2.6891,  1.0906],\n",
            "        [ 3.3066,  4.6241, -1.2183,  ..., -0.5405,  0.5053, -1.5611],\n",
            "        ...,\n",
            "        [ 1.7124,  0.9470,  1.0234,  ...,  0.6199,  1.4545,  1.4502],\n",
            "        [ 0.6411,  6.0294, -3.1845,  ..., -1.6888, -1.7552,  1.3130],\n",
            "        [ 2.2352,  0.4404,  0.4811,  ..., -0.1973,  2.4774, -0.3089]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7443, -1.1042,  2.9723,  ...,  0.8831,  2.8294, -0.3692],\n",
            "        [ 0.7192,  1.4011, -1.4396,  ..., -0.4771,  3.8879,  2.5625],\n",
            "        [ 5.4193,  1.7983, -3.2666,  ..., -1.5022, -0.0493,  1.1064],\n",
            "        ...,\n",
            "        [ 1.5208,  0.0244, -2.9606,  ...,  1.3603,  2.6042,  0.2108],\n",
            "        [-0.3054,  0.2745,  1.0465,  ...,  1.2692,  3.5741, -0.5315],\n",
            "        [-0.2522, -0.0718,  0.6630,  ...,  0.4679,  0.1777, -1.4426]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2993,  2.1884,  1.1707,  ...,  0.4244,  0.0758,  0.6944],\n",
            "        [ 3.1584,  0.4234,  0.4842,  ..., -1.5544,  1.8456, -0.5486],\n",
            "        [ 1.4325,  6.0252, -2.8802,  ..., -0.6051,  0.3867, -1.2538],\n",
            "        ...,\n",
            "        [ 1.4641,  3.9181, -0.2048,  ..., -0.5804,  2.5050,  2.6333],\n",
            "        [ 4.6774,  2.2686,  1.3333,  ...,  1.3171,  1.8366, -0.0468],\n",
            "        [-0.2036,  0.2866,  2.0500,  ...,  1.4191,  2.5986, -1.0277]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9859,  1.1317, -0.6485,  ..., -0.6115,  0.3909, -1.1859],\n",
            "        [-0.2643,  1.7877,  0.2741,  ...,  0.4188,  3.7307,  1.4590],\n",
            "        [ 0.1043,  6.4719, -0.4518,  ..., -1.7015, -0.5345,  3.7888],\n",
            "        ...,\n",
            "        [ 3.3034,  1.0138, -0.3613,  ...,  0.1981,  4.4238, -0.2141],\n",
            "        [ 2.1557,  5.0020, -1.8227,  ..., -0.7490,  2.2811,  2.9165],\n",
            "        [ 2.2532, -0.1483,  2.4964,  ..., -0.1198,  2.6947,  0.1272]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6413,  2.0963, -2.5520,  ..., -1.2578,  0.9624, -0.0904],\n",
            "        [ 1.0801,  1.1357,  1.1841,  ...,  0.0865,  1.5395, -1.2033],\n",
            "        [ 2.5893, -0.6016, -3.1490,  ..., -0.9831,  3.5193,  0.2135],\n",
            "        ...,\n",
            "        [ 0.7364,  1.6874, -1.7666,  ..., -1.6363, -0.5657, -0.5053],\n",
            "        [-1.0852,  1.6048,  2.4404,  ...,  2.2991,  3.7094,  0.0042],\n",
            "        [-0.6003,  1.8680, -2.6824,  ..., -1.7461,  1.2510, -0.5634]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3875,  3.4491, -5.7499,  ..., -0.0243, -0.1567, -0.4161],\n",
            "        [ 2.7056, -1.6849, -0.2120,  ...,  0.0105,  2.2661, -0.8703],\n",
            "        [ 1.8124,  1.7962, -0.7141,  ..., -1.1191,  1.3736, -0.5168],\n",
            "        ...,\n",
            "        [ 1.6853,  3.3148, -1.7769,  ...,  0.4672,  0.6415, -0.7908],\n",
            "        [ 1.5036,  4.4732,  0.8910,  ..., -1.1596,  1.8151,  0.1378],\n",
            "        [-0.8574,  2.6526, -1.7695,  ..., -1.3419,  0.5411, -0.6741]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7371, -0.3394,  0.3302,  ..., -1.1268,  2.6515, -0.3184],\n",
            "        [ 0.1906,  2.7582,  5.0924,  ...,  1.0242,  1.8237, -0.2419],\n",
            "        [-0.6946,  1.8153, -1.9760,  ..., -1.8167,  0.5019, -0.9915],\n",
            "        ...,\n",
            "        [ 0.6993, -0.4613,  4.5130,  ...,  2.2380,  5.0276, -1.4581],\n",
            "        [-1.5691,  2.0092, -1.4582,  ..., -0.6745, -0.1993,  0.8158],\n",
            "        [ 3.5640,  4.0342, -3.5086,  ..., -1.7485, -1.1726,  0.4794]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 7.6250e-01,  4.4891e+00, -1.5085e+00,  ...,  1.7989e-01,\n",
            "          1.3071e+00,  2.9751e-01],\n",
            "        [-2.5401e-01,  1.4375e+00, -1.5840e+00,  ...,  1.5616e+00,\n",
            "          3.8129e+00,  1.8135e+00],\n",
            "        [ 9.5008e-01, -2.6105e-01, -1.6748e+00,  ..., -2.9757e-01,\n",
            "          1.0866e+00, -1.5002e+00],\n",
            "        ...,\n",
            "        [ 1.7084e+00,  1.2559e+00,  4.5707e+00,  ..., -1.8051e+00,\n",
            "          1.6365e+00, -1.7394e-01],\n",
            "        [ 1.1716e+00,  4.9187e+00,  2.1969e-03,  ...,  5.8761e-02,\n",
            "          3.2800e-01,  1.7824e+00],\n",
            "        [-9.2292e-01,  1.9437e+00,  3.9293e-01,  ..., -5.5430e-01,\n",
            "          8.4042e-01, -2.6925e-02]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2933,  0.9967,  1.9305,  ..., -1.9251,  3.1866,  0.5069],\n",
            "        [ 1.8232,  1.3967,  2.1159,  ..., -0.9509,  0.2316,  0.0898],\n",
            "        [ 2.7818,  0.7649, -1.4823,  ..., -0.1855,  2.7240,  1.7784],\n",
            "        ...,\n",
            "        [ 0.0582,  6.3459, -0.5822,  ...,  0.7996,  0.5083,  4.0965],\n",
            "        [ 0.3877,  2.7215, -3.0246,  ..., -1.7428,  0.1128, -0.8039],\n",
            "        [ 2.2180,  4.9981,  1.1825,  ..., -1.3887, -0.1700,  4.1360]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1061,  3.5064, -2.4311,  ..., -0.3813,  0.6003,  4.9712],\n",
            "        [ 0.3492,  2.7998,  1.7134,  ...,  0.8835,  1.6516,  1.5350],\n",
            "        [-2.1213,  3.5482, -0.1952,  ...,  2.6292,  3.7838,  1.4366],\n",
            "        ...,\n",
            "        [-0.3447,  3.2827,  0.2523,  ...,  1.2545,  3.7525,  1.6592],\n",
            "        [ 1.9763, -0.5091,  2.4125,  ...,  0.4615,  3.8762,  0.0791],\n",
            "        [-0.9557,  1.0310, -0.7206,  ..., -0.2031,  0.8421, -1.3531]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4583,  3.9842,  0.5646,  ...,  1.5353,  3.8436,  1.3327],\n",
            "        [-1.0889,  0.9743, -0.4565,  ..., -0.2977,  0.4197, -1.2029],\n",
            "        [-0.7718,  3.8546, -1.1694,  ...,  0.4038,  3.9266,  2.1969],\n",
            "        ...,\n",
            "        [-0.9979,  0.2423,  0.3829,  ..., -0.4119,  1.9170, -0.1932],\n",
            "        [-1.1085,  5.5978, -0.0318,  ...,  0.0994,  1.8792,  2.8836],\n",
            "        [ 0.5254,  0.6300,  2.4311,  ...,  0.6231,  3.5406,  1.7932]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2550,  3.5746, -3.8842,  ..., -1.4047,  3.4296,  0.5397],\n",
            "        [-0.6979,  4.1123,  3.4357,  ..., -1.0700,  1.3114, -0.1225],\n",
            "        [-0.4487,  2.4285, -2.8129,  ..., -1.7418,  0.9943, -0.8804],\n",
            "        ...,\n",
            "        [ 2.9931,  1.2253, -3.2787,  ..., -1.3563,  2.8791, -2.3903],\n",
            "        [ 0.9410, -0.0800,  3.6068,  ...,  0.3577,  4.1118, -0.9422],\n",
            "        [ 0.6626,  5.6749, -4.0216,  ...,  0.4490,  4.6300,  3.6715]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8331,  1.8630, -1.1204,  ..., -0.7955,  0.4376, -0.6769],\n",
            "        [-0.4382,  2.3488, -2.3336,  ..., -0.8514,  1.0872, -0.7141],\n",
            "        [ 2.3315,  3.2781,  1.2009,  ..., -0.4196, -1.6248, -0.1283],\n",
            "        ...,\n",
            "        [ 2.8584,  1.5750, -0.1306,  ..., -1.2821, -0.5715,  0.2036],\n",
            "        [-0.8593,  1.0444, -0.2087,  ...,  0.0544, -0.1052, -1.5301],\n",
            "        [-1.8669,  4.6246, -1.4156,  ..., -1.9368,  2.6792,  1.9013]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2057e+00,  5.3994e+00, -1.3242e+00,  ..., -1.1553e+00,\n",
            "          3.0382e-01,  1.6125e+00],\n",
            "        [ 1.1285e-01,  3.4117e+00, -1.9605e+00,  ..., -1.0447e+00,\n",
            "          2.9603e+00,  2.9339e-03],\n",
            "        [ 1.3242e+00,  1.7065e+00, -1.3886e+00,  ...,  1.3846e+00,\n",
            "          3.5378e+00,  6.9906e-01],\n",
            "        ...,\n",
            "        [ 2.3302e+00,  2.8700e-01,  3.5839e-01,  ..., -1.2985e+00,\n",
            "          1.7697e+00, -2.3483e+00],\n",
            "        [-3.1188e-01,  2.7281e+00, -3.5533e+00,  ..., -2.1601e+00,\n",
            "          2.0527e+00, -5.4682e-01],\n",
            "        [ 2.9975e+00,  3.2415e-01, -1.6927e-01,  ..., -4.4623e-01,\n",
            "          1.0175e+00, -1.1287e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3693,  4.3334, -3.0407,  ..., -2.8844,  1.5638,  0.9397],\n",
            "        [ 3.8255,  0.8059, -2.4571,  ..., -1.3557, -0.3172, -0.9731],\n",
            "        [ 1.2113, -0.7150,  1.7105,  ..., -0.7593,  3.8235,  1.0531],\n",
            "        ...,\n",
            "        [ 4.6980,  0.4950, -2.0480,  ..., -1.2593,  2.3552, -1.0481],\n",
            "        [ 0.9635,  5.9639, -0.4794,  ..., -0.3947, -0.0900,  0.9162],\n",
            "        [ 0.9604,  3.9976, -0.8850,  ..., -0.5833,  2.3613,  1.9260]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9452, -0.1738, -1.5911,  ..., -1.0538,  3.7498, -0.6226],\n",
            "        [ 3.1543,  0.6264,  0.0784,  ..., -0.8833,  2.6446, -1.7348],\n",
            "        [-0.1883,  1.9411, -0.1801,  ...,  0.5061,  3.5388,  1.8922],\n",
            "        ...,\n",
            "        [ 1.3818,  3.0331, -2.0544,  ...,  0.7941,  1.6131,  0.6612],\n",
            "        [ 3.0996,  2.5863, -1.9395,  ..., -3.2246, -1.3682, -0.6654],\n",
            "        [ 3.1868,  2.6984, -0.5141,  ..., -1.4171, -0.1656,  1.4323]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6637,  3.3913, -0.1373,  ...,  2.3414,  3.7500,  2.1113],\n",
            "        [-0.3991,  5.4227,  0.3338,  ..., -2.0871,  2.9367,  3.5586],\n",
            "        [-0.6449,  0.8845, -1.4366,  ..., -0.4370,  1.8060,  1.0527],\n",
            "        ...,\n",
            "        [-0.4460,  1.6525,  1.1288,  ...,  0.9104,  0.0664, -0.6432],\n",
            "        [-0.4233,  3.6013, -1.4701,  ...,  0.2341,  2.7427,  0.7997],\n",
            "        [ 3.8170,  0.1946, -2.0369,  ..., -0.1288,  2.7181, -1.6044]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3945,  1.2329,  4.2459,  ...,  0.5871,  1.4383, -0.7800],\n",
            "        [ 1.9312,  6.3575,  0.6032,  ..., -0.8882,  1.7343,  2.8811],\n",
            "        [-0.7914,  0.2884,  0.1656,  ..., -0.5074,  0.2408, -0.2971],\n",
            "        ...,\n",
            "        [ 2.0315,  3.0065, -2.9616,  ...,  0.7279,  1.1263, -0.2577],\n",
            "        [-2.0645,  3.0846,  0.4707,  ...,  0.1617,  2.2524,  0.8689],\n",
            "        [ 1.3357,  2.0268,  2.1816,  ...,  1.6417,  1.4563,  3.4662]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1511, -0.8009, -0.4875,  ...,  0.5568,  1.7173, -0.0506],\n",
            "        [-1.1021,  3.0436,  0.1765,  ..., -0.5956, -0.2564,  2.1859],\n",
            "        [-0.3158,  3.3211, -2.3225,  ..., -1.7250,  0.4728, -0.6735],\n",
            "        ...,\n",
            "        [ 2.0782,  2.1828,  0.8114,  ..., -0.9004,  2.8140, -0.3955],\n",
            "        [ 0.2988,  3.1659, -2.5004,  ..., -1.6991, -0.1367, -1.3067],\n",
            "        [ 0.9672,  0.9361, -1.5966,  ..., -1.3162,  2.1599, -1.5064]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7560,  1.7581,  1.1670,  ...,  1.2334,  1.3188, -1.1628],\n",
            "        [ 2.8270, -0.4512,  1.3412,  ..., -0.0762,  3.2302,  0.0383],\n",
            "        [ 0.4528,  1.3450, -1.0364,  ..., -0.1393,  1.6227, -2.0954],\n",
            "        ...,\n",
            "        [-0.1015,  2.1046,  0.5720,  ...,  0.8882,  3.7038, -0.6592],\n",
            "        [ 4.4838,  0.3226, -3.1891,  ..., -1.3842,  3.2184,  0.3245],\n",
            "        [-0.7604,  1.1117,  4.4609,  ...,  0.9189,  2.8361, -0.1166]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5119,  1.8201,  2.3289,  ..., -1.5384, -1.4833, -0.5358],\n",
            "        [ 6.6748,  1.1100, -3.0951,  ...,  1.0991,  0.9102, -0.2208],\n",
            "        [ 0.8626,  4.8495,  1.0939,  ...,  2.5500,  1.7234,  0.4995],\n",
            "        ...,\n",
            "        [-0.3873, -0.8706,  4.8399,  ..., -0.0760,  3.3003, -2.1990],\n",
            "        [ 2.1912,  2.0483,  5.1086,  ..., -1.2740,  1.4902,  1.7428],\n",
            "        [-1.4766,  3.3057,  1.0192,  ...,  0.1332,  2.3905,  3.8867]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2017,  1.4746,  3.0890,  ..., -0.4027,  3.9062,  0.2218],\n",
            "        [ 0.3037,  0.5499,  1.6510,  ...,  0.2128,  4.6925,  1.5791],\n",
            "        [ 1.4964,  1.3168, -2.3683,  ...,  0.8254,  3.5795,  2.7594],\n",
            "        ...,\n",
            "        [ 2.3639, -0.5038,  1.3815,  ...,  0.0792,  1.7636, -0.3046],\n",
            "        [ 2.9010,  4.3226, -0.4519,  ..., -0.1803,  1.0861,  2.0553],\n",
            "        [-0.3001,  1.0716, -0.8835,  ..., -0.3064,  0.3787, -0.7394]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6710,  4.2042, -2.8715,  ..., -1.6362,  0.3482,  0.3333],\n",
            "        [ 3.7171,  2.1792, -3.2997,  ...,  0.4859,  3.6395, -1.6569],\n",
            "        [ 4.0473,  3.6175, -4.3596,  ..., -1.3216,  4.0006, -0.5368],\n",
            "        ...,\n",
            "        [-0.3984,  4.2092,  2.5295,  ...,  1.0103,  2.1396,  0.7018],\n",
            "        [ 2.7253,  3.2270,  2.2529,  ..., -1.5988,  1.5190,  2.6604],\n",
            "        [ 2.8741,  2.3843, -1.8417,  ..., -2.3277,  1.3020,  0.5759]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2204,  0.7019, -0.9972,  ..., -0.0070,  3.9291,  0.5362],\n",
            "        [ 2.1885,  2.4699,  0.4302,  ..., -1.4747,  1.2436, -1.4572],\n",
            "        [ 5.6904,  2.5822,  0.7471,  ..., -1.2670, -1.5766,  1.9404],\n",
            "        ...,\n",
            "        [ 3.1027,  4.2875, -1.6860,  ..., -3.0549,  1.8370,  0.3582],\n",
            "        [-1.9157,  2.7701, -0.9471,  ...,  1.2027,  2.1960,  1.6861],\n",
            "        [ 5.3241, -0.3804, -1.6021,  ..., -0.3216,  0.6355, -2.0271]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5334,  3.1460,  5.9683,  ..., -0.5026,  1.3439,  1.7665],\n",
            "        [ 3.5772,  6.3814,  0.6975,  ..., -2.4681,  0.2438,  2.5160],\n",
            "        [ 3.4194, -0.9635,  2.1385,  ...,  0.8841,  2.8044, -0.2181],\n",
            "        ...,\n",
            "        [ 0.3392,  1.3973,  1.9750,  ..., -0.6322,  3.9096, -1.7461],\n",
            "        [ 1.3555,  0.9706,  0.7884,  ...,  0.8661,  1.8865,  0.0725],\n",
            "        [ 2.8650,  3.2792, -1.6595,  ...,  0.5082,  2.0432, -0.2882]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5675e+00,  3.1525e+00, -8.6073e-01,  ..., -2.0398e+00,\n",
            "         -7.0575e-01,  9.9110e-01],\n",
            "        [ 3.4158e+00,  4.1664e-01,  7.7466e-01,  ...,  6.4207e-01,\n",
            "          2.2607e+00, -2.5781e-01],\n",
            "        [ 2.3081e+00,  1.2872e+00, -1.5250e+00,  ...,  6.0227e-01,\n",
            "          2.5544e+00, -5.9336e-01],\n",
            "        ...,\n",
            "        [ 3.1570e+00,  2.8073e+00,  2.4176e+00,  ...,  2.7938e-01,\n",
            "          8.7267e-01, -1.2769e+00],\n",
            "        [ 8.1812e-01,  5.4350e+00,  3.2249e+00,  ...,  1.9745e+00,\n",
            "          1.6377e+00,  1.2716e+00],\n",
            "        [ 1.0454e+00,  7.8683e-01,  1.0043e+00,  ..., -1.2204e-01,\n",
            "         -5.2662e-04, -1.9208e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8404,  1.9916,  1.0485,  ..., -0.4223,  3.6974, -1.9808],\n",
            "        [ 2.0320,  4.4961,  1.4033,  ..., -0.9803, -0.1863,  1.6314],\n",
            "        [ 3.6426,  2.7404,  1.1389,  ..., -1.7437,  2.2620,  1.7878],\n",
            "        ...,\n",
            "        [ 1.8180,  0.9080, -0.9067,  ..., -0.1525,  5.1934,  2.5734],\n",
            "        [ 1.6932,  2.6309, -1.8720,  ...,  0.3067,  4.2153,  1.2496],\n",
            "        [ 4.3398,  0.1452,  0.8250,  ..., -1.4096, -0.7102, -1.1993]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2369,  3.3328, -0.3116,  ..., -0.9425,  1.1873,  1.3638],\n",
            "        [ 4.1994,  2.9021,  0.5819,  ..., -1.9624,  1.9175, -4.6008],\n",
            "        [-1.7807,  6.0841,  0.0431,  ...,  0.5241,  2.1189,  2.4206],\n",
            "        ...,\n",
            "        [-0.0634,  2.0122, -2.1022,  ...,  0.9176,  2.8078, -0.4272],\n",
            "        [ 4.3341,  1.7504, -1.7378,  ..., -0.6355,  2.0301,  1.4584],\n",
            "        [ 0.9770,  3.3825,  0.8893,  ...,  1.3728,  3.6686,  1.4101]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1488e+00,  3.7251e+00, -2.4304e+00,  ..., -5.6242e-01,\n",
            "          1.7006e+00,  2.6046e-01],\n",
            "        [ 2.0606e-01,  6.2863e+00,  2.5908e+00,  ...,  8.3622e-01,\n",
            "          1.0898e+00,  2.2307e-01],\n",
            "        [ 3.1435e+00,  6.4481e-01,  1.8948e+00,  ..., -1.0517e+00,\n",
            "          1.8230e+00, -2.3147e+00],\n",
            "        ...,\n",
            "        [-1.4276e+00, -1.0596e+00,  2.0871e+00,  ..., -1.4896e+00,\n",
            "          4.8010e-01, -2.0209e+00],\n",
            "        [ 1.5501e+00,  6.7084e+00, -7.5712e-01,  ..., -9.5718e-01,\n",
            "          4.8324e-03,  1.3979e+00],\n",
            "        [ 1.3897e+00,  5.7717e+00,  2.4296e+00,  ...,  6.3915e-01,\n",
            "          2.1698e+00,  2.6925e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2105,  3.2494, -3.7368,  ..., -1.7474,  0.6622, -0.2657],\n",
            "        [ 1.4095, -0.7205,  3.1849,  ...,  2.2299,  3.8472,  0.0791],\n",
            "        [-0.4452, -0.1261,  2.7162,  ..., -1.7601,  1.3608,  0.9498],\n",
            "        ...,\n",
            "        [ 1.6731,  5.6588, -2.2854,  ...,  1.8510,  4.0794,  2.9960],\n",
            "        [ 2.2829,  3.3367, -1.9327,  ...,  0.4376,  0.0068,  1.5492],\n",
            "        [ 0.8673,  1.7268,  1.3736,  ...,  0.1594,  0.4891,  0.7905]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0718,  3.4478, -0.2056,  ..., -1.1263, -1.5548,  0.9537],\n",
            "        [ 0.3974,  0.7945,  0.0168,  ...,  0.0382, -0.3458, -1.4578],\n",
            "        [-0.0562,  7.7772, -1.3164,  ..., -1.5086,  0.1015,  3.7312],\n",
            "        ...,\n",
            "        [ 1.1621,  1.8282,  0.7588,  ...,  0.7303,  4.9406,  3.0155],\n",
            "        [ 2.8020,  2.3730,  2.9665,  ..., -0.7015, -0.7230, -0.3013],\n",
            "        [-1.2457,  4.3175, -0.3434,  ...,  0.3420,  0.4777,  1.6351]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5988, -0.4254,  4.0584,  ...,  1.3407,  3.1845, -0.5894],\n",
            "        [ 1.3304,  4.4516, -4.3103,  ..., -0.5273,  0.8153,  1.1108],\n",
            "        [ 3.2787,  4.8591, -0.1170,  ..., -0.8264, -0.8481,  1.5780],\n",
            "        ...,\n",
            "        [ 2.4723,  1.5967, -0.3144,  ..., -1.9657,  4.8610, -0.7928],\n",
            "        [-0.4773,  1.3373, -1.8659,  ..., -0.2959,  0.8047, -0.9759],\n",
            "        [ 0.0479,  5.0060,  0.0236,  ...,  1.2265, -0.8487,  2.3436]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5964,  4.7728,  0.1053,  ..., -1.1360,  3.0149,  3.7841],\n",
            "        [ 1.4944,  1.4983, -0.2244,  ..., -2.8244, -0.9218, -1.1105],\n",
            "        [ 1.6813,  3.8696, -1.7520,  ...,  0.7671,  3.0801,  1.2349],\n",
            "        ...,\n",
            "        [ 1.4290,  5.0230, -2.5798,  ..., -1.3335, -0.4072,  0.5577],\n",
            "        [-0.8911,  2.6728, -1.3568,  ..., -1.0374,  0.9366, -0.0675],\n",
            "        [ 1.3517,  1.8220, -3.4473,  ..., -1.5165,  1.7250, -1.1980]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1962,  4.1614,  0.0424,  ...,  1.3967,  1.3707,  0.3316],\n",
            "        [-0.4539,  5.8771, -5.1752,  ..., -1.9418,  2.2884,  1.4693],\n",
            "        [ 1.5288,  2.7726,  0.7105,  ...,  0.6368,  2.4340,  1.3949],\n",
            "        ...,\n",
            "        [-0.3215,  3.8690, -2.0083,  ...,  0.9240,  3.9820,  1.9875],\n",
            "        [-1.4659,  1.2710,  4.5649,  ...,  0.9521,  2.6772, -0.0506],\n",
            "        [ 2.1544,  4.5249,  0.2932,  ..., -0.3047,  0.4017,  2.8889]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3792,  3.2343,  0.4751,  ..., -1.6646, -2.7068,  1.1511],\n",
            "        [ 2.3352,  1.6504, -1.7102,  ...,  0.2306,  5.8943,  0.6836],\n",
            "        [ 1.2337,  0.9389, -1.4677,  ...,  0.2729,  3.4877, -0.7625],\n",
            "        ...,\n",
            "        [ 1.6010,  3.0590, -4.9931,  ...,  0.5774,  2.2910,  1.1930],\n",
            "        [ 4.0599,  2.1141, -2.2359,  ...,  0.0320,  5.5089,  1.1929],\n",
            "        [ 3.4405,  1.2731, -0.1261,  ..., -1.5195,  0.1926,  0.6429]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6962,  3.1077,  1.3406,  ...,  1.6320,  3.4421,  1.6609],\n",
            "        [ 1.2422,  5.3371, -2.2205,  ...,  0.5152, -1.9243,  2.2001],\n",
            "        [ 1.1803,  4.3435, -0.9179,  ..., -1.6633,  2.2663,  2.2994],\n",
            "        ...,\n",
            "        [ 0.8131,  1.7386,  1.7773,  ...,  0.0889,  2.0698,  0.3183],\n",
            "        [ 2.4482,  0.6284,  1.2414,  ...,  1.2433,  3.8665, -0.3713],\n",
            "        [ 5.0910,  3.5715, -3.8039,  ...,  0.1173,  3.6720, -1.1353]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7704,  4.7310, -5.5683,  ..., -2.0457,  0.9948,  0.4701],\n",
            "        [ 0.1554,  2.1768, -1.4081,  ..., -0.0900,  5.4382,  1.4290],\n",
            "        [ 1.7787,  4.0545, -3.5943,  ..., -1.6237,  2.7693,  1.6287],\n",
            "        ...,\n",
            "        [ 0.7540,  3.9046,  1.1578,  ...,  0.7076,  2.1164,  0.6480],\n",
            "        [-0.9838,  5.5500, -1.7760,  ..., -0.1214,  2.4890,  3.9071],\n",
            "        [ 0.4550,  4.6436,  2.1547,  ...,  0.5898,  3.2178,  1.2554]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7660,  3.3267,  0.7620,  ...,  2.1604,  2.7114, -0.0876],\n",
            "        [ 0.1603,  4.1429, -0.9349,  ..., -0.2627,  1.6599,  0.3033],\n",
            "        [ 0.1079,  2.9004, -3.6193,  ..., -1.7425,  0.9432, -0.8801],\n",
            "        ...,\n",
            "        [ 3.1014,  0.8213, -1.1419,  ..., -0.6614,  0.4736, -0.4622],\n",
            "        [ 2.3669,  3.8528, -2.1303,  ..., -2.5931,  0.1136, -1.2163],\n",
            "        [ 0.0119,  7.5572, -1.0222,  ..., -1.3172,  0.8846,  1.9778]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1587,  1.3252,  1.5554,  ...,  1.1026,  3.4117,  1.3995],\n",
            "        [ 1.1111,  4.4643, -1.3525,  ..., -2.4455, -0.6713, -1.6214],\n",
            "        [ 0.7760,  1.8331, -4.4993,  ...,  0.6667,  0.5937,  0.4354],\n",
            "        ...,\n",
            "        [ 2.2679,  6.1516, -1.3577,  ..., -0.8112,  0.1474,  2.8188],\n",
            "        [ 1.6665,  3.7811, -0.5796,  ..., -0.5690,  2.7585,  4.2163],\n",
            "        [ 0.3950,  0.7710,  5.3447,  ...,  1.5029,  3.7811,  0.0450]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7436,  1.2897,  2.5622,  ..., -1.0970,  2.0942,  0.1846],\n",
            "        [ 2.6268,  1.0491, -3.5876,  ...,  1.7409,  3.6062,  1.6337],\n",
            "        [ 1.6205,  6.0897, -2.6739,  ..., -0.2330,  1.9858,  2.5482],\n",
            "        ...,\n",
            "        [ 1.8435,  0.6890, -0.3851,  ...,  0.3708,  2.0129,  0.0669],\n",
            "        [ 1.7728,  3.8456, -2.7364,  ...,  1.7174,  0.8564,  0.6162],\n",
            "        [ 1.6233,  4.3411,  0.9145,  ...,  2.1170,  1.1677, -0.3010]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.4263,  2.5082,  0.5445,  ..., -0.7505,  1.1852, -1.5131],\n",
            "        [ 3.0207,  4.4847, -0.8191,  ..., -0.5363,  1.7030,  2.3750],\n",
            "        [ 3.9509,  2.6398,  1.0236,  ..., -3.9341,  2.5562,  1.5271],\n",
            "        ...,\n",
            "        [ 3.7617,  2.2517, -4.0841,  ..., -1.0441,  4.3142,  0.0516],\n",
            "        [ 0.4936,  4.1229, -2.1351,  ...,  1.0702,  0.3159,  1.3156],\n",
            "        [ 3.3179,  4.0979,  0.4195,  ..., -2.6578,  3.3436, -0.7488]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3559,  3.0343, -3.7425,  ..., -1.7200,  1.0268, -1.5737],\n",
            "        [ 1.5615,  4.4215, -3.1307,  ...,  0.5210,  2.2927,  4.5272],\n",
            "        [ 0.0209,  1.1539,  2.7341,  ...,  1.0335,  4.5193,  1.0585],\n",
            "        ...,\n",
            "        [-0.6316,  3.3276, -2.0574,  ...,  0.3111,  1.7288,  0.6492],\n",
            "        [ 0.6742,  2.7486, -5.0526,  ..., -0.1253,  3.2609,  1.4117],\n",
            "        [ 0.3906,  3.2319, -3.6617,  ..., -1.3504,  3.4660,  0.0686]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2924,  4.8443,  4.1575,  ...,  2.1582,  2.6255,  2.0120],\n",
            "        [ 0.9155,  0.7837,  2.6674,  ..., -0.6136,  1.2791, -0.3302],\n",
            "        [ 0.8922,  3.1321,  4.3583,  ..., -0.5358,  2.3343,  0.8317],\n",
            "        ...,\n",
            "        [ 2.6944,  6.6580, -0.8895,  ...,  0.0605,  1.5679,  3.3561],\n",
            "        [ 1.1125,  4.0885, -4.7966,  ..., -0.1127,  2.9228,  3.0072],\n",
            "        [-0.8177,  3.1666, -2.1031,  ..., -1.6318,  0.5044, -0.4203]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7203,  4.8989, -6.3920,  ..., -0.7994,  1.7189,  1.4292],\n",
            "        [ 1.4196,  0.4637,  1.3828,  ...,  0.5357,  1.8299, -1.6361],\n",
            "        [ 1.4280,  2.0186, -2.8093,  ..., -0.6550,  1.8236, -0.0273],\n",
            "        ...,\n",
            "        [-0.1574,  3.8560, -1.2624,  ...,  0.9837,  5.8882,  3.5705],\n",
            "        [ 0.9556,  2.9312, -0.9232,  ...,  0.2682,  2.5795,  1.1203],\n",
            "        [ 0.3129,  0.4200,  0.5363,  ..., -1.1032,  2.1542,  1.9054]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4040,  1.2925, -0.9225,  ...,  1.0128,  3.6745,  1.8873],\n",
            "        [ 1.1306,  1.7518, -3.4888,  ...,  0.3285,  2.4730,  0.9213],\n",
            "        [ 4.8267,  0.5553,  3.3801,  ..., -0.4132,  3.2232, -1.0778],\n",
            "        ...,\n",
            "        [ 1.2559,  2.4088,  2.3156,  ...,  0.3694,  2.6807, -0.1987],\n",
            "        [ 0.0609,  3.7484, -4.8427,  ..., -1.1387,  1.6421, -0.2615],\n",
            "        [ 2.6405,  4.2484,  0.7552,  ..., -1.2313,  1.0803,  2.2630]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6778,  4.7588,  1.5455,  ..., -3.8880, -1.0964, -1.2981],\n",
            "        [ 4.1886,  2.1405,  3.8141,  ...,  0.9377,  2.6685,  0.5477],\n",
            "        [ 0.1594, -0.2180,  0.6790,  ...,  1.3231,  0.1131, -1.7335],\n",
            "        ...,\n",
            "        [-0.0456,  2.1234,  1.7586,  ...,  0.1920,  1.0417, -0.2632],\n",
            "        [ 3.9011,  2.2683,  0.3074,  ...,  1.9294,  0.3500, -1.6854],\n",
            "        [ 2.7272,  2.0344,  0.2003,  ...,  0.1677,  0.1885, -0.2622]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3887e+00,  1.5198e+00, -3.4320e+00,  ..., -1.1223e-01,\n",
            "          3.7306e+00,  9.8379e-01],\n",
            "        [-2.2048e-01,  3.6745e+00, -2.0027e+00,  ...,  7.6088e-01,\n",
            "          2.3736e+00,  7.3299e-01],\n",
            "        [ 5.4296e-01,  4.0397e+00, -1.7685e+00,  ..., -1.4519e+00,\n",
            "          1.1066e+00,  3.6003e+00],\n",
            "        ...,\n",
            "        [ 4.5370e-01,  3.8028e+00,  1.2983e+00,  ...,  1.1632e+00,\n",
            "          2.3364e+00,  1.6744e+00],\n",
            "        [ 7.3203e-01,  3.5308e+00, -4.5009e+00,  ..., -9.3399e-01,\n",
            "          6.0245e-01, -2.7284e-03],\n",
            "        [ 5.2922e-01,  2.9375e+00,  4.6000e+00,  ..., -8.0935e-01,\n",
            "          3.8498e+00,  1.1977e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3598,  3.2134,  2.3548,  ..., -0.9810, -0.3015,  0.2818],\n",
            "        [-0.6767,  5.3008,  0.6650,  ...,  3.0832,  2.9720,  2.6219],\n",
            "        [ 1.5581,  2.3166,  2.3811,  ..., -0.9786, -0.6670,  0.7271],\n",
            "        ...,\n",
            "        [ 4.1708,  5.2666, -3.3845,  ..., -1.0167,  0.9637,  1.3720],\n",
            "        [ 4.2872,  0.6633,  0.2658,  ..., -0.8871,  4.7571, -0.9142],\n",
            "        [ 1.8944,  3.0166, -2.5063,  ..., -0.3948,  3.2585,  2.7316]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1021, -0.1779,  1.0220,  ...,  0.5388,  1.1003, -2.0967],\n",
            "        [-0.9853,  2.3339, -0.8151,  ..., -0.3368,  2.6031,  0.3544],\n",
            "        [ 2.9199,  1.0176,  2.5870,  ...,  0.8490,  3.4566,  0.8959],\n",
            "        ...,\n",
            "        [-0.3896,  0.2163, -0.5623,  ...,  0.9224,  0.6670, -0.3840],\n",
            "        [ 0.6531,  0.8096,  0.8437,  ...,  0.1407,  2.8970,  1.2875],\n",
            "        [-0.3000,  1.3388,  5.0623,  ...,  0.8305,  3.3797, -0.4208]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2981,  0.7104, -0.1354,  ..., -0.9002, -1.3406, -0.8173],\n",
            "        [-0.0342,  2.5342, -2.0542,  ..., -1.2052, -0.3445, -0.8288],\n",
            "        [ 1.4764,  2.2331, -4.0442,  ...,  0.1347,  2.7767,  0.4314],\n",
            "        ...,\n",
            "        [ 1.0925,  2.9701,  0.3879,  ...,  2.8199,  4.4405,  2.7512],\n",
            "        [-0.6408,  2.7381,  4.2977,  ...,  1.2784,  3.7950,  2.3424],\n",
            "        [ 2.3957,  2.8711,  0.7664,  ...,  0.2246,  1.0398,  0.7310]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0697,  0.7641,  0.4689,  ...,  2.1673,  2.0587, -1.2294],\n",
            "        [ 0.6950,  3.2948, -3.1581,  ..., -1.3444,  0.3178,  0.1740],\n",
            "        [-1.0673,  2.3902, -1.7593,  ..., -0.9670,  0.1306, -0.5412],\n",
            "        ...,\n",
            "        [ 1.3556,  0.9270,  1.1034,  ...,  0.3642,  0.6959, -4.0888],\n",
            "        [ 1.1469,  2.6343, -2.5715,  ..., -1.2009,  2.1458,  1.7146],\n",
            "        [ 4.8288,  3.2868, -1.1592,  ..., -1.8417,  0.9200,  2.3632]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.7019,  0.8117,  0.1872,  ...,  1.8777,  0.2781, -0.5142],\n",
            "        [ 3.9596,  3.6870, -0.1239,  ..., -0.8335, -0.1869, -1.2496],\n",
            "        [ 4.1238,  6.6023, -4.7715,  ...,  0.0515,  4.6644,  1.6827],\n",
            "        ...,\n",
            "        [ 1.1267,  6.0089, -1.6633,  ...,  1.2786,  0.8078, -0.1832],\n",
            "        [ 4.7565, -0.0817,  0.3761,  ...,  0.7850,  1.1681, -1.9288],\n",
            "        [ 0.2856,  7.0949, -2.4953,  ..., -1.9282, -2.2847,  3.5571]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2269,  2.6798, -4.7179,  ...,  1.9689,  2.2895,  2.9105],\n",
            "        [ 3.1989,  7.9277, -4.3520,  ..., -1.6576,  1.8180,  5.9793],\n",
            "        [ 2.5798,  4.4406,  1.2859,  ...,  0.0772,  0.8095,  3.3086],\n",
            "        ...,\n",
            "        [ 0.7600,  1.4439, -1.0193,  ...,  1.3381,  2.4592,  0.6947],\n",
            "        [-0.2784,  5.0015, -2.0212,  ..., -0.6978,  0.1998,  0.6479],\n",
            "        [ 1.8448,  2.4365,  0.2381,  ..., -1.3362,  0.0658,  1.3865]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2490,  2.1003, -0.6457,  ..., -0.3272, -0.7080, -1.8337],\n",
            "        [ 2.5947,  3.1472,  0.3673,  ..., -3.0848,  1.6062, -0.6877],\n",
            "        [ 7.1001, -0.8119, -1.2187,  ...,  0.7104,  1.6570, -1.8770],\n",
            "        ...,\n",
            "        [ 1.0979,  2.2991, -3.8617,  ...,  1.0887,  3.2875,  0.6423],\n",
            "        [ 3.4489,  1.9942,  0.1476,  ..., -0.8764,  0.4040, -3.0547],\n",
            "        [ 3.4794, -0.4765, -0.1106,  ...,  0.9059,  2.4257, -0.9326]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3249,  2.8283, -4.7094,  ...,  0.5889,  3.3291,  1.6859],\n",
            "        [-1.7844,  3.5265,  1.4424,  ...,  1.5324,  3.1913,  1.8541],\n",
            "        [ 5.2111,  1.3925, -1.5023,  ..., -0.0174,  6.1182,  1.8194],\n",
            "        ...,\n",
            "        [ 0.5982,  1.4438, -1.9445,  ...,  1.4186,  2.4525,  0.1854],\n",
            "        [ 2.8553,  3.9650,  0.7651,  ...,  1.2398,  0.8487,  1.3757],\n",
            "        [-0.3294,  1.4293, -1.7748,  ...,  0.1204,  0.0317, -2.2262]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5606,  2.0783, -1.1198,  ..., -0.9082,  3.5222,  2.2215],\n",
            "        [ 3.0495,  6.1870, -0.5850,  ..., -0.1970,  0.7001,  2.0560],\n",
            "        [ 2.2888,  4.5768, -1.4456,  ..., -0.7275,  1.3780,  2.8025],\n",
            "        ...,\n",
            "        [-0.2526,  4.0091, -4.5591,  ..., -1.8992,  1.6638, -0.7515],\n",
            "        [ 2.2756,  2.6231, -0.7805,  ...,  0.1907,  1.7415,  0.9782],\n",
            "        [ 1.2032,  4.2634,  0.4487,  ...,  2.4383,  3.6204,  1.1408]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3726,  2.5709, -2.3532,  ..., -1.7994,  4.2092,  0.9833],\n",
            "        [ 2.6472,  1.4107,  2.1290,  ..., -3.5555,  1.2020, -2.0461],\n",
            "        [ 4.3683,  4.9963, -1.7601,  ..., -1.0774,  0.6874, -0.4257],\n",
            "        ...,\n",
            "        [-0.4930,  3.1063, -2.5259,  ...,  2.6675,  2.1629,  0.2003],\n",
            "        [ 2.2468,  4.1660,  2.4476,  ...,  0.6779,  1.0099, -0.4600],\n",
            "        [ 0.7606,  3.5481, -4.2314,  ..., -1.9956,  1.1501, -1.1155]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0435,  1.8897,  0.0841,  ...,  2.2687,  2.2048, -0.2415],\n",
            "        [ 2.3509,  2.0769,  0.5637,  ...,  2.0333,  4.4715,  3.3624],\n",
            "        [ 1.9260,  2.8936, -0.1811,  ...,  0.2913,  3.5489,  2.2529],\n",
            "        ...,\n",
            "        [-0.0165,  3.4516, -0.2068,  ...,  1.2639,  3.5217,  0.6575],\n",
            "        [ 0.9915,  2.7057,  0.2485,  ...,  1.4416,  1.4640, -0.3823],\n",
            "        [ 1.1836,  2.3598,  4.2032,  ..., -1.4428,  1.9502, -0.3247]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6322,  4.0062,  0.3738,  ...,  1.0023,  2.4102,  0.8208],\n",
            "        [ 3.2902,  3.4649,  0.3845,  ..., -2.7952,  2.0453, -0.0383],\n",
            "        [-1.9109,  2.6383, -0.5770,  ..., -0.0610,  3.4769,  0.6916],\n",
            "        ...,\n",
            "        [-0.1742,  3.1389,  2.6121,  ...,  1.1049,  1.8855,  0.4540],\n",
            "        [ 0.4838,  5.3440, -0.8734,  ..., -0.9038,  2.7945,  2.5811],\n",
            "        [ 2.6159,  1.8237,  1.9265,  ..., -1.4467,  2.7651,  0.1865]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7561,  1.3744, -1.1232,  ...,  0.8267,  2.2559, -0.2713],\n",
            "        [ 3.2351,  1.5007, -3.6487,  ...,  0.4275,  3.8417,  0.0142],\n",
            "        [ 3.0220,  1.5728,  0.9304,  ...,  0.4055,  1.6637, -0.3531],\n",
            "        ...,\n",
            "        [ 2.9808,  6.2848, -4.8333,  ..., -1.8908, -1.2165,  0.3402],\n",
            "        [ 2.3889,  1.3535,  1.5196,  ...,  0.7829,  2.0448, -2.2200],\n",
            "        [ 3.1133,  2.2341, -1.4611,  ..., -0.1945,  3.6486, -0.2372]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9599,  2.9583, -2.9518,  ..., -1.5815,  0.1480, -0.8898],\n",
            "        [ 1.3138,  3.4175, -3.2002,  ..., -0.8641,  0.7608, -1.3339],\n",
            "        [ 5.5694,  1.9181, -0.9120,  ...,  1.4389,  0.1099, -1.6342],\n",
            "        ...,\n",
            "        [-2.0753,  3.1042,  3.4012,  ...,  0.9373,  5.5816,  2.8947],\n",
            "        [ 1.5772,  5.8221, -2.0284,  ...,  0.3712,  2.3205,  1.2613],\n",
            "        [ 1.9118,  2.9076,  0.6731,  ..., -1.3589,  4.8918,  2.2767]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3024,  4.1968, -3.4298,  ...,  1.8518,  2.5977,  1.0360],\n",
            "        [ 0.5078,  5.6646, -1.5421,  ...,  1.2598,  0.6871,  0.3311],\n",
            "        [ 3.4810,  2.5891,  3.8912,  ..., -1.7886,  0.0429,  0.6507],\n",
            "        ...,\n",
            "        [ 3.0570,  2.9996, -2.7039,  ...,  2.5844,  1.3232,  1.2797],\n",
            "        [ 0.1625,  3.7585,  2.2183,  ...,  3.9973,  1.8658,  1.8132],\n",
            "        [ 1.8473,  4.1060, -2.2328,  ..., -1.3649,  2.8494,  2.5889]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8564,  2.1199,  3.4760,  ..., -2.3688,  1.3387,  2.7620],\n",
            "        [ 0.1198,  4.2874, -4.3528,  ..., -0.8581,  1.7331,  0.1700],\n",
            "        [ 1.0974,  3.0895, -1.3163,  ...,  2.3466,  5.0486,  3.8842],\n",
            "        ...,\n",
            "        [-0.4621,  4.9345,  3.7854,  ...,  3.0250,  4.2053,  3.4995],\n",
            "        [ 3.1576,  4.7673,  2.6810,  ...,  3.1758,  2.4278,  2.4045],\n",
            "        [ 4.6387,  3.8448,  3.2722,  ...,  1.4433, -0.8851, -1.0492]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.6284,  5.0288, -2.4374,  ..., -0.8797,  2.1458,  0.1513],\n",
            "        [ 0.4126,  1.2259,  4.5653,  ...,  2.5910,  3.2048,  0.5724],\n",
            "        [ 1.0638,  2.7279, -0.9736,  ...,  1.6737,  1.5453,  3.3003],\n",
            "        ...,\n",
            "        [-0.4114,  2.7263, -1.0417,  ..., -0.8529,  0.8903, -0.3778],\n",
            "        [-0.1527,  1.2812, -0.3379,  ...,  0.5903,  0.0678, -1.8529],\n",
            "        [ 2.5073,  1.6330, -3.4405,  ...,  1.1041,  2.5811,  1.0272]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2911,  3.0967, -4.6092,  ..., -1.6659,  2.0667, -0.7395],\n",
            "        [ 4.4797,  3.4100,  1.4053,  ...,  0.0344,  2.0389,  2.5717],\n",
            "        [ 2.4821,  2.3438,  0.6284,  ...,  1.2138,  2.9565, -0.6340],\n",
            "        ...,\n",
            "        [ 1.7581,  4.1466, -2.9521,  ..., -1.3276,  5.8472,  3.4712],\n",
            "        [ 0.5647,  1.2770, -4.9169,  ..., -0.8310,  2.0727,  2.9001],\n",
            "        [-0.7432,  4.1594, -2.8035,  ..., -1.3957,  2.3122, -0.1796]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9694,  1.2980, -1.6255,  ...,  1.4769,  4.4262,  1.9810],\n",
            "        [ 1.0738,  1.3378, -2.0302,  ..., -0.4873,  1.6608, -0.5681],\n",
            "        [-1.8251,  3.4290,  3.2277,  ...,  1.2789,  3.9384,  1.5232],\n",
            "        ...,\n",
            "        [ 2.3401,  0.8279,  1.9428,  ...,  0.9456,  3.9069, -0.6675],\n",
            "        [ 2.9365,  2.7689, -5.0863,  ...,  0.2013,  2.8008,  0.2466],\n",
            "        [ 0.2279,  0.3371,  0.2360,  ...,  0.3546, -0.3919, -1.5195]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0132,  2.6951, -2.7174,  ..., -0.1509,  0.1025, -1.1454],\n",
            "        [ 3.6096,  3.0094,  1.2438,  ..., -0.7773, -0.9137, -0.5110],\n",
            "        [ 2.9167,  2.4926,  2.4105,  ..., -0.8953,  1.3086, -0.3728],\n",
            "        ...,\n",
            "        [ 0.8207,  2.3589,  1.5484,  ...,  0.0382,  1.2676, -1.7448],\n",
            "        [ 1.3328,  3.2604, -0.9203,  ...,  0.3221,  3.7431,  1.0662],\n",
            "        [ 1.8840,  0.5381,  0.8314,  ...,  0.7302,  3.0505,  0.0518]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4230,  1.2120,  4.0599,  ...,  0.5240,  4.3048,  0.6065],\n",
            "        [ 1.6713,  2.5542, -1.3095,  ...,  1.7549,  5.0315,  2.3202],\n",
            "        [ 0.9164, -2.5073,  3.7154,  ...,  2.5775,  3.4896,  0.5810],\n",
            "        ...,\n",
            "        [ 2.4119,  2.6124,  0.3463,  ...,  2.0135,  2.5491,  0.6111],\n",
            "        [ 1.8886,  3.1054, -3.3046,  ..., -1.7253,  2.0791,  0.4488],\n",
            "        [-0.1548,  4.9875, -3.0212,  ...,  3.1698,  3.9992,  1.6995]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2503,  3.0036, -0.6117,  ...,  1.1047,  0.5066,  1.0317],\n",
            "        [ 3.4722,  5.4613, -1.0222,  ...,  2.4083,  1.1787,  2.1958],\n",
            "        [ 0.9428,  5.2713,  2.2056,  ...,  0.6840,  3.8684,  2.6566],\n",
            "        ...,\n",
            "        [-0.6292,  3.2958, -1.7241,  ...,  0.4801,  3.5683,  1.5695],\n",
            "        [ 0.7223,  4.3653,  1.7647,  ...,  2.2974,  4.0232,  1.7077],\n",
            "        [ 2.0272,  5.3510, -1.4781,  ...,  2.4383,  4.1584,  2.9084]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4679,  1.6220, -0.4020,  ...,  2.8485,  2.9345, -0.4128],\n",
            "        [ 4.9710,  0.2660, -1.6780,  ..., -0.3846,  0.9502, -1.1030],\n",
            "        [-0.2667,  3.3906, -2.8898,  ..., -0.8158,  0.2768, -0.0550],\n",
            "        ...,\n",
            "        [ 3.5941,  4.6738, -1.2119,  ..., -2.3505,  1.5976,  0.5547],\n",
            "        [ 4.8129,  0.7200, -2.9702,  ...,  2.0643,  1.7862,  0.1577],\n",
            "        [-0.0120, -0.2540,  0.0697,  ...,  1.6382, -0.2100, -0.9431]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6157,  5.3522,  2.5516,  ...,  3.6560,  2.6458,  2.0474],\n",
            "        [ 1.0636,  4.5528, -1.3269,  ...,  0.9717,  1.0357,  2.4463],\n",
            "        [ 3.4931,  1.5439,  1.2696,  ...,  1.8094,  3.1350,  0.1186],\n",
            "        ...,\n",
            "        [-1.8434,  3.0442,  2.2214,  ...,  2.4041,  1.9887,  0.4720],\n",
            "        [ 0.4509,  0.8555, -1.0703,  ...,  1.6748,  1.8099, -2.1652],\n",
            "        [ 1.2419,  0.1760,  5.6681,  ...,  0.6463,  3.6599,  0.4272]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7050,  4.3127, -0.5270,  ..., -0.7108,  1.6867,  4.0742],\n",
            "        [ 1.9295,  1.2805,  1.9356,  ..., -0.0954,  3.5433,  1.4939],\n",
            "        [ 1.9025,  7.1210, -4.0436,  ...,  0.7365,  1.0504,  1.7579],\n",
            "        ...,\n",
            "        [-1.9097,  1.8175,  0.8505,  ...,  1.6350,  2.8938,  0.4006],\n",
            "        [ 1.1463,  4.0372, -0.0565,  ...,  1.3796,  4.3954,  5.5252],\n",
            "        [ 4.9728,  3.9273,  2.9271,  ..., -2.2936,  1.1602,  4.0849]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1876,  4.0388, -7.3339,  ..., -0.2064,  1.4372,  0.4938],\n",
            "        [ 2.0687,  4.9013, -2.2227,  ..., -0.5699, -0.7906,  0.0622],\n",
            "        [-0.2758,  2.8327,  2.0723,  ...,  3.0045,  2.6808,  1.2405],\n",
            "        ...,\n",
            "        [ 3.2403,  5.0963,  0.9406,  ...,  0.8765,  2.3765,  2.9895],\n",
            "        [ 0.4398,  4.1202, -4.6266,  ..., -1.4169,  1.1484,  0.0711],\n",
            "        [ 2.0269, -0.1171, -2.2062,  ..., -0.0347,  4.4119,  1.0216]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5493,  4.3333, -0.4942,  ...,  1.9452,  3.5390,  3.0788],\n",
            "        [-0.1166,  1.1674,  0.7561,  ...,  1.7143,  1.8986,  0.6450],\n",
            "        [ 1.9097, -2.7084,  1.0103,  ...,  1.1115,  4.2761,  0.2271],\n",
            "        ...,\n",
            "        [ 2.8907,  3.8759, -3.2216,  ...,  1.5465,  1.6205,  1.0348],\n",
            "        [ 1.5745,  2.4052, -4.5164,  ...,  2.5176, -0.2943,  1.5034],\n",
            "        [-0.4133,  4.8384,  1.7703,  ..., -0.2019,  4.5943,  1.9116]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4504,  7.4753,  0.2861,  ...,  0.3011,  3.7613,  5.4194],\n",
            "        [ 4.7499,  3.0592,  1.0845,  ...,  1.5418,  0.5740,  1.7856],\n",
            "        [ 0.2479,  2.9113, -2.7403,  ..., -0.5463, -0.2884, -0.5407],\n",
            "        ...,\n",
            "        [ 4.1132,  2.0811,  1.5336,  ..., -2.3577, -0.4727,  1.8406],\n",
            "        [ 4.4810,  1.8331,  3.8682,  ..., -1.7653,  0.9079,  1.7351],\n",
            "        [ 2.9127,  2.2169, -1.7290,  ..., -2.8394, -0.1148,  0.3553]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1138,  0.9556, -1.2673,  ...,  2.1561,  4.5543, -0.0213],\n",
            "        [ 2.2361,  0.4617,  4.6379,  ...,  1.1295,  1.9474, -1.8486],\n",
            "        [ 3.6513,  5.1226,  1.5813,  ...,  1.9017, -0.4872,  1.9862],\n",
            "        ...,\n",
            "        [-2.5054,  3.5721,  0.5583,  ...,  2.4623,  3.5036,  2.7373],\n",
            "        [ 2.7064,  3.5341,  0.6277,  ..., -1.1970,  0.7559,  2.3350],\n",
            "        [ 0.2564,  6.1794,  2.6523,  ..., -0.2686,  5.2425,  5.0797]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9042,  3.5095, -3.9543,  ...,  0.2410,  4.8081,  2.2256],\n",
            "        [-0.4407,  3.7779,  2.6539,  ...,  0.0195,  2.4546, -0.0886],\n",
            "        [-0.7089,  1.6880, -1.3188,  ...,  0.0380,  0.7524, -0.5274],\n",
            "        ...,\n",
            "        [ 1.8230,  1.7690, -0.5981,  ..., -0.0089,  3.0213,  0.6073],\n",
            "        [ 0.6936,  5.5860, -3.7230,  ..., -0.4423,  1.0000,  0.6656],\n",
            "        [ 2.7305,  3.4715,  0.4790,  ..., -1.3893, -0.7128, -0.0107]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1717e+00,  3.6354e+00,  6.2415e+00,  ..., -2.1944e+00,\n",
            "          2.2150e+00,  2.6002e+00],\n",
            "        [ 4.3925e-01,  3.3485e+00, -4.4471e+00,  ..., -1.2585e+00,\n",
            "          1.9741e+00,  9.4948e-01],\n",
            "        [ 4.0511e+00,  2.4380e+00,  4.4962e+00,  ..., -1.4239e+00,\n",
            "          2.0189e+00,  3.5235e+00],\n",
            "        ...,\n",
            "        [ 3.6682e+00,  2.0073e+00, -4.2345e+00,  ...,  3.0905e-01,\n",
            "          4.8007e+00,  8.1680e-01],\n",
            "        [ 1.6579e+00,  5.2307e-01,  4.0369e-03,  ...,  2.9364e+00,\n",
            "          1.9127e+00,  6.1343e-01],\n",
            "        [ 2.7021e-01,  2.1288e+00, -2.2598e+00,  ...,  5.7410e-01,\n",
            "          4.5431e+00,  6.1651e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0827,  2.9222, -4.2446,  ..., -0.8040,  0.3425, -0.6162],\n",
            "        [ 2.9188,  2.8512, -0.4887,  ...,  0.9411, -0.2189, -0.2597],\n",
            "        [ 1.8491,  6.4148,  2.9177,  ..., -0.4504, -0.6180,  6.1179],\n",
            "        ...,\n",
            "        [-1.0962,  3.4931, -0.5974,  ...,  2.6257,  4.7030,  2.9680],\n",
            "        [ 5.5586,  2.0017,  1.6852,  ..., -1.3019,  3.0212,  0.6586],\n",
            "        [ 4.6291,  6.8633, -4.8708,  ..., -2.1175,  1.7592,  2.8684]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5081, -0.1199,  5.6191,  ...,  3.9312,  2.3759,  2.4637],\n",
            "        [-0.8034,  2.2086, -2.0887,  ..., -0.4384,  0.1969, -1.7752],\n",
            "        [ 1.6570,  2.5554, -1.8543,  ...,  1.5324,  1.8965, -1.2061],\n",
            "        ...,\n",
            "        [-0.7420,  4.5134, -2.6970,  ...,  1.2870,  3.4423,  1.7956],\n",
            "        [ 3.5364,  3.2654, -2.5636,  ...,  2.7191,  0.1149,  2.1553],\n",
            "        [ 5.4043,  1.0115,  5.3663,  ..., -2.6283, -0.0199, -0.2657]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0314,  3.5089, -2.9559,  ..., -0.5027,  1.2893,  0.0977],\n",
            "        [ 0.8006,  1.2670, -1.3141,  ...,  2.3688,  5.2445,  3.1261],\n",
            "        [ 5.6159,  5.7022, -1.0883,  ..., -0.5688, -2.0031,  2.6960],\n",
            "        ...,\n",
            "        [ 1.1134,  2.6988, -0.3429,  ...,  1.0295,  0.6581,  1.3725],\n",
            "        [ 0.4486,  3.7263, -3.7679,  ..., -1.4592,  0.5487, -0.0066],\n",
            "        [ 0.5334,  3.2278, -0.0547,  ...,  1.9151,  2.0112,  1.9951]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8162,  0.8622,  0.5251,  ..., -0.1583,  2.1200,  0.8875],\n",
            "        [-1.4404,  4.0193, -2.5561,  ..., -0.9341,  1.6307, -0.5457],\n",
            "        [ 1.8377,  1.9378, -0.4010,  ...,  0.2524,  2.6169, -2.1380],\n",
            "        ...,\n",
            "        [ 1.5970,  3.3324, -3.8947,  ...,  0.7900,  2.3072,  0.5242],\n",
            "        [ 1.0544,  1.9790,  0.1989,  ...,  2.2220,  1.4124,  0.3221],\n",
            "        [ 0.3740,  2.8961, -2.3962,  ..., -0.4902, -0.1519, -0.3522]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4621,  4.5586, -2.0535,  ..., -0.9971,  4.0252,  4.3247],\n",
            "        [ 3.0175,  0.4406,  2.5091,  ...,  1.8786,  5.0359,  1.8580],\n",
            "        [ 0.2633,  3.8448, -6.0917,  ..., -1.3398,  2.3919,  0.2675],\n",
            "        ...,\n",
            "        [ 1.3939,  2.2885, -1.5188,  ...,  1.1666,  6.5337,  3.8084],\n",
            "        [ 6.3094,  1.9076, -2.9405,  ...,  1.7414,  1.5087,  0.2458],\n",
            "        [ 0.7615,  3.0933, -4.1810,  ..., -0.9711,  0.6732, -0.1878]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3119,  2.0519, -3.2745,  ...,  0.4896,  1.8050,  0.5649],\n",
            "        [ 0.5398,  0.9151,  0.7989,  ...,  0.0720,  1.8518,  0.4197],\n",
            "        [-1.8113,  3.2937, -1.5757,  ...,  2.1549,  2.9474,  1.5198],\n",
            "        ...,\n",
            "        [ 1.7263,  5.1473, -0.6503,  ...,  0.0419,  2.0904,  1.5356],\n",
            "        [-1.2341,  3.0267, -1.6721,  ...,  2.3381,  4.2854,  0.9789],\n",
            "        [ 1.5890,  8.5900, -4.2267,  ..., -0.1672,  3.7295,  6.1213]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.4929,  3.2422, -2.4777,  ...,  1.6398,  2.6995,  0.5698],\n",
            "        [ 1.9303, -0.4948,  0.6792,  ...,  0.7775,  1.1699, -2.6970],\n",
            "        [ 2.9589,  2.3105, -0.1279,  ..., -0.0698,  1.8023, -0.7012],\n",
            "        ...,\n",
            "        [ 1.7483,  0.4839,  2.5825,  ...,  0.6550,  6.1459,  1.8162],\n",
            "        [ 4.0650,  0.5277,  3.8778,  ..., -0.3923,  0.0985,  1.2026],\n",
            "        [-0.1154,  5.3600, -2.8605,  ...,  4.6215,  3.1192,  2.9527]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2174,  3.1049, -3.2594,  ..., -1.0775,  0.4951, -0.8666],\n",
            "        [ 4.9503,  8.2677, -0.9352,  ..., -2.6489, -1.2536,  2.6609],\n",
            "        [ 0.3841,  1.1021, -1.8050,  ...,  0.6689,  0.5269, -2.1095],\n",
            "        ...,\n",
            "        [ 5.0326,  0.7403, -1.5205,  ..., -0.6825,  3.5308,  0.8074],\n",
            "        [ 1.9200, -2.4162,  1.0824,  ..., -0.1024, -0.2880, -2.0077],\n",
            "        [ 4.2001,  4.1513, -4.7380,  ..., -0.6056,  5.2115,  0.6014]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9618,  0.9849, -3.9146,  ...,  0.7616,  3.8265, -1.0399],\n",
            "        [ 4.1490,  3.2195, -3.2006,  ..., -1.1750,  1.6499, -1.8252],\n",
            "        [ 2.1811,  3.9436,  0.3331,  ..., -0.3937,  4.7329,  1.0422],\n",
            "        ...,\n",
            "        [ 2.0652,  4.2037, -0.9106,  ..., -0.4594,  1.2962, -0.4754],\n",
            "        [ 3.0814,  2.6164, -1.8750,  ..., -0.9439,  2.1298,  3.2054],\n",
            "        [ 3.9911,  0.1429,  4.6650,  ...,  0.2923,  4.5748,  0.9903]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1448,  0.8747, -0.4629,  ...,  1.1665,  1.7702, -1.2893],\n",
            "        [-0.0186,  3.5241,  0.8111,  ...,  0.6597,  1.2253, -1.5334],\n",
            "        [-0.3882,  5.9402, -4.8925,  ..., -1.2256,  0.3021,  0.6886],\n",
            "        ...,\n",
            "        [ 2.3968,  0.7270, -4.4387,  ...,  2.1532,  3.4640,  2.4517],\n",
            "        [ 0.9082,  5.0677,  0.3801,  ...,  0.3032,  2.1007,  4.9238],\n",
            "        [ 0.0510,  2.4843, -1.7987,  ...,  0.0286,  0.1355, -1.9384]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53f3de93fd3d41aa8aca4c29941ea3d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6.5700, -1.0580,  3.6643,  ...,  0.3858,  1.5575, -1.3858],\n",
            "        [ 1.3932,  3.9105, -1.3005,  ...,  4.2499,  6.0625,  2.8661],\n",
            "        [ 1.2480,  2.7806, -4.6400,  ...,  1.4423,  2.6139,  2.8621],\n",
            "        ...,\n",
            "        [ 1.5066,  3.2083, -0.4174,  ...,  1.1159,  0.5868, -2.5397],\n",
            "        [ 4.1833,  8.2390, -1.2604,  ..., -0.8595,  0.3786,  0.3255],\n",
            "        [ 4.9191,  4.7771, -6.3242,  ...,  1.1364,  0.1521,  0.4055]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.4833,  2.9442, -3.9242,  ...,  0.7872,  3.5861, -0.4585],\n",
            "        [ 0.4204,  0.8111, -1.0611,  ..., -0.2615,  0.1889, -1.6450],\n",
            "        [-0.8322,  5.1563,  0.5944,  ...,  0.9187,  1.1716,  1.0837],\n",
            "        ...,\n",
            "        [ 1.3747,  4.2866, -4.6520,  ..., -0.0601,  3.8030,  1.1282],\n",
            "        [ 2.2606,  2.7216,  1.5619,  ...,  0.6933,  1.9178, -0.1565],\n",
            "        [ 6.5988,  0.9476,  4.0979,  ...,  0.0402,  0.1438, -1.1339]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0596,  2.5345,  4.0227,  ...,  3.3669,  2.1385, -1.3654],\n",
            "        [ 2.7949, -0.0530, -1.2875,  ...,  0.2026,  4.5570, -0.7243],\n",
            "        [ 5.2851,  3.7198,  1.3045,  ...,  1.6010,  1.6810,  0.8806],\n",
            "        ...,\n",
            "        [ 1.6849,  2.0611,  2.1100,  ...,  1.2751,  2.5644, -0.1309],\n",
            "        [ 3.9159,  7.3489, -6.2638,  ..., -1.6640, -1.1832,  0.3928],\n",
            "        [ 1.2461,  5.7181,  2.8664,  ...,  3.5421,  1.9062,  1.2884]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7272e+00,  6.1491e+00, -3.3856e+00,  ...,  1.3454e+00,\n",
            "          1.9462e+00, -7.7761e-01],\n",
            "        [ 1.8270e+00,  1.1437e+00, -2.8965e+00,  ...,  3.5063e+00,\n",
            "          1.6374e+00,  9.1771e-01],\n",
            "        [-2.3798e-01,  2.0421e+00,  1.1062e+00,  ..., -9.7052e-02,\n",
            "          7.9539e-01,  3.4470e-01],\n",
            "        ...,\n",
            "        [ 3.3679e+00,  3.1216e+00,  5.7867e+00,  ..., -7.8821e-02,\n",
            "          3.1763e+00,  6.8153e-01],\n",
            "        [ 3.6894e+00,  4.2199e-03, -1.1251e+00,  ..., -1.5414e-02,\n",
            "          2.7232e+00, -2.2751e+00],\n",
            "        [ 1.5906e+00,  3.3123e+00, -1.7588e+00,  ...,  2.7580e+00,\n",
            "          3.8133e+00,  1.6355e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2342,  2.8309,  0.0095,  ..., -0.1066, -0.9884,  0.4990],\n",
            "        [ 0.3992,  2.7476,  1.0826,  ...,  0.9415,  3.9645,  0.0236],\n",
            "        [ 0.4697,  3.8562, -2.0480,  ...,  1.5216,  0.9063,  1.4425],\n",
            "        ...,\n",
            "        [ 1.2656,  2.9457, -3.4370,  ..., -0.9063,  2.0400, -0.7026],\n",
            "        [ 0.7740,  3.4888, -3.4095,  ..., -0.8248,  0.1545, -1.2254],\n",
            "        [-0.0211,  2.1474, -1.1332,  ..., -0.1706,  1.4219, -0.5791]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0313,  4.2118, -3.4114,  ...,  0.7739,  2.2152, -0.1653],\n",
            "        [ 2.8739,  0.6520,  0.3510,  ...,  2.0919,  3.5284,  0.6185],\n",
            "        [ 3.1837,  4.5610, -2.0882,  ...,  0.0423,  3.9194,  1.6338],\n",
            "        ...,\n",
            "        [ 0.4172,  5.0519,  0.7154,  ...,  1.5534,  1.5113,  2.5909],\n",
            "        [ 5.1425,  3.1685, -1.0930,  ...,  1.1193,  1.3857, -0.6641],\n",
            "        [ 5.9886,  4.7003, -2.1296,  ...,  1.7431,  2.0577, -0.5015]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1680,  4.0263, -2.7669,  ...,  1.7038,  2.6553, -2.8956],\n",
            "        [ 2.8076,  3.7600,  3.4947,  ...,  1.0127,  3.2957,  2.1355],\n",
            "        [ 0.3917,  4.2684, -2.2118,  ...,  2.1906,  5.6383,  2.7314],\n",
            "        ...,\n",
            "        [ 1.1125,  0.6609,  0.5552,  ...,  0.8504,  1.4694, -2.7729],\n",
            "        [ 3.8937,  2.9028,  0.9790,  ...,  0.1965,  1.3720, -0.8780],\n",
            "        [ 2.8111,  2.0407, -1.4531,  ...,  0.8289,  1.8718, -1.8364]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5908,  6.0112,  1.2811,  ..., -0.3593, -0.1755, -0.9532],\n",
            "        [ 0.7027,  1.0870,  5.1698,  ...,  1.7824,  4.3165,  0.5708],\n",
            "        [ 1.1896,  3.7736, -4.1314,  ..., -0.5009,  0.4433, -1.1179],\n",
            "        ...,\n",
            "        [ 3.7995,  3.7478,  2.6865,  ..., -0.6099,  0.0549,  1.8169],\n",
            "        [ 0.9365,  4.3369,  1.3585,  ...,  3.3786,  3.1464,  1.2161],\n",
            "        [ 3.6792,  2.6212, -2.7675,  ...,  1.8584,  2.5335, -1.8919]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6543,  2.9869, -0.8102,  ...,  2.4210,  4.7801,  1.9866],\n",
            "        [ 5.9165,  3.5508,  4.3978,  ..., -0.7203, -0.2474,  2.6651],\n",
            "        [ 3.2913,  3.1438, -3.8717,  ...,  0.9543,  2.5206, -2.7254],\n",
            "        ...,\n",
            "        [ 1.8717,  3.2591, -1.6659,  ...,  1.0828,  2.9663, -0.4150],\n",
            "        [-0.8285,  4.5593, -1.9299,  ...,  1.4378,  2.3830,  1.4821],\n",
            "        [ 2.1814,  2.1570, -1.5807,  ...,  0.0326,  0.8859, -2.3058]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6973,  0.8916, -2.5539,  ...,  3.0592,  2.7753, -1.0123],\n",
            "        [ 0.2022,  3.4491, -1.7064,  ...,  2.7588,  4.2789,  1.3023],\n",
            "        [-0.5921,  3.5643, -3.4108,  ..., -0.7026,  0.7748, -1.2403],\n",
            "        ...,\n",
            "        [ 0.7252,  5.5849, -1.7468,  ...,  1.1449,  4.5892, -0.4753],\n",
            "        [ 1.2361,  0.6385,  1.3433,  ...,  2.7740,  2.2381, -1.6096],\n",
            "        [ 1.1026,  5.8679, -2.3725,  ...,  0.5184, -0.5955,  0.3189]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9828,  2.7737, -4.6654,  ..., -1.4727,  2.8006, -0.3942],\n",
            "        [-0.0159,  2.3413, -3.5618,  ..., -1.2497,  0.6301, -1.2355],\n",
            "        [ 3.1221, -0.7698,  3.0689,  ...,  0.8342,  4.0025, -0.4172],\n",
            "        ...,\n",
            "        [-0.0421,  2.3456, -2.3378,  ...,  0.2191, -0.1242, -2.0172],\n",
            "        [-0.7726,  0.3744, -1.7522,  ...,  1.3079,  0.0655, -2.9730],\n",
            "        [ 4.3390,  1.3591,  1.9923,  ..., -3.2350, -0.5059,  1.4326]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8467,  0.1425, -1.1789,  ...,  0.5852,  0.7244, -1.8373],\n",
            "        [ 1.9156,  3.9536, -0.3628,  ...,  0.2151,  1.7544, -1.1850],\n",
            "        [ 2.2680,  5.5404, -1.8735,  ...,  0.7014,  1.1471,  2.7215],\n",
            "        ...,\n",
            "        [ 1.5835, -0.4013,  2.7080,  ..., -1.5410,  2.8657, -0.7922],\n",
            "        [ 2.1848,  3.8275,  2.2068,  ...,  2.0840,  2.3196,  0.3359],\n",
            "        [ 3.3418,  3.6543,  2.2113,  ...,  0.7438,  2.4633,  2.9805]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5533,  4.0663,  2.3389,  ...,  0.7597,  3.7849,  3.0865],\n",
            "        [ 3.7346,  4.5953, -2.8356,  ..., -1.0776,  3.4074,  0.2065],\n",
            "        [-0.2700,  0.9354, -2.0125,  ...,  1.2635, -0.0116, -2.7401],\n",
            "        ...,\n",
            "        [ 0.1187,  3.8951, -2.9087,  ...,  1.4602,  4.5902,  1.0161],\n",
            "        [ 1.8950,  7.7447, -6.1236,  ..., -1.4847, -0.2593, -0.8594],\n",
            "        [ 4.8048,  2.4456, -1.9515,  ...,  2.6210,  2.2774,  0.1372]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6228,  1.7790, -0.3962,  ...,  1.8120,  2.7879, -1.1750],\n",
            "        [ 5.7632,  6.9679, -0.5299,  ..., -3.6590,  0.9777,  3.7271],\n",
            "        [ 0.1391,  2.3436, -3.2637,  ..., -0.0085,  0.3427, -2.0460],\n",
            "        ...,\n",
            "        [ 2.9658,  3.9890, -1.6688,  ...,  1.2990,  5.1081,  2.4738],\n",
            "        [ 1.4671,  4.1474, -1.9752,  ...,  0.4695, -0.0971,  1.6269],\n",
            "        [ 1.7386,  2.7183, -2.2392,  ...,  1.3690,  5.3332,  2.1454]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1631e+00,  2.2099e+00, -2.8916e+00,  ..., -7.8546e-01,\n",
            "          6.8999e-01, -1.0444e+00],\n",
            "        [-1.0489e+00,  3.3898e+00, -5.2048e+00,  ..., -2.0808e+00,\n",
            "          1.5316e+00, -6.4302e-01],\n",
            "        [ 2.0983e+00,  2.0499e+00,  3.7347e+00,  ..., -4.6391e-01,\n",
            "          1.4910e+00, -2.0830e+00],\n",
            "        ...,\n",
            "        [ 3.9757e+00, -2.3193e-03,  2.0144e+00,  ..., -1.4732e+00,\n",
            "          3.0754e+00, -2.4234e+00],\n",
            "        [ 1.5757e+00,  4.2785e+00,  2.6412e+00,  ...,  2.3437e-01,\n",
            "         -1.6798e+00,  1.0128e+00],\n",
            "        [-2.0006e-01,  3.0096e+00, -8.5594e-01,  ...,  1.4794e+00,\n",
            "          1.6787e+00, -7.2676e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4728,  2.4035, -1.2541,  ...,  0.6365,  3.4940, -0.2730],\n",
            "        [ 0.4497,  2.5771,  2.9475,  ...,  1.6058,  1.4398, -0.9336],\n",
            "        [ 2.1427,  3.2657, -4.7426,  ...,  0.5806,  3.0950, -0.1894],\n",
            "        ...,\n",
            "        [ 2.5835,  1.3330, -0.8645,  ...,  0.0075,  2.6183, -0.8563],\n",
            "        [-0.1302,  4.8114, -1.8459,  ...,  2.2414,  2.6275,  0.5959],\n",
            "        [-0.1042,  1.1497,  2.9581,  ...,  0.3800,  4.0316, -1.2565]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5090,  5.1057, -6.2902,  ..., -1.1325,  1.6369,  0.9241],\n",
            "        [-1.4803,  0.3668, -0.0981,  ...,  0.4858,  2.4208,  0.0584],\n",
            "        [ 2.9393, -0.5464, -0.4713,  ...,  1.4033,  3.2717, -0.9722],\n",
            "        ...,\n",
            "        [ 2.2531,  4.4895, -2.9498,  ..., -1.5623,  3.2069,  2.2947],\n",
            "        [-1.0653,  4.5205,  1.1515,  ...,  2.8903,  4.2256,  2.1415],\n",
            "        [ 2.4502,  5.6996, -3.5874,  ...,  0.2253, -0.7627,  1.5370]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1309,  2.9472, -1.1380,  ...,  0.3797,  1.7254,  2.2579],\n",
            "        [ 3.0132,  4.6332, -1.0510,  ..., -1.5588,  1.9294,  1.7879],\n",
            "        [ 3.3743,  1.0342, -1.4376,  ...,  0.3428,  1.7969, -1.0377],\n",
            "        ...,\n",
            "        [-0.7049,  1.8851, -3.0398,  ..., -1.1572,  0.2782, -1.9786],\n",
            "        [-0.8679,  3.0091, -0.5247,  ...,  1.5260,  4.0181,  1.2003],\n",
            "        [ 0.9495,  2.7692, -4.6695,  ...,  1.0671,  1.6578, -0.4533]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8299,  5.5717, -6.6271,  ..., -1.6461,  2.5166,  0.0372],\n",
            "        [ 1.1747,  6.4691, -5.9282,  ...,  0.0868,  4.9534,  4.6181],\n",
            "        [ 2.0168,  1.6647,  0.5651,  ..., -1.0463,  4.3944,  0.3953],\n",
            "        ...,\n",
            "        [ 1.0227,  4.1577, -3.3192,  ...,  0.4484, -1.0331,  3.6646],\n",
            "        [ 3.5538,  2.3716,  1.2861,  ..., -1.7011,  0.4814,  1.8952],\n",
            "        [ 4.7936,  4.5839,  1.8433,  ..., -0.6300,  0.1787,  1.2978]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9872,  3.2617, -0.7864,  ...,  2.6134,  3.7361,  1.5050],\n",
            "        [-0.9709,  4.0993,  1.3847,  ...,  2.7444,  4.2549,  1.1958],\n",
            "        [ 1.2749,  1.4727, -1.1007,  ...,  1.9912,  3.0061,  0.4663],\n",
            "        ...,\n",
            "        [ 1.5814,  0.2851, -1.4844,  ..., -0.5333,  0.5223, -2.6026],\n",
            "        [ 0.5880,  6.1359,  2.4617,  ...,  3.5349,  2.6619,  1.2891],\n",
            "        [ 1.3354,  2.2266, -0.6971,  ..., -0.9488,  5.4017, -0.9416]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0390,  2.0414, -2.0633,  ..., -0.9626,  2.2504, -1.5503],\n",
            "        [ 0.9951,  2.5856,  0.7541,  ..., -1.1639,  5.0300, -0.6861],\n",
            "        [ 1.1729,  1.3169,  0.2291,  ...,  0.0966,  2.4997,  0.4878],\n",
            "        ...,\n",
            "        [ 0.2161,  1.8702, -0.8182,  ...,  0.6547,  4.3816, -1.7912],\n",
            "        [ 1.0399,  0.7604, -0.3450,  ...,  0.8964,  7.4558,  1.8226],\n",
            "        [ 3.2990,  0.3908, -0.4346,  ..., -0.1569,  6.0473,  0.8513]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5333,  2.2593, -0.1807,  ...,  1.7093,  6.6995,  3.0491],\n",
            "        [ 3.8910,  3.8436, -0.3304,  ..., -3.6418, -0.2121,  1.1749],\n",
            "        [ 3.2981,  2.0340, -0.3513,  ..., -0.3864,  1.3985, -0.8572],\n",
            "        ...,\n",
            "        [ 1.8765,  1.6461,  0.2834,  ...,  0.1757,  2.3564,  0.4265],\n",
            "        [ 1.8009,  0.8095, -4.8563,  ...,  1.7913,  3.7003,  2.1505],\n",
            "        [ 5.3647,  4.1873,  2.1578,  ..., -0.6570, -0.0309, -0.0365]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4970,  3.9097, -2.0490,  ...,  0.0658,  3.3687,  3.0708],\n",
            "        [ 1.0354,  3.6889, -3.6968,  ..., -0.3418,  4.8546,  1.5631],\n",
            "        [ 0.3538,  0.0637, -1.0621,  ...,  1.0509,  0.4025, -1.8822],\n",
            "        ...,\n",
            "        [ 5.8093,  0.0552,  3.9977,  ..., -1.0008,  1.6030, -0.5378],\n",
            "        [-2.1857,  5.4632, -2.2794,  ...,  2.0439,  4.5475,  1.0991],\n",
            "        [ 1.5934,  5.0496, -1.0848,  ..., -0.4206,  4.1100,  0.7579]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6537,  2.6879, -2.4815,  ...,  0.3891,  2.8270, -0.3290],\n",
            "        [ 5.1287,  3.8394,  2.5122,  ..., -2.0352,  2.0147,  2.4410],\n",
            "        [ 0.6914,  2.7801, -0.7210,  ...,  0.8311,  3.4658,  0.7304],\n",
            "        ...,\n",
            "        [ 1.9644, -1.5069,  5.1254,  ...,  1.1939,  4.7544,  0.8943],\n",
            "        [ 2.9264,  1.3442, -0.9113,  ...,  1.0760,  2.7822, -1.8934],\n",
            "        [ 2.1698,  2.4216,  0.8895,  ...,  1.0213,  1.4282,  1.9333]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7935,  1.1347, -1.7127,  ..., -0.5061,  0.1745, -1.8076],\n",
            "        [-1.8382,  4.3036, -3.2050,  ...,  2.8233,  4.7215,  1.4662],\n",
            "        [-0.2395,  1.7951, -0.1794,  ...,  3.9650,  2.0039,  0.7432],\n",
            "        ...,\n",
            "        [-1.2956,  3.5410,  1.3287,  ...,  2.7684,  4.3229, -0.3855],\n",
            "        [ 2.0935,  0.5126, -2.0171,  ...,  0.0374,  5.9986,  0.9866],\n",
            "        [ 3.2289,  3.5464,  1.1012,  ..., -2.1752,  4.8971, -2.4577]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-8.7236e-01,  2.6542e+00, -2.9296e+00,  ..., -2.5355e-01,\n",
            "          1.0000e+00, -1.5485e+00],\n",
            "        [ 2.8905e+00,  2.1736e+00,  4.2250e+00,  ..., -1.9997e+00,\n",
            "          4.3937e-01,  5.4235e-01],\n",
            "        [ 1.3013e+00,  5.5744e+00, -3.8752e+00,  ..., -3.9227e-03,\n",
            "          1.4026e+00, -5.0313e-01],\n",
            "        ...,\n",
            "        [ 4.8711e+00, -1.2293e+00,  1.3285e+00,  ..., -1.9257e+00,\n",
            "         -1.2901e-01,  9.7789e-01],\n",
            "        [-8.9227e-01,  6.2927e-01, -2.1841e+00,  ...,  1.1531e+00,\n",
            "          1.1664e+00, -2.1288e+00],\n",
            "        [ 4.5622e+00,  5.5053e-02,  3.2921e-01,  ..., -8.3514e-02,\n",
            "          1.2389e+00, -9.2250e-02]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2490,  3.1730, -7.0472,  ..., -2.3043,  6.2224,  1.1484],\n",
            "        [-1.1165,  3.8877, -1.3048,  ...,  2.8834,  3.2124,  0.8974],\n",
            "        [ 0.7835,  2.1404,  0.1192,  ..., -1.5717,  0.4496, -0.4882],\n",
            "        ...,\n",
            "        [-0.1064,  1.8809, -0.6003,  ...,  1.3240,  3.9735,  1.3286],\n",
            "        [-0.4314,  3.7032, -5.0624,  ..., -1.2686,  1.7742,  0.9432],\n",
            "        [ 2.0675,  1.5802, -2.5939,  ...,  0.1686,  5.7846, -0.6597]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4700e-01,  2.4105e+00,  5.7863e+00,  ..., -7.3776e-01,\n",
            "          4.3478e+00,  1.2613e+00],\n",
            "        [ 5.1303e-03,  5.7439e+00, -1.0671e+00,  ...,  1.9491e-01,\n",
            "          1.9113e+00,  3.6591e+00],\n",
            "        [-7.4273e-01,  3.8822e+00, -6.0528e-02,  ..., -1.1204e+00,\n",
            "          5.6259e+00, -2.3354e+00],\n",
            "        ...,\n",
            "        [ 3.7177e+00,  5.4415e+00, -3.7258e+00,  ..., -8.1477e-01,\n",
            "          1.2679e+00,  1.5359e+00],\n",
            "        [ 1.8646e+00,  3.4154e+00,  2.6013e+00,  ...,  1.5375e-01,\n",
            "          1.6700e+00, -1.0978e+00],\n",
            "        [-1.6463e-01,  3.1669e+00,  3.9270e-01,  ...,  1.1085e-01,\n",
            "          5.1006e+00,  2.3883e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3682,  3.7992, -2.0335,  ...,  1.1197,  0.6973,  0.6079],\n",
            "        [ 1.7229, -1.1980,  2.0125,  ...,  1.5191,  4.1169, -2.6661],\n",
            "        [-1.1350,  3.4485,  1.0752,  ..., -0.1854,  1.4869,  3.0989],\n",
            "        ...,\n",
            "        [ 0.3858,  2.2053, -2.9060,  ...,  0.9981,  4.5349,  2.4057],\n",
            "        [ 0.1273,  3.6025, -6.5125,  ..., -1.8722,  2.2621,  0.6113],\n",
            "        [ 1.1320,  4.5085, -2.6088,  ...,  1.5978,  3.8345,  3.7856]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6832,  2.8995, -2.0282,  ..., -1.0777,  2.8542, -1.1358],\n",
            "        [ 1.6653,  2.4044, -4.3488,  ...,  3.1805,  3.9501,  1.2275],\n",
            "        [ 7.5928,  0.2827, -1.0161,  ..., -0.0743,  1.0895, -0.7319],\n",
            "        ...,\n",
            "        [ 3.2446,  1.9140, -3.0494,  ..., -0.1942,  3.2572, -1.3839],\n",
            "        [ 0.5467,  1.6967, -2.8600,  ...,  0.6170,  3.5146,  1.2680],\n",
            "        [ 3.2427,  4.3157, -4.7643,  ...,  1.9703,  2.5880,  1.7147]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3597,  0.7351, -0.8572,  ...,  1.4431,  0.7898, -0.5291],\n",
            "        [ 2.8060,  0.9157,  1.1006,  ..., -0.0331,  2.6725, -1.1037],\n",
            "        [ 2.2352,  1.8084, -0.8269,  ...,  1.0790,  1.1404, -0.5710],\n",
            "        ...,\n",
            "        [-0.0853,  3.2264, -2.9248,  ...,  1.9532,  3.0990,  3.4401],\n",
            "        [ 4.4767,  3.5618, -1.5738,  ..., -2.0976,  2.3514,  1.1428],\n",
            "        [-1.9605,  4.7394, -1.2297,  ...,  2.3367,  4.8812,  1.0367]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1973,  3.5640, -4.6339,  ..., -0.1321,  3.3981,  2.0580],\n",
            "        [-1.6329, -0.3114,  6.9671,  ...,  0.5049,  3.7372, -0.5444],\n",
            "        [ 2.0444,  1.6723, -0.4100,  ...,  1.2567,  4.1023,  4.7931],\n",
            "        ...,\n",
            "        [ 1.3909,  1.5364,  3.0664,  ...,  0.6695,  3.7385,  0.2288],\n",
            "        [-2.4490,  3.9643,  1.3116,  ...,  2.0229,  1.5566,  0.4493],\n",
            "        [ 1.7397,  3.0542, -1.1464,  ..., -1.2735,  0.6422,  1.0573]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.5202,  4.6909, -0.8594,  ..., -0.3204,  3.0732,  1.3992],\n",
            "        [ 2.5880,  5.1205, -2.4799,  ..., -0.6223,  0.4480,  1.9685],\n",
            "        [ 2.4936,  1.4182, -4.9413,  ..., -0.1655,  3.5320,  0.9236],\n",
            "        ...,\n",
            "        [ 3.3217,  5.7312,  0.2734,  ..., -0.4705,  1.8086,  2.7735],\n",
            "        [ 2.2846,  6.2578,  0.2048,  ...,  0.1938,  1.1243,  3.5672],\n",
            "        [ 1.8371,  3.2394, -5.3757,  ...,  1.2339,  1.2022,  1.4413]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2836,  0.6989,  1.0559,  ..., -0.3982,  4.7112,  0.2716],\n",
            "        [ 0.6405,  1.4985, -5.9343,  ...,  0.6531,  4.0230,  1.3001],\n",
            "        [ 0.6648,  5.2769, -1.9669,  ..., -2.5501,  0.9744, -1.0387],\n",
            "        ...,\n",
            "        [ 3.9860,  4.3948, -6.4407,  ..., -1.1452,  5.3502,  2.2609],\n",
            "        [-1.2420,  3.0463,  3.2827,  ...,  3.1011,  3.9013,  1.1773],\n",
            "        [ 3.1544, -0.6728,  0.9076,  ...,  1.1256,  3.4024,  0.0620]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3937,  1.8255, -3.0958,  ..., -0.6560,  0.8223, -0.0784],\n",
            "        [-0.2392,  3.1853, -0.3941,  ...,  4.7140,  2.4315,  1.7240],\n",
            "        [ 5.2150, -1.1067, -3.0339,  ...,  0.5040,  5.6756, -0.9688],\n",
            "        ...,\n",
            "        [-1.8631,  3.0801, -1.3079,  ...,  0.3392,  3.6355,  0.0912],\n",
            "        [-0.6761,  0.5413, -2.0976,  ...,  0.6521, -0.0248, -1.6922],\n",
            "        [-0.4286,  3.8138, -1.1285,  ...,  5.3060,  4.5209,  2.7424]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7281,  0.5442,  4.9315,  ...,  0.8507,  5.4528,  0.0108],\n",
            "        [ 2.4115,  1.3899,  5.1835,  ...,  0.9101,  0.2107,  0.8545],\n",
            "        [-0.6247,  2.3074,  3.8722,  ...,  1.9469,  2.2306,  1.7675],\n",
            "        ...,\n",
            "        [ 0.4485,  2.7329, -4.6276,  ..., -1.0578,  0.1033, -0.4361],\n",
            "        [ 4.2897,  2.6980,  2.8358,  ..., -2.8390,  0.3618,  1.2213],\n",
            "        [ 4.1780,  5.1957, -4.3978,  ..., -0.6678, -1.7712,  1.1623]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7346,  2.6052,  1.0002,  ..., -1.1345, -0.8890,  0.3028],\n",
            "        [ 1.9585,  2.2028, -3.1322,  ...,  2.1587,  1.8414,  1.1418],\n",
            "        [ 3.4877,  0.8470,  2.7433,  ...,  2.3579,  1.4925, -1.1175],\n",
            "        ...,\n",
            "        [ 0.5941,  2.0163,  1.8278,  ...,  1.0968,  5.9225,  1.0564],\n",
            "        [-0.5193,  6.2722, -2.2303,  ...,  0.1762,  1.2267,  3.9218],\n",
            "        [ 3.6865,  1.3533, -5.0214,  ...,  2.0396,  1.2129,  0.9089]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.4553,  3.5368, -0.0603,  ..., -2.2656, -1.1451,  1.4823],\n",
            "        [ 5.6108,  1.9920,  1.7288,  ..., -1.8995, -0.8399,  2.1904],\n",
            "        [ 3.8303,  2.2462, -1.8777,  ...,  2.4955,  2.4520,  0.0114],\n",
            "        ...,\n",
            "        [ 0.5235,  3.3862,  1.5619,  ...,  2.7245,  3.2797,  1.2508],\n",
            "        [ 0.3295,  2.8970,  1.3182,  ...,  1.4181,  2.9122,  2.7456],\n",
            "        [ 0.3094,  3.0066, -6.7052,  ..., -0.2652,  3.0519,  1.0379]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.0980,  2.8028,  2.3879,  ..., -1.3537,  3.7581,  2.9933],\n",
            "        [ 2.3093,  2.1298, -3.7925,  ..., -1.0087,  3.9999,  1.4596],\n",
            "        [ 4.0968,  4.6982, -4.6516,  ..., -0.6499,  1.9589,  1.5225],\n",
            "        ...,\n",
            "        [ 1.1457,  3.2033, -3.6796,  ...,  3.1771,  2.3994, -0.0399],\n",
            "        [ 3.2622, -0.2688, -0.2901,  ..., -0.5531,  2.8524, -1.7522],\n",
            "        [ 1.7072,  2.8188, -0.4736,  ..., -2.3185, -0.0132,  3.6326]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2756,  0.7450, -0.1642,  ..., -0.1097,  0.7599, -0.1967],\n",
            "        [ 2.7882,  2.0209, -0.0247,  ...,  0.5426,  1.3118,  0.6292],\n",
            "        [ 0.7850,  3.2772, -4.6006,  ..., -1.3212,  0.3602,  0.5350],\n",
            "        ...,\n",
            "        [ 0.3702, -0.2839,  2.0690,  ...,  1.9453,  3.0517,  1.9664],\n",
            "        [ 1.4131,  5.4617, -0.1494,  ..., -1.9090,  2.3325,  5.9639],\n",
            "        [ 1.1449,  2.1103,  5.7544,  ..., -1.3421,  0.8464,  0.5764]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0733e-01,  4.7561e+00, -4.8873e+00,  ...,  1.3980e+00,\n",
            "          3.6255e+00,  2.4576e+00],\n",
            "        [-8.5847e-01,  2.8570e+00, -2.7647e-01,  ...,  1.4411e+00,\n",
            "          2.6787e+00,  5.7280e-01],\n",
            "        [ 4.1234e+00,  2.3688e+00, -4.1328e+00,  ..., -3.1606e-02,\n",
            "          6.3771e+00,  8.0226e-01],\n",
            "        ...,\n",
            "        [ 2.6715e+00,  5.8943e+00, -1.6518e+00,  ..., -1.6071e+00,\n",
            "          2.1190e-01,  2.6821e+00],\n",
            "        [ 1.1121e-04,  1.4317e+00, -2.9151e+00,  ...,  4.7574e-01,\n",
            "          5.4290e+00, -4.1247e-01],\n",
            "        [ 2.0965e+00,  3.2855e+00,  2.1776e+00,  ..., -1.6786e+00,\n",
            "          3.5851e+00,  3.5600e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5423,  1.7897, -1.2757,  ...,  1.2568,  1.9264, -0.1268],\n",
            "        [ 2.0666,  4.9544,  0.7595,  ..., -3.2932,  1.5573,  3.4235],\n",
            "        [-0.7667,  2.2589, -0.2507,  ...,  2.6605,  3.5643,  3.4145],\n",
            "        ...,\n",
            "        [ 2.0421, -1.9679,  3.8013,  ..., -1.0311,  5.1112,  2.3066],\n",
            "        [ 4.9678,  4.2552, -5.0031,  ..., -0.6554,  1.3058,  0.5591],\n",
            "        [ 1.2003,  1.8152, -3.5422,  ..., -1.2343,  1.1423, -1.5213]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0924,  2.1834, -2.4775,  ..., -1.8175,  2.2082, -0.4610],\n",
            "        [ 1.3786,  1.7486,  4.3707,  ...,  0.0990,  3.7139,  0.1637],\n",
            "        [ 2.9771,  3.7134,  1.4993,  ..., -2.5523,  1.1253, -0.9684],\n",
            "        ...,\n",
            "        [ 1.0014,  2.4459,  2.0769,  ...,  3.0287,  2.4484,  0.0824],\n",
            "        [ 3.5178,  1.7658, -3.4723,  ..., -0.8741,  3.3303, -1.1455],\n",
            "        [-1.9422,  2.6723,  2.0173,  ...,  0.8578,  1.6062,  0.2138]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4230,  2.0631, -0.1148,  ...,  2.8793,  3.4838,  2.4719],\n",
            "        [-1.4949,  2.2043,  1.0445,  ..., -1.5735,  2.5886, -0.3416],\n",
            "        [ 3.0674,  3.4087,  2.6276,  ...,  1.7661,  2.3842,  0.7657],\n",
            "        ...,\n",
            "        [ 2.0226,  2.4562,  4.0224,  ...,  0.0755,  2.4100, -1.8935],\n",
            "        [ 2.1209,  2.4154,  0.3963,  ...,  1.1204,  2.5490,  2.3280],\n",
            "        [ 2.0229,  4.8957,  1.7024,  ..., -1.7881, -0.4099,  2.3168]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2491,  0.7280, -0.3752,  ...,  0.0403,  3.6864, -1.7173],\n",
            "        [ 0.0806,  1.2144,  3.6007,  ...,  0.2783,  3.6952, -0.9058],\n",
            "        [ 3.7469,  1.2083, -0.5895,  ..., -4.3435,  0.9265,  1.0425],\n",
            "        ...,\n",
            "        [-0.2628,  2.2479,  3.6301,  ...,  2.0711,  5.2836,  2.2918],\n",
            "        [ 2.8558, -0.6794,  3.2318,  ..., -4.4684,  0.5116,  0.3517],\n",
            "        [ 1.7614,  1.3606,  2.2887,  ...,  1.2858,  3.4583, -0.2660]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6246,  0.5798,  2.6490,  ..., -2.0558,  2.1437,  0.7526],\n",
            "        [-0.5321,  3.0801,  1.3366,  ...,  2.2055,  0.1516, -0.0509],\n",
            "        [ 3.4467,  4.8587, -4.9128,  ..., -2.3218,  6.6741,  3.4324],\n",
            "        ...,\n",
            "        [ 6.1480,  1.6389, -1.8067,  ..., -1.9820,  5.9258, -0.4737],\n",
            "        [ 2.6485,  0.0711,  1.6145,  ...,  1.2014,  0.3535, -1.7647],\n",
            "        [-0.9970,  2.2437,  3.6480,  ...,  0.9999,  6.2171,  0.5445]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7992,  3.8572, -3.4203,  ..., -0.7167,  2.7344,  2.6218],\n",
            "        [ 2.9354,  2.9888,  0.8118,  ..., -1.9478,  0.6548,  3.9332],\n",
            "        [-2.2070,  4.3288,  0.2493,  ...,  3.0710,  4.0505,  3.4124],\n",
            "        ...,\n",
            "        [ 3.1378,  1.8913, -3.3396,  ..., -0.9189,  5.7386, -0.3969],\n",
            "        [ 3.3770,  1.7424, -0.7938,  ..., -0.9954,  4.1224,  2.3220],\n",
            "        [ 1.1982,  2.1097,  5.9860,  ..., -3.2291,  1.9958,  1.6505]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5200,  4.1437,  4.3815,  ..., -2.4369,  4.1391,  2.2684],\n",
            "        [ 3.7998,  1.3363,  0.9127,  ..., -0.0356,  4.0178,  2.3153],\n",
            "        [ 2.3901,  2.1766, -0.4458,  ...,  1.4484,  5.2779,  2.7202],\n",
            "        ...,\n",
            "        [-0.0667,  2.3451, -2.8499,  ...,  2.8747,  3.2645,  0.8006],\n",
            "        [-0.2022,  2.5218, -2.7919,  ..., -1.8720,  3.7240,  1.1146],\n",
            "        [ 2.2913,  3.6868, -1.8164,  ..., -1.8228, -0.7239, -0.0292]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7713,  1.4634, -3.8603,  ...,  0.0174,  2.7241, -0.3973],\n",
            "        [-1.1292,  1.2502, -2.4880,  ...,  1.1705,  0.7096, -1.9797],\n",
            "        [ 1.0341,  3.7822,  3.4169,  ...,  3.2182,  5.1162,  2.9664],\n",
            "        ...,\n",
            "        [ 0.8271,  0.7172, -2.2792,  ..., -1.5475,  6.9465, -0.4250],\n",
            "        [ 0.2930,  5.2096, -0.8270,  ..., -0.8663,  2.5762,  3.7097],\n",
            "        [ 4.2012,  0.5203, -3.0077,  ...,  1.2867,  1.9581,  0.4044]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4571,  1.1824,  1.5124,  ...,  2.4052,  4.5723,  0.5957],\n",
            "        [ 2.2484,  5.3211, -4.4039,  ..., -1.3484, -0.5187,  2.4070],\n",
            "        [ 7.6903,  1.0814, -0.6929,  ..., -0.5350,  2.2915,  0.0905],\n",
            "        ...,\n",
            "        [-0.8028,  2.1990,  0.1073,  ...,  1.2447,  3.3966,  1.7194],\n",
            "        [ 1.7105, -0.6550, -0.7833,  ...,  1.7033,  3.0662, -2.9800],\n",
            "        [-1.7062, -2.0699,  2.4458,  ..., -0.8538,  0.6224, -2.0742]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1554,  4.0788, -6.5571,  ..., -1.7377,  2.3014,  0.5943],\n",
            "        [ 2.4708,  1.0201,  5.0064,  ..., -2.0424,  2.7908,  0.2134],\n",
            "        [ 0.6250,  3.5259, -2.2752,  ...,  2.2130,  1.5031,  0.6262],\n",
            "        ...,\n",
            "        [-0.4444,  2.8297, -2.4816,  ..., -0.3404,  0.9217, -0.9407],\n",
            "        [ 0.2024,  1.3614,  2.7026,  ...,  0.4124,  4.4308,  0.7115],\n",
            "        [ 1.4952,  1.3237, -1.4692,  ...,  0.9588,  2.0650, -0.9269]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0439e+00,  2.1722e+00,  4.9654e+00,  ..., -2.6659e+00,\n",
            "          3.3687e+00,  9.5129e-01],\n",
            "        [ 2.6132e+00,  9.3086e-01,  3.5225e+00,  ..., -1.8597e+00,\n",
            "          3.7135e+00,  1.8904e+00],\n",
            "        [ 9.4289e-01,  3.9148e+00, -3.8924e+00,  ...,  1.5698e+00,\n",
            "          3.2420e+00,  3.5665e+00],\n",
            "        ...,\n",
            "        [-4.9956e-01,  1.9876e+00, -2.1606e-01,  ...,  4.4756e-01,\n",
            "          3.1113e+00,  1.6544e+00],\n",
            "        [-5.6412e-01,  2.7784e+00, -4.7762e+00,  ..., -1.7670e+00,\n",
            "          1.7880e+00, -5.8926e-01],\n",
            "        [ 1.8487e+00,  4.4312e-03,  3.0534e+00,  ..., -2.5505e+00,\n",
            "          9.6373e-01,  1.4049e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4361e+00,  1.1082e+00, -1.2764e+00,  ..., -1.0967e+00,\n",
            "          5.0795e+00,  2.3858e+00],\n",
            "        [ 5.2792e+00,  3.2971e+00, -5.4946e+00,  ...,  2.1816e+00,\n",
            "          1.3093e+00,  1.7357e+00],\n",
            "        [-1.5143e+00,  1.9302e+00,  3.2923e+00,  ..., -2.5280e+00,\n",
            "          4.6194e+00,  3.8827e-01],\n",
            "        ...,\n",
            "        [ 4.3719e+00,  1.5350e+00, -3.9870e+00,  ...,  8.7637e-01,\n",
            "          1.9229e+00,  4.6966e-01],\n",
            "        [ 2.7617e+00,  4.0011e-01,  4.9483e+00,  ..., -3.0931e-03,\n",
            "          3.2652e+00,  1.3844e+00],\n",
            "        [ 1.6913e+00,  1.9396e+00, -3.7010e+00,  ..., -3.2565e-01,\n",
            "          2.3089e+00, -8.9846e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4540e+00,  4.5244e+00, -5.5369e+00,  ...,  2.0646e+00,\n",
            "         -1.3727e-02,  2.6834e+00],\n",
            "        [ 5.7136e+00,  1.9693e+00, -4.2249e+00,  ...,  1.5190e+00,\n",
            "          2.1400e+00,  8.3975e-01],\n",
            "        [-3.2845e-01,  1.1671e+00, -2.1363e+00,  ..., -1.6418e-01,\n",
            "          7.1180e-01, -1.4270e+00],\n",
            "        ...,\n",
            "        [ 2.7868e+00,  2.3880e-03, -3.2577e+00,  ...,  3.5572e-01,\n",
            "          4.4855e+00, -2.3046e+00],\n",
            "        [ 2.9980e+00,  2.6840e+00, -5.3244e+00,  ..., -8.9537e-01,\n",
            "          7.0331e+00,  2.3008e+00],\n",
            "        [ 7.9324e-01,  2.5339e+00, -3.0155e+00,  ..., -8.1019e-01,\n",
            "          4.8663e+00,  3.3944e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1732,  3.2281,  4.6510,  ..., -2.7104,  0.7758,  1.8996],\n",
            "        [ 1.2990,  2.4120, -3.9125,  ..., -0.7806,  2.9522,  1.5102],\n",
            "        [ 0.3466,  0.3502,  2.9613,  ...,  0.5959,  3.7553,  0.7930],\n",
            "        ...,\n",
            "        [ 0.9740,  3.5787, -1.3556,  ...,  0.4515,  2.5383,  0.7463],\n",
            "        [ 3.3863,  2.3185,  7.0904,  ..., -1.4013,  1.3592,  1.2372],\n",
            "        [ 4.0176,  6.6976, -1.9342,  ..., -3.9990, -0.4219,  1.8267]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3382,  2.2795, -2.2083,  ..., -1.0205,  1.5289, -0.1702],\n",
            "        [-0.1433,  5.3974, -2.8271,  ...,  0.1233,  1.2193,  4.2331],\n",
            "        [ 3.6905,  4.8989, -2.6908,  ..., -2.5368,  1.3724,  0.6217],\n",
            "        ...,\n",
            "        [ 2.8954,  2.9944,  0.1880,  ...,  2.1972,  3.6635,  1.5658],\n",
            "        [-0.8636,  1.8127, -0.4714,  ...,  0.8931,  5.0188,  0.8190],\n",
            "        [ 5.1062,  3.6876, -0.2640,  ..., -1.4991,  2.4196,  1.2163]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3620,  0.4952,  3.2034,  ..., -1.3941,  5.9325,  0.0665],\n",
            "        [ 0.9586,  4.1608, -2.3842,  ...,  0.5266,  0.8763,  0.0539],\n",
            "        [-0.2280,  3.8964, -0.5674,  ...,  2.8012,  3.8834,  0.2868],\n",
            "        ...,\n",
            "        [-1.7038,  4.3670,  2.0133,  ...,  2.8825,  3.6870,  1.7174],\n",
            "        [ 2.5151,  2.2405, -2.7192,  ..., -1.0977,  4.7502, -0.3550],\n",
            "        [ 3.3244,  6.2360, -0.3896,  ..., -1.3962, -1.3202,  1.8169]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8388,  5.0386,  4.2107,  ...,  2.1488,  4.2443,  1.9799],\n",
            "        [ 0.8542,  1.9390, -2.4204,  ..., -0.1985,  4.7552,  2.4429],\n",
            "        [-0.2113,  2.0445, -4.0563,  ..., -1.5490,  0.9015, -0.8236],\n",
            "        ...,\n",
            "        [ 0.0735,  5.2188, -3.8343,  ...,  0.4722,  2.3843,  3.5948],\n",
            "        [ 1.1285,  3.7775, -3.5310,  ..., -0.0418,  3.2711,  1.8770],\n",
            "        [ 3.3460,  0.2270,  0.3522,  ..., -1.3491,  5.2033, -1.1033]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4087,  5.3157, -3.7587,  ...,  1.5649,  3.9171,  3.4867],\n",
            "        [ 3.0106,  3.4589,  3.5903,  ..., -2.0724,  0.6272,  1.9317],\n",
            "        [ 4.7645,  4.4063,  0.7821,  ..., -1.1819, -0.9221,  1.8170],\n",
            "        ...,\n",
            "        [ 0.3168,  2.8299, -0.5687,  ..., -0.9898,  0.5507, -4.3997],\n",
            "        [-1.4828,  2.0633,  0.2400,  ..., -2.3780,  2.0385,  0.8824],\n",
            "        [ 0.8178,  2.3345, -3.1094,  ..., -1.3108,  2.5091,  0.7709]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2595,  0.4475, -1.7898,  ...,  0.8551,  1.0817, -0.6317],\n",
            "        [ 3.9172,  6.2973, -5.3084,  ..., -2.7271, -0.5101,  1.4951],\n",
            "        [ 3.6127,  4.5277, -1.2279,  ..., -1.6386,  2.5285, -0.9992],\n",
            "        ...,\n",
            "        [ 0.5020,  3.1596, -4.0998,  ...,  0.5439,  3.4691,  1.2101],\n",
            "        [ 0.2556,  3.3784, -6.0684,  ..., -2.0288,  1.6132, -0.2660],\n",
            "        [ 1.9820,  1.0580, -1.5472,  ..., -1.7506,  6.2203,  0.9219]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4584,  5.1577,  0.3523,  ..., -0.7266,  1.8950, -0.9956],\n",
            "        [-1.3190,  2.5659,  5.8678,  ...,  1.7198,  3.3677, -0.4073],\n",
            "        [ 2.8239,  4.6206,  1.0105,  ...,  0.7916,  1.6909,  1.9143],\n",
            "        ...,\n",
            "        [ 1.4176,  0.9945,  4.4094,  ..., -2.8802,  3.2336,  1.9211],\n",
            "        [ 1.6257,  2.5152, -1.2630,  ..., -0.8934,  5.5356,  1.9739],\n",
            "        [ 1.4159,  4.6386, -4.6547,  ..., -1.9943,  4.2373,  3.5860]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1057,  2.9382,  0.1282,  ...,  1.0207,  3.1637,  1.6688],\n",
            "        [ 0.2432,  1.9266, -4.5430,  ..., -0.8584,  1.1499, -1.3119],\n",
            "        [ 5.4135,  0.3947,  1.3258,  ..., -1.0438,  4.1771, -0.4420],\n",
            "        ...,\n",
            "        [ 2.7592,  5.2736, -1.6908,  ..., -2.0664,  1.4551,  2.9942],\n",
            "        [ 1.0865,  2.8163,  1.2352,  ..., -1.8010,  4.8623, -0.0484],\n",
            "        [ 0.7568,  2.1062,  2.9329,  ...,  1.2960,  2.2764,  2.0524]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3341,  2.7846, -0.2371,  ...,  0.5249, -0.3376,  0.2189],\n",
            "        [ 0.2670,  5.5003, -7.8708,  ..., -0.3475,  3.3217,  1.3194],\n",
            "        [-0.0447,  1.6685,  1.8407,  ..., -0.1791,  3.1703,  1.4492],\n",
            "        ...,\n",
            "        [ 0.5496,  1.8330, -2.4814,  ..., -0.4929,  4.1545,  2.0934],\n",
            "        [-0.6776,  3.5369,  0.0600,  ...,  0.2391,  3.2009,  5.8454],\n",
            "        [-1.7890,  3.8161, -4.6206,  ..., -1.0387,  1.3013, -0.3957]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4610,  5.1525, -2.8342,  ..., -0.0618,  3.4095,  3.7437],\n",
            "        [-0.1228,  3.5421,  0.4592,  ...,  0.2675,  2.0764, -1.1593],\n",
            "        [ 3.7848, -0.5650,  4.5571,  ..., -4.4387,  1.3805, -0.1968],\n",
            "        ...,\n",
            "        [ 0.2125,  4.3742,  3.1523,  ...,  2.3462,  5.2445,  1.3758],\n",
            "        [ 4.2901,  0.5586, -1.2707,  ...,  0.2445,  1.4024, -0.6664],\n",
            "        [ 1.6561,  5.6715,  0.7158,  ..., -0.2757,  1.4035,  5.3865]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7727,  1.0894,  6.2293,  ...,  0.7957,  3.7733, -0.0936],\n",
            "        [ 2.8581,  4.0637,  5.0427,  ..., -3.7459,  3.2758,  3.8609],\n",
            "        [ 6.3346,  2.5179,  0.0645,  ...,  0.4870,  2.4183,  1.6446],\n",
            "        ...,\n",
            "        [ 5.5763,  0.9413,  2.2046,  ..., -3.7712, -0.2540,  1.5563],\n",
            "        [ 1.4300,  2.4017, -2.4485,  ..., -1.5157,  0.5828, -1.4677],\n",
            "        [ 3.3383,  1.1732,  4.1393,  ..., -2.0860,  1.0134,  0.5049]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4966,  3.8916, -1.4177,  ..., -1.8718,  3.6201,  1.1634],\n",
            "        [ 2.8751,  5.7233, -1.4620,  ..., -1.0720,  3.9873,  2.8474],\n",
            "        [ 0.6005,  2.7887,  3.5217,  ..., -0.5551,  1.0866, -0.1912],\n",
            "        ...,\n",
            "        [ 4.1546,  2.8117, -8.0708,  ...,  0.1149,  0.5594,  2.5755],\n",
            "        [-0.0518, -0.6783, -1.3911,  ...,  0.5003,  0.0423, -1.5888],\n",
            "        [ 0.9600,  2.8828, -1.8849,  ..., -0.9461,  0.4378,  0.6084]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1462,  1.0467, -4.2743,  ...,  1.0134,  3.9026,  1.4648],\n",
            "        [ 2.9581,  0.6741, -0.1363,  ..., -1.3033,  1.7978, -0.9461],\n",
            "        [-0.8531,  1.7317, -2.3074,  ...,  2.1964,  5.3414,  1.9054],\n",
            "        ...,\n",
            "        [ 5.4056,  3.5511, -0.3230,  ..., -1.4854,  1.3947,  2.6636],\n",
            "        [ 2.7644,  5.4554,  3.8673,  ..., -5.3846, -0.7459, -1.5379],\n",
            "        [-1.6742,  3.7533, -1.4561,  ...,  2.0325,  2.2866,  0.9016]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1656,  4.0092, -2.3264,  ...,  2.3181,  3.8815,  2.2784],\n",
            "        [-1.0264,  3.9498,  2.1406,  ...,  2.3983,  4.7160,  3.2497],\n",
            "        [ 0.1010,  1.4167, -3.0206,  ..., -0.0453,  2.0273, -1.1426],\n",
            "        ...,\n",
            "        [-0.3484,  3.3312, -0.7165,  ...,  2.0890,  4.4079,  2.8548],\n",
            "        [ 2.1968,  1.1116,  2.0119,  ...,  1.0343,  0.8161, -2.8256],\n",
            "        [-0.2726,  2.3137, -1.7061,  ..., -0.1556,  1.7256,  1.4122]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3702,  6.2966,  0.4075,  ..., -1.9751, -1.4298,  1.2336],\n",
            "        [ 4.7434,  2.5244, -1.5224,  ...,  0.4088,  2.2389, -1.3660],\n",
            "        [ 1.6141,  0.0839,  1.8826,  ...,  1.8963,  3.2491,  0.1956],\n",
            "        ...,\n",
            "        [ 2.9937,  1.5402,  0.6226,  ...,  0.6620,  3.0080,  0.3418],\n",
            "        [ 0.7430,  3.1008,  0.3508,  ...,  2.1648,  2.2576,  1.3845],\n",
            "        [-0.6525,  1.0975,  2.3552,  ...,  0.8699,  2.2739, -0.5300]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4396,  4.1482, -2.9680,  ...,  2.2314,  4.9283,  2.2243],\n",
            "        [ 1.5754,  0.6192,  1.1584,  ..., -1.0403,  3.8576, -0.1876],\n",
            "        [ 4.1469,  1.5403,  1.1215,  ..., -3.1993,  0.3754,  0.7578],\n",
            "        ...,\n",
            "        [-1.9174,  1.5326,  5.6144,  ..., -1.5241,  0.9749, -0.1188],\n",
            "        [-3.8918,  4.0719, -2.3891,  ..., -1.0224,  2.8795,  0.8628],\n",
            "        [ 1.4395,  4.9614, -6.3774,  ..., -0.9126,  2.6559,  1.7256]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0567,  2.9073, -1.2930,  ...,  1.6525,  2.7670,  0.6686],\n",
            "        [-1.1354,  4.1183,  1.1224,  ..., -2.1962,  4.8552,  1.1397],\n",
            "        [ 4.3708,  4.4517,  0.4017,  ..., -1.6167,  1.7771,  3.9166],\n",
            "        ...,\n",
            "        [ 3.3786,  3.4227,  5.6219,  ..., -2.2141,  0.3964,  1.8189],\n",
            "        [ 4.2571,  2.4844, -2.0019,  ..., -1.1944,  2.6375, -0.2806],\n",
            "        [ 0.8098,  2.8712,  3.5817,  ..., -1.6337,  4.3468,  0.6856]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0139,  2.4024, -3.0133,  ..., -2.3345, -0.0311, -0.7576],\n",
            "        [ 1.6809,  1.3957, -2.6359,  ...,  0.1737,  2.1195,  0.2802],\n",
            "        [-0.5112,  4.0194, -0.2813,  ..., -1.6414,  2.5831,  0.0196],\n",
            "        ...,\n",
            "        [ 3.1996,  2.6039, -3.2247,  ..., -2.0973,  1.2246,  0.4555],\n",
            "        [ 1.8465,  1.2803,  2.2547,  ..., -2.5221,  3.6193, -0.4520],\n",
            "        [ 2.2278,  4.4709, -5.1965,  ..., -1.9300, -0.3108, -0.0278]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3961e+00,  1.0510e+00, -2.4962e+00,  ..., -7.0388e-01,\n",
            "          6.5006e+00,  1.1653e+00],\n",
            "        [ 3.8050e+00,  4.6405e+00,  4.2278e+00,  ..., -2.2682e+00,\n",
            "          2.6594e-01,  2.7950e+00],\n",
            "        [-5.0937e-01,  1.0548e+00,  1.4927e+00,  ..., -8.2341e-01,\n",
            "          1.3795e+00,  2.2922e-01],\n",
            "        ...,\n",
            "        [ 5.4843e-02,  4.5278e+00, -4.0287e+00,  ..., -2.6911e+00,\n",
            "          2.6701e+00,  1.2850e+00],\n",
            "        [-4.3779e-01,  1.1304e+00, -2.3108e-01,  ..., -5.3833e-01,\n",
            "          8.4628e-01,  3.8414e-03],\n",
            "        [ 5.3935e-01,  6.9441e-01, -6.2890e+00,  ..., -5.5902e-01,\n",
            "          1.4573e+00,  2.9020e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.1258,  2.3833,  2.2997,  ...,  1.6181,  3.0167,  1.7995],\n",
            "        [ 1.5407,  0.3160, -4.2448,  ...,  0.4776,  2.0613,  0.6830],\n",
            "        [ 2.0097,  4.3983, -2.5482,  ..., -0.7935,  2.7798,  2.7313],\n",
            "        ...,\n",
            "        [ 0.6482,  3.9456, -0.4981,  ..., -1.6675,  5.7381,  2.9196],\n",
            "        [ 0.4719,  1.9020, -2.1441,  ..., -0.6766,  3.8324,  3.0850],\n",
            "        [ 2.0737,  1.8217,  0.9092,  ..., -0.7131,  3.5103,  1.8394]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5800,  4.1363, -6.1444,  ..., -2.3877,  1.5269,  0.2428],\n",
            "        [ 4.9032,  2.2001,  2.1037,  ..., -2.4914,  0.3075,  1.3589],\n",
            "        [ 3.9531,  4.7026, -5.6562,  ..., -2.8816, -1.2938,  1.4962],\n",
            "        ...,\n",
            "        [ 3.8275,  1.4552, -0.5567,  ..., -2.2957,  1.8661,  0.5777],\n",
            "        [ 5.7124,  1.6609,  6.7599,  ..., -3.4029,  0.0199,  0.5311],\n",
            "        [-1.0235,  2.9704, -0.4427,  ..., -0.2570,  1.9901, -0.5341]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6642,  3.4402, -3.2911,  ..., -3.2397,  1.7369,  0.2107],\n",
            "        [ 4.4023,  5.3992,  4.8365,  ..., -1.8515,  1.0152,  2.3781],\n",
            "        [-0.3437,  1.6051,  0.5787,  ...,  0.6324,  0.7085,  0.3873],\n",
            "        ...,\n",
            "        [ 5.4249,  1.4997, -3.5049,  ..., -0.4887,  1.8757, -0.4377],\n",
            "        [ 2.4538,  4.8683,  0.1810,  ..., -3.7086,  4.1569,  3.6734],\n",
            "        [ 2.3287,  2.6527, -1.9598,  ..., -0.5012,  2.7972, -0.5172]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 9.4182e-01,  7.6127e-01, -5.2597e+00,  ...,  6.6106e-01,\n",
            "          4.8089e+00,  1.9320e+00],\n",
            "        [ 4.5344e+00,  4.3621e+00,  1.6493e+00,  ..., -2.7322e-03,\n",
            "          9.4268e-01, -1.0153e+00],\n",
            "        [ 2.3190e+00,  2.4091e+00,  2.6018e+00,  ..., -1.4228e+00,\n",
            "          5.7817e+00,  1.9322e+00],\n",
            "        ...,\n",
            "        [-2.1028e+00,  1.8485e+00, -6.8687e-01,  ..., -1.0912e+00,\n",
            "          2.2840e+00,  2.5900e+00],\n",
            "        [ 2.7761e+00,  2.3705e+00, -5.1826e+00,  ..., -1.5344e+00,\n",
            "          3.9307e+00,  8.3826e-02],\n",
            "        [ 1.8426e+00,  2.1793e+00,  1.7891e+00,  ..., -1.1611e+00,\n",
            "          2.3042e+00, -8.5055e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.8035,  2.9247, -1.1044,  ..., -0.6711,  1.6872,  1.1907],\n",
            "        [ 5.1301,  3.9933,  2.1480,  ..., -0.8103,  0.1270,  0.5235],\n",
            "        [ 2.2488,  3.9617,  0.6587,  ..., -1.6213,  2.8224, -0.6593],\n",
            "        ...,\n",
            "        [ 1.0719,  7.7274, -1.4751,  ..., -3.0400,  3.5888,  2.6750],\n",
            "        [ 3.3609,  3.8416, -2.4435,  ..., -1.7832,  1.0304,  1.2635],\n",
            "        [-0.7580,  3.1945, -5.1963,  ..., -3.1639,  1.7914,  0.2509]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7940, -1.3203,  4.7337,  ..., -1.0945,  4.8079,  1.1293],\n",
            "        [ 2.4005,  4.4372,  2.2486,  ...,  2.8769,  4.2776,  1.0522],\n",
            "        [ 0.6394,  1.0431,  1.2167,  ..., -1.0412,  2.6740,  0.1352],\n",
            "        ...,\n",
            "        [-0.4564,  1.8856, -0.2402,  ...,  1.1980,  2.0598,  0.2179],\n",
            "        [ 4.0296,  3.7054,  2.2216,  ..., -2.6118, -0.0609, -1.4433],\n",
            "        [ 4.7235,  4.3315, -1.3489,  ..., -2.2488,  1.4409,  1.4480]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0510e-01,  3.2329e+00, -4.3410e+00,  ..., -2.0238e+00,\n",
            "          8.7846e-01, -7.5124e-01],\n",
            "        [ 2.8729e+00,  9.5633e-01, -2.1536e+00,  ..., -1.5558e+00,\n",
            "          3.3379e+00, -9.5390e-01],\n",
            "        [ 1.8964e+00,  2.4656e+00, -2.9020e+00,  ..., -1.7162e+00,\n",
            "          1.9297e+00, -4.1982e-01],\n",
            "        ...,\n",
            "        [-6.4630e-01,  3.6817e+00, -4.8165e+00,  ..., -2.3039e+00,\n",
            "          1.1224e+00, -3.1277e-01],\n",
            "        [ 3.0644e+00,  3.1243e+00,  2.3613e-02,  ..., -1.7309e+00,\n",
            "          1.7735e+00, -1.5502e+00],\n",
            "        [ 5.0237e-01, -2.7259e-02,  1.9316e+00,  ..., -4.1143e-03,\n",
            "          2.3078e+00, -1.4227e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-7.7568e-01, -9.9997e-01,  4.8562e+00,  ...,  2.8218e+00,\n",
            "          2.0440e+00,  1.2061e-03],\n",
            "        [-2.0277e+00,  4.0100e+00, -2.1965e+00,  ..., -1.8646e-01,\n",
            "          2.2115e+00,  8.1136e-01],\n",
            "        [ 3.7069e+00,  2.2618e+00,  4.9892e+00,  ..., -8.8666e-01,\n",
            "          3.9255e+00,  2.0649e+00],\n",
            "        ...,\n",
            "        [-9.3688e-01,  2.7842e+00, -2.5894e+00,  ..., -1.8881e+00,\n",
            "          1.6213e+00, -1.5917e-01],\n",
            "        [ 2.2229e+00,  3.1365e+00,  7.5477e-01,  ...,  1.4998e+00,\n",
            "          3.0433e+00,  9.3659e-01],\n",
            "        [-2.2444e+00,  7.0138e+00, -6.3416e+00,  ..., -3.4982e+00,\n",
            "          2.2284e+00, -9.9840e-02]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9549,  6.2822, -1.4625,  ..., -4.1433, -0.3958,  0.3837],\n",
            "        [ 1.5696,  2.8381,  8.7112,  ..., -0.2147,  4.0653,  1.4743],\n",
            "        [ 2.8948,  1.4767, -4.2110,  ..., -1.3066,  4.2971,  0.5164],\n",
            "        ...,\n",
            "        [ 0.8065,  3.0165,  0.9094,  ..., -1.8102,  2.9577, -2.2791],\n",
            "        [-0.0613,  2.6704,  1.0534,  ...,  1.2768,  3.4042,  1.0052],\n",
            "        [ 1.4285,  0.2731, -4.5009,  ...,  0.0538,  3.3962,  1.1184]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4160,  2.5964,  2.8975,  ...,  0.7521,  5.2031,  1.2919],\n",
            "        [ 4.3187,  3.4684, -4.9100,  ..., -0.2116,  0.9151, -0.5106],\n",
            "        [ 0.9105,  3.8922,  4.4931,  ...,  2.3210,  4.8049,  1.0544],\n",
            "        ...,\n",
            "        [ 3.9112,  3.0362, -3.4017,  ..., -1.5803,  6.5070, -0.8416],\n",
            "        [ 1.6487, -0.8298,  2.3710,  ...,  0.0873,  4.0037, -0.1871],\n",
            "        [-1.7763,  0.8190,  5.5670,  ..., -0.6549,  7.5248,  1.1194]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0258,  7.1966, -1.3296,  ..., -2.5043,  0.2063,  4.7752],\n",
            "        [ 1.8600,  0.0244, -4.4411,  ...,  0.1163,  4.7594,  0.2253],\n",
            "        [-1.3290,  4.4156,  0.9472,  ...,  3.3600,  4.5469,  2.3674],\n",
            "        ...,\n",
            "        [-0.8707,  3.6219,  1.9413,  ...,  1.8473,  2.9768,  1.4227],\n",
            "        [ 0.1769,  3.1121, -5.3773,  ..., -0.8414,  2.2302, -0.6561],\n",
            "        [ 6.5572, -0.3920, -1.3153,  ...,  0.5776,  2.3172, -1.2123]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3579,  2.9090, -3.5262,  ..., -2.1225,  0.6947, -0.7113],\n",
            "        [-0.4887,  3.2138, -2.9438,  ...,  0.0920,  2.8058,  1.8695],\n",
            "        [-1.4513,  0.5454,  7.0649,  ...,  0.4751,  4.7431,  2.1849],\n",
            "        ...,\n",
            "        [ 2.0339,  1.6270,  3.8599,  ..., -0.3395,  5.5515, -0.5685],\n",
            "        [ 2.5724, -0.3333,  1.2958,  ...,  2.0579,  3.4051, -1.9789],\n",
            "        [ 0.8215,  2.8688,  2.5490,  ..., -3.0196,  2.8046,  2.8556]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8788,  5.9197, -2.2309,  ..., -2.1815, -0.0412,  1.4552],\n",
            "        [ 5.6539,  1.8177,  4.7557,  ..., -1.3067,  1.6173, -1.2158],\n",
            "        [ 1.8182,  3.5888, -1.0740,  ..., -3.5964,  1.3647, -0.1279],\n",
            "        ...,\n",
            "        [ 2.5390,  6.3240, -2.0409,  ..., -1.1310,  0.6990,  1.6309],\n",
            "        [ 0.6394,  1.8712, -1.5613,  ...,  1.6958,  4.0710,  1.6876],\n",
            "        [ 1.5241,  4.2294,  1.5488,  ...,  2.7822,  3.1438,  1.5316]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2597,  1.7888,  3.0905,  ..., -2.0316,  0.4379, -0.5669],\n",
            "        [-0.4690,  3.4297, -3.5847,  ..., -1.6372,  0.5336, -1.1899],\n",
            "        [ 1.8380,  5.5276,  0.3730,  ...,  0.5899,  4.4447,  3.8636],\n",
            "        ...,\n",
            "        [ 0.1137,  3.4124, -1.9944,  ...,  2.4143,  4.8569, -1.0594],\n",
            "        [ 0.5534, -0.6938,  4.9809,  ..., -2.9136,  3.3784, -1.2150],\n",
            "        [-0.7345,  1.5953, -2.2314,  ...,  0.1208,  0.5535, -2.2675]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1667,  2.8407, -4.6293,  ..., -1.5341,  4.2714, -0.3280],\n",
            "        [-0.1334,  2.1079, -0.1932,  ...,  0.2979,  3.4055, -0.5218],\n",
            "        [-3.7558,  5.6050, -3.2251,  ..., -0.2528,  2.8038,  2.2757],\n",
            "        ...,\n",
            "        [ 1.4521,  0.7167,  5.5097,  ..., -2.0098,  3.3223,  0.8605],\n",
            "        [ 3.1197,  0.5963, -0.3183,  ..., -0.5050,  6.3439,  0.0322],\n",
            "        [ 2.2426,  3.8325, -0.1185,  ..., -3.3869,  0.3678,  0.4680]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0965, -1.3201,  1.2942,  ...,  0.7652,  4.5168, -0.4646],\n",
            "        [ 1.8483,  1.7689, -1.1208,  ..., -1.4738, -0.7171, -0.7853],\n",
            "        [-0.9512,  1.5460, -2.6588,  ..., -0.8554,  1.8552, -0.8472],\n",
            "        ...,\n",
            "        [ 0.9891, -1.6444,  7.9954,  ...,  0.4686,  4.1539,  0.9712],\n",
            "        [ 0.0765,  2.9958, -4.4625,  ..., -1.9679,  0.1509, -0.7740],\n",
            "        [ 2.3550,  3.9267,  2.0277,  ..., -2.0987,  0.7362,  0.5037]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6874,  2.0949,  3.7789,  ..., -2.5545,  3.7517,  3.0466],\n",
            "        [ 1.5839,  5.8083, -1.8895,  ..., -0.2750,  2.5260,  3.5887],\n",
            "        [-2.1582,  2.0567,  2.3914,  ..., -1.8519,  3.7651,  2.5548],\n",
            "        ...,\n",
            "        [ 3.1304,  2.2564, -5.6128,  ..., -1.5353,  4.3697, -0.1048],\n",
            "        [ 2.7739,  2.2494, -6.8919,  ...,  1.1620,  3.0956,  0.6345],\n",
            "        [ 2.8047,  5.0977, -7.5433,  ..., -2.1424,  1.3303,  1.2918]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1853e+00,  3.4068e+00,  2.4803e+00,  ...,  5.7647e-01,\n",
            "          4.3071e-01,  8.8706e-01],\n",
            "        [-2.7116e-01,  1.5398e-01,  2.3484e+00,  ...,  3.7231e-01,\n",
            "          3.8733e+00,  6.9010e-03],\n",
            "        [ 4.3233e+00,  1.8971e+00, -1.4796e-01,  ..., -7.8968e-01,\n",
            "          1.5987e+00, -2.6625e+00],\n",
            "        ...,\n",
            "        [ 6.8127e-01,  3.0744e+00,  4.7601e+00,  ..., -5.1564e-01,\n",
            "          1.5868e+00, -7.4783e-01],\n",
            "        [ 2.4253e+00,  7.2349e+00,  1.3120e+00,  ..., -1.6268e+00,\n",
            "          2.5320e+00,  2.0803e+00],\n",
            "        [-1.5228e+00,  4.8209e+00, -4.1097e-01,  ...,  1.5312e+00,\n",
            "          3.3331e+00,  9.7789e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6502,  6.8490, -0.5117,  ..., -2.0980,  0.1356,  1.9339],\n",
            "        [ 0.4894, -0.1570,  1.4637,  ...,  0.5467,  3.9634, -2.0752],\n",
            "        [ 1.6998, -0.8073, -0.4194,  ...,  0.4518,  2.4832, -5.2226],\n",
            "        ...,\n",
            "        [ 2.8891,  3.3811, -4.9382,  ..., -1.4901,  0.0775,  1.3433],\n",
            "        [-0.1475,  3.7664, -4.6810,  ..., -2.5167,  1.9138,  0.6422],\n",
            "        [ 4.1057,  1.8217,  6.4655,  ..., -2.8267,  1.2570,  2.8354]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.7430,  2.1354, -2.3112,  ..., -1.5378,  3.5385, -1.9066],\n",
            "        [ 3.1045,  2.4300, -3.0820,  ..., -0.8551,  6.3624, -0.4742],\n",
            "        [ 2.5337,  0.5150,  2.6700,  ..., -3.2610,  3.1676, -0.0952],\n",
            "        ...,\n",
            "        [ 2.3029,  5.5241, -2.2165,  ...,  0.3395,  2.0357,  4.6334],\n",
            "        [ 0.1163,  4.6677, -7.3059,  ..., -2.2892,  3.6257,  0.9915],\n",
            "        [ 3.6741,  3.7173, -2.1696,  ..., -0.0508,  1.3085,  1.5504]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8109,  3.8235, -0.6120,  ..., -0.2195,  4.8907,  1.7656],\n",
            "        [ 3.2834,  1.3477,  8.1783,  ..., -5.6081,  1.5661,  1.2804],\n",
            "        [ 2.9949,  2.5012, -2.5425,  ..., -1.2431,  4.0091, -0.1505],\n",
            "        ...,\n",
            "        [ 5.3999,  4.0508, -1.4776,  ...,  1.2870,  0.1946,  0.9506],\n",
            "        [-1.8542,  3.0622,  2.0366,  ..., -2.8149,  4.3123,  3.2143],\n",
            "        [ 3.1572,  3.9964,  1.1406,  ..., -3.2597,  2.0369, -0.0452]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8683,  2.2371, -0.4167,  ...,  0.2148,  4.1781,  3.4493],\n",
            "        [-2.2013,  6.1080, -0.8671,  ..., -1.1558,  1.3967,  4.3033],\n",
            "        [-0.2335,  2.5562, -3.1027,  ..., -1.6270,  1.2521,  0.2913],\n",
            "        ...,\n",
            "        [ 0.1438,  2.3239,  0.8178,  ...,  2.2543,  3.7188, -1.1684],\n",
            "        [-0.6644,  4.5436, -5.0282,  ..., -1.9363,  0.4956,  0.0186],\n",
            "        [-2.0433,  7.7156,  2.1546,  ...,  0.7030, -0.1051,  2.3014]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1300, -0.6701,  2.3178,  ...,  0.1071,  5.1313,  1.2709],\n",
            "        [-3.2274,  5.3500, -1.5045,  ...,  1.5941,  3.6688,  3.6000],\n",
            "        [-1.1081,  5.0436, -3.0747,  ..., -0.4955,  1.1012,  0.4093],\n",
            "        ...,\n",
            "        [ 1.4983,  5.0455,  1.4354,  ...,  1.4272,  2.1701,  3.7255],\n",
            "        [ 0.3266,  1.8964, -0.3343,  ..., -2.3502,  1.5184,  1.6203],\n",
            "        [ 3.2805,  4.5092, -2.8352,  ..., -0.5638,  0.8377, -0.5889]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0365,  0.8529,  0.5741,  ...,  1.1800,  3.5198,  0.5039],\n",
            "        [ 2.1473,  1.2524, -2.0603,  ..., -1.4820,  2.9160, -0.8741],\n",
            "        [ 1.9820,  0.4905,  2.0693,  ...,  0.3218,  2.7075, -1.3246],\n",
            "        ...,\n",
            "        [-2.3480,  7.7933, -1.4916,  ..., -1.7939,  0.9660,  1.6776],\n",
            "        [ 0.6011,  2.6387, -2.9252,  ..., -2.2851,  0.0913, -0.8745],\n",
            "        [ 2.5603,  4.1321, -0.8718,  ..., -2.2625, -0.8769,  3.8709]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5051,  4.9225,  1.6418,  ...,  0.9518, -0.2887, -0.2747],\n",
            "        [ 4.2709,  4.6892,  0.7730,  ..., -1.9125,  0.3391, -1.5647],\n",
            "        [ 2.0309,  3.4560,  4.1557,  ..., -1.5386,  1.1640,  3.7979],\n",
            "        ...,\n",
            "        [ 0.1262,  0.5938, -1.6088,  ...,  1.3568,  0.3937, -3.6689],\n",
            "        [ 1.9507,  3.0149,  2.2013,  ...,  2.2747,  2.3027,  1.1962],\n",
            "        [ 2.0055,  2.8259,  0.1635,  ...,  2.4095,  3.3698, -0.2443]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.8838, -0.3861,  6.6872,  ..., -0.8960,  3.4656, -1.8218],\n",
            "        [ 1.8006,  0.3398,  2.7773,  ..., -0.6040,  4.8662,  0.3342],\n",
            "        [ 0.5003,  0.2351, -0.0383,  ...,  0.5452,  0.5443, -2.4836],\n",
            "        ...,\n",
            "        [ 1.7519, -1.2884,  1.3276,  ..., -1.4014,  2.5147, -1.9539],\n",
            "        [ 6.5626, -0.0525,  3.6787,  ..., -0.0446,  2.2379, -4.1941],\n",
            "        [-0.2625,  4.1802,  1.6128,  ...,  2.5803,  4.4527,  0.6572]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8188,  3.2231,  0.9746,  ...,  3.1783,  4.8361,  2.3986],\n",
            "        [ 3.3050,  3.0848,  3.4958,  ..., -1.2060,  3.0050, -1.4338],\n",
            "        [ 2.8126,  5.6500,  1.9092,  ..., -1.5307, -1.5032,  1.4551],\n",
            "        ...,\n",
            "        [-0.4614,  2.7061, -4.0748,  ..., -1.9172,  1.0369, -1.2069],\n",
            "        [ 2.0067,  4.3993, -1.0846,  ..., -2.8282, -0.2946,  0.5068],\n",
            "        [-0.4443,  1.7170, -0.0516,  ...,  3.5885,  4.7312,  1.8305]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9093,  2.2748, -1.4980,  ..., -0.8036,  0.7312, -1.2139],\n",
            "        [ 3.7493,  3.1953,  6.8474,  ...,  0.7066,  1.2071, -0.0610],\n",
            "        [ 4.2549,  1.7751,  2.3123,  ...,  0.7820,  3.6268,  0.4997],\n",
            "        ...,\n",
            "        [ 1.4113,  2.7942, -6.2708,  ..., -0.6104,  7.3631,  1.2101],\n",
            "        [ 3.5280,  1.5782, -1.3626,  ..., -1.9599,  3.4322,  3.6106],\n",
            "        [-1.5579,  1.5785,  2.4951,  ..., -1.6494, -0.3435, -2.5883]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.0188e+00,  2.5194e+00,  8.5382e+00,  ..., -4.4626e+00,\n",
            "          1.8820e+00,  2.1020e+00],\n",
            "        [ 3.1149e+00,  2.4622e+00,  5.3363e+00,  ..., -1.8172e+00,\n",
            "          7.5660e-03,  1.1917e+00],\n",
            "        [-2.4047e+00,  4.6254e+00,  1.1426e+00,  ..., -3.7937e-01,\n",
            "          2.8160e+00,  2.2491e+00],\n",
            "        ...,\n",
            "        [ 3.7644e+00,  4.1279e+00, -3.6519e+00,  ..., -1.5065e+00,\n",
            "          4.2371e-02,  7.5009e-01],\n",
            "        [ 1.3546e+00,  4.6470e-01,  2.4683e+00,  ...,  1.7250e+00,\n",
            "          4.6026e+00,  6.0497e-01],\n",
            "        [ 1.3176e+00,  1.7459e+00, -3.4912e+00,  ..., -3.9594e-02,\n",
            "          2.3817e+00,  1.4000e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4862,  2.5243, -1.1580,  ..., -0.4840,  2.5207, -0.2204],\n",
            "        [ 1.7223, -1.0792,  3.6493,  ...,  0.9806,  2.5512,  1.1635],\n",
            "        [ 4.2775,  3.4771,  0.5482,  ..., -2.9092,  2.5775,  3.1899],\n",
            "        ...,\n",
            "        [-3.8230,  0.6181,  6.8218,  ...,  1.0572,  2.3875, -0.3365],\n",
            "        [-0.5492,  2.8837, -2.0145,  ..., -0.4549,  1.5608, -0.9787],\n",
            "        [ 0.1269,  2.4620,  3.0550,  ..., -1.6347,  1.2592, -4.3163]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5571,  1.4662,  3.6761,  ...,  0.0439,  1.8598, -0.7586],\n",
            "        [-1.4702, -1.9404,  7.3171,  ..., -0.5097,  2.7252, -3.2604],\n",
            "        [-0.1857,  4.7189, -2.1031,  ..., -1.6245,  1.1110,  0.9876],\n",
            "        ...,\n",
            "        [ 3.0239,  2.9609, -6.2633,  ..., -0.9734,  3.2008, -0.0877],\n",
            "        [ 1.3258, -0.4313,  1.4960,  ..., -0.6426,  0.8642, -3.0514],\n",
            "        [ 6.0298, -1.8635,  1.5308,  ...,  0.9621,  0.5195, -2.1378]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1686,  2.4938, -1.1564,  ...,  0.4746,  2.2492, -0.0539],\n",
            "        [-0.4673,  0.9032, -1.6879,  ...,  0.4663,  0.5062, -3.1535],\n",
            "        [-2.2079,  1.4718,  7.8381,  ..., -2.3932,  4.5615, -0.4395],\n",
            "        ...,\n",
            "        [-0.3813,  3.2581, -0.2299,  ...,  0.5824, -0.1034, -0.3499],\n",
            "        [-0.7400,  2.6622, -3.0627,  ..., -1.3599,  0.9654, -1.4423],\n",
            "        [-2.2253,  3.3191,  0.8525,  ...,  1.7981,  3.4160,  1.3528]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3019,  1.5140,  1.9436,  ...,  1.0977,  4.4934,  0.9996],\n",
            "        [ 5.7773,  2.6006,  1.0839,  ..., -3.7644, -1.9662,  1.6919],\n",
            "        [ 4.7596,  2.8990, -4.6013,  ..., -2.5003,  2.2984, -1.6525],\n",
            "        ...,\n",
            "        [ 3.2226,  1.4308,  6.8383,  ..., -2.1550,  1.2253,  1.8942],\n",
            "        [-0.2985,  1.0238,  1.6199,  ...,  0.4993,  5.0608, -0.7441],\n",
            "        [ 3.5561,  1.9862,  1.4879,  ..., -0.7087, -0.0708, -0.7089]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4986,  4.9248,  0.5019,  ..., -0.9654,  2.3648, -0.6021],\n",
            "        [ 1.0455,  3.4209, -6.6544,  ..., -2.4227,  1.8414, -0.6996],\n",
            "        [-1.0148,  2.3777,  3.2057,  ...,  0.4701,  2.0510, -0.2077],\n",
            "        ...,\n",
            "        [-2.4129,  3.5251, -0.1593,  ...,  0.9128,  1.2105, -1.1424],\n",
            "        [ 4.4921,  3.2517, -0.3939,  ..., -1.9243,  6.3416, -0.2055],\n",
            "        [ 0.9383,  3.2226,  0.4669,  ..., -2.8852,  2.3161,  4.0767]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4683,  1.9615,  4.0707,  ...,  1.3181,  3.1741,  1.1973],\n",
            "        [ 0.5578,  2.0350, -3.2935,  ..., -0.1648,  4.0785,  1.4524],\n",
            "        [ 1.2465, -0.2618,  0.7373,  ...,  2.5182,  2.4871, -2.9555],\n",
            "        ...,\n",
            "        [ 1.3617,  0.1172,  2.2554,  ..., -0.1120,  2.9071,  0.1236],\n",
            "        [-0.3085,  3.5228, -3.9882,  ..., -2.3344,  0.6310, -1.9142],\n",
            "        [ 3.9164,  2.6630, -2.3743,  ...,  1.1181,  1.8431, -1.1086]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0439,  1.1411,  3.1322,  ..., -3.3387,  2.8462, -3.0201],\n",
            "        [ 0.7564,  4.2547,  4.3400,  ...,  2.9883,  4.3571,  0.3423],\n",
            "        [-1.9373,  1.9258,  7.4131,  ..., -1.5810,  2.3332,  0.6420],\n",
            "        ...,\n",
            "        [-1.1659,  3.0271,  1.2121,  ...,  0.7605,  2.2209,  2.4632],\n",
            "        [ 4.0328,  3.7884,  4.9018,  ..., -1.7322,  1.0385,  1.5005],\n",
            "        [ 1.9912,  1.1106, -1.4465,  ...,  0.6448,  3.2954, -1.2008]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7482,  2.0605, -3.2349,  ..., -0.3439,  5.3101, -0.9689],\n",
            "        [ 0.6088,  4.3565, -2.9870,  ..., -0.0261,  1.0715,  0.0101],\n",
            "        [-1.6333,  2.3663,  0.4858,  ...,  0.3751,  4.9009, -0.3145],\n",
            "        ...,\n",
            "        [-1.1613,  4.3471,  1.9216,  ...,  2.4393,  6.3489,  0.4153],\n",
            "        [ 0.9511,  0.3342,  0.8285,  ...,  0.7590,  5.4496,  0.6040],\n",
            "        [ 3.7990, -0.1389,  7.8345,  ..., -2.0560,  4.6301,  1.3646]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8010,  1.3789, -1.9516,  ...,  1.4181,  3.8396, -0.0174],\n",
            "        [ 1.0052,  2.4752, -1.8162,  ...,  0.4913,  3.9282,  3.7973],\n",
            "        [ 1.0486,  2.1529, -1.7645,  ...,  0.8200,  2.8040,  0.7914],\n",
            "        ...,\n",
            "        [ 0.5892,  3.3297, -3.5470,  ..., -2.0299,  0.2424, -1.0192],\n",
            "        [-0.9290,  3.2579, -0.5795,  ...,  1.8439,  2.9310,  1.7619],\n",
            "        [ 0.3808,  1.3351,  2.4316,  ...,  0.7501,  1.3358, -0.3143]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6512,  3.0843, -1.2505,  ...,  1.3468,  3.6839,  0.0447],\n",
            "        [ 2.4178,  2.8786, -3.1336,  ..., -0.9232,  2.6188,  0.6702],\n",
            "        [ 1.9758,  0.9887, -2.0453,  ..., -0.8986,  3.3010, -0.7983],\n",
            "        ...,\n",
            "        [ 0.9487,  5.8809,  1.6391,  ..., -1.8736,  2.3399,  3.3071],\n",
            "        [ 2.6278,  5.2433, -1.4686,  ..., -1.2284,  1.5562,  0.1578],\n",
            "        [-1.6665,  2.1372,  0.0859,  ...,  0.4340,  4.0695,  0.0071]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4485,  3.5966, -0.8228,  ...,  0.1787, -0.6389,  1.9450],\n",
            "        [ 4.0976,  3.1860,  2.3865,  ..., -3.6758,  4.5935, -0.7088],\n",
            "        [ 1.4761,  0.3332,  1.8555,  ..., -0.3324,  2.0667, -2.6457],\n",
            "        ...,\n",
            "        [ 2.1156,  0.7293, -3.9164,  ..., -0.6298,  4.2778,  0.5959],\n",
            "        [-0.0552,  3.6266,  5.9786,  ...,  1.8618,  3.5327, -0.8328],\n",
            "        [-1.2800,  3.9225, -0.1659,  ...,  2.8450,  2.7289,  0.4763]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9329,  4.6911,  0.9333,  ...,  0.3153, -0.3597,  0.7488],\n",
            "        [ 1.9128,  2.0137,  6.1602,  ..., -1.1678,  2.7351,  1.0166],\n",
            "        [ 1.8470,  2.4776, -0.6171,  ..., -2.4466,  3.8733, -2.6394],\n",
            "        ...,\n",
            "        [ 2.6895,  0.8956, -0.9447,  ...,  0.6701,  1.4909, -1.0470],\n",
            "        [ 4.5675,  2.5214, -0.0360,  ...,  1.3721,  1.1243, -1.1960],\n",
            "        [ 0.0181,  3.4815, -2.4180,  ...,  1.4683,  2.6915, -0.3496]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.8347,  4.3065, -3.6182,  ..., -1.4942,  6.2891,  0.2508],\n",
            "        [ 4.1506,  1.7950,  4.1534,  ..., -4.1512,  0.6464, -0.2996],\n",
            "        [ 1.8260,  2.5210,  5.9722,  ..., -1.3998,  1.5015,  1.4259],\n",
            "        ...,\n",
            "        [ 0.0790,  3.9737, -4.7515,  ..., -1.9976,  0.6769,  0.3296],\n",
            "        [ 2.5506,  4.0783, -1.2760,  ..., -0.3898, -0.0938,  0.3074],\n",
            "        [ 1.6098,  0.4748,  1.1689,  ...,  0.5758,  2.8797, -1.9323]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.5631,  3.7262,  5.0982,  ..., -1.4885, -1.3890,  0.8110],\n",
            "        [ 2.7004,  1.7804,  2.3666,  ..., -0.4180, -0.1092, -3.6075],\n",
            "        [-0.2401,  3.4366,  1.6029,  ...,  3.5433,  2.0425,  0.9135],\n",
            "        ...,\n",
            "        [ 1.4165, -1.4154,  4.0243,  ...,  0.2512,  3.1871, -0.3066],\n",
            "        [ 1.8571,  4.7237,  0.5323,  ..., -1.9546,  1.0768,  4.1224],\n",
            "        [-0.6706,  6.3679, -6.1578,  ..., -1.1187,  0.6384, -0.2162]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3929,  1.0902, -1.0465,  ..., -2.3323,  0.9579,  0.3937],\n",
            "        [-0.9079,  2.8085, -3.7758,  ..., -1.3185, -0.0705, -2.1612],\n",
            "        [ 1.7606, -0.1934,  1.8504,  ...,  0.9671,  2.6508, -3.3923],\n",
            "        ...,\n",
            "        [ 5.7052, -0.7680,  2.5352,  ...,  0.9455,  2.2304, -1.8648],\n",
            "        [ 7.1148, -0.5067,  1.1315,  ...,  2.3936,  2.8732, -1.2900],\n",
            "        [ 0.4564, -0.9363,  1.9125,  ..., -1.1248,  3.6293, -2.6024]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2388,  2.1448,  6.9466,  ..., -1.2951,  5.3041,  2.8460],\n",
            "        [ 3.7748,  1.5679, -1.0507,  ..., -1.5489,  4.3651, -1.1390],\n",
            "        [-0.6206,  1.1612, -2.0709,  ..., -0.0978, -0.0079, -2.6984],\n",
            "        ...,\n",
            "        [ 0.5927,  2.7627, -3.7432,  ..., -1.3065,  1.2824, -0.1832],\n",
            "        [ 1.9306,  3.1714,  3.3824,  ..., -0.2461, -1.1401, -1.7837],\n",
            "        [ 4.1182,  3.5823,  1.2573,  ..., -1.6859, -1.5521, -0.3326]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6804,  2.0047, -0.6131,  ...,  0.1802,  1.0334, -4.0903],\n",
            "        [ 3.3462,  4.0915,  2.4293,  ...,  0.8910,  1.6333,  0.3107],\n",
            "        [ 0.9171,  6.2636, -6.3132,  ...,  0.4537, -2.0633,  0.5280],\n",
            "        ...,\n",
            "        [ 2.5243,  3.9970, -2.6799,  ..., -1.5719,  1.6127, -0.4682],\n",
            "        [ 3.0774, -0.4591,  3.1121,  ..., -4.1622,  1.7536,  0.6215],\n",
            "        [ 4.7541,  1.2537,  3.5644,  ...,  0.2553,  1.9428, -0.2933]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4858,  1.2643, -2.1464,  ..., -0.2244,  0.2776, -1.4993],\n",
            "        [ 1.3254,  3.0912, -3.1047,  ..., -0.1072,  1.2636,  0.6456],\n",
            "        [ 6.2516,  0.4025,  2.7659,  ...,  0.1041,  1.3533, -1.9306],\n",
            "        ...,\n",
            "        [-3.4413,  0.0851,  3.0928,  ...,  2.1972,  2.7654,  0.8435],\n",
            "        [ 2.3684,  3.1701, -0.4720,  ...,  1.7546,  2.5246, -0.6924],\n",
            "        [ 0.6710,  5.2170, -5.8348,  ..., -1.0500, -0.1688,  0.7626]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1137,  4.4770,  2.0873,  ...,  2.2556,  2.6934,  0.6657],\n",
            "        [-0.5991,  2.5620, -3.3009,  ...,  1.8723,  5.0221,  1.9030],\n",
            "        [ 3.5928,  4.2541,  2.2119,  ..., -0.9941,  1.2500,  4.5758],\n",
            "        ...,\n",
            "        [-0.4607,  0.9295, -0.7007,  ...,  1.4172,  0.7413,  0.3294],\n",
            "        [ 1.5576,  2.0313, -3.1577,  ...,  1.8957,  2.1565,  0.4794],\n",
            "        [-0.5691,  2.2197, -3.2052,  ..., -1.2137,  2.0182, -1.1944]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9810,  2.1785,  3.8677,  ...,  1.3250,  0.9493,  0.5172],\n",
            "        [ 1.8626,  3.8980, -3.6545,  ..., -1.3029,  0.1345,  0.7115],\n",
            "        [ 0.7308,  4.9476, -1.9822,  ..., -1.3641,  1.0835,  1.9726],\n",
            "        ...,\n",
            "        [-1.9267,  3.0365,  1.3565,  ...,  1.6030, -0.0914,  1.5752],\n",
            "        [ 1.1128,  1.7797, -2.4871,  ..., -2.0410,  0.3179, -3.2953],\n",
            "        [ 0.8019,  6.2234, -2.1651,  ..., -1.5353,  0.6685,  0.3565]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6404,  3.0551, -2.8816,  ...,  2.2733,  4.2320,  1.7366],\n",
            "        [ 3.0368,  1.9528,  0.2328,  ..., -0.9737,  1.4103,  1.2871],\n",
            "        [ 2.4074,  2.2316, -4.0010,  ..., -0.2978,  1.2730,  0.5530],\n",
            "        ...,\n",
            "        [ 2.7445,  1.0098,  0.6875,  ..., -0.1472,  1.4513, -2.8249],\n",
            "        [ 0.7291,  1.6950, -3.9778,  ..., -0.1546,  5.9662,  3.2896],\n",
            "        [ 1.7368,  2.7601, -4.5638,  ...,  0.9450,  2.4107,  0.0730]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8545,  3.6908,  0.1677,  ..., -3.5559,  0.0061,  0.7282],\n",
            "        [-0.4324,  3.3284, -4.1499,  ..., -1.7894,  1.3708, -0.4471],\n",
            "        [-2.2636,  2.6481, -0.8033,  ...,  0.9072,  0.5693, -0.5144],\n",
            "        ...,\n",
            "        [ 1.7773,  4.1040,  1.0519,  ..., -2.8490, -1.5780,  1.4836],\n",
            "        [-0.6023,  0.1572, -1.5309,  ...,  0.1402, -0.1604, -2.1597],\n",
            "        [ 1.6805,  1.0171, -4.3654,  ..., -0.8196,  4.6476,  1.2560]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9312,  1.5655, -5.7076,  ...,  0.2807,  4.2946,  1.2203],\n",
            "        [-0.9552,  3.0191, -2.6403,  ..., -1.3303,  0.5328, -0.6790],\n",
            "        [ 0.2571,  0.9351, -4.7867,  ...,  1.4175,  2.7015, -0.5691],\n",
            "        ...,\n",
            "        [-0.4596,  3.9476, -4.4337,  ..., -2.0325,  0.8766, -1.2774],\n",
            "        [ 2.3018,  3.2759, -1.0925,  ..., -1.5999,  1.6688,  0.5307],\n",
            "        [-1.1348,  1.7175, -2.2941,  ..., -0.5977,  1.3781, -1.2958]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7306,  1.6057, -2.5549,  ..., -1.9778,  3.7514,  0.3721],\n",
            "        [-1.0295,  3.9637, -6.8369,  ..., -0.9156,  3.0791,  1.8773],\n",
            "        [ 1.9215,  0.3877,  0.1831,  ..., -0.7072,  5.3630,  1.3593],\n",
            "        ...,\n",
            "        [ 3.1025,  1.8511,  3.5219,  ...,  0.2766,  2.1344, -1.2261],\n",
            "        [ 5.7814,  2.1974, -1.7130,  ..., -1.1713,  1.2038, -1.3636],\n",
            "        [ 0.2708,  2.7495,  2.2929,  ...,  1.0636,  4.4197,  0.9453]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1393,  2.5710,  6.3016,  ..., -1.8362,  6.0385,  2.4844],\n",
            "        [ 4.3108,  0.1426,  4.2369,  ..., -2.3416,  1.7105,  0.2999],\n",
            "        [-0.2855,  2.5634, -4.0845,  ..., -2.0935,  0.9965, -0.7455],\n",
            "        ...,\n",
            "        [ 0.3155,  1.8728, -1.4966,  ...,  1.2311,  3.3054, -1.6516],\n",
            "        [ 3.2020,  1.8259,  6.8660,  ..., -5.4424,  1.8243,  1.9673],\n",
            "        [-0.1160,  2.9058, -0.2737,  ...,  2.6448,  2.4631,  0.3598]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0800,  4.4672, -6.5595,  ..., -2.3500,  2.3638,  0.5747],\n",
            "        [ 2.2294,  0.7058, -0.4241,  ..., -0.2596,  3.0831, -2.1869],\n",
            "        [ 3.5450,  0.5097, -0.5560,  ..., -1.8764,  1.5142, -1.2372],\n",
            "        ...,\n",
            "        [-1.9974,  3.7318, -0.7556,  ..., -1.4408,  1.0784,  2.7586],\n",
            "        [ 2.1092,  0.0807, -2.7679,  ..., -0.6984,  5.1486,  1.9641],\n",
            "        [ 1.9254,  1.1381, -5.5713,  ...,  0.8022,  4.7095,  0.2530]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5693,  3.8055,  0.1389,  ...,  1.7148,  2.2822,  0.5810],\n",
            "        [ 1.7696,  1.0023, -2.9102,  ...,  0.1609,  3.5666,  0.0378],\n",
            "        [ 1.1457,  3.2442, -1.6952,  ..., -2.4060,  1.5558, -0.3448],\n",
            "        ...,\n",
            "        [ 1.4326,  4.7093, -0.7954,  ..., -0.2769,  2.9693,  2.6673],\n",
            "        [ 0.3795,  2.7759,  0.6438,  ..., -1.5238,  4.5784,  1.4891],\n",
            "        [ 2.1701,  2.0266, -0.3430,  ..., -0.6136,  3.4649,  0.2714]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9582,  4.4355,  4.4768,  ...,  0.2859,  3.0516,  3.3718],\n",
            "        [ 4.9572,  0.0282, -0.0609,  ..., -1.0334,  1.8728,  3.4287],\n",
            "        [ 2.3516, -0.2497, -0.1236,  ..., -2.9810,  2.1800, -1.6961],\n",
            "        ...,\n",
            "        [ 1.5412,  4.0711, -0.8048,  ..., -0.6056,  3.8339,  0.6945],\n",
            "        [-0.3896,  2.4645, -2.7030,  ..., -1.2221,  0.5437, -1.3865],\n",
            "        [ 4.8295,  0.8429, -2.4156,  ..., -0.7537,  2.1036, -1.3961]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0953,  1.0489,  0.5252,  ...,  0.1441,  5.8358,  1.7664],\n",
            "        [-1.0583,  1.3996,  5.0485,  ..., -1.3491,  2.2356,  0.9527],\n",
            "        [ 6.9524,  0.3490,  2.4983,  ..., -1.0347,  0.3449,  0.9234],\n",
            "        ...,\n",
            "        [ 2.6803,  4.9661, -2.2822,  ..., -1.7539,  1.1479,  0.9387],\n",
            "        [ 0.0112,  3.3504, -0.8759,  ..., -1.1248,  0.8027,  0.6655],\n",
            "        [ 2.8055, -0.2265,  1.2349,  ...,  0.0951,  0.4445, -0.9356]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0603,  2.3419, -3.6213,  ...,  0.2450,  4.8385, -1.9381],\n",
            "        [ 2.0724,  1.3425,  5.9631,  ...,  0.0833,  2.2628,  0.1077],\n",
            "        [ 0.8383,  6.7718, -1.1313,  ..., -1.8326,  3.7743,  5.3882],\n",
            "        ...,\n",
            "        [ 1.4280,  3.6772, -7.3534,  ..., -0.5864,  3.6905, -0.1671],\n",
            "        [ 1.9739,  2.9625, -1.2613,  ...,  0.3099,  2.0640, -0.4323],\n",
            "        [ 4.3873,  2.4175,  1.9813,  ..., -0.6429,  0.0511,  0.4574]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.4376,  2.3848,  5.0539,  ..., -0.5578,  1.4063,  0.4267],\n",
            "        [ 2.5830,  1.6314, -6.0752,  ..., -0.1130,  3.0897, -0.7023],\n",
            "        [ 1.6510, -0.2490,  2.6842,  ...,  1.7709,  3.4186,  0.6209],\n",
            "        ...,\n",
            "        [ 0.0526,  0.9873, -2.0677,  ...,  0.6142,  0.0965, -3.4507],\n",
            "        [ 0.4663,  2.4075, -4.8221,  ..., -1.6473,  1.2825, -0.9044],\n",
            "        [ 1.3644,  1.1054, -1.6191,  ..., -0.3800,  1.9294, -0.5701]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.6208,  1.5624,  0.9562,  ..., -1.5105,  0.4965, -0.5022],\n",
            "        [ 1.3938,  3.5363, -0.4439,  ..., -0.9044,  1.5439,  3.1687],\n",
            "        [ 1.9586,  1.5917, -0.5638,  ..., -0.1996,  1.4623, -1.5606],\n",
            "        ...,\n",
            "        [ 2.0765,  2.2508, -0.7648,  ..., -1.7261,  1.0418, -2.9749],\n",
            "        [-0.1107,  6.1793, -0.3619,  ..., -0.3344,  2.2738,  4.1753],\n",
            "        [ 2.0238, -0.7166, -1.4105,  ..., -0.4054,  2.9728, -1.6843]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3929,  4.1220,  0.8285,  ...,  0.2597,  1.6501,  1.9230],\n",
            "        [ 2.5465,  3.6856, -5.3979,  ..., -1.7024,  3.4288,  1.1722],\n",
            "        [-2.2640, -0.2000,  6.6596,  ..., -2.1585,  1.6253, -0.5490],\n",
            "        ...,\n",
            "        [ 1.1649,  7.0335,  0.5525,  ..., -1.1955, -0.6678,  4.8954],\n",
            "        [-1.9021,  3.6270, -0.6173,  ...,  2.2969,  2.9296, -0.0460],\n",
            "        [-1.0024,  1.8650,  4.4425,  ...,  2.3051,  2.3280,  2.8712]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1523,  3.6417,  6.3750,  ..., -3.5025, -0.4133, -0.0899],\n",
            "        [ 0.0960,  1.9067, -3.2400,  ...,  2.2520,  3.8002,  0.8739],\n",
            "        [ 3.9393,  0.4857, -2.7037,  ...,  1.0997, -0.2293,  0.1396],\n",
            "        ...,\n",
            "        [ 3.5210,  2.5865,  5.0485,  ...,  1.5423,  0.5541,  0.5648],\n",
            "        [ 1.2642,  4.2749, -4.4656,  ...,  0.1637,  0.3878, -1.1152],\n",
            "        [ 2.5344,  1.4135, -5.8067,  ...,  1.2627,  2.7263, -0.0576]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2010,  1.4985,  1.3722,  ..., -1.8503,  4.7270,  2.9931],\n",
            "        [ 3.1102,  3.4660,  0.7782,  ...,  0.4945,  2.6211,  1.7496],\n",
            "        [ 1.8555,  2.3004, -4.5447,  ...,  0.3319,  1.8267, -0.0514],\n",
            "        ...,\n",
            "        [ 2.5617,  0.8943,  1.0258,  ..., -2.2263,  0.8442, -2.1660],\n",
            "        [-0.2661,  2.1984, -5.4556,  ...,  3.6752,  1.7329, -0.6428],\n",
            "        [-1.9395,  3.1133, -2.5749,  ...,  1.0463,  2.3290,  0.0847]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0182,  3.0478,  1.2591,  ..., -2.3831,  0.9619, -0.0873],\n",
            "        [ 0.6610,  4.6957, -2.0725,  ..., -0.9270, -0.3099,  1.2082],\n",
            "        [ 0.6094, -1.5552,  4.8880,  ...,  0.7942,  2.5785, -1.1032],\n",
            "        ...,\n",
            "        [-2.8946,  3.8915, -2.6155,  ...,  2.7566,  2.5093,  0.6703],\n",
            "        [-0.3940, -1.4829,  4.8187,  ..., -0.5322,  0.4701, -2.5557],\n",
            "        [ 4.6839,  1.6223,  4.3349,  ..., -1.2519,  0.1053,  1.7871]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2338,  3.6641, -6.2187,  ..., -1.1469,  1.0547, -0.6895],\n",
            "        [ 7.8725,  2.3380, -0.8109,  ...,  0.4668,  3.6211, -0.2266],\n",
            "        [-0.7645,  2.1599, -2.6613,  ..., -0.0960,  1.0734, -1.5297],\n",
            "        ...,\n",
            "        [ 3.8325,  0.7621, -1.9627,  ..., -0.0916,  3.9066, -0.6937],\n",
            "        [ 2.3820,  0.2404, -2.1425,  ..., -0.7406,  5.8663,  0.6503],\n",
            "        [-0.6090,  4.5359, -5.1441,  ..., -0.1225,  2.1216,  0.7111]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5723,  4.5760, -5.1055,  ..., -1.6008,  2.5519,  1.4747],\n",
            "        [-0.6405,  5.2370, -3.7284,  ..., -0.4378,  0.1124,  0.7280],\n",
            "        [ 0.8371,  2.2834, -0.5040,  ...,  2.5322,  0.8799, -0.5507],\n",
            "        ...,\n",
            "        [-0.3791, -0.1713,  4.2844,  ..., -0.1844,  5.0173,  0.9667],\n",
            "        [ 0.3225,  5.6454, -1.4552,  ..., -0.7513,  1.1155,  3.8832],\n",
            "        [-1.1476,  2.9747,  2.0990,  ...,  0.2585,  1.6067,  0.6588]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4280,  1.5267, -1.7627,  ...,  0.2415,  6.4447,  1.0866],\n",
            "        [ 0.7925,  5.8496, -1.6196,  ..., -2.2400,  0.5261,  0.4913],\n",
            "        [ 1.9210,  4.0702, -1.4370,  ...,  1.1025,  0.8566,  0.9937],\n",
            "        ...,\n",
            "        [ 2.4039,  0.3193, -1.2844,  ...,  1.6363,  1.1160, -4.6997],\n",
            "        [-1.4975,  0.5979, -0.2004,  ...,  1.4410,  2.8136,  0.5194],\n",
            "        [ 0.7090,  2.1515, -4.4686,  ...,  1.8268,  5.2235,  3.8273]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4606,  5.7730, -2.1576,  ..., -0.9188,  3.5330,  4.0828],\n",
            "        [ 3.3384,  3.2740,  1.0457,  ...,  0.1040,  0.3627,  2.1948],\n",
            "        [-0.6352,  2.7426, -3.8485,  ..., -1.7247,  0.3997, -1.3871],\n",
            "        ...,\n",
            "        [ 4.8080,  0.2359,  1.1049,  ...,  0.1757,  6.9181,  1.7075],\n",
            "        [-0.9877,  1.7576, -3.0798,  ...,  1.7406,  4.3752, -0.4549],\n",
            "        [ 0.7508,  3.5721, -5.5170,  ..., -1.0362,  2.1790,  3.4130]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1911,  3.2263, -4.8880,  ...,  1.2580,  3.1961,  0.6271],\n",
            "        [ 2.6146,  3.0040,  2.0734,  ..., -1.8251,  0.7945,  1.1681],\n",
            "        [ 4.4458,  2.8525,  1.0208,  ..., -3.5140,  0.8311,  0.9206],\n",
            "        ...,\n",
            "        [ 2.7699, -1.6100, -0.9114,  ..., -0.4636,  2.5039, -0.8501],\n",
            "        [ 0.7141,  3.1680, -2.6555,  ...,  0.3111, -0.1433,  0.6109],\n",
            "        [ 4.9159,  5.5759, -2.7303,  ..., -2.2355,  2.5865,  2.8593]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1694e+00,  1.4723e+00, -1.4189e+00,  ..., -8.2057e-01,\n",
            "          1.8246e+00, -1.6932e+00],\n",
            "        [ 1.3957e+00,  3.2983e+00,  2.6833e-02,  ...,  1.4431e+00,\n",
            "          3.7575e+00,  4.0504e-01],\n",
            "        [ 4.8237e+00, -2.0174e+00,  9.7896e-01,  ...,  6.2949e-01,\n",
            "          1.2551e+00, -9.3299e-02],\n",
            "        ...,\n",
            "        [ 5.6161e-01,  1.5395e+00, -1.9588e-01,  ..., -1.2608e+00,\n",
            "         -3.5330e-01, -6.7845e-01],\n",
            "        [ 3.9105e+00,  1.5966e+00, -1.5591e+00,  ..., -2.3898e+00,\n",
            "          2.6765e-01, -1.2006e+00],\n",
            "        [-1.4237e+00,  7.5131e+00,  4.0816e-03,  ..., -1.0286e+00,\n",
            "         -7.0554e-03,  2.8316e-02]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2554,  5.5294, -0.6046,  ..., -0.9920,  0.3311,  1.3017],\n",
            "        [ 1.0656,  3.6306, -0.7255,  ...,  0.2320,  2.2106,  4.9053],\n",
            "        [ 5.4793,  0.5238,  2.3518,  ..., -2.1777, -0.3562, -0.2958],\n",
            "        ...,\n",
            "        [-0.4159,  1.9881, -0.1354,  ...,  1.1829,  4.3891,  1.0958],\n",
            "        [-0.4048,  1.9707, -1.3412,  ...,  2.1374,  1.9582,  0.0104],\n",
            "        [-0.8908,  0.2769,  7.2445,  ...,  1.3107,  3.0698, -0.5866]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5604,  3.8166, -1.5632,  ..., -1.4197,  0.8555,  0.6257],\n",
            "        [ 3.8236,  3.4044, -4.4349,  ..., -2.2471,  1.6132, -0.0203],\n",
            "        [ 0.2793,  2.1626, -7.3501,  ...,  0.1390,  3.9890,  0.3353],\n",
            "        ...,\n",
            "        [ 1.7277,  4.9080, -1.4403,  ...,  1.3959,  5.3831,  4.2929],\n",
            "        [ 2.4469,  3.1619,  4.3620,  ..., -0.2317,  2.5968,  4.6346],\n",
            "        [-0.4302,  1.0111, -2.3529,  ..., -0.1948,  0.2719, -2.1271]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1819,  0.0693,  0.4905,  ...,  0.1267, -0.8512, -1.1596],\n",
            "        [ 3.1935,  0.8082, -0.5971,  ..., -0.1584,  3.0076, -0.9402],\n",
            "        [ 2.1959,  1.7287, -4.5930,  ..., -1.4819,  2.3704,  1.5164],\n",
            "        ...,\n",
            "        [ 1.7506,  3.3456, -3.2233,  ..., -2.4066,  3.6696,  1.2412],\n",
            "        [ 2.7093,  0.8868, -1.8215,  ..., -2.1201,  3.2575, -2.3674],\n",
            "        [ 2.7604,  3.1256,  3.3649,  ...,  2.1927,  2.4999,  1.4567]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8942,  1.5458,  2.6540,  ..., -1.0319,  0.9447, -0.5193],\n",
            "        [ 1.5816, -1.5440,  0.9448,  ..., -0.1068,  4.7439, -0.0858],\n",
            "        [-1.0737,  4.3958, -6.0299,  ...,  0.8066, -0.1384,  0.7365],\n",
            "        ...,\n",
            "        [ 0.3661,  4.0284, -6.9798,  ...,  0.7626,  3.6703,  0.7344],\n",
            "        [ 0.8959,  2.3101, -4.4831,  ..., -2.3321,  1.4300, -1.7937],\n",
            "        [ 1.9195,  1.6248, -3.1094,  ...,  2.2462,  3.5717, -0.4490]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2153,  4.0478,  0.8977,  ..., -2.9179,  1.6489,  2.3042],\n",
            "        [-1.0843,  3.6395,  0.5533,  ...,  3.4883,  4.7159,  1.2876],\n",
            "        [ 0.1401,  2.1413, -3.3648,  ..., -0.8554,  1.0424, -0.7222],\n",
            "        ...,\n",
            "        [-0.3976,  3.0473,  0.3081,  ...,  4.0442,  3.0007,  1.1124],\n",
            "        [-0.1786,  2.6977, -5.4818,  ...,  0.2636,  1.8569, -2.0697],\n",
            "        [-0.5712,  1.8533, -3.9074,  ...,  1.7371,  6.2039, -1.1386]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8837,  0.1210, -1.7406,  ..., -1.0024,  5.2430, -1.6649],\n",
            "        [ 3.3765,  0.8511, -2.7857,  ..., -0.5569,  5.4885, -1.7778],\n",
            "        [ 2.0950,  0.5341, -2.3233,  ...,  0.7599,  3.9577, -0.2613],\n",
            "        ...,\n",
            "        [-0.1925,  2.0179, -4.6081,  ..., -1.1640,  1.8220, -0.7112],\n",
            "        [ 0.4364,  2.6468, -3.8677,  ..., -1.1377,  5.3945, -0.1718],\n",
            "        [ 1.4190,  3.4741, -4.6475,  ..., -1.8996,  2.8128, -0.2986]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1562, -0.2492,  4.5996,  ...,  0.8871,  0.5278, -0.7775],\n",
            "        [-0.9109,  3.6945, -4.4202,  ..., -1.9505,  0.8926,  0.2242],\n",
            "        [ 2.6971,  1.4490, -0.3050,  ..., -0.8740,  4.3087, -0.5438],\n",
            "        ...,\n",
            "        [ 1.8107,  4.7919,  4.1355,  ...,  3.5170,  3.2845,  2.2627],\n",
            "        [ 1.6772,  3.8465, -6.8287,  ...,  1.1199,  2.1469, -0.4497],\n",
            "        [ 0.3644,  2.0063, -3.9342,  ...,  0.4520,  5.4780,  1.9590]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.4233,  0.0287,  1.4560,  ..., -0.7784,  0.0275,  2.3661],\n",
            "        [ 0.7128,  5.9333, -0.7974,  ..., -0.3436, -1.0965,  1.4936],\n",
            "        [ 1.1236,  2.8122, -2.5263,  ...,  4.2607,  4.0197,  0.6794],\n",
            "        ...,\n",
            "        [ 3.4863, -0.5348, -2.2873,  ...,  1.0805,  2.1876, -0.6698],\n",
            "        [-0.6763,  2.7161, -3.8188,  ..., -1.5734,  1.6107, -1.2782],\n",
            "        [-0.3132,  3.7234, -5.6284,  ..., -1.6287,  1.9853,  0.3548]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0998,  1.7747,  6.1083,  ...,  1.7815,  2.3920,  0.5875],\n",
            "        [ 1.5488, -0.3427,  3.3876,  ..., -1.1815,  2.4859, -0.1034],\n",
            "        [ 0.9364,  4.9436, -0.5605,  ..., -2.0899,  3.1749, -2.1546],\n",
            "        ...,\n",
            "        [-1.2188,  0.7010,  3.1975,  ..., -2.8154,  2.4593, -0.8297],\n",
            "        [-1.5652,  3.0733,  1.4950,  ...,  3.3241,  4.6166,  1.4996],\n",
            "        [-0.1968,  3.0142, -3.0217,  ..., -0.9223,  0.7236, -0.9266]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0688, -1.0488, -0.8612,  ..., -0.6585,  5.1495,  1.6926],\n",
            "        [ 0.4904,  1.7763, -3.2871,  ...,  0.5179,  2.1595, -2.3004],\n",
            "        [ 0.0623,  1.7029,  0.5463,  ...,  1.7846,  6.1137,  1.7444],\n",
            "        ...,\n",
            "        [-2.5773,  2.4077,  4.4000,  ...,  3.3943,  4.2367,  1.4360],\n",
            "        [ 0.8292,  5.3197,  4.6753,  ..., -1.4443, -0.0864,  3.0725],\n",
            "        [ 3.8514,  3.0080, -1.3738,  ..., -0.3498,  3.7826, -1.2466]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0633,  2.9730, -4.8480,  ..., -1.1678,  2.0283, -0.1262],\n",
            "        [ 0.6958,  3.4313, -0.7312,  ..., -1.4598,  0.9909,  0.0723],\n",
            "        [ 0.8146,  3.1864, -6.4654,  ..., -1.8959,  2.0858, -0.3030],\n",
            "        ...,\n",
            "        [ 1.3629,  2.8141,  0.4109,  ...,  3.0804,  2.4821,  0.5181],\n",
            "        [ 0.6956,  2.6247, -7.3344,  ..., -1.0073,  3.0486,  0.3897],\n",
            "        [ 5.1031,  1.3045,  4.2818,  ..., -1.5464,  0.1676, -0.4281]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 7.8917,  2.2626, -1.1964,  ...,  2.5153,  2.0378, -0.5566],\n",
            "        [ 2.7550, -1.0664,  4.8111,  ...,  0.2539,  3.6771, -1.6093],\n",
            "        [ 2.2434,  1.0573, -1.2232,  ..., -0.0155,  0.3080, -0.1286],\n",
            "        ...,\n",
            "        [ 2.9623,  1.9420, -3.6363,  ...,  0.2300,  2.5050,  0.1157],\n",
            "        [ 3.7313,  1.2533,  0.1511,  ...,  1.1871,  0.1724, -0.2776],\n",
            "        [ 0.0420,  3.1415,  1.7741,  ...,  5.1368,  2.7626,  0.8983]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7045e-03,  1.4693e+00,  1.9807e+00,  ..., -2.6325e+00,\n",
            "          4.5484e-01, -1.4277e+00],\n",
            "        [ 1.7244e+00,  2.3461e+00,  1.2490e-01,  ...,  1.0482e+00,\n",
            "          1.1155e+00,  3.4610e-01],\n",
            "        [ 2.3264e+00, -5.1630e-01,  7.8417e+00,  ..., -4.3219e+00,\n",
            "          2.6427e+00,  1.0440e+00],\n",
            "        ...,\n",
            "        [ 1.4927e+00,  8.3189e-01, -6.2390e-01,  ..., -1.2309e+00,\n",
            "          8.0775e-01,  3.2990e-01],\n",
            "        [-1.6067e+00,  6.5811e-01,  9.0374e+00,  ..., -3.0286e+00,\n",
            "          3.7728e+00,  7.3634e-01],\n",
            "        [ 1.7658e+00,  2.6736e+00, -5.4648e+00,  ..., -3.4937e-01,\n",
            "          3.6345e+00,  1.1512e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0196a2fe0d944ce085e6c817ddd8971f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5569,  3.0622, -2.5806,  ..., -2.6605,  1.5829, -0.6183],\n",
            "        [-1.9862,  4.2034, -3.0141,  ...,  2.6744,  3.9429,  1.4471],\n",
            "        [ 1.2074,  4.8080, -2.5518,  ..., -0.3426,  3.2466,  0.6315],\n",
            "        ...,\n",
            "        [ 0.3208,  1.2499, -2.4587,  ...,  0.6975, -0.4738, -2.3784],\n",
            "        [ 1.5453,  2.8503, -4.0062,  ...,  0.7088,  4.7590,  2.9735],\n",
            "        [-1.3528,  3.5447, -0.7091,  ..., -1.4743, -0.3934,  1.7292]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0339,  0.6705,  1.0484,  ...,  1.4889,  2.0893, -1.3049],\n",
            "        [ 3.7151, -0.9163,  1.3273,  ..., -0.0719,  3.2938, -0.5644],\n",
            "        [ 2.3066,  1.5489,  1.7857,  ...,  0.3922,  6.0553,  0.7046],\n",
            "        ...,\n",
            "        [-0.8776,  1.3834,  1.9857,  ..., -0.9789,  0.9223,  0.5057],\n",
            "        [ 0.8342,  2.8165, -3.7660,  ..., -2.6647,  1.2311, -2.1450],\n",
            "        [ 2.4101,  2.5744, -4.6513,  ..., -0.7126,  0.2336, -1.3200]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1749,  1.2869, -2.3637,  ..., -0.3882, -0.2667, -2.5233],\n",
            "        [ 3.8999,  1.2269, -2.2097,  ...,  0.7466,  1.1074, -0.0194],\n",
            "        [ 0.6253,  0.5077,  3.3076,  ..., -0.6916,  4.0283, -0.9155],\n",
            "        ...,\n",
            "        [ 2.1339,  2.6029,  2.5860,  ..., -1.6647,  4.5374, -2.2089],\n",
            "        [ 3.9009,  1.8775, -2.3460,  ..., -1.5649,  0.7512,  0.0842],\n",
            "        [ 0.9259,  1.9365, -4.8228,  ...,  2.0979,  2.4176,  0.5226]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9773,  1.3860, -0.9544,  ..., -0.5150,  4.7493,  1.2039],\n",
            "        [-0.1611,  2.3295, -3.5205,  ..., -0.2406, -0.1222, -3.3981],\n",
            "        [ 7.8447, -0.9010, -1.1658,  ..., -0.9623,  5.9745,  1.6181],\n",
            "        ...,\n",
            "        [ 3.2614,  0.6082, -1.1356,  ...,  1.4577,  5.6903, -0.6532],\n",
            "        [-0.4354,  2.6645, -3.6689,  ..., -1.0679,  0.8000, -1.2694],\n",
            "        [ 2.2512,  4.1739, -6.4071,  ..., -2.1208,  0.3327,  2.6366]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4081,  0.7968, -2.0266,  ..., -0.2177,  1.2550, -1.7110],\n",
            "        [ 6.0815,  3.7526, -4.6063,  ..., -1.0872,  3.4609, -0.8564],\n",
            "        [-0.0439,  2.9892, -4.9911,  ...,  1.1478,  4.4851, -0.1438],\n",
            "        ...,\n",
            "        [ 2.1508,  3.5555,  2.9332,  ...,  1.1372,  4.0552,  2.6520],\n",
            "        [ 1.3762, -1.0684,  3.1397,  ..., -1.3483,  2.0721, -1.2596],\n",
            "        [-3.4461,  3.4980, -2.1747,  ..., -0.6665,  2.5444,  1.4763]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9428,  1.5192,  2.5607,  ..., -0.2923,  4.0421, -0.3293],\n",
            "        [ 1.0140,  2.9092, -1.2933,  ...,  0.5928,  3.9219,  2.5769],\n",
            "        [ 1.1607,  2.1773, -4.3446,  ...,  0.1536,  4.2398, -1.5001],\n",
            "        ...,\n",
            "        [-0.5904,  4.7518,  3.3567,  ..., -4.1187,  1.8979,  0.1277],\n",
            "        [ 4.4385, -1.6957,  1.8284,  ..., -4.2314,  1.0589, -1.5098],\n",
            "        [-0.2652,  1.8810, -1.2827,  ...,  0.4097,  1.5947, -0.5674]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4728, -0.3595,  5.2833,  ...,  0.3984,  4.5672, -0.0767],\n",
            "        [ 2.8347,  6.1107, -3.7679,  ..., -3.5634, -0.5187,  3.2397],\n",
            "        [ 2.4522,  1.2533,  2.4444,  ..., -0.6294,  2.0334,  1.8916],\n",
            "        ...,\n",
            "        [ 0.7573,  3.0591, -1.9474,  ...,  4.1343,  1.5616,  0.0437],\n",
            "        [ 4.7310,  4.9609, -7.3973,  ..., -1.2489,  5.4113,  4.9629],\n",
            "        [ 5.1891, -0.7075, -0.6231,  ..., -0.2978,  2.3145, -2.1958]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0771,  2.4978,  2.8977,  ..., -1.0759,  1.7410,  0.4981],\n",
            "        [-0.0100,  5.7393, -2.4592,  ..., -2.8187, -2.1303, -0.8648],\n",
            "        [ 2.7953,  0.1040,  0.4241,  ...,  0.7984,  1.6027, -3.7056],\n",
            "        ...,\n",
            "        [ 3.2077,  1.8671, -4.3704,  ..., -1.4187,  2.1555, -1.4817],\n",
            "        [ 5.2658,  3.3793, -4.7599,  ..., -0.8273,  1.4167,  0.4560],\n",
            "        [ 1.8079,  1.8598, -3.8767,  ..., -1.3010,  1.5042, -0.5675]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.0060,  1.2071, -2.4039,  ..., -1.9543,  0.3686, -1.2697],\n",
            "        [ 2.4629, -0.2379, -1.2854,  ..., -0.8094,  1.7981, -0.3598],\n",
            "        [ 8.6908,  1.6144, -0.6927,  ...,  1.5553, -0.4405,  0.0597],\n",
            "        ...,\n",
            "        [-1.0822,  1.8005,  5.4832,  ..., -3.3108,  1.5842, -0.3732],\n",
            "        [-1.9449,  3.1614, -0.5156,  ...,  3.9920,  4.5162,  1.3134],\n",
            "        [ 4.1922,  0.1662, -2.6015,  ...,  2.3789,  3.1333, -1.4501]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2829,  5.6626,  3.4972,  ..., -2.4443,  1.0354,  1.2171],\n",
            "        [ 0.3135,  4.4630, -3.7257,  ...,  0.6086,  2.0724,  0.5364],\n",
            "        [ 3.9118, -0.0775, -0.7978,  ..., -1.1300,  6.7830, -0.2574],\n",
            "        ...,\n",
            "        [-1.0631,  3.3221,  3.6235,  ..., -0.2478,  3.9563,  2.7866],\n",
            "        [ 0.3094,  2.3896, -5.0074,  ..., -1.3519,  1.2870, -0.9226],\n",
            "        [ 2.1167,  0.7558,  0.7572,  ..., -0.8421,  2.3566, -2.9154]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7328,  1.7766, -3.4245,  ..., -0.6204, -0.6984, -2.9064],\n",
            "        [ 0.7846,  3.5874, -5.3509,  ..., -1.9999,  0.5375, -0.7806],\n",
            "        [ 0.7813,  1.7889,  7.0384,  ..., -1.7046,  3.6424,  1.7521],\n",
            "        ...,\n",
            "        [ 2.8956,  5.6663, -4.0182,  ..., -0.5821,  0.5381,  1.5733],\n",
            "        [ 5.7843, -0.6074,  5.3683,  ..., -1.1041,  2.5870,  2.0345],\n",
            "        [ 1.8398,  3.1514, -2.7680,  ...,  0.3769,  4.6304,  2.5223]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0220,  2.7244,  6.3363,  ..., -1.6816,  2.0259,  1.1387],\n",
            "        [ 0.7470,  0.9726,  2.1391,  ...,  1.1285,  0.4204, -1.3772],\n",
            "        [ 4.5900,  1.3182, -3.5819,  ..., -1.9941,  3.2755,  0.5509],\n",
            "        ...,\n",
            "        [ 2.7520,  2.1721, -4.8267,  ..., -1.4868,  1.9702,  0.3032],\n",
            "        [ 3.7200,  3.9548, -2.7804,  ..., -1.5946,  1.3400,  0.9696],\n",
            "        [-0.8320,  3.7352, -2.2440,  ..., -0.2668,  4.0126,  0.9500]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4244,  4.6334,  0.4604,  ...,  4.3055,  2.4511,  1.7195],\n",
            "        [ 2.0283, -1.8256,  2.0181,  ..., -0.1341,  3.1731, -2.2508],\n",
            "        [ 0.2117,  0.8227, -2.7217,  ...,  0.2247,  0.0967, -2.5655],\n",
            "        ...,\n",
            "        [ 0.9282,  4.1329,  0.1569,  ...,  3.1349,  2.0521,  2.1479],\n",
            "        [ 0.7745,  2.8017, -5.5003,  ..., -1.1764,  2.3026,  0.2755],\n",
            "        [ 2.1922,  4.0405, -0.8189,  ...,  0.7949,  0.5821,  2.8525]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6941,  5.4534, -0.9938,  ...,  0.9374,  3.5786,  4.1800],\n",
            "        [ 4.3238,  1.6393, -4.9344,  ...,  0.8279,  3.6434,  1.7031],\n",
            "        [ 4.8095,  1.2601,  3.3771,  ..., -0.7800,  0.6105,  2.0051],\n",
            "        ...,\n",
            "        [ 1.1771,  2.1408, -5.6242,  ..., -0.0878,  2.0417, -1.6953],\n",
            "        [-0.3168,  3.1733, -1.6931,  ..., -2.0485,  2.2575,  0.5869],\n",
            "        [ 2.4685, -0.8005, -0.2271,  ..., -1.0183,  2.7643, -1.3306]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3322,  1.3210, -1.7193,  ...,  0.8086,  1.9913, -0.9887],\n",
            "        [ 1.2367,  2.1013, -5.5496,  ...,  0.2894,  2.7619, -0.7988],\n",
            "        [ 0.6831,  2.6457,  1.9819,  ...,  2.2668,  2.1307, -0.6059],\n",
            "        ...,\n",
            "        [ 0.7516,  3.2948,  4.0181,  ..., -1.1589,  5.0486,  3.7797],\n",
            "        [ 2.7629,  0.3060,  6.0379,  ..., -3.3134,  2.3527, -0.6336],\n",
            "        [ 3.4263,  1.6072, -0.0834,  ...,  1.8227,  1.4450, -1.8069]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9798,  2.9581, -1.5838,  ..., -0.4677,  5.8061,  1.6897],\n",
            "        [ 4.4700,  2.3074, -0.4461,  ..., -1.4256,  2.7291,  0.5881],\n",
            "        [ 1.9486,  4.3091,  2.1324,  ..., -2.7889,  1.2064,  3.6128],\n",
            "        ...,\n",
            "        [ 1.9226,  0.6428,  6.4229,  ..., -2.8250,  2.9932, -0.3680],\n",
            "        [-4.2279, -0.7667,  2.1153,  ..., -1.6121,  3.1820, -2.4328],\n",
            "        [ 2.2323,  1.0333,  4.3594,  ...,  0.8205,  4.2547,  0.7815]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2893e+00,  2.4851e+00, -5.6312e+00,  ..., -1.5782e+00,\n",
            "          2.3559e+00, -3.3667e-01],\n",
            "        [ 3.2442e+00,  1.7027e+00, -3.8536e+00,  ..., -2.0786e+00,\n",
            "          9.1054e-01, -2.0673e+00],\n",
            "        [ 6.0663e+00,  4.9423e-02,  4.0590e+00,  ..., -3.7115e+00,\n",
            "         -5.0199e-01, -1.7360e-01],\n",
            "        ...,\n",
            "        [-3.2130e-01,  9.4880e-01,  1.2318e+00,  ...,  4.0873e-01,\n",
            "          2.6238e+00,  2.0032e-01],\n",
            "        [ 2.6432e+00, -1.8546e-01,  2.6369e+00,  ...,  3.0997e-01,\n",
            "          7.4881e-01,  4.6002e-03],\n",
            "        [ 4.6212e-01,  3.2061e+00, -4.9941e+00,  ..., -2.1795e+00,\n",
            "          1.2303e+00, -7.3313e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.4656,  3.2430, -1.2581,  ..., -2.0423,  0.9446,  4.1907],\n",
            "        [ 0.3847, -0.0837,  2.7268,  ..., -0.2766,  3.3501, -1.0748],\n",
            "        [ 0.6783,  0.4551, -2.4515,  ..., -0.0485,  0.2350, -2.6053],\n",
            "        ...,\n",
            "        [ 0.3542,  3.1291, -4.9327,  ..., -1.9539,  1.5587,  0.7057],\n",
            "        [ 4.5618,  0.1896, -1.1312,  ..., -1.1844,  7.1891, -2.4677],\n",
            "        [-0.0485,  2.7306, -4.9426,  ..., -1.4318,  1.3392, -0.8826]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0941,  4.1660, -3.3942,  ..., -2.1965, -0.5218,  2.9888],\n",
            "        [-0.4525,  3.8435, -2.5665,  ...,  3.1754,  2.4313,  0.6384],\n",
            "        [ 0.0176,  4.6832, -3.0384,  ..., -0.7013,  5.0567,  3.2613],\n",
            "        ...,\n",
            "        [ 4.0933, -0.4925,  4.8906,  ..., -2.8669,  1.9632, -1.3632],\n",
            "        [ 0.2111, -0.7006,  5.0617,  ..., -0.3010,  4.2750,  0.2807],\n",
            "        [ 3.0691,  6.1817, -3.2753,  ..., -2.0540,  1.4134,  2.8372]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2576e+00,  3.4769e+00,  2.3380e-01,  ...,  5.3906e+00,\n",
            "          4.3386e+00,  8.7476e-01],\n",
            "        [-1.2530e-01,  3.7465e-01,  8.1780e+00,  ..., -1.9508e+00,\n",
            "          4.7802e+00,  1.7210e+00],\n",
            "        [-3.2624e+00,  5.6583e-01,  6.3842e+00,  ...,  2.3814e-01,\n",
            "          2.9531e+00, -8.7411e-01],\n",
            "        ...,\n",
            "        [ 4.9115e+00,  1.7134e+00, -5.2887e+00,  ...,  4.1793e-03,\n",
            "          5.9276e+00,  9.6226e-01],\n",
            "        [ 7.7990e-01, -1.5029e+00, -2.3654e+00,  ...,  1.8226e+00,\n",
            "          1.4040e+00, -4.1506e+00],\n",
            "        [ 3.1047e+00,  3.4122e+00,  3.8206e-01,  ...,  4.9199e-01,\n",
            "          4.0359e+00,  5.7347e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3779, -0.9260,  0.8046,  ..., -2.1770,  2.1703, -3.2810],\n",
            "        [ 0.6910, -0.8016,  0.7038,  ...,  0.7605,  1.7977, -6.1049],\n",
            "        [ 0.7560,  3.4013, -7.2267,  ..., -1.3353,  2.2095, -0.4496],\n",
            "        ...,\n",
            "        [ 1.5949,  2.8196, -3.2418,  ..., -0.2916,  2.5371, -1.8221],\n",
            "        [ 5.2147,  0.0217, -4.7437,  ...,  0.8064,  6.3740,  1.0069],\n",
            "        [ 4.1129,  0.2034, -3.2450,  ...,  1.8143,  2.6436, -0.2483]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1713,  1.9966, -2.8454,  ...,  0.6498,  2.8937, -0.3123],\n",
            "        [ 5.6064,  1.4097, -4.3516,  ..., -1.7387,  4.6553,  0.7137],\n",
            "        [ 1.4952,  0.6323,  3.4081,  ...,  0.2407,  3.0345,  0.4437],\n",
            "        ...,\n",
            "        [ 2.6402,  0.2618,  1.9097,  ..., -0.5641,  0.9170, -1.3747],\n",
            "        [ 3.0832,  0.3227, -2.5736,  ...,  0.2378,  4.0467,  0.2288],\n",
            "        [-0.0581,  2.7324, -1.6344,  ...,  4.7842,  2.9322,  0.2199]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0807,  5.2849,  2.1848,  ...,  0.3336,  3.3241,  6.4615],\n",
            "        [-2.1023,  2.5596, -1.9055,  ...,  0.5253,  4.8222,  0.6685],\n",
            "        [ 2.1123,  3.7449, -1.2836,  ..., -3.3975, -2.1035, -0.2935],\n",
            "        ...,\n",
            "        [ 3.9003, -0.7916,  1.0030,  ..., -1.3805,  2.4020, -0.5112],\n",
            "        [-0.7610,  0.5300,  4.9107,  ...,  2.6419,  4.4539,  1.1373],\n",
            "        [ 1.0793,  0.3948,  1.0925,  ..., -1.7822,  1.3225,  0.5481]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1165,  0.4423, -1.3706,  ...,  1.1986,  2.6504, -2.0966],\n",
            "        [ 3.3667,  5.9553,  2.5419,  ..., -1.8894,  1.7770,  6.2359],\n",
            "        [ 0.3086,  3.7177, -4.8747,  ..., -1.5752,  1.3409, -0.4427],\n",
            "        ...,\n",
            "        [ 3.9392,  2.2038, -3.2420,  ..., -0.8575,  0.9645,  0.4218],\n",
            "        [ 3.6911,  1.8996, -1.4201,  ..., -2.2020,  1.2209,  0.7995],\n",
            "        [ 2.6159,  4.0246, -2.1977,  ...,  0.7527,  3.1767,  0.4663]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7322,  1.0386, -4.6689,  ...,  2.8331,  4.6021,  2.4971],\n",
            "        [-0.4935,  1.7841,  0.7402,  ..., -1.5090,  0.6377, -0.4515],\n",
            "        [ 3.7579,  0.0192, -1.2289,  ...,  1.4684,  0.6867, -0.6618],\n",
            "        ...,\n",
            "        [ 0.3750,  1.9588, -4.1201,  ...,  0.5569, -0.1647, -2.3588],\n",
            "        [ 0.7335,  3.2736,  2.5863,  ...,  5.0834,  4.0487,  1.5431],\n",
            "        [ 2.9344,  1.5173,  0.0111,  ...,  0.6767,  0.6347, -1.3406]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0423,  0.0671,  7.7017,  ..., -3.4231,  2.6491, -0.2110],\n",
            "        [ 2.3133,  0.1232, -2.2401,  ...,  1.6657,  4.5968,  1.6549],\n",
            "        [ 3.5556,  2.5860, -6.0293,  ...,  1.3065,  5.3850,  0.1307],\n",
            "        ...,\n",
            "        [ 0.8106, -1.3095,  1.6754,  ...,  3.2285,  2.2714,  0.0572],\n",
            "        [ 2.7539,  3.5467, -1.9944,  ..., -2.1794, -0.5785,  0.4480],\n",
            "        [ 4.1325,  4.9901, -6.2805,  ...,  0.2253,  5.3506,  1.6115]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6144, -1.1603, -2.4410,  ..., -1.2099,  3.4317,  2.5656],\n",
            "        [ 1.9276,  4.7259, -0.2117,  ...,  1.8158,  1.7064,  3.9386],\n",
            "        [ 3.2232,  3.2675,  1.1135,  ..., -3.2625,  1.2542, -1.1896],\n",
            "        ...,\n",
            "        [-0.7345,  1.2509, -3.1206,  ..., -0.1512,  1.6863, -1.1247],\n",
            "        [ 2.6536,  0.7418, -1.0138,  ..., -1.0525,  0.7959, -0.9433],\n",
            "        [ 2.4184,  3.6606, -0.5129,  ...,  4.4522,  3.6988,  1.9987]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6033,  2.4308, -3.6793,  ...,  1.1038,  3.1238, -2.3903],\n",
            "        [ 1.0705,  0.7761, -7.0075,  ...,  0.8327,  1.1800, -0.4891],\n",
            "        [ 2.0441,  4.4193, -2.1429,  ...,  0.8594,  1.6083,  3.6437],\n",
            "        ...,\n",
            "        [ 2.4085,  2.3282, -3.1848,  ..., -0.4667,  3.4156,  1.5792],\n",
            "        [ 1.0597,  3.5220, -2.1974,  ..., -1.2572,  0.8721,  1.8602],\n",
            "        [ 1.4155,  0.2375, -2.7732,  ...,  0.4365,  1.7014, -2.3030]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1533,  0.1372, -2.7066,  ..., -0.1253,  0.3654, -0.2324],\n",
            "        [ 6.0664,  0.1712,  8.6610,  ..., -5.4133,  0.3470, -0.2602],\n",
            "        [ 3.3010, -2.1818,  2.0681,  ...,  1.8857,  1.4813, -1.8428],\n",
            "        ...,\n",
            "        [ 3.0869,  1.9221, -3.2179,  ..., -0.9011,  2.7662, -1.5437],\n",
            "        [-0.0938,  0.2285, -3.4098,  ...,  0.3587,  0.0901, -1.9888],\n",
            "        [ 6.5293,  0.7336,  6.4917,  ..., -2.5577,  0.5108, -0.3420]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.5233e-01,  3.5235e+00, -8.1770e-01,  ..., -2.2023e+00,\n",
            "         -9.2194e-01, -4.8677e-01],\n",
            "        [ 2.1951e+00,  1.0935e+00, -5.8270e+00,  ...,  4.8872e-03,\n",
            "          1.7647e+00, -7.1663e-01],\n",
            "        [ 2.6861e+00,  1.3594e+00, -5.9794e+00,  ..., -1.4812e+00,\n",
            "          6.8766e+00,  2.2166e+00],\n",
            "        ...,\n",
            "        [ 3.1606e+00,  2.2963e+00,  6.8320e+00,  ..., -6.9319e-01,\n",
            "          1.7651e+00,  2.2418e+00],\n",
            "        [ 2.7925e+00,  1.1363e+00, -2.9510e+00,  ...,  9.3084e-01,\n",
            "          2.6365e+00,  5.0253e-02],\n",
            "        [ 5.0185e+00,  3.6833e+00, -4.0741e+00,  ...,  1.6150e-02,\n",
            "         -4.0338e-01,  2.2276e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7412e+00,  6.3047e-01, -1.1519e+00,  ...,  7.1003e-01,\n",
            "          1.1568e+00, -7.6810e-01],\n",
            "        [ 1.3275e+00,  1.4617e+00,  3.5994e+00,  ...,  9.2843e-01,\n",
            "         -2.3122e-03, -3.5697e+00],\n",
            "        [ 2.2209e-01,  1.1512e+00, -3.4357e+00,  ...,  4.2681e-01,\n",
            "         -2.6223e-01, -1.8471e+00],\n",
            "        ...,\n",
            "        [ 2.3174e+00,  1.7169e+00,  5.8895e+00,  ..., -1.6072e+00,\n",
            "         -3.6361e-01, -1.0334e+00],\n",
            "        [-5.4711e-01,  6.5148e-01, -3.0669e+00,  ...,  9.7505e-01,\n",
            "          2.9050e-01, -2.1756e+00],\n",
            "        [ 3.8017e-01,  1.4451e+00,  1.5906e+00,  ..., -1.0660e-01,\n",
            "          2.0578e+00,  5.3468e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9755,  0.1211, -4.9997,  ...,  1.4046,  4.4585,  1.9984],\n",
            "        [-2.1007,  0.8782,  4.9661,  ...,  0.4746,  2.4346, -0.5757],\n",
            "        [-1.5089,  3.5400, -3.8258,  ..., -0.8644,  1.8458, -0.1582],\n",
            "        ...,\n",
            "        [ 2.8374,  1.2671, -3.4593,  ..., -1.6684,  1.5267, -0.6371],\n",
            "        [-0.0144, -1.0100,  4.4277,  ...,  1.1903,  2.6867,  1.6764],\n",
            "        [ 2.1798,  1.9797,  1.0600,  ..., -3.0531,  0.0171,  0.8515]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1869,  4.6673, -0.8950,  ..., -1.7014,  2.6496,  4.0340],\n",
            "        [-0.0762,  0.4654, -2.0775,  ...,  0.0174,  3.5675, -1.2053],\n",
            "        [ 0.2898, -1.0966,  3.6918,  ..., -0.3742,  3.3265,  0.8020],\n",
            "        ...,\n",
            "        [ 4.7789, -1.3177,  2.5907,  ...,  1.8683,  2.4270, -0.8399],\n",
            "        [ 2.6544,  3.4728, -2.0770,  ..., -1.8382,  0.6913,  3.4890],\n",
            "        [ 3.8721,  2.1650, -4.5582,  ..., -1.5310,  3.5107, -0.3074]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8494,  3.0107, -0.7064,  ..., -0.9176,  0.1173,  1.2178],\n",
            "        [ 2.9299,  3.3400,  1.7847,  ...,  3.3848,  4.0606,  1.3507],\n",
            "        [ 0.0746, -0.2063,  1.6147,  ..., -0.3596,  4.1622,  4.0232],\n",
            "        ...,\n",
            "        [ 0.4912,  2.4930, -6.0871,  ..., -1.3606,  2.0245,  0.0321],\n",
            "        [ 1.7415,  0.5621, -0.2740,  ..., -2.6878,  2.3665, -0.8704],\n",
            "        [ 0.4878,  2.6053, -3.6733,  ..., -0.9307,  0.7905,  0.5244]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.5725,  1.5842,  3.5021,  ..., -2.5461,  1.1221, -0.6350],\n",
            "        [ 3.1094,  4.5957, -0.1296,  ...,  1.5342,  3.5107,  5.3263],\n",
            "        [ 3.8603,  2.8271, -6.2092,  ..., -0.2464, -0.4569,  0.1261],\n",
            "        ...,\n",
            "        [ 0.9296,  4.3535, -3.0747,  ...,  0.9272,  2.7679, -0.2564],\n",
            "        [ 2.3782,  0.2404, -3.3792,  ..., -0.7618,  0.6842, -2.4245],\n",
            "        [ 0.1935,  2.7170, -3.5379,  ..., -1.9807,  0.5409,  0.4931]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0386,  1.0310, -0.7195,  ..., -2.3332,  4.4970,  0.5755],\n",
            "        [-0.3376,  1.0408, -0.5416,  ...,  2.3300,  4.7057,  2.5103],\n",
            "        [ 2.5917,  5.3465,  2.3170,  ...,  3.6526,  1.7742,  2.3714],\n",
            "        ...,\n",
            "        [ 0.2465,  0.4825,  2.4239,  ...,  0.5605,  3.0716,  0.7805],\n",
            "        [ 2.1540,  1.2902, -4.0947,  ..., -0.6882,  3.0578,  3.1046],\n",
            "        [-0.2810,  2.2434, -2.5429,  ..., -1.2366,  0.0097,  0.0187]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4857,  0.2357, -3.9199,  ...,  0.0086,  5.8522,  0.2714],\n",
            "        [-1.4174,  2.8088, -1.6883,  ...,  2.6902,  3.8550,  0.5559],\n",
            "        [ 5.0282,  0.6135, -4.0954,  ...,  1.0991,  5.1339,  1.4961],\n",
            "        ...,\n",
            "        [ 1.8848,  0.6691, -2.0553,  ..., -0.5750,  1.9024, -1.5955],\n",
            "        [ 0.3035,  2.2673, -1.1330,  ..., -0.3436,  3.9916,  2.8961],\n",
            "        [ 0.9812,  2.6821, -0.2660,  ..., -2.0648,  1.5297, -0.0527]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7665,  0.3651,  1.4326,  ..., -0.8462,  2.6860, -0.9139],\n",
            "        [ 0.1873,  2.2757, -5.5614,  ...,  1.5541,  2.8928, -0.1674],\n",
            "        [ 4.0570,  1.8352,  0.2332,  ...,  0.2990,  6.4188,  2.6746],\n",
            "        ...,\n",
            "        [ 1.9164,  2.6147,  3.8703,  ..., -2.2623,  0.7977,  3.6308],\n",
            "        [ 1.5326,  4.7877, -1.5350,  ..., -5.3442, -1.4131,  0.1990],\n",
            "        [ 2.8386,  1.8975, -6.4159,  ...,  0.5711,  4.5729,  1.7857]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0765,  0.5688, -3.0018,  ..., -0.7403,  1.3188,  0.5490],\n",
            "        [ 0.7698,  6.2962,  1.4115,  ..., -2.6480,  0.9069,  5.0346],\n",
            "        [-3.3547,  0.2085,  5.3625,  ..., -1.0005,  6.8283,  1.9651],\n",
            "        ...,\n",
            "        [ 0.1624,  1.1181, -4.7672,  ..., -0.8564,  0.3842, -2.4837],\n",
            "        [ 3.9748,  2.7340, -2.6483,  ..., -2.1660,  0.6840,  1.3690],\n",
            "        [ 4.4752,  2.3716, -0.3499,  ..., -1.0906, -0.8281, -0.2431]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6514,  3.5765, -1.5622,  ...,  1.2436,  2.9722,  2.1589],\n",
            "        [ 1.3432,  0.8947, -3.5154,  ..., -1.5002,  2.7524,  0.5734],\n",
            "        [ 0.0760,  3.7323, -8.2411,  ..., -0.2190,  3.4719,  1.3711],\n",
            "        ...,\n",
            "        [ 4.8387,  0.0904, -3.1120,  ..., -0.7380,  2.0161, -0.5134],\n",
            "        [ 0.9545, -0.5751, -4.0162,  ...,  0.1561,  5.9023, -0.2385],\n",
            "        [ 0.1224,  3.0765,  3.0034,  ...,  3.9470,  4.1894,  1.8495]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5195,  4.5903, -6.7570,  ..., -0.7169,  0.5339,  1.2611],\n",
            "        [ 1.2258, -1.3590,  7.7915,  ..., -1.3698,  2.5115,  0.3267],\n",
            "        [ 0.3342,  2.2092, -3.2984,  ...,  1.7780,  2.9950,  1.1159],\n",
            "        ...,\n",
            "        [ 0.3900,  2.5401, -4.7020,  ..., -2.5237,  1.7393,  0.8000],\n",
            "        [ 3.2295,  1.3503, -8.6909,  ...,  0.7068,  3.8634,  1.5043],\n",
            "        [ 3.3418,  0.8955,  6.7694,  ..., -3.8502,  3.2258,  4.3142]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6043,  1.2276,  3.1223,  ..., -1.4102,  1.3705,  2.4151],\n",
            "        [ 4.6924,  1.3549, -4.7844,  ..., -1.5457,  3.8977, -0.3221],\n",
            "        [ 2.7381,  3.8499, -1.8181,  ..., -2.5517,  1.1714,  1.5040],\n",
            "        ...,\n",
            "        [ 0.3031,  2.3625, -5.6200,  ..., -2.4020,  1.7891,  0.0883],\n",
            "        [ 0.7781,  0.3960, -2.5736,  ..., -1.0193,  0.4698, -1.6611],\n",
            "        [-0.1200,  2.6846, -3.4851,  ..., -1.8773,  0.2092, -0.4856]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1169,  1.3080,  5.5094,  ...,  0.4243,  0.4597, -2.0055],\n",
            "        [ 3.6741,  0.6094, -3.6068,  ..., -0.3301,  4.2681, -0.1748],\n",
            "        [ 1.3771,  4.1083, -2.4961,  ...,  0.2939,  1.7874,  1.2637],\n",
            "        ...,\n",
            "        [-0.4281,  1.1626, -0.1209,  ..., -1.2270,  1.4549, -5.1810],\n",
            "        [ 3.9752,  0.1307, -2.6361,  ..., -1.0103,  1.1282,  0.5326],\n",
            "        [ 3.5646,  0.2543, -3.6016,  ..., -0.1226,  3.0111, -1.0154]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4074,  0.5587,  1.5165,  ...,  2.4520,  1.1868,  0.2362],\n",
            "        [-0.0682,  2.3527,  1.9466,  ..., -1.6431,  2.5201,  5.1580],\n",
            "        [ 3.1140,  0.1283,  3.6547,  ..., -4.3574,  1.9761, -1.2314],\n",
            "        ...,\n",
            "        [ 2.1271,  0.1874, -2.5968,  ...,  0.0209,  0.8248, -2.4334],\n",
            "        [ 0.6671,  2.2260, -1.2827,  ...,  0.1658,  1.7333,  0.1412],\n",
            "        [ 2.6549,  3.2173,  0.7718,  ...,  1.2644,  1.0994,  4.5519]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6664,  2.8040,  1.8169,  ...,  4.0795,  4.0585,  2.0004],\n",
            "        [-0.2338,  2.5508, -4.8980,  ..., -1.0211,  3.2037,  1.5782],\n",
            "        [-1.1097,  3.2233, -6.7107,  ..., -1.8980,  1.8580,  0.5641],\n",
            "        ...,\n",
            "        [-0.4992,  3.2996, -4.3939,  ..., -2.0595,  0.9495, -0.6787],\n",
            "        [ 3.4342,  1.3284,  2.8640,  ..., -0.1207,  1.7572,  0.5064],\n",
            "        [-0.7771,  1.7216, -2.2232,  ..., -0.9223,  1.0752, -0.9655]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6167,  1.7866, -1.1594,  ..., -1.3174,  3.0552,  2.9812],\n",
            "        [ 4.9047, -0.4803, -1.2684,  ...,  1.8685,  1.1292,  0.1269],\n",
            "        [ 0.5962, -0.2050,  1.6650,  ..., -0.6383,  2.3852, -2.4049],\n",
            "        ...,\n",
            "        [ 0.3833,  1.6939,  0.0481,  ...,  0.7146,  2.1109, -0.8970],\n",
            "        [ 3.4741,  2.0752, -2.9694,  ..., -2.5935,  0.3636,  1.2438],\n",
            "        [ 0.8890,  1.9159,  2.5606,  ...,  0.6646,  3.0326,  2.0651]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8512,  4.0877, -0.7822,  ..., -3.0494,  2.8168, -2.1300],\n",
            "        [ 0.4087,  2.5128,  0.0563,  ...,  2.8948,  2.9423,  0.6430],\n",
            "        [-0.6618,  2.7805, -5.9576,  ..., -2.6446,  2.2073,  0.2010],\n",
            "        ...,\n",
            "        [ 0.9346,  2.9484, -1.7626,  ...,  0.9654,  4.1784,  1.9119],\n",
            "        [ 1.3896,  2.9487, -0.1420,  ...,  1.1730,  4.2795,  3.5168],\n",
            "        [-0.3382,  4.6102, -4.6902,  ..., -0.9303,  0.4569,  2.1643]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4205,  3.8594, -3.5435,  ...,  4.4911,  3.4132,  2.1586],\n",
            "        [ 0.9815,  0.5247, -3.1117,  ...,  0.6657,  3.9318,  2.1332],\n",
            "        [ 0.2846,  0.2337,  3.5222,  ..., -0.2638,  3.9068, -0.2288],\n",
            "        ...,\n",
            "        [ 1.3534,  2.2917, -2.9842,  ..., -1.0613,  2.3375, -0.4063],\n",
            "        [ 4.5703, -2.2339,  3.1406,  ..., -2.3432,  2.9532, -2.9125],\n",
            "        [ 4.9430,  0.8969, -2.5040,  ..., -1.2121,  0.0690,  0.0782]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 8.4016,  0.0396,  6.0520,  ..., -4.5273, -0.2037,  1.4293],\n",
            "        [ 1.7133, -0.4719, -0.7131,  ..., -0.8593,  2.6721, -2.5189],\n",
            "        [-1.2100, -3.5915,  7.3922,  ..., -2.2012,  3.3003, -2.3730],\n",
            "        ...,\n",
            "        [ 7.7758,  3.3931, -0.3762,  ..., -1.9289, -1.5830,  2.0862],\n",
            "        [-0.1267,  5.3240, -0.6669,  ...,  0.1713,  3.9754,  6.7280],\n",
            "        [ 0.6040,  2.4427,  1.8847,  ..., -0.6474,  3.8471,  2.7269]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4674,  1.9849, -3.6046,  ...,  0.4834,  2.0321,  0.2524],\n",
            "        [ 5.1658,  1.1064,  0.2542,  ..., -1.5868,  1.6708,  1.3166],\n",
            "        [ 3.7563, -1.5974, -3.4262,  ..., -0.7662,  3.8087, -1.4912],\n",
            "        ...,\n",
            "        [ 4.0310,  0.0566,  1.6298,  ..., -0.5742,  3.8452, -2.5548],\n",
            "        [ 2.0279,  2.6896, -1.7607,  ..., -1.6503,  0.6734,  2.8464],\n",
            "        [-1.8940,  3.6953, -1.7670,  ...,  2.7837,  3.3427,  2.7021]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6799e+00, -2.2375e-01,  5.5854e+00,  ..., -4.3911e+00,\n",
            "         -2.1077e-01,  2.9372e+00],\n",
            "        [ 1.7527e+00,  8.4004e-01, -1.4828e+00,  ...,  2.0012e+00,\n",
            "          2.7727e+00, -1.5493e-03],\n",
            "        [ 8.9908e-01,  3.3308e+00, -6.4332e+00,  ..., -2.3064e-01,\n",
            "          1.5820e+00,  1.6007e+00],\n",
            "        ...,\n",
            "        [-7.9953e-01,  5.5437e+00, -1.0515e+00,  ...,  1.8885e+00,\n",
            "          9.3555e-01,  3.8295e+00],\n",
            "        [ 3.4526e+00,  6.2609e-01, -2.2823e+00,  ..., -1.5759e+00,\n",
            "          3.5010e+00, -5.5507e-01],\n",
            "        [ 1.3955e+00,  6.1026e+00, -3.1950e-01,  ..., -5.2771e+00,\n",
            "          2.1312e-01,  1.7597e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6285,  3.7750,  1.1871,  ..., -1.1056,  1.9533, -0.3586],\n",
            "        [ 2.6944,  0.5711,  4.7254,  ..., -1.4501,  3.1663,  2.9455],\n",
            "        [ 4.7690,  2.1442,  5.4874,  ..., -0.3250,  0.0365,  0.9179],\n",
            "        ...,\n",
            "        [ 4.3652,  1.2210,  4.5820,  ..., -2.9218,  0.4517, -0.2860],\n",
            "        [ 1.3584,  2.7524,  4.1695,  ..., -1.4720,  1.0999, -2.5569],\n",
            "        [ 5.1043,  3.7847,  0.1568,  ..., -1.5427, -0.6629,  1.2430]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3943, -1.3258,  5.5353,  ...,  0.3780,  4.8089,  0.4975],\n",
            "        [ 3.7994,  0.9036, -4.7468,  ..., -0.5356,  3.9692, -0.7559],\n",
            "        [ 1.1591, -0.3508,  2.8388,  ..., -1.6909,  2.1650, -0.4302],\n",
            "        ...,\n",
            "        [ 4.2222,  2.7291, -1.6820,  ..., -1.3683,  1.2877,  0.6490],\n",
            "        [ 3.8941, -0.7294, -2.8412,  ..., -1.5637,  3.8359, -0.3308],\n",
            "        [ 0.3027,  3.2659, -8.3191,  ..., -0.8029,  2.8283,  3.1025]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5383e+00, -1.6972e-03, -4.1780e-01,  ..., -1.4998e-01,\n",
            "          4.7080e+00, -1.7219e+00],\n",
            "        [ 5.4784e+00,  6.9010e-01, -4.3509e+00,  ..., -9.9271e-01,\n",
            "          5.9118e+00,  2.5672e-01],\n",
            "        [-3.2402e-01,  5.6736e+00,  6.6961e-01,  ..., -2.5634e+00,\n",
            "          1.4466e+00,  7.9180e+00],\n",
            "        ...,\n",
            "        [ 4.7166e+00,  9.4772e-01,  9.4203e-01,  ..., -2.6871e-02,\n",
            "          1.1684e+00, -2.0188e+00],\n",
            "        [-6.4703e-01,  3.4571e-01,  6.9765e+00,  ...,  1.0498e+00,\n",
            "          4.6904e+00, -5.0960e-01],\n",
            "        [ 7.6595e-01,  3.2210e+00, -3.3725e+00,  ...,  1.4661e+00,\n",
            "          4.3197e+00,  3.8198e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1330,  2.8945,  0.8357,  ..., -3.1649,  2.5917,  1.2103],\n",
            "        [ 0.9612,  2.0595, -3.8313,  ..., -2.0871,  2.7755,  0.6180],\n",
            "        [ 2.0428,  4.5304, -0.2002,  ...,  2.0656,  2.0962,  5.6454],\n",
            "        ...,\n",
            "        [-2.7680,  2.2251,  5.8946,  ...,  0.6731,  4.0702,  1.1021],\n",
            "        [ 1.8716,  2.1767,  6.5784,  ..., -2.6431,  5.2314, -0.9239],\n",
            "        [ 1.1656,  1.0093, -1.8029,  ...,  3.6690,  2.3124, -1.2382]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6186,  3.2586, -0.1665,  ..., -2.1405,  2.6806, -1.1497],\n",
            "        [ 3.1487,  4.1336, -0.0766,  ..., -1.4890,  0.6378,  0.9599],\n",
            "        [ 7.6283,  0.3754, -2.6280,  ..., -2.3509,  1.7868,  2.4729],\n",
            "        ...,\n",
            "        [ 2.8900,  1.4516,  8.3075,  ..., -0.1284,  1.6205,  0.8212],\n",
            "        [ 5.7268,  1.4841,  0.3110,  ...,  0.4110,  1.0908,  0.3201],\n",
            "        [ 0.0806,  2.5825, -3.3135,  ...,  1.6830,  3.0325,  0.9587]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8063,  1.7738, -2.9993,  ...,  1.0393,  3.2945, -0.6535],\n",
            "        [-1.0179, -0.0162,  6.3102,  ...,  0.2834,  3.1872,  1.7499],\n",
            "        [ 1.0229,  4.7407, -0.2134,  ...,  1.8909,  3.3778,  2.9789],\n",
            "        ...,\n",
            "        [ 4.4384,  1.0706,  0.3793,  ..., -5.2332,  0.9178,  0.8514],\n",
            "        [ 1.9871,  3.0858,  0.2638,  ..., -0.8147,  1.9232,  4.0374],\n",
            "        [ 3.9353,  6.7743, -3.0145,  ..., -2.8245,  2.9290,  7.8435]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2490,  5.9092, -9.0633,  ..., -1.6710, -0.1461,  1.4580],\n",
            "        [ 3.0353,  0.2821, -0.9413,  ...,  2.8573,  5.6441,  1.8785],\n",
            "        [ 2.7085,  0.8866, -3.8087,  ...,  0.8347,  5.4253,  1.3730],\n",
            "        ...,\n",
            "        [-0.6076,  1.7960, -1.5407,  ...,  0.7912,  1.9063, -0.3414],\n",
            "        [ 3.9490,  0.6769,  0.7012,  ..., -0.1456,  1.2925,  1.1619],\n",
            "        [ 4.9214,  0.8906,  7.2605,  ..., -3.4545,  2.5417,  2.1620]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1920,  3.4682,  1.2647,  ..., -1.9192,  2.4405,  4.2719],\n",
            "        [ 3.7653,  0.1220,  0.7098,  ..., -0.6363,  2.5473, -2.5871],\n",
            "        [-0.9415, -0.5098,  0.0466,  ...,  1.7441,  4.6960,  0.9491],\n",
            "        ...,\n",
            "        [ 6.5163, -1.0060,  7.7897,  ..., -7.0055,  0.7471,  1.3428],\n",
            "        [ 3.1862,  2.7407, -3.3692,  ..., -0.5492,  5.8272,  0.6574],\n",
            "        [ 0.0726,  2.9843, -7.3142,  ..., -1.9587,  2.9694,  1.7044]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3397,  4.7523, -0.8565,  ..., -4.9668,  1.4077,  1.2220],\n",
            "        [-0.2695,  2.0984, -0.3486,  ..., -1.0520,  5.0567, -0.2884],\n",
            "        [-0.7499,  3.5160,  2.8538,  ...,  3.5420,  5.0551,  2.5477],\n",
            "        ...,\n",
            "        [ 2.8082, -0.1974, -5.1818,  ...,  0.2796,  2.4687, -0.1509],\n",
            "        [ 0.7085, -0.2820,  5.9325,  ..., -3.1865,  1.3465, -1.6127],\n",
            "        [ 2.0399,  0.0734, -3.1610,  ...,  1.0236,  2.1642,  1.1988]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6353,  2.4889, -1.5490,  ...,  2.6559,  4.3207,  2.6684],\n",
            "        [ 2.5450,  0.4259,  0.2486,  ..., -2.4706,  3.2287, -1.1881],\n",
            "        [-3.5486,  2.0680,  3.9106,  ..., -4.1000,  2.2520, -2.4809],\n",
            "        ...,\n",
            "        [ 2.9079,  1.3936, -5.9160,  ..., -1.0073,  2.1798,  1.0853],\n",
            "        [ 1.3514,  1.2418, -0.6262,  ..., -1.3416,  1.3873, -0.5714],\n",
            "        [ 1.6912, -0.4220,  4.5827,  ..., -1.0801,  4.3192,  1.7611]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2800, -0.2841, -2.3363,  ...,  0.7147,  2.9925, -1.0129],\n",
            "        [-0.7965,  0.7242, -1.0175,  ...,  0.4439,  4.9180,  0.1640],\n",
            "        [ 1.3255,  4.0313, -3.6908,  ...,  1.1040,  5.7304,  4.4787],\n",
            "        ...,\n",
            "        [-0.5518,  1.5107, -1.8556,  ..., -0.7997,  6.2896, -0.4626],\n",
            "        [ 2.3500,  2.2882,  5.1483,  ..., -1.8005,  1.2087,  2.5916],\n",
            "        [ 1.5871,  2.8919,  1.3984,  ...,  3.1279,  1.6773,  0.7779]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0682,  3.9090, -5.5916,  ...,  1.3485,  2.2284, -1.6762],\n",
            "        [ 3.1229,  2.8363, -6.3093,  ...,  0.1705,  2.9493,  3.1448],\n",
            "        [-0.3908,  2.1953, -8.3187,  ...,  0.1492,  4.5949,  2.1960],\n",
            "        ...,\n",
            "        [-1.3151,  4.0673, -3.1184,  ...,  2.7880,  3.5113,  1.8397],\n",
            "        [-0.6640,  1.7919,  6.6049,  ...,  0.5887,  3.4865,  0.1813],\n",
            "        [-1.5554,  5.3385, -1.4361,  ..., -0.6372,  2.4968,  0.0213]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5274,  5.2100, -2.7140,  ..., -4.4324,  2.3300,  3.2593],\n",
            "        [ 0.6251,  2.1966, -0.7629,  ...,  1.7809,  3.3714,  0.4134],\n",
            "        [ 3.2978,  1.1435,  0.8910,  ...,  0.6083,  2.0622, -1.1242],\n",
            "        ...,\n",
            "        [ 9.8194,  1.0020,  6.4978,  ..., -4.4044,  1.3719,  0.4290],\n",
            "        [ 1.2334,  2.1930, -0.4298,  ..., -1.5376,  4.9152,  2.1956],\n",
            "        [ 4.9838,  2.4745,  5.7340,  ..., -4.1370,  1.9704,  5.5648]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0814,  2.5641, -1.2512,  ...,  2.3629,  3.3332,  3.1657],\n",
            "        [ 5.7086,  2.7505, -0.8300,  ..., -1.6727,  5.6981,  3.3746],\n",
            "        [ 0.9828,  0.9880,  1.6577,  ...,  2.0095,  4.5103,  0.7857],\n",
            "        ...,\n",
            "        [-0.6163,  4.1800, -1.7543,  ...,  0.9556,  3.0528, -0.6289],\n",
            "        [ 2.3374, -0.4872,  0.0583,  ...,  1.9223,  3.3595, -0.4584],\n",
            "        [-1.2372,  1.7563,  1.5205,  ..., -1.8994,  3.0854, -0.2227]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9686, -1.5811,  3.2588,  ...,  0.4903,  4.1437, -0.3521],\n",
            "        [ 0.0141,  0.4626, -1.0122,  ...,  1.0722,  1.3420, -1.8403],\n",
            "        [ 2.5666,  2.7385, -0.6018,  ...,  1.5523,  1.0644,  0.1379],\n",
            "        ...,\n",
            "        [ 2.2021,  4.8189, -5.0267,  ..., -1.2044,  2.7920,  4.5668],\n",
            "        [ 4.6053,  1.8554, -2.8237,  ..., -1.9817,  6.0177,  2.5332],\n",
            "        [ 2.0019,  2.1536, -3.8836,  ..., -0.8267,  1.5259, -0.9699]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4281,  4.9364, -3.8853,  ..., -0.4540,  2.5715,  0.4877],\n",
            "        [-0.4939,  3.1391, -6.0384,  ..., -2.1954,  1.4440,  1.4245],\n",
            "        [ 0.5084,  2.1431, -3.1555,  ...,  1.7887,  5.4050,  3.4832],\n",
            "        ...,\n",
            "        [ 0.0816,  2.2464, -3.5367,  ..., -1.5772,  0.3086, -0.2184],\n",
            "        [ 3.5942,  3.2690,  4.3626,  ..., -0.3116,  2.8596,  4.4591],\n",
            "        [ 4.0147,  2.7964, -1.9170,  ..., -3.2718, -0.2795,  1.7587]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2542,  7.8545, -1.0744,  ..., -3.7006,  2.3166,  7.3941],\n",
            "        [-0.8765,  0.9214,  6.2806,  ..., -2.4937,  4.2008,  0.0826],\n",
            "        [-0.8467,  3.8600, -3.2083,  ...,  3.2655,  2.6579,  1.5837],\n",
            "        ...,\n",
            "        [ 1.5807,  2.7582,  1.5757,  ..., -1.7809,  3.6409,  3.4444],\n",
            "        [ 0.0984,  0.5951, -3.5492,  ...,  1.1594,  5.8294, -1.3339],\n",
            "        [ 1.9556,  5.9058, -0.4663,  ..., -2.1268,  0.2175,  6.0709]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7832, -1.4450,  2.2029,  ..., -3.0679,  3.2644, -0.9991],\n",
            "        [ 2.9376,  3.7271, -2.4968,  ..., -2.8588,  3.1368,  2.9437],\n",
            "        [ 0.4094,  4.5632,  4.7179,  ...,  2.3949,  2.8423,  1.7585],\n",
            "        ...,\n",
            "        [ 1.4756,  2.9196, -3.3459,  ...,  1.1151,  3.7188,  2.5522],\n",
            "        [ 6.6361,  2.0765,  0.3798,  ...,  0.4252,  3.9681,  0.0980],\n",
            "        [-0.3698,  1.9630, -2.9326,  ...,  0.7640,  0.8719, -1.7674]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7080,  3.0942, -2.2035,  ..., -2.8932,  4.3502, -2.1228],\n",
            "        [ 1.2298,  0.7214, -2.3187,  ..., -1.1357,  0.1315, -2.5227],\n",
            "        [ 2.3776,  2.6600,  2.2411,  ...,  2.1852,  2.6190,  1.0231],\n",
            "        ...,\n",
            "        [ 0.6967,  1.8751, -3.4945,  ..., -0.7736,  0.8193,  0.4254],\n",
            "        [ 6.4269,  2.6953, -0.6281,  ...,  2.0463,  1.9478,  0.6758],\n",
            "        [-1.3906,  3.4770,  4.3443,  ...,  1.7152,  7.1861,  2.3827]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3923,  4.1414, -2.3130,  ...,  2.4856,  4.9773,  3.5377],\n",
            "        [ 0.5921,  1.8906, -3.6258,  ...,  3.4379,  4.2477,  0.6988],\n",
            "        [ 0.4542,  3.1107, -6.8804,  ..., -1.5855,  1.4378, -0.0797],\n",
            "        ...,\n",
            "        [ 5.0441, -0.9321,  7.6036,  ..., -4.0740,  3.2148,  1.4014],\n",
            "        [-0.3483,  4.3561, -5.0304,  ...,  1.8017,  3.6863,  2.5809],\n",
            "        [ 0.2726,  0.7339, -2.1094,  ...,  0.5734,  0.2463, -2.7575]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5654,  2.3822,  6.6590,  ...,  2.6445,  3.3414,  0.3124],\n",
            "        [ 0.4712,  0.5158, -1.3721,  ...,  0.5892, -0.2337, -2.2441],\n",
            "        [ 0.9075,  5.1378, -0.8141,  ..., -0.8666,  2.5445,  2.3737],\n",
            "        ...,\n",
            "        [ 4.2319,  1.3775, -4.0366,  ...,  1.1564,  1.7278, -0.9452],\n",
            "        [ 3.7794, -0.0589,  6.3832,  ..., -1.9827,  5.9241,  1.4370],\n",
            "        [ 0.3813,  1.9630, -4.0788,  ..., -0.4297,  3.8357, -0.2572]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3433,  0.4394,  2.1145,  ...,  0.6977,  4.0079,  1.3308],\n",
            "        [ 2.1298,  0.6600,  1.6641,  ..., -0.8119,  2.6419,  1.4201],\n",
            "        [-0.1570,  2.8089, -1.0897,  ...,  1.8011,  1.5783, -0.6611],\n",
            "        ...,\n",
            "        [ 1.3259,  2.8221, -0.2661,  ..., -1.3658,  4.2346, -0.4289],\n",
            "        [ 0.7402,  2.6663,  4.9666,  ...,  1.2002,  2.6622,  1.4808],\n",
            "        [-1.4561,  2.0145,  1.2787,  ..., -0.0055,  4.7241, -0.5817]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9069,  0.3663, -4.9400,  ...,  1.5942,  5.7260,  2.2725],\n",
            "        [ 1.9899,  1.2349, -2.4758,  ...,  0.2680,  4.1182,  1.3615],\n",
            "        [ 2.3922,  0.7097, -1.0129,  ..., -0.6298,  2.9339, -0.4439],\n",
            "        ...,\n",
            "        [-1.4727,  2.5996, -2.4636,  ...,  2.4013,  5.4255,  2.3335],\n",
            "        [-2.7960,  1.8230,  3.7796,  ...,  1.6914,  6.0417, -0.1882],\n",
            "        [ 1.9900,  3.1060,  0.0241,  ..., -1.7197,  1.9458, -0.6784]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3015e+00, -5.4392e-03,  3.7046e-01,  ..., -1.9410e+00,\n",
            "          1.5486e+00, -7.6081e-01],\n",
            "        [ 8.2332e-01,  4.2153e+00,  1.1728e+00,  ...,  4.3942e+00,\n",
            "          4.5093e+00,  3.5491e+00],\n",
            "        [ 1.7428e+00,  2.1974e+00, -5.4936e+00,  ...,  4.6115e-01,\n",
            "          2.6680e+00, -1.1402e-01],\n",
            "        ...,\n",
            "        [ 9.9289e-01,  2.5861e+00, -6.5268e-01,  ..., -5.0120e-01,\n",
            "          1.4945e+00, -4.4541e+00],\n",
            "        [-2.4776e-01,  1.7207e+00, -4.3881e+00,  ..., -6.7187e-01,\n",
            "          2.1383e+00, -4.7837e-01],\n",
            "        [ 5.2002e-01,  3.4076e+00, -2.6419e+00,  ..., -1.2935e+00,\n",
            "          2.9075e+00,  1.2616e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1964,  2.7647, -1.0289,  ...,  1.5677,  4.8583,  0.6673],\n",
            "        [-1.4757, -0.4207,  4.2430,  ..., -2.1699,  2.7498, -1.7626],\n",
            "        [-0.2269,  1.2027,  6.6459,  ...,  3.3517,  2.8013, -2.2522],\n",
            "        ...,\n",
            "        [ 3.2783, -0.8952,  4.9158,  ..., -1.0377,  4.3744,  1.6325],\n",
            "        [-0.3011,  1.9650, -0.4672,  ...,  1.0206,  4.7218,  3.7429],\n",
            "        [-0.8429, -1.5040,  9.2940,  ..., -1.8175,  1.0743, -2.9662]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6750,  3.3194,  0.2817,  ..., -0.2620,  2.7695, -0.9105],\n",
            "        [ 1.4143,  0.0197, -5.9355,  ..., -0.3147,  5.1045,  1.3154],\n",
            "        [ 3.1938,  4.8774,  4.8680,  ..., -2.6353,  1.8718,  3.2730],\n",
            "        ...,\n",
            "        [ 3.4939, -0.1098,  0.3759,  ...,  1.9249,  1.4858, -1.3181],\n",
            "        [ 4.5899,  4.2326, -4.7624,  ..., -3.2629,  1.7386,  2.0531],\n",
            "        [ 1.3820,  1.6465,  1.4450,  ..., -2.3976,  5.6707, -1.0764]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4893,  2.2967, -4.7584,  ..., -1.7827,  0.7127, -0.1769],\n",
            "        [-0.2030,  1.0133, -2.5482,  ...,  1.4197,  2.1409, -3.7061],\n",
            "        [ 1.0631,  6.6624, -1.1635,  ..., -1.6158,  4.5030,  6.1303],\n",
            "        ...,\n",
            "        [ 1.5477,  0.7108,  0.6676,  ..., -1.1905,  1.9610, -1.0762],\n",
            "        [ 2.8897,  2.6544,  8.7248,  ..., -4.1624,  4.3103,  5.1337],\n",
            "        [ 0.6389,  0.4103, -2.2524,  ..., -1.2386,  0.4536, -2.2242]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1808, -0.9090,  0.8720,  ..., -2.2164,  3.5187,  1.1444],\n",
            "        [ 4.9674,  0.7112,  3.4532,  ..., -2.2365,  0.6751,  1.7668],\n",
            "        [ 4.4261,  2.7194, -2.6740,  ..., -0.7437,  2.7360,  1.0337],\n",
            "        ...,\n",
            "        [ 0.8147,  2.1343, -2.9927,  ..., -1.2876,  2.3715, -1.9916],\n",
            "        [ 0.1690,  2.9448, -5.7135,  ..., -1.9035,  1.7861,  0.1184],\n",
            "        [-0.0582,  0.3930,  6.5904,  ..., -0.1063,  3.9122,  0.5006]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2898,  2.3676, -5.1516,  ...,  0.8854,  3.1541,  0.8856],\n",
            "        [ 2.7995,  0.1362,  3.1365,  ...,  0.7550,  1.9604,  1.0982],\n",
            "        [ 3.2098,  0.7101,  6.4254,  ...,  1.4365,  3.4869,  2.5788],\n",
            "        ...,\n",
            "        [ 3.4289,  2.5551, -2.9995,  ..., -2.1305,  5.3517,  2.3891],\n",
            "        [-1.0181,  2.2948, -4.6101,  ..., -0.0746,  1.3121, -1.3738],\n",
            "        [-0.9782,  0.9199,  2.2925,  ...,  1.9255,  4.1733,  2.1159]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5226,  1.6310,  8.0945,  ..., -1.8637,  2.9609,  0.4943],\n",
            "        [ 2.2510,  1.1375,  5.5464,  ..., -2.1696,  5.4580,  2.5446],\n",
            "        [ 0.3663,  3.6948, -0.5865,  ...,  2.5763,  3.8366,  2.2537],\n",
            "        ...,\n",
            "        [-0.5234,  2.3891,  6.8684,  ..., -0.6483,  0.1946,  0.3805],\n",
            "        [ 2.0899,  3.9729,  1.5536,  ..., -3.1334, -1.4330,  2.3569],\n",
            "        [-0.4499,  0.6682,  3.2327,  ...,  1.7848,  2.5467,  0.1068]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9284,  2.4831,  8.7067,  ..., -3.8546,  2.7241,  3.9775],\n",
            "        [ 1.4278,  0.1062,  2.5919,  ..., -0.3468,  4.2804, -0.1729],\n",
            "        [ 2.1650, -0.7191,  2.6999,  ..., -1.2847,  4.4391,  1.0474],\n",
            "        ...,\n",
            "        [-1.4584, -1.3207,  6.6864,  ..., -0.2780,  4.3117,  1.0716],\n",
            "        [ 6.9759, -0.6081, -0.6356,  ...,  0.6506,  2.6653, -1.6099],\n",
            "        [ 5.9231,  3.3415,  0.1720,  ..., -1.6303,  0.8933,  1.6782]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2124,  2.2815, -0.0591,  ..., -0.3520,  1.7908, -0.9176],\n",
            "        [-0.9484,  2.5721, -2.9555,  ...,  1.1795,  3.0718,  1.6870],\n",
            "        [-0.2190,  0.4419, -3.0760,  ...,  1.1745,  0.9164, -2.5430],\n",
            "        ...,\n",
            "        [-0.6612,  5.2797, -1.2802,  ...,  1.4154,  6.0749,  5.1084],\n",
            "        [ 0.5697,  5.7336, -4.0813,  ..., -0.0925,  0.6597,  1.2716],\n",
            "        [ 2.3619,  6.4590, -1.0326,  ..., -4.9692,  0.5575,  4.1255]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2305,  2.0992,  1.2112,  ..., -2.0156,  1.6548, -2.6429],\n",
            "        [-0.5473,  1.2508, -2.5192,  ..., -0.1236,  1.0978, -1.0256],\n",
            "        [ 4.7031,  1.4350, -4.2330,  ..., -1.5068,  5.2265,  3.5303],\n",
            "        ...,\n",
            "        [ 0.1604,  0.7248, -0.7589,  ...,  2.6665,  3.3736,  0.5941],\n",
            "        [ 1.2364,  3.7188, -4.1303,  ..., -2.2692, -0.2443,  2.2652],\n",
            "        [ 1.5095,  0.9701, -6.1854,  ...,  0.9125,  2.9265,  2.1850]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-7.2040e-01,  3.1738e+00, -2.8519e+00,  ..., -1.0933e+00,\n",
            "          8.6660e-01, -1.3227e-01],\n",
            "        [ 1.7480e+00,  3.4805e-01, -6.8733e+00,  ...,  3.0512e-01,\n",
            "          3.6534e+00,  4.1972e-01],\n",
            "        [-3.7783e-01,  3.7007e+00, -3.7537e+00,  ...,  3.2216e-01,\n",
            "          1.6139e+00,  1.9965e+00],\n",
            "        ...,\n",
            "        [-9.9392e-01, -2.7892e+00,  8.9878e+00,  ..., -2.7715e+00,\n",
            "          3.0936e+00, -3.5272e+00],\n",
            "        [ 1.9684e+00,  2.6935e+00, -1.8541e+00,  ..., -2.8168e-02,\n",
            "          4.2071e+00,  5.2710e+00],\n",
            "        [ 3.0180e+00,  1.1428e+00,  1.9496e-01,  ...,  5.1869e-04,\n",
            "          2.0157e+00, -6.9068e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6002,  1.0166, -7.4553,  ...,  2.5737,  5.0924,  2.0963],\n",
            "        [ 7.8905, -0.8665,  4.0059,  ..., -0.3763,  1.5282, -1.8439],\n",
            "        [ 1.5778,  1.7822, -4.5246,  ..., -2.2262,  5.0664,  3.0699],\n",
            "        ...,\n",
            "        [ 4.1395,  1.6541, -2.9333,  ...,  0.0920,  5.2586,  0.0722],\n",
            "        [-1.8826,  2.8639, -1.4205,  ...,  3.0154,  3.1230,  1.6410],\n",
            "        [-0.0580,  4.8756, -1.9281,  ..., -0.0201,  0.7127,  5.5949]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9943e+00,  2.0442e+00, -6.2268e-01,  ..., -1.6473e+00,\n",
            "          4.5025e+00, -3.1040e-01],\n",
            "        [ 3.8564e+00, -6.4100e-01, -4.5273e+00,  ...,  1.3368e+00,\n",
            "          5.6282e+00, -6.6333e-01],\n",
            "        [ 5.6940e+00, -1.6901e+00, -4.4492e-01,  ..., -1.5718e+00,\n",
            "          6.7106e+00,  4.7942e-01],\n",
            "        ...,\n",
            "        [-2.3690e-02,  6.2366e-01,  1.6747e+00,  ..., -4.1769e-01,\n",
            "          4.7944e+00,  8.4000e-01],\n",
            "        [-4.3155e-01,  1.8507e-01,  5.2005e+00,  ...,  2.4488e+00,\n",
            "          3.0682e+00,  1.2901e-03],\n",
            "        [-3.3899e-02,  1.4894e+00,  4.0915e-01,  ..., -1.6730e+00,\n",
            "          6.4583e+00, -4.0308e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3252,  3.9001, -4.7303,  ..., -1.5269,  1.0096,  0.7236],\n",
            "        [ 3.1598,  1.5768,  2.2204,  ...,  0.6233,  1.5579,  0.4003],\n",
            "        [ 3.1126, -1.1853,  1.0049,  ...,  2.1726,  3.4786, -2.2020],\n",
            "        ...,\n",
            "        [ 6.6237, -0.3037, -0.6610,  ..., -0.6118,  3.3613, -1.3287],\n",
            "        [ 5.8129,  1.3142, -4.9008,  ...,  2.2818,  0.5466,  0.6970],\n",
            "        [ 0.6405,  2.5454, -8.2792,  ..., -1.5587,  2.9465,  0.8576]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1844,  1.6386, -0.7257,  ..., -2.7945,  4.2343, -0.2834],\n",
            "        [ 2.2640,  0.8851,  1.2459,  ..., -2.3845,  2.5433,  0.0452],\n",
            "        [ 2.2522,  1.8171,  3.0278,  ...,  0.4838,  0.7610, -2.6277],\n",
            "        ...,\n",
            "        [ 0.7206,  1.5317, -4.5878,  ...,  0.6350,  5.0066,  3.3071],\n",
            "        [ 1.7150,  0.5573, -3.6209,  ...,  1.1126,  4.1794,  1.4349],\n",
            "        [ 2.6480,  5.1168, -4.5680,  ..., -0.0352, -0.2186,  2.4072]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3747,  2.9079, -6.3673,  ..., -1.5536,  2.1072, -0.0447],\n",
            "        [ 2.5894,  0.5375, -1.7072,  ..., -0.5747,  3.6022,  1.1404],\n",
            "        [ 0.2227,  1.3282,  1.2672,  ...,  0.7529,  2.5497,  0.2477],\n",
            "        ...,\n",
            "        [ 4.4305,  2.3600, -2.1004,  ..., -1.2801,  1.5655,  1.4709],\n",
            "        [ 3.3238,  1.6108,  3.5472,  ..., -1.9913, -0.0085, -1.6715],\n",
            "        [ 1.3853, -0.7750,  7.0278,  ..., -3.7139,  6.1736, -0.1120]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8665,  3.5506,  0.5301,  ...,  3.0605,  2.0200,  0.1435],\n",
            "        [ 0.9729,  1.8419, -0.2553,  ..., -2.2736,  5.5810,  0.6222],\n",
            "        [ 0.7306,  5.4473, -7.9442,  ..., -0.6916,  1.9393,  0.0450],\n",
            "        ...,\n",
            "        [-3.0372,  4.6410, -3.0554,  ..., -0.1213,  2.4390,  1.6199],\n",
            "        [ 2.2198,  0.5163, -4.9345,  ...,  1.0192,  4.3084,  1.2149],\n",
            "        [ 8.4666,  0.0515,  6.5778,  ..., -6.9520,  2.2128,  1.9025]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7089e+00,  7.1607e-01, -5.5203e+00,  ..., -3.1655e-01,\n",
            "          3.0313e+00, -5.2018e-02],\n",
            "        [ 2.8282e+00,  3.1909e+00,  3.7194e+00,  ..., -2.5290e+00,\n",
            "          2.0767e+00,  4.1511e+00],\n",
            "        [ 1.7436e+00,  3.9375e+00,  3.4404e+00,  ...,  4.2984e-01,\n",
            "          3.5245e-01,  2.5890e-01],\n",
            "        ...,\n",
            "        [ 3.3918e+00,  4.1649e+00,  3.5840e+00,  ..., -2.0482e+00,\n",
            "         -5.8722e-01,  1.0120e+00],\n",
            "        [ 4.8462e+00,  4.6215e+00, -2.1291e+00,  ..., -1.4617e+00,\n",
            "         -1.0214e+00,  3.3333e+00],\n",
            "        [-3.2994e+00,  4.2838e+00, -4.5074e+00,  ..., -2.7235e-03,\n",
            "          3.3168e+00,  8.8720e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6037,  0.9434,  7.8074,  ..., -4.4396,  3.5514,  2.9027],\n",
            "        [-0.4505,  1.0683, -2.2160,  ...,  0.3664,  0.9395, -2.0938],\n",
            "        [ 5.1386,  1.0558,  6.5113,  ..., -1.5529,  1.3887,  1.2732],\n",
            "        ...,\n",
            "        [ 3.1641,  0.7159, -3.3105,  ...,  1.9808,  6.1148,  0.2527],\n",
            "        [ 4.1475,  1.4620, -1.7346,  ...,  3.1895,  2.0777,  1.3295],\n",
            "        [ 1.0711,  2.6956, -4.0008,  ..., -1.0476,  1.5778,  0.0219]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5513,  3.5318,  0.9601,  ...,  3.2582,  3.5118,  0.6087],\n",
            "        [ 2.1259,  4.0086,  1.0472,  ...,  0.5189,  3.2042,  3.0682],\n",
            "        [-0.5510,  1.5434,  1.7198,  ..., -1.4723,  2.3434, -3.1241],\n",
            "        ...,\n",
            "        [ 0.1438,  5.3418, -4.0976,  ..., -1.9475,  3.1146,  3.1838],\n",
            "        [ 4.4980,  4.2322, -3.4315,  ..., -1.6464,  3.4765, -0.0065],\n",
            "        [ 0.6331,  2.5080,  0.3207,  ..., -0.8122,  1.1452, -2.1053]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5486,  4.8973,  2.9034,  ..., -0.4299,  4.1129,  5.8093],\n",
            "        [ 2.7661,  3.9568, -3.1259,  ..., -2.2249,  2.7681,  0.7462],\n",
            "        [ 1.8340, -0.0420, -3.6452,  ...,  0.5612,  3.0430, -1.0365],\n",
            "        ...,\n",
            "        [ 0.6368,  3.6949, -1.1793,  ..., -0.4169,  2.6404,  0.7600],\n",
            "        [ 1.9059,  1.6154, -0.9405,  ..., -1.6775,  1.6684, -2.2165],\n",
            "        [ 5.5786,  1.3044, -2.6821,  ..., -0.9700,  6.1584,  0.2546]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7128, -1.4767,  2.4272,  ..., -1.3074,  3.8842, -6.7942],\n",
            "        [ 3.0628,  3.6772,  3.1357,  ..., -0.3530,  3.5483,  4.0331],\n",
            "        [ 2.1351,  2.8570, -1.7840,  ...,  0.2922,  1.8995,  0.3216],\n",
            "        ...,\n",
            "        [ 4.3702,  0.9685,  0.1922,  ..., -2.7840,  3.2326, -2.4702],\n",
            "        [ 1.7354, -0.6268,  6.0666,  ..., -6.0140,  1.9871,  0.1936],\n",
            "        [ 9.9715,  0.5019,  3.9034,  ...,  0.0808,  0.8695,  0.0684]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1086,  4.9103, -3.0028,  ...,  1.0300,  4.9346,  4.7328],\n",
            "        [ 2.6930,  1.1784, -1.3642,  ..., -0.2357,  1.7975,  0.8449],\n",
            "        [ 0.7108,  3.3583,  2.8154,  ...,  0.1452,  6.0469,  2.3092],\n",
            "        ...,\n",
            "        [ 2.1987,  1.0576,  7.6647,  ..., -3.9494,  2.9067,  3.8167],\n",
            "        [ 3.5526,  0.8525, -0.0124,  ..., -0.1659,  1.4380, -1.3657],\n",
            "        [ 5.6340,  1.6958, -2.7861,  ...,  1.8130,  3.8099, -1.9062]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9304,  0.5214, -4.7999,  ..., -0.4383,  4.7355,  0.8309],\n",
            "        [ 0.5667,  6.2607, -3.9382,  ...,  1.4419,  1.5793,  0.8755],\n",
            "        [-2.5164,  3.1020,  0.6894,  ...,  1.9762,  6.3733,  1.5688],\n",
            "        ...,\n",
            "        [ 1.6901,  0.7223, -5.3320,  ...,  0.7925,  6.0119,  0.8341],\n",
            "        [ 3.2305,  3.5955, -8.1380,  ..., -0.9757,  3.9018,  0.9902],\n",
            "        [ 0.0862,  1.3529,  1.9052,  ..., -1.4486,  3.1901, -1.9005]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-6.4384e-01,  1.4318e+00, -2.7436e+00,  ...,  1.2240e+00,\n",
            "          8.6882e-01, -3.3274e+00],\n",
            "        [ 2.4152e+00,  3.2633e-03,  2.0617e+00,  ..., -4.1106e+00,\n",
            "          3.3450e+00, -1.0744e+00],\n",
            "        [ 4.6666e+00,  5.8253e+00, -1.1195e+00,  ..., -3.5752e+00,\n",
            "         -3.1959e-01,  4.9435e+00],\n",
            "        ...,\n",
            "        [ 2.5184e+00,  2.6394e+00,  3.8503e+00,  ..., -2.4074e+00,\n",
            "          4.5777e+00,  4.3140e+00],\n",
            "        [ 3.8910e+00,  2.3971e-01,  4.4159e+00,  ...,  2.8670e+00,\n",
            "          1.8136e+00, -2.5082e+00],\n",
            "        [ 5.0875e+00,  1.0843e+00,  6.1618e+00,  ..., -2.5168e+00,\n",
            "          3.7195e+00,  2.0847e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7490,  2.0364, -1.5185,  ...,  0.0387,  3.1157,  0.8350],\n",
            "        [ 4.3754,  2.3536,  3.6497,  ...,  1.3697,  2.5394,  3.2038],\n",
            "        [-0.0962,  3.2835, -5.1009,  ..., -2.7744,  1.3758, -0.8784],\n",
            "        ...,\n",
            "        [-0.2550,  3.1121, -3.6329,  ..., -1.7819,  1.1572, -0.3707],\n",
            "        [ 1.9423,  1.6820, -6.6560,  ...,  0.1106,  3.7305, -0.1711],\n",
            "        [ 4.0659,  1.7041,  2.6591,  ..., -3.3828,  0.6415, -0.6555]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6651,  2.4037, -6.9776,  ..., -2.7350,  2.8833,  0.4530],\n",
            "        [-1.5067,  5.8901, -1.7285,  ..., -1.1819,  1.0373,  1.8103],\n",
            "        [ 1.0850,  2.8147, -5.7737,  ..., -2.6331,  1.8750,  0.5693],\n",
            "        ...,\n",
            "        [ 2.0735,  1.9619, -2.4470,  ..., -2.3555,  6.0090,  1.6172],\n",
            "        [ 4.0122,  1.9557, -1.2372,  ..., -2.8549,  4.4778, -2.3469],\n",
            "        [ 3.3271, -0.5713, -0.2569,  ..., -2.0346,  6.2760, -1.2730]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2890,  2.2951, -3.6332,  ..., -2.4620,  1.0213, -0.6728],\n",
            "        [ 1.4282, -1.1105,  4.2640,  ..., -0.6699,  4.3013,  1.8930],\n",
            "        [ 1.0864, -1.4729,  1.2846,  ...,  1.3006,  6.1659, -3.8128],\n",
            "        ...,\n",
            "        [ 0.6491,  5.5432, -0.8367,  ..., -1.0327, -0.0913,  2.0554],\n",
            "        [ 2.4428, -0.3537, -2.1288,  ..., -2.3520,  6.2475,  0.9282],\n",
            "        [-0.6621,  3.4284,  2.6599,  ...,  0.2514,  1.9351,  2.5395]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4723,  0.8223, -0.0944,  ...,  1.0291,  2.8039, -2.6532],\n",
            "        [ 4.7794,  2.0479,  0.4392,  ...,  1.4324,  2.5692,  1.3027],\n",
            "        [-0.1386,  1.5128, -4.3539,  ..., -2.6833,  1.5832, -0.6983],\n",
            "        ...,\n",
            "        [ 3.2261, -0.7964, -1.1392,  ..., -0.1963,  3.2560, -1.5685],\n",
            "        [ 0.5991,  3.0514, -6.2241,  ..., -1.8854,  1.2036, -0.9311],\n",
            "        [-0.6808,  1.1956,  0.0541,  ..., -0.7138,  2.5245,  2.8378]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3917,  4.4401, -6.9796,  ..., -2.2443,  2.2810,  2.8539],\n",
            "        [ 4.2284,  1.3199,  9.8151,  ..., -6.2270,  2.5857,  2.1932],\n",
            "        [-0.7002,  0.8001,  9.8111,  ..., -3.9049,  3.6818,  0.0637],\n",
            "        ...,\n",
            "        [ 3.3574,  0.1724,  1.2361,  ...,  2.6782,  2.0995, -1.4902],\n",
            "        [ 1.5278,  1.1767, -7.1936,  ..., -0.2533,  4.6866, -0.0968],\n",
            "        [ 0.3404,  0.5928, -2.2069,  ...,  1.1089,  3.2177,  0.7460]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8889,  4.3399, -6.7626,  ...,  0.1965,  2.0761, -0.9980],\n",
            "        [ 1.8858,  3.0724, -8.3563,  ..., -0.7254, -1.3685,  1.4308],\n",
            "        [-0.2005,  2.1432, -2.2030,  ...,  0.6896,  2.5019,  1.8088],\n",
            "        ...,\n",
            "        [ 0.0723,  1.8889, -3.6138,  ...,  0.5023,  2.4627,  0.7678],\n",
            "        [ 5.2319,  1.4861,  2.3338,  ..., -4.3408,  4.5133,  3.3737],\n",
            "        [ 0.0995,  2.7655, -5.8223,  ..., -2.2130,  2.2406,  0.0282]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3968,  3.2015, -5.0206,  ..., -1.9365,  2.3812,  0.1446],\n",
            "        [ 5.6523,  0.9872,  6.7331,  ..., -2.9240,  2.6368,  3.0286],\n",
            "        [-1.1806,  1.7104,  3.8933,  ..., -0.2736,  4.1193,  1.9080],\n",
            "        ...,\n",
            "        [ 0.5469,  2.5989, -0.2136,  ..., -0.2778,  2.8516,  2.3104],\n",
            "        [ 5.3092,  2.5051, -0.3143,  ..., -2.3138,  1.0016,  2.3534],\n",
            "        [ 4.7702,  3.1422,  2.8283,  ...,  1.3816,  1.8724, -0.7755]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.0439e+00,  2.9791e+00,  1.3139e+00,  ...,  6.6442e-01,\n",
            "          3.9219e-01, -9.1821e-01],\n",
            "        [-2.8939e-01, -2.2703e-01,  7.2777e+00,  ..., -5.0813e+00,\n",
            "          2.1620e+00, -4.4803e-03],\n",
            "        [ 1.9649e+00,  1.4446e+00, -4.6424e+00,  ..., -1.4638e+00,\n",
            "          2.5184e+00, -1.5627e-01],\n",
            "        ...,\n",
            "        [ 2.3876e+00,  5.4598e-01, -6.6472e+00,  ...,  2.1041e+00,\n",
            "          6.1167e+00,  9.3455e-01],\n",
            "        [ 1.4263e+00, -7.0830e-01,  2.2603e+00,  ..., -2.7746e+00,\n",
            "          5.8740e+00, -1.0050e+00],\n",
            "        [ 1.0480e+00, -2.1107e+00,  7.1950e+00,  ..., -3.5432e-01,\n",
            "          4.7449e+00,  8.1601e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2710,  0.8287, -1.9266,  ..., -1.8934,  4.7772,  2.6902],\n",
            "        [ 2.3234,  2.6462,  5.1074,  ...,  3.7125,  3.9398,  1.6592],\n",
            "        [ 4.4595,  4.2248, -2.5416,  ..., -2.1795, -0.6260,  0.9930],\n",
            "        ...,\n",
            "        [ 2.8037, -0.0292, -3.9588,  ...,  0.7859,  3.1884, -0.5911],\n",
            "        [ 0.0058, -0.3792, -1.0116,  ...,  0.9285, -0.1265, -2.6883],\n",
            "        [ 1.3538,  2.2967,  4.1192,  ...,  2.4103,  5.5669,  2.6513]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7649,  3.4422, -5.4458,  ..., -2.0288,  2.9741,  1.7213],\n",
            "        [ 0.5481,  2.1801, -7.0645,  ..., -2.4914,  2.3177,  1.3663],\n",
            "        [ 4.3614,  2.4988, -3.1666,  ..., -1.1048,  3.0396,  1.0862],\n",
            "        ...,\n",
            "        [ 0.0915,  3.3147, -5.4227,  ..., -1.9006,  0.9640, -0.5944],\n",
            "        [ 1.8408,  2.8056, -3.4042,  ..., -0.4872, -1.0892,  0.5662],\n",
            "        [ 5.8401, -2.5385,  1.2777,  ...,  0.2790,  1.3969, -0.4046]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1667,  2.4854, -5.1665,  ..., -1.1134,  2.0571,  0.4538],\n",
            "        [ 6.9481, -0.8922, -0.3077,  ...,  0.7116,  2.0620, -0.5241],\n",
            "        [ 1.6084, -1.6865,  3.3119,  ..., -0.4246,  4.2741, -0.9235],\n",
            "        ...,\n",
            "        [ 2.1292,  0.9387,  2.3672,  ...,  2.0520,  2.3670,  0.6102],\n",
            "        [ 1.7863,  0.1528, -0.1498,  ..., -1.7020, -1.5403, -1.0544],\n",
            "        [ 0.5795,  0.6344, -2.5228,  ..., -0.7523,  3.1054, -1.6166]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2450,  2.5133, -1.6197,  ...,  2.3471,  1.9480, -0.0339],\n",
            "        [ 0.0952,  2.7622, -2.8836,  ..., -1.1025,  0.7209, -2.8351],\n",
            "        [ 0.9631,  2.9342, -4.7238,  ...,  0.7184,  2.8319,  0.2037],\n",
            "        ...,\n",
            "        [ 3.2420,  3.2386, -5.3402,  ...,  0.2714, -0.5348, -0.1316],\n",
            "        [ 2.2573, -0.7081, -3.2112,  ..., -0.4419,  5.0417,  3.3101],\n",
            "        [ 0.7657,  1.6982,  1.7745,  ..., -1.0491,  4.0099,  1.0841]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9123,  0.4221,  2.3845,  ..., -1.4605,  1.5298,  1.9729],\n",
            "        [ 2.7402, -0.3897,  5.3034,  ..., -3.5237,  0.6666,  2.4602],\n",
            "        [ 0.8692,  1.8558, -3.6767,  ..., -0.0896,  0.0859,  0.8846],\n",
            "        ...,\n",
            "        [-0.2642,  2.4274, -3.6693,  ..., -0.5933,  0.7265, -0.9820],\n",
            "        [ 3.0165, -1.5426,  0.6219,  ..., -0.0362,  4.4737,  0.8982],\n",
            "        [ 0.1704,  3.8150, -2.3167,  ...,  3.5118,  6.1195,  1.7743]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5195,  1.0566,  4.5937,  ..., -0.8038,  5.9911,  3.7820],\n",
            "        [-0.3330,  4.2492, -1.6915,  ...,  4.4319,  3.9976,  2.0785],\n",
            "        [ 0.8101, -0.0315, -0.9564,  ...,  1.4610,  0.7071, -2.6199],\n",
            "        ...,\n",
            "        [ 3.1731,  1.4125, -4.5319,  ..., -1.0266,  1.0711,  0.1807],\n",
            "        [ 3.8659,  2.1028,  0.8156,  ..., -1.5526,  0.0323,  4.5010],\n",
            "        [ 0.7223,  1.5343, -6.0301,  ...,  1.6492,  3.7515,  0.8669]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7738,  4.4340, -3.4517,  ..., -0.2713,  3.1567,  1.4245],\n",
            "        [-0.6743,  2.8482, -1.4188,  ...,  3.7184,  4.6268,  1.8059],\n",
            "        [-2.0544,  2.8745, -3.7338,  ...,  2.6820,  2.8325,  1.9348],\n",
            "        ...,\n",
            "        [ 0.6980,  5.4637, -1.0438,  ..., -0.3791,  2.4708,  3.7240],\n",
            "        [ 3.1481,  1.8498, -1.7424,  ...,  2.1815,  1.3707,  2.1544],\n",
            "        [ 0.3191,  0.9336, -6.8073,  ...,  1.3616,  3.4128,  1.4678]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8616,  2.6281, -1.4674,  ..., -2.4711,  0.0236,  1.1490],\n",
            "        [ 1.1002,  0.8594, -4.5481,  ..., -0.1771,  2.1863, -0.3179],\n",
            "        [ 1.5891,  1.7246, -4.2740,  ..., -0.6252,  2.2700,  2.4525],\n",
            "        ...,\n",
            "        [ 0.7822,  1.8950,  0.8760,  ...,  1.6042,  3.0280,  2.0876],\n",
            "        [ 3.9004, -1.7594,  7.9280,  ..., -6.8307,  1.9138,  0.1581],\n",
            "        [ 1.5370,  4.9279,  2.7705,  ..., -1.3768, -0.0958,  2.3208]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3910,  4.0886, -1.2431,  ..., -0.5124,  1.5898,  0.9467],\n",
            "        [ 1.9569,  4.1911,  0.7147,  ..., -2.2812,  0.1798,  0.9461],\n",
            "        [ 3.2153,  3.5848,  0.4285,  ...,  0.8799,  1.8037,  4.6560],\n",
            "        ...,\n",
            "        [ 3.3937,  4.2947, -7.2234,  ..., -0.4253,  4.1300,  3.9805],\n",
            "        [ 2.8053,  5.2676, -2.1301,  ..., -1.5146,  1.8312,  3.0965],\n",
            "        [ 2.4029, -0.8081,  0.3152,  ..., -1.1617,  3.3668,  1.0158]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2604,  3.1689, -3.9446,  ...,  2.0307,  3.4262,  1.1908],\n",
            "        [ 2.0327, -0.4762, -3.2716,  ...,  0.5726,  3.4257, -2.4633],\n",
            "        [-2.1153,  1.3480, -3.2060,  ..., -1.2042,  4.5731,  0.9294],\n",
            "        ...,\n",
            "        [ 1.0267,  3.4092, -4.3706,  ...,  4.6791,  3.9725,  2.4794],\n",
            "        [ 0.7451,  2.6249,  4.7854,  ...,  1.9520, -0.1245,  1.9320],\n",
            "        [-0.2126,  2.6666, -4.7491,  ..., -0.6732,  1.4085, -0.2667]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5433,  1.8572, -5.1494,  ...,  2.1820,  4.2794,  0.9915],\n",
            "        [-1.1464,  2.6154, -3.6080,  ..., -0.7814,  1.1769, -0.8909],\n",
            "        [ 0.5408,  2.3239, -5.0440,  ..., -2.0458,  1.6377,  0.7110],\n",
            "        ...,\n",
            "        [-0.5704,  2.9140, -0.7153,  ..., -0.5563,  2.3866, -0.1170],\n",
            "        [-0.3998,  2.6991, -3.5174,  ..., -1.7557,  1.2767,  0.1339],\n",
            "        [ 0.4162,  3.8955, -3.4622,  ..., -0.3468,  2.7458,  2.8321]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9171,  4.3810, -5.6779,  ..., -2.1821,  2.5085,  3.2096],\n",
            "        [ 4.3371,  3.4324, -6.7773,  ..., -0.5137,  7.2922,  2.4067],\n",
            "        [ 0.6072,  1.7087, -4.1666,  ..., -1.1145,  2.5557,  0.9952],\n",
            "        ...,\n",
            "        [ 5.1644, -1.8539,  6.6546,  ..., -0.7428,  4.0930,  0.1624],\n",
            "        [ 1.5212,  4.0580, -8.9820,  ..., -0.5753,  0.4123,  4.2497],\n",
            "        [ 3.9387,  1.5232,  2.4613,  ..., -0.7011,  0.9171,  2.3939]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.1840,  1.4788, -3.3806,  ...,  0.7801,  5.2271,  2.8703],\n",
            "        [-0.4882,  3.8110,  0.4220,  ...,  3.8197,  3.2211,  0.4139],\n",
            "        [ 4.1369,  2.3918,  5.2630,  ..., -0.8961,  3.3445,  5.1538],\n",
            "        ...,\n",
            "        [ 2.0986,  0.8636, -3.7753,  ..., -0.3644,  4.5816,  2.5048],\n",
            "        [ 1.6286, -1.2076,  1.6731,  ...,  0.1245,  3.4213, -1.5687],\n",
            "        [-1.4743,  4.0437, -2.3083,  ...,  1.6330,  0.1808,  1.1478]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.0286, -0.2135,  3.2504,  ...,  0.5393,  0.8303, -0.0162],\n",
            "        [ 2.3551,  3.1281, -0.6587,  ...,  3.7993,  3.9653,  2.4805],\n",
            "        [-0.0951,  4.4554, -3.7602,  ..., -0.5264,  2.3916,  7.1533],\n",
            "        ...,\n",
            "        [ 0.3443,  0.4232,  2.9247,  ..., -2.6843,  3.5405,  0.3748],\n",
            "        [ 4.5644,  1.8740,  2.8741,  ..., -2.0591,  1.6974,  1.7901],\n",
            "        [ 2.5989,  6.9136,  0.2837,  ..., -2.9802,  1.0704,  6.7155]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2150, -0.1901, -0.4755,  ..., -0.7521,  3.3504, -0.5808],\n",
            "        [ 0.6872,  3.8144,  6.6386,  ...,  3.2539,  3.8417,  2.6797],\n",
            "        [-1.7048,  5.8603, -4.9983,  ..., -0.3347, -0.0748,  1.8623],\n",
            "        ...,\n",
            "        [ 0.5297,  3.5041, -6.7490,  ..., -2.6821,  2.4001,  1.2628],\n",
            "        [ 3.6957, -1.5156,  4.0586,  ..., -0.3690,  3.6380, -0.9731],\n",
            "        [ 0.6539,  4.1909, -3.2110,  ..., -1.5567,  0.9278,  2.0791]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4401,  2.0168,  5.4793,  ..., -0.2312,  3.6254,  3.6688],\n",
            "        [-0.1444,  3.4354, -7.3040,  ..., -1.6425,  2.2107,  1.4791],\n",
            "        [ 1.3971,  3.3145, -5.5257,  ..., -1.7089,  4.1266,  1.8917],\n",
            "        ...,\n",
            "        [ 5.2661,  4.3566,  1.6928,  ..., -3.8254,  1.9726,  5.3954],\n",
            "        [ 2.2916,  1.8200,  6.9560,  ..., -1.6881,  1.5297,  3.7662],\n",
            "        [ 3.1465,  0.9101, -6.6324,  ...,  0.9092,  3.4407,  1.4393]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2035,  4.0639, -4.7986,  ..., -3.0636,  3.3594,  1.3516],\n",
            "        [ 0.5881,  0.1272, -1.0709,  ...,  2.3268,  2.8437, -1.9854],\n",
            "        [ 0.6116,  0.7772, -1.2446,  ...,  0.9262,  2.5069, -1.3460],\n",
            "        ...,\n",
            "        [ 1.2504,  0.0496,  4.4963,  ...,  0.4945,  3.2960,  2.4357],\n",
            "        [ 0.7517,  3.0736, -1.6075,  ...,  4.0765,  3.7645,  1.8378],\n",
            "        [ 0.6656, -1.8436,  0.7640,  ..., -0.1552,  4.4713, -4.8055]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4988e+00,  2.4320e+00, -1.2235e+00,  ...,  2.7865e+00,\n",
            "          1.9277e+00, -5.8571e-01],\n",
            "        [-1.0098e+00,  3.0900e+00, -4.7401e+00,  ...,  3.0569e+00,\n",
            "          3.3876e+00,  9.4061e-01],\n",
            "        [-6.7031e-01,  3.8635e-02, -2.2011e+00,  ...,  2.5884e+00,\n",
            "          8.8326e-01, -1.6278e+00],\n",
            "        ...,\n",
            "        [ 9.5976e-01, -1.3158e+00, -3.0118e+00,  ..., -2.2691e+00,\n",
            "          5.9477e+00,  2.2302e-01],\n",
            "        [-1.1513e-01,  1.4991e+00, -2.2096e+00,  ...,  1.5830e+00,\n",
            "          2.2524e+00, -3.3603e-01],\n",
            "        [-4.3050e-01,  4.4128e+00, -7.4161e+00,  ...,  1.0479e+00,\n",
            "          3.8409e+00, -7.0002e-03]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2885,  0.9085, -3.4403,  ..., -0.5252,  0.5368, -1.2573],\n",
            "        [-0.1473, -0.0611, -2.0894,  ...,  2.8438,  0.9650, -2.4195],\n",
            "        [-1.7010,  3.4122,  1.3227,  ...,  3.6540,  4.9632,  2.5826],\n",
            "        ...,\n",
            "        [-1.8551,  4.0907, -4.8425,  ...,  2.2137,  3.6978,  2.2290],\n",
            "        [ 0.3662,  3.5713,  5.9967,  ...,  3.2906,  4.8278,  1.7892],\n",
            "        [ 1.5532,  2.7634,  4.0908,  ..., -4.5321,  1.3886,  1.9543]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5348,  2.6080,  0.7887,  ..., -2.3084,  0.9967,  3.2540],\n",
            "        [ 7.2024, -0.5464,  2.3933,  ...,  0.5678,  1.7234,  1.2122],\n",
            "        [ 1.7942,  1.0335, -4.9035,  ...,  1.1063,  3.2245, -1.3842],\n",
            "        ...,\n",
            "        [ 1.5901, -2.2862,  3.0915,  ..., -2.1847,  1.4973,  1.1446],\n",
            "        [ 6.5350,  1.1083,  3.4566,  ...,  2.3614,  3.0333,  2.6440],\n",
            "        [ 0.2481,  0.4290,  2.4400,  ...,  0.5879,  3.6386, -3.3091]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4193,  4.2103,  0.5201,  ..., -1.5089,  1.3396, -1.5407],\n",
            "        [ 1.5626,  4.5346, -7.2482,  ..., -0.5799,  0.8940,  1.8375],\n",
            "        [ 4.1295, -2.3096,  7.2242,  ..., -5.4134,  1.8718,  0.0975],\n",
            "        ...,\n",
            "        [-4.2143,  3.5888, -3.8158,  ...,  2.5787,  7.0001,  2.7149],\n",
            "        [ 2.3431, -0.9927, -4.2487,  ...,  1.0232,  7.3460,  1.6136],\n",
            "        [ 3.4503,  1.4317,  0.3717,  ...,  2.2321,  1.2952, -2.3684]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6803,  5.5929, -1.2713,  ...,  0.4413,  2.5078,  4.8737],\n",
            "        [ 1.4683,  0.7902, -0.8756,  ...,  0.8239,  5.8780,  1.8747],\n",
            "        [ 3.4855,  2.2632, -1.3741,  ..., -1.4826,  4.4824,  3.0889],\n",
            "        ...,\n",
            "        [ 0.5783, -0.6432,  3.6381,  ...,  2.6412,  0.8022, -0.0589],\n",
            "        [ 4.1973,  3.0862, -1.3658,  ..., -0.8149,  5.5474,  0.1023],\n",
            "        [ 0.3654,  1.3158, -4.0860,  ..., -0.1587,  0.7236, -3.0264]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3157,  2.8772,  3.5954,  ...,  0.1709,  2.4074, -0.9262],\n",
            "        [-0.7537,  3.8450, -2.4932,  ..., -0.1739,  4.5972,  2.4801],\n",
            "        [-0.5688,  1.9182,  0.3287,  ...,  1.7489,  6.1533,  2.1964],\n",
            "        ...,\n",
            "        [-0.4873,  1.9899, -3.3133,  ...,  0.0722,  0.7184, -2.7094],\n",
            "        [ 0.4136,  2.2539,  1.9324,  ...,  0.2331,  2.8488,  0.3861],\n",
            "        [-1.8801, -1.2928,  2.0132,  ..., -1.0080,  3.1112, -2.2392]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1615,  0.0877,  7.2325,  ..., -1.2480,  4.6344,  1.9434],\n",
            "        [ 0.6782,  0.8899, -0.4892,  ..., -1.1295,  1.7765, -2.3864],\n",
            "        [-2.9977,  7.6119, -1.0628,  ..., -1.0807,  1.6913,  2.5987],\n",
            "        ...,\n",
            "        [-1.0774, -2.1394,  5.5721,  ...,  0.0756,  4.0161,  0.9448],\n",
            "        [ 4.9290,  1.8635, -6.9715,  ..., -0.4203,  0.3975,  2.9773],\n",
            "        [ 0.0996,  2.0001, -4.8268,  ...,  0.9308,  1.8545, -2.4688]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2152,  4.0565, -1.6121,  ...,  0.0829,  3.2744, -0.0876],\n",
            "        [ 2.0111,  4.4799, -2.7885,  ..., -2.9684,  0.5206, -0.2890],\n",
            "        [ 1.7376,  0.9836, -2.6086,  ...,  2.2370,  3.5127, -0.4181],\n",
            "        ...,\n",
            "        [ 1.9771,  3.2841, -2.7741,  ..., -0.8826,  4.5576,  4.2466],\n",
            "        [ 3.6636,  2.5109, -1.9026,  ..., -0.2152,  6.5237,  1.5256],\n",
            "        [ 1.5581, -1.1438,  1.3268,  ...,  1.3365,  3.6097, -0.3313]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.7002,  2.6909, -1.8510,  ..., -1.5207,  2.9505,  2.6565],\n",
            "        [-0.3368,  2.2872, -2.0686,  ..., -0.8409,  3.3950,  2.5817],\n",
            "        [ 4.2010,  2.1997, -6.4390,  ...,  0.2154,  3.0803,  1.9492],\n",
            "        ...,\n",
            "        [ 2.3149,  0.5455,  2.3642,  ...,  2.1827,  1.6671, -3.6280],\n",
            "        [ 2.2645,  5.1656, -2.7689,  ..., -1.6941, -1.9862,  4.1220],\n",
            "        [ 1.2349, -0.7299, -3.2304,  ...,  2.4555,  9.1181,  1.7485]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3117, -1.4495,  0.2711,  ..., -1.2284,  2.8355, -1.7777],\n",
            "        [ 0.2353,  1.2777,  2.7294,  ...,  0.4535,  1.5719, -0.6591],\n",
            "        [-1.5341,  2.7191, -0.8411,  ...,  5.1536,  2.9807,  1.2467],\n",
            "        ...,\n",
            "        [-1.3455,  6.8333,  1.2812,  ...,  0.2490,  3.2068,  4.4044],\n",
            "        [ 1.4859, -1.3024, -2.1385,  ...,  0.7157,  5.9062, -1.6693],\n",
            "        [ 1.5099,  3.5690, -4.0364,  ..., -2.1479,  3.5344,  1.6806]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6939,  3.4833, -2.6303,  ...,  3.4258,  2.1258,  0.8477],\n",
            "        [-1.5345,  2.4301, 10.8597,  ..., -1.1915,  2.5563,  1.3358],\n",
            "        [ 4.0831,  3.1197,  0.6704,  ..., -2.0752,  2.7282, -0.5103],\n",
            "        ...,\n",
            "        [ 0.9731,  4.9471, -0.2467,  ..., -0.6296,  2.0284,  0.4808],\n",
            "        [ 2.8375,  0.8472, -0.6508,  ..., -0.1382,  2.7195,  1.7384],\n",
            "        [ 1.6486,  6.1474, -2.8943,  ...,  0.3532,  2.4331,  4.7575]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9058, -0.9063,  6.6469,  ..., -3.6640,  4.3071, -0.2688],\n",
            "        [ 0.6796,  2.5450, -2.6836,  ...,  1.7790,  3.2642,  1.9352],\n",
            "        [-0.2889, -0.1440, -1.0761,  ...,  2.6816,  2.1295, -4.6199],\n",
            "        ...,\n",
            "        [ 5.4096,  2.4338,  1.1685,  ..., -3.0033, -0.9338, -0.3311],\n",
            "        [ 1.2214,  3.0882,  5.9744,  ..., -4.4116,  1.6658,  0.6471],\n",
            "        [-0.4570,  3.5319, -3.9234,  ...,  1.6555,  2.8383,  0.9217]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6466,  0.5666, -0.8313,  ..., -1.1367,  1.0881,  0.0398],\n",
            "        [ 3.4067,  2.2612,  2.7377,  ..., -0.5950,  0.8534,  0.7311],\n",
            "        [ 0.5163,  1.8252,  2.9776,  ..., -3.4639,  0.7637, -1.0398],\n",
            "        ...,\n",
            "        [ 4.8426,  0.8747,  5.4654,  ...,  0.6270,  2.2580,  2.8007],\n",
            "        [-0.6861,  1.5691,  5.0223,  ...,  1.5877,  4.7114,  1.2558],\n",
            "        [ 1.5049,  0.9072, -1.1572,  ...,  4.5425,  6.1758,  1.3009]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3510,  5.5595, -1.0309,  ..., -1.8665,  0.3687,  2.7497],\n",
            "        [ 2.2154,  0.0512,  0.7228,  ...,  1.3347,  5.3133,  0.5679],\n",
            "        [ 4.6860,  4.4562,  0.1400,  ..., -2.9153,  1.9115,  1.1359],\n",
            "        ...,\n",
            "        [ 0.1106,  4.0439, -3.9235,  ...,  0.8439,  3.6694,  3.5637],\n",
            "        [ 2.3503,  5.0291,  0.6764,  ..., -1.7067,  2.5325,  2.2692],\n",
            "        [ 2.4461,  1.6939, -3.9030,  ..., -1.0939,  2.6413, -0.5467]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0884,  0.0341, -0.4692,  ...,  1.2987,  6.4351,  2.4840],\n",
            "        [ 1.1032,  2.6075, -0.1291,  ...,  0.3511,  4.8882,  6.4362],\n",
            "        [-0.5036,  0.5828,  1.2583,  ..., -1.5331,  1.5075, -0.1568],\n",
            "        ...,\n",
            "        [ 0.7404,  0.9113, -5.5109,  ...,  0.3606,  3.9301,  3.2820],\n",
            "        [-1.9748,  3.6467, -0.2577,  ...,  2.6705,  5.1746,  3.2851],\n",
            "        [ 3.5930,  4.4300, -1.2085,  ..., -2.8379,  4.8973,  2.6878]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1138, -1.2551,  3.3638,  ..., -0.8160,  4.6359, -1.5211],\n",
            "        [-1.5714,  0.2627,  6.1460,  ..., -1.9903,  7.3236,  2.1713],\n",
            "        [ 1.7189,  0.0392, -4.8075,  ...,  1.7651,  3.4555,  0.4038],\n",
            "        ...,\n",
            "        [-2.1961,  2.3558, -2.5756,  ..., -0.9742,  1.5884,  0.1735],\n",
            "        [ 1.0026,  1.3636,  1.6432,  ...,  0.5903,  1.3653,  0.5598],\n",
            "        [ 3.0294,  3.4324,  2.8289,  ...,  1.7359,  2.3686,  4.3917]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3389,  0.8070, -2.2147,  ...,  1.2087,  0.3886, -1.8690],\n",
            "        [ 1.6050, -1.5263,  0.4984,  ..., -1.7797,  2.4176, -1.6902],\n",
            "        [-0.5453,  2.3049, -2.8999,  ..., -0.6957,  0.5102, -0.8090],\n",
            "        ...,\n",
            "        [ 5.1240,  1.8673, -1.7311,  ...,  0.3951,  6.0915,  1.6943],\n",
            "        [ 4.2391, -1.0966,  2.8022,  ...,  1.4379,  1.8420, -0.4208],\n",
            "        [-0.4570,  1.5513, -4.9705,  ...,  3.0061,  4.3356,  2.0556]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0620,  5.2544, -4.7103,  ...,  0.6291,  1.2261,  0.8575],\n",
            "        [-0.4405,  3.1559,  2.1653,  ..., -0.1872,  2.0717, -1.8289],\n",
            "        [ 5.1249, -1.2393, -0.5947,  ...,  2.4698,  1.2847, -0.2334],\n",
            "        ...,\n",
            "        [ 3.3727,  1.3653, -5.6685,  ...,  0.4192,  5.8075,  2.6702],\n",
            "        [ 0.4095,  3.4238, -0.0275,  ..., -0.8502,  1.2949, -0.5206],\n",
            "        [ 2.5911, -2.0285,  0.3751,  ...,  0.9042,  2.4454, -2.3910]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8631e+00,  8.1661e-01,  8.5585e+00,  ..., -3.2705e+00,\n",
            "          2.6166e+00,  1.8909e+00],\n",
            "        [ 1.6618e+00,  2.8568e+00, -2.1713e+00,  ..., -1.7885e+00,\n",
            "          7.2340e-01, -7.3839e-01],\n",
            "        [-8.0977e-02,  3.4269e-01, -7.5469e-01,  ...,  2.3631e+00,\n",
            "          1.3278e+00, -3.7371e+00],\n",
            "        ...,\n",
            "        [ 2.8708e+00,  2.2221e+00, -9.8472e+00,  ..., -1.2049e+00,\n",
            "          4.8138e+00,  2.8387e+00],\n",
            "        [ 7.9925e-01,  3.6931e+00, -2.6203e+00,  ..., -3.9215e-01,\n",
            "          1.0650e-01, -6.3869e-03],\n",
            "        [ 2.0347e+00, -9.1936e-01, -2.6208e+00,  ...,  1.8638e+00,\n",
            "          2.8950e+00,  4.2028e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9547, -0.0107, -0.6491,  ...,  0.8592,  0.8900, -2.4497],\n",
            "        [-2.4614,  3.7491, -4.1984,  ...,  1.7577,  3.8453,  2.2194],\n",
            "        [ 3.4100,  0.5045, -5.2070,  ...,  2.2174,  1.9419, -1.2868],\n",
            "        ...,\n",
            "        [ 1.0853,  0.3487, -3.1160,  ..., -0.6375,  1.9598, -1.6855],\n",
            "        [ 0.2401,  1.5776, -7.5069,  ...,  1.7482,  2.8003,  3.0462],\n",
            "        [ 4.0151,  0.5069,  0.1468,  ..., -0.8210,  4.2213,  0.4683]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6916,  6.3454, -1.6571,  ..., -0.5058,  0.7217,  3.3741],\n",
            "        [-1.5033, -0.0587,  2.1907,  ..., -2.3518,  4.1650, -2.0534],\n",
            "        [ 0.3893,  3.3610, -5.6041,  ..., -2.9861,  6.6800,  2.3192],\n",
            "        ...,\n",
            "        [ 1.8324, -0.0675, -4.8844,  ..., -0.5389,  5.2490,  1.0730],\n",
            "        [ 0.5706,  3.8950, -1.3317,  ...,  0.7168,  2.5221,  3.3244],\n",
            "        [ 5.4052,  2.2933,  4.0073,  ..., -3.6411,  1.0924,  5.1643]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3922,  4.0104,  0.6886,  ...,  1.0434,  2.5115,  3.5091],\n",
            "        [-1.9224,  2.5541, -6.2988,  ..., -0.2814,  1.8132, -0.8552],\n",
            "        [ 4.1878,  0.1352, 10.8331,  ..., -5.5623,  2.1558,  4.2632],\n",
            "        ...,\n",
            "        [ 7.6004,  2.5547,  3.8186,  ..., -5.2989, -3.1123, -1.7153],\n",
            "        [ 3.3952,  3.2547,  0.5102,  ..., -0.4200, -0.9457,  3.2704],\n",
            "        [ 3.8290,  1.0341,  3.6519,  ..., -1.4929,  0.7096, -0.4688]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9015,  3.6710, -5.8080,  ..., -2.1168,  4.1605,  3.6456],\n",
            "        [ 3.4695,  0.3026, -1.1892,  ..., -1.9427,  4.0023, -1.0244],\n",
            "        [-0.6915,  2.0018, -0.0838,  ...,  0.5041,  3.4788,  1.4205],\n",
            "        ...,\n",
            "        [ 0.8975,  0.9931, -7.1948,  ...,  0.9132,  4.6881,  1.9900],\n",
            "        [ 5.6635,  0.3853, -1.3262,  ...,  4.1026,  3.0131,  1.8802],\n",
            "        [ 2.9377,  0.9445,  6.4965,  ..., -5.0396,  0.4540,  1.0980]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6014,  0.5656,  1.6199,  ..., -0.9207,  2.4401, -6.2113],\n",
            "        [-1.5938,  5.0089,  6.3384,  ..., -0.5127,  0.5936, -2.0851],\n",
            "        [ 1.0427,  3.3535, -3.7993,  ..., -1.8623,  2.7940,  1.6031],\n",
            "        ...,\n",
            "        [ 4.5763,  0.2386, -0.1116,  ...,  0.9273,  0.3808, -1.3631],\n",
            "        [ 2.9357,  4.1122, -1.5294,  ..., -5.1666, -1.8402,  0.7061],\n",
            "        [ 0.7825,  0.9479,  4.5208,  ..., -0.0722,  3.4536,  2.1723]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3295,  2.3451, -1.6662,  ...,  0.8500,  2.8632,  2.6506],\n",
            "        [ 2.1242,  0.0327,  2.3165,  ...,  0.4155,  3.3457,  1.1467],\n",
            "        [ 2.3203,  0.6680,  2.9191,  ..., -0.3052,  1.8215,  3.1896],\n",
            "        ...,\n",
            "        [ 1.5932,  5.0075,  0.0816,  ...,  1.8533,  3.3224,  1.3170],\n",
            "        [ 1.9899, -0.2079,  0.3093,  ..., -2.1896,  3.3302,  1.2707],\n",
            "        [ 0.3840,  1.9173, -3.3264,  ..., -0.4510,  3.9262, -1.5402]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3101,  3.1186, -2.5114,  ...,  2.1405,  4.9529,  1.7943],\n",
            "        [ 4.2265,  4.5643,  0.8648,  ..., -2.2479, -2.9708,  2.8178],\n",
            "        [ 4.9409,  3.1395, -0.9317,  ..., -2.1688,  2.3102,  0.0169],\n",
            "        ...,\n",
            "        [-0.3529,  4.9730, -8.2216,  ..., -0.0418,  1.4859,  0.9790],\n",
            "        [ 3.4371, -0.1127, -2.3954,  ..., -0.3583,  2.1380, -2.6202],\n",
            "        [ 1.3579,  2.9126, -5.0813,  ..., -1.4208,  4.7115,  2.3955]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3168, -1.2580,  6.1718,  ..., -0.1018,  1.7615,  0.0337],\n",
            "        [ 2.1244,  3.4014, -3.2293,  ..., -0.5017,  3.6602,  2.8743],\n",
            "        [ 3.6816,  0.8706,  1.8968,  ...,  0.0635,  1.8222, -2.1410],\n",
            "        ...,\n",
            "        [-2.5879,  2.9568,  0.8356,  ...,  2.6130,  2.1598,  2.3839],\n",
            "        [-0.5489,  1.4560, -2.3236,  ..., -0.2506,  0.8512, -3.2196],\n",
            "        [ 3.4778, -0.0147, -3.7823,  ...,  1.1835,  5.9220,  1.9180]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5237, -0.7283,  3.5229,  ..., -3.4447,  0.3430, -0.1822],\n",
            "        [-1.8501,  5.2018, -7.6540,  ..., -1.5264, -0.4910,  3.2714],\n",
            "        [ 3.8938,  0.5801,  8.5136,  ..., -2.8942,  1.5160,  4.0363],\n",
            "        ...,\n",
            "        [ 2.2237,  2.6870,  3.0783,  ..., -1.1128, -0.9935,  0.2810],\n",
            "        [ 2.9779,  1.1257, -1.7229,  ...,  0.9179,  4.6587,  1.6477],\n",
            "        [-2.5036,  0.7719,  1.4049,  ..., -0.2469,  0.8669, -1.1401]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5800, -1.6945,  6.4401,  ..., -1.0128,  4.4583,  1.0827],\n",
            "        [ 3.1457,  0.0762,  3.0824,  ..., -1.8300,  1.7136, -1.3297],\n",
            "        [ 2.3442,  1.0328, -2.3825,  ...,  2.1133,  5.4727,  1.5298],\n",
            "        ...,\n",
            "        [ 2.0815,  1.1528, -7.3921,  ...,  1.6394,  1.4229,  0.2657],\n",
            "        [ 1.0564,  0.6151, -0.0685,  ..., -0.8572,  2.1098, -0.2497],\n",
            "        [ 0.0090,  2.3422, -0.3960,  ..., -2.3764,  5.6254, -0.4866]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1869, -0.0345,  1.7778,  ..., -1.3474,  2.4112, -2.6433],\n",
            "        [ 1.4131,  1.3060,  4.8183,  ..., -4.3517,  0.3607,  0.3417],\n",
            "        [ 1.1507,  3.6901,  1.2821,  ...,  0.2751,  0.6313, -0.2971],\n",
            "        ...,\n",
            "        [ 2.5240,  1.7214,  0.9147,  ...,  1.2375,  2.7450,  0.9342],\n",
            "        [-0.1513,  5.7772,  3.7860,  ..., -1.2313,  4.4886,  7.5098],\n",
            "        [ 0.7594,  2.5211, -5.3803,  ..., -3.0671,  1.7398,  0.7244]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5094,  4.0357, -2.4524,  ..., -1.0588,  1.0422,  1.8207],\n",
            "        [ 2.8287,  1.3882, -0.9471,  ..., -2.8020,  2.4578, -0.1441],\n",
            "        [ 3.1837,  3.8434, -0.2820,  ..., -0.8197,  4.0247,  1.2125],\n",
            "        ...,\n",
            "        [ 1.0150, -0.4706, -2.6701,  ...,  0.1183,  0.7496, -2.8189],\n",
            "        [ 0.9986, -0.0226,  5.1729,  ...,  0.3570,  2.5689, -0.9637],\n",
            "        [ 0.1082,  2.3402, -2.1101,  ...,  3.3716,  3.2328,  0.3589]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2344,  2.2445, -0.5690,  ...,  2.1857,  2.3111,  0.6748],\n",
            "        [ 0.4910,  3.4744,  1.1420,  ...,  0.5753,  2.1694, -1.9619],\n",
            "        [ 4.3222,  2.1823,  1.1882,  ...,  2.2826,  0.6711, -1.5697],\n",
            "        ...,\n",
            "        [ 1.0384,  3.2110, -7.7352,  ..., -1.1839,  3.0727,  0.8748],\n",
            "        [ 0.3105,  3.8140,  2.2175,  ..., -1.2282,  0.9157, -0.1474],\n",
            "        [ 1.9821, -0.5471,  0.5665,  ..., -1.7481,  2.5510, -1.9114]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8481,  2.1516, -2.3215,  ..., -0.2900,  1.7696, -0.4824],\n",
            "        [-0.9408,  4.1756,  1.3402,  ...,  3.1295,  2.7769,  1.3602],\n",
            "        [ 2.5760,  1.1565,  9.5445,  ..., -0.2339,  3.2838,  3.1839],\n",
            "        ...,\n",
            "        [ 6.0287,  1.5621,  5.8520,  ..., -0.8599,  0.7745,  0.4619],\n",
            "        [ 0.9112, -4.3272,  3.6702,  ...,  0.5313,  2.1441, -1.0592],\n",
            "        [ 0.6069,  0.2396,  7.5394,  ..., -1.6002,  2.0738,  1.6810]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class SimpleMLPTrainingArgs:\n",
        "    \"\"\"\n",
        "    Defining this class implicitly creates an __init__ method, which sets arguments as below, e.g. self.batch_size=64.\n",
        "    Any of these fields can also be overridden when you create an instance, e.g. SimpleMLPTrainingArgs(batch_size=128).\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 3\n",
        "    learning_rate: float = 1e-3\n",
        "\n",
        "\n",
        "def train(args: SimpleMLPTrainingArgs) -> tuple[list[float], SimpleMLP]:\n",
        "    \"\"\"\n",
        "    Trains & returns the model, using training parameters from the `args` object. Returns the model, and loss list.\n",
        "    \"\"\"\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    mnist_trainset, _ = get_mnist()\n",
        "    mnist_trainloader = DataLoader(mnist_trainset, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "    loss_list = []\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        pbar = tqdm(mnist_trainloader)\n",
        "\n",
        "        for imgs, labels in pbar:\n",
        "            # Move data to device, perform forward pass\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            # Calculate loss, perform backward pass\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update logs & progress bar\n",
        "            loss_list.append(loss.item())\n",
        "            pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")\n",
        "\n",
        "    return loss_list, model\n",
        "\n",
        "\n",
        "args = SimpleMLPTrainingArgs()\n",
        "loss_list, model = train(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ENfdZdxajBUO",
        "outputId": "ae775882-abb6-41c5-8d4a-48f8aac54db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d89a4b3f-b068-4ddf-bdf9-615f47265545\" class=\"plotly-graph-div\" style=\"height:525px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d89a4b3f-b068-4ddf-bdf9-615f47265545\")) {                    Plotly.newPlot(                        \"d89a4b3f-b068-4ddf-bdf9-615f47265545\",                        [{\"hovertemplate\":\"Examples seen=%{x}\\u003cbr\\u003eCross entropy loss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,63.829787234042556,127.65957446808511,191.48936170212767,255.31914893617022,319.1489361702128,382.97872340425533,446.8085106382979,510.63829787234044,574.468085106383,638.2978723404256,702.1276595744681,765.9574468085107,829.7872340425532,893.6170212765958,957.4468085106383,1021.2765957446809,1085.1063829787236,1148.936170212766,1212.7659574468084,1276.595744680851,1340.4255319148938,1404.2553191489362,1468.0851063829787,1531.9148936170213,1595.744680851064,1659.5744680851064,1723.404255319149,1787.2340425531916,1851.0638297872342,1914.8936170212767,1978.723404255319,2042.5531914893618,2106.3829787234044,2170.212765957447,2234.0425531914893,2297.872340425532,2361.7021276595747,2425.531914893617,2489.3617021276596,2553.191489361702,2617.021276595745,2680.8510638297876,2744.68085106383,2808.5106382978724,2872.340425531915,2936.1702127659573,3000.0,3063.8297872340427,3127.6595744680853,3191.489361702128,3255.31914893617,3319.148936170213,3382.9787234042556,3446.808510638298,3510.6382978723404,3574.468085106383,3638.297872340426,3702.1276595744685,3765.9574468085107,3829.7872340425533,3893.617021276596,3957.446808510638,4021.276595744681,4085.1063829787236,4148.936170212766,4212.765957446809,4276.595744680852,4340.425531914894,4404.255319148936,4468.085106382979,4531.914893617021,4595.744680851064,4659.574468085107,4723.404255319149,4787.234042553192,4851.063829787234,4914.893617021276,4978.723404255319,5042.553191489362,5106.382978723404,5170.212765957447,5234.04255319149,5297.8723404255325,5361.702127659575,5425.531914893617,5489.36170212766,5553.191489361702,5617.021276595745,5680.851063829788,5744.68085106383,5808.510638297873,5872.340425531915,5936.170212765957,6000.0,6063.829787234043,6127.659574468085,6191.489361702128,6255.319148936171,6319.148936170213,6382.978723404256,6446.808510638298,6510.63829787234,6574.468085106383,6638.297872340426,6702.127659574468,6765.957446808511,6829.787234042554,6893.617021276596,6957.446808510638,7021.276595744681,7085.106382978724,7148.936170212766,7212.765957446809,7276.595744680852,7340.425531914894,7404.255319148937,7468.085106382979,7531.914893617021,7595.744680851064,7659.574468085107,7723.404255319149,7787.234042553192,7851.063829787235,7914.893617021276,7978.723404255319,8042.553191489362,8106.382978723404,8170.212765957447,8234.04255319149,8297.872340425532,8361.702127659575,8425.531914893618,8489.36170212766,8553.191489361703,8617.021276595746,8680.851063829788,8744.68085106383,8808.510638297872,8872.340425531915,8936.170212765957,9000.0,9063.829787234043,9127.659574468085,9191.489361702128,9255.31914893617,9319.148936170213,9382.978723404256,9446.808510638299,9510.638297872341,9574.468085106384,9638.297872340427,9702.127659574468,9765.95744680851,9829.787234042553,9893.617021276596,9957.446808510638,10021.27659574468,10085.106382978724,10148.936170212766,10212.765957446809,10276.595744680852,10340.425531914894,10404.255319148937,10468.08510638298,10531.914893617022,10595.744680851065,10659.574468085108,10723.40425531915,10787.234042553191,10851.063829787234,10914.893617021276,10978.72340425532,11042.553191489362,11106.382978723404,11170.212765957447,11234.04255319149,11297.872340425532,11361.702127659575,11425.531914893618,11489.36170212766,11553.191489361703,11617.021276595746,11680.851063829788,11744.68085106383,11808.510638297872,11872.340425531915,11936.170212765957,12000.0,12063.829787234043,12127.659574468085,12191.489361702128,12255.31914893617,12319.148936170213,12382.978723404256,12446.808510638299,12510.638297872341,12574.468085106384,12638.297872340427,12702.12765957447,12765.957446808512,12829.787234042553,12893.617021276596,12957.446808510638,13021.27659574468,13085.106382978724,13148.936170212766,13212.765957446809,13276.595744680852,13340.425531914894,13404.255319148937,13468.08510638298,13531.914893617022,13595.744680851065,13659.574468085108,13723.40425531915,13787.234042553191,13851.063829787234,13914.893617021276,13978.72340425532,14042.553191489362,14106.382978723404,14170.212765957447,14234.04255319149,14297.872340425532,14361.702127659575,14425.531914893618,14489.36170212766,14553.191489361703,14617.021276595746,14680.851063829788,14744.680851063831,14808.510638297874,14872.340425531915,14936.170212765957,15000.0,15063.829787234043,15127.659574468085,15191.489361702128,15255.31914893617,15319.148936170213,15382.978723404256,15446.808510638299,15510.638297872341,15574.468085106384,15638.297872340427,15702.12765957447,15765.957446808512,15829.787234042553,15893.617021276596,15957.446808510638,16021.27659574468,16085.106382978724,16148.936170212766,16212.765957446809,16276.595744680852,16340.425531914894,16404.255319148935,16468.08510638298,16531.91489361702,16595.744680851065,16659.574468085106,16723.40425531915,16787.23404255319,16851.063829787236,16914.893617021276,16978.72340425532,17042.55319148936,17106.382978723406,17170.212765957447,17234.04255319149,17297.872340425532,17361.702127659577,17425.531914893618,17489.36170212766,17553.191489361703,17617.021276595744,17680.85106382979,17744.68085106383,17808.510638297874,17872.340425531915,17936.17021276596,18000.0,18063.829787234044,18127.659574468085,18191.48936170213,18255.31914893617,18319.148936170215,18382.978723404256,18446.808510638297,18510.63829787234,18574.468085106382,18638.297872340427,18702.127659574468,18765.957446808512,18829.787234042553,18893.617021276597,18957.44680851064,19021.276595744683,19085.106382978724,19148.936170212768,19212.76595744681,19276.595744680853,19340.425531914894,19404.255319148935,19468.08510638298,19531.91489361702,19595.744680851065,19659.574468085106,19723.40425531915,19787.23404255319,19851.063829787236,19914.893617021276,19978.72340425532,20042.55319148936,20106.382978723406,20170.212765957447,20234.04255319149,20297.872340425532,20361.702127659577,20425.531914893618,20489.36170212766,20553.191489361703,20617.021276595744,20680.85106382979,20744.68085106383,20808.510638297874,20872.340425531915,20936.17021276596,21000.0,21063.829787234044,21127.659574468085,21191.48936170213,21255.31914893617,21319.148936170215,21382.978723404256,21446.8085106383,21510.63829787234,21574.468085106382,21638.297872340427,21702.127659574468,21765.957446808512,21829.787234042553,21893.617021276597,21957.44680851064,22021.276595744683,22085.106382978724,22148.936170212768,22212.76595744681,22276.595744680853,22340.425531914894,22404.25531914894,22468.08510638298,22531.91489361702,22595.744680851065,22659.574468085106,22723.40425531915,22787.23404255319,22851.063829787236,22914.893617021276,22978.72340425532,23042.55319148936,23106.382978723406,23170.212765957447,23234.04255319149,23297.872340425532,23361.702127659577,23425.531914893618,23489.36170212766,23553.191489361703,23617.021276595744,23680.85106382979,23744.68085106383,23808.510638297874,23872.340425531915,23936.17021276596,24000.0,24063.829787234044,24127.659574468085,24191.48936170213,24255.31914893617,24319.148936170215,24382.978723404256,24446.8085106383,24510.63829787234,24574.468085106382,24638.297872340427,24702.127659574468,24765.957446808512,24829.787234042553,24893.617021276597,24957.44680851064,25021.276595744683,25085.106382978724,25148.936170212768,25212.76595744681,25276.595744680853,25340.425531914894,25404.25531914894,25468.08510638298,25531.914893617024,25595.744680851065,25659.574468085106,25723.40425531915,25787.23404255319,25851.063829787236,25914.893617021276,25978.72340425532,26042.55319148936,26106.382978723406,26170.212765957447,26234.04255319149,26297.872340425532,26361.702127659577,26425.531914893618,26489.361702127662,26553.191489361703,26617.021276595744,26680.85106382979,26744.68085106383,26808.510638297874,26872.340425531915,26936.17021276596,27000.0,27063.829787234044,27127.659574468085,27191.48936170213,27255.31914893617,27319.148936170215,27382.978723404256,27446.8085106383,27510.63829787234,27574.468085106382,27638.297872340427,27702.127659574468,27765.957446808512,27829.787234042553,27893.617021276597,27957.44680851064,28021.276595744683,28085.106382978724,28148.936170212768,28212.76595744681,28276.595744680853,28340.425531914894,28404.25531914894,28468.08510638298,28531.914893617024,28595.744680851065,28659.574468085106,28723.40425531915,28787.23404255319,28851.063829787236,28914.893617021276,28978.72340425532,29042.55319148936,29106.382978723406,29170.212765957447,29234.04255319149,29297.872340425532,29361.702127659577,29425.531914893618,29489.361702127662,29553.191489361703,29617.021276595748,29680.85106382979,29744.68085106383,29808.510638297874,29872.340425531915,29936.17021276596,30000.0],\"xaxis\":\"x\",\"y\":[3.1032543182373047,2.7213406562805176,2.2229537963867188,2.0663838386535645,1.7095547914505005,1.499592661857605,1.6778661012649536,1.3465027809143066,1.279482364654541,1.074128270149231,1.1868501901626587,1.0900846719741821,0.884526252746582,1.0505436658859253,1.0842427015304565,0.9007909297943115,0.8298368453979492,0.7549884915351868,0.8241145610809326,0.7957701086997986,0.8204542398452759,0.8181692957878113,0.6688032746315002,0.6581957936286926,0.5535356402397156,0.7471826076507568,0.6290754079818726,0.6973121762275696,0.8123438954353333,0.4433797299861908,0.6169153451919556,0.688088059425354,0.3942464590072632,0.45697543025016785,0.5627947449684143,0.462666392326355,0.5221489667892456,0.39415422081947327,0.38527408242225647,0.40362295508384705,0.44152194261550903,0.3244906961917877,0.43205198645591736,0.38751325011253357,0.4990580677986145,0.4622456729412079,0.5221684575080872,0.36356425285339355,0.4745957851409912,0.3143782615661621,0.3999261260032654,0.5864584445953369,0.5369013547897339,0.3219859004020691,0.5752769708633423,0.1951933652162552,0.2519623339176178,0.2939959466457367,0.3873428702354431,0.4708382189273834,0.4609636962413788,0.32375049591064453,0.3902147114276886,0.37977251410484314,0.4182579517364502,0.33696499466896057,0.4225686490535736,0.4848724901676178,0.5332513451576233,0.42758551239967346,0.21674729883670807,0.482854962348938,0.36737895011901855,0.3423888087272644,0.367073655128479,0.2880108058452606,0.38985854387283325,0.28892549872398376,0.31583890318870544,0.45996811985969543,0.33163344860076904,0.31646496057510376,0.45724397897720337,0.5809072852134705,0.41500791907310486,0.16501827538013458,0.37473952770233154,0.3237238824367523,0.15673482418060303,0.3467998802661896,0.3669384717941284,0.33968663215637207,0.42495617270469666,0.4033220410346985,0.402885764837265,0.5161744952201843,0.36526554822921753,0.4735087752342224,0.19421318173408508,0.2659985423088074,0.35652047395706177,0.3821069300174713,0.4767463505268097,0.31842923164367676,0.24969664216041565,0.21298475563526154,0.264102965593338,0.21841198205947876,0.34528374671936035,0.4560388922691345,0.3103543221950531,0.4389912188053131,0.5519638061523438,0.3622239828109741,0.4112636148929596,0.16983208060264587,0.3464869260787964,0.30954596400260925,0.4011099934577942,0.35526031255722046,0.20802035927772522,0.3063087463378906,0.23535065352916718,0.23169538378715515,0.32800403237342834,0.2985599637031555,0.4539142847061157,0.5161993503570557,0.5648731589317322,0.27073195576667786,0.435596764087677,0.4231448173522949,0.39287590980529785,0.2670932114124298,0.20972846448421478,0.24013546109199524,0.17923445999622345,0.2399364560842514,0.4004952311515808,0.31985142827033997,0.1840515285730362,0.30304110050201416,0.17256373167037964,0.23523153364658356,0.21418239176273346,0.224516361951828,0.2812141478061676,0.24686673283576965,0.29840755462646484,0.4117816984653473,0.27789127826690674,0.21890203654766083,0.2859761118888855,0.3463071286678314,0.305440217256546,0.4243519604206085,0.25740209221839905,0.24022933840751648,0.2589188516139984,0.2521391808986664,0.3380565345287323,0.20871517062187195,0.2309914082288742,0.28773531317710876,0.22352170944213867,0.2919687032699585,0.30538812279701233,0.2818242609500885,0.295733779668808,0.19314534962177277,0.34091514348983765,0.3444593548774719,0.24151642620563507,0.3297664225101471,0.17046907544136047,0.23741303384304047,0.18194852769374847,0.3029310703277588,0.30657944083213806,0.19335152208805084,0.36109355092048645,0.25020381808280945,0.30525490641593933,0.2582242488861084,0.13239337503910065,0.30941852927207947,0.19689972698688507,0.2811618447303772,0.31120309233665466,0.19701817631721497,0.28982916474342346,0.3530791699886322,0.21793197095394135,0.20255443453788757,0.2704538404941559,0.23189786076545715,0.2668220102787018,0.33250918984413147,0.32676583528518677,0.3565242886543274,0.18203875422477722,0.09471984207630157,0.1232951357960701,0.09733082354068756,0.11131270229816437,0.20038725435733795,0.5124830007553101,0.08323661237955093,0.28569310903549194,0.19131745398044586,0.15307043492794037,0.25226595997810364,0.13429021835327148,0.13044464588165283,0.19640424847602844,0.20549534261226654,0.11961434781551361,0.1874302178621292,0.17902520298957825,0.29345738887786865,0.2658649981021881,0.1319933384656906,0.16057410836219788,0.2329588085412979,0.173606276512146,0.0936606302857399,0.1551836133003235,0.17406687140464783,0.5299307703971863,0.12329846620559692,0.20990799367427826,0.2746603786945343,0.3383244574069977,0.19624732434749603,0.2779865860939026,0.3992617428302765,0.42899197340011597,0.23675952851772308,0.41158244013786316,0.1849384903907776,0.27875494956970215,0.19446656107902527,0.18858258426189423,0.08118169754743576,0.08202113956212997,0.19382259249687195,0.18789130449295044,0.1928562968969345,0.1483127772808075,0.26348719000816345,0.24681492149829865,0.38125717639923096,0.06419449299573898,0.14543971419334412,0.20480719208717346,0.12890489399433136,0.20372232794761658,0.20027042925357819,0.2878164052963257,0.20746833086013794,0.19698676466941833,0.16981397569179535,0.24608318507671356,0.25610989332199097,0.13503222167491913,0.24436049163341522,0.11336088180541992,0.22385218739509583,0.28016141057014465,0.2584996223449707,0.19883795082569122,0.18688848614692688,0.5552933216094971,0.249529168009758,0.0945250391960144,0.265377014875412,0.1794263869524002,0.36126425862312317,0.27539101243019104,0.10675424337387085,0.18706247210502625,0.1286672055721283,0.1152128204703331,0.29374927282333374,0.12517228722572327,0.21953612565994263,0.21418318152427673,0.1156272366642952,0.1939825564622879,0.2221204936504364,0.37600886821746826,0.05387931317090988,0.22469209134578705,0.18551260232925415,0.23513460159301758,0.3584632873535156,0.19549429416656494,0.2229926437139511,0.22317522764205933,0.2408910095691681,0.17119815945625305,0.08730383217334747,0.28887757658958435,0.18201491236686707,0.08344583213329315,0.09608790278434753,0.22624316811561584,0.19583669304847717,0.21027635037899017,0.265199214220047,0.20724566280841827,0.20232105255126953,0.310685932636261,0.4420759677886963,0.13569045066833496,0.14634855091571808,0.13790324330329895,0.14299345016479492,0.17100897431373596,0.1608704924583435,0.2903802692890167,0.2633351981639862,0.0946538895368576,0.15933136641979218,0.1353936344385147,0.1457517445087433,0.0639980286359787,0.179703950881958,0.16749778389930725,0.15192130208015442,0.10036696493625641,0.15368717908859253,0.31539249420166016,0.1781431883573532,0.20915354788303375,0.22779326140880585,0.1512642204761505,0.17109468579292297,0.12169124186038971,0.21907293796539307,0.14563745260238647,0.09837706387042999,0.17263755202293396,0.116944320499897,0.4555778503417969,0.0674053281545639,0.08622446656227112,0.11456383019685745,0.1184908002614975,0.09241030365228653,0.18025830388069153,0.13911113142967224,0.1573880910873413,0.23839396238327026,0.15821129083633423,0.29494085907936096,0.09627685695886612,0.10580405592918396,0.21690446138381958,0.2556679844856262,0.12770690023899078,0.1500694453716278,0.18881195783615112,0.14795662462711334,0.05694568157196045,0.17295168340206146,0.1922413408756256,0.06800638884305954,0.24036681652069092,0.11646145582199097,0.0989299789071083,0.1477600336074829,0.16476565599441528,0.10103923827409744,0.2096146047115326,0.09105486422777176,0.12860500812530518,0.18434056639671326,0.1685909777879715,0.1600862294435501,0.12541410326957703,0.22675378620624542,0.1350872665643692,0.2524924874305725,0.11401139199733734,0.21178367733955383,0.07153531908988953,0.19555577635765076,0.08676742017269135,0.1677868366241455,0.21962212026119232,0.1268380582332611,0.18858841061592102,0.12340430915355682,0.12622292339801788,0.10558179765939713,0.12621834874153137,0.11328568309545517,0.1740393042564392,0.10602035373449326,0.08180799335241318,0.17531216144561768,0.145122230052948,0.11783243715763092,0.23922234773635864,0.22587332129478455,0.09148496389389038,0.29002487659454346,0.06447504460811615,0.21535710990428925,0.14498063921928406,0.21607600152492523,0.16253499686717987,0.2021186202764511,0.15555012226104736,0.10245911031961441,0.14126689732074738,0.212825745344162,0.16592812538146973,0.08294562250375748,0.09298872947692871,0.11905588209629059,0.16706642508506775,0.19561874866485596,0.2503330409526825,0.12098841369152069,0.17419378459453583,0.112810879945755,0.1281338334083557,0.1389886885881424,0.033547475934028625,0.1856403350830078,0.1668528914451599,0.08599451929330826,0.3201100528240204,0.2418554425239563,0.17241111397743225,0.18004366755485535,0.07002223283052444,0.2006012201309204,0.1543787568807602,0.20626768469810486,0.20680318772792816,0.13244223594665527,0.30235350131988525,0.14181432127952576,0.11717267334461212,0.1102805882692337,0.12223035097122192,0.11909157782793045,0.18318019807338715,0.12425663322210312,0.19768446683883667,0.21578186750411987,0.17170830070972443,0.16671350598335266,0.12227040529251099,0.08276642858982086,0.18034552037715912,0.1339545100927353,0.08961209654808044,0.20975053310394287,0.0773339569568634,0.061809640377759933,0.05121920630335808,0.06865334510803223,0.07786433398723602,0.08328687399625778,0.0474558062851429,0.13016699254512787,0.03575565293431282],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Examples seen\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Cross entropy loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"SimpleMLP training on MNIST\"},\"width\":700,\"hovermode\":\"x unified\"},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d89a4b3f-b068-4ddf-bdf9-615f47265545');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "line(\n",
        "    loss_list,\n",
        "    x_max=args.epochs * len(mnist_trainset),\n",
        "    labels={\"x\": \"Examples seen\", \"y\": \"Cross entropy loss\"},\n",
        "    title=\"SimpleMLP training on MNIST\",\n",
        "    width=700,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_sh7yNCjBUO"
      },
      "source": [
        "### Exercise - add a validation loop\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵🔵\n",
        ">\n",
        "> You should spend up to ~20 minutes on this exercise.\n",
        "> It is very important that you understand training loops and how they work, because we'll be doing a lot of model training in this way.\n",
        "> ```\n",
        "\n",
        "Edit the `train` function above to include a validation loop. Train your model, making sure you measure the accuracy at the end of each epoch.\n",
        "\n",
        "Here are a few tips to help you:\n",
        "\n",
        "* You'll need a dataloader for the testset, just like we did for the trainset. It doesn't matter whether you shuffle the testset or not, because we're not updating our model parameters during validation (we usually set `shuffle=False` for testsets).\n",
        "    * You can set the same batch size as for your training set (we'll discuss more optimal choices for this later in the course).\n",
        "* During the validation step, you should be measuring **accuracy**, which is defined as **the fraction of correctly classified images**.\n",
        "    * Note that (unlike loss) accuracy should only be logged after you've gone through the whole validation set. This is because your model doesn't update between computing different accuracies, so it doesn't make sense to log all of them separately.\n",
        "    * Computing accuracy is meant to be a very short operation, so you shouldn't need a progress bar.\n",
        "    * You can wrap your forward pass in `with t.inference_mode():` to make sure that your model is in inference mode during validation (i.e. gradients don't propagate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3TpwzEitjBUO",
        "outputId": "46c54439-bb5e-4369-e405-9e3d36f616fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c23ee43448bc4b3795632b4dee165302",
            "838a2ec1340846fca940ebf64964945d",
            "53b14da794ce42cd8e367438909afc50",
            "b8d6c81e97014a07b416ee92f9bf3bcc",
            "3667b7c0416145c587436b66e7590973",
            "0d2b6a0bc4f0494b96bbaa5184dff26f",
            "e8815e16b99e4da1b91442440d6ed73a",
            "257943fbdda14b4cacd98a9424856957",
            "72a65f947be74d47a0a4037c89fe9be7",
            "e79861e2523f48a4854864f7ba56a77a",
            "2b19966922de452fa22d570bff7655a6",
            "9a05a100de8147dc8d79d5674471d56a",
            "fee95d8b6b624c3ba48ee9774af62fb7",
            "a5268be6cbf64ae697ee8dcb4564c5f9",
            "7d4406d7945346518a5ffdc34e78892a",
            "5a59fc9ed6f942eea842b73779980c15",
            "0d6e112eb4ee44b2a206f5ac75089375",
            "7d01e0804d7b427ca566c5ba36f801ae",
            "21669a2b3e48435690e0f02e730c3240",
            "8450d64dad8b404996396310d3c974a8",
            "3dee1564d340404b917f5d0d2f1c9b1f",
            "1857c0a48853423c9abe7967e8524e74",
            "973c21dc4e0747e5bcc05dde595187b4",
            "6e1a7c41f90b4af5b7e691f2e2749f6b",
            "988681b1f9d0496a85603ec32a65bf08",
            "b1c7025203a145c2b52f5de0de678f42",
            "53b0421d898e4a7384e878c332545106",
            "52ef5ae48a384e0593cf930f5f226701",
            "060cfda0dd944425bfd0a24fbc85bd6a",
            "333725bd217e40858aecd3d04b6730ba",
            "ad96b52b6f3946a69951e6274f25e11f",
            "aa67a2e13a444fb1930a07a6cc584b12",
            "85a657e77b714204ba91dc616d4a068b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c23ee43448bc4b3795632b4dee165302"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3381, -4.6947,  0.4501,  ..., -2.2102,  1.3639, -0.4003],\n",
            "        [-0.4881, -0.7222,  0.0213,  ...,  1.5145, -0.1270, -2.3732],\n",
            "        [ 1.3181, -0.2825,  0.9009,  ...,  1.0155, -0.1837,  1.5948],\n",
            "        ...,\n",
            "        [ 0.2129, -2.4482, -0.2054,  ...,  2.0343, -2.0881,  2.1264],\n",
            "        [ 0.5418, -0.7291,  0.9762,  ...,  1.2156,  0.4219,  1.3694],\n",
            "        [-1.3898, -1.0838, -0.8328,  ...,  1.3939, -0.9643,  0.3463]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1930, -3.4458,  0.9547,  ...,  0.6323, -1.0057,  0.3099],\n",
            "        [ 0.6342, -4.2828, -1.6294,  ..., -2.7255, -0.7928, -1.9043],\n",
            "        [ 0.4840, -3.7903, -1.0570,  ..., -1.5092, -0.2717,  1.3316],\n",
            "        ...,\n",
            "        [ 0.9305,  0.1798,  0.1582,  ...,  0.2869, -0.5144,  0.6869],\n",
            "        [-0.2498, -2.1854,  1.0148,  ..., -0.4117, -3.5667, -0.5907],\n",
            "        [ 0.9261, -1.1556, -0.0073,  ..., -0.2080, -1.1879,  1.0931]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4762,  0.0982,  0.7383,  ...,  0.5660, -0.2687,  1.5473],\n",
            "        [ 0.7660, -4.7448,  0.9119,  ..., -0.6156, -1.9476,  0.7148],\n",
            "        [ 0.7559, -2.9244, -0.6834,  ...,  0.8324, -0.2675,  0.7774],\n",
            "        ...,\n",
            "        [ 1.8356, -0.5537, -1.2962,  ...,  0.8414,  1.1929, -0.4890],\n",
            "        [-1.2372, -2.8595, -2.2476,  ..., -2.4000, -1.3380,  1.5846],\n",
            "        [ 0.5228, -1.3244, -1.3892,  ...,  0.6211,  0.7526, -0.5107]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5486, -0.0694,  1.0743,  ..., -0.9494,  0.4995, -0.5062],\n",
            "        [-2.0629, -2.5445, -2.7258,  ..., -1.3324,  0.3460, -0.4202],\n",
            "        [-0.0466, -1.2478,  0.2105,  ...,  0.3622, -2.2679,  2.6782],\n",
            "        ...,\n",
            "        [-1.4049,  0.0803, -1.1400,  ..., -1.1367,  0.4277, -1.6341],\n",
            "        [-0.8363, -1.7947,  0.9182,  ..., -1.4351, -1.8977,  1.3518],\n",
            "        [ 0.8890,  0.2110,  0.2963,  ...,  0.0999, -1.3474,  1.4281]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2957,  0.1520, -0.3885,  ..., -0.7829,  2.2150, -0.5053],\n",
            "        [-1.1584, -3.6005, -0.9083,  ..., -2.4585,  1.3907, -1.5273],\n",
            "        [ 1.2053,  1.6063,  0.0040,  ...,  0.7045, -0.0892,  2.0368],\n",
            "        ...,\n",
            "        [-0.0960, -1.6747,  0.0389,  ...,  0.0387, -1.5416,  1.8394],\n",
            "        [ 0.6099,  0.6932, -1.1038,  ...,  0.0187, -1.3898,  1.1459],\n",
            "        [ 0.8698, -0.7751,  0.2493,  ..., -1.9278,  0.2173,  1.1152]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3124,  1.3222, -1.7064,  ...,  0.1232,  0.8126, -1.0137],\n",
            "        [-0.0381, -0.4782, -0.1110,  ...,  0.1110, -0.2766, -2.6131],\n",
            "        [-0.6890, -2.1464,  0.0128,  ...,  0.2905, -2.4511,  2.3575],\n",
            "        ...,\n",
            "        [-0.9009,  0.3295, -0.6852,  ..., -0.3219, -0.1805, -3.1857],\n",
            "        [-0.8946, -0.5379, -0.2520,  ..., -1.4379,  2.2935,  0.1552],\n",
            "        [-2.3245, -2.3205, -4.4377,  ..., -3.8587,  0.0127, -0.2931]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1049, -1.5090, -2.9615,  ..., -0.5360, -0.3692, -0.4913],\n",
            "        [ 0.8617,  0.8220,  0.7967,  ..., -1.0643, -0.3450,  1.2532],\n",
            "        [ 0.0148, -0.3315, -2.3682,  ...,  0.6985, -0.5353, -2.1490],\n",
            "        ...,\n",
            "        [ 0.2615, -0.9219, -0.3592,  ..., -0.2009, -1.6325,  1.5226],\n",
            "        [-0.1263, -0.5054, -0.1457,  ..., -1.0184, -0.8509, -0.4605],\n",
            "        [-0.3705,  1.8847,  0.2415,  ..., -0.2070, -0.3019,  1.0618]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8120,  0.0875, -2.0012,  ..., -1.0989, -1.3484, -1.7859],\n",
            "        [ 0.3362, -0.9088, -0.9545,  ..., -1.5764,  0.0932,  2.2096],\n",
            "        [-0.7740, -3.4267, -1.0290,  ..., -0.2660,  0.4134, -0.6569],\n",
            "        ...,\n",
            "        [-0.7879,  1.4015, -0.5712,  ..., -0.5234,  1.5988, -0.0461],\n",
            "        [ 0.1123, -0.9547, -2.3397,  ..., -1.5545,  3.9744,  2.2968],\n",
            "        [-2.8789, -1.3926, -3.9075,  ..., -2.8865,  0.3466,  1.3441]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7848, -3.7022, -1.2650,  ..., -1.4351, -2.0303,  0.2909],\n",
            "        [-0.2923, -2.8310, -0.8145,  ...,  0.1593,  0.0148,  1.7516],\n",
            "        [ 1.9937, -0.2941, -0.5378,  ..., -1.0302, -2.2218,  0.7857],\n",
            "        ...,\n",
            "        [-0.6173, -1.8457, -0.6178,  ..., -2.9560, -0.7839,  1.0074],\n",
            "        [-2.2615, -4.1002, -1.7876,  ..., -1.5434, -0.7453,  0.9408],\n",
            "        [ 0.2141, -2.6079, -1.9090,  ..., -0.6338,  1.8101, -0.7522]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1205, -1.4380, -0.8698,  ..., -2.1037,  1.7395,  1.7249],\n",
            "        [-0.9813,  1.4011, -0.4509,  ..., -2.5915,  1.4214,  0.0917],\n",
            "        [ 0.3185, -4.1818, -3.8410,  ..., -0.6435, -1.6424,  0.4985],\n",
            "        ...,\n",
            "        [-2.2076, -1.6316, -1.3378,  ..., -4.4172,  0.0582, -0.0264],\n",
            "        [-1.2569, -1.1413,  0.1964,  ..., -2.2225,  0.2041, -1.0492],\n",
            "        [ 0.5627, -0.4176, -0.6191,  ..., -1.9353, -1.0947,  3.7330]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2293, -1.9546, -0.3709,  ..., -3.9850,  0.4038, -0.3512],\n",
            "        [-2.2273,  1.0245, -1.5844,  ..., -2.3577,  2.1520,  0.7302],\n",
            "        [-2.1334, -1.3416,  0.2155,  ..., -2.4658, -3.1506,  2.1714],\n",
            "        ...,\n",
            "        [ 0.0368, -0.9143, -0.6431,  ..., -0.6860, -0.9344, -0.1443],\n",
            "        [-3.5387, -0.7410, -2.9816,  ..., -4.1789,  1.1801,  3.7776],\n",
            "        [-1.4099, -1.8856, -1.9964,  ..., -0.9038, -0.9360,  0.8564]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8585,  1.5283, -2.9006,  ..., -1.2539, -0.5511,  0.9994],\n",
            "        [ 1.9470,  1.0352, -2.6386,  ...,  0.0665,  0.4197,  0.7259],\n",
            "        [ 0.3535, -0.5663, -2.5195,  ...,  0.1197,  0.5056, -1.7557],\n",
            "        ...,\n",
            "        [ 0.8057,  0.7176, -0.6958,  ..., -0.7899, -0.1307,  0.5265],\n",
            "        [ 0.9315,  2.2308, -2.1250,  ..., -1.6358,  2.1071, -0.9144],\n",
            "        [-1.5724, -0.3140, -1.5915,  ..., -3.0116, -0.2978,  2.3376]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4927, -0.5165, -3.9741,  ..., -4.4554, -1.6361,  0.3776],\n",
            "        [ 1.6338,  2.3276, -0.2947,  ..., -1.7276,  0.5751,  1.4263],\n",
            "        [ 2.5056, -0.3198, -1.3278,  ..., -2.9002,  0.2450, -0.3124],\n",
            "        ...,\n",
            "        [ 0.4076,  1.0931, -1.6021,  ..., -1.9118,  1.5752, -2.4192],\n",
            "        [-1.4688, -0.7455, -2.0129,  ..., -1.8934,  0.6809,  0.0293],\n",
            "        [-0.1547,  0.0822, -1.5874,  ..., -1.8149,  1.2316,  2.5569]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2317,  5.0348, -0.8333,  ..., -1.6033,  1.5411,  1.4093],\n",
            "        [-0.7463, -0.8735, -1.7243,  ..., -3.4314, -0.4830,  2.8609],\n",
            "        [ 1.8847,  0.9784, -0.7443,  ..., -2.4153,  0.4625,  1.8861],\n",
            "        ...,\n",
            "        [ 1.0157,  0.4834, -0.4817,  ..., -2.8067,  2.0920, -0.1153],\n",
            "        [-1.2262, -0.6219, -3.3587,  ..., -3.1624, -2.2996,  1.5620],\n",
            "        [ 0.0236,  0.1687, -1.3713,  ..., -3.0448,  3.3638,  0.7250]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9797, -1.2189, -0.1035,  ..., -2.4430, -2.0447,  0.2783],\n",
            "        [ 0.1669, -2.0923, -0.4782,  ..., -0.9407, -1.4354,  1.7846],\n",
            "        [-0.0526,  0.4805,  0.1761,  ..., -2.2977,  0.5770,  1.0503],\n",
            "        ...,\n",
            "        [-2.9496, -3.2666, -2.4634,  ..., -2.6748, -1.7441, -0.6868],\n",
            "        [ 1.8045,  1.9468, -0.7376,  ..., -0.8962, -0.0717,  1.1391],\n",
            "        [-3.0926, -2.3336, -2.6597,  ..., -2.1632,  0.2254,  2.4868]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0422,  1.8631, -1.4924,  ..., -2.0733, -2.9034, -0.0088],\n",
            "        [ 0.0617,  0.2415, -1.8562,  ..., -2.8012, -0.1103, -0.0822],\n",
            "        [ 0.0470, -0.9840, -3.2642,  ..., -3.0387,  2.4169, -0.8419],\n",
            "        ...,\n",
            "        [-0.0320,  1.4690, -1.3785,  ..., -2.7746, -2.2302,  0.4773],\n",
            "        [ 0.4611, -0.3607,  0.0854,  ..., -1.5718, -1.7180,  0.9307],\n",
            "        [ 1.3412,  3.3881, -0.0065,  ..., -2.5702,  0.7184, -0.1869]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8894,  0.2336, -0.2286,  ..., -1.5856, -1.8142,  1.4210],\n",
            "        [-3.4183, -0.3458, -2.9826,  ..., -3.5312,  1.4837,  2.3780],\n",
            "        [ 1.9670,  2.4702, -1.8757,  ..., -1.4076, -0.1339, -0.6670],\n",
            "        ...,\n",
            "        [ 1.3218, -1.0064, -0.4594,  ..., -0.5644, -0.3454,  0.9921],\n",
            "        [ 0.5797,  0.8340,  0.4019,  ..., -3.9787,  1.4060, -0.4474],\n",
            "        [-0.0608,  0.5175, -0.2279,  ..., -3.5809,  0.8366,  2.3204]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5117,  1.2436, -0.9794,  ..., -3.3226, -0.4535,  1.4382],\n",
            "        [ 0.6557, -0.6133, -2.8817,  ..., -2.2566,  0.6236,  0.2826],\n",
            "        [ 1.6012,  3.3853, -2.7045,  ..., -1.7268,  2.4509,  0.1740],\n",
            "        ...,\n",
            "        [ 1.7153,  0.2803, -2.9096,  ..., -1.0774,  1.1192, -0.6791],\n",
            "        [-0.6462,  2.2111, -1.1372,  ..., -2.2648,  0.9844,  2.1792],\n",
            "        [ 0.1537,  4.0407, -2.3311,  ..., -0.9721,  0.8000,  0.2815]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0937,  0.5519, -2.7781,  ..., -0.8986,  3.8538,  2.3822],\n",
            "        [-2.4389,  0.2698, -2.0272,  ..., -3.5736, -0.6398, -1.8870],\n",
            "        [ 1.8180,  2.3607, -3.3783,  ..., -0.7552, -0.8512, -0.2756],\n",
            "        ...,\n",
            "        [ 0.6771, -0.0564, -2.8365,  ..., -2.3270,  4.8794,  1.5424],\n",
            "        [-2.4218, -2.3608, -3.2749,  ..., -4.4829,  0.8672,  4.4036],\n",
            "        [-0.8393, -2.7176, -2.4757,  ..., -1.5640, -1.5964, -0.0142]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5680,  3.3768, -1.3918,  ..., -2.8696, -1.0919, -1.8979],\n",
            "        [ 0.8029,  3.1159, -0.5575,  ..., -3.2575,  1.2775,  0.9868],\n",
            "        [-0.7595, -0.4198, -3.7620,  ..., -1.6820, -1.9234,  0.1098],\n",
            "        ...,\n",
            "        [-2.3937, -0.2451, -2.0639,  ..., -3.2748,  1.4872,  0.3969],\n",
            "        [-1.4425,  0.7863, -1.6999,  ..., -0.1534,  0.5332, -1.1352],\n",
            "        [ 0.8695,  1.3539, -2.0321,  ..., -0.6023, -0.9311,  1.1675]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5976,  3.9607, -1.8390,  ..., -3.8577, -1.5553,  0.4359],\n",
            "        [-1.9524,  1.9146, -0.4936,  ..., -1.5667, -0.3062,  0.0539],\n",
            "        [ 0.3939, -1.6932, -0.6260,  ..., -3.0683, -0.7404,  2.5618],\n",
            "        ...,\n",
            "        [-0.0232,  3.8800, -0.4404,  ..., -2.6008, -0.5347, -1.0422],\n",
            "        [ 0.4760, -3.1190, -4.3002,  ..., -3.5080,  3.1051,  5.4495],\n",
            "        [-0.9332, -1.7880, -2.0813,  ..., -1.9597,  1.6723,  0.0733]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3743, -0.3981,  0.6703,  ..., -3.0226,  2.8435, -0.8803],\n",
            "        [ 0.0716, -1.2553, -1.4443,  ..., -3.7939,  3.9326,  1.8640],\n",
            "        [-0.5125, -0.4573, -1.3430,  ..., -3.2028, -0.6685,  4.7146],\n",
            "        ...,\n",
            "        [-0.1018,  2.9548, -3.6238,  ..., -1.2676,  1.7554, -1.8798],\n",
            "        [ 0.3848,  0.3868, -2.7309,  ..., -3.7557,  3.6255,  1.3537],\n",
            "        [-2.8903, -2.1793, -2.4387,  ..., -4.5350, -1.0660,  1.6692]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5311,  2.2749, -0.8807,  ..., -0.7237,  1.9849,  0.9697],\n",
            "        [ 0.2509, -0.1522, -0.2794,  ..., -3.4789,  1.8693,  0.4736],\n",
            "        [-0.1846, -2.1539, -3.5840,  ..., -1.1114,  0.8906, -0.0783],\n",
            "        ...,\n",
            "        [ 2.2914,  1.3548, -2.0098,  ..., -1.3090,  1.8800,  1.1869],\n",
            "        [-1.6350, -0.3571, -0.7442,  ..., -3.2508, -0.9934,  2.1502],\n",
            "        [ 1.4729,  2.1249, -3.8042,  ...,  0.0793, -0.8516, -0.8858]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9636, -0.8213,  0.3150,  ..., -2.1284, -0.3273,  2.4502],\n",
            "        [ 0.2590,  0.3157, -3.5760,  ..., -1.5855,  1.3510, -1.1753],\n",
            "        [ 1.2580,  2.3703, -2.0312,  ..., -1.7595,  1.5101,  1.0691],\n",
            "        ...,\n",
            "        [ 1.4595,  1.4634, -2.7843,  ..., -3.7610,  6.7798,  1.6310],\n",
            "        [-0.7732,  1.5027, -1.6482,  ..., -0.9901,  1.7526, -0.1413],\n",
            "        [ 2.6541,  1.6051, -3.7450,  ..., -1.9336,  3.8741,  2.2004]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1655, -0.5633, -1.9949,  ..., -6.0139,  3.1588,  0.5986],\n",
            "        [ 1.2675,  1.6531, -2.9195,  ..., -3.5074,  0.9544,  2.7655],\n",
            "        [ 1.5766,  2.7318, -2.0265,  ..., -3.7115,  0.5783,  1.5606],\n",
            "        ...,\n",
            "        [-1.0407, -0.1283, -2.6815,  ..., -2.0323,  0.3665, -1.3465],\n",
            "        [-0.2284,  0.1606, -0.2714,  ..., -1.9090,  1.2913, -0.4082],\n",
            "        [ 1.2265,  3.4115, -3.1652,  ..., -1.2481,  0.9139,  0.1464]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1001,  0.3337, -1.6792,  ..., -3.5507,  1.2832, -1.5618],\n",
            "        [-1.6917, -1.8923, -1.3644,  ..., -2.1427, -1.1294,  0.4325],\n",
            "        [-0.7132,  2.2708, -4.2569,  ..., -1.4872,  1.2760, -0.2753],\n",
            "        ...,\n",
            "        [-1.7225, -1.0372, -1.0052,  ..., -3.4967,  3.1318,  1.2504],\n",
            "        [ 0.0486, -1.2465, -0.5700,  ..., -2.4007,  0.1431,  3.3431],\n",
            "        [-0.8995,  2.3327, -0.6658,  ..., -2.0277,  0.7098,  0.4446]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6028, -1.2840, -0.4456,  ..., -2.4208,  2.1470,  2.7509],\n",
            "        [ 1.3204,  0.0161, -2.5245,  ..., -2.0274,  3.9896,  2.1436],\n",
            "        [-0.7921, -1.0440, -3.8284,  ..., -3.6682,  0.0899,  0.3415],\n",
            "        ...,\n",
            "        [ 0.6065,  3.2472, -1.8282,  ..., -1.2294, -0.0290,  1.0099],\n",
            "        [ 0.6968,  1.2380, -4.1953,  ..., -1.8237,  1.3490,  0.4196],\n",
            "        [-0.3970,  3.7224, -1.9806,  ..., -2.4325,  0.2806, -1.6558]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1021,  0.4137, -1.5065,  ..., -3.2352, -0.6735,  1.0391],\n",
            "        [ 1.9645, -0.2565, -0.6703,  ..., -1.8935,  2.4809, -0.7085],\n",
            "        [ 1.3805,  2.6307, -1.2462,  ..., -2.0015,  0.0638,  0.6078],\n",
            "        ...,\n",
            "        [-0.6005,  1.8152, -2.2260,  ..., -3.0622,  1.4013,  2.8937],\n",
            "        [-2.1237, -0.9386, -4.4502,  ..., -3.7240,  1.8813,  2.8104],\n",
            "        [ 1.4607, -2.4437, -1.0411,  ..., -3.6246, -0.5780,  0.5440]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1048, -5.0023, -1.8050,  ..., -2.9120, -0.5139,  1.9797],\n",
            "        [ 1.9181,  4.2427, -1.2804,  ..., -1.7001,  0.1687,  1.8379],\n",
            "        [-0.8840,  2.9977, -4.5220,  ..., -2.0294,  0.5939,  0.6477],\n",
            "        ...,\n",
            "        [ 2.4046,  1.0343, -2.1267,  ..., -2.0083,  7.3534,  2.1824],\n",
            "        [-0.0416, -1.6755,  0.7027,  ..., -3.3666,  2.5671, -0.2976],\n",
            "        [-1.6483,  3.1456, -2.5513,  ..., -0.1466,  1.2999, -2.2901]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8500, -4.1094, -4.3510,  ..., -2.3257,  2.6122, -0.7019],\n",
            "        [ 0.9376,  3.1343, -2.1947,  ..., -1.5279, -1.8472, -0.1084],\n",
            "        [ 1.8636,  2.7706, -2.3738,  ..., -3.7877,  2.2707, -0.1786],\n",
            "        ...,\n",
            "        [ 1.5746,  1.7542, -0.8295,  ..., -1.6886, -1.2825,  0.7858],\n",
            "        [-0.8112,  3.5426, -2.4205,  ..., -2.1090, -0.3108, -0.7788],\n",
            "        [ 0.7384, -0.1047, -2.3509,  ..., -2.9492, -1.9009,  0.6506]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0804,  4.9344, -2.4720,  ..., -1.4207,  3.6809, -1.7517],\n",
            "        [ 1.0429,  0.7172,  0.5525,  ..., -2.8724, -1.7113, -0.8129],\n",
            "        [-3.9478, -5.2122, -5.7359,  ..., -3.8872,  1.0918,  2.8461],\n",
            "        ...,\n",
            "        [ 1.1691,  2.4450, -2.5851,  ..., -2.0904,  2.6973, -1.1548],\n",
            "        [ 1.4563,  1.0083, -0.4119,  ..., -3.4916,  0.4825,  1.8398],\n",
            "        [ 0.6884,  1.4529, -0.5437,  ..., -2.0013,  1.2123,  1.3822]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3750,  3.8401, -1.9115,  ...,  0.1436,  1.8069, -1.4776],\n",
            "        [ 1.2651,  3.9632, -2.0384,  ..., -2.4831,  1.9423, -0.2012],\n",
            "        [ 0.1228,  5.7808, -2.0662,  ..., -3.6271, -0.5158, -0.4296],\n",
            "        ...,\n",
            "        [-1.4299,  4.5169, -2.1054,  ..., -2.2554, -0.4462, -2.7855],\n",
            "        [ 1.1700,  3.9877, -2.6460,  ..., -1.9935,  1.6500,  1.2952],\n",
            "        [ 2.7538,  3.5235, -0.3159,  ..., -2.5491,  0.9333,  1.3104]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7818,  3.5454, -1.3563,  ..., -0.9298,  1.3424, -0.6394],\n",
            "        [-1.0856, -2.1010, -3.9837,  ..., -1.3250,  1.8747,  0.1972],\n",
            "        [ 2.0851,  1.6059, -2.3640,  ..., -1.8206,  1.0879, -0.2622],\n",
            "        ...,\n",
            "        [-0.1161,  2.8455, -1.7705,  ..., -1.4976,  1.3887, -0.8846],\n",
            "        [ 2.8113,  3.5999, -0.6914,  ..., -2.8415,  0.4498,  1.1322],\n",
            "        [ 2.4913,  1.2485, -2.6046,  ..., -0.3965,  4.9420,  0.3250]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 8.3225e-01,  2.3203e+00, -2.4889e+00,  ..., -3.3605e+00,\n",
            "          2.1910e+00,  2.3765e+00],\n",
            "        [ 3.4880e-03,  4.1887e+00, -3.1628e+00,  ..., -9.5716e-01,\n",
            "          1.1996e+00, -2.6800e+00],\n",
            "        [ 2.4710e+00,  4.5245e+00, -1.4570e+00,  ..., -3.2080e+00,\n",
            "          1.9546e+00,  1.1247e+00],\n",
            "        ...,\n",
            "        [ 1.2617e+00, -3.8722e-01, -8.2637e-01,  ..., -1.0817e+00,\n",
            "          3.1878e+00, -4.4272e-01],\n",
            "        [ 1.1705e+00,  2.0078e+00, -2.3873e+00,  ..., -7.9424e-01,\n",
            "          3.1471e+00,  6.2986e-01],\n",
            "        [-4.2467e-01,  3.3860e+00, -3.2482e+00,  ..., -1.9987e+00,\n",
            "         -1.8801e+00, -8.9257e-02]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1670,  2.4760, -2.8457,  ..., -0.8185,  0.9226, -2.8979],\n",
            "        [-1.0634,  2.0047, -2.0353,  ..., -3.6029,  0.5878, -0.4865],\n",
            "        [-2.4820,  1.2228, -2.7750,  ..., -3.5291,  3.5923, -1.3526],\n",
            "        ...,\n",
            "        [ 3.8530,  2.4035, -3.3961,  ..., -2.5514,  7.3243,  0.6139],\n",
            "        [ 0.8545,  3.1608, -1.6530,  ..., -2.3483, -0.2288, -0.7290],\n",
            "        [ 2.6063,  1.8632, -1.3920,  ..., -1.0628,  2.2950,  0.0618]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7309,  4.5547, -2.4968,  ..., -2.5038,  2.4787,  0.9692],\n",
            "        [ 1.3405,  1.3856, -0.5832,  ..., -3.2294,  0.0382,  1.4938],\n",
            "        [ 0.3269,  2.7980, -1.9889,  ..., -2.4950, -1.6611, -1.2935],\n",
            "        ...,\n",
            "        [-3.1321, -2.2987, -2.0262,  ..., -3.4959, -0.2649,  1.5804],\n",
            "        [-3.8140, -0.6733, -1.9741,  ..., -4.1212,  1.5169,  5.0767],\n",
            "        [ 1.8863,  2.3426, -1.2452,  ..., -1.3410,  3.8108,  0.7564]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6090, -2.3894, -3.0028,  ..., -0.3215,  1.2853, -0.0602],\n",
            "        [ 0.6733,  2.8339, -1.9441,  ..., -2.9170, -2.2071, -1.1170],\n",
            "        [ 0.8405,  5.2105, -2.5220,  ..., -2.0157, -1.0937, -1.9639],\n",
            "        ...,\n",
            "        [ 2.2070,  4.4942, -1.7048,  ..., -1.9050,  1.0073,  0.3407],\n",
            "        [-4.0680, -0.6994, -2.7601,  ..., -4.2886,  3.4549,  4.8496],\n",
            "        [-0.4868,  2.5971, -4.1673,  ...,  0.8558,  1.1186, -2.2390]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4642, -0.1794, -2.6796,  ..., -2.7703,  1.4695,  2.5039],\n",
            "        [-2.1081, -0.5696, -0.3849,  ..., -1.6101,  0.4856,  0.7930],\n",
            "        [-1.4998, -0.0062, -3.3850,  ..., -2.4207,  2.4818,  4.1026],\n",
            "        ...,\n",
            "        [ 1.4697,  5.8604, -3.0076,  ..., -1.4423,  1.8827, -0.4088],\n",
            "        [ 3.0597,  1.9589, -3.5491,  ..., -1.2108,  3.3148,  2.0923],\n",
            "        [-0.5831,  1.4051,  0.2585,  ..., -4.3372,  0.5913,  3.4576]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2246, -0.3398, -0.1627,  ..., -2.2639,  0.3378, -0.2871],\n",
            "        [-0.7403,  1.5785, -1.8307,  ..., -4.6163,  1.4817,  3.5892],\n",
            "        [ 2.4872,  5.4134, -0.6529,  ..., -2.4684,  2.0010,  2.4765],\n",
            "        ...,\n",
            "        [-4.5257, -0.5688, -4.2367,  ..., -4.7866,  1.7398,  3.2453],\n",
            "        [-3.1995, -3.9062, -1.1898,  ..., -4.2220, -1.5234,  4.4622],\n",
            "        [ 0.2658,  3.4413, -0.3639,  ..., -3.2173, -0.2636,  2.1320]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9871e+00, -1.7645e+00, -8.3060e-01,  ..., -5.4371e+00,\n",
            "          2.0475e+00,  3.1676e+00],\n",
            "        [-1.8045e+00, -1.7620e+00, -2.0695e+00,  ..., -1.7344e+00,\n",
            "          1.8546e+00,  1.0917e+00],\n",
            "        [-1.7494e+00, -6.5879e-01, -1.1060e+00,  ..., -3.7170e+00,\n",
            "          6.2346e-01,  3.8644e+00],\n",
            "        ...,\n",
            "        [ 2.2304e+00,  2.1738e+00, -2.4554e+00,  ..., -3.3738e+00,\n",
            "          1.5204e+00,  3.7064e+00],\n",
            "        [-1.3162e+00,  3.3499e+00,  1.5794e-01,  ..., -3.0244e+00,\n",
            "          5.8499e-01,  8.8260e-01],\n",
            "        [-1.3219e+00,  1.2486e+00, -2.4156e+00,  ..., -4.0868e+00,\n",
            "         -3.0023e-01, -4.6981e-04]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0755,  2.6438, -5.2169,  ..., -2.1201,  2.5160,  0.5984],\n",
            "        [ 1.3306, -1.0939, -0.1171,  ..., -3.0868, -0.0530,  3.0349],\n",
            "        [-1.0488, -1.3345, -1.4285,  ..., -4.5543, -2.9415,  3.3324],\n",
            "        ...,\n",
            "        [ 2.2637, -0.8961, -4.0019,  ..., -1.4050,  2.8379, -2.5661],\n",
            "        [ 2.9665,  3.4994, -3.0177,  ...,  0.6883,  1.3608, -1.7830],\n",
            "        [-0.5958,  2.9503, -3.5077,  ..., -2.0970,  3.7902,  2.9485]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1864,  1.2242,  0.4167,  ..., -3.2298,  0.2202,  3.9919],\n",
            "        [-1.9545, -0.3803, -1.2792,  ..., -3.5725, -0.3861,  1.1852],\n",
            "        [-0.1549,  4.5141, -2.2654,  ..., -3.0514, -1.5901, -0.7113],\n",
            "        ...,\n",
            "        [-0.8785,  1.4959, -0.5354,  ..., -0.2641, -0.7415,  1.5420],\n",
            "        [-1.8101,  2.2923, -0.5457,  ..., -3.3145,  1.1139,  1.2364],\n",
            "        [-2.6242, -1.3553, -3.4058,  ..., -0.9974,  3.1848,  0.7933]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3439,  6.3320, -2.6640,  ..., -1.5845,  0.7215, -0.8302],\n",
            "        [ 0.8870,  2.7200, -2.3575,  ..., -1.3885, -0.0983,  1.8204],\n",
            "        [ 0.2611, -0.2991, -3.6372,  ..., -1.6779,  1.3323, -0.5871],\n",
            "        ...,\n",
            "        [ 1.1900,  5.6620, -3.0059,  ..., -1.5306,  2.8553,  0.5013],\n",
            "        [ 0.8373,  3.0710, -2.9256,  ..., -0.3342,  1.2716, -1.6058],\n",
            "        [-1.2415, -2.3631, -5.5430,  ..., -3.5279,  4.0606,  2.7214]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0169,  3.5541, -1.9125,  ..., -1.8813, -0.8123, -0.6767],\n",
            "        [-3.2163, -1.6554, -3.5532,  ..., -4.7359,  0.9248,  2.3517],\n",
            "        [ 0.3814,  2.0175, -1.6988,  ..., -2.7315, -2.3363, -0.8881],\n",
            "        ...,\n",
            "        [ 2.3830,  2.5054, -1.6129,  ..., -3.0917,  1.2642,  1.1868],\n",
            "        [ 2.2217,  0.2548, -3.8304,  ..., -2.4180, -0.1490,  0.3568],\n",
            "        [ 0.0300,  3.0899, -3.2536,  ..., -2.1931,  0.2253, -0.0430]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9986,  0.1616, -2.1021,  ..., -2.2904,  0.2498,  0.8472],\n",
            "        [ 0.0771,  4.8004, -1.5079,  ..., -1.0211,  2.8096,  1.6801],\n",
            "        [ 0.9501,  1.2755, -0.6751,  ..., -3.2027, -0.3872,  1.8602],\n",
            "        ...,\n",
            "        [-3.3824, -4.0023, -2.4221,  ..., -3.7305, -0.4909,  1.0454],\n",
            "        [ 0.6856, -0.5594, -0.6367,  ..., -2.3757, -1.4329,  1.2333],\n",
            "        [ 1.2294,  0.5333, -2.7649,  ..., -1.1379,  3.2817, -1.0738]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7360, -2.5629, -2.0199,  ..., -1.0199,  1.8262, -0.3818],\n",
            "        [ 1.3280, -0.0959, -0.5322,  ..., -3.2276, -1.2229,  2.8276],\n",
            "        [ 0.6686,  4.9111, -3.1119,  ..., -2.6753,  1.8477,  1.5739],\n",
            "        ...,\n",
            "        [ 1.0618,  3.5967, -1.1639,  ..., -2.2469, -3.0372,  1.3252],\n",
            "        [ 3.2312,  2.1038, -2.5341,  ..., -1.6935,  4.4431,  2.2176],\n",
            "        [-1.7914, -2.6431, -1.9860,  ..., -3.2056,  1.8325, -1.3232]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2860, -0.0948,  0.1595,  ..., -2.7406, -0.7821,  2.5818],\n",
            "        [-1.1242, -2.4940, -1.1937,  ..., -3.3893,  1.5169,  0.6291],\n",
            "        [ 2.0631,  3.7719, -1.4078,  ..., -2.5094,  0.5929,  0.3359],\n",
            "        ...,\n",
            "        [ 2.3360, -0.8499, -0.6610,  ..., -4.8457,  2.8887, -0.3813],\n",
            "        [-0.4406,  5.3160, -2.4817,  ..., -1.2920, -0.2861, -1.3926],\n",
            "        [-0.4367, -0.6290,  0.0058,  ..., -2.7808, -0.6146,  2.2058]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5032,  3.7089, -1.5178,  ..., -1.4878, -0.6097, -0.9521],\n",
            "        [ 3.0574,  5.7168, -3.0021,  ..., -0.8843,  1.4894, -0.2812],\n",
            "        [ 0.8775,  1.8936, -2.3618,  ..., -2.9945,  0.8073,  1.8375],\n",
            "        ...,\n",
            "        [ 2.2341,  3.8478, -1.1129,  ..., -2.7719,  0.6696,  1.0015],\n",
            "        [-1.6841, -2.0479, -2.5845,  ..., -2.5833,  3.0579,  0.9398],\n",
            "        [-0.0310,  4.6366, -1.7887,  ..., -2.0315,  1.2208, -0.8709]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2572,  1.5395, -4.2789,  ..., -0.6642,  1.3935, -2.6341],\n",
            "        [-0.2180,  1.0585, -3.1789,  ..., -2.7144,  0.1467, -0.1454],\n",
            "        [ 0.8275,  1.2204, -2.2999,  ..., -1.4953,  4.2650,  1.3556],\n",
            "        ...,\n",
            "        [-0.9830,  2.6802, -0.9031,  ..., -2.7424, -0.0593, -1.0476],\n",
            "        [ 0.5011,  2.7264, -2.1494,  ..., -2.1628,  0.1176,  0.4084],\n",
            "        [ 0.7047, -2.4594, -1.7832,  ..., -0.1632,  1.7927, -2.8502]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4084,  3.6828, -0.5610,  ..., -0.4486, -0.1267,  0.2508],\n",
            "        [ 1.4423,  0.0552, -1.9883,  ..., -3.3904,  2.2423,  3.3091],\n",
            "        [ 2.1078,  1.4272, -0.7334,  ..., -2.8328,  1.4633,  2.1427],\n",
            "        ...,\n",
            "        [ 2.8657, -0.0080, -0.9261,  ..., -0.8899,  3.4146,  1.1126],\n",
            "        [-4.2100,  1.0004, -4.3810,  ..., -0.0810,  2.7025, -1.0706],\n",
            "        [ 2.4831,  4.0098, -1.0060,  ..., -1.9269, -0.1647,  2.1655]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9788,  4.9644, -0.7366,  ..., -2.7139,  1.0794,  2.1461],\n",
            "        [ 0.6473,  3.9325, -2.3334,  ..., -0.1540, -0.3975, -0.8642],\n",
            "        [-3.6924, -0.9605, -1.1678,  ..., -3.4105, -0.1241,  1.1860],\n",
            "        ...,\n",
            "        [-0.4838,  1.6552, -2.5401,  ..., -3.4691,  0.0493,  0.6201],\n",
            "        [ 2.9027,  1.5619, -1.2995,  ..., -1.7672,  5.5235,  1.6355],\n",
            "        [-0.9955,  3.9273, -1.0031,  ..., -2.2414, -1.8018, -0.4005]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5447, -1.5980, -5.0601,  ..., -3.9246,  3.7821,  2.6182],\n",
            "        [ 3.1128,  4.3896, -1.6012,  ..., -1.5143,  1.1794,  1.3477],\n",
            "        [ 0.9972, -1.9907, -1.5672,  ..., -2.4457,  5.5869,  0.0100],\n",
            "        ...,\n",
            "        [ 1.1988, -0.1535, -2.0921,  ...,  0.3778,  0.3292,  1.1785],\n",
            "        [ 0.3500,  1.4950, -0.9774,  ..., -4.7173, -0.0270,  0.7175],\n",
            "        [ 1.6737,  3.8363,  0.1956,  ..., -2.1809,  0.9079,  0.8424]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0984, -0.7792, -3.4360,  ..., -3.7743,  2.9396,  0.2038],\n",
            "        [-1.3639,  0.3334,  1.0476,  ..., -3.7141,  4.3492,  2.1432],\n",
            "        [ 1.3790, -2.4640, -1.0668,  ..., -4.1103,  3.7511, -0.8354],\n",
            "        ...,\n",
            "        [ 2.8202,  3.9867, -1.6366,  ..., -2.0568,  1.1924,  2.2072],\n",
            "        [-0.4823, -0.1394,  0.4919,  ..., -3.1527, -0.4536,  1.7623],\n",
            "        [-0.0510, -1.4846, -0.2430,  ..., -2.5815,  0.0226,  2.9209]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6358, -0.8655, -1.2368,  ..., -2.9866,  0.5820,  0.2395],\n",
            "        [ 1.6729,  1.5179, -0.8002,  ..., -3.0870,  1.8634,  2.2518],\n",
            "        [-0.2338,  1.1850, -1.2582,  ..., -2.4508, -3.3685, -0.5481],\n",
            "        ...,\n",
            "        [-3.2099, -3.2320, -1.9435,  ..., -1.7097,  1.3780, -0.0164],\n",
            "        [-0.2614,  4.1218, -2.8259,  ..., -1.6899,  2.3173, -1.6108],\n",
            "        [-0.0886,  2.8551, -1.5730,  ..., -2.8463,  0.2052,  0.2515]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7753, -0.4781, -0.5074,  ..., -2.6433,  2.2374,  2.1559],\n",
            "        [ 1.6191,  1.5368, -0.8799,  ..., -1.4003,  4.2484,  1.4834],\n",
            "        [ 0.2871,  2.5250, -1.4509,  ..., -2.8333,  0.3111, -0.8380],\n",
            "        ...,\n",
            "        [ 2.4381, -3.2159, -0.1375,  ..., -2.6473,  3.0978, -1.0427],\n",
            "        [ 0.8447, -0.6133, -4.1564,  ..., -1.4510,  5.6893,  3.1384],\n",
            "        [-1.0941,  1.0413, -1.3676,  ..., -0.6714,  4.5592,  1.0362]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3125,  0.3681, -1.0024,  ..., -3.6110,  2.2910,  0.1836],\n",
            "        [-1.2208, -3.8979, -0.2136,  ..., -4.3068,  0.6026,  0.3834],\n",
            "        [-1.0160,  2.6649, -1.7668,  ..., -3.3702, -1.0163,  0.1077],\n",
            "        ...,\n",
            "        [-0.0468,  4.9224, -3.1037,  ..., -1.4597,  3.1116, -2.9477],\n",
            "        [-2.9869, -2.7111,  0.1590,  ..., -2.6200,  1.5728,  0.0755],\n",
            "        [-1.9026, -3.4686, -0.9267,  ..., -2.2308,  3.5877, -2.9027]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3468,  2.2168, -3.6504,  ..., -0.4455,  2.8226,  0.2584],\n",
            "        [ 0.3412,  2.2093, -1.2647,  ...,  0.2374,  0.3510, -2.6488],\n",
            "        [ 0.0589,  2.0311, -4.6003,  ..., -1.0778, -0.4596, -0.1016],\n",
            "        ...,\n",
            "        [ 0.3643, -0.0244, -1.3222,  ..., -0.7204,  3.5914,  2.1218],\n",
            "        [ 1.3176,  2.2607, -1.4257,  ..., -2.6882,  3.4985,  0.4577],\n",
            "        [-0.6836,  5.1269, -2.9214,  ..., -0.8465,  0.9551, -1.9161]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8715, -0.2840, -0.9432,  ..., -2.5951,  2.1756,  4.1037],\n",
            "        [-2.7149, -2.1006, -2.1974,  ..., -3.7482,  1.1668,  1.9986],\n",
            "        [-3.5712, -3.5938, -2.1448,  ..., -3.9708,  2.5753,  5.0805],\n",
            "        ...,\n",
            "        [-1.7940, -2.4148, -3.7226,  ..., -3.3634,  6.7161,  4.4535],\n",
            "        [-1.3441,  2.7061, -2.0765,  ..., -1.0947, -1.2474, -0.8850],\n",
            "        [ 2.2789,  1.3347, -2.6013,  ..., -2.4633,  4.6386,  0.9829]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0482,  2.2746, -1.2694,  ..., -1.7764,  1.2136,  1.3014],\n",
            "        [-1.0025,  4.9420, -3.2435,  ..., -1.6672,  1.8181, -1.4533],\n",
            "        [-3.2722, -3.2355, -5.5797,  ..., -4.3200,  4.2447,  1.9990],\n",
            "        ...,\n",
            "        [-0.5695,  4.5859, -1.8447,  ..., -0.8128, -1.5250, -2.4071],\n",
            "        [ 0.5282,  0.9814, -1.8886,  ..., -4.3961,  1.5349,  2.5964],\n",
            "        [-2.1153, -2.5302, -4.2819,  ..., -3.4000,  4.4109,  4.0806]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9930, -1.9756, -2.3723,  ..., -1.4709,  2.1366, -0.3530],\n",
            "        [-1.2613,  1.4271, -0.4275,  ..., -2.2497,  0.6602, -0.1097],\n",
            "        [ 0.1514,  3.6562, -0.6970,  ..., -1.5487,  0.2311, -0.5253],\n",
            "        ...,\n",
            "        [ 1.1784,  2.6370, -1.5988,  ..., -1.5404,  0.8170,  0.3034],\n",
            "        [-0.9397, -0.4582, -3.7981,  ...,  1.8567,  0.8482, -1.5899],\n",
            "        [-1.9117,  1.3393, -0.7151,  ..., -2.8384,  2.1300,  2.1267]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3435,  1.4953, -1.0714,  ..., -0.5705,  0.5482,  0.2238],\n",
            "        [-2.4220, -1.3387, -2.9839,  ..., -4.0538,  3.2998,  4.5476],\n",
            "        [-1.5736, -6.7121, -2.0425,  ..., -2.6557,  3.4081, -0.4450],\n",
            "        ...,\n",
            "        [-0.5074, -2.1984, -2.1498,  ..., -2.1392,  3.7285,  0.2470],\n",
            "        [-0.7047,  2.9561, -2.4746,  ...,  0.0874,  2.3286, -2.0761],\n",
            "        [ 2.1176,  1.6209, -2.6049,  ..., -2.2737,  7.9087, -0.4146]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8655,  1.3721, -0.0889,  ..., -2.8964,  0.8083,  1.0601],\n",
            "        [ 1.1143,  1.4398, -1.5973,  ..., -3.5961,  3.2159,  2.7179],\n",
            "        [-1.0405,  3.3254, -0.7869,  ..., -2.0091,  0.5369,  0.3040],\n",
            "        ...,\n",
            "        [-0.5939,  0.7002, -0.4814,  ..., -2.6356,  0.6574,  2.8014],\n",
            "        [ 0.3136,  2.8301, -0.9679,  ..., -0.8432,  1.9817, -1.6744],\n",
            "        [ 2.3518,  0.4773, -2.0875,  ..., -2.1037,  8.0105,  2.1675]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3021,  5.1234, -1.0488,  ..., -1.7992,  0.6144,  1.4880],\n",
            "        [-0.9297, -0.3290, -1.6628,  ..., -1.6183,  1.3762,  0.1837],\n",
            "        [-2.5017, -3.2017, -1.1410,  ..., -3.2084, -1.7797,  1.9114],\n",
            "        ...,\n",
            "        [-0.7139,  1.5583, -1.7432,  ..., -2.9588, -1.0043, -1.0005],\n",
            "        [ 1.9641,  4.1224, -1.8197,  ..., -1.6517,  1.4855,  0.8402],\n",
            "        [-0.7620,  0.3285, -2.0902,  ..., -0.2871, -0.5461, -2.8558]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2217, -0.0797, -1.4889,  ..., -3.4286,  3.0867,  1.5587],\n",
            "        [ 0.0853,  3.8333, -2.6382,  ..., -2.1428, -2.0981,  2.1230],\n",
            "        [ 0.1073, -1.6815, -1.9357,  ..., -0.2051,  3.0230,  0.3043],\n",
            "        ...,\n",
            "        [-3.2369,  1.8860, -3.0962,  ..., -0.6775, -0.3757, -1.8575],\n",
            "        [-1.5636,  2.0146, -1.3242,  ..., -1.1737,  2.0363,  2.1127],\n",
            "        [ 0.0326,  0.9184, -1.3064,  ..., -3.1026,  1.6804,  0.7664]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.4822e+00, -4.5258e+00, -1.9703e+00,  ..., -3.6346e+00,\n",
            "          9.5121e-01, -8.9513e-01],\n",
            "        [-3.1953e+00, -4.3113e-01, -2.3906e+00,  ..., -1.9467e+00,\n",
            "         -3.3979e-01,  1.1824e+00],\n",
            "        [-1.3401e+00,  6.7461e+00, -2.9719e+00,  ..., -1.2801e+00,\n",
            "         -1.6711e+00, -1.9633e-02],\n",
            "        ...,\n",
            "        [-1.7403e+00,  1.2305e+00, -1.3244e+00,  ..., -3.1603e+00,\n",
            "         -2.3836e+00,  3.0448e-02],\n",
            "        [ 2.0940e-03,  8.4854e-01, -7.1553e-01,  ..., -3.1925e+00,\n",
            "         -7.0405e-01,  2.6901e+00],\n",
            "        [-2.4114e+00, -2.9894e+00, -1.4752e+00,  ..., -2.4417e+00,\n",
            "          1.3261e+00,  1.6796e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5825,  2.4750, -1.4982,  ..., -2.5210, -1.2726,  0.4164],\n",
            "        [ 1.7284,  3.4818, -0.8114,  ..., -1.7127,  0.7644,  0.2418],\n",
            "        [-3.6080, -3.9551, -3.1578,  ..., -2.8815,  0.7806,  4.4880],\n",
            "        ...,\n",
            "        [-0.1793, -1.6938, -1.3337,  ..., -1.8410,  0.2039,  0.8102],\n",
            "        [-1.0605,  1.6378, -2.5545,  ..., -1.6117, -1.0387, -1.5981],\n",
            "        [-2.3344, -2.5268,  0.9488,  ..., -2.1385, -0.5481,  1.5700]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2852, -2.4751, -1.3198,  ..., -1.8022,  0.3215, -0.6149],\n",
            "        [ 1.5247,  1.8298, -2.8013,  ..., -1.2438,  1.6996,  0.2750],\n",
            "        [-2.1893,  1.1621, -1.3390,  ..., -1.5292, -1.9595, -0.7712],\n",
            "        ...,\n",
            "        [-4.8682, -4.5102, -4.5635,  ..., -4.1008,  2.8071,  5.9290],\n",
            "        [ 0.6963,  4.5213, -2.4840,  ..., -1.8552, -1.7562, -0.5839],\n",
            "        [-4.2634, -0.3794, -0.8987,  ..., -0.3133,  1.5323,  1.3789]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7907,  0.8959, -1.4820,  ..., -2.6864, -1.8197, -0.1944],\n",
            "        [ 0.4941,  3.4209, -1.6766,  ..., -3.1547,  0.9249,  3.0139],\n",
            "        [ 0.2061,  2.0933, -1.7547,  ..., -3.4097,  1.0363,  3.4143],\n",
            "        ...,\n",
            "        [-0.5391,  2.1104, -2.2055,  ..., -1.2832, -1.4479, -1.6640],\n",
            "        [-0.6426, -0.2535, -0.0089,  ..., -2.0524, -2.2840,  0.6466],\n",
            "        [-3.0887, -0.5824, -2.6944,  ..., -4.4215,  1.8461,  3.2512]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1506,  4.1899, -2.8662,  ..., -0.7316,  0.1194, -0.6215],\n",
            "        [-1.4535,  0.7801, -0.2704,  ..., -3.7422, -1.0994,  1.8992],\n",
            "        [-0.7459,  1.1452, -0.2082,  ..., -3.1958,  0.0807,  2.5478],\n",
            "        ...,\n",
            "        [-3.3252, -1.5994, -1.0997,  ..., -3.6837,  0.7094,  0.6035],\n",
            "        [-3.6277,  2.6475, -3.4775,  ...,  2.1408,  0.5580, -2.5602],\n",
            "        [ 0.3964, -0.8089, -4.9182,  ..., -1.7001,  5.3533,  0.4009]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4831,  1.9974, -1.0415,  ..., -2.4406, -1.3380,  1.5773],\n",
            "        [-3.9423, -0.5235,  0.5472,  ...,  0.3425, -1.1657,  2.3540],\n",
            "        [-1.5746,  5.8578, -2.4040,  ..., -0.6236, -0.0132, -1.3869],\n",
            "        ...,\n",
            "        [-0.6252,  2.9317, -1.0110,  ..., -1.0195,  0.7500,  2.1860],\n",
            "        [-2.4002, -0.0705, -1.2772,  ..., -2.0495,  0.9305,  3.7253],\n",
            "        [-3.9027, -3.6309, -2.2566,  ..., -1.5951,  0.0759,  0.3588]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7577, -0.3450, -1.9899,  ...,  0.0271,  0.3530, -1.0360],\n",
            "        [ 0.0828,  5.6037, -2.6404,  ..., -1.3525,  3.0441,  0.6757],\n",
            "        [-4.3142, -1.5106, -1.1615,  ..., -3.3337,  2.2805,  2.0402],\n",
            "        ...,\n",
            "        [-0.4095,  1.4346, -1.6738,  ..., -1.3190, -2.9212, -1.0713],\n",
            "        [-1.4599,  3.5660, -2.9001,  ..., -2.8647, -1.1417,  0.8725],\n",
            "        [ 0.3412,  4.0367, -1.0418,  ..., -1.1999, -3.8676,  1.3614]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4649,  0.8816, -2.5207,  ..., -0.2662, -2.5781, -1.7507],\n",
            "        [-2.5811, -1.0641, -1.7616,  ..., -3.7188,  1.4430,  0.6548],\n",
            "        [ 0.0684, -1.6272, -1.3423,  ..., -2.7790, -0.9251, -0.9339],\n",
            "        ...,\n",
            "        [-2.0055, -1.2827, -2.9455,  ..., -0.4642, -0.2390,  0.5684],\n",
            "        [-2.4892,  1.2343, -2.3538,  ..., -0.2076,  0.1189, -3.8303],\n",
            "        [-0.1352,  0.7494, -1.3120,  ..., -3.4643, -0.1388,  3.3427]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5563,  1.8320, -0.2856,  ..., -2.6194,  0.4713,  2.0213],\n",
            "        [-0.5353,  4.5742, -2.7979,  ..., -2.1026,  3.6020,  0.1799],\n",
            "        [-1.3267,  2.8305, -1.5951,  ..., -1.6255,  0.1316, -0.4644],\n",
            "        ...,\n",
            "        [ 1.9081,  0.5374, -2.9404,  ..., -0.2035,  4.4851,  2.2801],\n",
            "        [-3.9424, -3.7023, -3.1704,  ..., -3.4685,  2.3086,  5.4377],\n",
            "        [ 1.6072,  4.4984, -1.1821,  ..., -1.4192, -0.0765,  2.6480]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8140, -4.1593, -0.8020,  ..., -2.2320, -0.8756,  1.3398],\n",
            "        [-2.8980, -3.4511, -0.7440,  ..., -0.5419,  0.2139,  0.4706],\n",
            "        [-4.1316, -1.0593, -3.2027,  ..., -1.8619, -0.7886,  1.2253],\n",
            "        ...,\n",
            "        [ 0.6807,  1.6861, -0.8262,  ..., -0.5290,  3.0825,  1.4706],\n",
            "        [-2.1850,  1.9499, -3.3834,  ...,  2.6277, -1.1155, -2.1320],\n",
            "        [ 0.4316,  1.1724, -1.5027,  ..., -2.4833, -0.3473, -0.3751]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3292e+00,  3.6813e+00, -1.5466e+00,  ..., -1.2432e+00,\n",
            "         -5.8366e-01, -9.6253e-01],\n",
            "        [-3.2077e+00,  4.8170e+00, -3.6318e+00,  ...,  9.7481e-01,\n",
            "         -1.0878e-02, -3.5878e-01],\n",
            "        [ 1.4959e+00, -1.0064e+00, -2.8806e+00,  ...,  1.4075e+00,\n",
            "          8.9010e-01, -5.1430e-01],\n",
            "        ...,\n",
            "        [-1.2456e+00, -1.6889e+00, -1.1828e+00,  ..., -1.7663e+00,\n",
            "          2.6458e+00, -8.8254e-01],\n",
            "        [-2.3071e-01, -1.2041e+00, -2.3823e+00,  ..., -2.5155e+00,\n",
            "          3.6324e+00, -1.1317e-01],\n",
            "        [ 9.1117e-02,  3.1215e+00, -4.8888e-01,  ..., -1.0262e+00,\n",
            "         -3.7572e-03,  2.1739e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.2454, -7.8602, -1.5199,  ..., -3.3588,  2.8514,  1.7096],\n",
            "        [-1.7828, -4.3047, -3.6934,  ..., -3.2357,  1.4124,  4.0968],\n",
            "        [-0.6925, -2.1431, -2.0877,  ..., -2.9782,  2.8999,  3.9550],\n",
            "        ...,\n",
            "        [-2.9743, -3.1880, -2.5781,  ..., -0.4377,  1.4354, -1.7125],\n",
            "        [-0.7825,  5.8360, -2.6553,  ..., -0.6314, -0.6153, -0.1103],\n",
            "        [-0.2915,  0.6016, -2.3823,  ..., -0.7710, -0.6201,  1.9709]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5775, -0.5991, -2.8986,  ...,  0.7660, -0.1781,  0.5554],\n",
            "        [-2.2118, -2.4448, -2.0807,  ..., -1.4049,  2.5655,  0.9911],\n",
            "        [ 0.9420,  3.3121, -2.5293,  ..., -0.3925, -0.0710, -0.5744],\n",
            "        ...,\n",
            "        [ 0.1747,  2.4694, -0.6837,  ..., -1.6390, -2.6195,  3.2168],\n",
            "        [-0.3463,  5.2584, -2.5636,  ...,  0.1268,  1.6151,  0.1057],\n",
            "        [-3.4858, -4.1039, -5.4275,  ..., -3.4752,  1.7232,  3.4148]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3785,  0.5004, -2.8910,  ..., -2.0847,  6.4907,  2.2234],\n",
            "        [-0.8251,  0.7574, -1.2465,  ..., -1.7215,  1.6090,  0.4871],\n",
            "        [-5.5014, -1.4735, -4.6504,  ..., -1.9904,  2.8405,  5.5173],\n",
            "        ...,\n",
            "        [ 0.6000,  2.3497, -2.7750,  ..., -0.0768, -2.1122, -0.4041],\n",
            "        [-0.8284,  1.0913, -2.6765,  ..., -0.8501,  0.5473,  0.7724],\n",
            "        [ 1.7744,  1.9939, -1.7630,  ..., -1.7578,  3.7478, -0.2240]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5160,  2.4034, -3.4806,  ..., -1.1240,  0.0503, -0.9142],\n",
            "        [-0.1242,  1.6036,  1.0117,  ..., -1.0132, -0.7498,  1.7120],\n",
            "        [-3.4800, -0.7497, -1.7768,  ..., -2.4244, -1.1768,  1.5933],\n",
            "        ...,\n",
            "        [-3.0198,  2.1554, -2.7009,  ..., -0.7300,  1.4114, -1.5075],\n",
            "        [ 0.4957,  2.2356, -1.0715,  ..., -1.2782,  2.9055,  2.1372],\n",
            "        [ 1.2075,  2.2970, -1.7717,  ..., -2.0042,  6.2619,  1.7455]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0126,  1.8163, -3.6070,  ..., -0.6356,  2.4608,  1.6396],\n",
            "        [-0.8264,  0.0277, -3.0189,  ..., -1.0452,  3.4008,  3.1969],\n",
            "        [-5.4895, -0.9608, -1.6273,  ..., -3.0176, -1.0537,  3.0413],\n",
            "        ...,\n",
            "        [ 1.1546, -1.6992, -1.2780,  ..., -2.2761,  2.8851,  1.5290],\n",
            "        [ 3.0400,  0.5120, -1.2474,  ..., -1.5364,  4.8770,  1.7496],\n",
            "        [-0.9497,  1.3300, -4.3973,  ...,  0.9995, -0.1038, -1.0077]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7456,  4.4660, -4.1985,  ...,  0.8255, -0.4381, -0.2172],\n",
            "        [-0.8158,  1.9955, -1.5492,  ..., -3.1964, -0.1324,  2.7478],\n",
            "        [-1.3605,  1.8661, -2.3231,  ..., -1.6515,  0.6705,  1.5632],\n",
            "        ...,\n",
            "        [-0.0808,  4.6153, -4.2685,  ..., -1.7281, -1.3168,  1.0781],\n",
            "        [-4.1036, -1.6986, -3.5521,  ..., -2.6969,  4.1985,  4.3453],\n",
            "        [-0.7488, -2.5029, -1.8135,  ..., -3.7807,  0.9862,  0.6469]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4973,  4.4362, -2.5184,  ..., -1.5150, -0.8067,  1.2156],\n",
            "        [-4.9128, -3.2330, -1.1748,  ..., -3.8116, -0.7535,  5.5260],\n",
            "        [-2.3057,  0.6522, -0.6257,  ..., -3.1105, -0.4044,  1.7765],\n",
            "        ...,\n",
            "        [-4.3626, -0.8108, -3.2932,  ..., -1.8880,  1.6364,  3.1162],\n",
            "        [-0.4432, -0.7117, -2.9790,  ..., -2.5948,  1.7993,  0.8906],\n",
            "        [-0.9563, -1.2327, -1.4573,  ..., -2.5397,  3.7722,  3.9758]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1574, -2.1050, -2.0043,  ..., -2.8961, -0.1253, -2.5525],\n",
            "        [-1.4850,  3.3823, -2.4270,  ..., -2.9682, -2.2894,  1.3931],\n",
            "        [-2.1422, -2.3103,  0.6568,  ..., -1.8432, -0.3526,  1.3447],\n",
            "        ...,\n",
            "        [-0.8363,  2.4603, -4.3377,  ...,  0.0558,  1.2899,  0.6364],\n",
            "        [ 0.6999,  3.0008, -3.0713,  ..., -3.2741,  3.6462, -0.1845],\n",
            "        [-0.4627, -0.1205, -0.7057,  ..., -2.4813,  0.2320,  2.7689]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7626e+00, -2.7737e+00, -1.7367e+00,  ..., -8.9695e-01,\n",
            "         -8.0225e-01, -8.2031e-03],\n",
            "        [-1.9604e+00, -4.0097e-01, -3.9910e-01,  ..., -3.6668e+00,\n",
            "         -1.8072e+00,  3.9256e+00],\n",
            "        [-6.1207e-04,  2.7898e-01, -1.4116e+00,  ..., -2.9494e+00,\n",
            "         -4.6958e-01,  2.2939e+00],\n",
            "        ...,\n",
            "        [ 4.7610e-01,  2.7853e-01, -1.6152e+00,  ..., -2.7891e+00,\n",
            "          5.2022e-03,  2.9680e+00],\n",
            "        [-4.3351e-01, -7.3424e-01, -1.1443e+00,  ..., -4.7052e-01,\n",
            "         -6.8994e-01,  7.4839e-01],\n",
            "        [ 3.5997e+00, -5.1193e-02,  5.8664e-01,  ..., -2.4998e+00,\n",
            "          3.2061e+00, -6.6878e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6131, -0.7218, -0.9935,  ..., -0.9082,  4.1639,  0.1109],\n",
            "        [-1.8073,  0.9146, -1.2404,  ..., -1.8669,  0.6972,  2.4859],\n",
            "        [-1.5521, -1.0324, -1.7858,  ..., -3.6674,  2.7370,  2.2704],\n",
            "        ...,\n",
            "        [-1.7767,  4.0953, -1.7681,  ..., -0.3215, -1.5718, -1.8585],\n",
            "        [ 0.4490,  1.0072, -1.2667,  ..., -2.1384,  1.1736,  2.3640],\n",
            "        [-0.6047,  0.7243, -1.5636,  ..., -1.7194, -2.0476,  1.5262]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0903,  1.0975, -2.9567,  ..., -3.6391,  0.9112,  3.6088],\n",
            "        [-0.2309, -1.7485, -4.5105,  ..., -1.9114,  7.5974,  4.3515],\n",
            "        [-3.4151,  4.0392, -2.3150,  ...,  1.6521,  0.2512, -3.0889],\n",
            "        ...,\n",
            "        [-0.8158,  5.0095, -1.1703,  ..., -1.6467, -0.0858,  0.8618],\n",
            "        [-4.1306, -6.6924, -2.7357,  ..., -2.4951,  0.2925,  2.6164],\n",
            "        [ 0.3981,  1.3048, -2.6074,  ..., -1.7045,  3.5337, -1.2091]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6976,  0.4964, -1.5541,  ..., -1.6587,  2.0733, -0.3549],\n",
            "        [-2.8718, -4.1324, -4.8765,  ..., -3.3397,  2.2215,  3.1966],\n",
            "        [-0.8463,  2.1671, -2.8877,  ..., -1.7964, -3.1239, -0.8747],\n",
            "        ...,\n",
            "        [-3.1905, -2.6281, -4.2852,  ..., -3.2579,  1.0271, -0.4385],\n",
            "        [-3.0202, -1.0497, -5.0213,  ..., -4.3215, -0.1220,  3.4105],\n",
            "        [-3.3381, -0.5633, -2.3563,  ..., -3.1037, -0.0872,  0.5055]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9800,  2.1086, -2.9175,  ..., -0.5118,  5.6808,  1.2657],\n",
            "        [-0.2880,  1.1367, -3.1210,  ..., -1.9284,  6.3620,  0.0587],\n",
            "        [-0.5842, -0.6412, -1.6184,  ...,  2.3796,  0.6686, -1.5068],\n",
            "        ...,\n",
            "        [-3.0898, -2.8956, -4.0262,  ..., -2.9627, -2.9614,  0.7446],\n",
            "        [-1.3324,  2.1814, -1.5122,  ..., -0.6446,  2.5661,  2.4089],\n",
            "        [ 0.6034,  2.0453, -3.9103,  ..., -0.3675, -0.3670,  1.8910]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1794,  2.6915, -1.6831,  ...,  0.0219, -0.0827, -0.3714],\n",
            "        [ 1.6303,  2.2172, -3.2181,  ..., -0.8283,  3.2056,  2.6611],\n",
            "        [ 1.7733,  0.0298, -1.1127,  ...,  1.4168,  1.8763, -2.9655],\n",
            "        ...,\n",
            "        [ 1.4785, -0.3042, -3.8296,  ..., -0.1106,  6.1724,  2.5520],\n",
            "        [-2.5106, -4.4956, -3.0925,  ..., -2.8451,  1.0503,  3.3394],\n",
            "        [-1.7486,  3.2897, -2.2324,  ..., -1.8140,  0.5843,  0.8013]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.1820, -0.6039, -2.8418,  ..., -3.3688,  4.6613,  4.3138],\n",
            "        [-4.1992, -1.5015, -3.8777,  ..., -1.7343,  2.1102, -0.8587],\n",
            "        [ 0.8010, -2.7569, -2.9712,  ..., -0.0582,  1.1744, -0.3148],\n",
            "        ...,\n",
            "        [-4.9404, -3.5383, -0.3256,  ..., -3.6157,  0.0057,  1.2055],\n",
            "        [-3.0359,  2.2755, -0.8766,  ..., -1.6160,  1.4992,  1.4347],\n",
            "        [ 1.0781,  3.2917, -1.0680,  ..., -2.0769,  0.6464,  2.5658]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2704, -2.9987, -3.6689,  ..., -0.1150,  4.7385,  2.3188],\n",
            "        [-0.2960,  5.9492, -2.2500,  ..., -1.6388,  1.5230, -1.2286],\n",
            "        [-3.3501,  0.5684, -2.3849,  ...,  0.1036,  5.3579,  0.7958],\n",
            "        ...,\n",
            "        [ 2.2783,  1.1325, -1.1538,  ..., -1.1191,  1.5624, -1.4653],\n",
            "        [-2.2300, -1.6408, -4.7035,  ..., -1.9717,  3.9014,  5.1694],\n",
            "        [ 1.9401,  3.7581, -1.6756,  ..., -1.2939, -0.2065,  1.2020]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8043,  1.4162, -0.8431,  ..., -1.7729,  2.4269,  2.5658],\n",
            "        [ 0.6415,  2.7662, -4.1871,  ..., -1.1255, -0.2927,  1.8475],\n",
            "        [ 1.5609,  4.5787, -1.1680,  ..., -1.6082,  0.7668,  1.6571],\n",
            "        ...,\n",
            "        [-2.5246,  2.1591, -3.2395,  ..., -1.0123,  0.7775, -1.6727],\n",
            "        [-1.1881, -0.4900, -3.5065,  ...,  1.1478,  1.1216, -1.2545],\n",
            "        [-0.2369,  0.8586, -2.4265,  ..., -1.6363,  4.3069,  0.7449]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0813,  4.6839, -2.9117,  ..., -0.9008,  0.7128, -1.1466],\n",
            "        [-2.3822, -3.3309, -3.2252,  ..., -3.5352,  3.1182, -1.1458],\n",
            "        [-2.6487, -0.1349, -1.8299,  ...,  0.6078,  1.4393,  0.4861],\n",
            "        ...,\n",
            "        [ 1.5323,  2.2543, -1.3637,  ..., -2.1594,  0.9685,  2.3966],\n",
            "        [ 1.7613,  4.7780, -2.0119,  ..., -1.7614, -0.5787,  1.7095],\n",
            "        [ 1.2920,  3.5742, -2.4179,  ..., -1.7944,  6.6079,  0.1837]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9802,  2.7919, -2.4446,  ..., -1.9399, -0.9577, -0.2350],\n",
            "        [-1.8628,  2.1676, -3.0203,  ..., -1.8459, -2.2389, -1.3263],\n",
            "        [-0.8714,  3.6374, -2.4981,  ..., -0.9675,  0.6270, -1.3304],\n",
            "        ...,\n",
            "        [-2.7823, -1.8653, -4.0666,  ...,  0.5973,  5.3052,  1.5031],\n",
            "        [-1.4825,  0.4998, -3.3179,  ..., -1.4127,  2.6635,  0.4603],\n",
            "        [-3.5612, -1.4599, -4.2506,  ..., -0.3230,  4.1205,  1.6925]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8658e+00,  2.3199e+00, -4.5349e+00,  ..., -1.0582e+00,\n",
            "          3.3643e+00, -1.6707e+00],\n",
            "        [-3.8621e+00, -2.3744e+00, -5.0538e+00,  ..., -4.4680e+00,\n",
            "         -2.4776e+00,  2.3461e+00],\n",
            "        [-1.6664e+00, -9.9067e-04, -7.0146e-01,  ..., -1.7424e+00,\n",
            "         -7.5147e-01,  1.9476e+00],\n",
            "        ...,\n",
            "        [-2.6438e+00, -2.5424e+00, -4.5664e+00,  ..., -2.1171e+00,\n",
            "          1.2415e+00,  1.0943e+00],\n",
            "        [-3.5412e+00, -1.6498e+00, -5.0893e+00,  ..., -4.6261e+00,\n",
            "         -1.5846e+00,  4.0148e+00],\n",
            "        [-1.5714e+00,  4.0978e+00, -2.2243e+00,  ...,  4.8762e-01,\n",
            "          1.0894e+00, -2.4686e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7399,  6.2714, -3.7731,  ..., -1.6232,  0.3677, -1.4886],\n",
            "        [-1.1146,  2.7484, -2.7070,  ..., -2.3904, -1.0923,  0.1146],\n",
            "        [ 0.1481,  4.0609, -0.8104,  ...,  1.2585, -0.2669, -1.5082],\n",
            "        ...,\n",
            "        [-0.9239, -0.4780, -2.6635,  ..., -1.6992,  4.4157,  1.1105],\n",
            "        [ 0.3084,  0.3790, -3.2316,  ..., -0.2932,  1.5621,  1.3608],\n",
            "        [-1.7891,  1.3487, -4.1624,  ...,  0.0421,  0.7633, -0.7035]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1519, -0.2906, -1.5187,  ..., -2.7466,  0.2213,  2.6930],\n",
            "        [ 0.9128,  3.4655, -2.6843,  ..., -0.6179,  4.4414, -1.0692],\n",
            "        [-1.8548,  5.1197, -3.1782,  ..., -0.4221,  0.2417, -1.1141],\n",
            "        ...,\n",
            "        [-2.3140, -4.8786, -4.0541,  ..., -4.4644,  2.7343, -1.3890],\n",
            "        [ 0.0310, -1.7686, -1.6526,  ..., -0.2138,  1.2093, -2.5749],\n",
            "        [-2.4607,  3.7922, -2.4221,  ..., -0.9622, -2.0840, -0.5929]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1880,  3.0289, -2.3871,  ...,  1.0049, -2.2057,  0.3239],\n",
            "        [-0.6590, -3.0218, -2.0438,  ..., -3.6817,  1.5262,  3.7521],\n",
            "        [ 0.6214, -0.3961, -2.9433,  ..., -2.3500,  4.4365, -0.1380],\n",
            "        ...,\n",
            "        [ 2.0138,  2.5398, -1.6131,  ..., -2.3847,  6.7998,  0.1062],\n",
            "        [-1.4788,  1.7212, -1.4416,  ..., -2.8637, -0.3368,  0.9169],\n",
            "        [-3.1686, -2.8780, -1.3487,  ..., -0.8740,  0.7837,  0.3558]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1295, -0.5476, -0.7753,  ..., -1.0055,  1.7099, -0.7401],\n",
            "        [ 0.1727, -1.6775, -2.5309,  ..., -2.7461,  2.2476, -2.2634],\n",
            "        [ 1.7898,  5.4389, -1.9489,  ..., -1.4396,  0.8438,  1.0687],\n",
            "        ...,\n",
            "        [-2.5385, -2.3132, -1.2407,  ..., -3.1577, -1.6948,  2.4308],\n",
            "        [-1.6099, -1.6070, -0.4778,  ..., -2.4669,  1.1275,  4.8643],\n",
            "        [-1.2807, -0.9151, -4.0611,  ...,  0.0253,  1.0415,  0.4436]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9807,  0.3041, -1.0821,  ..., -1.7320, -1.1935,  1.8650],\n",
            "        [-0.1720,  5.1409, -2.7173,  ..., -1.1843, -0.3718, -0.1839],\n",
            "        [ 0.8731,  3.6742, -0.1140,  ..., -1.1157,  0.7987,  0.9516],\n",
            "        ...,\n",
            "        [-1.1140, -2.6776, -1.3995,  ..., -3.3748,  0.1191, -0.5960],\n",
            "        [-1.2908, -3.2703, -5.3940,  ..., -1.8703,  4.0937,  0.9986],\n",
            "        [-1.7162,  3.1122, -3.6137,  ..., -1.2566, -0.8495,  0.4612]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0750,  2.6796, -2.6266,  ..., -2.3842, -1.6026,  1.6701],\n",
            "        [-1.5372, -1.1983, -0.2380,  ..., -1.4127, -0.8092,  0.3468],\n",
            "        [-1.5033,  2.0836, -2.4648,  ..., -0.8654,  2.8516,  2.1061],\n",
            "        ...,\n",
            "        [ 0.8619,  5.8398, -2.5727,  ..., -1.4118, -0.0541,  0.6063],\n",
            "        [ 1.2997,  0.5350, -4.1887,  ..., -0.3893,  0.0174, -1.8435],\n",
            "        [-0.4927,  2.6847, -2.5634,  ...,  0.7144, -0.8431, -0.4638]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3966,  4.1126, -2.0570,  ..., -1.7853, -0.1327, -0.3889],\n",
            "        [-1.9957, -0.3417, -1.0904,  ..., -0.4104,  0.5488,  1.3085],\n",
            "        [ 1.0645,  0.7701, -1.7940,  ..., -3.6975, -0.1382,  3.9702],\n",
            "        ...,\n",
            "        [ 0.8166,  4.5598, -0.5121,  ..., -1.3714,  0.0603,  1.0980],\n",
            "        [ 0.2166,  0.3715, -0.4078,  ..., -2.6341,  0.9623,  2.3146],\n",
            "        [-1.9591, -4.0608, -3.6065,  ..., -3.2933,  2.7575,  2.3574]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9484,  5.8601, -1.7392,  ..., -2.0152,  0.0320,  2.2716],\n",
            "        [ 1.5094,  1.9720, -0.9983,  ..., -1.5887, -0.1515,  0.1764],\n",
            "        [ 0.1140,  0.4810, -1.8847,  ..., -1.1824,  2.5904,  0.2829],\n",
            "        ...,\n",
            "        [-4.4245, -1.8250, -1.0255,  ..., -1.6970, -1.4945,  0.6239],\n",
            "        [ 2.1004,  4.7362, -1.3816,  ..., -1.4964,  0.3257,  2.4336],\n",
            "        [-2.4008, -1.4035, -0.3430,  ..., -0.0796, -1.8640, -0.3822]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2357,  3.0450, -1.7847,  ..., -2.8031, -1.1264,  1.2221],\n",
            "        [ 1.3118,  2.4576, -3.9222,  ...,  0.9785, -0.6181, -0.3326],\n",
            "        [-1.4501,  2.3559, -1.2566,  ..., -0.0408, -2.2078,  1.0393],\n",
            "        ...,\n",
            "        [ 0.2131,  4.6999, -1.7605,  ..., -1.5459, -1.3292,  0.5166],\n",
            "        [-1.4258,  4.0344, -2.3185,  ...,  0.3686,  0.8054, -3.1099],\n",
            "        [ 0.1625,  0.6058, -1.4233,  ..., -0.6178,  2.5134, -0.8215]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2996,  2.8863, -1.6596,  ...,  0.7929, -1.0671, -0.0888],\n",
            "        [ 1.1750,  2.1245, -2.0451,  ...,  1.9981, -0.0928, -0.8799],\n",
            "        [-2.9887, -0.6620, -2.0711,  ..., -1.8186, -1.0386, -0.7297],\n",
            "        ...,\n",
            "        [-4.1786, -5.0827, -3.4439,  ..., -0.8484,  3.1780,  2.8418],\n",
            "        [-0.4394,  5.5022, -2.9448,  ..., -1.7004, -3.6251, -0.3266],\n",
            "        [ 1.0578, -0.4711, -2.3049,  ..., -0.3841,  4.0513,  1.7034]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8415,  1.0422, -0.5284,  ..., -1.4266, -0.0938,  3.1841],\n",
            "        [-2.8560, -6.1815, -5.4073,  ..., -3.6723,  2.8359,  6.0928],\n",
            "        [ 0.5925,  3.4166, -1.6855,  ..., -2.8413,  0.6061,  1.4807],\n",
            "        ...,\n",
            "        [ 0.7565, -0.0670, -0.9028,  ...,  1.3874, -0.2330,  0.0164],\n",
            "        [-1.7292, -2.0907, -3.2287,  ..., -2.2405,  1.6965,  3.2541],\n",
            "        [-2.2557, -2.9617,  1.4219,  ..., -1.9094, -0.3958,  1.5908]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7711,  4.0221, -2.1415,  ...,  1.3182, -1.3998, -2.9105],\n",
            "        [ 0.7324,  2.4116, -2.7525,  ..., -2.5202, -0.9107,  0.3925],\n",
            "        [ 0.5177,  4.3164, -3.2423,  ..., -3.7373, -2.4221, -0.6495],\n",
            "        ...,\n",
            "        [ 0.3126, -0.6145, -0.9453,  ..., -0.8429,  1.5693,  1.8194],\n",
            "        [-0.3307, -0.1032, -1.4615,  ..., -0.4353, -0.7326,  3.3408],\n",
            "        [-0.0556,  2.9719, -3.4360,  ...,  0.3814,  1.6007, -1.9823]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8454,  2.1163, -1.2338,  ..., -0.8461,  0.3212,  1.0356],\n",
            "        [-1.5663,  1.0016, -2.4201,  ..., -0.8344,  1.0151,  1.7216],\n",
            "        [ 1.7850,  2.0352, -0.5254,  ..., -1.6114,  0.1085,  0.9238],\n",
            "        ...,\n",
            "        [ 0.1116,  3.6869, -4.2613,  ..., -1.0975, -2.4548, -0.6673],\n",
            "        [-0.0737, -0.5326, -0.3904,  ..., -1.0981, -1.4930,  1.1264],\n",
            "        [ 2.4382,  4.5985, -1.8999,  ..., -1.8964, -0.7471,  2.3197]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1411, -0.6191, -2.1247,  ..., -1.7005,  2.6566, -0.4578],\n",
            "        [ 2.7747,  4.1404, -5.5346,  ..., -2.2512, -0.8898,  1.6556],\n",
            "        [-0.6917,  0.1241, -0.0526,  ..., -2.0748, -0.3767,  1.4580],\n",
            "        ...,\n",
            "        [-1.0440,  1.1927, -0.9166,  ..., -3.9153, -1.1557,  1.9524],\n",
            "        [ 0.9999,  3.6037, -1.5972,  ..., -1.0695,  0.8440, -0.6595],\n",
            "        [ 2.9928,  5.0180, -2.2979,  ..., -1.3045, -0.1057,  2.2507]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1442,  3.5606, -2.2431,  ..., -0.4213,  1.6888, -0.4372],\n",
            "        [-4.0972, -2.3916, -1.7488,  ..., -1.9714, -0.0728, -0.9181],\n",
            "        [-0.2441, -3.8156, -4.6176,  ..., -2.2039,  7.0798,  3.2578],\n",
            "        ...,\n",
            "        [ 0.3044, -1.0126, -1.7165,  ..., -2.4317, -1.1272, -0.1781],\n",
            "        [-2.0657, -1.9185, -3.4092,  ..., -3.6841,  3.0457,  4.8054],\n",
            "        [-3.9351, -1.0793,  0.3562,  ..., -1.7991,  0.7210,  2.1048]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3438,  3.6236, -2.5950,  ..., -1.4072,  2.7009,  2.8377],\n",
            "        [-1.3628, -0.0311, -0.9236,  ..., -0.2391,  1.5620,  0.6649],\n",
            "        [-0.9223, -2.2231, -3.5638,  ..., -0.2891,  3.4079, -0.1992],\n",
            "        ...,\n",
            "        [ 1.5740,  0.5918, -2.2311,  ..., -1.2678,  2.3095,  1.1219],\n",
            "        [ 1.5436,  2.0368, -0.6575,  ..., -1.5750,  0.0071,  2.3284],\n",
            "        [-0.7154,  0.3530, -4.8085,  ...,  0.7366, -2.0023, -1.9142]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4200,  1.9815, -2.3901,  ..., -2.4689,  2.4053, -0.8849],\n",
            "        [-1.9518,  1.7314, -3.1701,  ...,  2.7226,  0.0660, -3.2203],\n",
            "        [-0.0936, -2.9777, -2.9811,  ..., -3.5335,  4.1915,  3.2088],\n",
            "        ...,\n",
            "        [ 0.4471, -0.6911, -1.1657,  ..., -1.4543, -2.3856,  1.7371],\n",
            "        [-2.3157,  0.9576, -1.8470,  ..., -0.0946,  0.8642,  1.0873],\n",
            "        [ 3.2296,  5.1064, -1.7204,  ..., -1.6572, -0.1320,  1.7764]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3646,  5.0399, -3.4458,  ..., -1.7504,  0.0999, -1.0225],\n",
            "        [ 0.7418,  3.1579, -2.7644,  ..., -1.9728,  1.8214,  0.3395],\n",
            "        [ 2.5004,  1.1702, -3.4576,  ..., -1.0372,  4.0877, -0.2461],\n",
            "        ...,\n",
            "        [-1.1014,  1.1320, -2.9864,  ..., -0.5253, -0.4971, -1.3146],\n",
            "        [ 0.9668,  1.0605, -1.9999,  ..., -1.7696, -1.2934,  1.4048],\n",
            "        [-1.7648,  2.9473, -0.6227,  ..., -2.7097, -1.5747,  1.4184]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2078e+00,  1.1281e-01, -2.5744e-01,  ..., -3.2097e+00,\n",
            "         -1.0275e+00,  1.1797e+00],\n",
            "        [ 2.1168e+00, -5.7645e-01, -1.7530e+00,  ..., -2.0790e+00,\n",
            "          3.1884e+00,  6.1423e-01],\n",
            "        [-1.0671e+00,  1.3031e+00, -2.7248e+00,  ..., -1.7878e+00,\n",
            "         -1.0412e-01, -1.7614e-02],\n",
            "        ...,\n",
            "        [ 2.3832e-03,  5.1148e+00, -2.8376e+00,  ..., -6.1823e-01,\n",
            "         -1.5913e+00,  1.9799e-01],\n",
            "        [ 1.6206e+00,  4.6503e+00, -2.7869e+00,  ..., -1.7574e+00,\n",
            "         -2.8086e-01,  5.8701e-01],\n",
            "        [-3.7246e-01,  1.9249e+00, -2.5196e+00,  ..., -1.8422e+00,\n",
            "         -2.8727e+00, -1.8752e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1234,  3.7256, -2.9391,  ..., -3.2246, -1.9349, -1.0723],\n",
            "        [ 0.0379, -1.4129, -0.7129,  ..., -2.0365, -0.8943,  1.8551],\n",
            "        [ 2.3328, -1.0797, -2.6215,  ..., -1.9272,  2.0321, -1.3136],\n",
            "        ...,\n",
            "        [ 1.8507,  2.3067, -2.8127,  ..., -1.9885,  2.8532,  1.0183],\n",
            "        [ 2.3475, -3.7752, -1.2088,  ..., -0.4086,  4.5659, -0.4555],\n",
            "        [ 0.2857,  4.3430, -1.9890,  ...,  1.3625, -1.6246, -2.6274]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5873,  2.7746, -5.6348,  ...,  2.6105,  1.3637,  0.3804],\n",
            "        [-1.2225, -2.7338, -1.3827,  ...,  0.0730,  0.9769,  1.8491],\n",
            "        [-1.6987,  2.9877, -3.7502,  ...,  2.6552, -0.2146, -0.9004],\n",
            "        ...,\n",
            "        [-2.7638, -1.2871, -0.1340,  ..., -2.5002, -0.3043,  0.9943],\n",
            "        [-0.4353, -1.8350, -3.1955,  ..., -0.9456,  3.2951,  1.5747],\n",
            "        [-1.7428,  0.4653, -2.6873,  ...,  0.5234, -1.3611, -1.3583]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1247,  2.6890, -3.8763,  ..., -3.3257, -1.4464,  2.0275],\n",
            "        [ 1.2580,  4.6442, -2.6112,  ..., -0.7739,  0.8170,  1.6468],\n",
            "        [-1.9893, -4.5368, -2.7886,  ..., -2.4089,  1.3947,  0.1591],\n",
            "        ...,\n",
            "        [-2.0333, -0.0431, -0.3027,  ..., -2.9096, -0.2148,  1.2224],\n",
            "        [ 1.9890, -0.3678, -3.3520,  ..., -3.6573,  8.0485,  2.7526],\n",
            "        [-0.0101, -8.5844, -4.0802,  ..., -1.2392, -0.3871,  1.0022]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1187,  0.3324, -1.6834,  ..., -2.4758,  1.6654,  1.8132],\n",
            "        [ 1.8037, -2.5340, -0.2831,  ..., -0.4158,  0.7453, -0.4788],\n",
            "        [-2.7963,  2.5555, -2.6242,  ..., -1.0592,  1.3618,  1.3593],\n",
            "        ...,\n",
            "        [-3.2792, -2.9551, -0.8224,  ..., -1.5740,  1.7427,  3.2691],\n",
            "        [ 4.1352,  0.1086, -1.6273,  ..., -2.8698,  0.5031, -0.4249],\n",
            "        [-1.2260, -0.7242, -2.5881,  ..., -1.6175, -0.9981,  1.4951]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5628, -7.6265, -4.8164,  ..., -3.6567,  0.2118,  1.8078],\n",
            "        [ 3.5970,  2.8749, -0.7473,  ..., -1.0611, -0.4705,  1.8851],\n",
            "        [-0.5967, -0.3774, -1.8723,  ..., -2.8448,  1.5382, -1.4965],\n",
            "        ...,\n",
            "        [-0.8438,  1.1382, -3.0059,  ..., -0.2943,  0.8073, -2.4052],\n",
            "        [-1.6826,  1.7734, -2.5149,  ..., -1.0133,  0.3380,  0.3521],\n",
            "        [-0.9215,  5.4351, -3.6653,  ..., -0.9908,  0.0366, -1.1298]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1295,  2.5839, -1.3492,  ...,  0.7036,  0.0734, -2.1443],\n",
            "        [ 0.8665,  3.0480, -2.1180,  ..., -1.3542, -3.9424, -0.3946],\n",
            "        [-0.1397, -5.8300, -4.8080,  ..., -3.1282, -1.8601, -0.5810],\n",
            "        ...,\n",
            "        [-2.3884,  0.0601, -2.0643,  ..., -0.3288, -0.2157,  2.5813],\n",
            "        [-1.4749, -3.1354, -4.2572,  ..., -3.4158,  3.2110,  5.7258],\n",
            "        [ 0.2666,  1.9241, -2.2137,  ..., -1.3501,  2.9510,  2.8919]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1712,  5.4404, -3.5879,  ..., -0.5281,  1.7369, -2.1241],\n",
            "        [-1.2804,  3.8204, -2.5864,  ..., -1.7215, -1.0906, -2.7239],\n",
            "        [-1.8197, -4.4276, -4.7269,  ...,  1.1200,  1.1466, -1.0768],\n",
            "        ...,\n",
            "        [-0.7275, -1.1530, -1.7815,  ..., -2.3094,  2.5894,  1.5561],\n",
            "        [-0.2937,  5.0904, -3.3381,  ..., -0.6304,  1.7469, -1.6340],\n",
            "        [-0.4441,  3.0290, -1.2989,  ..., -0.0814, -1.6499, -3.1491]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8381e+00,  3.7245e+00, -1.5653e+00,  ..., -1.9515e+00,\n",
            "         -3.8916e-02,  2.0336e+00],\n",
            "        [-3.5131e+00, -6.4125e-01, -2.8576e+00,  ...,  1.7209e+00,\n",
            "         -1.1764e+00, -2.0201e+00],\n",
            "        [-7.6756e-01,  2.6369e+00, -2.5580e+00,  ..., -5.6198e-01,\n",
            "         -4.7117e-01, -1.5519e+00],\n",
            "        ...,\n",
            "        [-5.0645e-01, -9.0052e+00, -2.7782e+00,  ..., -1.3030e+00,\n",
            "          7.8850e-01,  3.8356e+00],\n",
            "        [ 1.3766e+00,  2.8065e+00, -2.8313e+00,  ..., -7.9434e-01,\n",
            "         -9.1989e-01, -6.8479e-01],\n",
            "        [ 1.9750e+00,  2.8449e+00, -2.5257e+00,  ...,  1.2867e+00,\n",
            "         -7.0716e-03, -5.6903e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5135,  1.5489, -2.9175,  ..., -1.7060, -0.2449,  1.9142],\n",
            "        [-0.3730,  0.9058, -0.0526,  ..., -2.6679,  2.1689,  0.5226],\n",
            "        [-1.4006, -5.1268, -3.7435,  ..., -4.7159,  4.3038,  4.3509],\n",
            "        ...,\n",
            "        [-4.4057, -1.5646, -4.1072,  ..., -4.4280, -0.5283,  1.2970],\n",
            "        [-0.5949,  1.0015, -3.9736,  ..., -1.8440, -1.2519,  1.3764],\n",
            "        [ 0.5034,  3.6302, -1.4441,  ...,  0.9741, -0.7097, -2.7192]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8132, -0.6195, -1.6750,  ..., -0.7062, -1.1927,  1.1296],\n",
            "        [ 1.9173,  2.6940, -1.5507,  ..., -2.4737,  0.4596,  1.7550],\n",
            "        [-1.9335, -1.3643, -3.0408,  ..., -1.4699,  0.6281,  1.9181],\n",
            "        ...,\n",
            "        [-1.6045,  0.4902, -2.4710,  ..., -1.2909, -2.6705,  2.0459],\n",
            "        [ 2.7309,  4.4520, -1.1378,  ..., -1.3617, -0.0183,  1.3478],\n",
            "        [-1.4592,  0.2457, -1.6126,  ..., -1.1445, -2.3838,  0.5119]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8911,  1.9271, -2.3292,  ..., -0.7079, -2.4900, -0.2912],\n",
            "        [-3.8308, -5.7160, -0.6557,  ..., -4.6991, -0.4744,  4.4545],\n",
            "        [-0.1359, -2.6748, -3.4890,  ..., -2.9069,  5.5808,  2.4997],\n",
            "        ...,\n",
            "        [ 1.9133,  0.5223, -2.3602,  ..., -3.7082,  5.0430, -2.0751],\n",
            "        [-1.0869,  5.3393, -3.0632,  ..., -2.0645, -0.2808, -1.2800],\n",
            "        [-0.8034,  4.7920, -2.4287,  ..., -0.5000, -0.6803, -0.1767]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4078,  1.3015, -1.4633,  ..., -2.5583,  4.6429, -0.3914],\n",
            "        [-1.8945, -1.1029, -1.3791,  ..., -1.3761, -0.3342,  0.3606],\n",
            "        [-2.3855, -1.9714,  0.0815,  ..., -4.2163,  2.4500,  3.4150],\n",
            "        ...,\n",
            "        [ 2.1375,  0.0751, -1.4775,  ..., -2.6363,  7.6839,  0.9412],\n",
            "        [-0.4857, -5.3072, -0.5435,  ..., -2.6189, -1.7500, -0.4859],\n",
            "        [-0.9242, -1.9376, -1.2300,  ..., -1.4824, -2.3586,  1.1211]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9517,  0.5239, -3.4407,  ...,  0.0880,  0.0706,  0.9939],\n",
            "        [ 0.0470,  4.0443, -2.2879,  ..., -1.5325, -0.6426, -0.8206],\n",
            "        [-2.9447, -1.7069, -1.8361,  ..., -1.8468,  0.1032, -0.8063],\n",
            "        ...,\n",
            "        [ 1.6073,  0.7439, -2.2882,  ..., -2.0272,  0.4394,  1.9483],\n",
            "        [ 0.5165,  3.2495, -1.5659,  ..., -2.3840,  1.9834,  3.4064],\n",
            "        [ 2.5367,  2.9796, -2.3320,  ..., -0.8245,  0.1418,  2.7809]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8886,  3.8928, -2.9101,  ...,  0.1261, -0.2485, -3.2527],\n",
            "        [ 0.7053,  1.9791, -2.0856,  ...,  1.1910,  0.1796, -0.9193],\n",
            "        [-5.5374, -6.5781, -1.5500,  ..., -2.0453,  0.5010, -1.4194],\n",
            "        ...,\n",
            "        [ 0.6168, -0.5364, -1.4563,  ..., -2.3967, -0.6671,  2.1427],\n",
            "        [ 1.3833, -0.0384, -2.8156,  ..., -0.0815,  4.5483,  2.6525],\n",
            "        [ 0.2890,  2.0799, -1.8224,  ..., -1.9263, -2.1949, -0.7861]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-7.4748, -4.5796, -2.6870,  ..., -4.4458, -0.8259,  1.2057],\n",
            "        [-0.1137, -1.4652, -2.7177,  ..., -2.7662,  4.9003, -0.8720],\n",
            "        [-1.2420,  4.9562, -1.6749,  ..., -1.4849, -2.0428, -0.7416],\n",
            "        ...,\n",
            "        [-4.3071, -3.1998, -1.2799,  ..., -0.1003, -1.3737, -1.7385],\n",
            "        [ 0.9248,  2.4665, -0.5845,  ..., -1.2350, -0.1894,  1.3600],\n",
            "        [-0.3693,  2.6206, -3.4168,  ..., -0.1946,  0.2290, -0.0258]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4823,  4.3847, -1.9508,  ...,  0.5148, -0.4731, -2.0462],\n",
            "        [-0.8483,  4.4965, -2.0659,  ..., -0.7396, -2.9046, -0.3132],\n",
            "        [-0.7834,  1.9335, -0.9995,  ..., -0.0312,  0.3498, -0.3234],\n",
            "        ...,\n",
            "        [-0.0575,  1.6404, -2.0144,  ..., -2.6649, -3.7515,  1.1204],\n",
            "        [ 2.4308,  1.2412, -3.6701,  ..., -0.0455, -0.6801,  0.5882],\n",
            "        [-0.7364, -0.7346,  0.1970,  ..., -1.7092, -0.2118,  0.9744]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2268, -3.6520, -4.3332,  ..., -4.3819,  2.3011,  2.7337],\n",
            "        [ 0.6997,  3.7950, -3.3167,  ..., -1.1534, -1.6198, -0.6191],\n",
            "        [-1.5551,  1.4900, -2.4597,  ..., -0.8293,  1.6761, -0.1350],\n",
            "        ...,\n",
            "        [ 0.3749,  3.7535, -3.4141,  ..., -0.7183, -1.1831,  0.3648],\n",
            "        [-2.7131,  2.3368, -1.5573,  ..., -2.2119, -0.7858,  1.1039],\n",
            "        [-0.0568,  0.9310, -0.7988,  ..., -1.1339, -1.0974,  0.4915]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7533,  4.1011, -4.0030,  ..., -0.3046,  0.1325,  0.5366],\n",
            "        [-0.8580,  1.6090, -2.3956,  ...,  1.2874,  1.1624, -2.0958],\n",
            "        [-2.3026, -2.1270, -1.6263,  ...,  0.7919,  1.8644,  0.9490],\n",
            "        ...,\n",
            "        [-0.1164,  0.7563, -1.9769,  ..., -2.1035,  1.0530,  1.5260],\n",
            "        [-1.5987,  3.2176, -2.2424,  ..., -1.4879, -2.3144, -2.1596],\n",
            "        [ 1.3540,  0.3776, -1.0788,  ..., -1.9759,  1.3487,  2.1269]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9741,  0.6900, -0.7978,  ..., -1.5007, -1.6704,  1.0656],\n",
            "        [ 0.6778,  3.6091, -3.1579,  ..., -0.3371,  0.5331, -0.1083],\n",
            "        [-1.0858, -0.3424,  0.6775,  ..., -3.1875,  1.2908,  2.9726],\n",
            "        ...,\n",
            "        [-0.7650, -1.5661, -4.9241,  ..., -3.5917, -1.6746,  0.6300],\n",
            "        [-2.0915, -0.5503, -1.2173,  ..., -2.4916, -0.6871,  3.9697],\n",
            "        [-3.4575, -2.2307, -1.5843,  ..., -1.7593, -1.0554,  0.6883]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6205,  1.3668, -1.3102,  ..., -2.2478,  0.3496,  1.5308],\n",
            "        [-0.4586,  0.5938, -2.8659,  ..., -1.6014,  2.2223, -2.2191],\n",
            "        [ 2.2150,  4.1511, -2.5866,  ..., -1.4483, -0.4015,  0.0226],\n",
            "        ...,\n",
            "        [-1.8739,  5.7684, -4.7975,  ..., -1.9471, -2.7736,  0.7503],\n",
            "        [ 0.9814, -1.8562, -4.5899,  ..., -2.5517,  1.6145, -0.7460],\n",
            "        [-2.2782, -1.8800, -1.1963,  ..., -2.1063, -1.0458, -0.5097]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6844, -0.6865, -0.3901,  ..., -0.2514,  0.6459, -1.3604],\n",
            "        [-0.2198,  1.3354, -1.0087,  ..., -3.3954,  2.0569,  2.5180],\n",
            "        [-0.6750,  4.6777, -4.1722,  ..., -0.9391, -0.9177, -2.1876],\n",
            "        ...,\n",
            "        [-0.3253,  4.5984, -3.1836,  ..., -1.4439,  0.5131, -0.9584],\n",
            "        [-0.5945,  4.2589, -1.5261,  ..., -0.8393, -0.1727, -1.9275],\n",
            "        [ 1.3388,  1.2368, -2.3869,  ..., -2.4967,  3.9369,  0.5535]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4583,  4.2972, -1.9467,  ..., -1.5393, -0.3441, -0.8321],\n",
            "        [-1.8767,  5.1129, -2.2896,  ..., -0.9237,  0.2615, -1.4311],\n",
            "        [-0.4367,  5.0066, -2.9103,  ..., -2.0414,  0.8782, -0.1270],\n",
            "        ...,\n",
            "        [-0.6918,  0.0190, -0.7657,  ..., -0.2656,  1.6175,  0.1963],\n",
            "        [-1.2119,  0.5433, -3.1435,  ..., -0.2682, -0.2517,  1.7921],\n",
            "        [-1.5312,  1.2602, -3.8067,  ..., -2.3893,  1.0214,  0.1482]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9895, -2.2489, -2.2414,  ..., -1.7067, -2.0511,  0.6493],\n",
            "        [-0.7719,  0.8556, -2.7577,  ..., -2.3401,  0.4133,  1.1028],\n",
            "        [-0.8806,  1.5385, -2.7259,  ..., -1.2620, -0.0275, -1.6528],\n",
            "        ...,\n",
            "        [ 0.3831, -4.1830, -2.6934,  ..., -1.9909,  2.2408,  0.3605],\n",
            "        [ 1.3139,  1.2059, -3.0423,  ..., -0.1241,  0.0708, -0.9117],\n",
            "        [ 2.9348, -0.2733, -2.5975,  ..., -2.3935,  6.3239,  0.9477]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1843,  5.3249, -2.0400,  ..., -2.0054, -0.4113, -1.5238],\n",
            "        [-3.1651, -5.2612, -1.2216,  ..., -2.5166, -0.9199, -1.0386],\n",
            "        [-0.5897,  4.9845, -2.0862,  ..., -1.8344, -0.6862,  0.0353],\n",
            "        ...,\n",
            "        [-1.4914, -4.7341, -2.5608,  ..., -1.7171,  2.7137,  0.1078],\n",
            "        [-0.6654,  1.4088, -3.1100,  ..., -2.8027,  3.2539, -0.2893],\n",
            "        [-1.4096, -2.1585, -1.9159,  ..., -3.4806, -1.2736,  0.0233]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8426,  2.3196, -1.7577,  ...,  3.1820,  0.2515, -3.7311],\n",
            "        [-0.6172,  1.5844, -3.0569,  ..., -1.5666, -1.7746, -0.5528],\n",
            "        [-1.0966, -0.6760, -2.7295,  ..., -3.3777,  3.2829,  1.1397],\n",
            "        ...,\n",
            "        [ 0.2992,  4.2822, -2.7575,  ..., -1.8350, -2.0545, -0.8512],\n",
            "        [-1.7917, -2.0410,  0.0554,  ..., -2.4706, -0.2104,  4.0728],\n",
            "        [-3.5535, -4.6693, -3.1259,  ..., -6.4733,  1.7531, -1.5837]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6306,  0.0229, -1.7838,  ..., -1.5837,  5.3448,  0.5284],\n",
            "        [-1.4360, -1.8514, -3.7630,  ...,  2.3413, -1.9890, -3.0262],\n",
            "        [ 2.1065, -1.0494, -3.4679,  ..., -3.2979,  7.8916, -1.3388],\n",
            "        ...,\n",
            "        [-0.5365, -0.9638, -6.6102,  ..., -3.1364,  5.4732,  2.4272],\n",
            "        [ 1.5205,  3.7548, -3.7463,  ..., -1.8239, -0.8477,  0.0962],\n",
            "        [-2.4036, -1.1483, -3.7726,  ..., -1.9671,  0.6488, -1.3864]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8446, -0.8029, -3.2694,  ..., -0.9431, -0.0551, -0.2968],\n",
            "        [ 1.3828,  0.6754, -1.7525,  ..., -2.8336,  5.8895,  0.4530],\n",
            "        [-0.7084,  3.8345, -1.6409,  ..., -2.7910, -1.6322, -0.0251],\n",
            "        ...,\n",
            "        [-2.7720, -3.0570, -2.9952,  ..., -0.4008, -0.5051, -1.9333],\n",
            "        [-0.9061, -3.5345, -2.5720,  ..., -0.2306,  4.1395, -0.5794],\n",
            "        [-0.8212, -1.3691, -3.2826,  ...,  1.2989,  0.3009, -2.6123]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.6177, -1.2096, -2.9482,  ...,  1.0522,  1.1949, -1.7906],\n",
            "        [-2.3293,  0.2359, -2.1181,  ..., -2.2068,  0.7188,  1.2749],\n",
            "        [-1.2010,  0.8081, -1.6959,  ..., -1.8148, -0.4704,  0.2473],\n",
            "        ...,\n",
            "        [-1.9087, -2.8164,  0.2867,  ..., -1.9802, -0.9885,  0.6660],\n",
            "        [-0.3554,  1.7465, -1.9941,  ..., -1.5382, -2.1406, -1.2613],\n",
            "        [ 1.7843, -0.1558, -4.2957,  ..., -3.4053,  6.6364,  0.6571]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3362,  2.2515, -3.8701,  ..., -1.3900,  0.0159, -2.3174],\n",
            "        [-2.8277, -2.0151, -0.6808,  ..., -0.5273, -0.4995,  0.7277],\n",
            "        [-2.7419, -4.2930, -3.8538,  ..., -4.1215,  0.6644, -4.3140],\n",
            "        ...,\n",
            "        [ 0.5552,  4.0652, -2.5569,  ..., -0.8828,  0.4604, -1.6275],\n",
            "        [ 1.6168,  0.8790, -2.2072,  ..., -2.9602, -0.1015,  2.3389],\n",
            "        [-1.1755,  4.3254, -3.1788,  ..., -0.1296,  1.2448, -1.2892]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1165,  1.8832, -2.8598,  ..., -0.3161,  0.3070,  0.4129],\n",
            "        [-1.4366,  2.4212, -4.5308,  ..., -0.4763, -4.5163, -1.1344],\n",
            "        [ 2.8669, -2.0652, -4.0488,  ..., -3.1886,  6.8969,  0.1578],\n",
            "        ...,\n",
            "        [-0.6075, -0.2048, -3.6224,  ..., -1.5773,  1.2621, -2.7583],\n",
            "        [ 2.1282, -3.0604, -2.5108,  ..., -3.6304, -0.0109, -0.3598],\n",
            "        [-1.1125, -0.9613, -1.4570,  ..., -2.0874,  1.2076, -0.5129]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6259, -2.4615, -3.2041,  ..., -3.5630, -1.5633,  3.0887],\n",
            "        [ 1.6917,  4.5769, -2.1457,  ..., -1.5971, -0.3959,  1.2153],\n",
            "        [-3.8195, -0.1146, -4.3633,  ..., -0.0684, -0.1574, -0.8034],\n",
            "        ...,\n",
            "        [-2.1504, -1.5889, -4.3046,  ..., -0.4374,  0.3154, -2.8147],\n",
            "        [-1.3868,  3.4214, -3.1278,  ..., -0.9921, -0.3731, -3.7845],\n",
            "        [-1.5142, -2.3678, -2.1281,  ..., -0.6204, -0.6443, -1.0760]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5956,  1.3821, -2.9780,  ..., -2.0887,  7.0547, -2.2226],\n",
            "        [ 0.7082,  2.8002, -2.0333,  ..., -0.6858,  2.2359,  0.2443],\n",
            "        [-1.2605, -1.2739, -2.9116,  ...,  2.1923,  0.5676, -1.6164],\n",
            "        ...,\n",
            "        [-4.8936, -3.8737, -2.6861,  ..., -2.1884, -1.2374, -1.1087],\n",
            "        [ 1.8878,  3.9391, -3.8309,  ...,  1.8388, -0.4447, -1.6346],\n",
            "        [-2.7169, -0.0695, -2.7479,  ..., -2.6269,  3.5329,  2.2335]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9630, -3.9018, -3.1210,  ..., -4.1945,  3.8878,  0.2483],\n",
            "        [-1.2134,  1.9690, -1.1092,  ..., -0.6504, -0.4074, -0.6040],\n",
            "        [-2.2652, -0.6591, -1.9410,  ..., -0.7031, -0.3113,  0.2119],\n",
            "        ...,\n",
            "        [-5.3180, -2.5710, -1.2833,  ..., -2.8949,  0.1878, -1.5495],\n",
            "        [-0.8119, -3.1052, -2.5839,  ...,  1.8069,  0.0535, -0.3176],\n",
            "        [-5.1514, -3.0275, -4.2866,  ..., -3.3947, -0.1840,  3.4911]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2044, -4.7445, -4.7735,  ..., -1.1615,  0.7388, -3.3854],\n",
            "        [-0.9454,  2.0965, -2.7196,  ...,  1.2203,  0.6753,  0.1457],\n",
            "        [-0.5385,  0.2954, -1.6545,  ..., -1.6393, -1.9410,  0.2518],\n",
            "        ...,\n",
            "        [-0.7037, -1.0165, -2.2526,  ..., -3.1331, -0.9748, -1.5737],\n",
            "        [-1.1696, -3.8218, -3.6597,  ..., -1.6891,  3.4172,  0.8402],\n",
            "        [-3.5949, -5.4557, -6.8908,  ..., -5.5031,  1.5255,  2.9418]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8509, -0.7759, -5.4706,  ..., -1.4527, -1.0204, -0.9775],\n",
            "        [ 0.8898,  3.7719, -2.4717,  ..., -1.4552,  3.6014,  2.2144],\n",
            "        [-5.1289, -4.5003, -2.8982,  ..., -0.5598,  2.3370, -0.7814],\n",
            "        ...,\n",
            "        [ 0.8820,  1.2223, -2.9165,  ..., -1.9354,  2.1351,  0.5770],\n",
            "        [-0.5554,  3.9913, -1.7695,  ...,  0.2196, -3.0678, -0.0497],\n",
            "        [ 0.7339, -2.5176, -2.3677,  ...,  1.0407, -0.0870, -2.1453]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9740e-01,  3.0990e+00, -1.7079e+00,  ..., -1.7867e+00,\n",
            "         -6.3283e+00, -8.2759e-01],\n",
            "        [-7.7800e-02,  3.5786e+00, -3.3652e+00,  ...,  2.9084e-02,\n",
            "          1.8038e+00, -1.6589e+00],\n",
            "        [-1.4094e+00, -1.0112e+00, -2.0937e+00,  ...,  3.5677e-01,\n",
            "          7.4919e-01,  1.6617e+00],\n",
            "        ...,\n",
            "        [-1.5601e+00,  3.2143e-01, -2.0503e+00,  ..., -3.7674e-01,\n",
            "          2.4573e+00, -6.8746e-06],\n",
            "        [ 6.5348e-02, -5.4913e-01, -6.6483e-01,  ..., -1.4294e+00,\n",
            "         -1.0331e+00,  3.3913e+00],\n",
            "        [-9.1790e-01, -7.8134e+00, -2.7661e+00,  ..., -1.8936e+00,\n",
            "         -1.7939e+00,  1.5807e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8048, -0.9357, -4.5612,  ..., -3.2586,  5.0758,  0.8933],\n",
            "        [-0.9857, -5.9971, -3.7483,  ..., -2.7008,  4.8809,  4.8588],\n",
            "        [ 0.6248,  4.4419, -1.6995,  ..., -1.7056, -0.3985, -0.5561],\n",
            "        ...,\n",
            "        [-2.8179, -1.4939, -5.0479,  ..., -0.6827,  3.1210, -2.8559],\n",
            "        [ 1.8700,  0.4073, -3.4340,  ..., -2.7522,  3.3816,  0.3073],\n",
            "        [-0.5447,  3.8328, -3.6175,  ..., -1.0659,  0.6189, -1.4579]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0925, -1.1841, -1.7541,  ..., -0.0125, -0.6185, -0.6578],\n",
            "        [-4.7008, -1.7611, -1.8439,  ..., -2.6771,  0.6807, -0.1404],\n",
            "        [ 0.2008,  4.3700, -2.4398,  ..., -0.2194, -1.8145, -0.4881],\n",
            "        ...,\n",
            "        [ 1.9967, -2.0977, -2.9751,  ..., -3.8059,  7.1883,  1.4634],\n",
            "        [-0.5682,  5.1390, -3.1234,  ..., -0.1728, -1.4960, -1.6452],\n",
            "        [-2.1877, -1.1351, -0.6904,  ..., -1.6967,  1.1734, -2.7112]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0854, -1.7394, -2.5883,  ..., -1.3280, -0.4207,  0.0141],\n",
            "        [ 0.6674, -2.1379, -2.0658,  ..., -2.6787,  0.4749,  2.0940],\n",
            "        [ 0.4976,  3.6391, -2.0978,  ..., -0.8724, -0.0561, -1.3641],\n",
            "        ...,\n",
            "        [ 1.3850,  0.6913, -3.0249,  ..., -1.2656, -1.1718, -0.2391],\n",
            "        [ 0.2572, -1.7924, -4.2351,  ..., -1.2887,  0.3466, -2.7323],\n",
            "        [-1.9586, -6.5150, -3.4069,  ..., -0.9292,  1.7366,  3.3372]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7043,  1.0387, -2.2202,  ..., -1.9681,  3.5345, -6.1770],\n",
            "        [ 1.0173,  2.0299, -2.5932,  ..., -2.6091, -0.1668, -2.0562],\n",
            "        [ 1.4637,  0.4652, -2.9055,  ..., -2.0050,  0.5581,  2.3144],\n",
            "        ...,\n",
            "        [ 1.2178,  2.2735, -2.9386,  ..., -0.2216, -1.2196, -2.5620],\n",
            "        [-1.3396, -1.3660,  1.2392,  ..., -2.1255, -0.5091,  0.4818],\n",
            "        [-2.1296, -3.2084, -5.7606,  ..., -4.1785, -0.5596,  2.5644]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8225,  4.3135, -3.6791,  ..., -1.6134,  1.5373,  0.2233],\n",
            "        [-1.5128,  1.2529, -3.5484,  ...,  2.2591, -1.5337, -1.5091],\n",
            "        [-3.2574, -2.8515, -1.9911,  ..., -0.2375,  3.2223,  3.2228],\n",
            "        ...,\n",
            "        [-1.5687,  1.1665, -0.5213,  ..., -0.7020, -2.2167,  1.3149],\n",
            "        [-0.8182, -1.8907, -0.9060,  ..., -0.2854,  3.9601,  0.3736],\n",
            "        [ 1.8354,  1.2876, -2.9229,  ..., -0.4209, -1.2824, -0.5029]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5409, -5.1469, -3.8546,  ..., -3.9585, -1.2398,  2.4318],\n",
            "        [ 2.7543,  3.6258, -1.2516,  ..., -2.0113,  0.2836,  0.7393],\n",
            "        [ 1.0013,  5.3759, -2.6158,  ..., -1.4242,  1.3685, -0.8366],\n",
            "        ...,\n",
            "        [ 2.7190, -0.7817, -3.3158,  ..., -0.0687,  5.8440,  2.7718],\n",
            "        [ 2.0908,  3.2363, -0.6775,  ..., -1.6730,  0.6102,  0.8669],\n",
            "        [-2.0811,  0.4462, -1.9062,  ...,  1.0045,  1.6546, -2.2181]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9070,  0.9057, -2.6566,  ..., -3.1505,  4.2705,  0.3082],\n",
            "        [-0.5911, -1.1297, -5.0950,  ..., -3.3005,  1.6494, -3.6125],\n",
            "        [-0.5423, -0.8265,  0.5063,  ..., -1.4965, -0.1863,  3.5216],\n",
            "        ...,\n",
            "        [ 1.9375,  2.4227, -1.6218,  ..., -1.6512,  3.5265,  0.2553],\n",
            "        [-2.0710, -3.4483, -2.7502,  ..., -0.5080, -4.1072, -1.5505],\n",
            "        [ 1.1543,  3.0185, -3.6348,  ...,  0.3948,  0.9048,  1.2408]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1365,  2.2446, -1.4518,  ..., -2.1916, -2.1308, -1.9389],\n",
            "        [ 2.7348, -5.0521, -1.7732,  ..., -1.8450,  2.7879, -0.6563],\n",
            "        [ 1.5513,  2.2603, -1.0419,  ..., -1.0723,  0.3885,  0.6835],\n",
            "        ...,\n",
            "        [-0.4795,  0.2302, -2.7404,  ..., -2.2601,  0.5896,  0.5550],\n",
            "        [ 0.4503,  4.1569, -2.9676,  ..., -1.0858,  2.3244, -1.9295],\n",
            "        [-0.8038,  0.7337, -2.9542,  ..., -0.7684, -0.3608, -2.3148]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0423, -0.2657, -3.0544,  ..., -0.2695, -2.7316, -2.2727],\n",
            "        [-0.1971,  3.9285, -1.4081,  ...,  0.6784,  1.4521, -1.9596],\n",
            "        [ 2.2324, -0.9740, -2.5776,  ..., -1.4868, -2.4618, -0.5494],\n",
            "        ...,\n",
            "        [-1.3094,  4.9684, -1.8411,  ..., -0.6044,  2.8540, -1.6797],\n",
            "        [-2.8541, -5.7925, -2.2637,  ..., -3.3173, -2.8451, -4.1673],\n",
            "        [-0.8829,  1.5335, -2.4057,  ..., -0.2665,  1.5130,  1.7200]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8058, -1.1983, -2.4355,  ..., -0.9003, -0.1030, -0.3800],\n",
            "        [-1.5070,  2.2934, -1.5708,  ..., -0.6531,  3.1026,  0.7921],\n",
            "        [ 1.8982,  1.4344, -4.3624,  ..., -2.9759,  6.9233,  0.4077],\n",
            "        ...,\n",
            "        [ 2.0789,  4.0272, -1.5483,  ..., -1.3527,  0.4806, -0.2781],\n",
            "        [ 0.0170,  1.5772, -2.6460,  ..., -0.9167, -2.0161,  0.9687],\n",
            "        [ 1.7726,  4.2515, -1.1347,  ..., -1.5450, -0.0511, -0.3717]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4424, -2.0541, -3.8718,  ..., -1.9883,  1.9403,  3.0431],\n",
            "        [-0.7050,  4.0075, -2.2322,  ...,  0.1726, -0.0054, -3.9274],\n",
            "        [-3.2363, -2.1481, -1.9074,  ..., -4.5631,  0.8308,  1.8196],\n",
            "        ...,\n",
            "        [-1.8363,  0.3136, -0.8614,  ..., -0.2401,  1.2998,  2.1775],\n",
            "        [-2.6399,  2.4337, -2.8554,  ..., -1.4724, -1.3187, -3.9807],\n",
            "        [-0.4533,  4.8789, -2.0532,  ..., -1.8836, -0.9964, -1.4809]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3446, -1.7310, -1.6190,  ..., -2.2506, -0.5206,  0.4554],\n",
            "        [ 1.8757,  0.4673, -3.1485,  ..., -1.7706,  3.7788,  0.6782],\n",
            "        [ 2.3105, -5.0628, -3.1758,  ..., -1.5764,  4.1672, -2.0008],\n",
            "        ...,\n",
            "        [ 0.8854,  3.2801, -1.5895,  ..., -0.7749, -3.2614,  1.9900],\n",
            "        [ 0.6501, -4.1501, -1.4408,  ...,  0.1580,  1.0127, -0.2467],\n",
            "        [-0.0732, -2.1255, -2.2924,  ..., -0.5044, -1.0501, -0.7228]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2294,  5.1476, -1.0915,  ..., -2.7776, -0.7659,  1.2976],\n",
            "        [-0.6409,  0.7167, -1.2614,  ..., -1.9385, -2.0405, -0.5330],\n",
            "        [-1.9873,  3.9879, -3.0788,  ...,  0.5046, -1.0058, -2.9549],\n",
            "        ...,\n",
            "        [-1.3269,  0.4745, -2.2540,  ..., -0.9861, -1.5506, -3.4516],\n",
            "        [-0.6419, -0.1395, -3.2928,  ..., -1.0004,  1.3931, -1.9053],\n",
            "        [-1.3496,  4.1537, -2.6832,  ..., -1.1160, -0.6774, -1.5918]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7486, -1.5912, -1.7571,  ..., -3.4779,  4.9417,  0.2732],\n",
            "        [ 2.1960,  3.6149, -1.0690,  ..., -1.4230,  0.1885,  1.4633],\n",
            "        [ 0.4903,  1.0231, -2.3447,  ..., -3.1541,  4.9313,  1.0233],\n",
            "        ...,\n",
            "        [ 0.5073, -1.8684, -2.7937,  ..., -1.9965, -3.3901,  1.0921],\n",
            "        [ 0.2715, -0.5092, -2.3250,  ..., -3.2255,  5.1881,  0.3888],\n",
            "        [ 1.1693,  1.1060, -3.2655,  ...,  1.3041, -2.2908, -0.7569]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2685,  1.7296, -3.7418,  ..., -1.5345, -0.4914,  1.1568],\n",
            "        [-3.6872, -2.1282, -2.7512,  ..., -1.5357,  0.6862, -1.7233],\n",
            "        [-0.7793,  1.4977, -4.2798,  ..., -3.6517,  1.6578, -0.5356],\n",
            "        ...,\n",
            "        [-2.1174, -0.0190, -1.7671,  ..., -0.6849,  2.6424,  1.8284],\n",
            "        [ 0.6709,  0.6020, -2.9777,  ..., -1.0130, -2.5880, -1.0765],\n",
            "        [ 0.3404,  2.4845, -1.6002,  ..., -2.1255, -2.8123,  0.3834]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2016, -2.3479, -1.1976,  ..., -3.2231,  0.6055, -2.2107],\n",
            "        [ 0.7678, -2.2961, -5.1632,  ..., -1.2710,  2.7524, -6.5195],\n",
            "        [ 0.3040, -3.4133, -4.4015,  ..., -2.0205, -4.4227, -1.7054],\n",
            "        ...,\n",
            "        [-0.1062, -1.7929, -2.1560,  ..., -2.5411,  1.0350, -1.6195],\n",
            "        [-2.3089, -3.0276, -1.9630,  ..., -1.7627, -1.7695,  0.3346],\n",
            "        [-1.0198,  5.9806, -3.4909,  ...,  1.0342,  0.9416, -1.7057]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8696, -0.2642, -3.5783,  ..., -1.1299,  0.7937, -0.1199],\n",
            "        [-1.1194,  0.7786, -1.7603,  ...,  0.6865,  0.6017, -1.0479],\n",
            "        [ 0.4929,  0.8361, -2.3553,  ..., -4.3812, -0.3154,  1.0219],\n",
            "        ...,\n",
            "        [ 0.6971,  0.7467, -1.9834,  ..., -0.7876, -0.2127, -1.4769],\n",
            "        [ 0.9255,  3.4605,  0.0851,  ..., -3.4115, -1.1852,  1.2533],\n",
            "        [-0.6831,  6.9614, -2.9328,  ..., -1.5750,  0.1577, -1.1454]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0270,  4.4925, -2.6975,  ..., -1.3911,  0.1223, -0.1060],\n",
            "        [-0.9220, -2.4756, -2.9465,  ...,  1.5000,  1.4808,  0.0579],\n",
            "        [ 0.1017, -1.9020, -3.7969,  ..., -3.2145, -1.2814,  2.5331],\n",
            "        ...,\n",
            "        [-2.2918, -6.6537, -4.3996,  ..., -3.9022,  0.6020,  3.8941],\n",
            "        [ 1.2201,  4.7315, -3.0887,  ..., -2.7002, -2.3916, -2.3530],\n",
            "        [-1.2805,  3.4545, -3.2467,  ..., -0.7146,  0.1706, -2.3633]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5126, -1.3365, -3.5297,  ..., -3.2308,  1.6692,  0.8055],\n",
            "        [-1.7132,  3.2577, -2.9086,  ..., -1.0410, -0.9915, -2.9468],\n",
            "        [-1.2900,  3.3318, -2.2552,  ...,  0.8742, -0.0861, -3.4491],\n",
            "        ...,\n",
            "        [ 1.3479,  4.4077, -4.1593,  ...,  0.2376, -1.1482, -2.9547],\n",
            "        [-3.1577, -4.6280, -2.9650,  ..., -0.5721,  2.9085,  1.0095],\n",
            "        [ 0.4971,  1.2390, -1.3782,  ..., -0.8121,  0.1473,  0.1722]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2882,  3.9274, -1.7781,  ..., -1.6004,  0.1400,  1.7477],\n",
            "        [ 1.4535,  0.0539, -2.4279,  ..., -2.4854,  5.2617,  1.1227],\n",
            "        [ 1.4911,  0.4293, -3.6314,  ..., -0.4578,  0.5479, -0.1941],\n",
            "        ...,\n",
            "        [-0.1348, -0.0681, -0.3521,  ..., -1.9409,  0.2430, -0.7798],\n",
            "        [ 1.2367,  0.1478, -2.1220,  ..., -0.4240,  0.6853, -0.7165],\n",
            "        [ 1.4691,  5.1736, -2.0621,  ..., -1.5618, -0.4972,  0.9845]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.3845e-01,  2.9459e+00, -2.7285e+00,  ..., -6.3649e-01,\n",
            "          1.2351e+00, -7.7461e-01],\n",
            "        [-1.3426e+00,  6.8362e+00, -3.6134e+00,  ...,  2.6481e-01,\n",
            "         -1.8069e+00, -1.2071e+00],\n",
            "        [ 3.5650e+00,  1.4866e+00, -3.1463e+00,  ..., -6.6646e-02,\n",
            "          4.3693e+00,  1.2705e+00],\n",
            "        ...,\n",
            "        [ 3.0328e-02,  2.3102e+00, -3.1978e+00,  ..., -1.4696e+00,\n",
            "          1.3257e-03, -3.7565e+00],\n",
            "        [-2.5678e+00, -7.3672e+00, -3.4459e+00,  ..., -2.8104e+00,\n",
            "          3.6867e+00, -3.4485e+00],\n",
            "        [-1.7975e+00, -4.3494e+00, -1.8840e+00,  ..., -4.8256e+00,\n",
            "          3.7855e+00,  1.0886e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.0240e-01, -2.4052e+00, -2.2995e+00,  ..., -3.8751e+00,\n",
            "          1.7250e+00,  1.7247e+00],\n",
            "        [-1.9159e-01,  4.4363e-01, -3.4357e+00,  ...,  1.9357e-03,\n",
            "          3.9988e+00,  1.9459e+00],\n",
            "        [ 6.0785e-01,  2.3812e+00, -1.3465e+00,  ..., -1.2200e+00,\n",
            "          1.6107e+00,  3.3508e-01],\n",
            "        ...,\n",
            "        [-3.4728e+00,  1.9625e-01,  3.0056e-01,  ..., -3.7399e+00,\n",
            "         -4.2403e-01, -9.4285e-01],\n",
            "        [ 8.1960e-01, -3.6190e-01, -2.2555e+00,  ..., -4.6105e+00,\n",
            "          1.7174e+00,  4.1765e-01],\n",
            "        [-1.6132e-01,  4.0004e+00, -1.3942e+00,  ..., -1.0325e+00,\n",
            "          2.1079e+00, -1.1938e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8497,  2.5345, -1.0390,  ..., -0.4810, -1.0766, -1.8443],\n",
            "        [-0.9888,  0.5825, -1.3413,  ..., -4.1996,  0.4111,  2.8383],\n",
            "        [-0.7641,  4.5814, -2.9746,  ...,  0.2864, -2.1525, -2.8198],\n",
            "        ...,\n",
            "        [-3.7077, -5.5419, -3.4518,  ..., -2.8743,  0.7685,  3.9744],\n",
            "        [-0.4756, -1.1304, -4.3875,  ..., -0.7529, -1.8205, -2.6533],\n",
            "        [-0.4314,  2.8766, -3.0322,  ..., -0.3125,  0.3463, -3.3146]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a05a100de8147dc8d79d5674471d56a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0759, -3.2271, -2.1089,  ..., -2.4761, -0.5178, -0.6313],\n",
            "        [ 0.8228,  2.5640, -4.1423,  ...,  0.1593,  3.9513,  1.7223],\n",
            "        [ 1.1899,  3.6761, -2.7732,  ..., -1.5687, -0.5306, -0.7274],\n",
            "        ...,\n",
            "        [-0.3630, -5.6752, -1.8948,  ..., -1.5433,  2.6930,  0.5975],\n",
            "        [-0.8536,  2.9753, -3.2023,  ...,  0.3324,  1.4320,  0.5026],\n",
            "        [ 2.3869,  0.2304, -4.5764,  ..., -3.1737,  3.2345,  1.6374]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3587,  2.8704, -3.5431,  ..., -0.3950,  1.0459, -0.8576],\n",
            "        [ 1.5121, -0.5661, -3.1320,  ..., -1.5362,  6.4109,  0.5791],\n",
            "        [-0.1016,  3.7289, -3.1127,  ...,  0.8249,  0.6032, -2.3590],\n",
            "        ...,\n",
            "        [-2.7577, -3.4020, -4.9094,  ..., -2.5149,  3.2736, -0.6690],\n",
            "        [ 1.2891,  1.6242, -2.6887,  ..., -2.5478,  0.7488,  1.9601],\n",
            "        [-3.5382, -5.0130, -1.9944,  ..., -1.8588, -3.5020, -1.6909]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4841,  2.6720, -3.0635,  ..., -2.9248, -3.3949, -1.1519],\n",
            "        [ 2.4200, -1.6719, -1.3957,  ..., -3.4194,  1.7238, -1.9901],\n",
            "        [-0.0498,  2.6215, -1.0505,  ..., -1.0826,  0.0105,  1.1001],\n",
            "        ...,\n",
            "        [-0.2174,  4.7051, -3.8916,  ..., -1.0975,  2.3156, -2.0154],\n",
            "        [-1.4357,  3.1726, -3.9196,  ...,  1.3570,  1.1058, -4.6086],\n",
            "        [ 3.0720,  3.8543, -4.4058,  ...,  0.7525, -1.0953, -1.2620]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9494,  3.4959, -3.1942,  ..., -3.2801, -2.4853, -2.1747],\n",
            "        [ 1.3406,  2.1905, -1.4804,  ..., -0.9609,  2.2245,  1.5770],\n",
            "        [-0.9979,  1.5470, -0.2057,  ..., -0.9233,  1.1752,  0.5647],\n",
            "        ...,\n",
            "        [-1.0268, -3.5628, -1.3231,  ..., -1.2167, -0.4692, -0.1419],\n",
            "        [-0.9559,  2.9569, -4.5509,  ..., -0.3052, -5.1090, -1.3240],\n",
            "        [ 2.1349, -0.7576, -2.2975,  ..., -3.4794,  6.4079,  0.6228]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4411,  1.3163, -1.9457,  ..., -0.5901, -2.2434, -2.3565],\n",
            "        [-1.4870,  1.3386, -2.8247,  ..., -0.6891, -2.1455, -2.4762],\n",
            "        [-1.3268, -1.2472, -3.9301,  ..., -2.6787,  2.4002,  3.1516],\n",
            "        ...,\n",
            "        [-2.5935, -1.4737, -2.1126,  ..., -0.3290, -1.1378, -3.0027],\n",
            "        [ 1.5877,  3.3911, -1.2137,  ..., -1.4593,  0.4932,  1.2204],\n",
            "        [ 1.2442,  0.7272, -1.8353,  ..., -0.3783, -2.2646,  1.4655]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0133e+00,  3.0753e+00, -2.5844e+00,  ..., -8.9774e-01,\n",
            "         -1.2070e+00, -4.4111e+00],\n",
            "        [-9.1070e-01,  5.4969e-01, -2.9281e+00,  ..., -8.3958e-01,\n",
            "          3.5474e+00,  1.9212e+00],\n",
            "        [-1.2269e+00, -3.2067e+00, -2.8140e+00,  ..., -2.2080e+00,\n",
            "          3.4533e+00,  2.1384e+00],\n",
            "        ...,\n",
            "        [-6.8318e-01, -1.1129e+00, -5.2833e-01,  ..., -1.2107e+00,\n",
            "         -2.8176e+00,  8.8325e-01],\n",
            "        [ 9.3283e-02, -4.5558e+00, -2.3392e+00,  ..., -3.0532e+00,\n",
            "          1.7295e+00, -2.7953e-01],\n",
            "        [ 2.5159e+00,  4.7775e+00, -1.8043e+00,  ..., -1.1413e+00,\n",
            "          4.4489e-03,  1.3831e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2310,  4.6587, -2.6897,  ..., -1.5914, -0.5281, -0.8787],\n",
            "        [ 0.2026, -1.9035, -0.3112,  ..., -0.1233, -0.6467,  1.4920],\n",
            "        [-0.9532, -1.9980, -3.6372,  ..., -3.4779,  2.4582,  2.5653],\n",
            "        ...,\n",
            "        [-1.0942,  4.1006, -2.1368,  ..., -1.4321,  2.9148,  1.2163],\n",
            "        [-1.3256,  1.3216, -2.7910,  ..., -1.3231,  2.8324,  1.4098],\n",
            "        [ 1.2637, -2.2803, -2.2767,  ...,  3.1196,  5.2609,  0.9976]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1462,  0.8114, -1.0841,  ..., -2.0641, -0.3479,  1.0299],\n",
            "        [-1.2921, -0.5755, -3.4796,  ...,  0.1387,  0.3406, -0.9761],\n",
            "        [ 0.3470,  0.3613, -1.3688,  ..., -3.4654, -2.2402, -0.4166],\n",
            "        ...,\n",
            "        [ 2.7659,  2.5419, -5.4570,  ..., -0.0997, -0.5565, -0.3346],\n",
            "        [-3.4476, -2.0489, -1.4639,  ..., -0.9496, -0.7826, -1.5552],\n",
            "        [-1.6454, -4.0051, -1.2783,  ..., -0.6867, -0.2600, -2.0150]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5930,  5.9387, -3.1935,  ...,  3.5466,  0.9694, -1.7417],\n",
            "        [-0.6588, -7.1280, -2.5359,  ..., -2.4525,  0.7939, -0.3528],\n",
            "        [-0.0263,  3.0881, -1.7897,  ..., -1.3310, -2.0493,  0.4263],\n",
            "        ...,\n",
            "        [-0.6791,  0.0484, -1.5761,  ..., -1.6473,  0.1212,  3.1950],\n",
            "        [-2.6091, -2.7522, -2.8941,  ...,  0.2686, -0.6028, -2.1372],\n",
            "        [-4.5693, -1.4583, -1.6740,  ..., -2.5569,  1.2180,  0.7717]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5635,  1.5779, -2.5249,  ..., -0.0505,  2.1303, -0.1863],\n",
            "        [ 2.1704,  0.9684, -2.9188,  ...,  0.2505, -2.6460,  0.6008],\n",
            "        [ 0.8093,  2.2202, -2.3055,  ...,  0.4899, -3.4863, -1.1323],\n",
            "        ...,\n",
            "        [-0.0057, -1.1531, -1.1199,  ..., -0.9756, -2.0548,  2.2809],\n",
            "        [ 0.0854,  1.3057, -0.6314,  ..., -0.9242, -0.4944,  1.5403],\n",
            "        [ 2.8059,  1.3479, -0.9972,  ..., -2.4205,  5.1836, -1.0071]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3274, -3.4988, -1.2403,  ...,  0.2678,  0.9476, -1.4156],\n",
            "        [-4.6395, -0.1346, -1.6866,  ..., -5.1144,  1.7235,  1.2990],\n",
            "        [-1.7303, -6.1297, -4.2448,  ..., -5.3886,  1.3475,  3.1138],\n",
            "        ...,\n",
            "        [ 1.0465,  4.8451, -3.4606,  ..., -1.8955,  0.2049,  0.5268],\n",
            "        [-1.8325,  5.2974, -3.0405,  ...,  0.4637,  0.5136, -3.1548],\n",
            "        [ 0.3608,  4.9391, -3.8633,  ...,  0.9286,  1.2226, -1.8656]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3948,  3.9872, -1.8891,  ..., -1.4756, -0.2195,  1.4289],\n",
            "        [-0.6846, -0.1056, -3.5766,  ..., -1.1068,  0.7911, -2.6332],\n",
            "        [ 2.3857, -0.4521, -2.4309,  ..., -1.1033,  2.9635,  2.5253],\n",
            "        ...,\n",
            "        [-0.9381,  1.6003, -1.7737,  ..., -2.2014,  1.7614,  1.9663],\n",
            "        [-0.0463,  4.2238, -1.9944,  ..., -2.0049,  0.5170, -1.5375],\n",
            "        [-1.3924, -4.2816, -5.0069,  ..., -1.5253,  2.7014,  2.3416]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6631,  4.3626, -3.5898,  ..., -0.6730, -1.8611, -1.0126],\n",
            "        [-0.8413,  5.6401, -3.5217,  ..., -0.0881, -0.8073, -2.7824],\n",
            "        [-0.2507,  2.0634, -1.2400,  ..., -1.5121, -0.5217, -1.0381],\n",
            "        ...,\n",
            "        [ 0.2676, -0.3452, -3.4200,  ..., -1.8227,  4.9588,  2.6103],\n",
            "        [ 1.9052, -1.5667, -4.8658,  ..., -1.3012,  1.3058, -0.8676],\n",
            "        [-1.2226,  0.0626, -2.4034,  ..., -1.9610,  3.3915,  0.9682]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-9.7842e-01,  4.1216e+00, -1.8033e+00,  ..., -1.9400e+00,\n",
            "         -2.3485e+00, -1.7884e+00],\n",
            "        [ 1.3773e+00,  3.3811e+00, -3.3798e+00,  ..., -3.4682e-01,\n",
            "         -6.7750e-01, -2.7457e+00],\n",
            "        [-7.3232e-01,  4.8167e+00, -2.8840e+00,  ...,  1.0323e+00,\n",
            "         -3.8427e-03, -1.1776e+00],\n",
            "        ...,\n",
            "        [ 2.4603e+00,  1.2771e+00, -3.0290e+00,  ..., -2.1232e+00,\n",
            "          3.8586e+00,  1.1686e+00],\n",
            "        [ 6.5643e-01,  1.4877e+00, -1.1752e+00,  ..., -1.1839e+00,\n",
            "         -1.5727e-01,  1.7829e+00],\n",
            "        [ 2.2331e+00,  5.1109e+00, -2.8504e+00,  ..., -2.3434e+00,\n",
            "         -1.4899e+00,  5.3594e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9273,  7.4541, -3.9589,  ...,  1.2592, -4.3962, -2.0902],\n",
            "        [-2.5378, -5.1646,  0.4604,  ..., -4.0664, -1.7071,  1.8609],\n",
            "        [-3.7220, -5.3973, -1.2899,  ..., -3.8217, -1.5644,  0.4151],\n",
            "        ...,\n",
            "        [ 0.3911,  1.2289, -1.7382,  ...,  0.5139, -1.1951,  1.7553],\n",
            "        [ 1.1147,  2.8531, -3.3279,  ..., -0.4763,  2.0369,  0.4752],\n",
            "        [-0.7035, -0.1667, -0.9450,  ..., -1.0631, -2.1799,  0.9252]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6556,  5.5138, -2.8137,  ..., -0.3579,  1.2293, -0.0612],\n",
            "        [ 0.4806,  4.5220, -2.5137,  ..., -0.4751,  0.2734, -0.8441],\n",
            "        [-0.3671,  2.9616, -2.3403,  ..., -0.0626, -0.9295,  1.9237],\n",
            "        ...,\n",
            "        [-1.1510,  3.8547, -2.8631,  ..., -2.1861, -0.9309,  0.3707],\n",
            "        [-2.9637,  0.4562, -3.7938,  ...,  1.1482, -0.8298, -1.2979],\n",
            "        [-0.2160,  3.9046, -2.7087,  ..., -1.9815, -1.8099, -0.8094]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9958, -2.7570, -3.0292,  ...,  0.2161,  5.7491, -4.2751],\n",
            "        [-2.6733, -2.3593, -2.5643,  ..., -0.8446, -1.3322,  1.0188],\n",
            "        [-2.2184,  2.4057, -1.2026,  ..., -0.7440, -0.7271, -2.6968],\n",
            "        ...,\n",
            "        [ 2.1004,  4.6162, -3.8797,  ..., -1.8069, -0.8919,  0.7025],\n",
            "        [ 0.5391,  2.6919, -2.5371,  ...,  1.2472,  1.3397, -2.4915],\n",
            "        [-1.8653,  4.6813, -1.3234,  ..., -1.5531,  0.8155,  3.0577]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0821, -2.6374, -4.0313,  ...,  0.2484,  3.1464,  2.7344],\n",
            "        [-1.2442, -8.0880, -4.9152,  ..., -1.2603, -1.9505,  0.4346],\n",
            "        [-3.9492,  2.4672, -2.4739,  ...,  1.2197, -0.1678, -4.2729],\n",
            "        ...,\n",
            "        [-2.1218, -4.5171, -3.3460,  ..., -0.1451, -0.5087, -3.6342],\n",
            "        [-4.6434, -1.5584, -2.2470,  ..., -0.1770, -1.3472,  0.8477],\n",
            "        [-0.2665,  6.1391, -1.7575,  ..., -0.5489, -0.6078, -0.9967]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3628, -2.3002, -4.6855,  ..., -0.5798, -1.8472, -3.3073],\n",
            "        [-2.9785, -3.1362, -2.5473,  ..., -0.5880, -0.1802, -0.4150],\n",
            "        [-1.3329,  2.3619, -2.3271,  ...,  0.4730, -1.2325, -2.6664],\n",
            "        ...,\n",
            "        [-2.1041, -0.7259, -3.2151,  ..., -1.5883, -1.1301, -1.3915],\n",
            "        [ 0.7824, -1.2248, -2.2210,  ..., -3.8074,  5.7020,  0.7092],\n",
            "        [-1.7011, -1.3884, -0.0394,  ..., -3.7076,  0.3358,  3.6489]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1028,  0.1695, -2.3308,  ...,  0.7083, -0.5937,  1.6968],\n",
            "        [ 1.9945,  2.9059, -2.7742,  ...,  0.5074,  0.9994,  0.8193],\n",
            "        [ 1.6606,  2.0644, -3.7559,  ..., -2.7142,  2.1779,  1.4508],\n",
            "        ...,\n",
            "        [-1.5110, -1.4226, -0.5567,  ..., -1.3911, -2.3684,  1.2685],\n",
            "        [-0.0305,  4.3187, -4.2662,  ..., -0.1022,  0.6348, -2.2022],\n",
            "        [ 0.3180, -1.1662, -1.9066,  ..., -1.1944,  0.2438, -0.1726]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0147, -1.6188, -0.5604,  ..., -1.2932, -2.7777,  0.0893],\n",
            "        [-1.2837,  0.2777, -3.3228,  ...,  1.1974, -1.5954, -2.6962],\n",
            "        [-2.0364,  1.3735, -2.7558,  ..., -0.3353,  2.6326,  2.1400],\n",
            "        ...,\n",
            "        [-0.9330,  2.2442, -1.6009,  ..., -2.5754,  3.2616,  2.5592],\n",
            "        [-1.7912, -0.5605, -3.3243,  ..., -1.4650, -0.1017, -0.4973],\n",
            "        [ 1.6000,  1.2636, -2.2641,  ..., -0.0217,  3.1111,  3.5678]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4869,  1.3866, -1.9002,  ...,  0.2702,  0.2820,  1.3445],\n",
            "        [-1.6637,  0.4590, -1.2304,  ..., -1.7883,  1.7936,  0.8316],\n",
            "        [ 1.4200,  1.9695, -4.2560,  ..., -1.1617,  1.3418,  1.9890],\n",
            "        ...,\n",
            "        [ 2.5572, -1.6337, -1.4437,  ..., -1.3321,  1.4166, -1.6595],\n",
            "        [ 1.3101,  5.4513, -2.4855,  ..., -1.2034,  3.1253,  0.4700],\n",
            "        [-2.7702, -1.7535, -3.8448,  ..., -2.9789, -1.8269, -0.8968]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4317,  1.1405, -2.3802,  ..., -2.3009, -2.2113,  0.7789],\n",
            "        [-0.1242,  3.9101, -2.6079,  ..., -1.0265,  0.2529,  0.7756],\n",
            "        [-1.4020,  3.4570, -2.2296,  ..., -1.8838,  0.3093, -0.8847],\n",
            "        ...,\n",
            "        [-1.9568,  3.8099, -0.3198,  ...,  0.8235, -1.9980,  0.9087],\n",
            "        [ 2.2157,  0.6480, -2.8211,  ..., -0.7017,  3.9280,  2.2078],\n",
            "        [-2.2764, -3.6766, -3.5872,  ..., -3.2397,  2.4149,  4.6917]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2310,  0.8654, -1.8876,  ..., -1.8477,  2.2798,  0.4710],\n",
            "        [ 1.7083, -0.1797, -1.3619,  ..., -0.9804,  0.2309,  2.2677],\n",
            "        [ 0.4080, -1.0914, -4.1210,  ..., -1.5066,  3.6560, -0.1489],\n",
            "        ...,\n",
            "        [-1.1582, -1.8557, -3.1291,  ...,  0.2448,  0.4885,  0.8359],\n",
            "        [ 0.2427, -5.0903, -2.0509,  ..., -3.8252,  1.2384,  1.4669],\n",
            "        [-1.4926,  5.2087, -4.1506,  ..., -1.2191,  0.2294, -1.1672]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0212,  1.7778, -3.6897,  ..., -2.7520,  4.9757, -0.0202],\n",
            "        [ 0.3086,  2.1353, -1.7710,  ..., -0.3635, -1.0824,  2.0851],\n",
            "        [ 2.6112,  2.7153, -1.3855,  ..., -1.5817,  0.2826,  2.5399],\n",
            "        ...,\n",
            "        [ 0.5206, -1.1826, -4.7115,  ..., -3.5729,  4.4731,  1.8763],\n",
            "        [-1.1503,  3.6536, -1.7643,  ...,  0.6168, -1.2961,  0.0642],\n",
            "        [ 3.3237,  1.4332, -4.3563,  ..., -2.8576,  2.1272, -0.3318]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6369,  1.0950, -1.7679,  ..., -1.1468, -0.3488, -1.4646],\n",
            "        [-0.3254,  3.6504, -3.7690,  ..., -0.2910, -0.1859, -0.7172],\n",
            "        [-0.6666,  5.2174, -4.2459,  ..., -0.9210, -2.1358, -1.8803],\n",
            "        ...,\n",
            "        [-0.1953,  3.4705, -3.2479,  ...,  1.9721, -0.1272, -0.7187],\n",
            "        [ 3.1096,  5.1571, -2.8825,  ..., -2.6244, -0.7771,  1.3857],\n",
            "        [-0.3614,  0.4899, -2.5297,  ...,  0.7951, -0.3064, -2.8432]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3685,  0.9885, -3.1080,  ..., -4.1702,  0.6539,  1.9091],\n",
            "        [-3.1263, -1.1055, -2.8014,  ..., -0.9405, -2.6497, -1.4284],\n",
            "        [-0.6297,  5.1590, -2.8022,  ..., -1.5685, -0.9827,  1.2134],\n",
            "        ...,\n",
            "        [-0.1519, -5.8433, -2.7541,  ..., -2.5714,  1.4228, -0.5267],\n",
            "        [ 0.0135, -0.2101, -3.5902,  ..., -2.3080,  5.6492, -0.4422],\n",
            "        [-3.6270, -2.3802, -1.3048,  ...,  0.0756, -1.0896,  1.0113]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0310,  0.5349, -1.0397,  ..., -0.2856, -0.4624,  1.6195],\n",
            "        [-0.3910,  0.9444, -0.9975,  ..., -1.4727,  0.6474,  1.6024],\n",
            "        [-7.2498, -0.9167, -1.9705,  ..., -4.1714, -1.8053,  2.4412],\n",
            "        ...,\n",
            "        [ 0.4618,  0.5673, -2.5988,  ..., -0.4096,  2.9215, -2.1235],\n",
            "        [-2.4298, -8.1474, -4.0954,  ..., -3.8428,  0.5332,  4.9627],\n",
            "        [-2.4063,  3.2080, -3.1370,  ...,  0.9443, -1.3668, -1.0914]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1382, -8.4289, -3.6355,  ..., -1.4173, -3.4945,  0.5760],\n",
            "        [-3.0651,  0.2629, -3.1867,  ...,  4.0625, -0.5929, -2.6543],\n",
            "        [-1.9581,  2.5358, -2.0340,  ...,  1.0310,  0.7800, -1.6813],\n",
            "        ...,\n",
            "        [-2.6763,  0.7021, -1.4228,  ..., -1.2890,  0.1691,  1.7188],\n",
            "        [-2.1301,  3.1876, -2.6921,  ..., -2.4077, -3.2749,  0.2278],\n",
            "        [ 0.1188, -0.0406, -1.7419,  ..., -1.7832, -0.9197,  1.8687]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1712,  0.0739, -2.6993,  ..., -0.9478, -2.5112,  0.1214],\n",
            "        [-1.6907,  0.9431, -1.2827,  ..., -0.6271,  0.4040, -0.7279],\n",
            "        [-0.7422,  2.4133, -2.4259,  ..., -0.6776, -1.1927,  0.8217],\n",
            "        ...,\n",
            "        [-1.1266,  2.0126, -3.1465,  ...,  3.5190, -1.6978, -2.8160],\n",
            "        [-4.1896, -0.6445, -2.1281,  ..., -1.4286, -0.5756,  2.1449],\n",
            "        [-2.7747,  6.4916, -2.5449,  ..., -0.2212,  0.4912,  0.1265]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5660,  2.9550, -1.9393,  ..., -1.5598, -2.9477, -0.8232],\n",
            "        [-1.8639, -2.8895, -1.7939,  ..., -4.7910,  2.7523,  0.7638],\n",
            "        [-2.0570, -0.5953, -1.9482,  ..., -2.7983, -1.6955,  5.7354],\n",
            "        ...,\n",
            "        [-0.0751,  3.0368, -1.5831,  ..., -0.4955,  0.8387, -0.2985],\n",
            "        [ 0.3318, -5.9323, -1.8327,  ..., -2.3433,  2.7639, -1.8674],\n",
            "        [-1.9185, -2.1653, -3.6893,  ...,  2.6792, -2.5045, -2.5766]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5745, -1.3198, -2.7316,  ..., -0.1853, -0.0476, -2.1053],\n",
            "        [-5.1314, -1.9513, -1.4269,  ..., -1.2915,  2.0116, -1.0214],\n",
            "        [-1.9348, -1.0073, -2.3611,  ..., -1.2156, -2.4387, -0.5689],\n",
            "        ...,\n",
            "        [-1.2910,  5.3319, -4.7619,  ..., -1.4982,  1.2271, -0.8717],\n",
            "        [-1.2608,  2.9395, -1.1228,  ..., -0.9130,  0.3373,  2.1629],\n",
            "        [-3.6441, -7.3487, -5.1452,  ..., -2.4792,  2.0913,  6.2485]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0099,  0.5864, -2.4050,  ..., -2.1284,  0.2131,  2.1636],\n",
            "        [-2.4011,  0.5710, -3.4994,  ...,  1.1101, -0.1192, -3.3428],\n",
            "        [ 0.5558,  1.3684, -2.6285,  ..., -2.5651,  1.0812,  3.9945],\n",
            "        ...,\n",
            "        [-1.0201,  1.8504, -1.8744,  ..., -0.1203, -0.0930, -1.4540],\n",
            "        [-0.8429,  4.7952, -2.8827,  ..., -1.0061,  0.6941, -1.3998],\n",
            "        [ 2.6237,  3.8388, -1.7055,  ..., -1.3118, -0.1680,  1.5183]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3379,  3.1098, -2.5804,  ...,  0.8908, -0.2079, -0.5112],\n",
            "        [-1.0237,  2.9394, -2.8525,  ..., -1.6283, -4.1373, -0.9802],\n",
            "        [-1.9258, -4.4548, -4.0236,  ..., -2.4630,  0.6109, -1.2747],\n",
            "        ...,\n",
            "        [-2.0876, -3.4820, -1.0239,  ..., -0.6371,  1.4435, -0.6130],\n",
            "        [-1.4509, -0.0772, -2.7129,  ..., -3.3163, -0.4747,  4.7092],\n",
            "        [-0.8896, -3.6034, -3.8467,  ..., -5.2106,  0.5794,  2.0788]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9355,  3.7593, -3.0709,  ..., -0.5351,  1.2407, -1.4531],\n",
            "        [-1.7677,  2.9397, -2.0477,  ..., -2.1096, -4.2643, -0.4359],\n",
            "        [-1.2367,  4.6182, -2.3113,  ..., -1.7827, -3.6945, -0.5379],\n",
            "        ...,\n",
            "        [-2.5768,  0.4306, -2.9464,  ..., -1.4061,  0.1632, -1.9474],\n",
            "        [ 1.4010,  4.2181, -1.3358,  ..., -2.0071, -1.7645,  0.6439],\n",
            "        [-4.2766, -4.2416, -3.3202,  ..., -3.2275, -4.1753,  3.4158]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6028,  1.7028, -4.9739,  ..., -1.6095,  7.6804,  1.2799],\n",
            "        [ 0.9434, -1.5003, -2.6300,  ..., -1.0777,  3.3518,  3.2180],\n",
            "        [ 1.6818,  2.2203, -1.3280,  ..., -1.0610,  0.1227,  2.8142],\n",
            "        ...,\n",
            "        [-0.7088, -1.0680, -2.5960,  ..., -0.4232,  0.1851, -2.4077],\n",
            "        [ 2.5807,  2.5244, -2.8596,  ...,  1.0363, -0.2339, -1.4928],\n",
            "        [-1.9567,  0.1176, -1.4653,  ..., -1.4582,  0.2992,  1.3631]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4816,  3.8289, -3.4554,  ..., -0.2359, -4.4575,  0.9272],\n",
            "        [-3.0573,  4.3472, -5.3601,  ...,  1.6666,  1.5246, -1.4458],\n",
            "        [ 1.7334,  0.6452, -5.6862,  ..., -0.5468,  5.0176,  2.5462],\n",
            "        ...,\n",
            "        [-0.3667,  4.5607, -0.7957,  ..., -2.5838, -0.6288,  1.0679],\n",
            "        [ 0.8994,  2.8702, -2.6453,  ..., -1.0670,  2.9140, -1.6493],\n",
            "        [-2.0997, -1.5691, -2.4996,  ...,  0.4968,  1.2161, -1.8890]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8727,  1.5267, -2.9579,  ...,  0.4548, -0.1739, -0.6822],\n",
            "        [-0.6826,  4.5611, -2.5189,  ..., -1.5160,  1.1725,  0.2863],\n",
            "        [-1.7492, -2.2622, -4.0106,  ..., -3.2871,  0.7721, -2.0816],\n",
            "        ...,\n",
            "        [-3.1046,  2.6510, -1.9779,  ...,  4.0998,  0.7205, -1.8143],\n",
            "        [-0.8233,  1.3963, -2.8975,  ..., -1.8659, -0.4175,  2.2896],\n",
            "        [-4.5394, -3.7801, -0.8679,  ..., -2.4209,  0.0949,  2.7004]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0377, -3.6973, -3.3239,  ..., -2.5260, -0.6806,  0.9697],\n",
            "        [-6.0910, -4.2064,  0.2725,  ..., -2.7198, -1.4373,  0.9690],\n",
            "        [-5.6195, -0.5629, -3.2627,  ..., -2.5266,  0.0292, -0.2267],\n",
            "        ...,\n",
            "        [-2.1532, -2.2098, -4.4602,  ..., -1.3610, -1.9172, -2.8502],\n",
            "        [ 2.3912,  4.6255, -1.8926,  ..., -1.7634,  0.2748,  2.4451],\n",
            "        [ 1.4974, -1.4607, -4.6014,  ..., -3.1973,  4.2833, -0.4458]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0010,  0.6125, -1.0407,  ..., -1.4220,  0.2220,  2.0402],\n",
            "        [-3.5049,  0.8018, -2.8011,  ..., -0.4849, -0.9978,  0.1825],\n",
            "        [-3.5699,  3.3287, -3.0010,  ..., -1.0951,  2.0856,  1.2212],\n",
            "        ...,\n",
            "        [-0.3372,  3.0578, -2.5244,  ...,  0.0617, -1.1617, -0.1304],\n",
            "        [ 1.3550,  3.4891, -1.1835,  ..., -1.6224, -0.3274,  1.8181],\n",
            "        [-2.5203,  3.7830, -2.2979,  ..., -0.6225,  0.1901, -1.5233]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7202,  1.0458, -3.3106,  ..., -0.9014, -1.9315, -3.1314],\n",
            "        [-1.6499,  1.0323, -2.7700,  ..., -1.7317, -4.9568, -1.1682],\n",
            "        [-1.1846, -0.3842, -1.1387,  ..., -1.7415, -1.8097,  4.2983],\n",
            "        ...,\n",
            "        [-4.6124,  0.3138, -4.3599,  ..., -0.1254, -0.6047, -0.7559],\n",
            "        [-4.9415,  1.8827, -1.1984,  ..., -0.9867, -2.0663, -0.4762],\n",
            "        [-1.6538,  5.9762, -1.9052,  ..., -0.6203, -2.5101, -0.9988]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0479,  1.4927, -2.9103,  ..., -0.3176,  3.2855,  0.5817],\n",
            "        [-3.5410, -1.9710, -0.8154,  ..., -1.4923,  0.2079, -1.2224],\n",
            "        [ 0.9045,  0.5975, -3.2644,  ..., -2.1212,  1.6641, -1.7765],\n",
            "        ...,\n",
            "        [-3.1817, -3.7499, -1.3617,  ..., -4.7428, -1.0563,  2.8295],\n",
            "        [-0.5757,  3.9798, -2.7227,  ..., -0.2233,  2.8913, -1.4422],\n",
            "        [ 1.3579, -6.9093, -2.7863,  ..., -1.4722, -2.9479,  0.6675]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2907, -2.1360,  0.5320,  ..., -2.2746, -1.6223,  2.0988],\n",
            "        [-2.4857, -1.2364,  0.2365,  ..., -0.6589, -1.6020,  1.9471],\n",
            "        [-4.6213, -1.0740, -3.5761,  ..., -4.6941, -2.5405, -0.7265],\n",
            "        ...,\n",
            "        [-4.6499, -0.0504, -3.6934,  ..., -1.7712, -0.3835, -0.0951],\n",
            "        [-0.7993, -4.4617, -3.5446,  ..., -2.9341, -2.3352,  0.4887],\n",
            "        [ 0.6137,  0.2461, -1.5051,  ..., -3.2972,  0.7385,  0.4863]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3058,  2.6834, -2.8302,  ..., -0.4475, -1.5541, -0.5604],\n",
            "        [-0.6825,  4.5861, -2.5247,  ..., -0.5950, -2.4993,  0.4749],\n",
            "        [ 0.4488, -2.1230, -2.5680,  ..., -2.6089,  3.8582,  1.4004],\n",
            "        ...,\n",
            "        [-1.3433,  5.9114, -3.6194,  ..., -0.8070,  1.7614,  0.5257],\n",
            "        [-2.2494,  2.0988, -1.3474,  ...,  0.6612, -0.2562, -1.9888],\n",
            "        [-0.4075,  3.3443, -2.2319,  ..., -0.8868,  1.4192, -0.1459]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3143,  0.2985, -0.8152,  ..., -3.0368,  0.4535,  0.2764],\n",
            "        [-2.7723,  0.1222, -0.7675,  ..., -2.0946,  0.3753,  3.8364],\n",
            "        [-0.5819,  1.9815, -1.6219,  ...,  1.1645, -0.9459,  0.9902],\n",
            "        ...,\n",
            "        [-1.8392, -6.7138, -1.9657,  ..., -1.5392, -2.5490, -0.2905],\n",
            "        [ 1.4185,  2.2237, -1.8143,  ..., -0.4228,  1.2562,  3.2139],\n",
            "        [-3.9172, -3.7798, -3.3349,  ...,  0.2698,  4.3343,  2.3260]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2317,  5.1910, -3.6115,  ...,  0.4511,  2.0377,  1.3388],\n",
            "        [ 0.2572, -1.1594, -2.6394,  ..., -3.0207,  7.0821,  2.5704],\n",
            "        [-1.6947,  1.1630, -2.8748,  ..., -1.4984, -0.6436,  0.1835],\n",
            "        ...,\n",
            "        [-1.6745,  0.6360, -2.7116,  ..., -0.7643,  0.1788, -0.6092],\n",
            "        [-1.4711, -0.7777,  0.1857,  ..., -0.2476, -1.6858,  1.5441],\n",
            "        [-1.1084, -2.5861, -4.7744,  ..., -3.2088,  0.3341,  1.8507]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0578,  2.6628, -2.7328,  ..., -1.5229, -3.7067, -2.0594],\n",
            "        [-2.9267,  1.6477, -0.5516,  ..., -0.4899, -0.3551,  0.2376],\n",
            "        [-0.8554, -2.7673, -2.3956,  ..., -0.0124, -0.4633, -0.1443],\n",
            "        ...,\n",
            "        [ 1.2077,  0.2844, -3.1852,  ..., -0.7891,  0.2929, -0.7895],\n",
            "        [ 0.5039,  2.9362, -1.3837,  ..., -0.3310, -0.7528,  1.7349],\n",
            "        [-2.2082,  4.0528, -5.3415,  ..., -2.2262,  0.3714, -2.6391]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9102,  0.8597, -1.5217,  ...,  0.3252, -0.8270,  1.1659],\n",
            "        [-4.0873,  0.0578, -1.3657,  ...,  0.4754, -0.7722, -0.0267],\n",
            "        [-0.6912,  0.5766, -3.4704,  ..., -1.3083,  0.7689,  1.7833],\n",
            "        ...,\n",
            "        [-5.3620, -8.4151, -2.9674,  ..., -3.1532, -3.0527,  2.4579],\n",
            "        [-1.7165, -2.9615, -2.6329,  ...,  2.2498, -0.7402, -0.8625],\n",
            "        [ 0.0775,  5.1362, -2.9324,  ...,  0.4589, -2.5656,  1.1935]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1409,  0.1138, -4.2203,  ..., -1.0534,  1.8650, -1.0750],\n",
            "        [-2.5723, -5.4096, -4.3801,  ..., -1.2471, -0.5079,  0.7686],\n",
            "        [-0.9427,  5.6090, -2.5220,  ..., -1.2783, -0.5103,  0.4280],\n",
            "        ...,\n",
            "        [ 2.0146,  0.9441, -3.6431,  ...,  2.8463,  0.4384, -1.1421],\n",
            "        [-3.2045, -1.6165, -0.2450,  ..., -1.8892, -1.8700, -0.0559],\n",
            "        [-1.9528, -0.3596, -0.3914,  ..., -2.0938,  1.6869,  4.9348]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3609e-01, -3.4669e+00, -3.4750e+00,  ..., -3.1170e+00,\n",
            "         -6.8967e-01,  3.8048e-03],\n",
            "        [ 1.9968e+00,  4.5775e+00, -1.2422e+00,  ..., -2.8528e+00,\n",
            "         -2.2662e-01,  3.1415e+00],\n",
            "        [-8.8344e-01,  3.6581e+00, -1.7016e+00,  ..., -2.9603e+00,\n",
            "         -1.2557e+00,  2.6760e+00],\n",
            "        ...,\n",
            "        [ 1.6688e+00, -8.4361e-01, -3.5512e+00,  ...,  1.4492e+00,\n",
            "          5.0470e+00,  2.4949e+00],\n",
            "        [-1.1000e+00, -5.7493e-02, -2.0915e+00,  ..., -1.9585e+00,\n",
            "         -5.5239e-03,  5.8548e+00],\n",
            "        [-5.1153e-01,  1.3426e+00, -1.8780e+00,  ..., -1.1614e+00,\n",
            "         -4.1312e+00, -4.9803e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.1470, -6.2042, -3.7653,  ..., -5.5433, -2.9055,  3.6890],\n",
            "        [-0.4954,  2.6878, -1.5675,  ..., -0.8532, -4.6173,  0.5375],\n",
            "        [ 2.0180,  3.9181, -1.2077,  ..., -2.3234, -0.2310,  1.4419],\n",
            "        ...,\n",
            "        [-3.5781, -3.3300,  0.0171,  ..., -2.3768, -2.2909,  3.3156],\n",
            "        [-2.8687, -0.1682, -0.6288,  ...,  0.4505, -0.5058,  1.8138],\n",
            "        [ 1.6894,  4.6777, -2.0795,  ..., -2.5514, -0.5141,  0.5872]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4841e+00, -4.4095e+00, -4.1061e+00,  ..., -4.5856e+00,\n",
            "          1.1926e+00,  4.4105e+00],\n",
            "        [-3.5950e-02,  1.8875e+00, -1.5399e+00,  ...,  2.1571e-01,\n",
            "         -1.0450e+00,  1.1093e+00],\n",
            "        [-4.3589e+00, -2.4412e+00, -1.9314e+00,  ..., -6.6690e-01,\n",
            "         -2.6738e+00, -7.3265e-02],\n",
            "        ...,\n",
            "        [-3.5769e+00, -1.2306e+00, -5.6368e-01,  ...,  2.2630e-03,\n",
            "          4.0619e-01, -2.3993e-02],\n",
            "        [-1.7488e+00,  1.6879e+00, -1.7768e+00,  ..., -1.0774e+00,\n",
            "          2.9241e+00,  2.4346e+00],\n",
            "        [ 1.0391e+00, -7.0068e-01, -3.9576e+00,  ..., -3.9418e+00,\n",
            "          7.4914e+00,  3.0627e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2869,  1.3696, -0.3164,  ..., -0.9202, -0.8634, -1.0320],\n",
            "        [-0.9033, -1.3710, -1.8928,  ..., -3.0672,  0.8915,  0.1222],\n",
            "        [-3.8708, -5.9894, -6.6563,  ..., -1.0673, -2.3357, -3.5515],\n",
            "        ...,\n",
            "        [-0.1696, -3.9526, -0.5450,  ..., -2.3640,  2.2002, -2.0579],\n",
            "        [ 0.9181,  3.9069, -2.5281,  ..., -0.6392,  1.1399, -1.2276],\n",
            "        [-0.1527,  4.9388, -1.0245,  ..., -0.4881, -1.8773,  0.5820]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8071,  1.6540, -1.1630,  ...,  1.1047, -1.2229, -0.9427],\n",
            "        [-2.4175, -3.0459, -2.0787,  ..., -1.0262, -0.6987,  1.2858],\n",
            "        [-1.5980,  0.0505, -2.2483,  ..., -2.0807,  0.3283,  1.3546],\n",
            "        ...,\n",
            "        [-1.2425, -5.0902, -3.6774,  ..., -2.6960, -3.6027,  2.5563],\n",
            "        [-3.7912, -1.2485, -3.4674,  ..., -2.9826,  2.9764,  3.3792],\n",
            "        [ 2.0642,  4.0688, -1.1788,  ..., -1.6388,  0.0843,  0.7899]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3616,  1.1215, -2.6579,  ..., -1.3229,  2.9487,  0.7987],\n",
            "        [-0.5961,  0.4210, -3.1071,  ..., -0.9822,  1.6095,  1.1219],\n",
            "        [-0.7063,  4.6461, -2.0824,  ...,  0.2523,  0.4430,  0.0553],\n",
            "        ...,\n",
            "        [-3.8241, -0.4266,  0.9391,  ..., -0.5782, -0.7606,  1.6453],\n",
            "        [ 0.1613,  6.0520, -2.5491,  ..., -0.8420, -0.2889,  0.3539],\n",
            "        [ 0.1074,  3.0734,  0.0696,  ..., -1.2555,  0.7976,  0.2582]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7738,  2.7591, -1.8042,  ..., -1.1823, -2.5095, -0.5950],\n",
            "        [-0.4010,  3.1557, -2.8960,  ..., -1.4331, -4.8501, -2.2027],\n",
            "        [ 1.1467, -2.9079, -4.0894,  ..., -1.3917,  4.5046,  0.7911],\n",
            "        ...,\n",
            "        [ 1.7562,  0.7480, -4.2623,  ..., -3.3789,  6.3629,  2.1172],\n",
            "        [ 1.0328,  4.9382, -3.5236,  ..., -1.5097, -2.8809, -1.1009],\n",
            "        [-1.5068,  0.3151, -1.1478,  ..., -0.6668,  2.5294,  1.1767]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8260, -2.5047, -3.5858,  ..., -3.2893,  3.1837,  3.2717],\n",
            "        [-1.9520, -3.9252, -1.8254,  ..., -0.6071,  2.2179, -1.7188],\n",
            "        [-3.1303, -6.6712, -4.2346,  ..., -5.2929,  0.2237,  2.3122],\n",
            "        ...,\n",
            "        [ 1.4030,  2.5415, -0.9555,  ..., -2.0965,  0.7448,  2.2148],\n",
            "        [-2.9068, -1.1041, -3.5125,  ..., -2.1922,  0.1385, -1.2031],\n",
            "        [-0.4112,  3.5356, -2.3736,  ..., -0.0565, -5.3791, -0.1473]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9513, -3.0039,  2.4006,  ..., -1.7849, -2.1565,  1.0236],\n",
            "        [-1.9729, -2.8143, -3.8365,  ..., -1.2347,  0.8260,  0.6557],\n",
            "        [-0.8115,  1.1288, -1.1528,  ..., -3.3500,  0.7877,  3.3001],\n",
            "        ...,\n",
            "        [-2.1821,  1.3937, -2.6083,  ...,  0.5042, -0.2364, -2.0725],\n",
            "        [-3.1858, -0.8929, -3.5020,  ..., -1.4265, -0.4291,  3.4509],\n",
            "        [-0.1210, -2.7001, -4.8651,  ..., -4.0918,  3.8092,  4.9615]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7183,  1.5170, -2.0284,  ...,  0.6358, -1.5966,  1.4285],\n",
            "        [ 2.6678,  4.5104, -1.1487,  ..., -0.8391, -0.7840,  2.6498],\n",
            "        [-0.6395,  5.5410, -1.7488,  ..., -1.0861, -0.4710, -0.3063],\n",
            "        ...,\n",
            "        [ 3.0288,  0.1176, -1.4831,  ..., -2.1726,  2.2971, -3.1461],\n",
            "        [-0.7645,  0.6631, -0.6452,  ..., -0.3952, -1.3452,  1.5453],\n",
            "        [ 1.2696, -6.0876, -3.6679,  ..., -1.6808,  3.1683,  0.7190]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8121,  1.4797, -3.1057,  ..., -2.1307,  5.7743, -0.1656],\n",
            "        [-1.7361,  0.1118, -0.3145,  ..., -0.9203, -0.3791,  2.2493],\n",
            "        [ 2.2782,  4.8052, -1.1547,  ..., -0.6746, -0.2553,  2.1543],\n",
            "        ...,\n",
            "        [-1.0133, -0.5496, -3.2908,  ...,  1.8465, -1.1229, -0.8970],\n",
            "        [ 1.6632,  4.4790, -1.8089,  ..., -0.9397, -0.3037,  2.6700],\n",
            "        [-0.1398,  6.3526, -2.2085,  ..., -1.7159,  0.4709, -1.2237]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.5804, -5.9508, -2.2018,  ..., -1.2115, -1.6492, -1.0231],\n",
            "        [-1.3405, -5.5560, -2.4431,  ..., -2.8415, -3.5022,  1.0725],\n",
            "        [-0.9941,  5.4888, -1.5595,  ..., -1.2548, -1.2457, -0.4448],\n",
            "        ...,\n",
            "        [-2.8519, -0.3601, -5.5331,  ..., -2.3782, -2.1119, -0.8614],\n",
            "        [ 0.8221,  1.0607, -3.9505,  ...,  0.1298,  0.1867,  0.5998],\n",
            "        [ 0.3687,  3.5005, -2.1492,  ..., -0.1014, -1.6124, -1.1926]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.2866, -5.6672, -3.1579,  ..., -3.9782,  2.3848,  5.1478],\n",
            "        [-3.8927,  2.0219, -1.1159,  ...,  0.6153, -0.5184,  0.4894],\n",
            "        [ 0.1182,  5.4333, -1.0918,  ..., -1.8758,  0.2342,  1.8004],\n",
            "        ...,\n",
            "        [-1.3473,  7.2742, -2.3995,  ..., -0.2452, -1.1581, -0.6049],\n",
            "        [-1.4518, -3.3560,  0.3379,  ..., -0.3968, -0.8418,  0.1673],\n",
            "        [-0.3796,  2.0510, -2.5410,  ..., -1.7875,  0.9235,  1.7219]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4924, -1.7668, -0.4803,  ..., -0.1111,  1.8042,  0.4379],\n",
            "        [-3.4693,  1.0686, -2.3379,  ..., -0.8767,  1.1984, -0.4100],\n",
            "        [ 2.1412,  5.3838, -1.4105,  ..., -1.0897, -0.4006,  1.5816],\n",
            "        ...,\n",
            "        [-0.6369,  4.5070, -3.7843,  ...,  0.9421,  1.0884,  0.5874],\n",
            "        [-0.9913,  1.0554, -3.3187,  ..., -0.6228, -1.6392, -3.1049],\n",
            "        [-3.3595, -1.9520, -4.3653,  ..., -2.9366, -0.4658,  2.3439]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0435,  2.3822, -1.7459,  ..., -0.9670, -1.7310, -0.5902],\n",
            "        [-2.1633,  1.7363, -2.9148,  ..., -1.1439, -3.6018, -1.6335],\n",
            "        [-1.2566, -4.0788, -4.1023,  ...,  0.4212, -0.6318, -1.6442],\n",
            "        ...,\n",
            "        [ 0.3514, -2.2188, -0.7204,  ...,  0.1794,  2.0726,  1.2500],\n",
            "        [ 0.5493,  1.5370, -4.6509,  ..., -2.5679,  8.1295,  2.1326],\n",
            "        [-2.1927, -0.5384, -1.3255,  ..., -1.3492, -2.0520,  2.3327]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7541, -5.5626, -1.8913,  ..., -0.7341,  1.0308,  0.2454],\n",
            "        [-6.6737, -3.1962, -1.6012,  ..., -2.7076, -0.9622, -2.0121],\n",
            "        [ 0.4447,  3.5909, -0.6510,  ...,  0.4134, -1.1574, -0.1307],\n",
            "        ...,\n",
            "        [ 1.3555,  3.8709, -2.5080,  ..., -0.1577,  0.2390, -0.2560],\n",
            "        [ 0.7161,  2.8263, -0.8613,  ..., -1.3590,  1.5771,  0.9676],\n",
            "        [-2.2171, -1.4932,  1.1814,  ..., -0.6238, -1.0302,  1.6439]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1048,  2.0101, -3.2246,  ...,  4.0078, -1.1640, -1.1443],\n",
            "        [-4.9483, -1.1372, -2.0414,  ..., -0.9685, -1.0821, -1.0069],\n",
            "        [-1.2959, -8.4635, -5.9887,  ..., -2.2101, -3.3019,  0.3447],\n",
            "        ...,\n",
            "        [-0.7700,  1.4250, -2.1756,  ..., -2.0205, -1.9630, -0.0945],\n",
            "        [-6.8239, -2.5885, -0.5979,  ..., -0.9006,  0.0209, -1.9545],\n",
            "        [-2.2882,  5.9207, -5.1857,  ..., -0.3625, -2.5641,  0.3908]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4921,  5.5941, -3.2411,  ..., -2.5712, -0.6438,  1.1461],\n",
            "        [-3.6834, -5.2063, -1.7901,  ..., -1.2729, -1.1884, -0.0418],\n",
            "        [-0.6115,  0.4945, -2.9620,  ..., -0.0593,  3.0523, -0.1696],\n",
            "        ...,\n",
            "        [-0.6536,  1.9489, -0.6422,  ..., -0.3132, -0.8868,  0.7982],\n",
            "        [ 0.7441,  2.6543, -1.5695,  ..., -1.2644, -1.7722, -0.5038],\n",
            "        [-2.4421, -6.2795, -2.7346,  ..., -2.3411, -1.4176, -1.5836]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6289, -5.7980, -1.4956,  ..., -0.6620, -0.8809, -3.3478],\n",
            "        [-3.2268, -2.3638, -1.1778,  ...,  0.3487, -0.7350, -2.8609],\n",
            "        [-1.2826,  3.9942, -1.7585,  ..., -0.1898, -1.0273,  0.7485],\n",
            "        ...,\n",
            "        [-4.4868, -8.7375, -5.0971,  ..., -4.5726, -2.2500,  0.1626],\n",
            "        [-5.4227, -5.8578, -2.2753,  ..., -3.8857,  0.3897,  3.3168],\n",
            "        [-0.8792, -0.4828, -1.6508,  ..., -1.5768,  4.2414,  1.2303]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5801, -3.1393, -0.6030,  ..., -2.1801,  2.7409,  0.4978],\n",
            "        [-4.1345, -3.1724, -2.6401,  ..., -4.0008,  0.3437,  2.2114],\n",
            "        [ 1.5950,  2.1007, -2.6798,  ..., -0.8321,  4.6393,  0.4310],\n",
            "        ...,\n",
            "        [-0.2281, -7.1866, -3.4168,  ..., -2.2128,  3.6456,  0.6148],\n",
            "        [-5.5668, -6.1336, -5.3198,  ..., -2.1818,  3.3653, -5.9408],\n",
            "        [-0.7119,  5.9617, -1.7287,  ..., -1.9379, -1.5278, -0.2627]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.5978e-01,  6.5280e-01, -2.5475e-01,  ..., -2.2256e+00,\n",
            "          2.0977e-01,  3.8273e+00],\n",
            "        [ 3.0479e-01, -4.7571e-01, -2.8442e+00,  ..., -2.5904e+00,\n",
            "          4.9239e+00,  1.4598e+00],\n",
            "        [ 2.1898e+00, -9.2830e-01, -1.9921e+00,  ..., -3.3823e+00,\n",
            "          5.5143e+00, -1.9101e+00],\n",
            "        ...,\n",
            "        [-2.6176e+00,  1.5099e+00, -2.1541e+00,  ...,  1.9555e-01,\n",
            "          6.9840e-01, -5.6529e-01],\n",
            "        [ 1.1904e-01,  2.9395e+00, -2.9668e+00,  ..., -4.4244e-01,\n",
            "          2.2103e-01,  5.3700e-01],\n",
            "        [-1.8478e+00,  1.2418e+00, -1.4281e+00,  ..., -1.0361e+00,\n",
            "         -2.9598e-03,  5.1011e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8909e+00, -2.9046e+00, -4.8360e+00,  ...,  8.7287e-01,\n",
            "          3.5957e+00, -2.5091e+00],\n",
            "        [-1.9036e+00,  3.7269e+00, -8.1683e-01,  ...,  1.6645e-01,\n",
            "         -1.3942e-01, -5.4860e-01],\n",
            "        [ 1.6834e+00,  3.8751e+00, -1.3685e+00,  ..., -8.1555e-01,\n",
            "         -3.1557e-01,  2.2336e+00],\n",
            "        ...,\n",
            "        [-4.4794e+00,  1.9691e-03,  9.3860e-03,  ..., -2.2613e+00,\n",
            "         -5.7261e-01,  9.7713e-01],\n",
            "        [-2.2018e+00,  6.0594e+00, -3.1938e+00,  ...,  4.0353e-01,\n",
            "         -1.7704e-01, -1.3761e+00],\n",
            "        [-3.6689e+00,  2.2904e+00, -2.4658e+00,  ..., -2.9249e-01,\n",
            "         -1.7237e+00, -2.5759e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6671, -1.8900, -3.5933,  ...,  1.1673,  0.3446, -0.4684],\n",
            "        [-1.5659, -3.6971, -3.8270,  ...,  0.6548,  1.7462,  0.4821],\n",
            "        [-0.9469,  1.2634, -0.9685,  ..., -0.6077, -0.3826, -0.7092],\n",
            "        ...,\n",
            "        [-3.5616,  2.2293, -2.1208,  ...,  0.4247, -2.6152, -3.7747],\n",
            "        [-1.5828,  3.0254, -3.7457,  ...,  0.7486,  2.0386,  0.2248],\n",
            "        [ 2.1111, -0.4748, -4.3808,  ...,  0.6838,  5.3111,  2.3097]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4634,  2.3392, -1.3804,  ..., -0.8603,  0.5724,  2.1415],\n",
            "        [ 0.9614,  0.5660, -3.9509,  ..., -0.9006,  4.8218,  2.0303],\n",
            "        [-0.7212,  3.1555, -1.6135,  ..., -2.3607, -5.3817,  1.4025],\n",
            "        ...,\n",
            "        [-0.9125,  4.1573, -2.5461,  ..., -1.2051,  1.3389, -3.0181],\n",
            "        [-5.9498, -5.4817, -1.7004,  ..., -4.4240, -2.5050,  3.8450],\n",
            "        [ 0.5762,  5.4148, -2.2816,  ...,  0.2271, -0.3105, -1.9186]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6500,  0.2686, -2.9847,  ..., -1.7306, -0.8259, -2.4675],\n",
            "        [-0.1430,  1.9293, -1.0620,  ...,  2.2642,  1.6897,  1.2730],\n",
            "        [-3.8991,  2.5469, -3.4461,  ...,  0.9002, -1.1484, -4.7527],\n",
            "        ...,\n",
            "        [-2.9384,  4.5792, -3.2083,  ..., -0.4346, -1.4215, -1.4522],\n",
            "        [-5.7349,  0.0661, -2.1262,  ..., -1.3544,  0.0657,  1.5257],\n",
            "        [-2.1475, -1.5759, -3.1916,  ..., -0.5073, -0.7411,  2.1274]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7498,  2.2603, -2.3122,  ..., -1.5219,  2.3188,  3.2469],\n",
            "        [-3.4473, -1.6110, -2.5278,  ...,  0.7021, -0.2574, -2.3105],\n",
            "        [-0.4844,  5.1726, -2.6102,  ..., -0.0177, -1.7115,  0.1159],\n",
            "        ...,\n",
            "        [-1.2032,  2.5489, -1.5385,  ..., -0.0462,  1.5688, -0.2369],\n",
            "        [-4.4055, -2.8678, -3.9490,  ..., -3.6731, -0.7311, -0.9669],\n",
            "        [ 1.6893, -0.2297, -0.5154,  ..., -1.9694,  1.7165, -3.8306]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6092,  1.6492, -2.9760,  ..., -2.5427,  1.0974,  1.6539],\n",
            "        [-2.1455, -2.2164,  1.3814,  ..., -0.6265, -0.3748,  2.5830],\n",
            "        [-3.1868, -0.0214, -0.6288,  ..., -0.1682, -1.7120,  1.3081],\n",
            "        ...,\n",
            "        [-0.7908,  2.2795, -0.8269,  ...,  0.3473, -2.1267,  0.5843],\n",
            "        [-3.9131,  1.1782, -0.3415,  ..., -0.5677,  0.2444,  1.0229],\n",
            "        [-0.2375,  3.4569, -2.6056,  ..., -1.0006,  2.8746, -1.8451]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -1.0416,   6.4793,  -3.1738,  ...,   3.3331,  -0.4447,   0.3280],\n",
            "        [ -1.9570,  -0.4982,  -3.5489,  ...,  -0.7162,   1.3686,   0.7072],\n",
            "        [ -0.6639,   0.2686,  -1.4498,  ...,  -2.4608,  -2.3939,   3.4997],\n",
            "        ...,\n",
            "        [ -3.6056, -10.1139,  -3.1351,  ...,  -3.8630,  -1.8123,   0.8056],\n",
            "        [ -0.1598,   2.4740,  -0.6049,  ...,  -0.1468,   1.3693,   1.3951],\n",
            "        [  0.4919,   5.4382,  -1.9089,  ...,  -2.1225,   1.3874,   1.0835]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9451, -0.5750, -0.0445,  ..., -0.5300, -2.2893,  0.3853],\n",
            "        [-1.6781, -2.3172, -0.8068,  ..., -1.0958,  2.2482, -1.3131],\n",
            "        [ 1.4248,  5.1085, -3.3364,  ..., -1.9995, -1.2440, -0.1795],\n",
            "        ...,\n",
            "        [-0.3058,  2.7536, -2.4658,  ..., -1.4883, -2.1464, -1.0085],\n",
            "        [ 1.5462,  3.9401, -0.1281,  ..., -0.5348,  0.3221,  0.5118],\n",
            "        [ 1.7745,  6.3769, -1.6641,  ..., -2.6373, -0.1844,  2.8110]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8693,  2.5031, -2.0861,  ..., -2.5590, -0.7090,  1.7392],\n",
            "        [-4.3669, -1.5469, -1.1070,  ...,  0.0485,  0.3586,  0.6102],\n",
            "        [ 0.5716,  1.1951, -0.5053,  ..., -3.9036,  3.3041, -3.6654],\n",
            "        ...,\n",
            "        [-1.4910,  7.1283, -2.6567,  ..., -1.8103, -0.0930, -1.7674],\n",
            "        [-3.0629,  0.0857, -2.9665,  ..., -0.8118,  4.2663,  0.8992],\n",
            "        [-0.3417, -2.8555, -2.1597,  ...,  1.6437,  0.7594, -2.5286]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2313,  3.1740, -1.7003,  ..., -2.6140, -1.5263,  0.4890],\n",
            "        [-7.1533, -6.4906, -2.7862,  ..., -2.5074, -2.9299, -2.2864],\n",
            "        [-4.4062, -7.5018, -4.5465,  ..., -4.8240, -3.6723,  3.3052],\n",
            "        ...,\n",
            "        [ 2.4478,  0.2638, -3.6946,  ..., -3.0487,  0.9777,  0.0091],\n",
            "        [-2.6507,  1.5953, -4.2839,  ..., -2.8910,  1.0906, -1.9675],\n",
            "        [-1.2955, -0.7481, -3.2370,  ..., -0.9700,  1.1228, -0.1961]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4997, -1.5467, -2.2643,  ..., -2.0122,  2.5673, -2.2533],\n",
            "        [ 0.9575,  0.5942, -2.2297,  ..., -2.7627, -3.9358, -0.3936],\n",
            "        [-3.5317, -6.3523, -3.0356,  ..., -0.2931,  1.5019,  3.8386],\n",
            "        ...,\n",
            "        [-0.2095,  0.5584, -0.3093,  ..., -0.8592,  0.4483,  1.8342],\n",
            "        [-5.1838, -7.0810, -4.6035,  ..., -3.5888, -0.4830, -3.2845],\n",
            "        [-0.2291,  2.6401, -1.9396,  ..., -1.6265, -3.1090, -0.9686]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1846,  4.9761, -1.5671,  ..., -1.1770,  0.5194,  0.7486],\n",
            "        [ 0.0727,  4.8359, -3.2137,  ..., -0.4279,  0.0142, -1.3286],\n",
            "        [ 1.6969, -0.0198, -2.4971,  ..., -2.5668,  2.4101, -2.2618],\n",
            "        ...,\n",
            "        [-4.0797, -3.4177, -3.0342,  ...,  1.5648, -0.2379, -3.4067],\n",
            "        [-0.7354, -2.1112, -2.5808,  ..., -0.2036,  2.2628,  3.7690],\n",
            "        [ 0.2590,  3.8949, -0.9329,  ...,  0.3831,  0.5424, -0.6744]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8988,  4.1279, -1.2095,  ..., -1.5310,  0.0376,  0.9722],\n",
            "        [ 0.2614,  2.7973, -0.7135,  ...,  0.2613,  0.5679,  0.2045],\n",
            "        [-3.5121, -2.0480, -0.9952,  ..., -3.6539,  0.1987, -1.2202],\n",
            "        ...,\n",
            "        [ 3.0002,  5.4013, -1.6989,  ..., -1.1595, -0.0475,  0.9834],\n",
            "        [-0.1118,  0.9227, -2.0825,  ..., -2.1460,  1.7049,  1.9493],\n",
            "        [-4.9995, -2.8059, -2.9384,  ..., -1.5030,  1.5146,  1.6105]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3774,  4.3144, -3.5749,  ..., -0.4645, -0.8543, -1.4660],\n",
            "        [ 1.6357, -0.5963, -1.2814,  ..., -1.0268,  1.6431, -0.9250],\n",
            "        [-1.5582,  1.7136, -2.0917,  ...,  0.3737, -1.6391,  1.9479],\n",
            "        ...,\n",
            "        [-1.0994,  1.9067, -1.8998,  ..., -1.1888, -4.0287, -1.6425],\n",
            "        [-1.2643,  2.7703, -3.9037,  ..., -1.0431,  0.2717, -0.4982],\n",
            "        [-4.6335, -0.2502, -2.3365,  ...,  1.6900, -1.5342,  1.1558]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4007, -5.0083, -2.8585,  ..., -1.4187, -0.6951, -0.7566],\n",
            "        [-1.0774,  2.5309, -0.9474,  ..., -0.9226, -0.4262, -0.6451],\n",
            "        [-1.9534, -1.8679,  1.0554,  ..., -1.1547, -1.6458,  3.0501],\n",
            "        ...,\n",
            "        [-2.4578,  5.7838, -2.8035,  ..., -0.1833,  2.1123, -2.7974],\n",
            "        [-1.5019,  3.4581, -4.5514,  ..., -0.1081,  2.1426, -1.7884],\n",
            "        [-0.6784,  1.2152, -1.9578,  ..., -2.7053,  2.2212, -0.2070]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9458, -7.1345, -3.3473,  ..., -2.4407,  0.8805,  0.9925],\n",
            "        [-0.9082, -1.3950, -2.5765,  ..., -0.2493, -0.9095, -2.0590],\n",
            "        [-5.2521, -4.5097, -4.1622,  ...,  0.1010,  2.4651,  2.4159],\n",
            "        ...,\n",
            "        [-0.5539,  0.5893, -3.1752,  ..., -2.0740,  2.8017,  2.1484],\n",
            "        [-1.9027, -0.5058, -1.7424,  ..., -0.5221, -1.9965,  2.1492],\n",
            "        [ 0.8249, -1.4103, -4.6883,  ..., -5.2307,  2.5673, -4.0593]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4494e+00,  4.5271e+00, -2.9299e+00,  ..., -2.0631e+00,\n",
            "         -2.2575e+00, -9.4986e-01],\n",
            "        [-5.0780e+00, -2.6515e+00, -4.2890e+00,  ..., -1.7212e+00,\n",
            "          3.8919e+00,  3.5558e+00],\n",
            "        [-3.3486e+00,  3.0120e+00, -1.9032e+00,  ..., -1.9238e+00,\n",
            "         -8.9760e-02,  7.9611e-01],\n",
            "        ...,\n",
            "        [-8.4752e-01, -8.7353e-01, -2.7138e+00,  ..., -1.2959e-03,\n",
            "          1.5429e+00, -7.8862e-02],\n",
            "        [-6.6965e-01,  7.0524e+00, -2.3132e+00,  ..., -2.0079e+00,\n",
            "         -6.5465e-01,  3.5616e-01],\n",
            "        [ 1.5062e+00,  7.3000e-02, -3.4074e+00,  ..., -8.7278e-01,\n",
            "          7.0355e+00, -8.3697e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6537e+00, -8.5905e-01, -3.7773e+00,  ..., -5.2916e-01,\n",
            "          6.3972e+00,  2.5365e+00],\n",
            "        [-2.4047e+00, -6.9657e-01, -9.2793e-01,  ..., -1.0166e+00,\n",
            "          2.5464e+00, -2.2374e+00],\n",
            "        [ 1.9749e+00,  5.8866e+00, -2.6156e+00,  ..., -1.9647e+00,\n",
            "         -5.2950e-03,  8.0414e-01],\n",
            "        ...,\n",
            "        [-2.1253e+00,  4.1783e+00, -3.7823e+00,  ..., -2.5154e+00,\n",
            "         -1.3231e+00, -1.3892e+00],\n",
            "        [-1.0484e+00, -4.6510e+00, -4.0364e+00,  ...,  1.6418e+00,\n",
            "          2.5885e-01, -3.9009e+00],\n",
            "        [ 1.5707e+00,  4.9039e+00, -2.7858e+00,  ..., -1.1260e+00,\n",
            "         -9.6303e-01, -9.0122e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2830,  1.3042, -2.4621,  ..., -2.7600,  4.4156,  2.0284],\n",
            "        [-0.7288, -2.0297, -2.4213,  ..., -3.4987,  0.6906, -2.0637],\n",
            "        [-3.2864, -0.0824, -0.5739,  ..., -1.4943,  1.5247, -3.4387],\n",
            "        ...,\n",
            "        [-0.4277,  2.7870, -2.8872,  ..., -1.6419, -3.2255,  2.4439],\n",
            "        [-2.3911, -0.7252, -0.4406,  ..., -2.5192, -1.4693, -1.6239],\n",
            "        [ 1.3954,  1.8648, -2.1111,  ..., -1.3012,  0.6073,  2.2830]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.9676e+00, -2.3059e+00, -2.0753e+00,  ..., -3.3402e+00,\n",
            "         -4.1205e-01,  6.6386e-02],\n",
            "        [-3.3706e-01, -1.9609e-01, -1.3096e+00,  ...,  1.6231e+00,\n",
            "          9.6504e-01,  3.0466e+00],\n",
            "        [-9.9267e-01,  4.7441e+00, -5.0377e+00,  ..., -1.9523e+00,\n",
            "         -2.7132e+00,  1.5935e-01],\n",
            "        ...,\n",
            "        [ 8.1656e-04,  1.0478e+00, -1.3967e+00,  ..., -5.9782e-01,\n",
            "         -2.4526e+00, -7.6100e-01],\n",
            "        [-2.2112e+00, -1.2086e+00, -2.7103e+00,  ..., -3.8119e+00,\n",
            "          2.0279e+00,  3.7338e+00],\n",
            "        [-1.9834e+00,  2.1424e+00, -2.4873e+00,  ..., -5.4933e-01,\n",
            "          7.4941e-01, -7.3795e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3204,  6.7029, -2.9417,  ..., -0.2816, -1.5238, -1.0103],\n",
            "        [ 0.7294, -1.9203, -3.1496,  ..., -4.1332,  7.4006,  0.9972],\n",
            "        [ 2.1272,  0.5185, -4.6867,  ..., -4.6115,  6.9910, -1.6516],\n",
            "        ...,\n",
            "        [-2.0671,  4.3454, -1.4646,  ...,  1.7204,  0.9464, -2.1874],\n",
            "        [-0.2495, -2.1351, -1.9511,  ..., -2.3170, -1.7694, -0.8933],\n",
            "        [-2.6555,  4.0125, -3.6214,  ...,  0.7422,  1.7110, -3.6247]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9664,  1.6468, -1.6142,  ...,  1.3050,  2.8277,  0.4409],\n",
            "        [ 0.5214, -0.7592, -3.9179,  ..., -5.0314,  6.2690, -0.1274],\n",
            "        [-3.1085, -1.3464, -3.7535,  ..., -2.3662,  0.4517,  0.0289],\n",
            "        ...,\n",
            "        [ 1.5538,  2.1162, -0.9331,  ..., -1.0596,  1.6301,  0.0985],\n",
            "        [ 0.0939,  3.0317, -2.7804,  ..., -2.3148, -2.1051, -1.8637],\n",
            "        [-1.7186,  0.7123, -0.9706,  ...,  0.8903, -1.4321,  0.6975]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2215, -9.3897, -3.8618,  ..., -3.0006,  0.1594,  1.7741],\n",
            "        [ 0.7171,  3.6007, -2.0253,  ..., -0.3092, -2.4035, -0.2804],\n",
            "        [ 2.6632,  5.6121, -1.8986,  ..., -1.0159,  0.3619,  1.4176],\n",
            "        ...,\n",
            "        [ 1.5319, -6.6989, -1.7815,  ..., -1.3790, -0.3200, -3.2513],\n",
            "        [ 2.6130,  0.1052, -2.1292,  ..., -2.0081,  2.3242, -0.7336],\n",
            "        [-1.3362,  4.8530, -1.8987,  ..., -1.0592, -1.6482, -1.9741]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1464, -1.2298, -3.4822,  ..., -0.0565,  5.7140,  1.5372],\n",
            "        [ 1.6115,  1.1871, -2.9170,  ..., -4.1690,  6.0419,  0.1314],\n",
            "        [-0.0675, -3.3961, -3.5024,  ..., -2.4212,  0.1236, -0.4512],\n",
            "        ...,\n",
            "        [-0.8455,  1.8938, -1.0409,  ..., -1.2401, -3.3452,  0.9811],\n",
            "        [-3.8825, -0.2978, -3.6414,  ..., -1.5491,  3.0913,  0.5639],\n",
            "        [ 1.8712,  1.2240, -3.9183,  ..., -2.4864,  5.7306, -0.2519]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8516,  3.2030, -3.3628,  ...,  2.0658,  0.8195, -1.8770],\n",
            "        [ 1.3657, -2.8069, -4.7696,  ..., -0.3849,  7.1188,  1.4164],\n",
            "        [-1.8879, -2.2726,  0.4636,  ..., -0.9435, -0.1940,  0.6814],\n",
            "        ...,\n",
            "        [-6.2256, -2.8025, -1.0629,  ..., -1.3056,  1.1097,  0.3636],\n",
            "        [ 1.1114,  2.1138,  0.0098,  ..., -2.0424,  1.7549,  2.9910],\n",
            "        [ 2.4222,  4.7576, -1.7723,  ..., -0.7647,  0.1418,  2.3523]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7058,  3.3459, -0.9698,  ..., -1.1494,  0.5612,  0.8662],\n",
            "        [-3.3879,  0.9485, -1.4646,  ..., -0.8336, -0.5405, -2.9528],\n",
            "        [-0.1061, -1.5819, -4.1585,  ..., -1.8890,  3.7748, -1.0122],\n",
            "        ...,\n",
            "        [ 2.7567,  0.0101, -2.6027,  ..., -3.3012,  5.2712, -3.1554],\n",
            "        [ 0.9830,  3.1623, -0.8231,  ..., -1.2410,  0.2226,  1.4452],\n",
            "        [-3.2110,  0.0643, -3.0615,  ...,  0.4389,  6.0622,  0.8913]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7001,  1.4570, -4.4752,  ..., -1.4752,  4.3355,  2.0314],\n",
            "        [-3.0364, -0.9555, -0.9297,  ..., -3.3557,  1.8442,  4.0755],\n",
            "        [ 1.9895, -0.1962, -3.7104,  ..., -1.4440,  6.3041,  0.6719],\n",
            "        ...,\n",
            "        [ 1.3052, -4.2425, -0.4312,  ...,  0.4241,  1.1867, -0.2261],\n",
            "        [ 2.9464,  5.3876, -2.2997,  ..., -1.0643,  0.5986, -0.3967],\n",
            "        [-1.8302, -1.6347, -0.7999,  ...,  0.1104, -1.1491,  1.2454]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0630,  0.0854, -2.1362,  ..., -4.5401,  6.9641, -1.6843],\n",
            "        [-5.7623, -6.2780, -4.4527,  ..., -4.0453, -3.6590,  1.4997],\n",
            "        [-1.8422, -3.2658, -3.0397,  ..., -3.9981,  2.8762,  2.8381],\n",
            "        ...,\n",
            "        [-3.0895, -1.9716, -0.7942,  ...,  0.2204, -1.8912,  0.5160],\n",
            "        [ 0.0785,  6.5613, -3.1633,  ..., -2.4735,  0.9906, -3.2755],\n",
            "        [ 0.6084, -2.1979, -1.1483,  ..., -1.1367,  1.9798, -1.1604]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8564, -1.8012, -0.1061,  ..., -0.3231, -1.3418,  0.6380],\n",
            "        [-2.1114, -0.8268, -0.1399,  ...,  0.1501, -0.4254,  1.8627],\n",
            "        [ 2.6783,  0.8131, -3.0570,  ..., -3.1478,  5.5575, -3.4559],\n",
            "        ...,\n",
            "        [-4.3296, -5.0355, -1.5592,  ...,  1.7082,  1.5050,  0.0654],\n",
            "        [-4.4469, -5.5438,  0.0323,  ..., -0.3313,  2.5858, -2.3529],\n",
            "        [ 0.3989,  4.6862, -3.3831,  ..., -2.9588, -4.8833,  2.0457]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6988, -0.2460, -2.1091,  ...,  1.9596,  0.1438, -2.2267],\n",
            "        [-2.0847,  1.5630, -2.4777,  ..., -0.6611,  4.4474,  1.6248],\n",
            "        [-3.7015,  1.0019, -3.7559,  ...,  1.9886, -0.6665, -3.2968],\n",
            "        ...,\n",
            "        [ 0.8114, -2.5581, -3.8975,  ..., -2.1810,  8.1965,  2.0621],\n",
            "        [-2.7162,  2.4751, -2.3902,  ..., -0.5766, -0.9155, -2.2881],\n",
            "        [ 2.6902, -2.6870, -3.7756,  ..., -4.8739,  6.1122, -2.2374]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5296e+00, -2.5037e-01, -1.0509e+00,  ...,  6.4391e-02,\n",
            "         -1.4395e+00,  5.2917e-01],\n",
            "        [-1.7582e+00, -1.3071e-01, -3.3314e+00,  ..., -1.5790e+00,\n",
            "          2.0210e+00,  2.5674e+00],\n",
            "        [-2.5913e+00,  7.2318e-01, -8.1941e-01,  ..., -2.1157e+00,\n",
            "          1.7659e+00,  2.7660e+00],\n",
            "        ...,\n",
            "        [-3.8370e-01,  8.1890e-01, -1.1322e+00,  ..., -2.1637e+00,\n",
            "          9.3026e-01,  2.8745e+00],\n",
            "        [ 3.6785e+00,  5.5340e+00, -2.5471e+00,  ..., -2.1083e+00,\n",
            "         -3.7980e-03,  1.1185e+00],\n",
            "        [ 2.2605e+00,  2.4691e+00, -7.6931e-01,  ..., -1.1126e+00,\n",
            "          4.7095e-01,  1.4566e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3146e+00, -3.8667e+00, -5.8244e+00,  ..., -4.6239e+00,\n",
            "         -1.2393e+00,  2.8739e+00],\n",
            "        [ 3.7188e+00,  4.9939e+00, -2.0069e+00,  ..., -1.3964e+00,\n",
            "         -2.1578e-04,  1.5629e+00],\n",
            "        [ 3.3357e+00,  5.9806e+00, -2.0283e+00,  ..., -1.6700e+00,\n",
            "         -2.2656e-01,  1.5680e+00],\n",
            "        ...,\n",
            "        [ 2.7152e+00,  5.2321e+00, -1.9533e+00,  ..., -3.9380e+00,\n",
            "          1.3481e-01,  2.2160e+00],\n",
            "        [-1.8688e+00, -1.3430e-01, -2.6436e+00,  ..., -2.8066e+00,\n",
            "          2.2791e+00, -1.4950e+00],\n",
            "        [ 7.2976e-01,  1.7422e-01, -1.1400e+00,  ..., -3.7115e+00,\n",
            "          3.9497e+00, -4.3612e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6448, -1.8282, -0.4811,  ..., -2.4056,  0.8096,  3.3948],\n",
            "        [ 0.4806, -1.8444, -4.9493,  ..., -1.8296,  3.6183, -6.8780],\n",
            "        [-1.6850, -1.0332, -3.3747,  ..., -1.0153, -0.4147, -3.9425],\n",
            "        ...,\n",
            "        [-1.0536, -0.1710, -1.0992,  ..., -0.9463, -0.6245, -3.2051],\n",
            "        [-0.3655,  1.3265, -1.8555,  ..., -1.8682, -5.3228, -1.3780],\n",
            "        [-3.3022,  1.9472, -4.6484,  ...,  0.1469,  0.0823, -1.9639]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8811, -3.5031, -1.4539,  ...,  0.3144,  1.3089,  0.1440],\n",
            "        [-2.9535,  1.0565, -1.6797,  ..., -3.0819, -0.4986,  0.9433],\n",
            "        [ 0.0154,  1.6901, -3.2037,  ..., -1.2551, -0.5637,  1.0538],\n",
            "        ...,\n",
            "        [ 0.7435,  1.2138, -1.9334,  ..., -1.6322,  2.1525,  1.5272],\n",
            "        [-1.0228, -6.0259, -2.6669,  ..., -2.6396,  2.1247, -0.9158],\n",
            "        [ 0.6725, -6.1062, -4.4458,  ..., -6.0052,  2.8554, -0.5589]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4447, -0.3793, -3.2761,  ..., -3.2199,  1.6867,  0.5857],\n",
            "        [ 1.7333,  4.7678, -1.5231,  ..., -2.0042, -0.0646, -0.2879],\n",
            "        [-1.8020, -0.7391, -2.6090,  ..., -1.4590,  0.4944, -1.0635],\n",
            "        ...,\n",
            "        [ 0.3192,  2.4580, -0.2403,  ..., -0.0600, -1.8293,  0.5769],\n",
            "        [-4.6213, -6.4048, -3.0218,  ..., -1.9370,  1.0052, -2.4345],\n",
            "        [ 3.4702,  3.0622, -1.8217,  ..., -2.0805, -1.9034, -0.4375]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2347, -3.3204, -2.7899,  ..., -0.7066,  0.3531, -1.0373],\n",
            "        [ 1.8072, -0.4715, -2.2017,  ..., -1.9305,  6.4593, -0.3404],\n",
            "        [ 0.1923, -1.6089, -5.0429,  ..., -1.0568,  1.3795,  0.9583],\n",
            "        ...,\n",
            "        [-3.8596, -3.9935, -0.6341,  ..., -3.4025, -1.8622,  0.9822],\n",
            "        [-5.1128, -2.0652, -0.8315,  ..., -2.4852,  0.7636,  1.3656],\n",
            "        [-0.1595,  5.1239, -3.6227,  ..., -1.6460, -0.1303, -1.6006]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6907, -2.0635,  0.1999,  ..., -2.8265,  1.1585, -0.6085],\n",
            "        [-5.8400, -9.3323, -0.7287,  ..., -3.3592,  1.6412,  1.2956],\n",
            "        [ 2.4469,  2.5067, -2.2784,  ..., -0.2377, -1.2007, -1.2770],\n",
            "        ...,\n",
            "        [-0.1931,  0.9319, -2.3016,  ..., -2.0317,  1.2934, -1.4974],\n",
            "        [-4.4950, -6.7009, -4.2653,  ..., -5.2968, -1.4933,  3.8449],\n",
            "        [ 0.4208,  2.0814, -3.0360,  ..., -2.9948,  2.2362,  0.4485]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.2263e-01, -3.0271e+00, -2.8354e+00,  ..., -2.4709e+00,\n",
            "          3.5545e+00, -1.8481e+00],\n",
            "        [ 2.3679e-03,  4.4919e+00, -3.0581e+00,  ..., -1.5689e+00,\n",
            "         -7.2702e-01, -5.1791e-01],\n",
            "        [-5.3450e-01,  2.7795e+00, -1.8618e+00,  ..., -1.5077e+00,\n",
            "          3.4717e-01,  5.8487e-01],\n",
            "        ...,\n",
            "        [ 2.0061e+00,  1.3102e+00, -1.6064e+00,  ..., -2.5645e+00,\n",
            "          4.2903e+00, -1.4339e+00],\n",
            "        [ 2.4587e+00,  4.5232e+00, -1.0278e+00,  ..., -9.4551e-01,\n",
            "          8.5196e-01,  2.1204e+00],\n",
            "        [-1.0941e+00,  4.3474e-01, -1.0090e+00,  ..., -1.5989e+00,\n",
            "         -2.8048e+00,  7.5416e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3007,  4.0575, -2.3201,  ..., -2.9728, -4.6500, -1.3025],\n",
            "        [ 0.0462,  2.4479, -2.0192,  ..., -1.2228,  2.6778, -0.6000],\n",
            "        [ 0.1142, -5.1150, -2.3380,  ..., -1.9615,  1.7134,  0.6595],\n",
            "        ...,\n",
            "        [ 2.6163,  4.3665, -0.5584,  ..., -1.3266, -1.0469,  1.4337],\n",
            "        [ 2.9438,  4.0949, -1.3367,  ..., -2.0145, -0.6168,  1.2490],\n",
            "        [ 0.8272,  1.5592, -2.0683,  ..., -2.9499, -1.1793,  0.5649]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6029, -6.8249, -5.2744,  ..., -4.9831,  0.2809,  2.7226],\n",
            "        [-0.8953, -0.3514, -2.5739,  ..., -0.4667, -0.1984,  1.7736],\n",
            "        [ 2.2630,  3.2989, -2.5670,  ..., -4.8965,  0.0155, -1.7306],\n",
            "        ...,\n",
            "        [ 3.2870,  2.8711, -1.2802,  ..., -1.8901,  0.1924,  0.7754],\n",
            "        [-1.2201,  0.2172, -2.8925,  ..., -2.2919, -0.0237, -1.7561],\n",
            "        [-1.9597,  6.3206, -2.1476,  ..., -2.0123, -3.6921, -1.9776]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0605, -3.8512, -1.6971,  ..., -1.4427, -0.2763, -2.3704],\n",
            "        [ 0.0657,  1.0163,  0.1877,  ..., -0.6980, -1.4861, -0.8294],\n",
            "        [-0.5070,  3.3762, -2.2678,  ..., -0.7634, -5.0188, -1.0845],\n",
            "        ...,\n",
            "        [ 1.6548,  4.8503, -2.8239,  ..., -4.2317, -1.0142, -0.6090],\n",
            "        [-2.4655, -3.0984, -1.8753,  ..., -2.8191, -2.0760, -2.7215],\n",
            "        [-4.7171, -4.8795, -2.8259,  ..., -6.0779, -1.0504,  4.0202]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8954,  3.2792, -3.7569,  ..., -3.1637,  1.4303, -0.4426],\n",
            "        [ 0.1811,  4.7398, -3.1128,  ..., -2.4543, -2.7717,  0.0384],\n",
            "        [ 3.2095, -4.8513, -3.7083,  ...,  0.7274,  6.3195, -8.2416],\n",
            "        ...,\n",
            "        [ 1.0232,  2.6539, -2.2395,  ..., -0.7352, -0.5311, -0.3599],\n",
            "        [-2.3014, -0.9487, -3.0395,  ...,  0.6186,  2.2519, -5.5078],\n",
            "        [-3.5031, -5.3512, -1.9567,  ...,  0.9798,  1.3826, -0.3786]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1731,  2.9568, -3.3308,  ..., -3.2420, -0.7230,  0.8700],\n",
            "        [ 0.0406,  3.6328, -2.6032,  ..., -2.0046, -0.0919, -0.9256],\n",
            "        [-1.8305,  1.0159, -2.3528,  ..., -1.8813, -2.8799, -3.3497],\n",
            "        ...,\n",
            "        [ 1.1260, -5.2305, -2.9184,  ...,  0.6017,  0.5609, -0.6945],\n",
            "        [ 1.0617, -1.3824, -3.4754,  ..., -2.7906,  0.2471, -3.2627],\n",
            "        [-2.8817,  1.9431, -2.7625,  ..., -0.5147, -0.4240, -3.6950]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2791,  2.3016, -2.3684,  ..., -0.9718, -3.3383, -0.9312],\n",
            "        [ 3.3700,  0.2437, -2.0553,  ..., -0.0403,  1.9773,  2.7255],\n",
            "        [-0.8271,  0.8293, -1.0143,  ..., -2.8287, -0.6728,  1.0994],\n",
            "        ...,\n",
            "        [ 2.3581,  3.7151, -0.6303,  ..., -1.0482, -0.1749,  1.2633],\n",
            "        [-0.9922, -3.1636, -1.4356,  ...,  1.1330,  3.9248,  3.7327],\n",
            "        [ 2.3915,  4.1966, -0.8960,  ..., -1.9927, -0.2192,  1.7261]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1247,  1.1046, -0.9985,  ..., -0.6768,  0.6492,  1.2011],\n",
            "        [-1.7611, -3.7069, -1.8736,  ..., -1.4419, -2.7908, -0.6091],\n",
            "        [ 0.5734,  1.3233, -2.6800,  ..., -1.1812,  0.9727,  1.9137],\n",
            "        ...,\n",
            "        [-2.9075, -4.2125, -0.1418,  ..., -0.4963,  1.5637,  5.0674],\n",
            "        [-1.7024,  0.0683, -0.9174,  ...,  0.0145,  0.8918, -1.3671],\n",
            "        [-1.4038,  4.7633, -2.3171,  ..., -2.1780, -3.8407, -2.4849]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0656,  2.2337, -3.1178,  ..., -2.4151,  5.3199, -0.0498],\n",
            "        [-6.0421, -4.0670, -1.5306,  ..., -0.7337, -1.2320, -2.0632],\n",
            "        [-0.8980,  2.9181, -2.5913,  ..., -0.6290,  2.9234,  1.2169],\n",
            "        ...,\n",
            "        [ 2.6824,  4.6235, -2.1022,  ..., -1.4750,  0.5692, -0.9761],\n",
            "        [-2.0556, -7.0825, -1.2539,  ..., -0.2320, -0.4333, -2.2003],\n",
            "        [ 0.1605, -5.9576, -2.7637,  ...,  1.8039, -1.8058, -3.2547]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0666, -1.7669,  0.5025,  ..., -1.0567, -2.1749,  1.0356],\n",
            "        [-6.1849, -6.3468, -2.0431,  ..., -2.2133, -3.0787, -2.7379],\n",
            "        [ 0.5162,  1.4218, -1.1320,  ..., -0.6838,  0.6082,  1.2634],\n",
            "        ...,\n",
            "        [ 1.3330,  3.2037, -1.1147,  ..., -2.9067,  0.8650,  1.8741],\n",
            "        [-0.1889,  1.0905, -3.5549,  ..., -1.7034,  0.2771, -1.1058],\n",
            "        [-3.9891, -1.2416, -0.8397,  ..., -2.2647, -0.5613,  1.5802]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5587, -1.9733, -2.0661,  ..., -1.4919, -0.6800, -2.8156],\n",
            "        [-2.0005, -5.1872, -3.6774,  ..., -5.4615,  1.1640,  0.2361],\n",
            "        [ 1.6588, -2.9213, -2.5297,  ..., -2.6863,  7.8207, -1.8962],\n",
            "        ...,\n",
            "        [ 0.9545,  4.6507, -3.7043,  ..., -2.2821,  1.0126, -1.3019],\n",
            "        [-0.7995, -7.6908, -3.1715,  ..., -4.6216,  3.4769, -1.5811],\n",
            "        [-2.1643, -4.1807, -1.9380,  ..., -3.1607,  0.4442,  1.7077]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3184,  4.4405, -0.8414,  ..., -1.1602, -0.0152,  1.3135],\n",
            "        [-2.1891, -1.1220, -2.4338,  ..., -2.7409, -2.4126, -2.8412],\n",
            "        [-1.9659,  3.2112, -4.2510,  ..., -0.6850,  1.7519, -3.3028],\n",
            "        ...,\n",
            "        [-0.6652,  2.9488, -3.9355,  ..., -1.9798,  1.4314, -2.2161],\n",
            "        [ 2.7450,  1.2155, -0.7831,  ..., -2.2105,  4.6705, -1.0006],\n",
            "        [-1.5241,  1.1814, -1.6547,  ..., -2.6563, -0.0387, -0.6759]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5603,  0.4750, -3.5841,  ..., -3.3609,  4.3168, -0.4658],\n",
            "        [ 1.3727,  0.3551, -1.1352,  ..., -1.5549,  2.5916, -2.7006],\n",
            "        [-0.8232,  4.8724, -2.4469,  ..., -1.5268, -0.9961, -1.8655],\n",
            "        ...,\n",
            "        [-4.5932, -6.2438, -1.8112,  ..., -2.2670, -1.9059, -0.4863],\n",
            "        [ 1.0223,  2.0254, -3.5758,  ..., -0.8677,  2.6551, -2.7020],\n",
            "        [-2.5890, -2.6092, -1.9681,  ..., -2.2180,  3.1901,  3.6709]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6975,  1.3961, -0.0984,  ...,  0.0711,  0.8735,  0.4869],\n",
            "        [-2.8369, -0.0389, -3.9994,  ...,  0.3496,  0.2889, -5.0996],\n",
            "        [-3.4265, -3.5095, -0.8853,  ...,  0.4197, -0.4830, -1.9528],\n",
            "        ...,\n",
            "        [-0.1791, -0.8740, -1.7981,  ..., -3.0060,  5.7752, -1.0504],\n",
            "        [ 0.9478, -3.3339, -3.0079,  ..., -3.5197,  5.7188,  3.3694],\n",
            "        [ 0.6676,  1.7893, -1.9771,  ..., -2.5137, -1.0858,  2.3479]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3982, -2.5791, -1.9152,  ...,  0.6144,  0.6818, -1.7985],\n",
            "        [ 1.8672,  1.6400, -2.9543,  ..., -2.1403, -1.4523, -2.3104],\n",
            "        [ 0.2282,  2.8866, -2.1519,  ..., -2.2917, -2.6736, -0.0431],\n",
            "        ...,\n",
            "        [ 1.2364, -0.2476, -2.6681,  ..., -0.5290,  5.1549,  0.0993],\n",
            "        [ 2.7394, -2.5463, -1.1154,  ..., -0.7256,  4.0597, -5.4680],\n",
            "        [ 1.0088,  2.0635, -1.3805,  ..., -0.1462, -0.8070, -1.7263]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7310,  0.5833, -3.6164,  ...,  0.1229,  2.1626, -1.8517],\n",
            "        [-0.7025,  2.3269, -1.7581,  ..., -3.9689, -0.7680,  2.3525],\n",
            "        [-0.3285, -1.2089, -0.7193,  ..., -3.3217, -1.2484,  3.6784],\n",
            "        ...,\n",
            "        [ 3.0415,  4.4630, -3.1628,  ..., -2.2690, -0.8344, -1.6248],\n",
            "        [ 1.2958,  3.2715, -1.0594,  ..., -0.3837, -0.6572,  1.0203],\n",
            "        [ 0.1234, -0.2843, -2.0819,  ..., -0.5653,  1.5897, -5.0071]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0381,  2.8635, -2.3663,  ..., -1.0078, -0.8200,  0.8783],\n",
            "        [-2.8035, -3.9665,  0.1640,  ...,  0.4831, -1.3860,  1.3800],\n",
            "        [-0.8401,  4.0129, -1.7118,  ..., -2.6001, -6.0425, -2.4706],\n",
            "        ...,\n",
            "        [-3.9659, -2.7918, -2.6426,  ..., -1.5223,  0.9812, -1.6431],\n",
            "        [-0.3766,  7.0412, -4.3469,  ..., -4.4349, -1.4239, -2.6396],\n",
            "        [-0.7094,  2.2063, -0.6377,  ..., -2.4417,  0.3989, -0.9955]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6382,  2.5461, -4.3379,  ..., -0.9940, -0.6491, -4.6252],\n",
            "        [ 0.0775,  1.1502,  0.2339,  ..., -0.1746, -0.6483,  0.6079],\n",
            "        [ 2.5674,  0.5574, -4.1753,  ...,  0.3193,  4.2805,  2.3917],\n",
            "        ...,\n",
            "        [ 0.1298,  6.7695, -2.1857,  ..., -1.3416,  2.1330, -1.4007],\n",
            "        [ 0.2143, -0.8338, -3.6164,  ..., -2.5234,  4.9539, -1.3629],\n",
            "        [ 2.6528,  4.2418, -0.9793,  ..., -1.6424, -0.5025,  1.4595]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5315, -0.4840, -2.9009,  ...,  0.8147,  4.1667,  1.8196],\n",
            "        [ 0.8018,  1.9814, -1.5298,  ..., -1.0785, -0.8872,  1.9890],\n",
            "        [-5.0403, -2.9183, -1.6483,  ..., -4.2300,  2.2076, -0.9507],\n",
            "        ...,\n",
            "        [ 2.0055, -0.6954, -3.3137,  ..., -0.9473,  5.9441,  0.2717],\n",
            "        [-3.9988, -1.4683, -1.1373,  ..., -2.2387,  1.2686, -2.0064],\n",
            "        [-4.1851, -3.8437,  0.3088,  ...,  0.5860, -0.8378,  2.0048]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2878,  3.6746, -2.2233,  ..., -0.4118,  0.3643, -2.0195],\n",
            "        [ 0.1636,  6.2131, -1.8018,  ..., -2.5539,  0.1924, -1.8670],\n",
            "        [ 2.1488, -5.5311, -3.3013,  ...,  3.1262,  1.5065, -4.3412],\n",
            "        ...,\n",
            "        [-1.1846,  0.3383, -1.2361,  ..., -4.3710,  0.9487,  0.8874],\n",
            "        [ 1.8800, -5.0746, -1.9736,  ..., -4.7868,  6.9442, -0.7186],\n",
            "        [ 2.3151,  3.0943, -2.9461,  ..., -1.3907, -0.3469, -1.1350]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8212, -1.0444, -2.1723,  ..., -3.0255, -2.3069, -2.6762],\n",
            "        [-0.7476,  1.7031, -4.1838,  ..., -1.1554,  2.5891, -3.5773],\n",
            "        [-0.0387,  0.0074, -2.2093,  ..., -4.0628, -0.5296, -1.4036],\n",
            "        ...,\n",
            "        [-0.3298,  5.4506, -3.6085,  ..., -1.6193,  2.8186, -3.0431],\n",
            "        [-0.2682, -1.1581, -3.1056,  ..., -2.5226, -0.5814, -1.4251],\n",
            "        [-0.3785,  4.0799, -4.5322,  ..., -2.4177,  0.4176, -0.6323]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8327e-01, -2.6488e-01, -2.2281e+00,  ..., -2.0249e+00,\n",
            "          1.8217e+00, -8.9889e-01],\n",
            "        [-2.9382e-01, -1.1044e-01, -1.8208e+00,  ..., -3.2836e+00,\n",
            "          1.0337e+00,  4.3222e-03],\n",
            "        [ 1.4402e+00, -7.7347e-01, -2.6621e+00,  ..., -2.2086e+00,\n",
            "          6.5159e+00, -6.4790e-01],\n",
            "        ...,\n",
            "        [-1.0676e+00, -6.4502e+00, -3.0478e+00,  ..., -8.8895e-01,\n",
            "         -2.0836e+00,  6.6531e-01],\n",
            "        [ 2.5091e-01, -3.9142e+00, -7.0374e-01,  ..., -2.0536e+00,\n",
            "          2.0322e+00, -1.2501e+00],\n",
            "        [-2.6123e+00, -6.2743e+00, -3.9378e+00,  ..., -2.4895e+00,\n",
            "          3.3469e+00,  2.2617e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8626, -8.7510, -4.3339,  ..., -2.8822, -0.3912, -3.8772],\n",
            "        [-1.0763,  5.9082, -1.8647,  ..., -1.9939,  0.7057, -0.4847],\n",
            "        [-4.6046, -7.0720, -7.0561,  ..., -6.3133,  1.3437,  2.1103],\n",
            "        ...,\n",
            "        [-0.0707, -0.0103, -2.0864,  ..., -2.6415, -2.6094, -1.1508],\n",
            "        [-3.3815, -0.6378, -0.8188,  ..., -2.2541, -0.3827, -1.2858],\n",
            "        [-2.4148, -0.2278, -2.2578,  ..., -1.5565,  2.0914, -0.7140]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5025,  4.9793, -2.4933,  ..., -1.8890,  0.1482, -2.0894],\n",
            "        [-0.5477, -4.1928, -3.1555,  ..., -5.7691,  4.3747, -0.2811],\n",
            "        [-0.6682, -0.8802, -0.9753,  ..., -0.6990, -3.0208,  1.4134],\n",
            "        ...,\n",
            "        [-2.6663, -5.8759, -2.1477,  ..., -3.6061, -0.0449, -1.9262],\n",
            "        [-2.3752, -2.5720, -2.8748,  ..., -2.7028,  1.4050,  1.0120],\n",
            "        [-1.8815, -1.9132, -2.3264,  ..., -1.7415, -0.5186, -2.4716]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -3.3034, -10.5258,  -5.1375,  ...,  -2.8771,  -3.3474,   1.5324],\n",
            "        [ -1.1759,  -4.5563,  -4.9726,  ...,  -1.6950,   3.3775,   3.1789],\n",
            "        [  1.6293,   3.8310,  -0.7356,  ...,  -0.7832,   0.2235,   0.6859],\n",
            "        ...,\n",
            "        [ -1.3570,   0.0724,  -1.9605,  ...,  -2.5942,  -2.2200,  -3.1006],\n",
            "        [  2.9485,   6.0074,  -1.5594,  ...,  -2.2715,  -0.7727,   0.4579],\n",
            "        [ -4.6226,  -7.8858,  -1.9243,  ...,  -4.1190,   2.4579,   2.1059]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3521, -4.0175, -1.2163,  ..., -0.8718,  0.3344, -2.4943],\n",
            "        [-0.6366,  1.1797, -3.2769,  ..., -1.8483,  2.2494, -3.3364],\n",
            "        [ 3.6885,  5.0888, -1.8400,  ..., -4.2522,  0.9379,  0.5187],\n",
            "        ...,\n",
            "        [-1.8330,  1.9240, -1.3984,  ...,  3.7609, -0.0484, -5.6328],\n",
            "        [ 0.2209,  3.9275, -1.9202,  ..., -2.2521, -3.8547, -1.1423],\n",
            "        [ 1.3988,  1.6078, -1.9445,  ..., -2.1883, -1.3558, -0.4865]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9515,  2.6651, -3.9270,  ..., -2.4652,  3.6074, -1.1735],\n",
            "        [ 0.6315, -3.7786, -3.7194,  ..., -3.7765,  4.3344, -5.2394],\n",
            "        [-3.8901, -0.9404, -2.2445,  ..., -1.5724,  0.6176, -1.2127],\n",
            "        ...,\n",
            "        [-3.4480, -5.2200, -1.4814,  ..., -2.2647,  0.1527, -2.0358],\n",
            "        [-1.4721,  4.1481, -2.2414,  ..., -2.2707, -1.4823, -2.7706],\n",
            "        [ 0.8385,  2.0420, -3.0368,  ..., -3.1772, -0.5175, -2.4404]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9161,  3.6799, -1.8720,  ..., -2.0715, -1.6500, -2.5004],\n",
            "        [ 0.6572, -0.6108, -3.4522,  ..., -1.9894,  5.2523,  1.3115],\n",
            "        [-4.4057, -5.0750, -5.6333,  ..., -3.9595, -1.9991, -2.0251],\n",
            "        ...,\n",
            "        [ 0.8614,  0.2345, -1.2826,  ..., -1.9726, -0.2447,  2.4232],\n",
            "        [ 0.4233,  5.2838, -2.5843,  ..., -2.0691, -0.0197, -1.5091],\n",
            "        [ 0.1799, -3.0823, -0.4657,  ..., -2.1369, -2.6370,  0.5661]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6161, -0.3589, -1.7057,  ..., -5.0096, -0.1295,  4.1021],\n",
            "        [ 0.2624, -2.2702, -1.5030,  ..., -2.2591,  1.3937, -3.2578],\n",
            "        [ 0.2748, -3.2332, -1.4928,  ..., -0.2103,  0.3128, -3.2163],\n",
            "        ...,\n",
            "        [ 0.6536, -1.8683, -3.6755,  ..., -2.8122,  3.3697,  0.6333],\n",
            "        [-2.0646, -5.9320,  0.0482,  ..., -2.8025,  0.1819, -0.6233],\n",
            "        [-1.6875, -7.0143, -2.7201,  ..., -1.3397,  1.3101, -5.4764]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4780, -1.2607, -2.0802,  ...,  0.4174, -0.2652, -0.2200],\n",
            "        [-0.3056,  4.7595, -1.1679,  ..., -0.9240,  0.7666, -2.9419],\n",
            "        [-4.4111, -4.3923, -3.7060,  ..., -5.3142,  1.8866,  3.4927],\n",
            "        ...,\n",
            "        [ 0.9341,  3.5260, -2.2813,  ..., -3.1871, -4.0801, -1.6750],\n",
            "        [-0.5508, -0.1699, -3.1034,  ..., -0.8250,  2.8589, -3.6594],\n",
            "        [-0.8262,  3.7695, -1.3765,  ..., -1.8205, -1.5364, -1.1942]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.7946, -7.3248, -1.2788,  ..., -4.0424,  2.7470,  4.0892],\n",
            "        [-1.8097, -4.5571, -2.3639,  ..., -2.4036, -1.6631, -0.6980],\n",
            "        [-2.5140, -0.3625,  0.1358,  ..., -1.6213, -0.3338, -1.0622],\n",
            "        ...,\n",
            "        [-0.9148, -4.9611, -0.5419,  ..., -0.8977,  1.0011, -3.4225],\n",
            "        [-0.9489, -2.3474,  1.4459,  ..., -0.2868, -1.2196,  1.8033],\n",
            "        [ 0.1368,  2.1605, -1.8672,  ..., -3.0816, -4.5349, -1.1441]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4578, -1.7370, -3.0673,  ..., -0.9132,  6.4922,  3.1039],\n",
            "        [-1.0359, -3.9704, -2.5914,  ..., -2.8675,  6.0458, -0.3519],\n",
            "        [ 1.9249, -1.1897, -0.9110,  ...,  0.9696,  1.9719, -1.8081],\n",
            "        ...,\n",
            "        [-2.0742, -3.6893, -3.8094,  ..., -4.7794, -0.5644, -5.1228],\n",
            "        [-1.1080, -0.5348, -0.0435,  ..., -1.9051, -0.6649, -1.3609],\n",
            "        [-1.7016,  1.6930, -0.1679,  ..., -0.5012,  0.3242,  0.3820]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1234, -0.3431, -2.3999,  ..., -0.4248,  2.3926, -3.3316],\n",
            "        [ 0.1283,  5.0469, -2.3751,  ..., -2.1000,  0.4803, -0.2691],\n",
            "        [ 2.8837,  1.2095, -1.9571,  ..., -2.0652,  3.7866, -3.9321],\n",
            "        ...,\n",
            "        [ 0.1812,  5.5959, -2.0857,  ..., -2.9236, -0.2215, -0.4659],\n",
            "        [-2.8040, -4.2328, -2.1352,  ..., -1.7997,  1.6156, -0.0355],\n",
            "        [-0.5237, -5.9509, -2.5551,  ..., -2.0359,  3.3896, -0.0197]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5960,  5.2327,  0.2379,  ..., -0.6472,  1.5579,  1.1121],\n",
            "        [-4.9399, -4.7113, -1.9174,  ..., -1.9849,  2.7597, -0.3317],\n",
            "        [-2.2257, -0.8140, -1.8640,  ..., -0.2482,  0.9574,  1.1060],\n",
            "        ...,\n",
            "        [-1.4589, -0.6631, -0.9664,  ..., -4.4751,  1.1225,  4.3311],\n",
            "        [ 3.1392, -2.3141, -2.6289,  ..., -3.3483,  0.8432, -2.9495],\n",
            "        [ 1.9507,  4.0960, -1.4804,  ..., -1.6765,  0.5411,  0.6804]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5456, -2.6273, -2.0735,  ..., -3.5052,  2.5463, -2.0992],\n",
            "        [-1.8494, -2.0149,  0.6157,  ..., -0.4412, -0.7609,  1.9917],\n",
            "        [ 0.5900,  1.7408, -1.7633,  ...,  0.3325, -1.2779, -0.6069],\n",
            "        ...,\n",
            "        [-2.2167, -1.6119, -4.0732,  ..., -0.6046,  0.4783, -4.9046],\n",
            "        [-1.4722, -3.2390, -3.3419,  ..., -0.9389,  4.2726,  2.6983],\n",
            "        [ 0.1397, -0.7317, -0.0464,  ..., -3.9276,  1.9905,  1.3004]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6836, -1.8773, -0.5943,  ..., -2.8922, -1.9873,  0.1989],\n",
            "        [-2.5826,  2.9796, -1.3199,  ...,  2.5458, -0.4095, -5.7800],\n",
            "        [ 1.2351,  6.3327, -1.5953,  ..., -3.1719,  1.6938, -0.5044],\n",
            "        ...,\n",
            "        [-3.6968, -5.3218, -4.1584,  ..., -0.6249, -0.6042, -6.8444],\n",
            "        [-2.9337, -1.9842, -0.3865,  ..., -5.2192,  1.2823,  4.2289],\n",
            "        [-0.3340,  4.5045, -2.8117,  ..., -1.5236,  1.0969, -4.0653]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7768, -2.4354, -0.8379,  ...,  0.6032,  1.8761, -0.0265],\n",
            "        [-0.4326, -8.4145, -3.1035,  ...,  1.4053, -2.7767, -2.8170],\n",
            "        [-2.7596, -3.1791,  1.0129,  ..., -0.6049,  1.0557,  2.9598],\n",
            "        ...,\n",
            "        [-1.6394, -2.1214, -1.0497,  ..., -2.2080,  1.0170, -1.7086],\n",
            "        [ 3.3483, -5.4448, -2.3268,  ..., -1.1320,  1.6977, -4.2508],\n",
            "        [-7.6567, -4.5589, -0.4892,  ..., -1.7147, -0.0238, -1.7886]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0024e-01,  4.5402e+00,  3.7149e-03,  ...,  6.7229e-01,\n",
            "         -3.3505e-01, -1.6427e+00],\n",
            "        [ 1.0017e+00,  4.4175e-01, -2.3798e+00,  ..., -1.7799e+00,\n",
            "          9.6606e-01, -1.2732e+00],\n",
            "        [ 1.6561e+00, -2.4539e+00, -2.0345e+00,  ...,  2.4787e+00,\n",
            "          4.6058e+00,  2.2714e+00],\n",
            "        ...,\n",
            "        [-3.2975e-01, -5.8469e+00, -3.8798e+00,  ..., -1.5888e+00,\n",
            "         -2.5999e+00,  9.3148e-01],\n",
            "        [ 2.9134e+00, -1.0622e+00, -2.9634e+00,  ...,  6.1541e-01,\n",
            "          6.1365e+00,  2.4020e+00],\n",
            "        [-6.6107e-01,  9.8486e-01, -2.3275e+00,  ..., -1.3788e+00,\n",
            "          7.5095e-01, -4.7576e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7389,  3.2499, -3.4784,  ..., -0.1242, -3.6295, -1.4589],\n",
            "        [-1.3016,  4.6952, -2.9013,  ..., -1.3882,  2.5664, -2.8899],\n",
            "        [-0.0168, -3.0186, -1.9714,  ..., -3.4854,  5.0430,  3.8676],\n",
            "        ...,\n",
            "        [ 1.6570,  3.5077, -2.4269,  ..., -0.9486,  3.3145, -2.1465],\n",
            "        [-0.1717, -3.6434, -2.4646,  ..., -2.3757, -0.2555, -4.0217],\n",
            "        [ 1.4503,  1.5325, -0.5064,  ..., -0.6433,  0.8039,  0.6440]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3733, -4.4027, -2.0630,  ..., -0.6746, -1.9559, -1.1981],\n",
            "        [ 0.2382,  0.1579, -0.9377,  ..., -0.3753, -0.3388, -0.1615],\n",
            "        [-0.0523,  0.2594, -0.6940,  ..., -0.5637,  2.3355, -3.1114],\n",
            "        ...,\n",
            "        [ 3.0682,  4.7552, -1.1296,  ..., -2.3035,  0.5413,  1.0478],\n",
            "        [-1.7864, -7.4366, -3.6398,  ...,  0.3073,  0.6688, -4.5560],\n",
            "        [ 3.3671,  4.1796, -0.8134,  ..., -1.7654,  0.4260,  1.3175]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9304,  0.2173, -1.8824,  ...,  0.1408,  1.5900, -1.0336],\n",
            "        [-1.4347, -3.1093, -4.7020,  ..., -1.4112,  1.4203, -4.5151],\n",
            "        [-1.9906,  0.7191, -2.0091,  ..., -1.1797, -0.0635, -1.7117],\n",
            "        ...,\n",
            "        [ 0.8695,  3.8361, -2.7822,  ..., -1.9327,  4.0038, -0.5061],\n",
            "        [ 0.5543, -7.3269, -5.5476,  ..., -3.3859,  4.4318,  2.2632],\n",
            "        [-0.4246, -1.3635, -2.8397,  ..., -1.0912,  0.9894, -3.4904]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0755, -1.8974, -1.7733,  ...,  2.1798, -0.6499, -3.6569],\n",
            "        [-1.9530, -2.7490, -2.9498,  ...,  0.8060,  1.8514, -3.4674],\n",
            "        [-3.8641, -3.3546, -2.7938,  ..., -0.0235,  4.1746,  0.2805],\n",
            "        ...,\n",
            "        [ 0.3521,  2.6318, -2.7157,  ..., -1.5825, -2.4989, -1.9261],\n",
            "        [-1.2333, -2.2318, -0.0676,  ..., -0.1503, -2.8129,  0.2297],\n",
            "        [-0.8466, -0.0983, -3.5315,  ..., -1.8974,  0.5336, -6.4928]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5796e+00,  6.9040e-02, -2.6003e+00,  ..., -1.9686e+00,\n",
            "          3.7546e+00,  1.7332e+00],\n",
            "        [-4.3690e-01,  5.5194e+00, -1.8778e+00,  ..., -6.9475e-01,\n",
            "         -1.6819e+00, -3.3782e+00],\n",
            "        [-4.2755e+00, -4.0172e+00, -2.1756e+00,  ..., -2.7976e+00,\n",
            "         -4.5230e-01,  1.2771e-02],\n",
            "        ...,\n",
            "        [-3.4991e+00, -8.3251e+00, -4.7667e+00,  ..., -3.5114e+00,\n",
            "         -6.7634e+00, -1.1683e+00],\n",
            "        [ 6.7514e-03, -2.7530e+00, -3.2798e+00,  ...,  3.5080e-01,\n",
            "         -2.4021e-02, -4.3146e+00],\n",
            "        [ 3.2763e+00,  2.7893e-01, -3.2880e+00,  ..., -1.4234e+00,\n",
            "          1.8373e+00, -2.6705e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7031,  2.7461, -2.0101,  ..., -1.4130,  4.1919,  1.4571],\n",
            "        [ 1.3016,  0.2532, -2.0535,  ..., -0.0084, -1.7094,  1.2474],\n",
            "        [ 0.9825, -3.7870, -3.8119,  ...,  0.9277,  1.9231, -2.1821],\n",
            "        ...,\n",
            "        [ 1.1241, -0.0809, -0.8752,  ..., -3.0098,  6.2114, -0.2473],\n",
            "        [-1.8201, -5.7817,  0.2625,  ..., -1.7130,  2.1677, -2.7728],\n",
            "        [-2.4694, -2.1143, -3.8959,  ..., -2.3482,  0.9627, -5.3203]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1594, -1.1772, -2.3416,  ...,  0.1007, -0.8268, -3.3279],\n",
            "        [ 0.2939,  3.7760, -1.1407,  ...,  0.2861,  3.1263, -1.1281],\n",
            "        [ 3.8023,  1.8249, -1.5530,  ..., -2.3319,  4.1008, -0.9234],\n",
            "        ...,\n",
            "        [-1.0936,  2.6512, -3.5122,  ..., -0.9789,  1.4269, -4.0666],\n",
            "        [-0.8418, -7.0784, -3.3368,  ..., -0.0163,  3.5531, -3.7112],\n",
            "        [ 0.3116, -1.5710, -0.7563,  ..., -0.7455,  3.6156,  3.0050]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0093,  3.1175, -1.5470,  ..., -1.5946,  1.1524,  0.1122],\n",
            "        [ 0.5018,  3.2343, -1.6254,  ...,  0.0687, -0.3028, -0.0074],\n",
            "        [-1.2683, -3.5409, -3.0951,  ..., -1.2198, -0.2094, -4.9770],\n",
            "        ...,\n",
            "        [-1.6848, -0.1629, -0.1460,  ..., -2.4574,  0.6392,  4.4153],\n",
            "        [-2.3454, -4.2422, -2.9734,  ..., -0.0393,  0.9633,  2.8811],\n",
            "        [ 0.1327, -2.4692, -1.3546,  ..., -1.8476, -3.0913, -3.1830]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8941, -3.6809,  1.1826,  ..., -0.9877,  0.2357,  3.1382],\n",
            "        [ 0.4769, -1.0626, -2.1634,  ..., -4.7005,  1.8572, -1.5876],\n",
            "        [-1.4136,  6.5609, -3.0477,  ..., -0.2522, -0.9898, -2.8730],\n",
            "        ...,\n",
            "        [-0.9618, -2.9824, -2.3941,  ..., -0.4110,  1.4101, -0.1654],\n",
            "        [ 0.9174,  2.2379, -1.7872,  ..., -1.5215,  0.8402,  0.0789],\n",
            "        [ 3.7013, -0.9725, -2.9165,  ..., -2.1459,  8.1997,  1.4934]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3656, -2.2495, -3.1645,  ..., -0.4935,  0.8588, -3.5834],\n",
            "        [-3.3091, -5.5485, -0.8109,  ..., -1.0047,  1.0412, -0.3232],\n",
            "        [-1.1869, -2.2025, -1.1733,  ...,  2.0765, -0.5853, -1.3827],\n",
            "        ...,\n",
            "        [ 1.2458,  2.5156, -3.2352,  ..., -1.8519,  3.6636, -0.1488],\n",
            "        [ 1.1033,  0.6043, -0.5211,  ...,  0.6313,  0.8480, -2.5449],\n",
            "        [ 0.9454, -1.0018, -3.5005,  ..., -3.4420,  2.8887,  0.9945]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1346, -6.1412, -0.1596,  ..., -5.1731, -1.2465,  1.8148],\n",
            "        [ 0.3661,  0.6117, -0.4562,  ...,  0.4205, -0.6771,  1.4195],\n",
            "        [-0.1064,  3.9951, -1.4905,  ..., -1.7813, -4.7222, -1.3826],\n",
            "        ...,\n",
            "        [-0.9257,  0.0065, -3.1479,  ..., -3.2191,  0.7212,  0.0861],\n",
            "        [-1.7353, -1.3003, -1.0466,  ...,  0.2095,  0.5091, -0.3640],\n",
            "        [-1.9553, -2.7552, -0.6941,  ..., -2.6803,  2.5185, -1.5940]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8164, -2.3607, -2.9835,  ..., -1.6032,  5.4297, -6.8981],\n",
            "        [-1.1326, -1.0664, -3.9060,  ..., -2.2978, -1.2367,  2.9644],\n",
            "        [ 4.1733,  4.7422, -1.2247,  ..., -2.5435,  0.5232,  1.7632],\n",
            "        ...,\n",
            "        [-0.3195,  1.9823, -2.9226,  ..., -0.3173, -0.3588, -0.5818],\n",
            "        [ 3.2971,  1.1926, -1.4329,  ..., -0.7137, -1.0162, -1.4250],\n",
            "        [ 1.2825,  1.5702, -0.6594,  ..., -0.3476, -2.7499,  0.6258]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0944,  1.5960, -1.1227,  ..., -1.9878, -2.5057, -2.0941],\n",
            "        [ 3.0653, -6.3410, -1.6753,  ..., -0.7794,  2.4562, -1.5126],\n",
            "        [ 1.3214,  2.3329, -0.3800,  ...,  0.1548,  0.3423,  0.8696],\n",
            "        ...,\n",
            "        [-0.5054, -0.8420, -2.4576,  ..., -2.7049,  0.6473,  0.3599],\n",
            "        [ 0.6148,  3.8371, -2.2358,  ..., -0.1763,  3.1285, -2.4608],\n",
            "        [-0.7884,  0.0780, -2.2706,  ..., -0.5310,  0.3245, -2.7020]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.9531e-01, -1.7407e+00, -2.3303e+00,  ...,  2.3637e-01,\n",
            "         -2.9575e+00, -2.5700e+00],\n",
            "        [-1.1227e-03,  4.0840e+00, -7.1889e-01,  ...,  1.1432e+00,\n",
            "          2.1284e+00, -2.0029e+00],\n",
            "        [ 2.2060e+00, -2.2578e+00, -1.8536e+00,  ..., -3.3084e-01,\n",
            "         -2.8453e+00, -1.5464e+00],\n",
            "        ...,\n",
            "        [-1.3638e+00,  4.2746e+00, -1.1155e+00,  ...,  1.8518e-01,\n",
            "          3.4803e+00, -2.3614e+00],\n",
            "        [-3.4683e+00, -8.7392e+00, -2.2155e+00,  ..., -1.8553e+00,\n",
            "         -2.7368e+00, -5.6364e+00],\n",
            "        [-7.9598e-01,  1.0472e+00, -1.5598e+00,  ...,  3.9405e-01,\n",
            "          2.4094e+00,  1.5263e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.1902e+00, -2.2849e+00, -1.1536e+00,  ..., -5.8464e-03,\n",
            "          7.4632e-01, -1.4082e+00],\n",
            "        [-1.3721e+00,  1.9515e+00, -7.3268e-01,  ..., -4.5706e-01,\n",
            "          4.2720e+00,  9.0876e-01],\n",
            "        [ 1.8808e+00, -1.9451e-01, -4.2329e+00,  ..., -2.8384e+00,\n",
            "          8.1291e+00, -6.4102e-01],\n",
            "        ...,\n",
            "        [ 2.8346e+00,  4.3554e+00, -1.0618e+00,  ..., -1.5015e+00,\n",
            "          1.0456e+00, -2.4914e-01],\n",
            "        [-3.7014e-01,  1.3453e+00, -1.6412e+00,  ...,  2.8290e-01,\n",
            "         -2.4263e+00,  1.3538e+00],\n",
            "        [ 2.5863e+00,  4.5658e+00, -6.9182e-01,  ..., -1.7311e+00,\n",
            "          3.3829e-01, -5.0498e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0927, -3.0112, -3.6957,  ..., -1.3929,  2.0311,  3.1472],\n",
            "        [-0.4832,  3.7284, -1.4548,  ...,  1.5311,  0.6866, -4.9510],\n",
            "        [-3.2977, -4.1873, -1.3701,  ..., -4.4319,  1.4472,  0.2304],\n",
            "        ...,\n",
            "        [-1.7416,  0.3427, -0.4440,  ..., -0.3155,  2.7250,  2.2907],\n",
            "        [-2.7063,  1.7368, -2.3830,  ..., -0.7031, -0.7066, -4.4861],\n",
            "        [-0.3810,  4.7711, -1.4267,  ..., -1.1496, -0.3754, -2.2279]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8636, -2.8658, -0.8028,  ..., -1.0802, -0.0624, -0.1006],\n",
            "        [ 2.1399,  0.2673, -2.5435,  ..., -1.5679,  4.1764,  0.5921],\n",
            "        [ 2.1167, -7.7306, -3.0041,  ..., -0.4239,  4.1169, -3.3624],\n",
            "        ...,\n",
            "        [ 1.2393,  3.6066, -0.5131,  ..., -0.7192, -4.7520,  2.0038],\n",
            "        [ 0.2472, -5.9671, -1.2825,  ...,  1.2100,  1.1503, -1.0828],\n",
            "        [-0.1180, -3.5299, -2.2761,  ...,  1.1482,  0.0542, -2.7394]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6415,  5.4097, -0.4497,  ..., -3.1117, -0.4949,  1.2399],\n",
            "        [-0.7516, -0.1029, -0.4456,  ..., -1.2246, -1.4198, -0.9539],\n",
            "        [-1.6182,  3.9634, -2.2855,  ...,  0.6347, -0.6540, -3.5458],\n",
            "        ...,\n",
            "        [-1.5378, -0.5674, -2.0004,  ..., -0.1285, -1.3704, -3.9382],\n",
            "        [-0.3255, -0.3050, -2.7543,  ..., -0.5846,  2.1135, -3.0876],\n",
            "        [-1.3768,  3.5167, -2.1770,  ..., -0.5215, -0.2412, -1.8296]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5425, -3.7306, -1.6557,  ..., -2.9335,  5.9705, -0.8894],\n",
            "        [ 2.4139,  3.7922, -0.4216,  ..., -0.8759,  0.2967,  1.7803],\n",
            "        [ 0.6267,  0.1936, -1.8981,  ..., -3.5377,  5.8523,  0.7297],\n",
            "        ...,\n",
            "        [ 0.2406, -3.4782, -2.3870,  ..., -1.2917, -4.6153,  0.9042],\n",
            "        [ 0.1826, -2.3767, -2.2935,  ..., -2.8912,  6.7341, -0.8732],\n",
            "        [ 0.9915,  0.6745, -2.2167,  ...,  1.3752, -3.1190, -0.3819]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3194,  1.5228, -3.1218,  ..., -1.8451,  0.2875,  1.1077],\n",
            "        [-4.2972, -4.2032, -2.8458,  ...,  0.0249,  1.6581, -3.3913],\n",
            "        [-0.4170,  1.5437, -3.8798,  ..., -3.9417,  2.4639, -1.4186],\n",
            "        ...,\n",
            "        [-2.1595,  0.0202, -1.4367,  ..., -0.1513,  3.8438,  1.4551],\n",
            "        [ 0.5275, -0.7415, -2.1522,  ..., -0.6491, -2.8037, -1.1467],\n",
            "        [ 0.4416,  2.0228, -0.6460,  ..., -2.4239, -2.6656,  0.5311]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3013, -3.7488, -0.5154,  ..., -1.8390,  0.7888, -2.8509],\n",
            "        [ 0.6064, -3.8637, -4.6479,  ..., -0.2676,  2.6003, -7.7232],\n",
            "        [-0.0867, -5.9084, -3.8069,  ...,  0.0982, -5.1826, -3.0868],\n",
            "        ...,\n",
            "        [-0.0223, -2.5480, -1.9822,  ..., -1.7793,  1.0703, -2.4692],\n",
            "        [-2.7650, -3.3470, -1.5963,  ..., -0.8450, -1.6431,  0.1848],\n",
            "        [-0.6420,  6.3428, -2.6878,  ...,  1.1885,  1.7173, -2.7395]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-6.9195e-01, -6.5848e-01, -2.6679e+00,  ..., -7.0666e-01,\n",
            "          9.0790e-01, -6.2614e-01],\n",
            "        [-9.7676e-01,  1.4337e-01, -8.1034e-01,  ...,  1.1784e+00,\n",
            "          1.7208e+00, -1.3470e+00],\n",
            "        [ 4.3127e-01, -1.2862e-01, -1.6485e+00,  ..., -3.7992e+00,\n",
            "          9.1076e-02,  9.4388e-01],\n",
            "        ...,\n",
            "        [ 4.3361e-01, -3.6594e-01, -1.8622e+00,  ...,  5.5118e-01,\n",
            "         -3.1843e-03, -2.3256e+00],\n",
            "        [ 1.2925e+00,  2.7398e+00,  6.5706e-01,  ..., -3.7165e+00,\n",
            "         -2.4379e+00,  9.9957e-01],\n",
            "        [-5.6501e-01,  6.4719e+00, -2.0815e+00,  ..., -1.5937e+00,\n",
            "          3.5816e-01, -1.5957e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0413,  5.2298, -2.2002,  ..., -2.0001,  0.8540, -0.2171],\n",
            "        [-1.2278, -3.4790, -2.2150,  ...,  1.5407,  2.7207, -0.5978],\n",
            "        [-0.4890, -3.7769, -3.4883,  ..., -2.8804, -2.7680,  2.4473],\n",
            "        ...,\n",
            "        [-2.9943, -8.9849, -4.6985,  ..., -3.6606,  0.6260,  3.0950],\n",
            "        [ 1.5171,  4.5658, -2.5898,  ..., -2.7038, -2.3133, -2.4923],\n",
            "        [-1.5965,  2.6678, -2.6217,  ...,  0.2748,  0.9957, -2.9009]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2038, -2.6385, -3.6109,  ..., -3.0098,  2.0845,  0.5936],\n",
            "        [-1.8003,  2.7501, -2.4214,  ..., -0.2772, -0.5599, -3.3821],\n",
            "        [-0.9116,  3.4573, -1.4369,  ...,  1.7877,  0.7481, -4.3566],\n",
            "        ...,\n",
            "        [ 1.3031,  3.4343, -3.2477,  ...,  0.5455, -0.9638, -3.7647],\n",
            "        [-3.5972, -6.2183, -2.5890,  ...,  0.2735,  4.3292, -0.7544],\n",
            "        [ 0.0613,  0.9641, -0.3921,  ...,  0.5390,  0.3082,  0.4821]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8589,  4.3366, -1.2037,  ..., -1.4267,  0.3222,  2.0068],\n",
            "        [ 1.6836, -0.7037, -2.1304,  ..., -3.0559,  6.5606,  1.1116],\n",
            "        [ 1.3742, -1.1871, -3.1938,  ..., -0.5233,  1.0773, -0.7459],\n",
            "        ...,\n",
            "        [-0.1281, -0.9641,  0.5649,  ..., -1.9346, -0.3522, -0.5118],\n",
            "        [ 1.0518, -0.7867, -1.7268,  ..., -0.0553,  1.3273, -0.8225],\n",
            "        [ 1.6397,  5.5150, -1.3325,  ..., -0.9020, -0.5008,  1.2028]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5649,  2.3946, -1.9630,  ...,  0.1468,  2.0363, -0.9448],\n",
            "        [-1.0491,  7.2458, -2.8626,  ...,  0.5735, -1.8013, -1.6362],\n",
            "        [ 4.1465,  1.1870, -2.6181,  ...,  0.2127,  4.7738,  1.2284],\n",
            "        ...,\n",
            "        [ 0.3345,  1.0546, -2.6108,  ..., -0.6527,  0.4972, -4.6384],\n",
            "        [-2.7337, -9.8546, -3.2935,  ..., -1.7774,  4.1268, -5.5591],\n",
            "        [-2.0802, -6.7924, -1.7514,  ..., -4.7339,  4.0901, -0.5834]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3373e-01, -4.4042e+00, -2.1726e+00,  ..., -4.1276e+00,\n",
            "          1.9411e+00,  1.2993e+00],\n",
            "        [-2.0658e-01, -3.7435e-01, -3.0152e+00,  ...,  7.3266e-01,\n",
            "          5.3421e+00,  1.0296e+00],\n",
            "        [ 3.9463e-01,  1.6479e+00, -5.5016e-01,  ..., -1.0673e-01,\n",
            "          2.2508e+00,  8.8969e-03],\n",
            "        ...,\n",
            "        [-3.8696e+00, -5.9614e-01,  5.0689e-01,  ..., -3.0049e+00,\n",
            "          4.1795e-01, -1.5980e+00],\n",
            "        [ 1.0687e+00, -9.3287e-01, -1.7754e+00,  ..., -4.5061e+00,\n",
            "          1.8578e+00,  4.3358e-03],\n",
            "        [-7.5898e-02,  4.0699e+00, -7.4024e-01,  ..., -4.2987e-01,\n",
            "          2.5850e+00, -1.6093e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8829,  2.2350, -0.1638,  ..., -0.2197, -1.0321, -1.6194],\n",
            "        [-1.3688, -0.1285, -0.2396,  ..., -4.2751,  1.1214,  3.1909],\n",
            "        [-0.6075,  4.2179, -2.1509,  ...,  1.0066, -1.2824, -3.5854],\n",
            "        ...,\n",
            "        [-4.5183, -7.9982, -3.5944,  ..., -2.5175,  0.7254,  3.4735],\n",
            "        [-0.3128, -2.7345, -3.7523,  ..., -0.0475, -2.7901, -3.9252],\n",
            "        [-0.2828,  1.9133, -2.1834,  ...,  0.7793,  1.1333, -4.1996]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "973c21dc4e0747e5bcc05dde595187b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0.2636,  -3.6898,  -3.0769,  ...,  -0.1879,   0.2018,   1.1463],\n",
            "        [  0.9195,   2.5702,  -2.4314,  ...,   0.5357,  -3.1107,  -3.0866],\n",
            "        [  1.1520,   0.7167,  -2.6038,  ...,  -0.6251,   1.2596,  -3.6563],\n",
            "        ...,\n",
            "        [  2.1511,   2.1817,  -0.8183,  ...,  -0.4697,   0.2682,   2.1397],\n",
            "        [ -1.5696, -11.7898,  -4.2836,  ...,  -1.5738,  -1.2624,   0.3337],\n",
            "        [  3.0833,  -2.2801,  -2.5163,  ...,  -1.8852,   5.9371,  -5.3411]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0370, -1.0900, -1.1724,  ..., -0.6331,  1.8772,  3.1388],\n",
            "        [ 0.8393,  2.6931, -0.4951,  ..., -3.2727, -2.2066,  0.4415],\n",
            "        [ 3.0529,  2.4027, -3.4058,  ..., -0.8524, -1.2022, -0.7795],\n",
            "        ...,\n",
            "        [-2.0981, -4.9785, -3.8937,  ..., -0.4376, -0.8107, -5.3939],\n",
            "        [ 0.4969,  4.9167, -1.5749,  ..., -0.5396, -2.2873, -0.6363],\n",
            "        [-1.2894, -7.3608, -3.7705,  ..., -1.5765, -2.5357,  0.2979]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8429,  3.9801, -0.7872,  ..., -1.8638,  0.5090,  1.8264],\n",
            "        [ 0.2835,  1.8340, -0.6273,  ...,  0.1630,  0.3655, -0.3022],\n",
            "        [ 2.3303,  4.2150, -2.8750,  ...,  2.1349, -0.3453, -1.9300],\n",
            "        ...,\n",
            "        [-1.7547, -4.0381, -4.1510,  ..., -4.6762,  2.7918,  0.4731],\n",
            "        [ 0.0323, -1.9631, -1.5604,  ..., -3.4580,  3.1343, -2.3600],\n",
            "        [-1.9105, -2.0879,  0.1403,  ...,  0.2685, -0.4863,  2.2591]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7170, -3.7879,  0.2895,  ..., -2.9085, -2.1717,  3.1381],\n",
            "        [-0.0531,  0.2969, -0.7001,  ..., -0.4920, -1.7735,  2.1371],\n",
            "        [ 3.2475,  2.6841, -1.1455,  ..., -2.3875,  4.2809, -0.8467],\n",
            "        ...,\n",
            "        [-0.1266,  4.6281, -1.5372,  ..., -0.5470,  2.9745, -2.2770],\n",
            "        [-0.4829,  5.1554, -5.1134,  ...,  0.2624, -2.1964, -2.4685],\n",
            "        [ 3.4404, -0.0259, -3.4133,  ...,  2.5608,  1.0024, -1.8072]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9170,  5.2855, -2.9683,  ..., -2.2747, -0.0112, -2.6673],\n",
            "        [ 0.8668,  1.2740, -2.3665,  ..., -2.0511, -3.0044, -3.2156],\n",
            "        [ 3.1489, -2.3483, -3.6165,  ..., -3.0948,  7.1744, -0.8895],\n",
            "        ...,\n",
            "        [-4.8094, -9.7376, -2.1853,  ..., -4.3654, -3.4895,  0.6401],\n",
            "        [ 0.2250, -1.5573, -1.2348,  ...,  1.9158,  1.2198, -0.2865],\n",
            "        [ 0.2160,  1.5857, -3.9294,  ..., -0.2452,  0.3015, -1.9044]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6995, -4.0125, -3.7724,  ...,  1.0562,  3.0088, -4.0182],\n",
            "        [-3.2314,  0.1336, -3.0459,  ..., -2.3831,  0.4494,  0.4956],\n",
            "        [ 0.0144,  0.6353, -3.0096,  ..., -0.7925,  2.6677, -0.0162],\n",
            "        ...,\n",
            "        [-1.6306, -8.6828, -5.4140,  ..., -2.0072, -0.8678,  0.3719],\n",
            "        [ 3.2956,  4.3942, -1.5020,  ..., -2.6707, -0.7838,  1.1146],\n",
            "        [-2.7915, -1.9311, -1.3047,  ..., -3.4180, -0.9803,  1.5314]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0335, -1.3120, -1.3113,  ..., -2.5174,  2.2337,  0.9011],\n",
            "        [-0.1718,  2.6033, -1.6402,  ..., -2.6710, -5.4076,  1.5947],\n",
            "        [ 2.1630, -2.1601, -3.7740,  ..., -2.0752,  8.5139,  0.5453],\n",
            "        ...,\n",
            "        [-0.1840,  0.6665, -1.6338,  ...,  0.0622, -0.6128,  1.3486],\n",
            "        [ 0.3888,  2.8249, -0.5983,  ..., -2.7588,  0.8986,  0.4459],\n",
            "        [-2.2795, -0.0204, -0.6332,  ..., -1.9588,  3.1979, -2.9770]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5501, -1.6417, -2.1362,  ..., -1.6563,  0.9285, -2.8401],\n",
            "        [ 2.2014,  2.4928, -3.0389,  ..., -1.0690, -3.3951,  0.0618],\n",
            "        [ 2.9053,  3.1722, -0.6910,  ..., -1.9051, -0.0555,  0.8954],\n",
            "        ...,\n",
            "        [ 0.4759,  4.2067, -3.5688,  ..., -0.1853,  2.4487, -3.5735],\n",
            "        [-1.4666,  0.0383, -0.4455,  ..., -0.2488, -0.8205,  2.0119],\n",
            "        [ 2.5918,  0.6739, -3.1405,  ..., -1.0524,  4.3970,  1.5877]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  0.6860,  -2.1925,  -1.3022,  ...,   1.1171,  -0.0895,  -0.8024],\n",
            "        [ -1.8007,  -0.5553,  -2.1221,  ...,  -2.3062,   3.0049,   2.0916],\n",
            "        [ -0.1485,   0.7370,  -1.5468,  ...,   0.4185,   1.6470,  -2.0437],\n",
            "        ...,\n",
            "        [  0.7866,   1.5542,  -0.3902,  ...,  -0.3233,   0.1712,   0.4917],\n",
            "        [ -3.4553, -10.2234,  -7.0599,  ...,  -4.6210,  -0.7645,   0.9321],\n",
            "        [ -2.2034,  -3.6154,  -3.3060,  ...,  -3.1212,   3.1295,   2.8610]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9616, -1.3055, -0.0684,  ..., -0.7908,  0.8435,  2.1979],\n",
            "        [ 0.5537,  1.8743, -2.3525,  ..., -2.3869, -2.8585, -1.8985],\n",
            "        [ 0.0959,  4.4150, -1.4711,  ..., -1.5418, -2.6894, -1.4066],\n",
            "        ...,\n",
            "        [ 1.3728, -2.5964, -3.4916,  ..., -3.0749,  3.6227,  1.9981],\n",
            "        [-0.3177, -5.4232, -3.1822,  ..., -2.0164,  0.7371, -0.9667],\n",
            "        [ 0.6693,  4.6918, -2.7074,  ..., -1.7710,  1.2411, -1.6870]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1074e-01,  2.1494e-01, -2.3019e+00,  ..., -3.7018e+00,\n",
            "          1.0806e+00,  1.8335e+00],\n",
            "        [ 1.4478e+00, -4.2240e-01, -8.1086e-01,  ..., -4.8730e-01,\n",
            "          1.9794e+00, -6.6448e-01],\n",
            "        [ 1.1527e+00,  2.5154e+00, -1.0392e+00,  ...,  1.9170e+00,\n",
            "         -1.1279e+00,  5.6141e-01],\n",
            "        ...,\n",
            "        [-1.7774e-02,  4.5794e+00, -3.6164e+00,  ..., -1.8417e+00,\n",
            "         -2.0680e+00, -1.7314e+00],\n",
            "        [ 7.2281e-01,  8.9779e-01, -2.2537e+00,  ...,  6.2538e-04,\n",
            "         -1.6577e+00, -4.3777e+00],\n",
            "        [ 1.5303e+00, -2.3571e+00, -2.5550e+00,  ..., -1.3680e+00,\n",
            "          3.4504e+00,  1.7995e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6574, -8.7372, -0.7925,  ..., -0.6188, -0.4195, -2.6527],\n",
            "        [-1.5591, -1.0439, -0.7963,  ..., -4.8144, -0.6033,  3.4537],\n",
            "        [ 0.6733,  1.0784, -1.6358,  ..., -1.5406, -0.8291, -0.3546],\n",
            "        ...,\n",
            "        [ 1.4659,  2.3146, -2.8892,  ..., -0.6568,  0.9390, -1.4845],\n",
            "        [-0.3051,  1.1801, -1.2633,  ..., -2.0864, -2.8269, -1.6662],\n",
            "        [-1.2938,  3.9919, -2.0426,  ..., -1.5739, -2.0785, -2.7463]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4492, -0.5831, -2.1483,  ...,  1.1761,  0.7318,  1.6255],\n",
            "        [-0.5691, -2.4472, -0.0735,  ..., -1.7535,  0.2444,  0.7352],\n",
            "        [-0.3680, -0.0484, -3.7348,  ..., -1.4813,  0.0430, -2.5317],\n",
            "        ...,\n",
            "        [-4.8014, -8.0890, -5.2534,  ..., -3.1922, -1.0229, -2.4023],\n",
            "        [-1.1763, -0.1300, -1.7578,  ..., -0.2401, -4.9579, -2.3698],\n",
            "        [ 1.0238, -3.6882, -3.6565,  ..., -1.3439,  7.6710,  1.7691]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1870,  0.3456, -3.4651,  ..., -2.8323,  5.9091, -0.2417],\n",
            "        [-4.4434, -2.0189, -1.7439,  ...,  0.7679, -1.1660, -2.1251],\n",
            "        [ 0.5861, -3.0438, -1.6263,  ..., -0.1270, -0.9507, -1.6597],\n",
            "        ...,\n",
            "        [-1.0862, -3.5169, -2.0626,  ..., -1.0287,  0.9631, -1.1458],\n",
            "        [-1.8842,  1.4888, -3.6756,  ...,  0.1855,  0.5503, -4.8346],\n",
            "        [-3.2127,  0.7497, -2.6906,  ..., -1.0012,  2.9848,  1.9885]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5649, -1.2631, -2.0096,  ..., -2.8163,  3.4874, -1.2809],\n",
            "        [ 2.1767,  1.8979,  0.0464,  ..., -1.2911, -0.0149,  1.8881],\n",
            "        [-1.5316, -1.0853,  0.0886,  ..., -0.3977, -0.1143,  2.9218],\n",
            "        ...,\n",
            "        [ 0.1013,  0.7559, -1.2364,  ...,  0.6634, -0.8245, -1.5053],\n",
            "        [-2.4124, -0.1457, -1.5959,  ..., -2.9198, -2.4178,  2.4525],\n",
            "        [ 2.4349,  4.8224, -1.2767,  ..., -1.9985,  0.0064, -1.0560]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0311, -2.9670, -2.4138,  ..., -1.6602,  3.4336, -1.3129],\n",
            "        [-1.2990,  4.2794, -2.3068,  ..., -0.3487, -1.6401, -2.4178],\n",
            "        [-2.8747, -3.3816, -1.2921,  ...,  0.2735,  0.8825,  2.3014],\n",
            "        ...,\n",
            "        [-5.5792, -3.5540, -1.4813,  ..., -1.6323, -1.9055,  0.4306],\n",
            "        [-2.5632, -3.1604, -2.1331,  ..., -3.1319,  0.4569, -2.3708],\n",
            "        [ 4.0240,  1.0467, -3.3769,  ..., -1.8120,  3.5695,  0.8901]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -1.6957,   4.6311,  -2.5202,  ...,  -2.1142,  -0.4264,  -1.3059],\n",
            "        [ -0.1337,   4.0124,  -2.4623,  ...,  -2.3412,  -2.5411,  -1.2578],\n",
            "        [ -1.9103,   0.3414,  -1.5381,  ...,  -3.0189,  -3.5411,  -1.9875],\n",
            "        ...,\n",
            "        [ -1.1705,   1.6867,  -1.3251,  ...,   0.6297,  -1.7227,  -2.5938],\n",
            "        [ -5.0753, -11.1028,  -1.5727,  ...,  -0.8792,  -1.9208,  -0.9656],\n",
            "        [ -0.5254,   3.5213,  -2.0168,  ...,  -0.8070,  -1.3874,  -0.9426]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5347, -1.1522, -1.9526,  ..., -3.9858,  6.7123, -2.2353],\n",
            "        [-0.5493,  1.0035, -2.4338,  ..., -1.6288, -5.7000, -2.0704],\n",
            "        [-0.6735,  0.9741, -0.2425,  ..., -1.5889, -0.1372,  2.5845],\n",
            "        ...,\n",
            "        [-1.4254,  2.0999, -0.4227,  ..., -1.2551, -1.8318, -0.4293],\n",
            "        [-3.1161, -1.5753, -0.6972,  ..., -3.2981,  1.7527, -0.7181],\n",
            "        [-2.1943, -0.7796, -3.1681,  ...,  4.7019,  0.7027, -2.3844]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6489,  2.6116, -2.7704,  ..., -1.7173,  4.4269,  0.2624],\n",
            "        [-0.6386, -0.9718, -2.1424,  ...,  0.7459, -2.4332,  1.0446],\n",
            "        [ 0.3076, -0.1771, -1.4891,  ..., -1.7082, -1.8577, -1.3670],\n",
            "        ...,\n",
            "        [ 1.9681,  0.8985, -4.0450,  ...,  2.2194,  2.8855,  1.2122],\n",
            "        [-1.7913, -7.0816, -0.9302,  ...,  0.1640,  2.1676, -0.1577],\n",
            "        [ 1.8910,  0.3500, -1.3998,  ..., -0.4697, -1.7361, -1.2820]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3007,  5.8644, -0.7384,  ..., -1.1664, -1.7847,  0.1625],\n",
            "        [-3.9890, -2.4642, -4.2144,  ..., -3.6913,  3.4806,  2.3194],\n",
            "        [-0.9196,  3.3512, -0.8329,  ..., -1.9502,  2.1590, -0.2105],\n",
            "        ...,\n",
            "        [-1.8271, -2.8622,  1.0316,  ..., -3.4183,  1.4825,  2.4160],\n",
            "        [-2.0630, -0.4256, -1.0462,  ..., -0.5363, -3.0027, -1.9977],\n",
            "        [ 0.0359, -2.5453, -2.6851,  ..., -0.9935,  1.4818, -2.2499]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0171,  5.5067, -1.6830,  ...,  1.2693,  0.5038, -4.4736],\n",
            "        [ 1.7075,  2.3895, -0.2994,  ..., -3.6124, -0.6195,  2.2752],\n",
            "        [-2.5609, -1.1353, -2.4794,  ..., -0.9448,  4.5838, -0.4552],\n",
            "        ...,\n",
            "        [-0.9751,  1.0304, -2.9837,  ..., -2.9460,  1.6090,  1.2625],\n",
            "        [ 2.1731, -2.3105, -1.8205,  ..., -1.3090,  2.7496, -5.0471],\n",
            "        [-2.0164,  1.5248, -0.9872,  ..., -0.4121, -1.9921,  0.3808]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.6331, -7.6627, -3.8874,  ..., -2.7514,  2.0372, -2.6602],\n",
            "        [-2.2113, -1.9982,  1.0471,  ..., -0.4728, -3.0454,  0.4029],\n",
            "        [-2.6618, -0.7642, -1.6102,  ..., -1.6132,  0.1260, -0.8587],\n",
            "        ...,\n",
            "        [ 2.1423,  3.0364, -0.3338,  ..., -1.9846, -0.1417,  1.5585],\n",
            "        [-3.0948, -5.5769, -2.8001,  ..., -1.5046,  0.4783,  0.2716],\n",
            "        [-4.3342, -1.7378, -3.7342,  ...,  1.2680, -2.7417, -5.4970]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1935, -3.2290, -1.3636,  ..., -2.0918,  1.1361, -2.7922],\n",
            "        [-4.1148, -1.4268,  0.3465,  ..., -3.9314, -1.7054,  3.8078],\n",
            "        [-1.5241,  1.1825, -0.8449,  ..., -3.6619, -1.8447,  1.4930],\n",
            "        ...,\n",
            "        [-6.5864, -4.0089, -1.1416,  ...,  0.1488, -0.1361, -3.0104],\n",
            "        [ 0.8395,  4.5105, -2.1356,  ..., -0.6966,  1.3553, -0.4802],\n",
            "        [-1.0876,  2.6577, -1.3029,  ..., -1.4774, -5.6594, -2.5513]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7386,  0.3429, -0.7473,  ...,  0.6635, -3.3795,  0.0905],\n",
            "        [-0.1418,  4.6842, -2.0821,  ..., -0.5543, -0.0809, -2.4580],\n",
            "        [-1.2103, -1.4858, -3.2511,  ..., -3.7502,  1.7869,  1.8238],\n",
            "        ...,\n",
            "        [-0.8879,  6.1871, -1.6291,  ..., -0.4336, -2.7606, -3.3766],\n",
            "        [-1.2230, -3.4373, -2.1496,  ..., -1.7032,  1.4581, -1.5537],\n",
            "        [-5.7108, -6.6631, -0.5232,  ...,  1.6922,  3.7479, -3.0684]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.9495, -1.3615, -1.0604,  ..., -4.8409,  0.3676, -2.2683],\n",
            "        [ 1.6916,  4.8145, -0.6290,  ..., -1.2880, -0.0579,  2.3885],\n",
            "        [ 0.3433,  3.7259, -0.1070,  ...,  0.8345, -1.6188, -0.3461],\n",
            "        ...,\n",
            "        [-1.4785,  3.0131, -1.0421,  ...,  0.9875, -0.3314, -1.2542],\n",
            "        [-3.0545, -2.3634, -1.9774,  ..., -1.1235, -0.1419, -1.5428],\n",
            "        [ 2.2081,  3.1751, -2.2728,  ..., -0.5387,  2.4599, -0.8326]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  0.8751,   5.8786,   0.1368,  ...,  -0.6584,  -1.9636,  -1.5240],\n",
            "        [ -1.2783,   1.8689,  -3.0273,  ...,  -0.2843,  -4.5926,  -2.6249],\n",
            "        [ -4.5318,  -1.8566,  -0.3042,  ...,  -1.5855,   0.0267,   0.9272],\n",
            "        ...,\n",
            "        [ -2.8548,  -1.4565,  -0.9231,  ...,  -0.3899,   4.1249,   1.5974],\n",
            "        [  0.3761,   4.8455,  -0.6455,  ...,  -1.0191,  -2.3361,  -1.6213],\n",
            "        [ -4.1188, -10.2800,  -3.7926,  ...,  -4.2987,  -3.0144,  -2.1781]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6896, -0.0126, -0.3449,  ...,  0.0323, -4.2835, -0.0650],\n",
            "        [ 0.6229,  3.7281, -1.4696,  ..., -3.0803,  0.9551, -0.8775],\n",
            "        [ 0.7052, -1.8449, -1.6682,  ..., -0.5727, -0.0596, -4.6887],\n",
            "        ...,\n",
            "        [ 0.0698,  4.9788, -1.7802,  ..., -3.4343, -0.0334, -0.7145],\n",
            "        [-0.2140, -7.8633, -3.5344,  ..., -1.8526,  6.4097, -4.8658],\n",
            "        [ 1.4151,  0.6583, -2.2338,  ..., -1.5789,  6.7759,  0.3102]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2645, -5.5229, -1.1232,  ..., -2.2827, -0.1467, -1.9366],\n",
            "        [-3.7256, -4.4976, -4.3664,  ..., -5.6919, -2.1350, -1.9268],\n",
            "        [-1.2332, -1.8081, -2.4221,  ..., -1.7141, -0.6753, -2.2244],\n",
            "        ...,\n",
            "        [ 0.7057, -1.4194, -4.6246,  ..., -3.0840,  3.4583,  0.7558],\n",
            "        [-0.8096,  2.2606, -1.9003,  ..., -1.3584,  2.9408,  1.8372],\n",
            "        [ 2.8271, -5.6318, -3.6657,  ...,  0.3939,  4.8277, -7.3923]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5446,  2.3410, -0.5466,  ..., -1.8424,  0.1112,  1.2872],\n",
            "        [-6.6178, -3.7675,  1.3390,  ..., -0.4275, -2.2261, -2.9308],\n",
            "        [-3.8632, -3.5484, -2.6764,  ..., -3.1585, -0.8621,  1.1268],\n",
            "        ...,\n",
            "        [-3.3913, -2.4140, -2.5489,  ..., -4.6919, -2.3221, -3.4073],\n",
            "        [ 0.4670, -0.9566, -2.3896,  ..., -2.6274,  1.2696, -2.6004],\n",
            "        [-2.5212, -0.9638, -0.6594,  ..., -4.0041, -0.8462, -0.0606]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-6.0456, -5.4332,  0.5041,  ..., -3.5484, -1.4824, -0.2340],\n",
            "        [ 2.8699, -0.8112, -2.7249,  ..., -4.0349,  6.8596, -1.5983],\n",
            "        [ 2.2805,  3.8306, -3.3793,  ..., -3.2625, -0.6630, -0.0843],\n",
            "        ...,\n",
            "        [ 0.4994,  3.4680, -2.6506,  ..., -1.9388,  0.3889,  1.5821],\n",
            "        [-0.6810,  1.6284, -0.3330,  ..., -0.0533, -0.7237,  1.5053],\n",
            "        [-0.5854, -1.2457, -3.1976,  ..., -2.4978,  4.0370,  0.0548]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6849e-01, -1.8175e+00, -4.6430e+00,  ..., -1.8545e+00,\n",
            "          7.7714e+00,  5.9345e-01],\n",
            "        [-1.9911e+00,  1.9031e+00, -2.2591e+00,  ..., -1.2121e+00,\n",
            "         -1.8118e+00, -3.1302e+00],\n",
            "        [-3.9901e-01,  1.2138e+00, -1.6246e-01,  ...,  1.9514e-01,\n",
            "         -5.8588e-01,  1.2551e+00],\n",
            "        ...,\n",
            "        [-1.7716e+00,  1.8356e-03,  7.6400e-02,  ..., -9.6199e-02,\n",
            "         -6.4840e-02,  1.4742e+00],\n",
            "        [-3.3198e+00, -4.3592e+00, -3.5583e+00,  ..., -1.0178e+00,\n",
            "         -2.0261e+00, -5.6754e+00],\n",
            "        [-1.0893e+00, -4.0775e+00, -2.5551e+00,  ..., -3.0832e+00,\n",
            "          3.8196e+00, -4.4409e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  2.0127,  -1.4193,  -0.6329,  ...,  -3.3074,   5.4713,  -2.9095],\n",
            "        [  0.4986,   6.2033,  -0.5467,  ...,  -2.2918,   0.7963,  -0.0366],\n",
            "        [ -5.7563,  -4.6740,  -2.2053,  ...,  -3.9616,  -1.9124,   1.2659],\n",
            "        ...,\n",
            "        [ -3.5174,  -1.7541,  -1.9312,  ...,  -0.6976,   5.7049,   0.5091],\n",
            "        [ -1.7521,  -4.6888,  -2.2828,  ...,  -0.9290,  -0.1014,  -2.3559],\n",
            "        [ -2.7674, -13.2309,  -4.5643,  ...,  -1.9131,   1.1842,   1.5275]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0567,  4.3481, -2.8088,  ..., -0.8967, -0.8087, -3.4834],\n",
            "        [-1.5594,  1.6060, -2.8067,  ..., -1.1617, -5.5683, -3.4606],\n",
            "        [-1.2290, -6.2667, -0.7389,  ..., -1.5030,  2.2938, -1.4338],\n",
            "        ...,\n",
            "        [-2.2589,  0.2165, -2.2911,  ...,  1.7385, -0.0163, -3.4020],\n",
            "        [ 1.3927,  2.4169, -1.8772,  ..., -1.2523, -1.4344, -1.8659],\n",
            "        [-3.8625, -3.5001,  1.3905,  ..., -1.0876,  0.2427,  2.7974]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4674,  1.4179, -3.3887,  ..., -1.3986, -0.9186, -2.3651],\n",
            "        [-0.9811,  7.9896, -2.6544,  ..., -1.3050, -4.8144, -1.4045],\n",
            "        [-0.4290, -3.4350, -3.8491,  ..., -3.0927,  4.4532,  1.1733],\n",
            "        ...,\n",
            "        [ 3.3258,  4.6651, -1.5586,  ..., -3.2504, -0.3125,  0.9229],\n",
            "        [-4.3340, -8.1373, -5.4661,  ..., -5.6247, -0.7003,  0.8869],\n",
            "        [ 2.3220,  3.9204, -0.8428,  ..., -1.4931, -0.4508,  1.3780]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1767,  2.4928, -0.5297,  ...,  3.8322, -1.0454, -5.2611],\n",
            "        [-0.3019, -3.7832, -2.5351,  ...,  0.0735,  0.3915, -1.6869],\n",
            "        [-1.4087, -3.6933, -4.1631,  ..., -0.5495,  5.3195,  0.4747],\n",
            "        ...,\n",
            "        [-4.0056, -7.5109, -2.8978,  ..., -3.5834,  3.8332, -0.0465],\n",
            "        [-2.3711,  2.9175, -3.0054,  ...,  0.8318,  1.6756, -4.4686],\n",
            "        [-2.7954, -0.9461, -2.3955,  ..., -1.9088,  1.5503, -2.3478]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6530,  2.9273, -1.2398,  ...,  0.3386, -6.2318, -1.5062],\n",
            "        [-1.9938, -3.1847, -1.8821,  ...,  1.3554, -0.2202, -0.8947],\n",
            "        [ 0.9379,  4.1789, -1.5507,  ..., -0.5033, -1.8896, -0.3976],\n",
            "        ...,\n",
            "        [ 1.2479, -4.9718, -4.8621,  ..., -3.7342,  8.2222, -2.4225],\n",
            "        [ 2.4391, -0.0432, -3.3524,  ..., -3.6016, -0.4663, -0.9527],\n",
            "        [-1.9823,  2.5397, -1.8270,  ...,  1.0853, -4.9794, -1.5303]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5004,  1.6031, -2.8192,  ..., -0.4542,  4.3932, -0.3667],\n",
            "        [-2.5637, -2.8413, -0.8162,  ..., -0.4205, -0.3999, -1.8430],\n",
            "        [-2.1190, -1.9146, -1.5434,  ..., -2.0049, -0.2166, -2.8138],\n",
            "        ...,\n",
            "        [-3.3895, -4.8867, -1.3737,  ..., -1.5861, -0.9801, -2.9979],\n",
            "        [-2.1821, -6.9890, -2.4947,  ..., -0.6170,  2.3652,  3.0526],\n",
            "        [-0.9566,  6.3620, -1.0263,  ..., -0.5195, -3.6532, -3.8286]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  0.8558,   1.6380,  -0.6228,  ...,  -0.4127,   3.2601,  -4.4686],\n",
            "        [  0.3583,   3.8451,  -1.6966,  ...,  -1.7265,  -0.9895,  -1.0191],\n",
            "        [ -4.3639, -11.9368,  -4.8013,  ...,  -3.0283,  -1.6637,   0.0368],\n",
            "        ...,\n",
            "        [ -3.0123,  -1.3104,   0.7406,  ...,   0.1000,  -1.2890,   1.6750],\n",
            "        [ -2.3534,  -0.1569,  -2.8369,  ...,  -1.6497,   1.4999,   2.3056],\n",
            "        [ -0.3037,  -0.8340,  -1.5003,  ...,  -3.2643,  -2.0676,   3.3673]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6901,  0.5213, -0.3556,  ..., -0.4861, -1.5666, -1.3509],\n",
            "        [ 2.4338,  3.8796, -3.3837,  ..., -2.6091, -1.7156, -2.5122],\n",
            "        [-5.3640, -5.1345, -2.9483,  ..., -3.6386,  2.2330,  2.9366],\n",
            "        ...,\n",
            "        [-1.6306,  1.6850, -1.6314,  ...,  0.0266, -0.9878, -3.0988],\n",
            "        [-0.3751,  3.3916, -2.3110,  ..., -2.6248, -0.6419,  0.5124],\n",
            "        [ 0.4025,  1.4826, -2.7654,  ...,  0.9211,  0.0469, -4.7569]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6671, -2.5735, -3.1884,  ..., -2.2216,  6.2491, -0.3322],\n",
            "        [-0.5087,  2.0300, -1.2191,  ..., -1.1837, -5.4738, -0.9919],\n",
            "        [-1.6490,  4.2889, -2.7269,  ...,  2.7989,  0.6354, -2.9969],\n",
            "        ...,\n",
            "        [-2.0839,  6.4712, -2.7303,  ..., -1.7469, -2.6861, -4.2670],\n",
            "        [-5.0390, -5.5918,  1.8774,  ..., -0.1232, -1.5720,  2.1801],\n",
            "        [-3.4646,  1.9011,  0.6469,  ..., -2.9897,  1.2583, -1.4421]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5586,  5.4807, -1.0214,  ...,  1.3985, -1.9238, -4.1743],\n",
            "        [ 0.1252, -1.4435, -2.6236,  ...,  2.8503,  2.7344,  0.4002],\n",
            "        [-1.8085, -2.7450, -2.3819,  ..., -3.8157,  2.9164,  1.4434],\n",
            "        ...,\n",
            "        [-3.7487, -6.9707, -2.5259,  ..., -2.4477,  1.3897, -3.3620],\n",
            "        [-2.4669, -0.4370,  0.6638,  ..., -0.8762, -0.6238,  0.9652],\n",
            "        [ 1.7205,  2.4952, -3.0310,  ..., -2.0432, -0.6129, -1.4468]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6142e+00,  9.6821e-01, -1.5636e+00,  ..., -1.8601e+00,\n",
            "          3.8885e+00,  3.8599e-01],\n",
            "        [-2.6627e+00,  2.6996e+00, -4.2684e+00,  ..., -3.6028e-01,\n",
            "          1.7855e+00, -1.6591e+00],\n",
            "        [-5.2270e-02, -8.4934e+00, -3.8284e+00,  ..., -1.6012e+00,\n",
            "          3.9333e+00, -7.3917e-01],\n",
            "        ...,\n",
            "        [-3.4333e+00, -8.8911e-01, -4.7000e-03,  ..., -3.5021e-01,\n",
            "         -2.0440e+00,  5.8531e-01],\n",
            "        [-8.4815e-01,  1.0263e-01, -1.8986e+00,  ..., -8.3906e-01,\n",
            "          4.2064e-01, -1.7446e+00],\n",
            "        [-8.6035e-01, -2.1890e+00, -3.1893e+00,  ..., -2.2622e+00,\n",
            "          5.0464e+00, -1.1655e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1213, -3.3321, -0.5728,  ..., -3.7051,  1.0360,  1.0892],\n",
            "        [-2.8868, -3.6523, -2.6475,  ..., -0.8136,  1.4140, -1.1393],\n",
            "        [-2.0294, -1.9921,  1.0564,  ..., -6.0583, -1.5359,  3.3304],\n",
            "        ...,\n",
            "        [-0.6553,  4.7789, -3.1647,  ..., -1.0296,  1.0835, -3.2081],\n",
            "        [ 0.1895,  1.9997, -2.5528,  ..., -0.6096, -7.6236, -0.7181],\n",
            "        [ 3.2535,  1.5930, -0.7713,  ..., -2.0077,  0.9332,  1.7077]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2285, -7.9979, -5.0219,  ..., -1.6213,  0.7074, -4.2614],\n",
            "        [-0.8849,  1.7217, -0.4516,  ...,  1.2700,  0.0427,  0.5398],\n",
            "        [ 0.1308,  2.2276, -2.1062,  ..., -1.8941, -1.9865, -2.7006],\n",
            "        ...,\n",
            "        [-3.5893, -4.4802, -0.5904,  ..., -0.5705, -0.6374, -0.9078],\n",
            "        [-2.2642, -1.0487, -2.1536,  ..., -2.7309, -0.2289, -1.5179],\n",
            "        [-5.3456, -3.9888, -0.6892,  ..., -2.8529, -2.8417, -0.7400]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6380,  4.3880, -2.3998,  ...,  0.1961,  1.4145, -1.7648],\n",
            "        [-2.8891, -2.0914, -2.1518,  ..., -1.8176, -1.3101,  2.2774],\n",
            "        [-0.4066,  6.4898, -0.9265,  ..., -0.6051, -1.0309, -1.9171],\n",
            "        ...,\n",
            "        [-1.6594, -1.0805, -1.4258,  ..., -0.3460, -3.3607,  1.8040],\n",
            "        [-0.7889, -0.1028, -3.6710,  ..., -4.9052, -0.1591, -1.2488],\n",
            "        [-2.1964, -5.4100, -3.6847,  ..., -0.1818,  0.8263, -1.8532]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9644, -3.1203, -1.3246,  ..., -2.7777,  6.7763,  1.2831],\n",
            "        [ 0.6248, -2.4134, -3.7598,  ..., -1.7157,  7.4451, -0.2902],\n",
            "        [-0.0133,  2.6210, -1.7102,  ..., -0.1706, -3.1882,  0.2984],\n",
            "        ...,\n",
            "        [-6.6922, -3.1992, -1.5321,  ..., -4.2787, -3.7899, -1.5175],\n",
            "        [ 0.5959,  3.9828, -2.4758,  ..., -0.9126, -3.9460, -1.7631],\n",
            "        [-0.1117,  2.8155, -2.5078,  ..., -2.6920, -0.8730,  0.3144]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2880, -0.2823, -2.5129,  ..., -0.1793, -4.6866, -3.7336],\n",
            "        [ 0.8630,  3.3355, -2.2727,  ..., -0.6783,  2.3991, -2.1694],\n",
            "        [ 0.3494, -2.8616, -2.6035,  ..., -5.3802,  7.9711,  0.6482],\n",
            "        ...,\n",
            "        [-2.9823, -2.3268, -1.7856,  ..., -5.9673, -2.9786,  3.0806],\n",
            "        [ 0.2801,  5.8288, -1.0644,  ..., -2.0361, -2.4440, -2.6226],\n",
            "        [-2.5306, -1.4139,  1.3416,  ...,  0.0170, -0.6141,  0.7233]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5592e+00, -1.7518e+00,  5.4898e-01,  ...,  1.6338e-01,\n",
            "         -1.9883e+00,  1.5525e+00],\n",
            "        [-2.6584e+00,  2.0515e+00, -2.5090e+00,  ..., -1.3061e+00,\n",
            "         -6.1311e+00, -1.6050e+00],\n",
            "        [-3.5915e+00, -1.1654e+00, -3.0014e+00,  ...,  3.8419e-01,\n",
            "         -6.2603e-02, -6.3541e+00],\n",
            "        ...,\n",
            "        [-2.2926e+00, -1.3693e-01, -8.5831e-01,  ..., -6.2188e-03,\n",
            "         -2.9360e+00,  1.2062e+00],\n",
            "        [-4.5028e+00, -4.1214e+00, -7.0336e-01,  ...,  2.8191e-01,\n",
            "          2.1211e+00, -2.5634e+00],\n",
            "        [-8.4529e-01,  4.4361e+00, -1.7907e-01,  ..., -1.1912e+00,\n",
            "         -2.6177e+00,  1.1339e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5817,  0.0510, -2.5673,  ...,  0.6905,  3.4564,  1.9858],\n",
            "        [-0.7622, -8.2009, -2.6789,  ...,  0.5957,  1.4766, -4.8025],\n",
            "        [-2.7574, -5.6738, -2.4943,  ..., -2.6255,  1.7498,  0.4024],\n",
            "        ...,\n",
            "        [-2.8127, -2.9158, -0.7512,  ...,  1.6734,  1.3955, -0.5820],\n",
            "        [-2.1463,  1.6843, -3.2253,  ...,  7.5228, -1.7005, -4.7049],\n",
            "        [-8.1598, -6.5131, -1.9361,  ..., -2.3775, -1.0225, -4.5139]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7990,  1.2634, -1.9319,  ..., -1.1168,  1.4565,  3.7478],\n",
            "        [ 0.3803,  0.3403, -2.0196,  ..., -0.2587, -0.8788, -0.5708],\n",
            "        [-3.0100, -2.7328, -2.1616,  ..., -4.0180,  1.1765,  1.6114],\n",
            "        ...,\n",
            "        [ 2.1445, -3.7667, -0.9484,  ..., -3.0073,  4.2886, -4.6385],\n",
            "        [ 2.1958,  0.3794, -1.7166,  ..., -2.2039,  4.1826, -1.3019],\n",
            "        [ 0.6674, -0.1134, -2.0272,  ..., -2.2793, -1.1392, -0.0980]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6981,  4.2775, -1.9547,  ..., -0.1696,  1.4972, -1.0835],\n",
            "        [-0.5307,  0.5761,  0.6588,  ..., -0.2923, -1.9521, -0.7677],\n",
            "        [-2.5165,  2.2547, -1.5007,  ..., -0.1853,  0.4305, -0.7302],\n",
            "        ...,\n",
            "        [-3.7109, -9.7237, -4.7925,  ..., -4.3346,  1.3307, -5.0132],\n",
            "        [ 0.3073,  1.2334, -0.6268,  ..., -0.0635, -1.5858,  2.2684],\n",
            "        [-1.4603,  0.6539, -0.6290,  ...,  0.7882,  0.0254,  1.1000]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1437, -7.9068, -3.7951,  ..., -3.0047,  4.4801, -0.5781],\n",
            "        [-3.4515, -6.1526, -1.3297,  ..., -1.0884,  2.1579, -1.4878],\n",
            "        [-2.2054,  0.7617, -2.7517,  ...,  0.2662, -2.1721,  0.9631],\n",
            "        ...,\n",
            "        [ 3.3677, -0.0602, -2.3025,  ..., -2.3196,  4.7214, -0.8664],\n",
            "        [-4.7550, -5.0162, -0.2639,  ..., -2.6338,  1.7212,  1.9214],\n",
            "        [-0.3588,  5.8295, -1.4860,  ..., -0.8177, -0.3704, -0.6932]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.8868, -6.2699, -3.1023,  ..., -3.0001, -0.3338, -1.1644],\n",
            "        [-3.8348,  0.0121, -1.4438,  ...,  0.4702, -1.2810,  0.9415],\n",
            "        [-4.0832, -0.7284, -3.4578,  ..., -2.4700, -1.2154, -0.2123],\n",
            "        ...,\n",
            "        [-1.2375, -4.5718, -1.9599,  ...,  3.3581,  3.9579,  2.0182],\n",
            "        [-0.4737, -4.9740, -0.6307,  ..., -2.8286,  4.3274, -0.8006],\n",
            "        [-2.9760, -3.9967, -2.5005,  ..., -0.6205,  0.0828, -3.1758]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0990,  0.8404, -2.2367,  ...,  1.6674,  0.0942, -2.9855],\n",
            "        [-5.2267, -7.1521, -3.1473,  ..., -0.1789, -1.3242, -5.5492],\n",
            "        [-0.8148, -6.1908, -2.6590,  ..., -0.9666,  0.6878,  0.1610],\n",
            "        ...,\n",
            "        [-3.0828, -1.2697, -0.3672,  ..., -0.2333,  5.1094, -2.4118],\n",
            "        [-0.4386,  4.3592, -1.5185,  ..., -0.1981, -2.9718, -2.3424],\n",
            "        [ 1.7921,  5.5358, -1.1930,  ..., -1.3677, -0.5681,  3.1120]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1532e-01,  2.8208e+00, -2.8677e+00,  ...,  8.3143e-01,\n",
            "         -3.7651e-01, -1.4568e+00],\n",
            "        [-7.0066e-01,  4.3920e-01, -7.2847e-01,  ...,  1.6874e+00,\n",
            "          2.1729e+00,  2.2784e-03],\n",
            "        [-9.8465e-01, -2.0709e-01, -1.0503e+00,  ...,  9.9216e-02,\n",
            "         -1.7441e+00,  1.2920e+00],\n",
            "        ...,\n",
            "        [-1.3237e+00,  1.5320e-01, -3.3308e+00,  ..., -2.2102e+00,\n",
            "         -5.0161e+00,  8.9470e-01],\n",
            "        [-2.6284e+00, -3.9548e+00, -2.0963e+00,  ..., -3.2003e+00,\n",
            "         -1.5049e+00, -1.1442e+00],\n",
            "        [-8.6700e-01, -2.2654e+00, -1.7656e+00,  ...,  3.3169e+00,\n",
            "         -1.9199e+00, -2.8427e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1353,  1.0522, -2.5895,  ...,  1.2664, -0.4110, -1.9180],\n",
            "        [ 2.3777, -1.0045, -2.8173,  ..., -0.3724,  3.7600,  1.8540],\n",
            "        [-0.6360,  5.1793, -0.5183,  ..., -1.4584,  0.0410,  0.8763],\n",
            "        ...,\n",
            "        [ 3.3475,  1.2609, -0.7234,  ..., -1.2645,  3.8588,  0.0070],\n",
            "        [-2.8473,  2.6506, -1.8544,  ...,  0.2336, -4.5106, -2.6980],\n",
            "        [ 0.0658,  5.2460, -1.5308,  ..., -0.8175, -0.7919,  0.0977]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4030,  0.6847, -2.3297,  ..., -1.3233, -5.4163,  3.2015],\n",
            "        [-1.9620,  1.5639, -1.4155,  ..., -2.0004, -0.7764, -0.6667],\n",
            "        [-2.3990,  1.8457, -0.7802,  ..., -0.5769, -3.4003, -0.2983],\n",
            "        ...,\n",
            "        [-2.3034,  0.1080, -3.1369,  ...,  1.1997, -2.5677,  0.7802],\n",
            "        [-0.4753, -0.1386, -0.7895,  ..., -0.2922, -0.1846,  2.9882],\n",
            "        [-1.3915, -0.6815, -2.1909,  ...,  0.1206, -2.3235,  2.3068]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -4.8994, -10.6025,  -2.3876,  ...,  -0.6241,  -0.7304,  -1.0565],\n",
            "        [ -3.7576,  -4.1564,  -0.9049,  ...,  -0.9110,   1.1920,  -2.0149],\n",
            "        [ -4.2986,  -6.0261,  -3.0563,  ...,  -0.3432,   0.7540,  -2.1214],\n",
            "        ...,\n",
            "        [ -1.4826,   3.6528,  -1.9853,  ...,  -1.6950,  -2.4678,  -1.9694],\n",
            "        [ -2.5303,  -1.7228,  -0.4448,  ...,  -4.9023,  -2.4687,   3.9643],\n",
            "        [  1.0506,  -2.0875,  -2.5609,  ...,  -0.6237,  -0.5690,   1.6122]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2659,  2.1462, -0.8568,  ..., -1.0059, -4.2896, -0.6802],\n",
            "        [-2.3602, -4.8987, -2.0562,  ...,  0.8254,  0.5744,  0.5386],\n",
            "        [-1.9495,  2.7737, -1.8526,  ...,  0.5039,  0.6587, -3.2631],\n",
            "        ...,\n",
            "        [ 1.8093,  1.8977, -1.8543,  ...,  0.2579,  0.8830,  0.4247],\n",
            "        [-2.5004, -4.3166, -6.2304,  ..., -1.3095,  1.0547,  3.0178],\n",
            "        [-1.5572, -1.0801, -1.5371,  ..., -1.8608, -0.1020, -2.2705]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3136,  2.6353, -1.0627,  ..., -1.1726,  0.0851,  2.2123],\n",
            "        [ 2.8253,  1.2561, -3.5416,  ..., -2.8480,  5.8052,  1.6172],\n",
            "        [-3.7653, -3.0044, -1.5234,  ..., -0.5328, -1.4519, -0.7222],\n",
            "        ...,\n",
            "        [-1.8191, -2.5691, -4.4259,  ..., -1.7384, -0.2146, -2.9021],\n",
            "        [ 2.2791,  3.2222, -2.2010,  ..., -1.0100, -1.4552,  0.4617],\n",
            "        [-2.0130, -6.6899, -2.9256,  ..., -2.2986,  2.0754, -2.9740]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  1.7107,  -2.0572,  -0.8411,  ...,  -2.3414,   6.5315,  -2.0673],\n",
            "        [ -5.6913, -11.4941,  -4.4410,  ...,  -2.7777,  -4.7484,  -0.7596],\n",
            "        [ -1.2179,   4.7729,  -2.5340,  ...,  -1.2047,  -4.1968,  -1.0463],\n",
            "        ...,\n",
            "        [ -2.0406,   6.4883,  -4.7137,  ...,  -1.6728,  -3.9758,   0.1973],\n",
            "        [ -2.3842,  -1.3135,  -2.2172,  ...,  -5.8712,  -0.2363,   2.9529],\n",
            "        [  0.2313,   2.6518,  -1.7232,  ...,  -0.3824,  -5.3322,  -0.3841]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7253,  4.6219, -3.4567,  ..., -1.2011, -0.1896, -2.2578],\n",
            "        [ 0.2364,  2.0046, -2.5345,  ..., -1.6664, -1.2876,  0.5007],\n",
            "        [ 2.5932,  1.9378, -1.8797,  ..., -2.0483,  2.1225,  2.4148],\n",
            "        ...,\n",
            "        [ 2.3538,  6.0039, -2.3919,  ..., -3.0521, -0.5483,  1.3265],\n",
            "        [-4.1780, -7.9324, -1.1519,  ...,  2.5716, -3.7788, -0.2536],\n",
            "        [ 0.3347,  1.0410, -4.6228,  ...,  0.6969,  4.8538, -2.2202]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8376,  2.8537, -3.2048,  ..., -1.3250,  1.5922, -3.7968],\n",
            "        [-0.1467,  5.0739, -2.4152,  ..., -1.3934,  2.5708, -0.2158],\n",
            "        [-0.8783,  2.7923, -0.5091,  ..., -1.8823, -0.3540,  2.0250],\n",
            "        ...,\n",
            "        [ 3.4844,  5.6967, -2.8224,  ..., -3.9600, -1.2110,  1.9077],\n",
            "        [-0.6612,  1.1791, -0.2397,  ..., -1.5022, -5.9887,  1.7984],\n",
            "        [-0.5453, -1.5228, -0.6154,  ..., -1.9951, -0.1146,  3.3844]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0191, -1.0453, -3.6897,  ..., -3.9346,  4.4108,  0.9529],\n",
            "        [-1.0630,  5.2560, -3.0306,  ..., -0.5622,  0.0255, -3.5045],\n",
            "        [-2.6068,  1.6703, -1.6745,  ..., -0.6086,  1.7839, -0.1639],\n",
            "        ...,\n",
            "        [ 2.0267,  3.6501, -3.4205,  ..., -2.4086, -1.0453,  0.1024],\n",
            "        [-2.0058, -1.0620, -1.2037,  ..., -1.7480,  0.1867,  3.5546],\n",
            "        [-2.9718, -3.8540, -2.7511,  ...,  4.4905,  0.5750, -2.8634]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9198, -1.8583, -0.0601,  ..., -3.1817,  1.7106,  1.6329],\n",
            "        [ 1.2551, -1.7632, -2.1306,  ..., -0.6661,  3.8740,  6.0484],\n",
            "        [ 2.4644, -0.7101, -3.0517,  ..., -3.1523,  7.6095,  2.2297],\n",
            "        ...,\n",
            "        [-4.8736, -9.6474, -4.7123,  ..., -2.9884,  1.3966, -2.5574],\n",
            "        [-1.3293, -4.5883, -2.2455,  ..., -4.0738,  2.0087,  1.1720],\n",
            "        [-1.8855, -2.1203, -4.0240,  ..., -1.1178,  2.0029,  2.5633]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.2305, -3.6746, -0.5759,  ...,  0.5461,  1.3587, -2.7889],\n",
            "        [-1.3266,  2.2951, -1.8824,  ..., -0.3635, -3.9484, -2.1058],\n",
            "        [-2.5577, -1.1543, -1.2016,  ...,  0.1425, -1.8698,  1.8994],\n",
            "        ...,\n",
            "        [-2.3348, -8.8123, -5.1992,  ..., -4.2063, -1.1503, -3.1143],\n",
            "        [-2.5051, -5.8522, -2.6606,  ..., -4.0694,  1.6311, -1.8199],\n",
            "        [-0.5891,  4.6518, -3.4948,  ..., -0.7846, -0.2389, -1.9997]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4007,  3.1264, -1.0334,  ..., -1.0043,  0.2909,  1.9676],\n",
            "        [ 2.6137, -3.1461, -2.7559,  ..., -2.2022,  5.1798, -4.5885],\n",
            "        [-0.4448,  5.9009, -2.3530,  ..., -1.2746,  2.5341, -0.9977],\n",
            "        ...,\n",
            "        [ 0.2674, -5.6259, -0.7624,  ...,  2.1695, -0.9427, -2.8894],\n",
            "        [-0.1340,  2.1081, -3.0715,  ..., -3.0604, -2.9642, -0.1069],\n",
            "        [ 1.1173,  1.0471, -1.0860,  ..., -3.0324,  1.7925,  1.2221]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  0.3362,   2.2868,  -2.8782,  ...,  -0.5054,  -1.1468,  -0.9099],\n",
            "        [  1.2380,   2.1932,  -4.3810,  ...,  -1.4525,  -3.1270,  -0.4496],\n",
            "        [ -4.5514,  -8.6367,  -5.6333,  ...,  -5.0338,   1.6379,   1.5872],\n",
            "        ...,\n",
            "        [ -2.3462,   1.4173,  -3.5098,  ...,  -2.2497,  -4.4052,  -2.9281],\n",
            "        [ -5.1340, -13.6130,  -7.1751,  ...,  -6.1308,  -0.4252,  -0.6479],\n",
            "        [ -0.7425,  -2.9690,  -3.0247,  ...,  -4.1843,   3.7653,   4.1969]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3843,  1.5518, -1.5685,  ..., -3.1850, -3.6627, -1.6342],\n",
            "        [-1.1262,  1.8521, -1.4831,  ..., -1.7538, -5.0570,  0.0560],\n",
            "        [-0.8574,  6.7518, -4.2914,  ..., -4.2260, -1.9417, -2.0325],\n",
            "        ...,\n",
            "        [-1.9382, -2.3117, -2.0301,  ..., -5.0979,  3.9572,  3.3917],\n",
            "        [ 0.4113, -8.2943, -2.9881,  ..., -2.9687,  2.7075,  0.3845],\n",
            "        [-0.0310,  2.1948, -1.3363,  ..., -0.1863, -1.1152,  2.4536]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8697, -0.1728, -1.9149,  ...,  0.8097,  3.1214, -3.4376],\n",
            "        [-0.1269,  0.3890, -4.4104,  ..., -0.4624,  4.3323,  2.2712],\n",
            "        [-0.3456,  5.6500, -1.2663,  ..., -3.6377, -3.1565, -0.4701],\n",
            "        ...,\n",
            "        [-1.3678,  5.2909, -2.2841,  ..., -1.8614,  2.0089, -0.5479],\n",
            "        [-0.3363,  2.2695, -2.2837,  ..., -1.1941, -2.0173, -1.0774],\n",
            "        [ 0.4705,  0.7110, -2.8339,  ..., -1.0101,  1.1057, -0.4059]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2217,  0.9000, -4.4018,  ..., -2.1425,  0.0554, -0.9313],\n",
            "        [-3.0253, -5.8978, -1.2744,  ..., -4.5730,  0.5945,  0.1081],\n",
            "        [-3.4678, -6.0293, -2.2683,  ..., -0.4524,  3.5147, -1.7381],\n",
            "        ...,\n",
            "        [-1.0059,  0.7564, -3.6608,  ..., -2.1543,  1.4706, -1.5719],\n",
            "        [-0.6992, -1.0139, -2.0573,  ..., -2.1929, -1.3471, -0.4126],\n",
            "        [-4.0286, -4.2094, -5.7530,  ..., -5.1929,  4.4380,  2.9040]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8501, -2.0336, -3.3863,  ...,  0.1195, -1.5838, -3.7635],\n",
            "        [-0.8922, -7.1221, -1.7313,  ..., -2.2718,  2.3986, -2.9224],\n",
            "        [ 0.2194, -0.8756, -1.1361,  ..., -2.3135, -4.5264,  3.1328],\n",
            "        ...,\n",
            "        [-2.7991, -6.4023, -2.0238,  ..., -3.1987,  2.9201,  0.2800],\n",
            "        [-0.8997, -4.9005, -1.2277,  ..., -4.2106,  5.0262,  0.7981],\n",
            "        [-3.4567, -1.9950, -3.7633,  ..., -1.9283,  0.7711, -0.4554]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3569,  3.8231, -1.4568,  ..., -0.8587,  2.3381,  0.8944],\n",
            "        [ 1.7240,  1.6164, -3.0765,  ..., -1.6796,  0.3489,  4.1955],\n",
            "        [-3.4881, -0.4758, -2.1106,  ..., -1.4032,  2.2800,  0.4232],\n",
            "        ...,\n",
            "        [-4.0559, -1.5952, -3.8037,  ..., -1.3966,  4.6343,  0.8984],\n",
            "        [ 1.1470, -1.6819, -2.9791,  ..., -3.8625,  6.6040,  1.1597],\n",
            "        [ 3.0302,  1.5475, -4.4734,  ..., -2.5703,  3.9226,  3.0083]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -2.0885,  -1.9426,  -5.1920,  ...,  -4.4910,   3.2374,   1.2014],\n",
            "        [ -1.9938, -14.0936,  -5.4466,  ...,  -0.1247,  -2.4349,   0.2407],\n",
            "        [ -2.7513,  -2.2480,  -1.2444,  ...,  -2.2157,  -0.2980,  -1.5056],\n",
            "        ...,\n",
            "        [ -2.7821,   1.5576,  -3.3043,  ...,  -2.4799,  -2.0998,  -2.5759],\n",
            "        [ -1.7616,   2.1916,  -3.7217,  ...,  -2.4426,   3.0667,   0.4715],\n",
            "        [ -1.0707,   2.9590,  -2.2044,  ...,  -3.0342,   0.6796,  -2.2449]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0496,  2.6183, -2.3289,  ..., -1.9079, -4.3155, -2.3299],\n",
            "        [-2.4576, -7.3335, -2.9141,  ..., -3.3133, -0.7813, -1.1038],\n",
            "        [-0.2614,  4.0517, -2.3074,  ..., -0.3167, -5.8500, -1.1492],\n",
            "        ...,\n",
            "        [-1.3990, -0.1531, -2.3344,  ..., -0.4198,  1.7745, -0.8422],\n",
            "        [-1.8880, -3.1632, -3.3441,  ..., -5.2271, -2.1706,  1.2159],\n",
            "        [-1.0941,  5.5043, -2.7616,  ..., -0.0946, -1.5349, -5.1443]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.5867e+00, -5.5060e+00, -3.7399e+00,  ..., -4.4359e+00,\n",
            "          3.1356e+00, -9.4303e-03],\n",
            "        [-7.0196e-01,  9.9910e-01, -1.6645e+00,  ..., -5.4219e+00,\n",
            "         -1.3577e+00,  4.9416e+00],\n",
            "        [-6.0554e+00, -1.1825e+01, -6.4117e+00,  ..., -3.9963e+00,\n",
            "         -5.4279e-01, -4.3875e+00],\n",
            "        ...,\n",
            "        [ 1.2746e+00, -6.5484e-01, -3.5700e+00,  ..., -2.3049e+00,\n",
            "          2.1263e+00, -1.8173e+00],\n",
            "        [-1.0118e+00,  1.2447e+00, -1.4070e+00,  ...,  2.8351e-01,\n",
            "         -1.0221e+00,  2.7463e+00],\n",
            "        [-2.9074e+00, -1.5354e+00,  1.7708e-01,  ..., -1.2174e+00,\n",
            "         -6.5056e-01,  2.1023e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3459,  1.0705, -2.0881,  ..., -3.2952, -1.2082,  1.8673],\n",
            "        [-1.7052,  0.9603, -2.0366,  ..., -1.7384, -3.3396, -1.3329],\n",
            "        [-2.1408, -3.6895, -1.9711,  ..., -0.0075,  0.2471, -0.5759],\n",
            "        ...,\n",
            "        [-0.1321, -4.9889, -5.6767,  ..., -5.7850,  3.9604,  3.6002],\n",
            "        [-1.3955,  3.9640, -3.2659,  ...,  2.1421, -0.0419, -4.3083],\n",
            "        [-1.6412, -0.6895, -0.9687,  ...,  0.0394, -0.4872,  2.6178]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8082, -2.7236, -2.8922,  ..., -0.3230, -0.7207, -3.6488],\n",
            "        [-0.6939,  3.7606, -2.3005,  ..., -0.1180, -3.5367, -2.0624],\n",
            "        [-0.8826,  7.0200, -1.9699,  ..., -1.8551, -1.5258, -2.5259],\n",
            "        ...,\n",
            "        [ 0.3885,  5.9647, -2.7457,  ..., -2.8983,  1.1706, -1.8313],\n",
            "        [-2.1821, -1.0533, -0.5973,  ..., -2.1825, -1.0947,  4.8610],\n",
            "        [ 0.3260, -0.5929, -1.5209,  ..., -0.5332,  2.0961, -0.6961]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1268, -3.3785, -1.6396,  ..., -0.6844, -2.7081,  3.5993],\n",
            "        [ 1.3399, -5.7392, -3.2639,  ..., -2.1834,  5.2020, -1.8332],\n",
            "        [-2.4488,  2.7638, -2.6067,  ..., -1.1511, -1.6608, -2.7258],\n",
            "        ...,\n",
            "        [-3.6999, -6.4414, -4.4199,  ..., -4.2610,  1.2449,  2.3749],\n",
            "        [-2.0056,  0.4755, -0.3522,  ...,  1.0566,  1.6812, -0.5199],\n",
            "        [-0.1781, -0.9670, -1.6126,  ..., -1.4966, -0.0431, -0.3262]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.4410e-01,  1.1125e+00, -2.5423e+00,  ..., -1.7630e+00,\n",
            "         -1.8223e+00,  2.7677e+00],\n",
            "        [-1.3012e+00, -4.7298e+00, -3.4341e+00,  ..., -1.5120e+00,\n",
            "          2.5885e+00, -1.9407e+00],\n",
            "        [-2.8441e+00, -4.6683e+00,  2.1459e+00,  ..., -2.5420e+00,\n",
            "         -9.7608e-01,  6.1145e-01],\n",
            "        ...,\n",
            "        [ 2.4118e+00, -3.4129e-01, -2.2296e+00,  ..., -5.1069e+00,\n",
            "          8.0173e+00,  9.4325e-01],\n",
            "        [-2.7356e+00, -2.0278e+00, -1.9333e+00,  ..., -5.3658e-01,\n",
            "         -2.3245e+00,  3.4049e+00],\n",
            "        [ 3.4670e-01,  3.7695e+00, -2.3834e+00,  ..., -2.6015e+00,\n",
            "         -4.4745e+00,  4.5898e-03]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0862,  0.9968, -1.6034,  ...,  0.9695, -0.1708,  0.2688],\n",
            "        [ 1.8561, -0.1028, -2.7803,  ..., -3.2239,  6.0975, -6.1260],\n",
            "        [ 3.4053,  4.4313, -2.1999,  ..., -3.0439,  0.0441,  2.4993],\n",
            "        ...,\n",
            "        [-2.7739, -1.8058, -3.2856,  ..., -0.4713,  3.2013,  1.2834],\n",
            "        [-2.8737,  0.7611, -3.5120,  ...,  3.2287, -1.3853, -1.9198],\n",
            "        [-0.9821,  1.7701, -1.3504,  ..., -0.7461, -0.4826,  1.4683]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3566, -0.6878, -3.7419,  ..., -4.4291, -1.7019,  2.3612],\n",
            "        [-2.7728, -1.8196,  0.1073,  ..., -1.1630, -0.8649,  2.2620],\n",
            "        [-0.1532,  4.2755, -1.1883,  ..., -2.1630, -0.1116, -1.7327],\n",
            "        ...,\n",
            "        [ 2.5938,  2.3903, -0.5158,  ..., -1.6428, -0.0726,  2.5643],\n",
            "        [ 1.8166,  1.7603, -3.3463,  ..., -1.4522, -0.1141,  0.8197],\n",
            "        [-2.6510,  1.4285, -3.3737,  ...,  0.4311, -3.5434, -3.1348]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6829, -3.9453, -2.6233,  ..., -0.6170,  2.8795, -1.0070],\n",
            "        [-3.0052,  2.6789, -2.0641,  ..., -3.4102, -0.3483,  1.3546],\n",
            "        [ 0.5680,  1.5429, -3.1040,  ..., -1.5594,  1.3580,  0.1999],\n",
            "        ...,\n",
            "        [-4.0486, -0.0681, -3.1599,  ..., -0.0415,  0.1595, -2.2628],\n",
            "        [-2.8045, -8.5997, -2.6527,  ..., -3.3274,  2.2978, -2.6212],\n",
            "        [-0.8762,  1.6562, -0.3526,  ..., -1.4548, -0.2699,  3.2597]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8628, -4.9791, -5.2240,  ..., -4.6331,  0.7265,  1.6895],\n",
            "        [ 0.6146,  5.9199, -1.0761,  ..., -2.2118, -0.2504,  2.2058],\n",
            "        [-0.2123,  4.4019, -2.8058,  ...,  0.7546, -2.2814,  0.6412],\n",
            "        ...,\n",
            "        [-1.9962, -0.6104, -2.6130,  ..., -1.0283,  0.2712,  1.2153],\n",
            "        [-1.3992, -0.5853, -4.3209,  ...,  1.2638, -0.5011, -1.4553],\n",
            "        [-1.1765, -3.5811, -4.2940,  ..., -5.4769,  3.2782,  1.7812]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0356,  2.1608, -1.1099,  ..., -1.9206,  1.2954,  2.3964],\n",
            "        [-2.1013,  3.6863, -3.7053,  ..., -2.5031, -0.0904, -3.3755],\n",
            "        [-0.1755,  1.3527, -4.3244,  ..., -3.8068, -3.3367,  0.8952],\n",
            "        ...,\n",
            "        [ 2.3737,  6.5389, -1.7359,  ..., -0.9900, -1.1830,  2.5081],\n",
            "        [-2.7836, -4.3883, -3.7490,  ..., -2.3358,  1.5646,  3.2626],\n",
            "        [-2.7532, -2.6132, -1.7357,  ..., -1.3231,  1.9972, -1.9507]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -4.0102,  -1.4572,  -3.1315,  ...,   5.7836,  -0.1082,  -4.3476],\n",
            "        [ -0.4048,  -0.1817,  -2.0731,  ...,  -3.6534,  -1.6292,   0.6150],\n",
            "        [ -4.2710, -12.9130,  -6.4691,  ...,  -3.7421,  -3.3432,   0.6276],\n",
            "        ...,\n",
            "        [ -1.6193,  -0.1856,  -4.3466,  ...,  -3.1879,   2.8035,   2.3544],\n",
            "        [  0.1905,   0.8860,  -0.1283,  ...,  -1.4847,  -1.5483,   2.6852],\n",
            "        [ -1.1523,  -6.0960,  -2.9649,  ...,  -2.7127,  -2.6122,   0.9629]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7279, -3.2439, -3.7634,  ..., -3.0870,  2.5046, -2.2061],\n",
            "        [-1.7056, -5.0411, -4.4874,  ..., -1.9011,  1.8701, -4.8617],\n",
            "        [-2.7645,  2.4234, -3.3932,  ..., -0.0584,  0.3940, -1.9793],\n",
            "        ...,\n",
            "        [-0.1701, -1.8755, -4.6940,  ..., -3.3189,  2.5137,  1.8612],\n",
            "        [-4.0455, -3.8065, -2.6313,  ..., -2.1255, -1.9982, -1.3984],\n",
            "        [-1.3499, -5.5974, -2.1713,  ..., -3.3854,  0.5151, -2.6422]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7844,  3.3784, -2.4318,  ...,  1.5019,  2.0210, -1.2523],\n",
            "        [-2.8463, -3.8126,  1.6544,  ..., -1.9033, -0.8290,  3.1634],\n",
            "        [-5.1196, -1.7971, -0.9188,  ..., -0.1270, -1.2502, -1.1709],\n",
            "        ...,\n",
            "        [-3.5222, -3.1882, -2.0612,  ..., -0.7297, -2.0425, -1.7188],\n",
            "        [ 1.1725,  3.0979, -0.8779,  ..., -1.2454, -4.2858,  0.4141],\n",
            "        [-0.0500,  2.5725, -2.2180,  ..., -0.9894, -1.5403,  1.8809]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3700, -5.8008, -4.5368,  ..., -2.3224,  0.2468, -1.7547],\n",
            "        [ 1.1014, -2.0105, -2.3304,  ..., -0.5776,  4.8210,  3.2473],\n",
            "        [ 0.3086,  2.5776, -2.2053,  ..., -2.0055, -5.3596, -0.9418],\n",
            "        ...,\n",
            "        [-1.8896, -1.1733, -3.9326,  ...,  4.6787, -0.0860, -3.5338],\n",
            "        [ 0.1006,  0.5872, -3.0035,  ..., -3.2721,  5.2826,  0.0536],\n",
            "        [ 1.7177,  3.2477, -3.0752,  ..., -1.0042, -0.4601, -3.2555]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.9362, -6.7230, -4.3215,  ..., -5.6963,  0.9420, -0.4226],\n",
            "        [-1.1780,  2.2056, -2.3432,  ..., -3.5473,  0.2779,  3.4706],\n",
            "        [-1.4950,  3.0064, -3.7929,  ..., -2.0408,  0.2016, -1.1475],\n",
            "        ...,\n",
            "        [-1.7455, -3.4948, -0.3820,  ..., -2.6134, -1.0509,  1.2981],\n",
            "        [-1.9508,  2.0233, -2.5491,  ..., -2.1229, -7.2069, -1.1849],\n",
            "        [-0.3667,  4.0294, -1.5662,  ...,  1.4879, -0.1681, -3.2077]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0138,  2.2757, -0.6584,  ..., -0.1060, -2.5897, -1.4725],\n",
            "        [-1.7407, -1.3584, -2.0187,  ..., -1.4746, -2.8116,  3.2078],\n",
            "        [-4.4435, -1.5564, -1.8069,  ..., -1.6034,  3.8703,  1.1065],\n",
            "        ...,\n",
            "        [ 2.6803,  1.6345, -1.3281,  ..., -3.6384,  5.1601,  0.2036],\n",
            "        [ 1.3029,  1.2979, -1.9363,  ..., -1.6686,  0.0850,  3.2458],\n",
            "        [-2.5241, -1.7089, -2.1629,  ..., -0.6871, -2.3779,  2.1076]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8754,  2.9741, -3.0050,  ..., -2.5468, -0.2093,  3.0470],\n",
            "        [ 1.3758, -0.4785, -0.3551,  ..., -4.9337,  4.0541,  0.0253],\n",
            "        [-5.2070, -1.3460, -0.5818,  ...,  1.5580, -0.1273,  0.4829],\n",
            "        ...,\n",
            "        [-3.7012, -4.3821, -1.8222,  ..., -5.1318, -1.8280,  0.5569],\n",
            "        [-2.7817, -2.3707, -0.0978,  ..., -0.6620, -1.2081,  2.6661],\n",
            "        [-0.3319,  4.9122, -3.2548,  ..., -0.4760,  3.8336, -2.8403]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3116,  4.3563, -3.0045,  ..., -4.4158, -4.6308, -1.8605],\n",
            "        [ 1.7348, -0.1351, -3.2192,  ..., -4.3136,  7.1742,  1.5861],\n",
            "        [ 1.2204,  4.2978, -0.9783,  ...,  0.0125, -0.1775,  1.4046],\n",
            "        ...,\n",
            "        [-0.3419, -7.2659, -4.8191,  ..., -5.3825,  4.7937,  3.3883],\n",
            "        [ 0.2407,  5.4193, -3.3424,  ..., -0.2892, -0.4625, -3.4711],\n",
            "        [-0.8091, -0.5793, -1.2430,  ..., -2.7832,  2.5530,  3.2234]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1610,  5.7011, -1.4018,  ..., -1.0669, -0.8512,  2.1998],\n",
            "        [-3.4271, -2.9410, -5.7062,  ..., -6.0754, -0.8573, -0.5007],\n",
            "        [-5.5246, -6.4642, -4.1963,  ..., -4.6493,  0.5992,  2.4094],\n",
            "        ...,\n",
            "        [ 0.0760,  0.8727, -1.1696,  ..., -3.9899, -0.2285,  1.7043],\n",
            "        [-1.7927,  1.7054, -2.3178,  ..., -0.5357, -3.0268, -2.9816],\n",
            "        [-5.3823, -2.7567, -2.5977,  ..., -0.4398, -0.6892, -0.3394]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9331, -5.3645, -5.7880,  ..., -6.0200,  3.1257, -3.3630],\n",
            "        [-1.8905,  4.5362, -1.4891,  ...,  0.2384, -1.8422, -3.1699],\n",
            "        [-0.2664,  1.4741, -2.5112,  ..., -5.1201,  0.4879,  2.8319],\n",
            "        ...,\n",
            "        [ 4.8615, -0.4459, -2.2999,  ..., -4.6426,  5.5565,  1.3873],\n",
            "        [-3.6597, -1.9974, -0.0868,  ..., -6.5890, -1.0233,  3.1099],\n",
            "        [-4.7184, -5.5600, -4.7137,  ..., -3.9795,  0.9495,  2.4169]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1258,  0.4671, -4.5051,  ...,  0.3845,  3.7886,  2.7992],\n",
            "        [-1.6056, -5.2782, -4.9220,  ..., -4.0722,  1.5940,  0.9494],\n",
            "        [-2.9323,  0.1228, -2.8313,  ..., -1.8995,  4.1411,  0.4624],\n",
            "        ...,\n",
            "        [-3.3651, -8.3357, -3.3090,  ..., -2.4166,  2.7087, -2.5221],\n",
            "        [-0.2953,  7.8380, -1.3636,  ..., -3.7323, -0.0655, -0.6532],\n",
            "        [-0.8656, -2.1357, -1.4998,  ..., -1.2913,  2.9932,  3.9414]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -2.4204,  -4.6034,  -2.3109,  ...,   3.4816,   0.2864,  -3.8330],\n",
            "        [ -1.9741,  -0.4707,   0.4149,  ...,  -0.6702,  -0.7816,   1.4571],\n",
            "        [ -0.1186,   5.4310,  -3.1290,  ...,  -4.1419,  -1.6240,  -0.2331],\n",
            "        ...,\n",
            "        [  1.8960,   2.0241,  -0.7398,  ...,  -1.3789,  -4.5563,   2.6233],\n",
            "        [ -2.1374,  -2.5352,  -2.2457,  ...,  -0.7019,  -2.6374,  -1.1085],\n",
            "        [ -4.1943, -10.3743,  -5.5773,  ...,  -2.0481,   2.6638,  -8.0434]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4296, -4.7157, -3.1383,  ..., -1.8066, -0.4886, -2.6749],\n",
            "        [-2.3002, -7.5118, -4.0706,  ...,  1.8643,  0.2575, -2.2148],\n",
            "        [-0.9207, -4.9265, -4.5492,  ..., -1.5363,  0.2034, -4.9282],\n",
            "        ...,\n",
            "        [ 3.0411,  1.2561, -0.8500,  ..., -4.0846,  6.4153, -1.5502],\n",
            "        [ 0.3703,  3.5279, -2.7441,  ...,  0.4645, -0.7465,  2.8357],\n",
            "        [-0.0142,  1.6920, -1.4400,  ..., -3.1159, -5.2297, -0.7518]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5778,  0.3817, -1.4771,  ..., -0.6106, -0.6348,  1.6532],\n",
            "        [-2.3448, -1.2623, -3.8198,  ..., -0.5225,  5.2723,  0.1130],\n",
            "        [-0.4391,  5.9919, -2.6480,  ..., -1.8943, -1.4475, -0.1720],\n",
            "        ...,\n",
            "        [ 3.1614, -0.6481, -4.4804,  ..., -6.2366,  7.2062, -1.8498],\n",
            "        [-3.5211,  0.6369, -1.0748,  ..., -3.4729, -1.6628,  1.9386],\n",
            "        [-0.3592,  3.8733, -2.5862,  ..., -0.4223, -2.2062, -1.1598]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5772,  1.8445, -1.1789,  ..., -1.3509, -3.2211, -1.6185],\n",
            "        [-3.3992, -4.4748, -0.0342,  ..., -0.9162, -1.9773,  1.1394],\n",
            "        [ 1.5209,  1.0829, -1.8576,  ..., -2.2367, -1.9680, -0.1300],\n",
            "        ...,\n",
            "        [-3.2769,  2.9987, -1.5029,  ...,  3.7082, -0.8858, -6.2373],\n",
            "        [ 1.4355,  3.5604, -1.6856,  ...,  0.5189, -2.9952, -0.1272],\n",
            "        [-2.3627, -3.5987, -1.3808,  ..., -2.4594, -0.4087, -0.3497]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4888,  3.2949, -3.5565,  ..., -1.8428,  3.1335, -0.7985],\n",
            "        [ 2.3411,  1.2571, -2.4882,  ..., -0.3976,  2.2752,  1.7291],\n",
            "        [-3.1025, -4.0758,  2.4056,  ..., -2.1742,  0.0896,  1.3064],\n",
            "        ...,\n",
            "        [ 1.1118,  5.6017, -1.0398,  ..., -0.9325,  1.2722,  1.8781],\n",
            "        [-4.0437, -2.9997, -2.8652,  ...,  0.8508, -3.1650, -0.7428],\n",
            "        [-0.7113,  2.8144, -3.0392,  ...,  0.2389, -1.6608,  1.8453]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2224, -3.4177, -3.2824,  ..., -1.7155,  2.0859, -1.5068],\n",
            "        [-2.1649, -5.7396, -2.8698,  ..., -3.8827,  1.6531,  1.2834],\n",
            "        [ 0.5239, -2.1989, -1.0172,  ...,  1.8375,  0.5453, -2.3418],\n",
            "        ...,\n",
            "        [ 1.3326, -1.5117, -3.7991,  ..., -3.4997,  4.3882, -6.5223],\n",
            "        [ 2.4676, -1.2405, -3.1724,  ..., -0.4439,  5.0479,  1.4723],\n",
            "        [ 1.1025,  1.2850, -1.6721,  ..., -0.4749, -4.4584,  0.9016]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3314,  2.3170, -0.9267,  ...,  0.4511, -1.3974,  2.0875],\n",
            "        [-2.7395, -4.9991, -3.2693,  ..., -5.5317, -1.0872,  0.6056],\n",
            "        [ 3.2238,  1.0352, -4.9373,  ..., -4.8701,  6.8119, -2.3096],\n",
            "        ...,\n",
            "        [-0.2099, -0.3943, -1.5578,  ...,  0.4502, -0.9431,  1.2400],\n",
            "        [ 1.0234,  4.6504, -3.3212,  ..., -2.7276,  1.0902,  0.1839],\n",
            "        [-3.4624, -1.2213, -2.8243,  ..., -1.3523, -0.9328, -2.9996]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  0.1568,   0.9866,  -3.9552,  ...,  -2.6154,   3.2496,  -4.4418],\n",
            "        [ -0.7456,   2.6661,  -2.7087,  ...,  -0.4675,   2.0028,  -1.8198],\n",
            "        [ -2.2846, -10.2977,  -2.8722,  ...,  -1.8493,  -0.5905,   2.2444],\n",
            "        ...,\n",
            "        [ -0.8298,   6.1385,  -2.6806,  ...,  -0.6598,  -1.4359,  -2.6425],\n",
            "        [  2.2925,  -2.1953,  -2.9788,  ...,  -0.7086,  -0.9899,  -4.2190],\n",
            "        [  0.2201,  -4.2584,  -2.5001,  ...,   1.5687,   1.0495,  -3.2003]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2391,  5.6181, -3.5324,  ..., -1.0497, -3.0405, -3.0749],\n",
            "        [-5.8662, -3.5237, -2.8216,  ..., -4.2997,  0.2528, -0.5602],\n",
            "        [-0.7107,  3.3357, -2.8661,  ...,  1.2737,  0.9998, -3.0131],\n",
            "        ...,\n",
            "        [ 0.6965,  1.3595, -0.6094,  ..., -1.2229, -3.8716,  2.0222],\n",
            "        [-2.2356,  3.6538, -1.3600,  ..., -0.7472, -3.0436, -1.3558],\n",
            "        [-6.4601, -6.5499, -4.3204,  ..., -5.9401, -1.6999,  0.9900]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9043,  2.7481, -3.5822,  ...,  3.1310,  1.3174, -1.4810],\n",
            "        [-1.4712,  0.6995, -0.3798,  ...,  0.9151, -1.4937,  0.2762],\n",
            "        [ 1.0768,  0.9495, -3.8860,  ..., -2.1918, -1.7114, -0.6815],\n",
            "        ...,\n",
            "        [-3.0703, -0.5528, -1.1031,  ...,  2.5142, -1.1609, -4.1853],\n",
            "        [-1.3252, -0.1065, -3.5454,  ..., -3.4471,  2.6423, -3.6870],\n",
            "        [-0.4704,  1.8093, -3.6912,  ..., -2.1071, -0.5624,  1.3177]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3147, -6.9795, -2.1474,  ..., -1.7245,  1.0342, -1.6636],\n",
            "        [-4.8927,  0.6468, -1.0968,  ..., -2.0955, -0.8050, -1.9833],\n",
            "        [-1.2243,  2.0135, -3.2061,  ..., -1.1650, -4.3047, -3.6661],\n",
            "        ...,\n",
            "        [-2.7201,  2.8449, -3.1966,  ..., -1.8851, -4.5612, -2.4472],\n",
            "        [-4.0296, -3.2136, -3.5207,  ..., -3.3694,  1.7526,  3.6973],\n",
            "        [-1.7714,  1.1052, -0.6755,  ..., -1.7370,  1.5458, -0.7970]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3675, -8.5269, -3.4297,  ..., -3.9541, -0.7758,  0.9965],\n",
            "        [-6.4007, -7.8414, -4.1665,  ..., -2.9131, -4.4350, -3.9503],\n",
            "        [ 3.4820,  2.0511, -1.9589,  ..., -2.0479, -0.6716,  2.6304],\n",
            "        ...,\n",
            "        [-2.5282,  2.7812, -2.6838,  ...,  4.8082,  0.3578, -4.7823],\n",
            "        [-0.0902,  1.7832, -0.6001,  ...,  0.1080,  0.6126,  1.6260],\n",
            "        [-3.8943, -2.4279, -1.7699,  ...,  0.2882, -0.9571, -0.1844]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5136, -1.5280, -1.7868,  ...,  0.7075,  0.9008, -3.9810],\n",
            "        [-0.5106,  0.3742, -3.0895,  ..., -5.4709, -0.0725,  0.0904],\n",
            "        [ 2.0999,  1.1645, -2.9426,  ..., -4.2306,  6.5732, -0.1130],\n",
            "        ...,\n",
            "        [-1.3668,  0.3489, -2.5425,  ...,  0.0796, -0.8191, -6.3600],\n",
            "        [ 2.9604, -0.8813, -2.0824,  ..., -4.5804,  4.8534, -1.2190],\n",
            "        [-4.5281, -4.6092, -3.6334,  ..., -4.3623,  0.7463, -1.0327]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6577,  0.1011, -0.0625,  ..., -3.9764, -1.7009,  5.3927],\n",
            "        [ 0.6301, -2.5207, -2.4803,  ..., -2.3555,  5.3484,  1.7519],\n",
            "        [ 2.7014,  3.8007, -3.0429,  ..., -4.0755, -0.9920, -1.8893],\n",
            "        ...,\n",
            "        [-0.1269,  3.2734, -1.4996,  ...,  0.2817, -2.3429,  1.9967],\n",
            "        [ 3.0239,  1.8207, -1.9208,  ..., -2.4119,  3.3285, -0.6246],\n",
            "        [-4.2746, -1.3585, -0.8953,  ..., -1.1450,  1.0196,  0.9769]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6238, -1.1549, -4.4029,  ..., -1.4462, -0.5573, -1.5141],\n",
            "        [-2.3560, -1.8463, -2.0192,  ..., -4.3330,  0.4355,  3.4641],\n",
            "        [ 0.2099,  0.5809, -0.6138,  ...,  0.4852, -0.0227,  0.3423],\n",
            "        ...,\n",
            "        [-0.3192,  1.5333, -2.1391,  ..., -0.1153, -4.1020, -2.8875],\n",
            "        [-1.6120,  0.9402, -3.4826,  ..., -3.0834,  3.3195, -2.3317],\n",
            "        [ 0.0288,  6.0121, -2.3827,  ..., -0.6516, -1.6016, -1.3619]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3043, -1.9914, -2.1729,  ..., -1.7990, -2.4160, -3.5030],\n",
            "        [-1.6897,  5.0526, -2.9051,  ..., -0.5716, -2.3658, -0.6651],\n",
            "        [ 0.6470, -1.7571, -2.5932,  ..., -0.8856, -2.3414, -1.6582],\n",
            "        ...,\n",
            "        [-2.4527, -7.1325, -2.3638,  ..., -2.8763,  3.6915, -0.0194],\n",
            "        [-0.1560,  0.8536, -4.6633,  ..., -0.9535, -1.6221, -2.1682],\n",
            "        [-1.0815,  1.2596, -1.9224,  ..., -1.3434, -2.7068, -1.4020]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.1283, -4.6092, -3.4627,  ..., -1.8402,  0.3978, -4.3511],\n",
            "        [-1.5869,  4.9965, -2.9855,  ..., -4.0874, -4.2076,  0.5245],\n",
            "        [-1.5365,  1.0921, -0.9612,  ...,  0.5426, -2.7978, -0.1247],\n",
            "        ...,\n",
            "        [-4.1260, -8.5091, -0.6687,  ..., -6.9292, -1.1429,  1.1279],\n",
            "        [-4.4374, -1.8330, -4.0588,  ..., -2.2578,  0.3272, -0.5027],\n",
            "        [-4.9297, -9.4273, -5.2830,  ..., -4.6949, -2.3958, -2.3190]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0951, -3.3438, -2.7245,  ..., -2.8376,  0.2265,  1.1203],\n",
            "        [ 1.2870,  0.6304, -3.3732,  ..., -1.6096, -1.9959, -0.9312],\n",
            "        [-2.3547, -6.5838, -3.2450,  ..., -3.0985,  1.7532,  1.3201],\n",
            "        ...,\n",
            "        [-1.9058,  0.2516, -1.4799,  ..., -3.1439, -0.9787,  1.5236],\n",
            "        [-4.2769, -3.1508, -3.9177,  ..., -0.5699, -1.5031, -1.1872],\n",
            "        [ 3.3809,  3.3397, -3.2794,  ..., -3.8041, -1.0942, -0.0879]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3571,  1.9679, -3.1097,  ..., -3.3506, -5.8611,  2.4384],\n",
            "        [-1.4826,  4.7750, -2.5505,  ..., -0.7247,  0.5471, -4.4813],\n",
            "        [ 2.1012,  1.0886, -2.5715,  ..., -6.0076, -0.0564,  0.6455],\n",
            "        ...,\n",
            "        [ 1.6183, -0.7150, -4.5824,  ..., -0.4702, -0.8821, -1.0904],\n",
            "        [-1.4537, -0.0526, -1.6932,  ..., -0.8638,  0.0100,  2.2688],\n",
            "        [-3.0616, -6.4720, -5.6342,  ..., -2.7219,  1.6957,  1.9898]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8506,  3.8937, -4.2153,  ..., -0.8448,  2.2322, -2.2395],\n",
            "        [-5.1518, -0.0124, -2.7130,  ..., -5.3371, -0.6662,  3.4119],\n",
            "        [-2.7859, -2.2742, -0.3955,  ..., -0.3189, -2.3732,  2.2612],\n",
            "        ...,\n",
            "        [ 3.1916,  0.6957, -1.9760,  ..., -0.4446,  2.5950, -3.0062],\n",
            "        [-0.9846,  1.2264, -4.4524,  ..., -0.8119,  1.7121, -3.9774],\n",
            "        [ 2.1325,  3.2345, -1.2999,  ..., -1.6493, -0.8664,  1.9657]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5203, -4.3057, -4.5201,  ..., -4.5551, -0.8209,  1.3659],\n",
            "        [ 1.3358, -4.3572, -2.9975,  ..., -4.2856,  7.3931, -1.9070],\n",
            "        [-1.9607,  1.7985, -2.4980,  ..., -5.9256,  0.1189, -1.4278],\n",
            "        ...,\n",
            "        [-1.4152,  4.5604, -1.6332,  ...,  1.3128, -7.5357, -2.3962],\n",
            "        [-2.7761,  3.6857, -2.6391,  ..., -0.8910, -2.1407, -2.7746],\n",
            "        [-2.5564, -4.2381, -1.1019,  ..., -1.0454,  1.4641, -1.2482]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2785, -2.5836, -2.8964,  ..., -2.5451, -1.4696,  0.3751],\n",
            "        [ 0.7812, -1.3378, -3.0907,  ..., -2.5013,  4.8184,  0.1846],\n",
            "        [ 3.3400,  5.8283, -3.1156,  ..., -2.9188, -0.7771,  0.3673],\n",
            "        ...,\n",
            "        [ 2.3775,  0.3633, -3.1215,  ..., -4.2827,  5.7612, -0.7564],\n",
            "        [-0.7700,  3.9989, -2.7202,  ..., -0.7124, -0.5055, -2.4194],\n",
            "        [ 0.6214,  7.4472, -2.5818,  ..., -3.1875, -0.7383,  0.6457]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1113, -1.1288, -4.2599,  ...,  0.4793,  1.2442, -0.3966],\n",
            "        [-4.5365, -3.1926, -4.4500,  ...,  1.6967, -0.4048, -4.6251],\n",
            "        [ 1.2693, -3.4670, -5.0345,  ..., -7.4566,  2.6783, -1.9419],\n",
            "        ...,\n",
            "        [ 2.9002,  0.5823, -1.4204,  ...,  0.1148,  0.3892,  0.0294],\n",
            "        [-2.6968, -4.7638, -0.0728,  ..., -4.2482, -0.6804,  5.6109],\n",
            "        [ 0.4541, -1.9098, -4.5137,  ..., -5.1938,  3.0268, -3.6148]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1318,  3.1788, -4.3670,  ..., -2.4396, -0.0196, -0.8800],\n",
            "        [-2.3705,  0.3219, -1.1419,  ...,  0.5437, -2.3662, -2.5852],\n",
            "        [-2.1604, -0.1435, -3.0037,  ..., -1.9011, -4.1872, -2.5664],\n",
            "        ...,\n",
            "        [ 2.8740, -1.6986, -2.4049,  ..., -3.9398,  5.0205, -1.5663],\n",
            "        [-2.0980, -1.0418, -1.8494,  ..., -4.2745, -0.8495, -0.0708],\n",
            "        [ 1.3703,  0.8207, -4.1517,  ..., -3.7506,  1.4945, -0.8569]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.5220, -1.5506, -2.4695,  ..., -3.8863, -1.9566,  0.2090],\n",
            "        [-2.0685, -4.2247, -4.1451,  ..., -4.7825,  5.7660, -1.0758],\n",
            "        [-0.7656, -0.4249, -4.2582,  ...,  0.1454,  0.1279, -3.4424],\n",
            "        ...,\n",
            "        [-3.6657, -2.3350, -3.7053,  ..., -0.6151,  0.1409, -2.0582],\n",
            "        [-1.5751,  3.1220, -1.9845,  ..., -0.8640, -3.5958, -1.0736],\n",
            "        [ 0.7259,  3.4402, -2.1471,  ..., -2.0288, -2.4147, -2.5571]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4237, -5.2438, -3.7076,  ..., -0.9795,  2.4351, -2.6187],\n",
            "        [-1.9055,  2.5949, -2.5255,  ...,  0.3739,  0.4919, -5.9824],\n",
            "        [-6.4844, -7.2084, -3.5407,  ..., -5.0187, -0.8461,  3.1109],\n",
            "        ...,\n",
            "        [-5.1470, -3.5151, -1.7296,  ..., -4.8573,  1.2085, -0.9609],\n",
            "        [ 1.1414, -2.0411, -1.3563,  ..., -3.3074,  5.1250,  0.1709],\n",
            "        [-1.1325,  3.2097, -2.9208,  ..., -3.1400, -5.6065, -1.6066]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1204, -2.1734, -4.3959,  ..., -1.7680,  3.0570, -2.1745],\n",
            "        [-2.4584,  2.4055, -3.1003,  ..., -0.1113, -1.7966, -1.3796],\n",
            "        [-1.1040,  2.0935, -3.8349,  ..., -0.7183, -1.1279, -2.8842],\n",
            "        ...,\n",
            "        [-5.8874, -5.8510, -2.5695,  ..., -0.0910, -0.7697, -2.8180],\n",
            "        [-2.6426, -3.5542, -3.2099,  ..., -2.8822,  2.1548,  2.4789],\n",
            "        [-0.7940,  5.3284, -4.0830,  ..., -1.3563, -2.8188, -4.5108]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -5.1701,  -7.2757,  -5.4258,  ...,  -4.5393,  -2.9329,  -0.2587],\n",
            "        [ -6.1591,  -1.9725,  -4.9547,  ...,  -1.4515,  -0.1899,  -2.4715],\n",
            "        [  1.1680,   0.1584,  -1.6279,  ...,  -1.7079,  -0.3483,   0.1216],\n",
            "        ...,\n",
            "        [ -7.0009, -12.2399,  -3.5918,  ...,  -5.4019,   1.2204,   0.4539],\n",
            "        [  0.2104,   2.9652,  -1.3702,  ...,   0.2664,  -0.7837,   0.7886],\n",
            "        [ -0.7475,   0.2797,  -3.8388,  ...,  -3.9063,  -0.2535,  -1.2983]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  1.4239,  -2.7082,  -4.5311,  ...,  -6.0419,   7.7780,   1.1384],\n",
            "        [ -0.7208,   1.9804,  -5.0557,  ...,  -2.5689,  -0.4028,  -1.7170],\n",
            "        [ -2.3674, -11.2040,  -4.9068,  ...,  -2.7795,   0.7132,  -4.2699],\n",
            "        ...,\n",
            "        [  3.5382,   1.5669,  -1.4935,  ...,  -3.1538,   4.7031,   0.2832],\n",
            "        [ -1.9653,  -7.2751,  -4.7253,  ...,  -4.0064,   0.6314,   1.1240],\n",
            "        [ -3.9388,  -3.0880,   0.3798,  ...,  -1.0807,  -1.4110,   0.8636]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -4.7444,  -6.3425,  -5.8414,  ...,  -6.8656,   2.0161,  -1.6384],\n",
            "        [ -6.7207, -15.1307,  -6.6111,  ...,  -2.5934,  -4.5008,  -0.1995],\n",
            "        [ -2.0724,   2.7613,  -2.6639,  ...,  -0.9200,   0.2445,  -1.7390],\n",
            "        ...,\n",
            "        [ -3.7152,  -1.8681,  -2.8851,  ...,  -3.9912,  -3.5713,  -0.5582],\n",
            "        [ -3.5387,  -1.9410,  -1.8074,  ...,   0.0937,  -2.8524,   1.9927],\n",
            "        [ -0.6336,  -5.9145,  -4.7004,  ...,  -1.7955,   2.3914,  -2.4741]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -0.9137,   4.9436,  -3.6771,  ...,  -3.7359,   3.2415,  -1.9215],\n",
            "        [ -5.2498,  -6.0942,  -3.9915,  ...,  -4.6096,   2.3344,   4.2057],\n",
            "        [ -3.6904,  -3.7051,  -2.2130,  ...,  -1.6416,   1.8868,  -5.9638],\n",
            "        ...,\n",
            "        [ -3.9062, -11.2504,  -5.3226,  ...,  -5.7116,   3.1550,   6.1658],\n",
            "        [  2.2637,   0.1066,  -2.8840,  ...,  -2.5204,   4.5471,   1.2212],\n",
            "        [ -0.3499,   3.4762,  -2.4737,  ...,  -1.7041,   1.1578,  -0.8721]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8431, -2.8973, -0.3086,  ..., -1.0352, -3.6646,  1.8591],\n",
            "        [-3.4064,  0.2208, -1.1037,  ..., -4.0043, -2.4915,  1.5596],\n",
            "        [-2.3721,  0.7436, -3.9507,  ..., -1.3664,  1.0352, -3.5503],\n",
            "        ...,\n",
            "        [-3.2418, -2.9853, -2.7316,  ...,  1.7871,  0.5728, -3.2863],\n",
            "        [-1.8244,  0.9092, -2.5201,  ..., -0.8140,  3.2514, -0.0662],\n",
            "        [ 2.5356,  5.4151, -2.6712,  ..., -5.5324, -0.2536,  3.2119]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.1664, -7.1297, -3.8410,  ..., -2.8814,  0.9903, -1.1746],\n",
            "        [-1.6266,  4.5342, -2.6480,  ..., -1.0491, -1.4068, -1.3060],\n",
            "        [-3.9438, -6.6052, -2.3689,  ..., -3.7369, -1.9843,  0.3310],\n",
            "        ...,\n",
            "        [-4.6483, -6.0485, -3.8317,  ..., -1.7416,  6.9751,  1.7016],\n",
            "        [ 0.8083, -0.0956, -4.4580,  ..., -0.6221,  4.2217,  3.1176],\n",
            "        [ 2.6102,  5.0054, -2.4482,  ..., -3.5195, -0.7230,  2.6288]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5488,  1.2677, -1.8257,  ..., -3.3458, -3.3301, -0.8111],\n",
            "        [-3.9797, -8.6805, -5.2722,  ..., -4.6085,  0.8039, -3.2333],\n",
            "        [ 0.2476,  2.4391, -2.2364,  ..., -2.1493, -0.3734, -1.7094],\n",
            "        ...,\n",
            "        [-1.5409, -5.5315, -5.7492,  ..., -5.3224,  1.5320,  3.7025],\n",
            "        [ 0.9860,  0.9238, -2.6333,  ..., -3.8782, -1.1394, -0.4083],\n",
            "        [ 2.1089, -0.6344, -4.6059,  ..., -5.2678,  6.0125, -2.5799]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.7358, -5.7994, -2.3108,  ..., -1.7088, -1.3548, -2.7190],\n",
            "        [-0.6699,  2.4048, -1.4345,  ...,  1.8157,  0.7084,  1.0905],\n",
            "        [-0.9152, -8.1768, -2.6777,  ...,  0.4841, -1.1321, -0.5274],\n",
            "        ...,\n",
            "        [ 2.6523, -0.8619, -2.5581,  ..., -6.0810,  6.6299,  0.4038],\n",
            "        [-1.3931, -3.1435, -1.0010,  ..., -1.3022,  1.9042, -0.7539],\n",
            "        [-0.9632,  4.1584, -2.0280,  ..., -1.5982,  1.1498,  0.4763]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5532, -4.8510, -1.8074,  ..., -4.4457,  2.3306, -1.5122],\n",
            "        [-3.2630, -1.3979, -2.0026,  ..., -1.4778, -0.3464,  2.8510],\n",
            "        [-0.0932, -4.1338, -1.4336,  ..., -1.4773, -0.4773,  0.8414],\n",
            "        ...,\n",
            "        [ 1.7491, -0.4975, -1.8664,  ..., -3.2767, -1.4987,  2.6200],\n",
            "        [ 0.3730,  4.4730, -0.4495,  ..., -2.1388, -6.2808,  0.5976],\n",
            "        [-2.1681,  0.8349, -3.0467,  ..., -1.6853, -0.1333, -2.1499]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4802, -3.6337, -3.0367,  ..., -5.8441,  2.8510, -1.9444],\n",
            "        [-0.3031,  0.5341, -1.9501,  ..., -0.7656, -3.8528,  1.6997],\n",
            "        [-2.7090, -2.9045,  0.4000,  ..., -0.2260, -2.1401,  1.6587],\n",
            "        ...,\n",
            "        [ 0.0066,  4.1501, -1.4087,  ..., -1.3025, -0.3828, -2.3058],\n",
            "        [-0.1368,  6.5350, -3.1524,  ..., -3.1408, -2.9743, -0.2898],\n",
            "        [-0.1496, -0.3159, -2.1405,  ..., -2.1854, -2.0057,  2.5576]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7271,  5.5043, -3.5320,  ..., -1.4148,  0.2548, -1.6063],\n",
            "        [-2.5357, -1.3896, -1.3297,  ..., -7.7391,  0.1746,  5.2696],\n",
            "        [ 0.5611,  1.6039, -3.1155,  ..., -2.9525, -1.4927,  2.7538],\n",
            "        ...,\n",
            "        [-4.2872,  1.1882, -2.3367,  ...,  1.1928, -0.0653,  0.1003],\n",
            "        [-0.9707, -5.8423, -3.0813,  ..., -5.9047,  3.2504,  2.6540],\n",
            "        [-6.9043, -3.7040, -2.8278,  ..., -4.3364, -2.9168,  1.1740]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -4.5168,  -5.8897,   1.1994,  ...,  -5.5191,   0.8163,   4.6625],\n",
            "        [ -1.7575,   2.9651,  -3.7972,  ...,   1.8834,  -0.0375,  -0.1108],\n",
            "        [ -7.2035, -11.7906,  -4.7046,  ...,  -4.3307,  -1.2275,  -2.0976],\n",
            "        ...,\n",
            "        [ -4.4500,  -5.8193,  -1.5283,  ...,  -2.6419,   0.9215,   1.3385],\n",
            "        [ -5.0297,  -3.5882,   0.9585,  ...,  -0.6614,   1.3648,  -1.6753],\n",
            "        [ -2.0303,   1.3837,  -2.4928,  ...,  -0.5105,  -5.1087,  -0.5203]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6073, -4.3370, -2.2821,  ..., -1.7327,  2.9754, -0.1833],\n",
            "        [-4.0352, -7.2708,  2.1991,  ..., -2.7443, -2.1325,  2.0853],\n",
            "        [-4.5678, -4.7246, -4.6848,  ..., -3.5355, -2.6476,  1.5704],\n",
            "        ...,\n",
            "        [-2.3313, -4.8568, -4.1017,  ..., -0.5094, -3.7573, -3.8657],\n",
            "        [-2.0512, -8.7275, -5.2401,  ..., -5.7384,  0.9667,  0.7078],\n",
            "        [ 1.8724,  1.9414, -3.3048,  ..., -4.3923, -1.5256,  0.6439]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7464, -3.2308, -1.6956,  ..., -5.9458, -1.7250,  5.6745],\n",
            "        [-1.0974, -2.1123, -3.8441,  ..., -2.9465, -0.9885, -1.3610],\n",
            "        [-4.2518, -6.7381, -0.2957,  ..., -5.2565, -1.1249,  1.2096],\n",
            "        ...,\n",
            "        [ 0.7202,  0.2248, -4.9041,  ..., -1.6615,  0.3912,  0.1199],\n",
            "        [ 3.6522,  0.6767, -2.7450,  ..., -5.9773,  6.6990,  0.0822],\n",
            "        [-1.3217,  3.7764, -2.6789,  ..., -4.0315, -3.2517, -1.5984]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9050, -2.5523, -0.4062,  ..., -2.7691,  0.6992,  4.4870],\n",
            "        [ 0.6488,  1.3103, -1.7955,  ...,  0.7324, -0.8544, -0.6000],\n",
            "        [-1.5254,  5.0555, -2.5882,  ..., -0.4836, -0.2222, -1.8397],\n",
            "        ...,\n",
            "        [-1.1616,  3.9197, -3.6635,  ..., -3.4795, -4.2471, -2.5478],\n",
            "        [ 3.0124,  4.5971, -2.0468,  ..., -3.3525, -1.2385,  2.6408],\n",
            "        [-4.6851, -6.8496, -1.7617,  ..., -0.8638,  3.5645, -0.0196]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3253,  4.3716, -3.1172,  ..., -4.0182, -4.2931,  0.3467],\n",
            "        [-0.7696,  2.2054, -3.3686,  ..., -2.8575, -2.7555, -1.4993],\n",
            "        [ 3.8320,  0.6125, -1.8125,  ..., -4.4493,  4.3877, -4.2996],\n",
            "        ...,\n",
            "        [ 0.2978,  5.8760, -2.8035,  ..., -3.4631, -5.3996, -0.7588],\n",
            "        [-0.3429,  1.0497, -2.1934,  ..., -2.6701, -4.1420, -1.7724],\n",
            "        [ 0.0271,  2.6390, -3.0656,  ..., -2.7198,  2.5156, -1.8446]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1183, -1.1512, -1.5546,  ..., -2.1071,  1.4995, -0.0463],\n",
            "        [-3.7955, -7.4294, -4.1278,  ..., -1.6742, -0.6587, -4.6502],\n",
            "        [ 2.4873,  2.0951, -1.1326,  ..., -2.0082, -0.3308,  2.7966],\n",
            "        ...,\n",
            "        [ 2.0948,  3.9365, -2.7865,  ..., -3.2838, -0.2227, -0.0359],\n",
            "        [-1.6598,  5.6433, -2.7426,  ..., -0.9006, -1.4638, -2.4472],\n",
            "        [ 0.2826,  0.4482, -2.4656,  ..., -1.8754,  1.1717,  1.4357]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  1.8448,   3.3634,  -0.4481,  ...,   0.3978,   0.3269,  -1.0270],\n",
            "        [  3.9405,   6.0726,  -1.9467,  ...,  -2.3918,  -0.8296,   1.9533],\n",
            "        [  2.9305,  -4.3850,  -3.0430,  ...,  -2.5288,   2.7412,  -3.3709],\n",
            "        ...,\n",
            "        [ -4.0164, -10.6178,  -5.0018,  ...,  -3.1975,  -2.2141,   1.0064],\n",
            "        [  0.1334,   0.9446,  -3.6356,  ...,   1.3935,  -0.0353,  -5.4971],\n",
            "        [ -0.0785,   3.2259,  -2.9256,  ...,  -1.2450,   1.3915,  -2.0737]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9620,  1.9299, -0.2605,  ..., -1.2142, -2.3675,  2.0014],\n",
            "        [ 3.6027, -3.9092, -4.5004,  ..., -7.4691,  6.6512, -0.8235],\n",
            "        [-2.7697, -4.3451, -0.7762,  ..., -4.2985, -0.5508,  2.0880],\n",
            "        ...,\n",
            "        [ 1.0732,  0.9692, -4.6696,  ..., -4.0941,  3.3461, -1.1807],\n",
            "        [ 0.6523,  3.2190, -1.3468,  ...,  0.2871, -1.5672,  1.6444],\n",
            "        [ 4.1283,  1.9552, -2.0387,  ..., -4.7191,  4.1394, -2.5029]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3664, -3.8137, -3.0059,  ..., -4.4701, -1.2801,  0.1167],\n",
            "        [ 1.3600, -2.8641, -5.5481,  ..., -2.7092,  4.3393,  2.3816],\n",
            "        [-0.8218, -2.7352, -1.8527,  ..., -1.8535,  0.7407,  0.3755],\n",
            "        ...,\n",
            "        [-0.6669, -2.1830, -3.0243,  ..., -0.7963, -1.1898, -4.4675],\n",
            "        [-4.4159, -1.2032, -2.2813,  ..., -0.5366, -1.1390,  1.3676],\n",
            "        [-2.1325,  3.0849, -3.1141,  ..., -2.2019, -4.0473, -2.7183]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6928,  1.9852, -2.8757,  ..., -0.4992, -0.8790, -4.1208],\n",
            "        [ 0.9048, -5.8701, -2.3082,  ...,  0.1647,  2.3141, -2.5030],\n",
            "        [-3.6468,  0.0900, -2.7983,  ..., -1.0958,  1.0854,  0.2625],\n",
            "        ...,\n",
            "        [ 1.2195,  3.5199, -2.6132,  ..., -1.1675, -2.4662,  0.7482],\n",
            "        [-3.2990, -1.8452, -2.4884,  ..., -0.5709,  3.0993, -1.3749],\n",
            "        [-3.3726,  0.6317, -3.8341,  ..., -3.2919, -2.2085, -0.5079]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8969,  0.3617, -2.6258,  ..., -4.2614,  4.9862,  1.5084],\n",
            "        [-2.1513, -1.7371, -4.5387,  ..., -0.9635, -0.6808, -1.5744],\n",
            "        [-0.1376, -4.7271, -2.3709,  ...,  2.4391,  3.3412, -2.0473],\n",
            "        ...,\n",
            "        [ 0.0997,  3.9540, -2.6801,  ..., -2.0660, -0.2066, -1.2570],\n",
            "        [-3.2115, -1.7498, -0.8254,  ..., -0.5595, -0.7814,  2.7840],\n",
            "        [ 0.9905,  1.1574, -2.1286,  ...,  0.1147, -3.8657, -2.9557]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8306,  3.9860, -3.1492,  ..., -2.0842,  2.3355, -0.2456],\n",
            "        [ 0.2477,  4.8141, -1.8141,  ..., -1.7969, -2.1242,  0.0836],\n",
            "        [ 2.6520,  4.4745, -3.3260,  ..., -2.6438,  1.6136,  1.4766],\n",
            "        ...,\n",
            "        [ 1.1180, -0.7859, -2.5004,  ..., -2.9986,  3.0506, -3.0805],\n",
            "        [-4.1813, -8.2881, -6.3144,  ..., -4.4599, -1.2607,  1.6676],\n",
            "        [ 3.1775, -0.6808, -3.2057,  ...,  0.4265,  3.5892,  2.9425]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2827,  4.9076, -4.0088,  ..., -3.2504, -2.5732,  1.3076],\n",
            "        [-0.0517,  3.3913, -2.6298,  ..., -0.9389,  4.0483,  0.6443],\n",
            "        [ 1.5610,  2.5254, -3.5605,  ..., -3.1826,  0.9059,  3.9012],\n",
            "        ...,\n",
            "        [-0.4396,  2.5266, -0.7636,  ...,  2.5686, -0.8672, -4.9058],\n",
            "        [ 0.5050, -2.4983, -4.9289,  ..., -2.2036,  6.7913,  1.2413],\n",
            "        [-0.8363,  3.1204, -3.5566,  ..., -1.5749, -0.8746, -2.7555]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8610, -6.7461, -3.8962,  ..., -1.3308,  2.0384, -4.1067],\n",
            "        [ 2.4983,  0.6322, -2.9315,  ..., -5.1790,  4.4039, -0.1849],\n",
            "        [-4.9628, -0.4393, -2.6831,  ..., -4.3458, -4.6189, -1.3319],\n",
            "        ...,\n",
            "        [-2.1073,  5.4696, -3.9745,  ...,  0.7038, -0.6757, -4.2184],\n",
            "        [-2.7334, -4.8193, -3.7782,  ..., -1.4889,  1.5664, -4.4531],\n",
            "        [-1.5078, -1.2782, -3.7909,  ..., -4.8061,  0.8781,  2.2393]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8867, -5.7167, -2.3553,  ...,  3.1374, -0.2005, -3.3574],\n",
            "        [-1.3306, -6.8834, -3.0598,  ..., -4.1610,  2.6080, -1.6615],\n",
            "        [ 2.5584,  5.1004, -0.4587,  ..., -0.8564, -1.2157,  2.1295],\n",
            "        ...,\n",
            "        [-0.0341, -2.5373, -1.6135,  ..., -3.8334,  0.8652,  2.7515],\n",
            "        [-4.2007, -9.2008, -1.1227,  ..., -1.0366, -0.6750, -3.1349],\n",
            "        [-5.7141, -3.1539, -0.2844,  ..., -0.9682, -2.5590, -0.5618]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4628,  7.0421, -2.9354,  ..., -2.7465,  2.2876, -1.4307],\n",
            "        [ 0.8702, -1.2266, -1.8960,  ..., -2.2891,  0.4037, -2.1389],\n",
            "        [-1.4596, -1.1403, -2.5020,  ..., -5.8217,  0.0555,  2.6370],\n",
            "        ...,\n",
            "        [ 4.1105, -5.3659, -2.1039,  ..., -3.7184,  0.7188, -5.9204],\n",
            "        [ 2.2129,  1.4400, -4.5375,  ..., -2.0681, -1.1894, -0.5776],\n",
            "        [-2.8087,  1.8032, -4.2070,  ..., -1.5557,  0.0525,  1.0135]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2479, -2.4461, -4.6337,  ..., -6.2625,  4.2353, -2.6529],\n",
            "        [-2.6272, -0.2552, -2.5959,  ..., -1.0480,  5.6428, -0.2644],\n",
            "        [-1.2292,  4.0996, -0.8254,  ..., -4.7778, -3.1319,  0.1416],\n",
            "        ...,\n",
            "        [-4.1945, -6.3485, -3.3888,  ..., -4.3892,  4.6722,  3.6438],\n",
            "        [ 1.0873,  4.3806, -3.3780,  ..., -3.6353, -3.3757,  0.0869],\n",
            "        [-4.9234, -7.3928, -2.1262,  ..., -2.9996, -1.4731, -2.3730]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.9448, -1.5540, -4.1846,  ...,  0.1313,  2.6319, -0.7163],\n",
            "        [-1.0410, -1.6837,  0.7190,  ..., -2.8053, -0.9191, -2.1826],\n",
            "        [-4.5806, -5.7300,  1.5581,  ..., -1.5925, -0.6067,  1.4715],\n",
            "        ...,\n",
            "        [ 2.3905, -4.1719, -3.7120,  ..., -2.6935,  6.2829,  1.4638],\n",
            "        [-0.1435, -7.3116, -5.0194,  ..., -4.1895, -3.9843,  2.0690],\n",
            "        [ 1.8000,  3.2137, -2.8210,  ..., -1.6164, -1.5416, -0.7150]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4022, -1.6468, -3.0333,  ...,  1.0836, -0.2703, -4.0251],\n",
            "        [-0.3095, -3.8934, -1.2090,  ...,  0.6402,  1.7232, -1.1212],\n",
            "        [-4.3819, -4.1377, -2.9937,  ..., -2.0703, -0.9380, -2.6072],\n",
            "        ...,\n",
            "        [ 3.3637,  7.2885, -2.3762,  ..., -3.8384,  0.3742, -0.3894],\n",
            "        [ 0.6290,  4.4677, -2.8269,  ..., -1.8558, -1.0771, -1.3743],\n",
            "        [-4.2041, -3.1084, -4.0880,  ..., -2.1900,  0.6993, -2.5848]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0508,  3.3534, -1.7611,  ..., -0.8405, -6.0444, -0.6687],\n",
            "        [ 0.5872,  3.2694, -2.0544,  ..., -1.3379, -4.0669, -2.8751],\n",
            "        [-1.6383,  6.0304, -0.9513,  ...,  3.5307, -2.3146, -4.0266],\n",
            "        ...,\n",
            "        [-3.6684,  2.2166, -1.0877,  ...,  5.5028, -0.0455, -4.8475],\n",
            "        [ 0.2078,  5.5151, -4.1244,  ..., -5.1091, -2.6695, -0.9899],\n",
            "        [-0.1239,  2.3481, -0.7663,  ..., -2.3229, -5.5688,  2.5620]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8903, -3.1567, -3.4411,  ..., -3.3669,  2.2929, -0.6800],\n",
            "        [-1.9745,  6.7078, -2.0826,  ..., -2.0391, -4.5225, -2.1730],\n",
            "        [-0.7675,  4.9435, -0.4850,  ..., -0.1521,  0.4675, -4.2438],\n",
            "        ...,\n",
            "        [-0.7548,  0.4922, -1.7203,  ..., -0.9281,  0.0351, -1.0802],\n",
            "        [-1.7854, -1.1707, -2.8181,  ..., -1.1939, -0.2838, -2.1934],\n",
            "        [-0.7118,  6.0628, -1.6679,  ..., -0.8857, -0.6295,  0.2156]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0048,  4.1157, -0.0502,  ..., -0.2353, -0.5012,  0.7800],\n",
            "        [ 4.3271,  4.2099, -2.9560,  ..., -1.9832, -2.0476, -0.5975],\n",
            "        [ 3.0725, -2.9123, -0.7156,  ...,  0.7991,  2.3629, -7.5408],\n",
            "        ...,\n",
            "        [ 3.5677,  5.4511, -1.4552,  ..., -4.0644, -0.7684,  2.8142],\n",
            "        [ 0.1057,  1.3957, -1.7018,  ..., -1.9397, -3.9850, -2.2093],\n",
            "        [ 3.4177,  1.1802, -2.2021,  ..., -4.5951,  3.6336, -0.0967]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  3.6493,   1.1171,  -2.2172,  ...,  -3.7792,   4.2278,   0.1983],\n",
            "        [ -5.6734,  -3.9010,  -4.4799,  ...,  -4.3266,  -5.0172,  -1.6348],\n",
            "        [ -3.7392,   3.1171,  -2.0111,  ...,   1.7167,  -0.3269,  -6.8434],\n",
            "        ...,\n",
            "        [ -1.9976,  -5.7536,  -1.8301,  ...,  -2.4489,  -1.7163,   0.5718],\n",
            "        [ -2.7640, -11.7527,  -5.2125,  ...,  -3.1282,   1.9156,  -4.1782],\n",
            "        [  2.7045,   4.8557,  -1.7977,  ...,  -0.4855,  -1.0145,   2.9125]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2514,  1.9612, -1.3046,  ..., -2.4000, -3.1978, -2.0825],\n",
            "        [ 2.4633, -6.3873, -2.3280,  ..., -1.8422,  0.6732, -2.2075],\n",
            "        [ 0.6882,  2.7123, -0.8235,  ...,  0.7640, -0.8181,  0.9760],\n",
            "        ...,\n",
            "        [-0.6815, -0.6444, -2.7144,  ..., -4.5968, -0.1420,  0.0177],\n",
            "        [ 0.3920,  4.9426, -2.2805,  ..., -0.0165,  2.5645, -2.5324],\n",
            "        [-1.1802,  0.6411, -2.8506,  ..., -1.3930, -0.7129, -2.9766]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8437, -1.5709, -2.2192,  ..., -0.4083, -3.4077, -2.6621],\n",
            "        [-0.7207,  5.1575, -1.1377,  ...,  1.0726,  1.0720, -1.7440],\n",
            "        [ 1.9396, -2.0071, -2.1370,  ..., -0.3589, -4.4577, -2.0787],\n",
            "        ...,\n",
            "        [-1.8934,  5.3694, -1.3850,  ...,  0.1927,  2.1729, -2.4081],\n",
            "        [-4.1472, -8.7577, -2.5619,  ..., -2.2897, -3.4024, -6.3755],\n",
            "        [-1.3472,  1.1556, -1.7789,  ...,  0.1528,  2.3777,  1.8752]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.2483, -1.8153, -1.5699,  ..., -0.6083,  0.0988, -1.8507],\n",
            "        [-1.7175,  2.4562, -0.9755,  ..., -0.7697,  4.0354,  1.3273],\n",
            "        [ 2.0690,  0.4207, -4.4944,  ..., -4.8239,  7.7239, -0.8228],\n",
            "        ...,\n",
            "        [ 2.8535,  5.4502, -1.5579,  ..., -1.9511, -0.1820,  0.1790],\n",
            "        [-1.6439,  1.5236, -2.4035,  ...,  0.0451, -3.9318,  1.4288],\n",
            "        [ 2.4873,  5.7690, -1.2921,  ..., -2.3089, -1.0632, -0.1161]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2490, -3.3061, -4.0185,  ..., -2.3444,  2.0963,  2.8950],\n",
            "        [-0.8566,  5.1217, -1.6031,  ...,  2.2600,  0.0109, -5.2528],\n",
            "        [-3.2160, -3.6686, -1.6881,  ..., -5.6296,  1.0642, -0.4035],\n",
            "        ...,\n",
            "        [-1.9770,  1.1659, -0.9619,  ..., -0.9980,  2.7721,  2.2905],\n",
            "        [-3.1426,  2.5327, -2.5022,  ..., -0.7394, -1.2682, -4.4287],\n",
            "        [-1.1394,  6.1954, -1.6880,  ..., -1.1284, -1.5260, -2.3040]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5372, -2.6521, -1.6663,  ..., -1.9617, -1.5835, -0.5588],\n",
            "        [ 1.1916,  1.0266, -3.4791,  ..., -2.7018,  2.1995,  0.9906],\n",
            "        [ 2.1091, -7.9839, -3.4483,  ..., -2.3232,  2.9420, -4.5525],\n",
            "        ...,\n",
            "        [ 0.6031,  3.8357, -0.5210,  ..., -0.9607, -7.0068,  2.1566],\n",
            "        [-0.1380, -5.9514, -2.0131,  ...,  0.4652,  0.4751, -1.6582],\n",
            "        [-0.8105, -2.8978, -2.9410,  ...,  1.2095, -0.2719, -3.8004]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0827,  6.3530, -0.9242,  ..., -3.6173, -1.9535,  1.5411],\n",
            "        [-1.3947,  0.2917, -0.9606,  ..., -1.3427, -2.2143, -1.2689],\n",
            "        [-2.2728,  5.2299, -2.7550,  ...,  0.7016, -2.1585, -3.3919],\n",
            "        ...,\n",
            "        [-1.5998,  0.1937, -2.2698,  ..., -0.1757, -2.3519, -3.9555],\n",
            "        [-0.9954,  1.4296, -3.3473,  ..., -1.2344,  0.6930, -3.4388],\n",
            "        [-1.6834,  4.2017, -2.3575,  ..., -0.5396, -0.7199, -1.8260]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9748, -3.4223, -1.8376,  ..., -4.4934,  5.3152, -1.2185],\n",
            "        [ 2.0466,  4.4541, -0.8890,  ..., -0.6779, -0.8922,  2.1125],\n",
            "        [ 0.8183,  0.9264, -2.2271,  ..., -5.1155,  5.0722,  0.7881],\n",
            "        ...,\n",
            "        [-0.1304, -3.5243, -2.5063,  ..., -1.2848, -6.2092,  0.7042],\n",
            "        [ 0.0478, -1.8018, -2.7487,  ..., -4.5290,  6.0569, -1.1373],\n",
            "        [ 0.0257,  1.0168, -2.5808,  ...,  0.1358, -4.4589, -0.5541]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0671,  2.1356, -3.9436,  ..., -3.2010, -0.3626,  1.1379],\n",
            "        [-4.9910, -3.7244, -3.4616,  ..., -0.8143,  1.4389, -4.0761],\n",
            "        [-1.1529,  3.1701, -4.8385,  ..., -5.3418,  1.0388, -1.6130],\n",
            "        ...,\n",
            "        [-2.6899,  1.1016, -2.0109,  ..., -0.4685,  3.5509,  1.3014],\n",
            "        [ 0.4023, -0.5261, -2.1951,  ..., -1.7014, -3.4850, -1.4014],\n",
            "        [ 0.1810,  2.2598, -1.1351,  ..., -3.0937, -3.8516,  0.6571]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8762, -3.8328, -1.1330,  ..., -2.1567, -0.8683, -3.3753],\n",
            "        [-0.2402, -3.3425, -4.9722,  ..., -1.5458,  0.6154, -8.6477],\n",
            "        [-0.6857, -6.1329, -3.9725,  ...,  0.2128, -6.4421, -3.7765],\n",
            "        ...,\n",
            "        [-0.6208, -1.9730, -2.6706,  ..., -2.4457, -0.2596, -3.0113],\n",
            "        [-3.7192, -2.8328, -2.5746,  ..., -1.2895, -2.8914, -0.2117],\n",
            "        [-1.7147,  7.9269, -2.9151,  ...,  1.1699,  0.2756, -2.6894]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7497,  0.3334, -3.5233,  ..., -1.7795, -0.9313, -0.8010],\n",
            "        [-1.7937,  0.8793, -1.3180,  ...,  1.0796,  0.8046, -1.2108],\n",
            "        [ 0.2105,  0.2557, -1.9101,  ..., -4.4183, -0.2385,  0.9227],\n",
            "        ...,\n",
            "        [-0.3190,  0.3522, -2.2884,  ...,  0.1674, -1.0124, -2.6023],\n",
            "        [ 1.1721,  2.6425,  0.7043,  ..., -4.2877, -4.0780,  1.0577],\n",
            "        [-1.2129,  7.2417, -2.2796,  ..., -2.4124, -0.7926, -1.5150]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7827,  6.6870, -2.8870,  ..., -2.9966, -0.7461,  0.2790],\n",
            "        [-2.0579, -2.9094, -2.7210,  ...,  0.2079,  1.8888, -0.8632],\n",
            "        [-1.2108, -4.2785, -3.6472,  ..., -3.5507, -4.4886,  2.5394],\n",
            "        ...,\n",
            "        [-3.5024, -9.3366, -5.3589,  ..., -4.9903,  0.1680,  2.8348],\n",
            "        [ 1.2041,  5.6390, -3.0467,  ..., -3.3811, -3.4296, -2.5176],\n",
            "        [-2.1608,  3.8513, -2.8050,  ...,  0.3662,  0.4088, -2.7332]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2626, -2.7925, -4.0176,  ..., -3.5782,  2.0175,  0.6184],\n",
            "        [-2.5016,  3.3858, -2.6269,  ..., -0.1501, -1.2402, -3.2565],\n",
            "        [-1.3682,  4.9538, -1.5151,  ...,  2.5606, -0.1402, -4.5170],\n",
            "        ...,\n",
            "        [ 1.0347,  4.1963, -3.1836,  ...,  0.0373, -1.7901, -4.0368],\n",
            "        [-4.5453, -5.6340, -3.2204,  ..., -0.6644,  4.0519, -1.6788],\n",
            "        [-0.6972,  1.1789, -0.8023,  ...,  1.1084, -0.8672,  0.6301]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5166,  5.1914, -1.8434,  ..., -1.7977, -1.1415,  2.3578],\n",
            "        [ 1.7440, -0.0985, -2.6197,  ..., -5.0048,  5.8773,  1.3796],\n",
            "        [ 1.1838, -0.9093, -3.0336,  ..., -1.6388,  0.6215, -0.7380],\n",
            "        ...,\n",
            "        [-0.2273, -0.7521,  0.3865,  ..., -3.5415, -1.3396, -0.3139],\n",
            "        [ 0.9551, -0.4003, -2.1103,  ..., -0.8003,  0.6672, -0.8717],\n",
            "        [ 0.8871,  6.3332, -1.8680,  ..., -0.7201, -1.9531,  1.4755]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1711,  3.0131, -2.0606,  ...,  0.2772,  1.5764, -0.7363],\n",
            "        [-2.0374,  8.3088, -3.1504,  ...,  0.6171, -3.1107, -1.4449],\n",
            "        [ 3.7979,  1.8936, -3.2816,  ..., -1.1090,  3.0674,  1.5321],\n",
            "        ...,\n",
            "        [ 0.1704,  1.9322, -2.6755,  ..., -0.7996, -0.1817, -4.9488],\n",
            "        [-3.6201, -9.2122, -3.9963,  ..., -4.1080,  2.9168, -6.5394],\n",
            "        [-2.5225, -6.4264, -2.4218,  ..., -6.8515,  2.6844, -1.4349]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3743, -4.6743, -2.1232,  ..., -5.2706,  1.2661,  1.1638],\n",
            "        [-0.6693,  0.0488, -3.3126,  ...,  0.7752,  5.0917,  0.7198],\n",
            "        [-0.5940,  2.5028, -0.9396,  ..., -0.6248,  1.3890, -0.0988],\n",
            "        ...,\n",
            "        [-4.7609,  0.1215, -0.1324,  ..., -3.4501, -0.0703, -1.7297],\n",
            "        [ 0.7919, -0.2639, -2.4779,  ..., -5.5489,  0.4019, -0.1596],\n",
            "        [-0.4802,  5.2648, -1.1299,  ...,  0.0487,  1.3421, -1.5656]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2210,  2.6641, -0.5345,  ..., -0.4189, -2.2004, -1.3984],\n",
            "        [-2.2651, -0.0288, -0.8284,  ..., -5.6847,  0.3503,  3.4345],\n",
            "        [-1.1419,  5.1658, -2.1608,  ...,  1.3012, -1.8946, -3.6368],\n",
            "        ...,\n",
            "        [-5.1011, -8.4624, -4.1871,  ..., -3.9595,  0.2941,  3.4323],\n",
            "        [-0.8741, -2.6158, -4.0330,  ..., -1.1907, -4.4418, -4.2674],\n",
            "        [-0.6324,  3.1172, -2.1689,  ...,  0.7455,  0.4852, -4.4547]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        }
      ],
      "source": [
        "def train(args: SimpleMLPTrainingArgs) -> tuple[list[float], list[float], SimpleMLP]:\n",
        "    \"\"\"\n",
        "    Trains the model, using training parameters from the `args` object. Returns the model, and lists of loss & accuracy.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE - add a validation loop to the train function from above\n",
        "\n",
        "    epochs = args.epochs\n",
        "    learning_rate = args.learning_rate\n",
        "    batch_size = args.batch_size\n",
        "\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    train_loader = DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(mnist_testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      pbar = tqdm(train_loader)\n",
        "      for img, labels in train_loader:\n",
        "\n",
        "        img, labels = img.to(device), labels.to(device)\n",
        "\n",
        "        # 1. take batch and do forward pass\n",
        "        logits = model(img)\n",
        "        # 2. reset gradients\n",
        "        optimizer.zero_grad()\n",
        "        # 3. calculate loss on logits\n",
        "        loss = loss_function(logits, labels)\n",
        "        # 4. do backward pass\n",
        "        loss.backward()\n",
        "        # 5. use gradients to update parameters\n",
        "        optimizer.step()\n",
        "        # 6. continue\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "      # validate after each epoch:\n",
        "      with t.inference_mode(False):\n",
        "\n",
        "        # forward pass with val set\n",
        "        num_correct_classifications = 0\n",
        "        for img, labels in val_loader:\n",
        "          img, labels = img.to(device), labels.to(device)\n",
        "\n",
        "          logits = model(img)\n",
        "\n",
        "          # get pred classes\n",
        "          y_hat = t.argmax(logits, dim=1)\n",
        "          num_correct_classifications += (y_hat == labels).sum().item()\n",
        "\n",
        "      # Compute & log total accuracy\n",
        "      accuracy = num_correct_classifications / len(val_loader)\n",
        "      accuracy_list.append(accuracy)\n",
        "\n",
        "    return loss_list, accuracy_list, model\n",
        "\n",
        "\n",
        "args = SimpleMLPTrainingArgs()\n",
        "loss_list, accuracy_list, model = train(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_list)"
      ],
      "metadata": {
        "id": "_F0x_9h_G996",
        "outputId": "944b0bc0-a4f2-4874-be7f-e435c3adce92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[56.0625, 56.5625, 58.1875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o8M8odHlG7V0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "XkofcnZKjBUO",
        "outputId": "ca147ade-4041-4bc7-cc36-fbe54a9fed6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"dc0d5e8e-3389-4250-97b6-e6838f25bab3\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dc0d5e8e-3389-4250-97b6-e6838f25bab3\")) {                    Plotly.newPlot(                        \"dc0d5e8e-3389-4250-97b6-e6838f25bab3\",                        [{\"name\":\"Cross entropy loss\",\"x\":[0.0,63.829787234042556,127.65957446808511,191.48936170212767,255.31914893617022,319.1489361702128,382.97872340425533,446.8085106382979,510.63829787234044,574.468085106383,638.2978723404256,702.1276595744681,765.9574468085107,829.7872340425532,893.6170212765958,957.4468085106383,1021.2765957446809,1085.1063829787236,1148.936170212766,1212.7659574468084,1276.595744680851,1340.4255319148938,1404.2553191489362,1468.0851063829787,1531.9148936170213,1595.744680851064,1659.5744680851064,1723.404255319149,1787.2340425531916,1851.0638297872342,1914.8936170212767,1978.723404255319,2042.5531914893618,2106.3829787234044,2170.212765957447,2234.0425531914893,2297.872340425532,2361.7021276595747,2425.531914893617,2489.3617021276596,2553.191489361702,2617.021276595745,2680.8510638297876,2744.68085106383,2808.5106382978724,2872.340425531915,2936.1702127659573,3000.0,3063.8297872340427,3127.6595744680853,3191.489361702128,3255.31914893617,3319.148936170213,3382.9787234042556,3446.808510638298,3510.6382978723404,3574.468085106383,3638.297872340426,3702.1276595744685,3765.9574468085107,3829.7872340425533,3893.617021276596,3957.446808510638,4021.276595744681,4085.1063829787236,4148.936170212766,4212.765957446809,4276.595744680852,4340.425531914894,4404.255319148936,4468.085106382979,4531.914893617021,4595.744680851064,4659.574468085107,4723.404255319149,4787.234042553192,4851.063829787234,4914.893617021276,4978.723404255319,5042.553191489362,5106.382978723404,5170.212765957447,5234.04255319149,5297.8723404255325,5361.702127659575,5425.531914893617,5489.36170212766,5553.191489361702,5617.021276595745,5680.851063829788,5744.68085106383,5808.510638297873,5872.340425531915,5936.170212765957,6000.0,6063.829787234043,6127.659574468085,6191.489361702128,6255.319148936171,6319.148936170213,6382.978723404256,6446.808510638298,6510.63829787234,6574.468085106383,6638.297872340426,6702.127659574468,6765.957446808511,6829.787234042554,6893.617021276596,6957.446808510638,7021.276595744681,7085.106382978724,7148.936170212766,7212.765957446809,7276.595744680852,7340.425531914894,7404.255319148937,7468.085106382979,7531.914893617021,7595.744680851064,7659.574468085107,7723.404255319149,7787.234042553192,7851.063829787235,7914.893617021276,7978.723404255319,8042.553191489362,8106.382978723404,8170.212765957447,8234.04255319149,8297.872340425532,8361.702127659575,8425.531914893618,8489.36170212766,8553.191489361703,8617.021276595746,8680.851063829788,8744.68085106383,8808.510638297872,8872.340425531915,8936.170212765957,9000.0,9063.829787234043,9127.659574468085,9191.489361702128,9255.31914893617,9319.148936170213,9382.978723404256,9446.808510638299,9510.638297872341,9574.468085106384,9638.297872340427,9702.127659574468,9765.95744680851,9829.787234042553,9893.617021276596,9957.446808510638,10021.27659574468,10085.106382978724,10148.936170212766,10212.765957446809,10276.595744680852,10340.425531914894,10404.255319148937,10468.08510638298,10531.914893617022,10595.744680851065,10659.574468085108,10723.40425531915,10787.234042553191,10851.063829787234,10914.893617021276,10978.72340425532,11042.553191489362,11106.382978723404,11170.212765957447,11234.04255319149,11297.872340425532,11361.702127659575,11425.531914893618,11489.36170212766,11553.191489361703,11617.021276595746,11680.851063829788,11744.68085106383,11808.510638297872,11872.340425531915,11936.170212765957,12000.0,12063.829787234043,12127.659574468085,12191.489361702128,12255.31914893617,12319.148936170213,12382.978723404256,12446.808510638299,12510.638297872341,12574.468085106384,12638.297872340427,12702.12765957447,12765.957446808512,12829.787234042553,12893.617021276596,12957.446808510638,13021.27659574468,13085.106382978724,13148.936170212766,13212.765957446809,13276.595744680852,13340.425531914894,13404.255319148937,13468.08510638298,13531.914893617022,13595.744680851065,13659.574468085108,13723.40425531915,13787.234042553191,13851.063829787234,13914.893617021276,13978.72340425532,14042.553191489362,14106.382978723404,14170.212765957447,14234.04255319149,14297.872340425532,14361.702127659575,14425.531914893618,14489.36170212766,14553.191489361703,14617.021276595746,14680.851063829788,14744.680851063831,14808.510638297874,14872.340425531915,14936.170212765957,15000.0,15063.829787234043,15127.659574468085,15191.489361702128,15255.31914893617,15319.148936170213,15382.978723404256,15446.808510638299,15510.638297872341,15574.468085106384,15638.297872340427,15702.12765957447,15765.957446808512,15829.787234042553,15893.617021276596,15957.446808510638,16021.27659574468,16085.106382978724,16148.936170212766,16212.765957446809,16276.595744680852,16340.425531914894,16404.255319148935,16468.08510638298,16531.91489361702,16595.744680851065,16659.574468085106,16723.40425531915,16787.23404255319,16851.063829787236,16914.893617021276,16978.72340425532,17042.55319148936,17106.382978723406,17170.212765957447,17234.04255319149,17297.872340425532,17361.702127659577,17425.531914893618,17489.36170212766,17553.191489361703,17617.021276595744,17680.85106382979,17744.68085106383,17808.510638297874,17872.340425531915,17936.17021276596,18000.0,18063.829787234044,18127.659574468085,18191.48936170213,18255.31914893617,18319.148936170215,18382.978723404256,18446.808510638297,18510.63829787234,18574.468085106382,18638.297872340427,18702.127659574468,18765.957446808512,18829.787234042553,18893.617021276597,18957.44680851064,19021.276595744683,19085.106382978724,19148.936170212768,19212.76595744681,19276.595744680853,19340.425531914894,19404.255319148935,19468.08510638298,19531.91489361702,19595.744680851065,19659.574468085106,19723.40425531915,19787.23404255319,19851.063829787236,19914.893617021276,19978.72340425532,20042.55319148936,20106.382978723406,20170.212765957447,20234.04255319149,20297.872340425532,20361.702127659577,20425.531914893618,20489.36170212766,20553.191489361703,20617.021276595744,20680.85106382979,20744.68085106383,20808.510638297874,20872.340425531915,20936.17021276596,21000.0,21063.829787234044,21127.659574468085,21191.48936170213,21255.31914893617,21319.148936170215,21382.978723404256,21446.8085106383,21510.63829787234,21574.468085106382,21638.297872340427,21702.127659574468,21765.957446808512,21829.787234042553,21893.617021276597,21957.44680851064,22021.276595744683,22085.106382978724,22148.936170212768,22212.76595744681,22276.595744680853,22340.425531914894,22404.25531914894,22468.08510638298,22531.91489361702,22595.744680851065,22659.574468085106,22723.40425531915,22787.23404255319,22851.063829787236,22914.893617021276,22978.72340425532,23042.55319148936,23106.382978723406,23170.212765957447,23234.04255319149,23297.872340425532,23361.702127659577,23425.531914893618,23489.36170212766,23553.191489361703,23617.021276595744,23680.85106382979,23744.68085106383,23808.510638297874,23872.340425531915,23936.17021276596,24000.0,24063.829787234044,24127.659574468085,24191.48936170213,24255.31914893617,24319.148936170215,24382.978723404256,24446.8085106383,24510.63829787234,24574.468085106382,24638.297872340427,24702.127659574468,24765.957446808512,24829.787234042553,24893.617021276597,24957.44680851064,25021.276595744683,25085.106382978724,25148.936170212768,25212.76595744681,25276.595744680853,25340.425531914894,25404.25531914894,25468.08510638298,25531.914893617024,25595.744680851065,25659.574468085106,25723.40425531915,25787.23404255319,25851.063829787236,25914.893617021276,25978.72340425532,26042.55319148936,26106.382978723406,26170.212765957447,26234.04255319149,26297.872340425532,26361.702127659577,26425.531914893618,26489.361702127662,26553.191489361703,26617.021276595744,26680.85106382979,26744.68085106383,26808.510638297874,26872.340425531915,26936.17021276596,27000.0,27063.829787234044,27127.659574468085,27191.48936170213,27255.31914893617,27319.148936170215,27382.978723404256,27446.8085106383,27510.63829787234,27574.468085106382,27638.297872340427,27702.127659574468,27765.957446808512,27829.787234042553,27893.617021276597,27957.44680851064,28021.276595744683,28085.106382978724,28148.936170212768,28212.76595744681,28276.595744680853,28340.425531914894,28404.25531914894,28468.08510638298,28531.914893617024,28595.744680851065,28659.574468085106,28723.40425531915,28787.23404255319,28851.063829787236,28914.893617021276,28978.72340425532,29042.55319148936,29106.382978723406,29170.212765957447,29234.04255319149,29297.872340425532,29361.702127659577,29425.531914893618,29489.361702127662,29553.191489361703,29617.021276595748,29680.85106382979,29744.68085106383,29808.510638297874,29872.340425531915,29936.17021276596,30000.0],\"y\":[3.2761991024017334,2.74580717086792,2.3826913833618164,2.164217948913574,2.056950092315674,1.7581002712249756,1.4795265197753906,1.5176048278808594,1.4517900943756104,1.1942685842514038,1.1489615440368652,1.2407926321029663,0.9228843450546265,0.9364842176437378,0.9341655969619751,0.9422258734703064,0.951919436454773,0.7446905970573425,0.6239715814590454,0.6836256980895996,0.5004024505615234,0.6377913355827332,0.5772121548652649,0.8442380428314209,0.6344590187072754,0.6275299787521362,0.6040201783180237,0.4247511923313141,0.591239869594574,0.6538497805595398,0.6001829504966736,0.8305151462554932,0.5705501437187195,0.515105128288269,0.5382182002067566,0.4202159643173218,0.495534211397171,0.382382869720459,0.549067497253418,0.6454229354858398,0.45682182908058167,0.42134618759155273,0.6304223537445068,0.64324951171875,0.336402952671051,0.24886994063854218,0.4035308063030243,0.4011647403240204,0.3455759882926941,0.4970341920852661,0.5541114807128906,0.4879719614982605,0.47847288846969604,0.2886303663253784,0.40365999937057495,0.23100882768630981,0.4711357355117798,0.4050460457801819,0.5634922385215759,0.365886390209198,0.2951231896877289,0.47162875533103943,0.288173645734787,0.30522388219833374,0.379042387008667,0.3076484799385071,0.2840269207954407,0.31168514490127563,0.47960153222084045,0.2546870708465576,0.6431422829627991,0.3471969962120056,0.4176877439022064,0.2785676121711731,0.44263747334480286,0.39536064863204956,0.3421754837036133,0.2815081477165222,0.4462214708328247,0.31486907601356506,0.4613601863384247,0.31626901030540466,0.32014337182044983,0.45780056715011597,0.30748915672302246,0.2614027261734009,0.2598998546600342,0.46775487065315247,0.3479379415512085,0.2977011501789093,0.25899794697761536,0.40709176659584045,0.4674856662750244,0.3022403120994568,0.32145825028419495,0.6197057366371155,0.3371738791465759,0.2989332377910614,0.26443159580230713,0.44627898931503296,0.34839147329330444,0.2724035084247589,0.4080634117126465,0.25824296474456787,0.27291426062583923,0.21983161568641663,0.31396108865737915,0.3191899061203003,0.21873855590820312,0.3745485544204712,0.42044737935066223,0.25143760442733765,0.41195160150527954,0.33843398094177246,0.33097702264785767,0.40191367268562317,0.4524121582508087,0.28824129700660706,0.46761655807495117,0.39015063643455505,0.33845677971839905,0.29148155450820923,0.43528011441230774,0.35604700446128845,0.33236896991729736,0.34915801882743835,0.5754648447036743,0.3631635904312134,0.5372647643089294,0.19363375008106232,0.2735048532485962,0.17684777081012726,0.451529324054718,0.2871650755405426,0.362283855676651,0.1744154989719391,0.498924195766449,0.19842591881752014,0.38270142674446106,0.22292731702327728,0.3810015320777893,0.2099507451057434,0.20852407813072205,0.2962189316749573,0.37621769309043884,0.395743191242218,0.17397856712341309,0.4792548716068268,0.1690305769443512,0.24950960278511047,0.15484103560447693,0.2463875114917755,0.22161369025707245,0.5263044834136963,0.3160419166088104,0.31480756402015686,0.3561583161354065,0.32944053411483765,0.28855958580970764,0.3145819306373596,0.328786164522171,0.26430511474609375,0.22348837554454803,0.18576645851135254,0.1183815449476242,0.14249390363693237,0.2547883093357086,0.34115099906921387,0.18525025248527527,0.16931912302970886,0.14578090608119965,0.2905990183353424,0.325808584690094,0.2983703911304474,0.23592281341552734,0.15638461709022522,0.18269716203212738,0.3211560845375061,0.2333909273147583,0.2526341676712036,0.07745280116796494,0.1485123634338379,0.0902094691991806,0.17954787611961365,0.17209434509277344,0.16185371577739716,0.12951387465000153,0.1205964982509613,0.3004124164581299,0.33085551857948303,0.20321698486804962,0.20986662805080414,0.261037677526474,0.219765305519104,0.19139690697193146,0.22725415229797363,0.08282506465911865,0.23426687717437744,0.10834408551454544,0.23986050486564636,0.2521408498287201,0.24838638305664062,0.09974803030490875,0.17299598455429077,0.20655430853366852,0.11077956855297089,0.4455319046974182,0.27942150831222534,0.2166655957698822,0.2551104426383972,0.13785012066364288,0.23756852746009827,0.13673202693462372,0.20275135338306427,0.28329768776893616,0.17238445580005646,0.4226832985877991,0.1467653512954712,0.23271484673023224,0.26080283522605896,0.18804161250591278,0.3026410937309265,0.17112450301647186,0.47070324420928955,0.16085615754127502,0.22122327983379364,0.26931726932525635,0.13950562477111816,0.3481011688709259,0.43258991837501526,0.23683372139930725,0.1545717418193817,0.18802021443843842,0.21302737295627594,0.2302502989768982,0.09965813159942627,0.3138726055622101,0.2694077789783478,0.31176120042800903,0.13914324343204498,0.25226154923439026,0.3577142655849457,0.16432635486125946,0.21668954193592072,0.14804700016975403,0.2911190986633301,0.35661423206329346,0.39396682381629944,0.2145177125930786,0.11233778297901154,0.3313106596469879,0.10318102687597275,0.08778552711009979,0.14206524193286896,0.22188371419906616,0.3073153793811798,0.09686322510242462,0.3322792649269104,0.2511744797229767,0.33332690596580505,0.3491710126399994,0.24477656185626984,0.3072892725467682,0.09029801934957504,0.1549251675605774,0.316555917263031,0.1260979026556015,0.3651752471923828,0.15532825887203217,0.16557548940181732,0.23237718641757965,0.1418715864419937,0.09185608476400375,0.22700732946395874,0.09170575439929962,0.28711122274398804,0.123553566634655,0.155409038066864,0.38552573323249817,0.20141524076461792,0.10225261002779007,0.22534149885177612,0.06418683379888535,0.11473741382360458,0.29581162333488464,0.23720259964466095,0.25780120491981506,0.12450909614562988,0.43754154443740845,0.10694421827793121,0.2154722511768341,0.29124289751052856,0.1802254319190979,0.16584478318691254,0.1502348780632019,0.36298370361328125,0.13716661930084229,0.19790394604206085,0.20564806461334229,0.11623840779066086,0.2276117205619812,0.21498093008995056,0.17023171484470367,0.21287626028060913,0.10655927658081055,0.30300799012184143,0.13565053045749664,0.2604406476020813,0.18968436121940613,0.26855596899986267,0.24124866724014282,0.18484844267368317,0.12831871211528778,0.692767322063446,0.12694741785526276,0.0835036039352417,0.2433815598487854,0.09588746726512909,0.07407835870981216,0.1550160050392151,0.2904447317123413,0.25325748324394226,0.15832799673080444,0.08739903569221497,0.15405099093914032,0.1075994223356247,0.11409453302621841,0.17103545367717743,0.18885920941829681,0.11936749517917633,0.11857669055461884,0.1314379870891571,0.18271902203559875,0.12892605364322662,0.2581315338611603,0.1781158447265625,0.1634255349636078,0.15033715963363647,0.1880078911781311,0.1225832849740982,0.15501253306865692,0.07580380141735077,0.19937054812908173,0.14116019010543823,0.10274849086999893,0.06920941919088364,0.11871933937072754,0.14449970424175262,0.19595801830291748,0.1307525485754013,0.2935597896575928,0.1433902233839035,0.058961257338523865,0.05857877433300018,0.15900486707687378,0.32533127069473267,0.07215201109647751,0.23431019484996796,0.17771339416503906,0.1547059416770935,0.16124624013900757,0.2645860016345978,0.11859360337257385,0.14159192144870758,0.28084009885787964,0.29801058769226074,0.12419035285711288,0.24000443518161774,0.20038621127605438,0.17806300520896912,0.12400929629802704,0.09952899068593979,0.3094177544116974,0.06869318336248398,0.20367825031280518,0.153728187084198,0.13347268104553223,0.10820038616657257,0.06941179931163788,0.10082226246595383,0.08073704689741135,0.21707206964492798,0.22501742839813232,0.12157116085290909,0.22169527411460876,0.16121035814285278,0.1462487429380417,0.2620735764503479,0.19642217457294464,0.12315025180578232,0.11202659457921982,0.1369403451681137,0.1326318383216858,0.13731160759925842,0.12887895107269287,0.2859797179698944,0.17118458449840546,0.2515001893043518,0.19017240405082703,0.13791504502296448,0.07336952537298203,0.12917982041835785,0.2853197157382965,0.18072129786014557,0.08022499084472656,0.2948578894138336,0.09642826020717621,0.14306481182575226,0.042285412549972534,0.07528577744960785,0.17051489651203156,0.09722629934549332,0.13536210358142853,0.12760040163993835,0.1875835657119751,0.11119476705789566,0.1028541624546051,0.10996916890144348,0.45445382595062256,0.18353046476840973,0.1919078230857849,0.09099971503019333,0.1234283447265625,0.09357322007417679,0.1601366400718689,0.1396191120147705,0.24249237775802612,0.0850953683257103,0.10559625923633575,0.24721059203147888,0.30483272671699524,0.24808020889759064,0.11460621654987335,0.10906921327114105,0.24393698573112488,0.16886350512504578,0.17849257588386536,0.08535318076610565,0.10327453911304474,0.15635932981967926,0.35230621695518494,0.10016989707946777,0.057948242872953415,0.2723385989665985,0.090638667345047,0.19437186419963837,0.07434917241334915,0.14169614017009735,0.14537715911865234,0.234699547290802,0.2601712942123413,0.11525839567184448,0.07715713977813721,0.04107016697525978,0.16136839985847473,0.18695758283138275,0.10103379935026169,0.19843876361846924,0.058322884142398834,0.21229301393032074,0.1928863823413849,0.2747126519680023,0.06411145627498627,0.16256439685821533,0.08633767068386078,0.152852401137352,0.08076637238264084,0.20529882609844208,0.15689243376255035,0.09427076578140259,0.13938269019126892],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Test Accuracy\",\"x\":[0.0,10000.0,20000.0,30000.0],\"y\":[0.1,56.0625,56.5625,58.1875],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Num examples seen\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Cross entropy loss\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Test Accuracy\"}},\"hovermode\":\"x unified\",\"title\":{\"text\":\"SimpleMLP training on MNIST\"},\"width\":800},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dc0d5e8e-3389-4250-97b6-e6838f25bab3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "line(\n",
        "    y=[loss_list, [0.1] + accuracy_list],  # we start by assuming a uniform accuracy of 10%\n",
        "    use_secondary_yaxis=True,\n",
        "    x_max=args.epochs * len(mnist_trainset),\n",
        "    labels={\"x\": \"Num examples seen\", \"y1\": \"Cross entropy loss\", \"y2\": \"Test Accuracy\"},\n",
        "    title=\"SimpleMLP training on MNIST\",\n",
        "    width=800,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.signal import convolve2d\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Create a larger image (40x40) with structure (hollow rectangle)\n",
        "image_size = 40\n",
        "original_image = np.zeros((image_size, image_size), dtype=np.float32) # Black background\n",
        "\n",
        "# Define rectangle boundaries (adjust thickness by changing the range)\n",
        "top_row, bottom_row = 5, image_size - 6\n",
        "left_col, right_col = 5, image_size - 6\n",
        "thickness = 2 # Make lines thicker\n",
        "\n",
        "# Draw rectangle (set pixels to 1.0 for white)\n",
        "original_image[top_row:bottom_row+thickness, left_col:left_col+thickness] = 1.0 # Top-left corner area\n",
        "original_image[top_row:bottom_row+thickness, right_col:right_col+thickness] = 1.0 # Top-right corner area\n",
        "original_image[top_row:top_row+thickness, left_col:right_col+thickness] = 1.0 # Top edge area\n",
        "original_image[bottom_row:bottom_row+thickness, left_col:right_col+thickness] = 1.0 # Bottom edge area\n",
        "\n",
        "\n",
        "# 2. Define the 3x3 average pooling kernel (remains the same)\n",
        "kernel = np.ones((2, 2), dtype=np.float32) / 1.0\n",
        "\n",
        "kernel = t.tensor([0.5, 0.0, -0.5]).repeat((3, 1))\n",
        "\n",
        "print(kernel)\n",
        "\n",
        "# 3. Convolve the image with the kernel\n",
        "# 'valid' mode: output size will be (image_size - kernel_size + 1)\n",
        "convolved_image = convolve2d(original_image, kernel, mode='valid')\n",
        "\n",
        "# 4. Plot the original and convolved images\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5)) # Adjusted figure size\n",
        "\n",
        "# Plot Original Image\n",
        "axes[0].imshow(original_image, cmap='gray', vmin=0, vmax=1)\n",
        "axes[0].set_title(f'Original Image ({original_image.shape[0]}x{original_image.shape[1]})')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Plot Convolved Image\n",
        "axes[1].imshow(convolved_image, cmap='gray', vmin=0, vmax=1)\n",
        "axes[1].set_title(f'Convolved (Avg. Pooled) ({convolved_image.shape[0]}x{convolved_image.shape[1]})')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Original Image Shape:\", original_image.shape)\n",
        "print(\"Kernel Shape:\", kernel.shape)\n",
        "print(\"Convolved Image Shape:\", convolved_image.shape)\n",
        "# Optional: Print a small section if needed, full arrays are large\n",
        "# print(\"\\nOriginal Image Tensor (Top-Left Corner):\\n\", original_image[0:8, 0:8])\n",
        "# print(\"\\nConvolved Image Tensor (Top-Left Corner):\\n\", convolved_image[0:6, 0:6])"
      ],
      "metadata": {
        "id": "Y8jMffwWC9K7",
        "outputId": "0f3d12e9-e328-4297-ecac-f0b41fc97654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5000,  0.0000, -0.5000],\n",
            "        [ 0.5000,  0.0000, -0.5000],\n",
            "        [ 0.5000,  0.0000, -0.5000]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Image Shape: (40, 40)\n",
            "Kernel Shape: torch.Size([3, 3])\n",
            "Convolved Image Shape: (38, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6xo0Kn9jBUO"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to measure correct classifications.</summary>\n",
        "\n",
        "You can take argmax of the output of your model, using `torch.argmax` (with the keyword argument `dim` to specify the dimension you want to take max over).\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I get <code>RuntimeError: expected scalar type Float but found Byte</code>.</summary>\n",
        "\n",
        "This is commonly because one of your operations is between tensors with the wrong datatypes (e.g. `int` and `float`). You can try adding assert or logging statements in your code, or alternatively if you're in VSCode then you can try navigating to the error line and checking your dtypes using VSCode's built-in debugger.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def train(args: SimpleMLPTrainingArgs) -> tuple[list[float], list[float], SimpleMLP]:\n",
        "    \"\"\"\n",
        "    Trains the model, using training parameters from the `args` object. Returns the model, and lists of loss & accuracy.\n",
        "    \"\"\"\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    mnist_trainset, mnist_testset = get_mnist()\n",
        "    mnist_trainloader = DataLoader(mnist_trainset, batch_size=args.batch_size, shuffle=True)\n",
        "    mnist_testloader = DataLoader(mnist_testset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "    accuracy = 0.0\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # Training loop\n",
        "        pbar = tqdm(mnist_trainloader)\n",
        "        for imgs, labels in pbar:\n",
        "            # Move data to device, perform forward pass\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            # Calculate loss, perform backward pass\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update logs & progress bar\n",
        "            loss_list.append(loss.item())\n",
        "            pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        num_correct_classifications = 0\n",
        "        for imgs, labels in mnist_testloader:\n",
        "            # Move data to device, perform forward pass in inference mode\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with t.inference_mode():\n",
        "                logits = model(imgs)\n",
        "\n",
        "            # Compute num correct by comparing argmaxed logits to true labels\n",
        "            predictions = t.argmax(logits, dim=1)\n",
        "            num_correct_classifications += (predictions == labels).sum().item()\n",
        "\n",
        "        # Compute & log total accuracy\n",
        "        accuracy = num_correct_classifications / len(mnist_testset)\n",
        "        accuracy_list.append(accuracy)\n",
        "\n",
        "    return loss_list, accuracy_list, model\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fefPyRdrjBUO"
      },
      "source": [
        "You should find that after the first epoch, the model is already doing much better than random chance (i.e. >80%), and it improves slightly in subsequent epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfzzybg8jBUO"
      },
      "source": [
        "# 3️⃣ Convolutions\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn how convolutions work, and why they are useful for vision models\n",
        "> * Implement your own convolutions, and maxpooling layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcNZO8ZjjBUO"
      },
      "source": [
        "_Note, this section is light on exercises, because it actually ends up being surprisingly hard to implement convolutional and linear operations from scratch (unlike the case for linear layers). It requires engaging with **strides**, an under-the-hood attribute of PyTorch tensors which we usually don't think about in regular work. For this reason, this section focuses more on understanding how convolutions work & giving you implementations of it, rather than asking you to implement it from scratch. There are implementation from scratch exercises in the bonus section at the end of today's material, if you get that far!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEE91TP1jBUO"
      },
      "source": [
        "## Reading\n",
        "\n",
        "We strongly recommend you at least watch the video in the first bullet point. The second article is recommended, but not essential. The third is more for interest (and will be more relevant next week, when we study interpretability).\n",
        "\n",
        "* [But what is a convolution?](https://www.youtube.com/watch?v=KuXjwB4LzSA) by 3Blue1Brown\n",
        "* [A Comprehensive Guide to Convolutional Neural Networks (Medium)](https://medium.com/towards-data-science/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)\n",
        "* [Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-MleGB0jBUO"
      },
      "source": [
        "## What are convolutions?\n",
        "\n",
        "A convolution is an operation which takes a kernel and slides it across the input, applying the kernel to each patch of the input. We can view it as a logical extension of the linear layer, except rather than having every output value being determined as a linear combination of every input value, we have a **prior of locality** - assuming that the input has some spatial structure, and each output value should only be determined by a small patch of the input. The kernel contains our learned weights, and we slide that kernel across our input, with each output value being computed by a sumproduct of the kernel values and the corresponding patch in the input. Note that we use all input channels when computing each output value, which means the sumproduct is over `kernel_length * in_channels` elements (or `kernel_width * kernel_height * in_channels` when, as is most often the case, we're using 2D kernels)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5dLKPJujBUO"
      },
      "source": [
        "### Mathematical definition\n",
        "\n",
        "Convolutions have 4 important parameters:\n",
        "\n",
        "- **Size** - the size of the kernel, i.e. the size of each patch of the input that the kernel is applied to when computing each output value.\n",
        "- **Stride** - the distance the kernel moves each time it is applied.\n",
        "- **Padding** - the number of pixels we pad around the input on each side.\n",
        "- **Output channels** - the number of separate kernels of shape `(in_channels, kernel_width, kernel_height)` we apply to the input. Each separate kernel has different learned weights, and will produce a separate output channel.\n",
        "\n",
        "Below is an illustration with `size=(3,3), stride=1, padding=1`, three input channels and a single output channel.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*ciDgQEjViWLnCbmX-EeSrA.gif\" width=\"800\">\n",
        "\n",
        "For width or height, we can compute the output dim size as a function of the input dim and convolution parameters:\n",
        "\n",
        "$$\n",
        "L_{\\text {out }}=\\left\\lfloor\\dfrac{L_{\\text {in }}+2 \\times \\text { padding }- \\text { kernel\\_size }}{\\text { stride }}+1\\right\\rfloor\n",
        "$$\n",
        "\n",
        "Notably, with our parameters `size=(3,3), stride=1, padding=1` this simplifies to $L_{\\text{out}} = \\left\\lfloor\\frac{L_{\\text{in}} + 2 - 3}{1} + 1\\right\\rfloor = L_{\\text{in}}$. We refer to this as a **shape-preserving convolution**, because the input & output dimensions for width/height are the same. This is quite useful because often when building neural networks we have to be careful to match the shapes of different tensors (otherwise skip connections will fail - we can't add together `x + conv(x)` if they're different shapes!).\n",
        "\n",
        "> A quick note on terminology - you might see docs and docstrings use `num_features`, sometimes use `channels` (sometimes abbreviated as $N_{in}$ or $C$ in PyTorch docs). When we're talking about convolutions specifically, these usually mean the same thing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJMslSkVjBUP"
      },
      "source": [
        "### What do convolutions learn?\n",
        "\n",
        "The terminology `num_features` hints at this, but often convolutions can be thought of as learning certain features from our data. For instance, there's evidence to suggest that early convolutional layers pick up on very simple low-level features such as edges, corners and curves, whereas later convolutional layers are able to combine these lower-level features hierarchically to form more complex representations.\n",
        "\n",
        "For more on this, we recommend the Distill post [Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/), which discusses various lines of evidence for interpreting the features learned by convolutional layers (and how they connect up to form circuits). Interestingly, this post philosophically underpins quite a lot of the current interpretability field - even though the focus has primarily shifted from vision models to language models, many of the underlying ideas remain the same.\n",
        "\n",
        "<img src=\"https://distill.pub/2020/circuits/zoom-in/images/curves.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPT61hsvjBUP"
      },
      "source": [
        "### Some questions about convolutions\n",
        "\n",
        "Here are some questions about convolutions to make sure you've understood the material. You should try and answer these questions without referring back to the article or video above.\n",
        "\n",
        "<details>\n",
        "<summary>Why would convolutional layers be less likely to overfit data than standard linear (fully connected) layers?</summary>\n",
        "\n",
        "Convolutional layers require significantly fewer weights to be learned. This is because the same kernel is applied all across the image, rather than every pair of `(input, output)` nodes requiring a different weight to be learned.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Suppose you fixed some random permutation of the pixels in an image, and applied this to all images in your dataset, before training a convolutional neural network for classifying images. Do you expect this to be less effective, or equally effective?</summary>\n",
        "\n",
        "It will be less effective, because CNNs work thanks to **spatial locality** - groups of pixels close together are more meaningful. For instance, CNNs will often learn convolutions at an early layer which recognise gradients or simple shapes. If you permute the pixels (even if you permute in the same way for every image), you destroy locality.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>If you have a 28x28 image, and you apply a 3x3 convolution with stride 2, padding 1, and 5 output channels, what shape will the output be?</summary>\n",
        "\n",
        "Applying the formula above, we get:\n",
        "\n",
        "$\n",
        "L_{\\text {out }}=\\left\\lfloor\\frac{L_{\\text {in }}+2 \\times \\text { padding }- \\text { kernel\\_size }}{\\text { stride }}+1\\right\\rfloor = \\left\\lfloor\\frac{28 + 2 \\times 1 - 3}{2} + 1\\right\\rfloor = 14\n",
        "$\n",
        "\n",
        "So our image has width & height 14. The shape will go from `(3, 28, 28)` to `(5, 14, 14)` (since the output dimensions are `out_channels, width, height`).\n",
        "\n",
        "As a general rule, a 3x3 convolution with padding 1, stride `stride` and input images with shape `(width, height)` will map to an output shape of `(width // stride, height // stride)`. This will be useful when we study GANs tomorrow, and we'll assemble a series of 3x3 convolutions with padding 1 and stride 2, which should each halve our input image size.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r5QjYtjjBUP"
      },
      "source": [
        "### Exercise - implement `Conv2d`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-20 minutes on this exercise.\n",
        "> This only requires you to create the conv weights - making your own fwd pass method is a bonus exercise later.\n",
        "> ```\n",
        "\n",
        "Rather than implementing the `conv2d` function from scratch, we'll allow you to use `t.nn.functional.conv2d`. In the exercise below, you should use this function to implement the `nn.Conv2d` layer. All you need to do is fill in the `__init__` method. Some guidance:\n",
        "\n",
        "- You should look at the PyTorch page for `nn.Conv2d` [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) (and review the discussion above) to understand what the shape of the weights should be.\n",
        "- We assume `bias=False`, so the only `nn.Parameter` object we need to define is `weight`.\n",
        "- You should use **uniform Kaiming initialization** like you have before, i.e. the bounds of the uniform distribution should be $\\pm 1/\\sqrt{N_{in}}$ where $N_{in}$ is the product of input channels and kernel height & width, as described at the bottom of the `nn.Conv2d` docs (the bullet points under the **Variables** header).\n",
        "\n",
        "<details>\n",
        "<summary>Question - why do you think we use the product of input channels and kernel height & width for our Kaiming initialization bounds?</summary>\n",
        "\n",
        "This is because each value in the output is computed by taking the product over `in_channels * kernel_height * kernel_width` elements, analogously to how each value in the linear layer is computed by taking the product over just `in_features` elements.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "gNDFqBv6jBUP",
        "outputId": "da9b6fe3-cdb5-4fd1-f9d8-6abe612e7f4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_conv2d_module` passed!\n",
            "Manually verify that this is an informative repr: Conv2d(in_channels=24, out_channels=12, kernel_size=3, stride=2, padding=1)\n"
          ]
        }
      ],
      "source": [
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0):\n",
        "        \"\"\"\n",
        "        Same as torch.nn.Conv2d with bias=False.\n",
        "\n",
        "        Name your weight field `self.weight` for compatibility with the PyTorch version.\n",
        "\n",
        "        We assume kernel is square, with height = width = `kernel_size`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        # YOUR CODE HERE - define & initialize `self.weight`\n",
        "        kernel_height = kernel_width = kernel_size\n",
        "        sf = 1 / np.sqrt(in_channels * kernel_width * kernel_height)\n",
        "        self.weight = nn.Parameter(sf * (2 * t.rand(out_channels, in_channels, kernel_height, kernel_width) - 1))\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Apply the functional conv2d, which you can import.\"\"\"\n",
        "        return t.nn.functional.conv2d(x, self.weight, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "\n",
        "\n",
        "tests.test_conv2d_module(Conv2d)\n",
        "m = Conv2d(in_channels=24, out_channels=12, kernel_size=3, stride=2, padding=1)\n",
        "print(f\"Manually verify that this is an informative repr: {m}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtXz-fmKjBUP"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0):\n",
        "        \"\"\"\n",
        "        Same as torch.nn.Conv2d with bias=False.\n",
        "\n",
        "        Name your weight field `self.weight` for compatibility with the PyTorch version.\n",
        "\n",
        "        We assume kernel is square, with height = width = `kernel_size`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        kernel_height = kernel_width = kernel_size\n",
        "        sf = 1 / np.sqrt(in_channels * kernel_width * kernel_height)\n",
        "        self.weight = nn.Parameter(sf * (2 * t.rand(out_channels, in_channels, kernel_height, kernel_width) - 1))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Apply the functional conv2d, which you can import.\"\"\"\n",
        "        return t.nn.functional.conv2d(x, self.weight, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pL7QknMjBUP"
      },
      "source": [
        "### `MaxPool2d`\n",
        "\n",
        "We often add a maxpool layer after a convolutional layer. This layer is responsible for reducing the spatial size of the convolved feature. It works by taking the maximum value in each kernel-sized window, and outputting that value. For instance, if we have a 2x2 kernel, then we take the maximum of each 2x2 window in the input.\n",
        "\n",
        "Maxpool is useful for downsampling the image (reducing the total amount of data we're having to work with), as well as extracting dominant features in the image. For example, if we're training a model for classification, the model might find it useful to create a \"wheel detector\" to identify whether a wheel is present in the image - even if most chunks of the image don't contain a wheel, we care more about whether a wheel exists _somewhere_ in the image, and so we might only be interested in the largest values.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*uoWYsCV5vBU8SHFPAPao-w.gif\" width=\"360\">\n",
        "\n",
        "We've given you `MaxPool2d` below. This is a wrapper for the `max_pool2d` function (although in the bonus exercises later you can implement your own version of this)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "5FDU_AqxjBUP"
      },
      "outputs": [],
      "source": [
        "class MaxPool2d(nn.Module):\n",
        "    def __init__(self, kernel_size: int, stride: int | None = None, padding: int = 1):\n",
        "        super().__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Call the functional version of maxpool2d.\"\"\"\n",
        "        return F.max_pool2d(x, kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        \"\"\"Add additional information to the string representation of this class.\"\"\"\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in [\"kernel_size\", \"stride\", \"padding\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfKdK3CsjBUP"
      },
      "source": [
        "# 4️⃣ ResNets\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn about skip connections, and how they help overcome the degradation problem\n",
        "> * Learn about batch normalization, and why it is used in training\n",
        "> * Assemble your own ResNet, and load in weights from PyTorch's ResNet implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTNY36KhjBUP"
      },
      "source": [
        "## Reading\n",
        "\n",
        "* [Batch Normalization in Convolutional Neural Networks](https://www.baeldung.com/cs/batch-normalization-cnn)\n",
        "* [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n",
        "\n",
        "You should move on once you can answer the following questions:\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\"Batch Normalization allows us to be less careful about initialization.\" Explain this statement.</summary>\n",
        "\n",
        "Weight initialisation methods like Xavier (which we encountered yesterday) are based on the idea of making sure the activations have approximately the same distribution across layers at initialisation. But batch normalisation ensures that this is the case as signals pass through the network.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Give three reasons why batch norm improves the performance of neural networks.</summary>\n",
        "\n",
        "The reasons given in the first linked document above are:\n",
        "\n",
        "* Normalising inputs speeds up computation\n",
        "* Internal covariate shift is reduced, i.e. the mean and standard deviation is kept constant across the layers.\n",
        "* Regularisation effect: noise internal to each minibatch is reduced\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>If you have an input tensor of size (batch, channels, width, height), and you apply a batchnorm layer, how many learned parameters will there be?</summary>\n",
        "\n",
        "A mean and standard deviation is calculated for each channel (i.e. each calculation is done across the batch, width, and height dimensions). So the number of learned params will be `2 * channels`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>In the paper, the diagram shows additive skip connections (i.e. F(x) + x). One can also form concatenated skip connections, by \"gluing together\" F(x) and x into a single tensor. Give one advantage and one disadvantage of these, relative to additive connections.</summary>\n",
        "\n",
        "One advantage of concatenation: the subsequent layers can re-use middle representations; maintaining more information which can lead to better performance. Also, this still works if the tensors aren't exactly the same shape. One disadvantage: less compact, so there may be more weights to learn in subsequent layers.\n",
        "\n",
        "Crucially, both the addition and concatenation methods have the property of preserving information, to at least some degree of fidelity. For instance, you can [use calculus to show](https://theaisummer.com/skip-connections/#:~:text=residual%20skip%20connections.-,ResNet%3A%20skip%20connections%C2%A0via%C2%A0addition,-The%20core%20idea) that both methods will fix the vanishing gradients problem.\n",
        "</details>\n",
        "\n",
        "\n",
        "In this section, we'll do a more advanced version of the exercise in part 1. Rather than building a relatively simple network in which computation can be easily represented by a sequence of simple layers, we're going to build a more complex architecture which requires us to define nested blocks.\n",
        "\n",
        "We'll start by defining a few more `nn.Module` objects, which we hadn't needed before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3UQwSkXjBUP"
      },
      "source": [
        "## Sequential\n",
        "\n",
        "Firstly, now that we're working with large and complex architectures, we should create a version of `nn.Sequential`. As the name suggests, when an `nn.Sequential` is fed an input, it sequentially applies each of its submodules to the input, with the output from one module feeding into the next one.\n",
        "\n",
        "The implementation is given to you below. A few notes:\n",
        "\n",
        "* In initalization, we add to the `_modules` dictionary.\n",
        "    * This is a special type of dict called an **ordered dictionary**, which preserves the order of elements that get added (although Python sort-of does this now by default).\n",
        "    * When we call `self.parameters()`, this recursively goes through all modules in `self._modules`, and returns the params in those modules. This means we can nest sequentials within sequentials!\n",
        "* The special `__getitem__` and `__setitem__` methods determine behaviour when we get and set modules within the sequential.\n",
        "* The `repr` of the base class `nn.Module` already recursively prints out the submodules, so we don't need to write anything in `extra_repr`.\n",
        "    * To see how this works in practice, try defining a `Sequential` which takes a sequence of modules that you've defined above, and see what it looks like when you print it.\n",
        "\n",
        "Don't worry about deeply understanding this code. The main takeaway is that `nn.Sequential` is a useful list-like object to store modules, and apply them all sequentially.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - initializing Sequential with an OrderedDict</summary>\n",
        "\n",
        "The actual `nn.Sequential` module can be initialized with an ordered dictionary, rather than a list of modules. For instance, rather than doing this:\n",
        "\n",
        "```python\n",
        "seq = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 30)\n",
        ")\n",
        "```\n",
        "\n",
        "we can do this:\n",
        "\n",
        "```python\n",
        "from collections import OrderedDict\n",
        "\n",
        "seq = nn.Sequential(OrderedDict([\n",
        "    (\"linear1\", nn.Linear(10, 20)),\n",
        "    (\"relu\", nn.ReLU()),\n",
        "    (\"linear2\", nn.Linear(20, 30))\n",
        "]))\n",
        "```\n",
        "\n",
        "This is handy if we want to give each module an descriptive name.\n",
        "\n",
        "The `Sequential` implementation below doesn't allow the input to be an OrderedDict. As a bonus exercise, can you rewrite the `__init__`, `__getitem__` and `__setitem__` methods to allow the input to be an OrderedDict? If you do this, you'll actually be able to match your eventual `ResNet` model names exactly to the PyTorch implementation.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "IMeB1It7jBUP"
      },
      "outputs": [],
      "source": [
        "class Sequential(nn.Module):\n",
        "    _modules: dict[str, nn.Module]\n",
        "\n",
        "    def __init__(self, *modules: nn.Module):\n",
        "        super().__init__()\n",
        "        for index, mod in enumerate(modules):\n",
        "            self._modules[str(index)] = mod\n",
        "\n",
        "    def __getitem__(self, index: int) -> nn.Module:\n",
        "        index %= len(self._modules)  # deal with negative indices\n",
        "        return self._modules[str(index)]\n",
        "\n",
        "    def __setitem__(self, index: int, module: nn.Module) -> None:\n",
        "        index %= len(self._modules)  # deal with negative indices\n",
        "        self._modules[str(index)] = module\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Chain each module together, with the output from one feeding into the next one.\"\"\"\n",
        "        for mod in self._modules.values():\n",
        "            x = mod(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiJjl23vjBUP"
      },
      "source": [
        "## BatchNorm2d\n",
        "\n",
        "Now, we'll implement our `BatchNorm2d`, the layer described in the reading material you hopefully read above. You'll be implementing it according to the [PyTorch docs](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) (with `affine=True` and `track_running_stats=True`).\n",
        "\n",
        "The primary function of batchnorm is to normalize the activations of each layer within the neural network during training. It normalizes each batch of input data to have a mean of 0 and std dev of 1. This normalization helps mitigate the **internal covariate shift** problem, which refers to the change in the distribution of layer inputs as the network trains. This becomes a particularly big problem as we build deeper networks, because there's more opportunity for the activation distribution to change over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1S4yU34jBUP"
      },
      "source": [
        "### Buffers\n",
        "\n",
        "A question that might have occurred to you as you read about batchnorm - how does averaging over input data work in inference mode, if you only have a single input rather than a batch? The answer is that during training mode we compute a running average of our data's mean and variance, and we use this running average in inference mode.\n",
        "\n",
        "How do we store these moving averages? We want them to be saved and loaded with the model (because we need these values in order to run our model), but we don't want to update them using gradient descent (so we don't want to use `nn.Parameter`). So instead, we use the Pytorch **buffers** feature. These are essentially tensors which are included in `model.state_dict()` (and so they're saved & loaded with the rest of the model) but not included in `model.parameters()`.\n",
        "\n",
        "You can create a buffer by calling [`self.register_buffer`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer) from inside a `nn.Module`. We've initialized the necessary buffers for you in the `__init__` method below - you'll need a running mean and variance, as well as a counter for the number of batches seen (technically this isn't strictly necessary because the running mean & variance are updated using an exponential moving average so the update rule is independent of the number of previous updates, but we're doing this so our state dict matches the PyTorch implementation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU_LYqcJjBUP"
      },
      "source": [
        "### Train and Eval Modes\n",
        "\n",
        "Okay so we have buffers, but how can we make them behave differently in different modes - i.e. updating the running mean & variance in training mode, and using the stored values in eval mode? The answer is that we use the `training` method of the `nn.Module` class, which is a boolean attribute that gets flipped when we call `self.eval()` or `self.train()`. In the case of batch norm, your code should look like this:\n",
        "\n",
        "```python\n",
        "if self.training:\n",
        "    # Use this data's mean & variance to normalize, then use it to update the buffers\n",
        "else:\n",
        "    # Use the buffer mean & variance to normalize\n",
        "```\n",
        "\n",
        "The other commonly used module which has different behaviour in training and eval modes is `Dropout` - in eval mode this module uses all its inputs, but in training it randomly selects some fraction `1 - p` of the input values to zero out and scales the remaining values by `1 / (1 - p)`.\n",
        "\n",
        "Note that other normalization modules we'll address later in this course like `LayerNorm` don't have different behaviour in training and eval modes, because these don't normalize over the batch dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHXorQkCjBUP"
      },
      "source": [
        "### Exercise - implement `BatchNorm2d`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-30 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `BatchNorm2d` according to the [PyTorch docs](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html). We're implementing it with `affine=True` and `track_running_stats=True`. All the parameters are defined for you in the `__init__` method, your job will be to fill in the `forward` and `extra_repr` methods.\n",
        "\n",
        "A few final tips:\n",
        "\n",
        "- Remember to use `weight` and `bias` in the fwd pass, after normalizing. You should multiply by `weight` and add `bias`.\n",
        "- All your tensors (`weight`, `bias`, `running_mean` and `running_var`) are vectors of length `num_features`, this should help you figure out what dimensions you're operating on.\n",
        "- Remember that the shape of `x` is `(batch, num_features, height, width)` which doesn't broadcast with `(num_features,)`. The easiest way to fix this is to reshape the latter to something like `(1, num_features, 1, 1)`, or optionally just `(num_features, 1, 1)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "N-PuyV34jBUP",
        "outputId": "32eb3595-762b-4636-d0aa-b275487ba99f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_batchnorm2d_module` passed!\n",
            "All tests in `test_batchnorm2d_forward` passed!\n",
            "All tests in `test_batchnorm2d_running_mean` passed!\n"
          ]
        }
      ],
      "source": [
        "class BatchNorm2d(nn.Module):\n",
        "    # The type hints below aren't functional, they're just for documentation\n",
        "    running_mean: Float[Tensor, \"num_features\"]\n",
        "    running_var: Float[Tensor, \"num_features\"]\n",
        "    num_batches_tracked: Int[Tensor, \"\"]  # This is how we denote a scalar tensor\n",
        "\n",
        "    def __init__(self, num_features: int, eps=1e-05, momentum=0.1):\n",
        "        \"\"\"\n",
        "        Like nn.BatchNorm2d with track_running_stats=True and affine=True.\n",
        "\n",
        "        Name the learnable affine parameters `weight` and `bias` in that order.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.weight = nn.Parameter(t.ones(num_features))\n",
        "        self.bias = nn.Parameter(t.zeros(num_features))\n",
        "\n",
        "        self.register_buffer(\"running_mean\", t.zeros(num_features))\n",
        "        self.register_buffer(\"running_var\", t.ones(num_features))\n",
        "        self.register_buffer(\"num_batches_tracked\", t.tensor(0))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Normalize each channel.\n",
        "\n",
        "        Compute the variance using `torch.var(x, unbiased=False)`\n",
        "        Hint: you may also find it helpful to use the argument `keepdim`.\n",
        "\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels, height, width)\n",
        "        \"\"\"\n",
        "        if self.training:\n",
        "            mean = t.mean(x, dim=(0, 2, 3))\n",
        "            var = t.var(x, unbiased=False, dim=(0, 2, 3))\n",
        "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
        "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
        "            self.num_batches_tracked += 1\n",
        "        else:\n",
        "            mean = self.running_mean\n",
        "            var = self.running_var\n",
        "\n",
        "        mean_reshaped = einops.rearrange(mean, 'c -> 1 c 1 1')\n",
        "        var_reshaped = einops.rearrange(var, 'c -> 1 c 1 1')\n",
        "\n",
        "        rehape = lambda x: einops.rearrange(x, 'c -> 1 c 1 1')\n",
        "\n",
        "        x_normed = (x - rehape(mean)) / (t.sqrt(var_reshaped) + self.eps)\n",
        "\n",
        "        x_affine = x_normed * einops.rearrange(self.weight, 'c -> 1 c 1 1') + einops.rearrange(self.bias, 'c -> 1 c 1 1')\n",
        "        return x_affine\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_batchnorm2d_module(BatchNorm2d)\n",
        "tests.test_batchnorm2d_forward(BatchNorm2d)\n",
        "tests.test_batchnorm2d_running_mean(BatchNorm2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDElfgGRjBUP"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm stuck on this implementation, and need a template.</summary>\n",
        "\n",
        "The easiest way is to structure it like this (we've omitted the reshaping to make sure the mean & variance broadcasts correctly):\n",
        "\n",
        "```python\n",
        "if self.training:\n",
        "    mean = ... # mean of new data\n",
        "    var = ... # variance of new data\n",
        "    self.running_mean = ... # update running mean using exponential moving average\n",
        "    self.running_var = ... # update running variance using exponential moving average\n",
        "    self.num_batches_tracked += 1\n",
        "else:\n",
        "    mean = self.running_mean\n",
        "    var = self.running_var\n",
        "\n",
        "x_normed = ... # normalize x using `mean` and `var` (make sure `mean` and `var` are broadcastable with `x`)\n",
        "x_affine = ... # apply affine transformation from `self.weight` and `self.bias` (again, be careful of broadcasting)\n",
        "return x_affine\n",
        "```\n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def forward(self, x: Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Normalize each channel.\n",
        "\n",
        "    Compute the variance using `torch.var(x, unbiased=False)`\n",
        "    Hint: you may also find it helpful to use the argument `keepdim`.\n",
        "\n",
        "    x: shape (batch, channels, height, width)\n",
        "    Return: shape (batch, channels, height, width)\n",
        "    \"\"\"\n",
        "    # Calculating mean and var over all dims except for the channel dim\n",
        "    if self.training:\n",
        "        # Take mean over all dimensions except the feature dimension\n",
        "        mean = x.mean(dim=(0, 2, 3))\n",
        "        var = x.var(dim=(0, 2, 3), unbiased=False)\n",
        "        # Updating running mean and variance, in line with PyTorch documentation\n",
        "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
        "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
        "        self.num_batches_tracked += 1\n",
        "    else:\n",
        "        mean = self.running_mean\n",
        "        var = self.running_var\n",
        "\n",
        "    # Rearranging these so they can be broadcasted\n",
        "    reshape = lambda x: einops.rearrange(x, \"channels -> 1 channels 1 1\")\n",
        "\n",
        "    # Normalize, then apply affine transformation from self.weight & self.bias\n",
        "    x_normed = (x - reshape(mean)) / (reshape(var) + self.eps).sqrt()\n",
        "    x_affine = x_normed * reshape(self.weight) + reshape(self.bias)\n",
        "    return x_affine\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-zIkZUEjBUP"
      },
      "source": [
        "## AveragePool\n",
        "\n",
        "Let's end our collection of `nn.Module`s with an easy one 🙂\n",
        "\n",
        "The ResNet has a Linear layer with 1000 outputs at the end in order to produce classification logits for each of the 1000 classes. Any Linear needs to have a constant number of input features, but the ResNet is supposed to be compatible with arbitrary height and width, so we can't just do a pooling operation with a fixed kernel size and stride.\n",
        "\n",
        "Luckily, the simplest possible solution works decently: take the mean over the spatial dimensions. Intuitively, each position has an equal \"vote\" for what objects it can \"see\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYnKXRrfjBUP"
      },
      "source": [
        "### Exercise - implement `AveragePool`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴⚪⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 5-10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "This should be a pretty straightforward implementation; it doesn't have any weights or parameters of any kind, so you only need to implement the `forward` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "bPy0xaU9jBUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcdc3934-6407-45bf-f7fd-b527f8b8e0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_averagepool` passed!\n"
          ]
        }
      ],
      "source": [
        "class AveragePool(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels)\n",
        "        \"\"\"\n",
        "        return einops.reduce(x, 'b c h w -> b c', reduction='mean')\n",
        "\n",
        "\n",
        "tests.test_averagepool(AveragePool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrMm9Hm8jBUP"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class AveragePool(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels)\n",
        "        \"\"\"\n",
        "        return t.mean(x, dim=(2, 3))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCgqtLlOjBUQ"
      },
      "source": [
        "## Building ResNet\n",
        "\n",
        "Now we have all the building blocks we need to start assembling your own ResNet! The following diagram describes the architecture of ResNet34 - the other versions are broadly similar.\n",
        "\n",
        "Note - unless otherwise noted, you should assume convolutions have `kernel_size=3, stride=1, padding=1` (this is a **shape preserving convolution** i.e. the width & height of the input and output will be the same). None of the convolutions have biases.\n",
        "\n",
        "You don't have to understand every detail in this diagram before proceeding; specific points will be clarified as we go through each exercise.\n",
        "\n",
        "<details>\n",
        "<summary>Question: why do we not care about including biases in the convolutional layers?</summary>\n",
        "\n",
        "Every convolution layer in this network is followed by a batch normalization layer. The first operation in the batch normalization layer is to subtract the mean of each output channel. But a convolutional bias just adds some scalar `b` to each output channel, increasing the mean by `b`. This means that for any `b` added, the batch normalization will subtract `b` to exactly negate the bias term.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm confused about how the nested subgraphs work.</summary>\n",
        "\n",
        "The right-most block in the diagram, `ResidualBlock`, is nested inside `BlockGroup` multiple times. When you see `ResidualBlock` in `BlockGroup`, you should visualise a copy of `ResidualBlock` sitting in that position.\n",
        "    \n",
        "Similarly, `BlockGroup` is nested multiple times (four to be precise) in the full `ResNet34` architecture.\n",
        "</details>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/resnet-fixed.svg\" width=\"900\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KC7tTKPjBUQ"
      },
      "source": [
        "### Exercise - implement `ResidualBlock`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 20-30 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `ResidualBlock` by referring to the diagram (i.e. the right-most of the three hierarchical diagrams above).\n",
        "\n",
        "The **left branch** starts with a strided convolution which changes the number of features from `in_feats` to `out_feats`. It has all conv parameters default i.e. `kernel_size=3, stride=1, padding=1` except for the stride which is instead given by `first_stride`. The second convolution has all default parameters, and maps from `out_feats` to `out_feats` (meaning it's fully shape preserving).\n",
        "\n",
        "As for the **right branch** - this is meant to essentially be a skip connection, the problem is we can't just use a skip connection because the shapes might not match up (and so we couldn't add them together at the end). The left branch is fully shape preserving if and only if `first_stride == 1` and `in_feats == out_feats`. If this is true then we do set the right branch to be the identity (that's what the \"OPTIONAL\" annotation refers to), but if this isn't true then we set the right branch to be a 1x1 convolution with stride `first_stride`, zero padding, and mapping from `in_feats` to `out_feats`, followed by a batchnorm layer. This is in a sense the simplest operation we can get which matches the left branch shape, since the convolution is basically just a downsampling operation (keeping pixels based on a `::first_stride` slice across the height and width dimensions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "D7B3MPn5jBUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd22f00-1cde-4e63-d782-38bec4f4761c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 2.7552e+00, -2.3893e+00,  2.6671e-01,  ..., -7.8654e-02,\n",
            "           -6.0168e-02, -1.0490e+00],\n",
            "          [ 3.8549e+00, -1.5034e+00, -1.8795e+00,  ..., -1.7914e+00,\n",
            "            1.1181e+00,  1.7681e+00],\n",
            "          [ 1.9169e+00,  1.7968e+00,  3.9023e-02,  ..., -1.1908e+00,\n",
            "           -6.2798e-01,  9.3227e-02],\n",
            "          ...,\n",
            "          [ 3.1941e-01,  9.9107e-01, -2.4754e-01,  ..., -3.6365e+00,\n",
            "           -4.9121e-01,  4.2135e+00],\n",
            "          [-8.2729e-01,  1.7952e+00,  3.4220e+00,  ...,  2.1095e+00,\n",
            "           -2.1342e+00, -1.5080e+00],\n",
            "          [ 6.8107e-01, -4.6451e-01,  9.8161e-01,  ...,  1.0931e+00,\n",
            "            9.1163e-01,  3.6990e-01]],\n",
            "\n",
            "         [[-2.0062e+00,  1.0870e+00, -9.7052e-01,  ..., -3.1802e-01,\n",
            "           -9.4786e-01, -1.1766e-02],\n",
            "          [-1.2861e+00, -6.4629e-01,  8.1177e-01,  ..., -1.6383e+00,\n",
            "            6.5234e-01, -1.0004e+00],\n",
            "          [-2.1902e+00,  1.6490e-01, -1.5735e+00,  ..., -1.8368e+00,\n",
            "            5.1042e-01,  5.0105e-01],\n",
            "          ...,\n",
            "          [ 6.8524e-01, -1.5238e+00,  6.4581e-01,  ...,  6.8873e-01,\n",
            "            3.0102e+00, -2.4569e-01],\n",
            "          [-1.9584e+00,  1.4588e-02,  3.0645e-01,  ..., -7.6246e-01,\n",
            "            1.3389e-01,  2.1695e+00],\n",
            "          [-1.7382e+00,  1.1535e+00,  7.4258e-01,  ..., -2.5351e+00,\n",
            "            1.9570e-02, -1.3784e+00]],\n",
            "\n",
            "         [[-7.9393e-01, -4.8747e-01, -1.3353e+00,  ...,  5.9176e-01,\n",
            "            9.9942e-02, -3.6059e-01],\n",
            "          [ 1.1947e+00,  1.0264e+00, -1.5090e+00,  ..., -1.2896e-01,\n",
            "            6.0056e-01, -8.5440e-01],\n",
            "          [ 6.9458e-01,  5.1866e-01, -2.0453e+00,  ..., -1.3493e+00,\n",
            "            1.3575e+00, -9.3212e-01],\n",
            "          ...,\n",
            "          [ 9.2129e-01, -1.8446e+00,  2.0465e+00,  ...,  4.6510e+00,\n",
            "           -8.9406e-01,  6.1961e-01],\n",
            "          [ 1.1197e+00, -3.9529e-03, -8.2426e-01,  ...,  1.2268e+00,\n",
            "           -9.3883e-01,  6.6450e-01],\n",
            "          [ 1.3550e+00,  1.2397e+00,  1.1158e+00,  ...,  9.3054e-01,\n",
            "           -5.5986e-02,  1.2033e+00]]]], grad_fn=<AddBackward0>)\n",
            "Passed all tests when first_stride=1\n",
            "tensor([[[[ 1.9907,  0.5239,  1.6504,  ..., -0.8028,  2.6096, -0.7454],\n",
            "          [ 2.1033, -0.9959, -0.9725,  ..., -0.5454, -0.1796,  1.9252],\n",
            "          [ 0.3231,  3.7130, -0.3164,  ...,  1.1070, -0.6629, -0.5922],\n",
            "          ...,\n",
            "          [-2.1447,  2.7025,  3.3503,  ...,  0.9879, -0.9935,  0.6172],\n",
            "          [-0.4515,  0.8089, -2.2107,  ..., -0.5627,  2.5376,  0.5551],\n",
            "          [-0.7747, -0.2570,  1.4242,  ..., -0.6212, -0.5751, -0.3402]],\n",
            "\n",
            "         [[-1.5601, -0.3143, -0.1228,  ..., -1.0772,  0.9478, -1.6780],\n",
            "          [-0.3435, -3.6720, -3.6267,  ...,  0.8675,  1.3075,  0.2836],\n",
            "          [-0.4600,  0.1460, -1.1062,  ...,  1.5051, -0.4098,  0.3132],\n",
            "          ...,\n",
            "          [-2.6221,  1.7889,  4.7755,  ...,  1.6029, -2.0100, -1.3303],\n",
            "          [-1.5082, -0.8961, -1.9618,  ...,  0.2936,  0.9714, -2.2313],\n",
            "          [ 1.3965, -1.5652, -1.9599,  ..., -2.5227, -1.1270, -2.0677]],\n",
            "\n",
            "         [[-2.2611,  0.8155,  1.0851,  ...,  1.2354, -0.5353,  0.7044],\n",
            "          [-2.6607, -0.4228, -0.8189,  ...,  2.6547,  0.5831, -0.9096],\n",
            "          [-1.0881, -0.7370,  0.6224,  ...,  1.5850,  2.4083,  0.8803],\n",
            "          ...,\n",
            "          [ 0.8804, -1.7163, -1.6684,  ...,  0.4185,  1.9571,  0.6061],\n",
            "          [ 0.2436, -0.1384,  0.7219,  ..., -1.6930, -4.2263, -0.1770],\n",
            "          [ 0.8478, -1.9263,  0.5794,  ..., -2.6518, -1.0270,  0.7804]],\n",
            "\n",
            "         [[-0.2723, -0.3327,  1.5844,  ..., -0.7160,  0.7351, -2.3373],\n",
            "          [-0.9046,  0.9399,  1.1773,  ...,  1.3524,  0.9962, -0.4190],\n",
            "          [-0.9308,  0.1530,  1.7322,  ...,  2.4729,  2.7227,  0.1151],\n",
            "          ...,\n",
            "          [ 0.4728, -0.3219, -0.4966,  ...,  1.2402,  0.6386,  2.1777],\n",
            "          [-0.3268,  0.0147,  4.2091,  ...,  0.3230, -1.0897, -2.7035],\n",
            "          [-2.9085, -1.3952, -0.1257,  ..., -2.3000, -0.9293,  1.7435]]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Passed all tests when first_stride>1\n",
            "All tests in `test_residual_block` passed!\n"
          ]
        }
      ],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"\n",
        "        A single residual block with optional downsampling.\n",
        "\n",
        "        For compatibility with the pretrained model, declare the left side branch first using a `Sequential`.\n",
        "\n",
        "        If first_stride is > 1, this means the optional (conv + bn) should be present on the right branch. Declare it second using another `Sequential`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        is_shape_preserving = (first_stride == 1) and (in_feats == out_feats)  # determines if right branch is identity\n",
        "        self.in_feats = in_feats\n",
        "        self.out_feats = out_feats\n",
        "        self.first_stride = first_stride\n",
        "        self.kernel_size = 3\n",
        "\n",
        "        if is_shape_preserving:\n",
        "          self.shortcut = nn.Identity()\n",
        "        else:\n",
        "          self.shortcut = nn.Sequential(\n",
        "              nn.Conv2d(self.in_feats,\n",
        "                        self.out_feats,\n",
        "                        kernel_size=1,\n",
        "                        stride=self.first_stride,\n",
        "                        padding=0,\n",
        "                        bias=False),\n",
        "              nn.BatchNorm2d(self.out_feats)\n",
        "          )\n",
        "\n",
        "        # left branch\n",
        "        self.left_branch = nn.Sequential(\n",
        "          nn.Conv2d(in_feats, out_feats, kernel_size=3, stride=first_stride, padding=1, bias=False),\n",
        "          nn.BatchNorm2d(out_feats),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(out_feats, out_feats, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "          nn.BatchNorm2d(out_feats)\n",
        "        )\n",
        "\n",
        "        self.relu = ReLU()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / stride, width / stride)\n",
        "\n",
        "        If no downsampling block is present, the addition should just add the left branch's output to the input.\n",
        "        \"\"\"\n",
        "        x_right = self.shortcut(x)\n",
        "        x_left = self.left_branch(x)\n",
        "\n",
        "        return self.relu(x_left + x_right)\n",
        "\n",
        "\n",
        "tests.test_residual_block(ResidualBlock)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY4GJqgYjBUQ"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"\n",
        "        A single residual block with optional downsampling.\n",
        "\n",
        "        For compatibility with the pretrained model, declare the left side branch first using a `Sequential`.\n",
        "\n",
        "        If first_stride is > 1, this means the optional (conv + bn) should be present on the right branch. Declare it second using another `Sequential`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        is_shape_preserving = (first_stride == 1) and (in_feats == out_feats)  # determines if right branch is identity\n",
        "\n",
        "        self.left = Sequential(\n",
        "            Conv2d(in_feats, out_feats, kernel_size=3, stride=first_stride, padding=1),\n",
        "            BatchNorm2d(out_feats),\n",
        "            ReLU(),\n",
        "            Conv2d(out_feats, out_feats, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(out_feats),\n",
        "        )\n",
        "        self.right = (\n",
        "            nn.Identity()\n",
        "            if is_shape_preserving\n",
        "            else Sequential(Conv2d(in_feats, out_feats, kernel_size=1, stride=first_stride), BatchNorm2d(out_feats))\n",
        "        )\n",
        "        self.relu = ReLU()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / stride, width / stride)\n",
        "\n",
        "        If no downsampling block is present, the addition should just add the left branch's output to the input.\n",
        "        \"\"\"\n",
        "        x_left = self.left(x)\n",
        "        x_right = self.right(x)\n",
        "        return self.relu(x_left + x_right)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53nkd-GDjBUQ"
      },
      "source": [
        "### Exercise - implement `BlockGroup`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `BlockGroup` according to the diagram. There should be `n_blocks` total blocks in the group. Only the first block has the possibility of having a right branch (because we might have either `first_stride > 1` or `in_feats != out_feats`), but every subsequent block will have the identity instead of a right branch.\n",
        "\n",
        "<details>\n",
        "<summary>Help - I don't understand why all blocks after the first one won't have a right branch.</summary>\n",
        "\n",
        "- The `first_stride` argument only gets applied to the first block, definitionally (i.e. the purpose of the `BlockGroup` is to downsample the input by `first_stride` just once, not on every single block).\n",
        "- After we pass through the first block we can guarantee that the number of channels will be `out_feats`, so every subsequent block will have `out_feats` input channels and `out_feats` output channels.\n",
        "\n",
        "Combining these two facts, we see that every subsequent block will have a shape-preserving left branch, so it can have the identity as its right branch.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "4vxTirPmjBUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f25b0725-187d-4c0d-8be6-857d934df5ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 1.2741e-01,  1.4999e+00,  1.5265e+00,  ..., -3.6514e-01,\n",
            "            1.2589e+00,  3.3218e-01],\n",
            "          [ 1.0813e+00, -1.0200e-01, -2.4337e+00,  ...,  4.1965e-01,\n",
            "            3.3201e-01, -1.2720e+00],\n",
            "          [-2.0760e+00,  1.0033e+00,  2.3895e+00,  ..., -2.9768e+00,\n",
            "            1.6818e+00,  9.9030e-01],\n",
            "          ...,\n",
            "          [ 1.4764e+00, -1.2266e-01, -2.1270e+00,  ...,  7.9660e-01,\n",
            "            9.4450e-01, -9.2455e-01],\n",
            "          [-3.0890e-01,  1.4149e+00,  1.6242e+00,  ..., -9.5998e-01,\n",
            "            1.1842e+00,  6.8884e-01],\n",
            "          [ 2.6545e-01, -9.7480e-01, -1.6245e+00,  ...,  5.1999e-01,\n",
            "            1.7123e-01, -1.4392e+00]],\n",
            "\n",
            "         [[-1.0478e+00,  9.8246e-02,  1.7303e+00,  ...,  9.9277e-01,\n",
            "           -8.3910e-01, -1.1340e+00],\n",
            "          [ 3.4171e+00, -1.7739e+00,  1.0805e+00,  ..., -4.0583e-01,\n",
            "            2.6141e-01, -2.1811e+00],\n",
            "          [ 4.3413e-01,  8.8114e-01, -1.5324e+00,  ...,  2.9244e-01,\n",
            "           -1.8242e+00, -1.0675e-01],\n",
            "          ...,\n",
            "          [ 1.0301e+00, -1.5832e+00, -5.9056e-01,  ..., -2.1860e+00,\n",
            "            1.1429e-01,  1.2726e+00],\n",
            "          [-1.4638e+00,  1.1253e+00, -2.3571e+00,  ...,  7.4488e-01,\n",
            "           -1.6882e+00,  1.8700e+00],\n",
            "          [ 1.0161e+00,  1.7833e-03,  6.9873e-01,  ...,  6.0249e-02,\n",
            "            2.1543e-01,  3.0716e-01]],\n",
            "\n",
            "         [[ 6.7130e-01, -1.3145e+00, -4.1949e-02,  ..., -1.2314e+00,\n",
            "            1.0079e+00, -6.4723e-01],\n",
            "          [-2.4523e-01,  3.8200e+00,  1.7805e+00,  ..., -3.4204e-01,\n",
            "            1.0211e+00,  2.5341e-01],\n",
            "          [ 3.3062e-01, -2.1886e+00,  2.2102e+00,  ...,  1.8634e+00,\n",
            "            7.4180e-01, -1.5683e+00],\n",
            "          ...,\n",
            "          [ 8.0810e-01,  2.3120e+00, -8.6865e-01,  ...,  3.1023e-01,\n",
            "           -9.5355e-01,  1.5308e+00],\n",
            "          [ 2.0876e-02,  1.0516e-01,  1.4572e+00,  ..., -1.7006e+00,\n",
            "           -2.2183e-01, -1.6369e+00],\n",
            "          [-4.1542e-01, -2.9655e-01, -2.6214e-01,  ...,  1.5748e-01,\n",
            "            4.3373e-01,  7.0954e-01]]]], grad_fn=<AddBackward0>)\n",
            "tensor([[[[ 1.2163,  1.0936,  2.9678,  ...,  0.4342,  1.6787,  0.5509],\n",
            "          [ 0.6209, -1.5058, -1.2934,  ...,  0.2360,  0.8875,  0.1533],\n",
            "          [ 1.1946,  2.2401,  2.1353,  ...,  1.6943,  0.7007,  0.8519],\n",
            "          ...,\n",
            "          [ 1.6688, -0.6305, -0.5758,  ...,  2.2456,  0.4587, -0.0074],\n",
            "          [ 1.0209,  1.8765,  2.5801,  ...,  1.1016,  1.5598,  0.1922],\n",
            "          [ 0.8419, -0.0474,  0.3421,  ...,  0.6011,  0.5444, -0.6491]],\n",
            "\n",
            "         [[ 1.7123, -0.7074,  0.6985,  ...,  0.5991, -0.0381, -0.2062],\n",
            "          [ 3.5170, -0.7034,  2.0407,  ...,  0.0273, -0.9407, -0.5997],\n",
            "          [ 2.4297,  0.3335, -0.2108,  ..., -0.0346, -0.0239, -0.8546],\n",
            "          ...,\n",
            "          [ 0.6493, -0.6121,  0.4505,  ...,  0.4445,  0.9095,  0.5144],\n",
            "          [ 0.6159,  1.1986,  0.6490,  ...,  0.7961,  0.1950,  1.2603],\n",
            "          [ 0.8676,  0.1816,  0.2250,  ...,  0.1496, -0.1035, -0.3645]],\n",
            "\n",
            "         [[-0.6863,  0.2798,  1.7779,  ..., -0.2386,  0.6982, -0.7320],\n",
            "          [-1.3411,  5.3502,  1.9129,  ...,  0.2535,  1.1812, -0.6047],\n",
            "          [-0.6841,  0.2295,  3.1034,  ...,  3.8454,  1.0886, -0.3656],\n",
            "          ...,\n",
            "          [ 0.2781,  2.4895,  0.8597,  ..., -0.4126,  0.7324,  1.9671],\n",
            "          [ 0.2055, -0.7114,  1.3555,  ..., -1.7590,  0.9868,  0.3738],\n",
            "          [-1.0000, -0.7661, -0.0438,  ..., -0.8993, -0.2164,  0.4646]]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Passed all tests when first_stride=1\n",
            "tensor([[[[-0.2671,  1.6232,  0.6269,  ...,  0.9886, -0.9844,  0.6024],\n",
            "          [-1.8482,  1.1548, -3.5036,  ..., -0.9903, -1.3370,  0.2261],\n",
            "          [ 0.5805,  1.7576,  1.3384,  ..., -0.0745,  3.6426, -1.1574],\n",
            "          ...,\n",
            "          [ 0.7136, -0.0398, -0.3679,  ...,  1.2829, -2.7206,  0.8684],\n",
            "          [-0.1251,  1.2844, -0.3499,  ..., -1.5342,  0.1183, -0.7230],\n",
            "          [ 0.1170,  2.0886,  1.3923,  ...,  1.0640, -2.8896, -1.8328]],\n",
            "\n",
            "         [[ 0.8026, -2.7036,  2.1885,  ..., -1.9551, -0.1439, -0.9054],\n",
            "          [ 1.7290, -0.2050,  2.6256,  ...,  0.1886, -0.3092, -0.3421],\n",
            "          [ 1.6512, -1.0366, -0.3586,  ..., -0.2237, -3.3952, -0.7836],\n",
            "          ...,\n",
            "          [-0.3982, -1.0250,  0.2046,  ..., -0.5768,  1.6392, -1.7197],\n",
            "          [ 0.2049, -2.8921, -0.2152,  ..., -0.6867, -1.2120, -0.1738],\n",
            "          [ 0.8913,  0.0524, -0.8145,  ..., -1.6763,  1.1074,  1.7024]],\n",
            "\n",
            "         [[ 0.5690, -0.2287,  2.5061,  ..., -0.7867, -0.2410,  1.5595],\n",
            "          [ 1.0343,  0.9996, -1.5464,  ..., -1.2379, -3.1105,  0.4659],\n",
            "          [ 0.1060, -0.5059,  1.5107,  ...,  0.0666, -0.2281, -1.4843],\n",
            "          ...,\n",
            "          [ 0.3883, -1.8508, -1.7640,  ...,  1.7519,  1.6915, -0.3030],\n",
            "          [-0.2326,  0.7532, -0.7816,  ...,  0.5726, -0.4327, -1.4372],\n",
            "          [ 0.8564,  0.8645,  1.7252,  ..., -0.0886, -1.4657, -0.9021]],\n",
            "\n",
            "         [[ 0.9481,  0.0930, -0.7093,  ...,  0.1632,  1.0394,  2.0572],\n",
            "          [-1.2010,  1.6703, -3.0125,  ..., -0.4853, -0.4840,  0.4737],\n",
            "          [-1.6041,  0.7285,  0.3294,  ..., -0.5018,  3.1438,  1.5971],\n",
            "          ...,\n",
            "          [ 0.5941,  0.0708, -1.3427,  ..., -0.1991, -1.9179,  1.2883],\n",
            "          [ 3.2001,  1.3801,  2.3581,  ..., -0.1456, -1.4869,  0.6612],\n",
            "          [ 0.1270,  1.1336,  0.0643,  ...,  2.6311, -1.0885, -0.7633]]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([[[[ 0.0639,  1.9708,  1.3152,  ..., -0.6204, -1.7213, -1.1283],\n",
            "          [-0.1276,  1.5154,  0.6351,  ..., -0.2236,  0.1609, -0.5793],\n",
            "          [ 1.0284,  3.2594,  1.4781,  ...,  0.7631,  2.9481,  0.4822],\n",
            "          ...,\n",
            "          [ 0.5749,  0.4332, -0.1563,  ..., -0.9728,  0.2786, -0.6895],\n",
            "          [ 0.6626,  1.7191,  0.7999,  ..., -1.0323,  0.3531,  0.2230],\n",
            "          [-0.2475,  1.8874,  1.2109,  ...,  2.2966,  0.0910,  0.0567]],\n",
            "\n",
            "         [[-0.3437, -0.2563,  0.9666,  ..., -0.2359, -1.0517, -1.1638],\n",
            "          [ 0.7317,  0.7872,  4.1317,  ...,  0.6865,  1.1153, -1.4678],\n",
            "          [ 2.6853,  1.4259,  0.7650,  ..., -0.5100,  0.6366, -0.5754],\n",
            "          ...,\n",
            "          [-0.1492,  0.7905, -0.9581,  ..., -0.6445,  1.4777, -0.4563],\n",
            "          [ 0.7159, -0.1618, -1.1488,  ..., -0.6351,  1.3557, -0.8949],\n",
            "          [ 0.3054,  0.2760,  0.3239,  ..., -0.3721,  1.2113,  0.4053]],\n",
            "\n",
            "         [[ 0.8370, -0.0713,  1.6873,  ...,  0.3633, -1.2646,  1.1526],\n",
            "          [ 0.1187,  0.0937, -0.8306,  ...,  0.6632,  0.5973,  1.5477],\n",
            "          [-1.1017, -0.2394,  0.3000,  ...,  0.5479,  1.2670, -1.1574],\n",
            "          ...,\n",
            "          [ 2.5767, -0.6335,  0.6054,  ...,  0.3254,  1.5632,  0.3166],\n",
            "          [ 0.3388,  0.5673,  0.5913,  ...,  0.8149,  1.2936, -0.4531],\n",
            "          [ 1.7830,  1.7130,  3.0278,  ...,  1.5592,  0.5024,  1.0870]],\n",
            "\n",
            "         [[ 0.3160, -0.0470, -0.1323,  ...,  1.5159,  1.4306,  2.9954],\n",
            "          [-0.5112,  1.4190,  0.4826,  ..., -0.3235, -0.6706,  0.4273],\n",
            "          [-1.3518, -0.5836,  0.8401,  ...,  0.1385,  2.0211,  3.0502],\n",
            "          ...,\n",
            "          [ 1.4508,  0.3478, -1.4235,  ..., -0.2713,  0.7911,  1.7319],\n",
            "          [ 2.6697,  0.0326,  3.4851,  ..., -0.4693, -0.1610,  2.6113],\n",
            "          [-0.3231,  0.4893, -0.7638,  ...,  3.6104, -1.4528,  0.1584]]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Passed all tests when first_stride>1\n",
            "tensor([[[[-0.6583,  1.0115, -1.3618,  ..., -1.2761, -0.1346, -0.2714],\n",
            "          [ 0.0109,  2.1287, -1.9494,  ..., -0.1132,  0.0713,  0.1370],\n",
            "          [ 0.6250,  1.0389,  0.1202,  ...,  1.9356,  1.8914,  0.0347],\n",
            "          ...,\n",
            "          [-0.5518, -0.4620, -0.0306,  ...,  0.2038, -2.4113,  1.9655],\n",
            "          [-0.2258,  1.6262, -0.7673,  ...,  0.6145,  1.0881, -0.7100],\n",
            "          [ 0.2505, -0.8668, -0.3767,  ..., -0.2888, -1.5760, -2.8500]],\n",
            "\n",
            "         [[ 1.5484,  0.7333,  1.0464,  ..., -0.1106, -0.6058,  2.4364],\n",
            "          [-0.7509,  0.1476, -1.9798,  ..., -1.6459, -2.6924,  1.0032],\n",
            "          [ 0.4648,  0.6690,  0.3764,  ..., -0.0560,  0.7770,  0.5895],\n",
            "          ...,\n",
            "          [ 1.6474, -1.6352, -1.3598,  ...,  2.2168, -0.3923, -0.9244],\n",
            "          [ 1.1939,  2.4866, -0.1193,  ..., -0.8179,  0.1294, -2.6134],\n",
            "          [-0.9540,  0.6620,  0.2259,  ...,  1.3562, -2.8944,  1.3184]],\n",
            "\n",
            "         [[-0.9749,  1.8043,  1.8123,  ...,  0.3702, -0.5574,  0.0519],\n",
            "          [ 0.6892,  0.0925, -0.5106,  ..., -0.9266, -0.4795, -0.0323],\n",
            "          [ 0.2154, -0.5977,  2.4206,  ...,  0.1732,  0.4375,  1.2957],\n",
            "          ...,\n",
            "          [ 0.6090,  0.2623,  0.7635,  ...,  0.5311, -1.4869,  1.6465],\n",
            "          [-3.3256,  1.8244, -1.3444,  ..., -0.3193,  0.2305, -0.5162],\n",
            "          [-1.6037, -1.1090,  1.8750,  ..., -0.0741, -1.3291,  1.1115]],\n",
            "\n",
            "         [[ 0.7382, -0.2738,  0.5380,  ..., -0.0976,  2.6163, -0.0058],\n",
            "          [-0.8205,  0.7638,  0.0984,  ...,  1.8903,  2.8368, -0.3672],\n",
            "          [ 0.8770, -1.3716, -3.9272,  ..., -0.4375,  0.2638,  0.7453],\n",
            "          ...,\n",
            "          [ 0.7738,  0.0991,  1.2859,  ..., -0.9012,  1.3672, -2.2546],\n",
            "          [ 2.5532, -1.6692,  1.5834,  ..., -1.2398, -0.3659, -0.3110],\n",
            "          [-0.4551, -1.6226, -1.7931,  ..., -0.2734, -0.5073,  0.2213]]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([[[[ 0.2717,  0.9285, -0.5779,  ..., -0.0178, -0.4488, -0.1297],\n",
            "          [-0.5135,  2.2382, -0.0241,  ..., -1.1132, -1.5234, -1.2830],\n",
            "          [ 0.6923,  2.1060,  0.7651,  ...,  3.9042,  2.8588, -0.9001],\n",
            "          ...,\n",
            "          [ 1.0235,  0.6467, -0.8221,  ...,  0.4287, -0.0189,  1.6320],\n",
            "          [ 0.3006,  2.6826, -0.1739,  ...,  0.4655,  0.3551, -0.2306],\n",
            "          [ 0.4332,  0.7892,  0.0849,  ...,  1.1603,  0.4545, -0.3572]],\n",
            "\n",
            "         [[ 1.8929,  0.1540,  0.1565,  ..., -0.4277, -0.2389,  2.3154],\n",
            "          [ 0.3035, -0.6628,  0.0061,  ...,  0.9360, -0.1549,  0.7471],\n",
            "          [ 0.8913, -0.3783,  0.6589,  ...,  1.4942,  0.4232,  0.2374],\n",
            "          ...,\n",
            "          [ 2.5819,  0.7966,  0.5200,  ...,  3.3600,  0.6273,  0.6212],\n",
            "          [ 1.2013,  2.5401,  2.0422,  ..., -0.2838, -0.1670, -0.7981],\n",
            "          [ 0.4973, -0.0358,  0.9509,  ...,  1.0792, -0.4049,  1.4868]],\n",
            "\n",
            "         [[-0.2985,  1.4291,  2.6402,  ...,  0.6169, -0.0450, -0.1314],\n",
            "          [ 0.6106, -0.0909, -0.0509,  ..., -0.1714,  0.1394, -0.6108],\n",
            "          [ 0.2817,  1.3181,  2.1206,  ..., -0.0449, -0.4730, -0.5218],\n",
            "          ...,\n",
            "          [ 0.9603,  0.6310,  1.7401,  ..., -0.0859, -1.1054,  0.4698],\n",
            "          [ 0.3613,  1.7211,  0.2440,  ..., -1.3480, -0.3770, -0.8076],\n",
            "          [-0.6052,  0.1659,  1.6817,  ..., -1.1872,  0.1266,  1.0687]],\n",
            "\n",
            "         [[ 1.2798,  0.7278,  1.3377,  ..., -0.6747,  3.0051,  0.8096],\n",
            "          [ 0.7703,  1.8966,  0.0043,  ...,  3.4118,  3.1911,  0.9453],\n",
            "          [ 1.5060, -0.8731, -0.5952,  ..., -1.5629, -0.5440,  1.1731],\n",
            "          ...,\n",
            "          [ 1.4044,  0.8850,  2.9099,  ..., -0.1675,  1.3854, -0.2860],\n",
            "          [ 2.7999, -0.1719, -0.0925,  ...,  0.4347,  0.3037,  0.0467],\n",
            "          [ 0.5505,  0.7974,  0.8588,  ...,  0.4752,  0.2757,  0.6351]]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([[[[ 5.4827e-01,  2.9114e+00,  3.3816e-01,  ...,  9.3236e-01,\n",
            "            9.9295e-01,  9.2297e-01],\n",
            "          [-4.0870e-01,  2.7830e+00, -2.1958e-01,  ..., -9.2438e-01,\n",
            "            2.3867e+00,  7.1531e-01],\n",
            "          [ 4.6946e-01,  3.1132e+00, -7.1189e-01,  ...,  1.7052e+00,\n",
            "            1.9831e+00,  1.8077e-01],\n",
            "          ...,\n",
            "          [-2.7699e-01,  6.2753e-01, -8.1487e-01,  ...,  1.9350e-01,\n",
            "           -6.3089e-01,  2.3975e+00],\n",
            "          [-1.7028e-01,  2.4327e+00, -1.0585e+00,  ...,  6.3173e-01,\n",
            "            4.1374e-01, -5.1911e-02],\n",
            "          [ 2.6113e-01,  9.2917e-01,  1.1101e-01,  ...,  1.2162e+00,\n",
            "            2.2460e-01, -3.2387e-01]],\n",
            "\n",
            "         [[ 7.3527e-01, -8.7011e-01, -1.2526e+00,  ...,  1.9775e-01,\n",
            "           -1.4347e+00,  1.3941e+00],\n",
            "          [-4.0426e-01, -5.5457e-01, -2.4126e-01,  ...,  1.0921e+00,\n",
            "            8.3954e-01,  1.5716e+00],\n",
            "          [-2.0090e-01, -6.5438e-01, -4.9010e-01,  ...,  3.1672e+00,\n",
            "            5.2122e-01, -4.8867e-04],\n",
            "          ...,\n",
            "          [ 2.9073e+00,  7.7486e-01,  4.3672e-01,  ...,  3.8648e+00,\n",
            "            7.9758e-01,  8.9243e-01],\n",
            "          [-1.8847e-01,  4.4489e+00,  1.7451e+00,  ..., -6.7350e-02,\n",
            "           -1.1694e+00, -8.3400e-01],\n",
            "          [-2.0495e-01, -7.1855e-01,  4.1732e-01,  ...,  6.2638e-01,\n",
            "           -3.8073e-01,  1.0717e+00]],\n",
            "\n",
            "         [[ 1.6624e+00,  2.4109e+00,  3.5473e+00,  ...,  2.6961e+00,\n",
            "            4.7465e-01,  1.5979e+00],\n",
            "          [ 1.8425e+00,  6.7136e-01,  1.3896e+00,  ..., -8.2698e-02,\n",
            "            2.7361e-02,  3.8451e-01],\n",
            "          [ 6.8515e-01,  1.8271e+00,  4.1781e+00,  ..., -8.8026e-01,\n",
            "           -4.9117e-01,  6.1686e-01],\n",
            "          ...,\n",
            "          [ 1.3180e+00,  8.7383e-01,  2.2254e+00,  ..., -1.2141e-01,\n",
            "           -1.8339e+00,  5.0292e-01],\n",
            "          [-2.5892e-01, -4.2471e-01,  4.5799e-01,  ..., -3.0491e-01,\n",
            "            4.4533e-01,  1.6165e+00],\n",
            "          [ 1.1106e-01,  3.7703e-01,  1.7145e+00,  ..., -7.7859e-02,\n",
            "            1.2438e-01,  1.0804e+00]],\n",
            "\n",
            "         [[ 2.3610e+00,  2.2276e+00,  1.5039e+00,  ...,  8.5056e-01,\n",
            "            4.4483e+00,  3.8607e-01],\n",
            "          [ 1.0350e+00,  2.7795e+00, -7.3302e-01,  ...,  3.8529e+00,\n",
            "            4.9328e+00,  1.5713e+00],\n",
            "          [ 1.2934e+00,  1.3638e+00,  8.1593e-02,  ..., -2.3682e+00,\n",
            "           -7.8952e-01,  6.1482e-01],\n",
            "          ...,\n",
            "          [ 1.0453e+00,  4.6917e-01,  3.3785e+00,  ...,  1.1979e+00,\n",
            "            2.2493e+00, -4.5397e-01],\n",
            "          [ 1.9166e+00,  2.1717e+00,  2.6345e-02,  ...,  3.2718e-01,\n",
            "            1.0377e+00, -4.3042e-01],\n",
            "          [ 1.1004e-01,  2.3441e-01,  2.0722e+00,  ...,  5.5647e-02,\n",
            "            1.4793e+00,  9.4031e-01]]]], grad_fn=<AddBackward0>)\n",
            "tensor([[[[-3.5859e-01,  4.1752e+00,  5.5065e-01,  ...,  2.2106e+00,\n",
            "            3.0025e+00,  2.2952e+00],\n",
            "          [ 7.4019e-01,  2.7873e+00, -3.1801e-01,  ..., -1.5156e+00,\n",
            "            3.7244e+00,  8.4610e-01],\n",
            "          [ 8.5316e-01,  3.3658e+00,  1.7045e-01,  ...,  2.6195e+00,\n",
            "            1.6229e+00,  3.9910e-01],\n",
            "          ...,\n",
            "          [-1.6673e-01,  1.0886e+00, -7.4940e-01,  ...,  1.4844e+00,\n",
            "           -6.9410e-01,  2.9505e+00],\n",
            "          [-2.8660e-01,  2.8887e+00,  3.6506e-01,  ...,  1.8239e+00,\n",
            "            8.0341e-01, -1.3272e-01],\n",
            "          [ 7.2117e-01,  9.1208e-01,  3.3243e-01,  ...,  1.1683e+00,\n",
            "            9.4320e-01,  1.0540e-01]],\n",
            "\n",
            "         [[-2.7663e-01,  4.6806e-01, -2.0648e-01,  ...,  1.3425e+00,\n",
            "            1.7489e+00,  1.5437e+00],\n",
            "          [-5.8647e-01, -2.3775e-01,  9.8186e-02,  ...,  8.6589e-01,\n",
            "            1.4610e-01,  2.5029e+00],\n",
            "          [-3.4692e-01, -4.0542e-02, -1.2472e+00,  ...,  2.7305e+00,\n",
            "            9.4407e-01,  5.7569e-01],\n",
            "          ...,\n",
            "          [ 2.1403e+00,  2.4771e+00,  1.8389e-01,  ...,  4.0868e+00,\n",
            "            8.9646e-01,  4.8444e-01],\n",
            "          [-3.9892e-01,  4.3176e+00,  2.1091e+00,  ...,  1.4910e+00,\n",
            "            1.3897e+00,  1.5013e+00],\n",
            "          [ 6.3042e-01,  4.0838e-01,  1.7263e+00,  ...,  2.8182e-01,\n",
            "           -4.2107e-01,  1.7403e+00]],\n",
            "\n",
            "         [[ 2.3221e+00,  3.5476e+00,  5.0034e+00,  ...,  3.6499e+00,\n",
            "            1.5023e+00,  1.7114e+00],\n",
            "          [ 5.3919e-01, -1.3037e+00, -1.0751e-02,  ..., -1.3780e+00,\n",
            "            6.8619e-01,  6.7458e-01],\n",
            "          [ 6.5164e-01,  1.5967e+00,  4.0298e+00,  ..., -2.5912e-01,\n",
            "           -4.6518e-03,  2.1636e-01],\n",
            "          ...,\n",
            "          [ 2.1934e+00,  1.9729e+00,  2.4193e+00,  ...,  1.2549e+00,\n",
            "           -1.4079e+00,  4.0421e-02],\n",
            "          [-5.7264e-01, -3.2355e-01,  1.2138e+00,  ..., -1.3135e-01,\n",
            "           -3.3433e-01,  1.5789e+00],\n",
            "          [-7.9216e-01,  3.4995e-01,  1.4666e+00,  ..., -4.4625e-01,\n",
            "            7.7131e-01,  1.3517e+00]],\n",
            "\n",
            "         [[ 2.6823e+00,  3.6097e+00,  2.4096e+00,  ...,  2.7097e+00,\n",
            "            4.9890e+00,  1.4549e+00],\n",
            "          [ 1.4076e+00,  1.8966e+00, -1.9038e+00,  ...,  2.5185e+00,\n",
            "            5.3891e+00,  3.4908e-02],\n",
            "          [ 1.8183e+00,  7.4523e-01,  5.3081e-01,  ...,  8.8241e-01,\n",
            "            1.0499e+00,  1.0549e+00],\n",
            "          ...,\n",
            "          [ 2.4727e+00,  5.7538e-01,  2.6298e+00,  ...,  2.2116e-01,\n",
            "            4.0242e-01, -4.6853e-01],\n",
            "          [ 1.3706e+00,  1.8395e+00,  2.3397e-01,  ...,  4.4703e-01,\n",
            "            1.4550e+00,  4.4183e-01],\n",
            "          [ 3.5194e-01,  5.5298e-01,  1.5299e+00,  ..., -1.6281e-01,\n",
            "            2.0413e+00,  1.2247e+00]]]], grad_fn=<AddBackward0>)\n",
            "tensor([[[[ 0.0306,  4.0243,  0.3355,  ...,  2.6617,  3.4798,  3.0908],\n",
            "          [ 0.2406,  3.2953,  0.3521,  ..., -0.7998,  3.5391,  2.0587],\n",
            "          [ 1.4055,  3.6877, -0.9607,  ...,  1.2682,  1.8246, -0.3626],\n",
            "          ...,\n",
            "          [ 1.1009,  1.1081,  0.6719,  ...,  0.9498, -0.7480,  3.0485],\n",
            "          [ 0.8064,  3.1108,  0.5377,  ...,  2.8108,  0.6984, -0.6294],\n",
            "          [ 1.7886,  1.6654,  0.0316,  ...,  1.1726,  0.3098,  0.0330]],\n",
            "\n",
            "         [[ 0.5407,  1.4157,  0.5172,  ...,  2.3058,  2.2848,  2.2091],\n",
            "          [ 0.0220, -0.7029, -0.7673,  ...,  2.5533, -1.0058,  2.6285],\n",
            "          [ 0.0759,  0.3345, -0.2158,  ...,  2.8655,  0.2964,  0.2578],\n",
            "          ...,\n",
            "          [ 2.2430,  3.1815,  0.0377,  ...,  4.9309,  1.0070, -0.2974],\n",
            "          [ 0.4764,  5.2314,  1.6532,  ...,  1.7526,  0.9364,  2.0282],\n",
            "          [ 0.2093, -0.0712,  2.2826,  ...,  0.6194, -0.4113,  2.5403]],\n",
            "\n",
            "         [[ 1.9943,  2.6992,  4.6926,  ...,  4.1359,  1.5111,  1.5705],\n",
            "          [ 1.7982,  0.5279,  1.2085,  ..., -0.9342, -0.8455,  1.2880],\n",
            "          [ 0.0770,  1.4534,  3.5128,  ..., -0.7044, -1.1546,  1.7696],\n",
            "          ...,\n",
            "          [ 1.9754,  1.5937,  2.0741,  ...,  1.9109,  0.5643,  1.0341],\n",
            "          [ 0.3311, -0.0393,  1.4576,  ..., -0.2889,  1.3571,  2.3841],\n",
            "          [-0.2134,  1.0540,  2.0277,  ...,  0.5760,  0.8747,  2.4999]],\n",
            "\n",
            "         [[ 1.2526,  3.5877,  2.4527,  ...,  1.5163,  5.2147,  1.3502],\n",
            "          [ 0.6550,  0.8850, -0.1356,  ...,  2.7920,  7.3197,  0.8536],\n",
            "          [ 1.3446, -0.0231, -0.2961,  ...,  0.2997,  1.9820,  1.3435],\n",
            "          ...,\n",
            "          [ 1.7956,  0.5555,  3.0508,  ..., -0.2937,  0.6947, -0.0332],\n",
            "          [ 1.4490,  1.1540,  0.8991,  ...,  0.6215,  0.9483, -0.5922],\n",
            "          [ 0.6984, -0.4237,  0.5464,  ..., -0.7918,  1.3506, -0.0380]]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Passed all tests when n_blocks>2\n",
            "All tests in `test_block_group` passed!\n"
          ]
        }
      ],
      "source": [
        "class BlockGroup(nn.Module):\n",
        "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"An n_blocks-long sequence of ResidualBlock where only the first block uses the provided stride.\"\"\"\n",
        "        super().__init__()\n",
        "        # normal block\n",
        "        self.res_block = ResidualBlock(in_feats, out_feats, first_stride)\n",
        "\n",
        "        # n res blocks without optional part\n",
        "        blocks = []\n",
        "        for _ in range(n_blocks - 1):\n",
        "          blocks.append(ResidualBlock(in_feats=out_feats, out_feats=out_feats))\n",
        "\n",
        "        self.n_res_blocks = nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / first_stride, width / first_stride)\n",
        "        \"\"\"\n",
        "        x = self.res_block(x)\n",
        "        x = self.n_res_blocks(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "tests.test_block_group(BlockGroup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRtj-5ukjBUQ"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class BlockGroup(nn.Module):\n",
        "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"An n_blocks-long sequence of ResidualBlock where only the first block uses the provided stride.\"\"\"\n",
        "        super().__init__()\n",
        "        self.blocks = Sequential(\n",
        "            ResidualBlock(in_feats, out_feats, first_stride),\n",
        "            *[ResidualBlock(out_feats, out_feats) for _ in range(n_blocks - 1)],\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / first_stride, width / first_stride)\n",
        "        \"\"\"\n",
        "        return self.blocks(x)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoeKPAlpjBUQ"
      },
      "source": [
        "### Exercise - implement `ResNet34`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 30-45 minutes on this exercise. This can sometimes involve a lot of fiddly debugging.\n",
        "> ```\n",
        "\n",
        "Last step! Assemble `ResNet34` using the diagram.\n",
        "\n",
        "To test your implementation, you can use the helper function `print_param_count` which prints out a stylized dataframe comparing your model's parameter count to the PyTorch implementation. Alternatively, you can use the following code to import your own `resnet34`, and inspect its architecture:\n",
        "\n",
        "```python\n",
        "resnet = models.resnet34()\n",
        "print(torchinfo.summary(resnet, input_size=(1, 3, 64, 64)))\n",
        "print(torchinfo.summary(my_resnet, input_size=(1, 3, 64, 64)))\n",
        "```\n",
        "\n",
        "Both will give you the shape & size of each of your model's parameters & buffers, and code is provided for both of these methods below.\n",
        "\n",
        "Note - in order to copy weights from the reference model to your implementation (which we'll do after this exercise), you'll need to have all the parameters defined in the same order as they are in the reference model - in other words, the rows from the two halves of the dataframe created via `print_param_count` should perfectly match up with each other. This can be a bit fiddly to get right, especially if the names of your parameters are different to the names in the PyTorch implementation. We recommend you look at the `__init__` methods of the solution if you're stuck (since it's the order that things are defined in for the various ResNet modules which determines the order of the rows in the dataframe).\n",
        "\n",
        "This 1-to-1 weight comparison won't always be possible during model replications, for example when we replicate GPT2-Small next week we'll be defining the attention weight matrices differently (in a way that's more condusive to interpretability research). In these cases, you'll need to resort to different debugging methods, like running the models on the same input and checking they give the same output. You can also break this down into smaller steps by running individual models, and by checking the shape before checking values. However in this case we don't need to resort to that, because our implementation is equivalent to the reference model's implementation.\n",
        "\n",
        "As a more general point, tweaking your model until all the layers match up might be a difficult and frustrating exercise at times, however it's a pretty good example of the kind of low-level model implementation and debugging that is important for your growth as ML engineers! So don't be disheartened if you find it hard to get exactly right (although we certainly recommend looking at the solutions and moving on if you're stuck on this particular exercise for more than ~45 minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f7NyxrEjBUQ"
      },
      "outputs": [],
      "source": [
        "class ResNet34(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_blocks_per_group=[3, 4, 6, 3],\n",
        "        out_features_per_group=[64, 128, 256, 512],\n",
        "        first_strides_per_group=[1, 2, 2, 2],\n",
        "        n_classes=1000,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        in_feats0 = 64\n",
        "        self.n_blocks_per_group = n_blocks_per_group\n",
        "        self.out_features_per_group = out_features_per_group\n",
        "        self.first_strides_per_group = first_strides_per_group\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # YOUR CODE HERE - define all components of resnet34\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, n_classes)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "my_resnet = ResNet34()\n",
        "\n",
        "# (1) Test via helper function `print_param_count`\n",
        "target_resnet = models.resnet34()  # without supplying a `weights` argument, we just initialize with random weights\n",
        "utils.print_param_count(my_resnet, target_resnet)\n",
        "\n",
        "# (2) Test via `torchinfo.summary`\n",
        "print(\"My model:\", torchinfo.summary(my_resnet, input_size=(1, 3, 64, 64)), sep=\"\\n\")\n",
        "print(\"\\nReference model:\", torchinfo.summary(target_resnet, input_size=(1, 3, 64, 64), depth=2), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf_bXp6hjBUQ"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to construct each of the BlockGroups.</summary>\n",
        "\n",
        "Each BlockGroup takes arguments `n_blocks`, `in_feats`, `out_feats` and `first_stride`. In the initialisation of `ResNet34` below, we're given a list of `n_blocks`, `out_feats` and `first_stride` for each of the BlockGroups. To find `in_feats` for each block, it suffices to note two things:\n",
        "    \n",
        "1. The first `in_feats` should be 64, because the input is coming from the convolutional layer with 64 output channels.\n",
        "2. The `out_feats` of each layer should be equal to the `in_feats` of the subsequent layer (because the BlockGroups are stacked one after the other; with no operations in between to change the shape).\n",
        "\n",
        "You can use these two facts to construct a list `in_features_per_group`, and then create your BlockGroups by zipping through all four lists.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm not sure how to construct the 7x7 conv at the very start.</summary>\n",
        "\n",
        "The stride, padding & output channels are givin in the diagram; the only thing not provided is `in_channels`. Recall that the input to this layer is an RGB image - can you deduce from this how many input channels your layer should have?\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm getting the right total parameter count, but my rows don't match up, and I'm not sure how to debug this.</summary>\n",
        "\n",
        "We'll use an example case to illustrate how to debug this. In the following case, our rows match up until the 21st row where we have our first discrepancy:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/row-diff.png\" width=\"1000\">\n",
        "\n",
        "We can see that the first discrepancy occurs at the first parameter from `residual_layers.1`, meaning something in the second `BlockGroup` in our sequential of blockgroups. We can see that the first blockgroup only had left branches but no right branches (this is because for the very first blockgroup we had `in_feats == out_feats == 64` and also `first_strides_per_group[0] == 1`, meaning this first blockgroup was shape-preserving and it didn't need a right branch). So it's the presence of a right branch that's causing the mismatch.\n",
        "\n",
        "Looking closer at the dataframe, we see that the left-hand parameter (from our model) has shape `(128, 64, 1, 1)` and has `right` in its name, so we deduce it's the 1x1 convolutional weight from the right branch. But the parameter from the PyTorch model has shape `(128, 64, 3, 3)`, i.e. it's a convolutional weight with a 3x3 kernel, so must be from the left branch (it also matches the naming convention for the left-branch convolutional weight from the first blockgroup - row index 3 in the dataframe). So we've now figured out what the problem is: **your implementation defines the right branch before the left branch in the the `ResidualBlock.__init__` method, and to match param orders with the PyTorch model you should swap them around.**\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ResNet34(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_blocks_per_group=[3, 4, 6, 3],\n",
        "        out_features_per_group=[64, 128, 256, 512],\n",
        "        first_strides_per_group=[1, 2, 2, 2],\n",
        "        n_classes=1000,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        in_feats0 = 64\n",
        "        self.n_blocks_per_group = n_blocks_per_group\n",
        "        self.out_features_per_group = out_features_per_group\n",
        "        self.first_strides_per_group = first_strides_per_group\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.in_layers = Sequential(\n",
        "            Conv2d(3, in_feats0, kernel_size=7, stride=2, padding=3),\n",
        "            BatchNorm2d(in_feats0),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "        residual_layers = []\n",
        "        for i in range(len(n_blocks_per_group)):\n",
        "            residual_layers.append(\n",
        "                BlockGroup(\n",
        "                    n_blocks=n_blocks_per_group[i],\n",
        "                    in_feats=[64, *self.out_features_per_group][i],\n",
        "                    out_feats=self.out_features_per_group[i],\n",
        "                    first_stride=self.first_strides_per_group[i],\n",
        "                )\n",
        "            )\n",
        "        self.residual_layers = Sequential(*residual_layers)\n",
        "\n",
        "        self.out_layers = Sequential(\n",
        "            AveragePool(),\n",
        "            Linear(out_features_per_group[-1], n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, n_classes)\n",
        "        \"\"\"\n",
        "        post_first_conv_block = self.in_layers(x)\n",
        "        post_block_groups = self.residual_layers(post_first_conv_block)\n",
        "        logits = self.out_layers(post_block_groups)\n",
        "        return logits\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGvDIe3UjBUQ"
      },
      "source": [
        "### Copying over weights\n",
        "\n",
        "Now that you've built your `ResNet34`, we'll copy weights over from PyTorch's pretrained resnet to yours. This is another good way to verify that you've designed the architecture correctly (although if you've passed all tests above and your parameter count order matches up, it's very likely that this code will also work)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoL_Jg8jjBUQ"
      },
      "outputs": [],
      "source": [
        "def copy_weights(my_resnet: ResNet34, pretrained_resnet: models.resnet.ResNet) -> ResNet34:\n",
        "    \"\"\"Copy over the weights of `pretrained_resnet` to your resnet.\"\"\"\n",
        "\n",
        "    # Get the state dictionaries for each model, check they have the same number of parameters & buffers\n",
        "    mydict = my_resnet.state_dict()\n",
        "    pretraineddict = pretrained_resnet.state_dict()\n",
        "    assert len(mydict) == len(pretraineddict), \"Mismatching state dictionaries.\"\n",
        "\n",
        "    # Define a dictionary mapping the names of your parameters / buffers to their values in the pretrained model\n",
        "    state_dict_to_load = {\n",
        "        mykey: pretrainedvalue\n",
        "        for (mykey, myvalue), (pretrainedkey, pretrainedvalue) in zip(mydict.items(), pretraineddict.items())\n",
        "    }\n",
        "\n",
        "    # Load in this dictionary to your model\n",
        "    my_resnet.load_state_dict(state_dict_to_load)\n",
        "\n",
        "    return my_resnet\n",
        "\n",
        "\n",
        "pretrained_resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1).to(device)\n",
        "my_resnet = copy_weights(my_resnet, pretrained_resnet).to(device)\n",
        "print(\"Weights copied successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTl0ji4bjBUQ"
      },
      "source": [
        "This function uses the `state_dict()` method, which returns an  `OrderedDict` (documentation [here](https://realpython.com/python-ordereddict/)) object containing all the parameter/buffer names and their values. State dicts can be extracted from models, saved to your filesystem (this is a common way to store the results of training a model), and can also be loaded back into a model using the `load_state_dict` method. (Note that you can also load weights using a regular Python `dict`, but since Python 3.7, the builtin `dict` is guaranteed to maintain items in the order they're inserted.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob6sea_yjBUQ"
      },
      "source": [
        "## Running Your Model\n",
        "\n",
        "We've provided you with some images for your model to classify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj_5PwZ9jBUQ"
      },
      "outputs": [],
      "source": [
        "IMAGE_FILENAMES = [\n",
        "    \"chimpanzee.jpg\",\n",
        "    \"golden_retriever.jpg\",\n",
        "    \"platypus.jpg\",\n",
        "    \"frogs.jpg\",\n",
        "    \"fireworks.jpg\",\n",
        "    \"astronaut.jpg\",\n",
        "    \"iguana.jpg\",\n",
        "    \"volcano.jpg\",\n",
        "    \"goofy.jpg\",\n",
        "    \"dragonfly.jpg\",\n",
        "]\n",
        "\n",
        "IMAGE_FOLDER = section_dir / \"resnet_inputs\"\n",
        "\n",
        "images = [Image.open(IMAGE_FOLDER / filename) for filename in IMAGE_FILENAMES]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6ZpFY0FjBUQ"
      },
      "source": [
        "Our `images` are of type `PIL.Image.Image`, so we can just call them in a cell to display them, or alternatively use a function like IPython's `display`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIw3-EK8jBUQ"
      },
      "outputs": [],
      "source": [
        "display(images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckcsww3hjBUQ"
      },
      "source": [
        "We now need to define a `transform` object like we did for MNIST. We will use the same transforms to convert the PIL image to a tensor, and to normalize it. But we also want to resize the images to `height=224, width=224`, because not all of them start out with this size and we need them to be consistent before passing them through our model.\n",
        "\n",
        "In the normalization step, we'll use a mean of `[0.485, 0.456, 0.406]`, and a standard deviation of `[0.229, 0.224, 0.225]` (these are the mean and std dev of images from [ImageNet](https://www.image-net.org/)). Note that the means and std devs have three elements, because ImageNet contains RGB rather than monochrome images, and we're normalising over each of the three RGB channels separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWkEk7fUjBUQ"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "IMAGENET_TRANSFORM = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prepared_images = t.stack([IMAGENET_TRANSFORM(img) for img in images], dim=0).to(device)\n",
        "assert prepared_images.shape == (len(images), 3, IMAGE_SIZE, IMAGE_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmZna3XejBUQ"
      },
      "source": [
        "### Exercise - verify your model's predictions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Lastly, you should run your model with these prepared images, and verify that your predictions are the same as the model's predictions.\n",
        "\n",
        "You can do this by filling in the `predict` function below, then running the code. We've also provided you with a file `imagenet_labels.json` which you can use to get the actual classnames of imagenet data, and see what your model's predictions actually are.\n",
        "\n",
        "When you run the code, you should find that your top prediction probabilities are within about 0.01% of the reference model's probabilities most (not all) of the time. This kind of error is not uncommon when you have slightly different orders of linear operations or small implementation details which differ between models, and which can introduce floating point errors that compound as we move through the model. As a bonus exercise (which may or may not break your sanity), you're welcome to try and work through our implementation, comparing it to the PyTorch model's implementation and find where the discrepancy comes from!\n",
        "\n",
        "*Tip - the torch method `torch.max` will return a tuple of (values, indices) if you supply a dimension argument `dim`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VHNYmPTjBUR"
      },
      "outputs": [],
      "source": [
        "@t.inference_mode()\n",
        "def predict(\n",
        "    model: nn.Module, images: Float[Tensor, \"batch rgb h w\"]\n",
        ") -> tuple[Float[Tensor, \"batch\"], Int[Tensor, \"batch\"]]:\n",
        "    \"\"\"\n",
        "    Returns the maximum probability and predicted class for each image, as a tensor of floats and ints respectively.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "with open(section_dir / \"imagenet_labels.json\") as f:\n",
        "    imagenet_labels = list(json.load(f).values())\n",
        "\n",
        "# Check your predictions match those of the pretrained model\n",
        "my_probs, my_predictions = predict(my_resnet, prepared_images)\n",
        "pretrained_probs, pretrained_predictions = predict(pretrained_resnet, prepared_images)\n",
        "assert (my_predictions == pretrained_predictions).all()\n",
        "t.testing.assert_close(my_probs, pretrained_probs, atol=5e-4, rtol=0)  # tolerance of 0.05%\n",
        "print(\"All predictions match!\")\n",
        "\n",
        "# Print out your predictions, next to the corresponding images\n",
        "for i, img in enumerate(images):\n",
        "    table = Table(\"Model\", \"Prediction\", \"Probability\")\n",
        "    table.add_row(\"My ResNet\", imagenet_labels[my_predictions[i]], f\"{my_probs[i]:.3%}\")\n",
        "    table.add_row(\"Reference Model\", imagenet_labels[pretrained_predictions[i]], f\"{pretrained_probs[i]:.3%}\")\n",
        "    rprint(table)\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqZ-CAOpjBUR"
      },
      "source": [
        "<details>\n",
        "<summary>Help! My model is predicting roughly the same percentage for every category!</summary>\n",
        "\n",
        "This can indicate that your model weights are randomly initialized, meaning the weight loading process didn't actually take. Or, you reinitialized your model by accident after loading the weights.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@t.inference_mode()\n",
        "def predict(\n",
        "    model: nn.Module, images: Float[Tensor, \"batch rgb h w\"]\n",
        ") -> tuple[Float[Tensor, \"batch\"], Int[Tensor, \"batch\"]]:\n",
        "    \"\"\"\n",
        "    Returns the maximum probability and predicted class for each image, as a tensor of floats and ints respectively.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    logits = model(images)\n",
        "    probabilities = logits.softmax(dim=-1)\n",
        "    return probabilities.max(dim=-1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkLlVXrdjBUR"
      },
      "source": [
        "If you've done everything correctly, your version should give the same classifications, and the percentages should match at least to a couple decimal places.\n",
        "\n",
        "If it does, congratulations, you've now run an entire ResNet, using barely any code from `torch.nn`! The only things we used were `nn.Module` and `nn.Parameter`.\n",
        "\n",
        "If it doesn't, you get to practice model debugging! Remember to use the `utils.print_param_count` function that was provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpA7i8hWjBUR"
      },
      "source": [
        "### Aside - hooks\n",
        "\n",
        "One problem you might have encountered is that your model outputs `NaN`s rather than actual numbers. When debugging this, it's useful to try and identify which module the error first appears in. This is a great use-case for **hooks**, which are something we'll be digging a lot more into during our mechanistic interpretability exercises later on.\n",
        "\n",
        "A hook is basically a function which you can attach to a particular `nn.Module`, which gets executed during your model's forward or backward passes. Here, we'll only consider forward hooks. A hook function's type signature is:\n",
        "\n",
        "```python\n",
        "def hook(module: nn.Module, inputs: list[t.Tensor], output: t.Tensor) -> None:\n",
        "    pass\n",
        "```\n",
        "\n",
        "The `inputs` argument is a list of the inputs to the module (often just one tensor), and the `output` argument is the output of the module. This hook gets registered to a module by calling `module.register_forward_hook(hook)`. During forward passes, the hook function will run.\n",
        "\n",
        "Here is some code which will check for `NaN`s in the output of each module, and raise a `ValueError` if it finds any. We've also given you an example tiny network which produces a `NaN` in the output of the second layer, to demonstrate it on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n4EvHKzjBUR"
      },
      "outputs": [],
      "source": [
        "class NanModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Define a module that always returns NaNs (we will use hooks to identify this error).\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return t.full_like(x, float(\"nan\"))\n",
        "\n",
        "\n",
        "def hook_check_for_nan_output(module: nn.Module, input: tuple[Tensor], output: Tensor) -> None:\n",
        "    \"\"\"\n",
        "    Hook function which detects when the output of a layer is NaN.\n",
        "    \"\"\"\n",
        "    if t.isnan(output).any():\n",
        "        raise ValueError(f\"NaN output from {module}\")\n",
        "\n",
        "\n",
        "def add_hook(module: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Register our hook function in a module.\n",
        "\n",
        "    Use model.apply(add_hook) to recursively apply the hook to model and all submodules.\n",
        "    \"\"\"\n",
        "    module.register_forward_hook(hook_check_for_nan_output)\n",
        "\n",
        "\n",
        "def remove_hooks(module: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Remove all hooks from module.\n",
        "\n",
        "    Use module.apply(remove_hooks) to do this recursively.\n",
        "    \"\"\"\n",
        "    module._backward_hooks.clear()\n",
        "    module._forward_hooks.clear()\n",
        "    module._forward_pre_hooks.clear()\n",
        "\n",
        "\n",
        "# Create our model with a NaN in the middle, and apply a hook function to it which checks for NaNs\n",
        "model = nn.Sequential(nn.Identity(), NanModule(), nn.Identity())\n",
        "model = model.apply(add_hook)\n",
        "\n",
        "# Run the model, and and our hook function should raise an error that gets caught by the try-except\n",
        "try:\n",
        "    input = t.randn(3)\n",
        "    output = model(input)\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "\n",
        "# Remove hooks at the end\n",
        "model = model.apply(remove_hooks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBg9yltzjBUR"
      },
      "source": [
        "When you run this code, you should find it raising an error at the `NanModule`.\n",
        "\n",
        "\n",
        "> Important - when you're working with PyTorch hooks, make sure you **remember to remove them at the end of each use**! This is a classic source of bugs, and one of the things that make PyTorch hooks so janky. When we study TransformerLens in the next chapter, we'll use a version of hooks that is essentially the same under the hood, but comes with quite a few quality of life improvements!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXL1UZH4jBUR"
      },
      "source": [
        "# ☆ Bonus - Feature Extraction\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand the difference between feature extraction and finetuning\n",
        "> * Perform feature extraction on a pre-trained ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XQ-NkXXjBUR"
      },
      "source": [
        "Now that you've seen how to build a modular training loop, and you've seen how ResNet works and is built, we're going to put these two things together to finetune a ResNet model on a new dataset.\n",
        "\n",
        "**Finetuning** can mean slightly different things in different contexts, but broadly speaking it means using the weights of an already trained network as the starting values for training a new network. Because training networks from scratch is very computationally expensive, this is a common practice in ML.\n",
        "\n",
        "The specific type of finetuning we'll be doing here is called **feature extraction**. This is when we freeze most layers of a model except the last few, and perform gradient descent on those. We call this feature extraction because the earlier layers of the model have already learned to identify important features of the data (and these features are also relevant for the new task), so all that we have to do is train a few final layers in the model to extract these features.\n",
        "\n",
        "*Terminology note - sometimes feature extraction and finetuning are defined differently, with finetuning referring to the training of all the weights in a pretrained model (usually with a small or decaying learning rate), and feature extraction referring to the freezing of some layers and training of others. To avoid confusion here, we'll use the term \"feature extraction\" rather than \"finetuning\".*\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/feature_extraction.png\" width=\"400\">\n",
        "\n",
        "How do we prepare a model for feature extraction? By **freezing layers** of our model.\n",
        "\n",
        "We'll discuss freezing layers & the backpropagation algorithm in much more detail tomorrow, but for now it's fine to just understand what's going on at a basic level. When we call `loss.backward()` in our training loop (or when this is implicitly called by our PyTorch Lightning trainer), this propagates gradients from our `loss` scalar back to all parameters in our model. If a parameter has its `requires_grad` attribute set to `False`, it means gradients won't be computed for this tensor during backpropagation. Thanks to PyTorch helpfully keeping track of the parameters which require gradients (using a structure called the **computational graph**), if we set `requires_grad = False` for the first few layers of parameters in our model, PyTorch will actually save us time and compute by not calculating gradients for these parameters at all.\n",
        "\n",
        "See the code below as an example of how gradient propagation stops at tensors with `requires_grad = False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NniVShj_jBUR"
      },
      "outputs": [],
      "source": [
        "layer0, layer1 = nn.Linear(3, 4), nn.Linear(4, 5)\n",
        "\n",
        "layer0.requires_grad_(False)  # generic code to set `param.requires_grad=False` recursively for a module / entire model\n",
        "\n",
        "x = t.randn(3)\n",
        "out = layer1(layer0(x)).sum()\n",
        "out.backward()\n",
        "\n",
        "assert layer0.weight.grad is None\n",
        "assert layer1.weight.grad is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihl5hAAIjBUR"
      },
      "source": [
        "### Exercise - prepare ResNet for feature extraction\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "First, you should complete the function below to do the following:\n",
        "\n",
        "* Instantiate a `ResNet34` model using your class, and copy in weights from a pretrained model (you can use code from earlier here)\n",
        "* Disable gradients for all layers\n",
        "* Replace the final linear layer with a new linear layer, which has the same number of `in_features`, but a different number of `out_features` (given by the `n_classes` argument)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9U-w8lejBUR"
      },
      "outputs": [],
      "source": [
        "def get_resnet_for_feature_extraction(n_classes: int) -> ResNet34:\n",
        "    \"\"\"\n",
        "    Creates a ResNet34 instance, replaces its final linear layer with a classifier for `n_classes` classes, and freezes\n",
        "    all weights except the ones in this layer.\n",
        "\n",
        "    Returns the ResNet model.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_get_resnet_for_feature_extraction(get_resnet_for_feature_extraction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmMmGjbfjBUR"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def get_resnet_for_feature_extraction(n_classes: int) -> ResNet34:\n",
        "    \"\"\"\n",
        "    Creates a ResNet34 instance, replaces its final linear layer with a classifier for `n_classes` classes, and freezes\n",
        "    all weights except the ones in this layer.\n",
        "\n",
        "    Returns the ResNet model.\n",
        "    \"\"\"\n",
        "    # Create a ResNet34 with the default number of classes\n",
        "    my_resnet = ResNet34()\n",
        "\n",
        "    # Load the pretrained weights\n",
        "    pretrained_resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # Copy the weights over\n",
        "    my_resnet = copy_weights(my_resnet, pretrained_resnet)\n",
        "\n",
        "    # Freeze gradients for all layers (note that when we redefine the last layer, it will be unfrozen)\n",
        "    my_resnet.requires_grad_(False)\n",
        "\n",
        "    # Redefine last layer\n",
        "    my_resnet.out_layers[-1] = Linear(my_resnet.out_features_per_group[-1], n_classes)\n",
        "\n",
        "    return my_resnet\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xFWfEyDjBUR"
      },
      "source": [
        "We'll now give you some boilerplate code to load in and transform your data (this is pretty similar to the MNIST code)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLaF_0mKjBUR"
      },
      "outputs": [],
      "source": [
        "def get_cifar() -> tuple[datasets.CIFAR10, datasets.CIFAR10]:\n",
        "    \"\"\"Returns CIFAR-10 train and test sets.\"\"\"\n",
        "    cifar_trainset = datasets.CIFAR10(exercises_dir / \"data\", train=True, download=True, transform=IMAGENET_TRANSFORM)\n",
        "    cifar_testset = datasets.CIFAR10(exercises_dir / \"data\", train=False, download=True, transform=IMAGENET_TRANSFORM)\n",
        "    return cifar_trainset, cifar_testset\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ResNetTrainingArgs:\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 5\n",
        "    learning_rate: float = 1e-3\n",
        "    n_classes: int = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9kgvI0UjBUR"
      },
      "source": [
        "The dataclass we've defined containing training arguments is basically the same as the one we had for the convnet, the main difference is that we're now using the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). This is the dataset we'll be training our model on. It consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. See the link for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9GO6tYjjBUR"
      },
      "source": [
        "### Exercise - write training loop for feature extraction\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "We now come to the final task - write a training loop for your ResNet model. This shouldn't be too difficult because most of the code can be directly taken from the exercise in section 2️⃣, however there are a few changes you should take note of:\n",
        "\n",
        "- Since all other parameters' gradients have been frozen, it doesn't really matter which parameters you pass to your optimizer. However, note that you have the option of passing just a subset of parameters using e.g. `AdamW(model.some_module.parameters(), ...)`.\n",
        "- Now that we're working with batchnorm, you'll have to call `model.train()` and `model.eval()` before your training and validation loops (recall that the behaviour of batchnorm changes between training and eval modes).\n",
        "- Make sure you're connected to GPU runtime rather than CPU, otherwise this training might take quite a while.\n",
        "- Also make sure you're logging progress within each epoch, since the epochs might each take a while (although we've given you the `get_cifar_subset` function which returns a subset of the CIFAR10 data, and we recommend using this function with default parameters so that each epoch is a bit faster)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz8BtxfujBUR"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "def get_cifar_subset(trainset_size: int = 10_000, testset_size: int = 1_000) -> tuple[Subset, Subset]:\n",
        "    \"\"\"Returns a subset of CIFAR-10 train and test sets (slicing the first examples from the datasets).\"\"\"\n",
        "    cifar_trainset, cifar_testset = get_cifar()\n",
        "    return Subset(cifar_trainset, range(trainset_size)), Subset(cifar_testset, range(testset_size))\n",
        "\n",
        "\n",
        "def train(args: ResNetTrainingArgs) -> tuple[list[float], list[float], ResNet34]:\n",
        "    \"\"\"\n",
        "    Performs feature extraction on ResNet, returning the model & lists of loss and accuracy.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE - write your train function for feature extraction\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "args = ResNetTrainingArgs()\n",
        "loss_list, accuracy_list, model = train(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsZIzFzzjBUR"
      },
      "outputs": [],
      "source": [
        "line(\n",
        "    y=[loss_list, [1 / args.n_classes] + accuracy_list],  # we start by assuming a uniform accuracy of 10%\n",
        "    use_secondary_yaxis=True,\n",
        "    x_max=args.epochs * 10_000,\n",
        "    labels={\"x\": \"Num examples seen\", \"y1\": \"Cross entropy loss\", \"y2\": \"Test Accuracy\"},\n",
        "    title=\"ResNet Feature Extraction\",\n",
        "    width=800,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw1WV4evjBUR"
      },
      "source": [
        "<details>\n",
        "<summary>Spoilers - what kind of results should you get?</summary>\n",
        "\n",
        "If you train the whole model rather than just the final layer, you should find accuracy increases very slowly, not getting very far above random chance. This reflects the fact that the model is trying to learn a new task (classifying images into 10 classes) from scratch, rather than just learning to extract features from images, and this takes a long time!\n",
        "\n",
        "If you train just the final layer, your accuracy should reach around 70-80% by the first epoch. This is because the model is already very good at extracting features from images, and it just needs to learn how to turn these features into predictions for this new set of classes.\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "def get_cifar_subset(trainset_size: int = 10_000, testset_size: int = 1_000) -> tuple[Subset, Subset]:\n",
        "    \"\"\"Returns a subset of CIFAR-10 train and test sets (slicing the first examples from the datasets).\"\"\"\n",
        "    cifar_trainset, cifar_testset = get_cifar()\n",
        "    return Subset(cifar_trainset, range(trainset_size)), Subset(cifar_testset, range(testset_size))\n",
        "\n",
        "\n",
        "def train(args: ResNetTrainingArgs) -> tuple[list[float], list[float], ResNet34]:\n",
        "    \"\"\"\n",
        "    Performs feature extraction on ResNet, returning the model & lists of loss and accuracy.\n",
        "    \"\"\"\n",
        "    model = get_resnet_for_feature_extraction(args.n_classes).to(device)\n",
        "\n",
        "    trainset, testset = get_cifar_subset()\n",
        "    trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
        "    testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.out_layers[-1].parameters(), lr=args.learning_rate)\n",
        "\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        for imgs, labels in (pbar := tqdm(trainloader)):\n",
        "            # Move data to device, perform forward pass\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            # Calculate loss, perform backward pass\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update logs & progress bar\n",
        "            loss_list.append(loss.item())\n",
        "            pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        num_correct_classifications = 0\n",
        "        for imgs, labels in testloader:\n",
        "            # Move data to device, perform forward pass in inference mode\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with t.inference_mode():\n",
        "                logits = model(imgs)\n",
        "\n",
        "            # Compute num correct by comparing argmaxed logits to true labels\n",
        "            predictions = t.argmax(logits, dim=1)\n",
        "            num_correct_classifications += (predictions == labels).sum().item()\n",
        "\n",
        "        # Compute & log total accuracy\n",
        "        accuracy = num_correct_classifications / len(mnist_testset)\n",
        "        accuracy_list.append(accuracy)\n",
        "\n",
        "    return loss_list, accuracy_list, model\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0Qbzi6hjBUR"
      },
      "source": [
        "# ☆ Bonus - Convolutions From Scratch\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand how array strides work, and why they're important for efficient linear operations\n",
        "> * Learn how to use `as_strided` to perform simple linear operations like trace and matrix multiplication\n",
        "> * Implement your own convolutions and maxpooling functions using stride-based methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKcm8AfIjBUR"
      },
      "source": [
        "This section is designed to get you familiar with the implementational details of layers like `Linear` and `Conv2d`. You'll be using libraries like `einops`, and functions like `torch.as_strided` to get a very low-level picture of how these operations work, which will help build up your overall understanding.\n",
        "\n",
        "Note that `torch.as_strided` isn't something which will come up explicitly in much of the rest of the course (unlike `einops`). The purpose of the stride exercises is more to give you an appreciation for what's going on under the hood, so that we can build layers of abstraction on top of that during the rest of this week (and by extension this course). I see this as analogous to how [many CS courses](https://cs50.harvard.edu/x/2023/) start by teaching you about languages like C and concepts like pointers and memory management before moving on to higher-level langauges like Python which abstract away these details. The hope is that when you get to the later sections of the course, you'll have the tools to understand them better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jei25WV9jBUR"
      },
      "source": [
        "## Reading\n",
        "\n",
        "* [Python NumPy, 6.1 - `as_strided()`](https://www.youtube.com/watch?v=VlkzN00P0Bc) explains what array strides are.\n",
        "* [`as_strided` and `sum` are all you need](https://jott.live/markdown/as_strided) gives an overview of how to use `as_strided` to perform array operations.\n",
        "* [Advanced NumPy: Master stride tricks with 25 illustrated exercises](https://towardsdatascience.com/advanced-numpy-master-stride-tricks-with-25-illustrated-exercises-923a9393ab20) provides several clear and intuitive examples of `as_strided` being used to construct arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-1QEmzWjBUR"
      },
      "source": [
        "## Basic stride exercises\n",
        "\n",
        "Array strides, and the `as_strided` method, are important to understand well because lots of linear operations are actually implementing something like `as_strided` under the hood.\n",
        "\n",
        "Run the following code, to define this tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR45lSoFjBUS"
      },
      "outputs": [],
      "source": [
        "test_input = t.tensor(\n",
        "    [\n",
        "        [0, 1, 2, 3, 4],\n",
        "        [5, 6, 7, 8, 9],\n",
        "        [10, 11, 12, 13, 14],\n",
        "        [15, 16, 17, 18, 19],\n",
        "    ],\n",
        "    dtype=t.float,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-iKkEfpjBUS"
      },
      "source": [
        "This tensor is stored in a contiguous block in computer memory.\n",
        "\n",
        "We can call the `stride` method to get the strides of this particular array. Running `test_input.stride()`, we get `(5, 1)`. This means that we need to skip over one element in the storage of this tensor to get to the next element in the row, and 5 elements to get the next element in the column (because you have to jump over all 5 elements in the row). Another way of phrasing this: the `n`th element in the stride is the number of elements we need to skip over to move one index position in the `n`th dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDrLYaxPjBUS"
      },
      "source": [
        "### Exercise - fill in the correct size and stride\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to ~30 minutes on these exercises collectively.\n",
        "> Strides can be confusing and fiddly, so you should be willing to look at the solution if you're stuck! They are not the most important part of the material today.\n",
        "> ```\n",
        "\n",
        "In the exercises below, we will work with the `test_input` tensor above. You should fill in the `size` and `stride` arguments so that calling `test_input.as_strided` with these arguments produces the desired output. When you run the cell, the `for` loop at the end will iterate through the test cases and print out whether the test passed or failed.\n",
        "\n",
        "We've already filled in the first two as an example, along with illustrations explaining what's going on:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/strides3c.png\" width=\"700\">\n",
        "\n",
        "By the end of these examples, hopefully you'll have a clear idea of what's going on. If you're still confused by some of these, then the dropdown below the codeblock contains some annotations to explain the answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tH7inLUjBUS"
      },
      "outputs": [],
      "source": [
        "TestCase = namedtuple(\"TestCase\", [\"output\", \"size\", \"stride\"])\n",
        "\n",
        "test_cases = [\n",
        "    # Example 1\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3]),\n",
        "        size=(4,),\n",
        "        stride=(1,),\n",
        "    ),\n",
        "    # Example 2\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 2], [5, 7]]),\n",
        "        size=(2, 2),\n",
        "        stride=(5, 2),\n",
        "    ),\n",
        "    # Start of exercises (you should fill in size & stride for all 6 of these):\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3, 4]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 5, 10, 15]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [5, 6, 7]]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [10, 11, 12]]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 0, 0], [11, 11, 11]]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 6, 12, 18]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "for i, test_case in enumerate(test_cases):\n",
        "    if (test_case.size is None) or (test_case.stride is None):\n",
        "        print(f\"Test {i} failed: attempt missing.\")\n",
        "    else:\n",
        "        actual = test_input.as_strided(size=test_case.size, stride=test_case.stride)\n",
        "        if (test_case.output != actual).any():\n",
        "            print(f\"Test {i} failed\\n  Expected: {test_case.output}\\n  Actual: {actual}\")\n",
        "        else:\n",
        "            print(f\"Test {i} passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKaHnmSEjBUS"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "test_cases = [\n",
        "    # Example 1\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3]),\n",
        "        size=(4,),\n",
        "        stride=(1,),\n",
        "    ),\n",
        "    # Example 2\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 2], [5, 7]]),\n",
        "        size=(2, 2),\n",
        "        stride=(5, 2),\n",
        "    ),\n",
        "    # Start of exercises (you should fill in size & stride for all 6 of these):\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3, 4]),\n",
        "        size=(5,),\n",
        "        stride=(1,),\n",
        "    ),\n",
        "    # # Explanation: the tensor is held in a contiguous memory block. When you get to the end of one row, a single\n",
        "    # # stride jumps to the start of the next row\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 5, 10, 15]),\n",
        "        size=(4,),\n",
        "        stride=(5,),\n",
        "    ),\n",
        "    # # Explanation: this is same as previous case, only now you're moving in colspace (i.e. skipping 5 elements) each\n",
        "    # # time you move one element across the output tensor. So stride is 5 rather than 1\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [5, 6, 7]]),\n",
        "        size=(2, 3),\n",
        "        stride=(5, 1),\n",
        "    ),\n",
        "    # # Explanation: as you move one column to the right in the output tensor, you want to jump one element in `test_input`\n",
        "    # # (since you're just going one column to the right). As you move one row down in the output tensor, you want to jump\n",
        "    # # down one row in `test_input` (which is equivalent to a stride of 5, because we're jumping 5 elements).\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [10, 11, 12]]),\n",
        "        size=(2, 3),\n",
        "        stride=(10, 1),\n",
        "    ),\n",
        "    # # Explanation: same as previous, except now we're jumping over 10 elements (2 rows of 5 elements) each time we\n",
        "    # # move down in the output tensor.\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 0, 0], [11, 11, 11]]),\n",
        "        size=(2, 3),\n",
        "        stride=(11, 0),\n",
        "    ),\n",
        "    # # Explanation: we're copying horizontally, i.e. we don't move in the original tensor when we step right in the\n",
        "    # # output tensor, so the stride is 0 (this is a very important case to understand for the later exercises, since\n",
        "    # # it's effectively our way of doing an einops.repeat operation!). As we move one row down, we're jumping over 11\n",
        "    # # elements in the original tensor (going from 0 to 11).\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 6, 12, 18]),\n",
        "        size=(4,),\n",
        "        stride=(6,),\n",
        "    ),\n",
        "    # Explanation: we're effectively taking the diagonal elements of the original tensor here, since we're creating a\n",
        "    # 1D tensor with stride equal to (row_stride + col_stride) of the original tensor.\n",
        "]\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxcpBvqJjBUS"
      },
      "source": [
        "## Intermediate stride exercises\n",
        "\n",
        "Now that you're comfortable with the basics, we'll dive a little deeper with `as_strided`. In the last few exercises of this section, you'll start to implement some more challenging stride functions: trace, matrix-vector and matrix-matrix multiplication, just like we did for `einsum` in the previous section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2KTSl8VjBUS"
      },
      "source": [
        "### Exercise - trace\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> Use the hint if you're stuck.\n",
        "> ```\n",
        "\n",
        "You might find the very last example in the previous section helpful for this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWEgP_XHjBUS"
      },
      "outputs": [],
      "source": [
        "def as_strided_trace(mat: Float[Tensor, \"i j\"]) -> Float[Tensor, \"\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.trace`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_trace(as_strided_trace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQRIlcRojBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "The trace is the sum of all the elements you get from starting at `[0, 0]` and then continually stepping down and right one element. Use strides to create a 1D array which contains these elements.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def as_strided_trace(mat: Float[Tensor, \"i j\"]) -> Float[Tensor, \"\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.trace`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    stride = mat.stride()\n",
        "\n",
        "    assert len(stride) == 2, f\"matrix should be 2D, not {len(stride)}\"\n",
        "    assert mat.size(0) == mat.size(1), \"matrix should be square\"\n",
        "\n",
        "    diag = mat.as_strided((mat.size(0),), (stride[0] + stride[1],))\n",
        "\n",
        "    return diag.sum()\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T00YeIh3jBUS"
      },
      "source": [
        "### Exercise - matrix-vector multiplication\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise.\n",
        "> The hints should be especially useful here if you're stuck. There are two hints available to you.\n",
        "> ```\n",
        "\n",
        "You should implement this using only `as_strided` and `sum` methods, and elementwise multiplication `*` - in other words, no matrix multiplication functions!\n",
        "\n",
        "You might find the second last example in the previous section helpful for this exercise (i.e. the one that involved a stride of zero)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v1OGj_LjBUS"
      },
      "outputs": [],
      "source": [
        "def as_strided_mv(mat: Float[Tensor, \"i j\"], vec: Float[Tensor, \"j\"]) -> Float[Tensor, \"i\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_mv(as_strided_mv)\n",
        "tests.test_mv2(as_strided_mv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpinaDvgjBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Hint 1</summary>\n",
        "\n",
        "You want your output array to be as follows:\n",
        "\n",
        "$$\n",
        "\\text{output}[i] = \\sum_j \\text{mat}[i, j] \\times \\text{vector}[j]\n",
        "$$\n",
        "\n",
        "so first try to create an array with:\n",
        "\n",
        "$$\n",
        "\\text{arr}[i, j] = \\text{mat}[i, j] \\times \\text{vector}[j]\n",
        "$$\n",
        "\n",
        "then you can calculate `output` by summing over the second dimension of `arr`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 2</summary>\n",
        "\n",
        "First try to use strides to create `vec_expanded` such that:\n",
        "\n",
        "$$\n",
        "\\text{vec\\_expanded}[i, j] = \\text{vec}[j]\n",
        "$$\n",
        "\n",
        "We can then compute:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{arr}[i, j] &= \\text{mat}[i, j] \\times \\text{vec\\_expanded}[i, j] \\\\\n",
        "\\text{output}[i] &= \\sum_j \\text{arr}[i, j]\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "with the first equation being a simple elementwise multiplication, and the second equation being a sum over the second dimension.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm passing the first test, but failing the second.</summary>\n",
        "\n",
        "It's possible that the input matrices you recieve could themselves be the output of an `as_strided` operation, so that they're represented in memory in a non-contiguous way. Make sure that your `as_strided `operation is using the strides from the original input arrays, i.e. it's not just assuming the last element in the `stride()` tuple is 1.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def as_strided_mv(mat: Float[Tensor, \"i j\"], vec: Float[Tensor, \"j\"]) -> Float[Tensor, \"i\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    sizeM = mat.shape\n",
        "    sizeV = vec.shape\n",
        "    strideV = vec.stride()\n",
        "\n",
        "    assert len(sizeM) == 2, f\"mat1 should be 2D, not {len(sizeM)}\"\n",
        "    assert sizeM[1] == sizeV[0], f\"mat{list(sizeM)}, vec{list(sizeV)} not compatible for multiplication\"\n",
        "\n",
        "    vec_expanded = vec.as_strided(mat.shape, (0, strideV[0]))\n",
        "\n",
        "    return (mat * vec_expanded).sum(dim=1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPLHf1Y0jBUS"
      },
      "source": [
        "### Exercise - matrix-matrix multiplication\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> The hints should be especially useful here if you're stuck. There are two hints available to you.\n",
        "> ```\n",
        "                \n",
        "Like the previous function, this should only involve `as_strided`, `sum`, and pointwise multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNmY5ncGjBUS"
      },
      "outputs": [],
      "source": [
        "def as_strided_mm(matA: Float[Tensor, \"i j\"], matB: Float[Tensor, \"j k\"]) -> Float[Tensor, \"i k\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_mm(as_strided_mm)\n",
        "tests.test_mm2(as_strided_mm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMIOVzNCjBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Hint 1</summary>\n",
        "\n",
        "If you did the first one, this isn't too dissimilar. We have:\n",
        "\n",
        "$$\n",
        "\\text{output}[i, k] = \\sum_j \\text{matA}[i, j] \\times \\text{matB}[j, k]\n",
        "$$\n",
        "\n",
        "\n",
        "so in this case, try to create an array with:\n",
        "\n",
        "$$\n",
        "\\text{arr}[i, j, k] = \\text{matA}[i, j] \\times \\text{matB}[j, k]\n",
        "$$\n",
        "\n",
        "then sum this array over `j` to get our output.\n",
        "\n",
        "We need to create expanded versions of both `matA` and `matB` in order to take this product.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 2</summary>\n",
        "\n",
        "We want to compute\n",
        "\n",
        "$$\n",
        "\\text{matA\\_expanded}[i, j, k] = \\text{matA}[i, j]\n",
        "$$\n",
        "\n",
        "so our stride for `matA` should be `(matA.stride(0), matA.stride(1), 0)` (because we're repeating over the last dimension but iterating over the first 2 dimensions just like for the 2D matrix `matA`).\n",
        "        \n",
        "A similar idea applies for `matB`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def as_strided_mm(matA: Float[Tensor, \"i j\"], matB: Float[Tensor, \"j k\"]) -> Float[Tensor, \"i k\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    assert len(matA.shape) == 2, f\"mat1 should be 2D, not {len(matA.shape)}\"\n",
        "    assert len(matB.shape) == 2, f\"mat2 should be 2D, not {len(matB.shape)}\"\n",
        "    assert matA.shape[1] == matB.shape[0], (\n",
        "        f\"mat1{list(matA.shape)}, mat2{list(matB.shape)} not compatible for multiplication\"\n",
        "    )\n",
        "\n",
        "    # Get the matrix strides, and matrix dims\n",
        "    sA0, sA1 = matA.stride()\n",
        "    dA0, dA1 = matA.shape\n",
        "    sB0, sB1 = matB.stride()\n",
        "    _, dB1 = matB.shape\n",
        "\n",
        "    # Get target size for matrices, as well as the strides necessary to create them\n",
        "    expanded_size = (dA0, dA1, dB1)\n",
        "    matA_expanded_stride = (sA0, sA1, 0)\n",
        "    matB_expanded_stride = (0, sB0, sB1)\n",
        "\n",
        "    # Create the strided matrices, and return their product summed over middle dimension\n",
        "    matA_expanded = matA.as_strided(expanded_size, matA_expanded_stride)\n",
        "    matB_expanded = matB.as_strided(expanded_size, matB_expanded_stride)\n",
        "    return (matA_expanded * matB_expanded).sum(dim=1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyD475YsjBUS"
      },
      "source": [
        "## conv1d minimal\n",
        "\n",
        "Here, we will implement the PyTorch `conv1d` function, which can be found [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html). We will start with a simple implementation where `stride=1` and `padding=0`, with the other arguments set to their default values.\n",
        "\n",
        "Firstly, some explanation of `conv1d` in PyTorch. The `1` in `1d` here refers to the number of dimensions along which we slide the weights (also called the kernel) when we convolve. Importantly, it does not refer to the number of dimensions of the tensors that are being used in our calculations. Typically the input and kernel are both 3D:\n",
        "\n",
        "* `input.shape = (batch, in_channels, width)`\n",
        "* `kernel.shape = (out_channels, in_channels, kernel_width)`\n",
        "\n",
        "A typical convolution operation is illustrated in the sketch below. Some notes on this sketch:\n",
        "\n",
        "* The `kernel_width` dimension of the kernel slides along the `width` dimension of the input. The `output_width` of the output is determined by the number of kernels that can be fit inside it; the formula can be seen in the right part of the sketch.\n",
        "* For each possible position of the kernel inside the model (i.e. each freezeframe position in the sketch), the operation happening is as follows:\n",
        "    * We take the product of the kernel values with the corresponding input values, and then take the sum\n",
        "    * This gives us a single value for each output channel\n",
        "    * These values are then passed into the output tensor\n",
        "* The sketch assumes a batch size of 1. To generalise to a larger batch number, we can just imagine this operation being repeated identically on every input.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-general.png\" width=950>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxAW8W4jBUS"
      },
      "source": [
        "### A note on `out_channels`\n",
        "\n",
        "The out_channels in a conv2d layer denotes the number of filters the layer uses. Each filter detects specific features in the input, producing an output with as many channels as filters.\n",
        "\n",
        "This number isn't tied to the input image's channels but is a design choice in the neural network architecture. Commonly, powers of 2 are chosen for computational efficiency, and deeper layers might have more channels to capture complex features. Additionally, this parameter is sometimes chosen based on the heuristic of wanting to balance the parameter count / compute for each layer - which is why you often see `out_channels` growing as the size of each feature map gets smaller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CTCD1yYjBUS"
      },
      "source": [
        "### Exercise - implement minimal 1D conv (part 1)\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> Use the diagram in the dropdown below, if you're stuck.\n",
        "> ```\n",
        "\n",
        "Below, you should implement `conv1d_minimal`. This is a function which works just like `conv1d`, but takes the default stride and padding values (these will be added back in later). You are allowed to use `as_strided` and `einsum`.\n",
        "\n",
        "Because this is a difficult exercise, we've given you a \"simplified\" function to implement first. This gets rid of the batch dimension, and input & output channel dimensions, so you only have to think about `x` and `weights` being one-dimensional tensors:\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-minimal.png\" width=650>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLxYfHY9jBUS"
      },
      "outputs": [],
      "source": [
        "def conv1d_minimal_simple(\n",
        "    x: Float[Tensor, \"width\"], weights: Float[Tensor, \"kernel_width\"]\n",
        ") -> Float[Tensor, \"output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "\n",
        "    Simplifications: batch = input channels = output channels = 1.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv1d_minimal_simple(conv1d_minimal_simple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCLG9IFfjBUS"
      },
      "source": [
        "<details>\n",
        "<summary>If you're stuck on <code>conv1d_minimal_simple</code>, click here to see a diagram which should help.</summary>\n",
        "\n",
        "This diagram illustrates the striding operation you'll need to perform on `x`. Once you do this, it's just a matter of using the right `einsum` operation to get the output.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-explained.png\" width=800>\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv1d_minimal_simple(\n",
        "    x: Float[Tensor, \"width\"], weights: Float[Tensor, \"kernel_width\"]\n",
        ") -> Float[Tensor, \"output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "\n",
        "    Simplifications: batch = input channels = output channels = 1.\n",
        "    \"\"\"\n",
        "    # Get output width, using formula\n",
        "    w = x.shape[0]\n",
        "    kw = weights.shape[0]\n",
        "    ow = w - kw + 1\n",
        "\n",
        "    # Get strides for x\n",
        "    s_w = x.stride(0)\n",
        "\n",
        "    # Get strided x (the new dimension has same stride as the original stride of x)\n",
        "    x_new_shape = (ow, kw)\n",
        "    x_new_stride = (s_w, s_w)\n",
        "    # Common error: s_w is always 1 if the tensor `x` wasn't itself created via striding, so if you put 1 here you won't\n",
        "    # spot your mistake until you try this with conv2d!\n",
        "    x_strided = x.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"ow kw, kw -> ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNGOcHejBUS"
      },
      "source": [
        "### Exercise - implement minimal 1D conv (part 2)\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Once you've implemented this function, you should now adapt it to make a \"full version\", which includes batch, in_channel and out_channel dimensions. If you're stuck, the dropdowns provide hints for how each of these new dimensions should be handled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Vimmc0ajBUS"
      },
      "outputs": [],
      "source": [
        "def conv1d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], weights: Float[Tensor, \"out_channels in_channels kernel_width\"]\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv1d_minimal(conv1d_minimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hmPFS18jBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm stuck on going from <code>conv1d_minimal_simple</code> to <code>conv1d_minimal</code>.</summary>\n",
        "\n",
        "The principle is the same as before. In your function, you should:\n",
        "\n",
        "* Create a strided version of `x` by adding a dimension of length `output_width` and with the same stride as the `width` stride of `x` (the purpose of which is to be able to do all the convolutions at once).\n",
        "* Perform an einsum between this strided version of `x` and `weights`, summing over the appropriate dimensions.\n",
        "\n",
        "The way each of the new dimensions `batch`, `out_channels` and `in_channels` are handled is as follows:\n",
        "\n",
        "* `batch` - this is an extra dimension for `x`, it is *not* summed over when creating `output`.\n",
        "* `out_channels` - this is an extra dimension for `weights`, it is *not* summed over when creating `output`.\n",
        "* `in_channels` - this is an extra dimension for `weights` *and* for `x`, it *is* summed over when creating `output`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv1d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], weights: Float[Tensor, \"out_channels in_channels kernel_width\"]\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    b, ic, w = x.shape\n",
        "    oc, ic2, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    # Get output width, using formula\n",
        "    ow = w - kw + 1\n",
        "\n",
        "    # Get strides for x\n",
        "    s_b, s_ic, s_w = x.stride()\n",
        "\n",
        "    # Get strided x (the new dimension has the same stride as the original width-stride of x)\n",
        "    x_new_shape = (b, ic, ow, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_w, s_w)\n",
        "    # Common error: xsWi is always 1, so if you put 1 here you won't spot your mistake until you try this with conv2d!\n",
        "    x_strided = x.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic ow kw, oc ic kw -> b oc ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgy48o8TjBUT"
      },
      "source": [
        "## conv2d minimal\n",
        "\n",
        "2D convolutions are conceptually similar to 1D. The only difference is in how you move the kernel across the tensor as you take your convolution. In this case, you will be moving the tensor across two dimensions:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv2d-general.png\" width=1050>\n",
        "\n",
        "For this reason, 1D convolutions tend to be used for signals (e.g. audio), 2D convolutions are used for images, and 3D convolutions are used for 3D scans (e.g. in medical applications)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p26FYremjBUT"
      },
      "source": [
        "### Exercise - implement 2D minimal convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        "> Use the diagram in the dropdown below, if you're stuck.\n",
        "> ```\n",
        "\n",
        "You should implement `conv2d` in a similar way to `conv1d`. Again, this is expected to be difficult and there are several hints you can go through. We've also provided a diagram to help you, like for the 1D case:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv2d-minimal.png\" width=900>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYIEJXr9jBUT"
      },
      "outputs": [],
      "source": [
        "def conv2d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        ") -> Float[Tensor, \"batch out_channels height_padding width_padding\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv2d_minimal(conv2d_minimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz3-F0JKjBUT"
      },
      "source": [
        "<details>\n",
        "<summary>Hint & diagram</summary>\n",
        "\n",
        "You should be doing the same thing that you did for the 1D version. The only difference is that you're introducing 2 new dimensions to your strided version of x, rather than 1 (their sizes should be `output_height` and `output_width`, and their strides should be the same as the original `height` and `width` strides of `x` respectively).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv2d-minimal-help.png\" width=700>\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv2d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        ") -> Float[Tensor, \"batch out_channels height_padding width_padding\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    b, ic, h, w = x.shape\n",
        "    oc, ic2, kh, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    ow = w - kw + 1\n",
        "    oh = h - kh + 1\n",
        "\n",
        "    s_b, s_ic, s_h, s_w = x.stride()\n",
        "\n",
        "    # Get strided x (the new height/width dims have the same stride as the original height/width-strides of x)\n",
        "    x_new_shape = (b, ic, oh, ow, kh, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_h, s_w, s_h, s_w)\n",
        "\n",
        "    x_strided = x.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic oh ow kh kw, oc ic kh kw -> b oc oh ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9ecETF0jBUT"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbXIYhvujBUT"
      },
      "source": [
        "For a full version of `conv`, and for `maxpool` (which will follow shortly), you'll need to implement `pad` helper functions. PyTorch has some very generic padding functions, but to keep things simple and build up gradually, we'll write 1D and 2D functions individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDcFkEyojBUT"
      },
      "source": [
        "### Exercise - implement padding\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise, and the next.\n",
        "> ```\n",
        "\n",
        "The `pad1d` function applies padding to the width dimension of a 1D tensor, i.e. we pad with `left` entries to the start of the last dimension of `x` and with `right` entries to the end of the last dimension of `x`.\n",
        "\n",
        "Tips:\n",
        "* Use the `new_full` method of the input tensor. This is a clean way to ensure that the output tensor is on the same device as the input, and has the same dtype.\n",
        "* You can use three dots to denote slicing over multiple dimensions. For instance, `x[..., 0]` will take the `0th` slice of `x` along its last dimension. This is equivalent to `x[:, 0]` for 2D, `x[:, :, 0]` for 3D, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAqi59injBUT"
      },
      "outputs": [],
      "source": [
        "def pad1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], left: int, right: int, pad_value: float\n",
        ") -> Float[Tensor, \"batch in_channels width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the edges.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_pad1d(pad1d)\n",
        "tests.test_pad1d_multi_channel(pad1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nb2FBTijBUT"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I get <code>RuntimeError: The expanded size of the tensor (0) must match ...</code></summary>\n",
        "\n",
        "This might be because you've indexed with `left : -right`. Think about what will happen here when `right` is zero.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def pad1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], left: int, right: int, pad_value: float\n",
        ") -> Float[Tensor, \"batch in_channels width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the edges.\"\"\"\n",
        "    B, C, W = x.shape\n",
        "    output = x.new_full(size=(B, C, left + W + right), fill_value=pad_value)\n",
        "    output[..., left : left + W] = x  # note we can't use `left:-right`, because `right` might be zero\n",
        "    return output\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQtx9KDOjBUT"
      },
      "source": [
        "Once you've passed the tests, you can implement the 2D version. The `left` and `right` padding arguments apply to the width dimension, and the `top` and `bottom` padding arguments apply to the height dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVwG4EvvjBUT"
      },
      "outputs": [],
      "source": [
        "def pad2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    left: int,\n",
        "    right: int,\n",
        "    top: int,\n",
        "    bottom: int,\n",
        "    pad_value: float,\n",
        ") -> Float[Tensor, \"batch in_channels height_padding width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the width & height dimensions.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_pad2d(pad2d)\n",
        "tests.test_pad2d_multi_channel(pad2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsNzMIWKjBUT"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def pad2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    left: int,\n",
        "    right: int,\n",
        "    top: int,\n",
        "    bottom: int,\n",
        "    pad_value: float,\n",
        ") -> Float[Tensor, \"batch in_channels height_padding width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the width & height dimensions.\"\"\"\n",
        "    B, C, H, W = x.shape\n",
        "    output = x.new_full(size=(B, C, top + H + bottom, left + W + right), fill_value=pad_value)\n",
        "    output[..., top : top + H, left : left + W] = x\n",
        "    return output\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ywkYQ6ZjBUT"
      },
      "source": [
        "## Full convolutions\n",
        "\n",
        "Now, you'll extend `conv1d` to handle the `stride` and `padding` arguments.\n",
        "\n",
        "`stride` is the number of input positions that the kernel slides at each step. `padding` is the number of zeros concatenated to each side of the input before the convolution.\n",
        "\n",
        "Output shape should be `(batch, output_channels, output_length)`, where output_length can be calculated as follows:\n",
        "\n",
        "$$\n",
        "\\text{output\\_length} = \\left\\lfloor\\frac{\\text{input\\_length} + 2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} \\right\\rfloor + 1\n",
        "$$\n",
        "\n",
        "Verify for yourself that the forumla above simplifies to the formula we used earlier when padding is 0 and stride is 1.\n",
        "\n",
        "Docs for pytorch's `conv1d` can be found [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2E-Io4YjBUT"
      },
      "source": [
        "### Exercise - implement 1D convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm9IJlj8jBUT"
      },
      "outputs": [],
      "source": [
        "def conv1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_width\"],\n",
        "    stride: int = 1,\n",
        "    padding: int = 0,\n",
        ") -> Float[Tensor, \"batch out_channels width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv1d(conv1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBSmgAEjjBUT"
      },
      "source": [
        "<details>\n",
        "<summary>Hint - dealing with padding</summary>\n",
        "\n",
        "As the first line of your function, replace `x` with the padded version of `x`. This way, you won't have to worry about accounting for padding in the rest of the function (e.g. in the formula for the output width).\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint - dealing with strides</summary>\n",
        "\n",
        "The following diagram shows how you should create the strided version of `x` differently, if you have a stride of 2 rather than the default stride of 1.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-help.png\" width=\"850\">\n",
        "\n",
        "Remember, you'll need a new formula for `output_width` (see formula in the  [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html) for help with this, or see if you can derive it without help).\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_width\"],\n",
        "    stride: int = 1,\n",
        "    padding: int = 0,\n",
        ") -> Float[Tensor, \"batch out_channels width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False.\n",
        "    \"\"\"\n",
        "    x_padded = pad1d(x, left=padding, right=padding, pad_value=0)\n",
        "\n",
        "    b, ic, w = x_padded.shape\n",
        "    oc, ic2, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    ow = 1 + (w - kw) // stride\n",
        "    # note, we assume padding is zero in the formula here, because we're working with input which has already been padded\n",
        "\n",
        "    s_b, s_ic, s_w = x_padded.stride()\n",
        "\n",
        "    # Get strided x (the new height/width dims have the same stride as the original height/width-strides of x,\n",
        "    # scaled by the stride (because we're \"skipping over\" x as we slide the kernel over it))\n",
        "    # See diagram in hints for more explanation.\n",
        "    x_new_shape = (b, ic, ow, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_w * stride, s_w)\n",
        "    x_strided = x_padded.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic ow kw, oc ic kw -> b oc ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rfXf1FyjBUT"
      },
      "source": [
        "### Exercise - implement 2D convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "A recurring pattern in these 2d functions is allowing the user to specify either an int or a pair of ints for an argument: examples are stride and padding. We've provided some type aliases and a helper function to simplify working with these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXVQGTOJjBUT"
      },
      "outputs": [],
      "source": [
        "IntOrPair = int | tuple[int, int]\n",
        "Pair = tuple[int, int]\n",
        "\n",
        "\n",
        "def force_pair(v: IntOrPair) -> Pair:\n",
        "    \"\"\"Convert v to a pair of int, if it isn't already.\"\"\"\n",
        "    if isinstance(v, tuple):\n",
        "        if len(v) != 2:\n",
        "            raise ValueError(v)\n",
        "        return (int(v[0]), int(v[1]))\n",
        "    elif isinstance(v, int):\n",
        "        return (v, v)\n",
        "    raise ValueError(v)\n",
        "\n",
        "\n",
        "# Examples of how this function can be used:\n",
        "for v in [(1, 2), 2, (1, 2, 3)]:\n",
        "    try:\n",
        "        print(f\"{v!r:9} -> {force_pair(v)!r}\")\n",
        "    except ValueError:\n",
        "        print(f\"{v!r:9} -> ValueError\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3x9bo6djBUT"
      },
      "source": [
        "Finally, you can implement a full version of `conv2d`. If you've done the full version of `conv1d`, and you've done `conv2d_minimal`, then you should be able to pull code from here to help you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYqsUhU-jBUT"
      },
      "outputs": [],
      "source": [
        "def conv2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        "    stride: IntOrPair = 1,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv2d(conv2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prEMdgDqjBUT"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        "    stride: IntOrPair = 1,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False.\n",
        "    \"\"\"\n",
        "    stride_h, stride_w = force_pair(stride)\n",
        "    padding_h, padding_w = force_pair(padding)\n",
        "\n",
        "    x_padded = pad2d(x, left=padding_w, right=padding_w, top=padding_h, bottom=padding_h, pad_value=0)\n",
        "\n",
        "    b, ic, h, w = x_padded.shape\n",
        "    oc, ic2, kh, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    ow = 1 + (w - kw) // stride_w\n",
        "    oh = 1 + (h - kh) // stride_h\n",
        "\n",
        "    s_b, s_ic, s_h, s_w = x_padded.stride()\n",
        "\n",
        "    # Get strided x (new height/width dims have same stride as original height/width-strides of x, scaled by stride)\n",
        "    x_new_shape = (b, ic, oh, ow, kh, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_h * stride_h, s_w * stride_w, s_h, s_w)\n",
        "    x_strided = x_padded.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic oh ow kh kw, oc ic kh kw -> b oc oh ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiY-d1FKjBUT"
      },
      "source": [
        "## Max pooling\n",
        "\n",
        "We have just one function left now - **max pooling**. You can review the [Medium post](https://medium.com/towards-data-science/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) from earlier to understand max pooling better.\n",
        "\n",
        "A \"max pooling\" layer is similar to a convolution in that you have a window sliding over some number of dimensions. The main difference is that there's no kernel: instead of multiplying by the kernel and adding, you just take the maximum.\n",
        "\n",
        "The way multiple channels work is also different. A convolution has some number of input and output channels, and each output channel is a function of all the input channels. There can be any number of output channels. In a pooling layer, the maximum operation is applied independently for each input channel, meaning the number of output channels is necessarily equal to the number of input channels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zfvV5G2jBUT"
      },
      "source": [
        "### Exercise - implement 2D max pooling\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `maxpool2d` using `torch.as_strided` and `torch.amax` (= max over axes) together. Your version should behave the same as the PyTorch version, but only the indicated arguments need to be supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17pBDSqOjBUT"
      },
      "outputs": [],
      "source": [
        "def maxpool2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    kernel_size: IntOrPair,\n",
        "    stride: IntOrPair | None = None,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like PyTorch's maxpool2d. If stride is None, should be equal to kernel size.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_maxpool2d(maxpool2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0OsLmyvjBUU"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Conceptually, this is similar to `conv2d`.\n",
        "    \n",
        "In `conv2d`, you had to use `as_strided` to turn the 4D tensor `x` into a 6D tensor `x_strided` (adding dimensions over which you would take the convolution), then multiply this tensor by the kernel and sum over these two new dimensions.\n",
        "\n",
        "`maxpool2d` is the same, except that you're simply taking max over those dimensions rather than a dot product with the kernel. So you should find yourself able to reuse a lot of code from your `conv2d` function.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm getting a small number of mismatched elements each time (e.g. between 0 and 5%).</summary>\n",
        "\n",
        "This is likely because you used an incorrect `pad_value`. In the convolution function, we set `pad_value=0` so these values wouldn't have any effect in the linear transformation. What pad value would make our padded elements \"invisible\" when we take the maximum?\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def maxpool2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    kernel_size: IntOrPair,\n",
        "    stride: IntOrPair | None = None,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like PyTorch's maxpool2d. If stride is None, should be equal to kernel size.\n",
        "    \"\"\"\n",
        "    # Set actual values for stride and padding, using force_pair function\n",
        "    if stride is None:\n",
        "        stride = kernel_size\n",
        "    stride_h, stride_w = force_pair(stride)\n",
        "    padding_h, padding_w = force_pair(padding)\n",
        "    kh, kw = force_pair(kernel_size)\n",
        "\n",
        "    # Get padded version of x\n",
        "    x_padded = pad2d(x, left=padding_w, right=padding_w, top=padding_h, bottom=padding_h, pad_value=-t.inf)\n",
        "\n",
        "    # Calculate output height and width for x\n",
        "    b, ic, h, w = x_padded.shape\n",
        "    ow = 1 + (w - kw) // stride_w\n",
        "    oh = 1 + (h - kh) // stride_h\n",
        "\n",
        "    # Get strided x\n",
        "    s_b, s_c, s_h, s_w = x_padded.stride()\n",
        "\n",
        "    x_new_shape = (b, ic, oh, ow, kh, kw)\n",
        "    x_new_stride = (s_b, s_c, s_h * stride_h, s_w * stride_w, s_h, s_w)\n",
        "    x_strided = x_padded.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    # Argmax over dimensions of the maxpool kernel\n",
        "    # (note these are the same dims that we multiply over in 2D convolutions)\n",
        "    return x_strided.amax(dim=(-1, -2))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd1rET04jBUU"
      },
      "source": [
        "Now, you're finished! You can go back to the ResNets exercises, and build your ResNet ***entirely using your own stride-based functions***."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0dfb59a99d334be79295eb8b7867b33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f60f1550aef947929790b23d53fb2214",
              "IPY_MODEL_f601fc08052c4d6bb3a406c0a1e3871d",
              "IPY_MODEL_09920f80665a40be843961e5c018685d"
            ],
            "layout": "IPY_MODEL_f01ca72e651149e69035da348dd18f49"
          }
        },
        "f60f1550aef947929790b23d53fb2214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aac21b6bf594cb790475e082c8d9b7e",
            "placeholder": "​",
            "style": "IPY_MODEL_dcedc6167cee4a4fa83b4e03715c8e72",
            "value": "100%"
          }
        },
        "f601fc08052c4d6bb3a406c0a1e3871d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5b687e2a86b4110b7f7ba6f27457f7f",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97b22c3d1591425caa0cb075cad17c84",
            "value": 6
          }
        },
        "09920f80665a40be843961e5c018685d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_367bf383c9324f5e9f9a07d7ca00200d",
            "placeholder": "​",
            "style": "IPY_MODEL_87f818029d06461c8b923fde45aabfc2",
            "value": " 6/6 [00:06&lt;00:00,  1.00s/it, i=5, letter=!, time=6.009]"
          }
        },
        "f01ca72e651149e69035da348dd18f49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aac21b6bf594cb790475e082c8d9b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcedc6167cee4a4fa83b4e03715c8e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5b687e2a86b4110b7f7ba6f27457f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97b22c3d1591425caa0cb075cad17c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "367bf383c9324f5e9f9a07d7ca00200d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f818029d06461c8b923fde45aabfc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "967a628fc674412fa6d7447d9b46d5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd41724d6200454b854bb838ea4a7a16",
              "IPY_MODEL_6e34a3a5b9f945418cfc57aa039a05df",
              "IPY_MODEL_6bbb7be75c7f4e07a5ff795e97aa98d7"
            ],
            "layout": "IPY_MODEL_cd473b454a034157a5d400feaf6ac250"
          }
        },
        "bd41724d6200454b854bb838ea4a7a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57b034f7dac44a13816ddceedb665633",
            "placeholder": "​",
            "style": "IPY_MODEL_ee98792456284a9cae8c02c7ca96f765",
            "value": "100%"
          }
        },
        "6e34a3a5b9f945418cfc57aa039a05df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ad7964756e477f87a3512418bd0b20",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2de6043c3ff404ead03cf3eb6406396",
            "value": 79
          }
        },
        "6bbb7be75c7f4e07a5ff795e97aa98d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb8a45c6caa14777a58c145ab152658b",
            "placeholder": "​",
            "style": "IPY_MODEL_250a2c27d4d442c2a0000b6875102a5d",
            "value": " 79/79 [00:02&lt;00:00, 31.97it/s, epoch=1/3, loss=0.640]"
          }
        },
        "cd473b454a034157a5d400feaf6ac250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b034f7dac44a13816ddceedb665633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee98792456284a9cae8c02c7ca96f765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02ad7964756e477f87a3512418bd0b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2de6043c3ff404ead03cf3eb6406396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb8a45c6caa14777a58c145ab152658b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250a2c27d4d442c2a0000b6875102a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96cfe2de9bbc4e4a9f5d0bfce6c0fd9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b56918497d9547e3a6084ddff8bcf6db",
              "IPY_MODEL_eef3d968a24d4c1c9da3c290db46b40f",
              "IPY_MODEL_2764620e9033405bb52b4514f59c0d87"
            ],
            "layout": "IPY_MODEL_a9d387ed255445fabe16dea48bce42fb"
          }
        },
        "b56918497d9547e3a6084ddff8bcf6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a486a6efac68481580910a65d8a18476",
            "placeholder": "​",
            "style": "IPY_MODEL_5cc08aba9dad4e2b9fa40796ef86fb08",
            "value": "100%"
          }
        },
        "eef3d968a24d4c1c9da3c290db46b40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db6b3e5d43574b758b961929e29b2002",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18a297df2f1d462aac8663b0a1c82bc1",
            "value": 79
          }
        },
        "2764620e9033405bb52b4514f59c0d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e55c5a1b454a36a4e8603d56578e98",
            "placeholder": "​",
            "style": "IPY_MODEL_c627d1e65ba848f280cf2daeef06cd21",
            "value": " 79/79 [00:03&lt;00:00, 18.05it/s, epoch=2/3, loss=0.317]"
          }
        },
        "a9d387ed255445fabe16dea48bce42fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a486a6efac68481580910a65d8a18476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc08aba9dad4e2b9fa40796ef86fb08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db6b3e5d43574b758b961929e29b2002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18a297df2f1d462aac8663b0a1c82bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05e55c5a1b454a36a4e8603d56578e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c627d1e65ba848f280cf2daeef06cd21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bc6662daec245c5a144716069e5a592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee5f92c05b964f19b5ae40743b2ba193",
              "IPY_MODEL_a61f2e72d0a5414aae874c46fd3ce13a",
              "IPY_MODEL_10a321e61d014dfca73ae0a1ac784251"
            ],
            "layout": "IPY_MODEL_0cae7a0bfab64c11907ea4943d473c28"
          }
        },
        "ee5f92c05b964f19b5ae40743b2ba193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7837facfe13a491086140a373f3a1f2c",
            "placeholder": "​",
            "style": "IPY_MODEL_f90f8703785847dfbd6a8a9eee542c9d",
            "value": "100%"
          }
        },
        "a61f2e72d0a5414aae874c46fd3ce13a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6ba1e2ffc0446e9b6a22addaee74f1c",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc0c14e4586f42799045f1a7428861a6",
            "value": 79
          }
        },
        "10a321e61d014dfca73ae0a1ac784251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80441d3c7893458abf71623ccc4b7c0a",
            "placeholder": "​",
            "style": "IPY_MODEL_572ac257e2ff4174b2505173a88610a1",
            "value": " 79/79 [00:03&lt;00:00, 21.19it/s, epoch=3/3, loss=0.378]"
          }
        },
        "0cae7a0bfab64c11907ea4943d473c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7837facfe13a491086140a373f3a1f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f90f8703785847dfbd6a8a9eee542c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6ba1e2ffc0446e9b6a22addaee74f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc0c14e4586f42799045f1a7428861a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80441d3c7893458abf71623ccc4b7c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572ac257e2ff4174b2505173a88610a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31a9dfa0cdee4d73974e7cdae2b90936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7583f45511f423e9b983f98a90c4f9c",
              "IPY_MODEL_d441ae9a839b4e1c8fedad369b53d8bb",
              "IPY_MODEL_819f245f0ec447bdb5b868f6e28c72a2"
            ],
            "layout": "IPY_MODEL_9162b3509c6a4c31be1d30752ece5978"
          }
        },
        "e7583f45511f423e9b983f98a90c4f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de79430615534ffea7cbad8904b2ef51",
            "placeholder": "​",
            "style": "IPY_MODEL_3dd7e5c9527f44e29d2852fb2b3c718e",
            "value": "100%"
          }
        },
        "d441ae9a839b4e1c8fedad369b53d8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4ea700bf68048f78c6e57a8c6f3888a",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_977b203a07fa42c68899d97e1118556e",
            "value": 157
          }
        },
        "819f245f0ec447bdb5b868f6e28c72a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bec8d813b87f4de483f18830dbc4c9c2",
            "placeholder": "​",
            "style": "IPY_MODEL_90b4f3ee35964c0e8dd172d0cd9850d8",
            "value": " 157/157 [00:02&lt;00:00, 51.33it/s, epoch=1/3, loss=0.257]"
          }
        },
        "9162b3509c6a4c31be1d30752ece5978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de79430615534ffea7cbad8904b2ef51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dd7e5c9527f44e29d2852fb2b3c718e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4ea700bf68048f78c6e57a8c6f3888a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "977b203a07fa42c68899d97e1118556e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bec8d813b87f4de483f18830dbc4c9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b4f3ee35964c0e8dd172d0cd9850d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f3de93fd3d41aa8aca4c29941ea3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ff5da20c5434f0ba32d808a24545ad0",
              "IPY_MODEL_605e8c23fad849f6a7764538eaaf2824",
              "IPY_MODEL_96c006f563584809b73443c9904841dc"
            ],
            "layout": "IPY_MODEL_f9a287e73ee44e19bddd141cec5d9494"
          }
        },
        "4ff5da20c5434f0ba32d808a24545ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_770ee75c8c45476fb65afa6713531390",
            "placeholder": "​",
            "style": "IPY_MODEL_6f368401424e4049a832a15d2bc5c753",
            "value": "100%"
          }
        },
        "605e8c23fad849f6a7764538eaaf2824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4fff127a480488f8ff611d9458ace23",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e72a39505ef4f86b9c64e4010ffbcb2",
            "value": 157
          }
        },
        "96c006f563584809b73443c9904841dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_918f52de36a44f28920e70e758972c63",
            "placeholder": "​",
            "style": "IPY_MODEL_3c0f8fcc13ae4ac8abaccdc21e0ce1db",
            "value": " 157/157 [00:03&lt;00:00, 50.71it/s, epoch=2/3, loss=0.442]"
          }
        },
        "f9a287e73ee44e19bddd141cec5d9494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "770ee75c8c45476fb65afa6713531390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f368401424e4049a832a15d2bc5c753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4fff127a480488f8ff611d9458ace23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e72a39505ef4f86b9c64e4010ffbcb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "918f52de36a44f28920e70e758972c63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c0f8fcc13ae4ac8abaccdc21e0ce1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0196a2fe0d944ce085e6c817ddd8971f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe95bd97dd3f4aaab22fc4635308fdc6",
              "IPY_MODEL_0de575497fa04a38b0ca117ad1b1dab7",
              "IPY_MODEL_acc4c790aa7a4731a961fcf026571b33"
            ],
            "layout": "IPY_MODEL_e40e8a9cef0a41238fd0b55e5a5a56d4"
          }
        },
        "fe95bd97dd3f4aaab22fc4635308fdc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e13ac616c8834025be04f2f249f3a2bb",
            "placeholder": "​",
            "style": "IPY_MODEL_1f5185b11b6d49cda8a68a385c5b4a51",
            "value": "100%"
          }
        },
        "0de575497fa04a38b0ca117ad1b1dab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_308b67c905a249938b1bd9e890d74de8",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec31335c71924671a8f97bb8a5671980",
            "value": 157
          }
        },
        "acc4c790aa7a4731a961fcf026571b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6be1dc9b9264a08bd84acc140c7b07c",
            "placeholder": "​",
            "style": "IPY_MODEL_7906053bb71b4549a4a5c35708a0b948",
            "value": " 157/157 [00:03&lt;00:00, 49.14it/s, epoch=3/3, loss=0.036]"
          }
        },
        "e40e8a9cef0a41238fd0b55e5a5a56d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e13ac616c8834025be04f2f249f3a2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5185b11b6d49cda8a68a385c5b4a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "308b67c905a249938b1bd9e890d74de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec31335c71924671a8f97bb8a5671980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6be1dc9b9264a08bd84acc140c7b07c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7906053bb71b4549a4a5c35708a0b948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c23ee43448bc4b3795632b4dee165302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_838a2ec1340846fca940ebf64964945d",
              "IPY_MODEL_53b14da794ce42cd8e367438909afc50",
              "IPY_MODEL_b8d6c81e97014a07b416ee92f9bf3bcc"
            ],
            "layout": "IPY_MODEL_3667b7c0416145c587436b66e7590973"
          }
        },
        "838a2ec1340846fca940ebf64964945d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d2b6a0bc4f0494b96bbaa5184dff26f",
            "placeholder": "​",
            "style": "IPY_MODEL_e8815e16b99e4da1b91442440d6ed73a",
            "value": "  0%"
          }
        },
        "53b14da794ce42cd8e367438909afc50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_257943fbdda14b4cacd98a9424856957",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72a65f947be74d47a0a4037c89fe9be7",
            "value": 0
          }
        },
        "b8d6c81e97014a07b416ee92f9bf3bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e79861e2523f48a4854864f7ba56a77a",
            "placeholder": "​",
            "style": "IPY_MODEL_2b19966922de452fa22d570bff7655a6",
            "value": " 0/157 [06:24&lt;?, ?it/s]"
          }
        },
        "3667b7c0416145c587436b66e7590973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2b6a0bc4f0494b96bbaa5184dff26f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8815e16b99e4da1b91442440d6ed73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "257943fbdda14b4cacd98a9424856957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72a65f947be74d47a0a4037c89fe9be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e79861e2523f48a4854864f7ba56a77a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b19966922de452fa22d570bff7655a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a05a100de8147dc8d79d5674471d56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fee95d8b6b624c3ba48ee9774af62fb7",
              "IPY_MODEL_a5268be6cbf64ae697ee8dcb4564c5f9",
              "IPY_MODEL_7d4406d7945346518a5ffdc34e78892a"
            ],
            "layout": "IPY_MODEL_5a59fc9ed6f942eea842b73779980c15"
          }
        },
        "fee95d8b6b624c3ba48ee9774af62fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d6e112eb4ee44b2a206f5ac75089375",
            "placeholder": "​",
            "style": "IPY_MODEL_7d01e0804d7b427ca566c5ba36f801ae",
            "value": "  0%"
          }
        },
        "a5268be6cbf64ae697ee8dcb4564c5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21669a2b3e48435690e0f02e730c3240",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8450d64dad8b404996396310d3c974a8",
            "value": 0
          }
        },
        "7d4406d7945346518a5ffdc34e78892a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dee1564d340404b917f5d0d2f1c9b1f",
            "placeholder": "​",
            "style": "IPY_MODEL_1857c0a48853423c9abe7967e8524e74",
            "value": " 0/157 [00:02&lt;?, ?it/s]"
          }
        },
        "5a59fc9ed6f942eea842b73779980c15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d6e112eb4ee44b2a206f5ac75089375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d01e0804d7b427ca566c5ba36f801ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21669a2b3e48435690e0f02e730c3240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8450d64dad8b404996396310d3c974a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dee1564d340404b917f5d0d2f1c9b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1857c0a48853423c9abe7967e8524e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "973c21dc4e0747e5bcc05dde595187b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e1a7c41f90b4af5b7e691f2e2749f6b",
              "IPY_MODEL_988681b1f9d0496a85603ec32a65bf08",
              "IPY_MODEL_b1c7025203a145c2b52f5de0de678f42"
            ],
            "layout": "IPY_MODEL_53b0421d898e4a7384e878c332545106"
          }
        },
        "6e1a7c41f90b4af5b7e691f2e2749f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52ef5ae48a384e0593cf930f5f226701",
            "placeholder": "​",
            "style": "IPY_MODEL_060cfda0dd944425bfd0a24fbc85bd6a",
            "value": "  0%"
          }
        },
        "988681b1f9d0496a85603ec32a65bf08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_333725bd217e40858aecd3d04b6730ba",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad96b52b6f3946a69951e6274f25e11f",
            "value": 0
          }
        },
        "b1c7025203a145c2b52f5de0de678f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa67a2e13a444fb1930a07a6cc584b12",
            "placeholder": "​",
            "style": "IPY_MODEL_85a657e77b714204ba91dc616d4a068b",
            "value": " 0/157 [00:02&lt;?, ?it/s]"
          }
        },
        "53b0421d898e4a7384e878c332545106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ef5ae48a384e0593cf930f5f226701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "060cfda0dd944425bfd0a24fbc85bd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "333725bd217e40858aecd3d04b6730ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad96b52b6f3946a69951e6274f25e11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa67a2e13a444fb1930a07a6cc584b12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a657e77b714204ba91dc616d4a068b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}