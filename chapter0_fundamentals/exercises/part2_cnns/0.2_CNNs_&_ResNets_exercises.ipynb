{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_iswa50jBUB"
      },
      "source": [
        "# [0.2] - CNNs & ResNets (exercises)\n",
        "\n",
        "> **ARENA [Streamlit Page](https://arena-chapter0-fundamentals.streamlit.app/02_[0.2]_CNNs_&_ResNets)**\n",
        ">\n",
        "> **Colab: [exercises](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_exercises.ipynb?t=20250316) | [solutions](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_solutions.ipynb?t=20250316)**\n",
        "\n",
        "Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-2zick19fl-6GY1yoGaoUozyM3wObwmnQ), and ask any questions on the dedicated channels for this chapter of material.\n",
        "\n",
        "You can collapse each section so only the headers are visible, by clicking the arrow symbol on the left hand side of the markdown header cells.\n",
        "\n",
        "Links to all other chapters: [(0) Fundamentals](https://arena-chapter0-fundamentals.streamlit.app/), [(1) Transformer Interpretability](https://arena-chapter1-transformer-interp.streamlit.app/), [(2) RL](https://arena-chapter2-rl.streamlit.app/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KReTy3YXjBUD"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/headers/header-02.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjDs7AnnjBUD"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IteXpvwkjBUE"
      },
      "source": [
        "This section is designed to get you familiar with basic neural networks: how they are structured, the basic operations like linear layers and convolutions which go into making them, and why they work as well as they do. You'll start by making very simple neural networks, and by the end of today you'll build up to assembling ResNet34, a comparatively much more complicated architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ56L21GjBUE"
      },
      "source": [
        "## Content & Learning Objectives\n",
        "\n",
        "### 1️⃣ Making your own modules\n",
        "\n",
        "In the first set of exercises, we'll cover the general structure of modules in PyTorch. You'll also implement your own basic modules, including for ReLU and Linear layers. You'll finish by assembling a very simple neural network.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn how to create your own modules in PyTorch, by inheriting from `nn.Module`\n",
        "> - Assemble the pieces together to create a simple fully-connected network, to classify MNIST digits\n",
        "\n",
        "### 2️⃣ Training Neural Networks\n",
        "\n",
        "Here, you'll learn how to write a training loop in PyTorch. We'll keep it simple for today (and later on we'll experiment with more modular and extensible designs).\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand how to work with transforms, datasets and dataloaders\n",
        "> - Understand the basic structure of a training loop\n",
        "> - Learn how to write your own validation loop\n",
        "\n",
        "### 3️⃣ Convolutions\n",
        "\n",
        "In this section, you'll read about convolutions, and implement them as an `nn.Module` (not from scratch; we leave that to the bonus exercises). You'll also learn about maxpooling, and implement that as well.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn how convolutions work, and why they are useful for vision models\n",
        "> * Implement your own convolutions, and maxpooling layers\n",
        "\n",
        "### 4️⃣ ResNets\n",
        "\n",
        "Here, you'll combine all the pieces you've learned so far to assemble ResNet34, a much more complex architecture used for image classification.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn about skip connections, and how they help overcome the degradation problem\n",
        "> * Learn about batch normalization, and why it is used in training\n",
        "> * Assemble your own ResNet, and load in weights from PyTorch's ResNet implementation\n",
        "\n",
        "### ☆ Bonus - Feature Extraction\n",
        "\n",
        "In this section, you'll learn how to repurpose your ResNet to perform a different task than it was designed for, using feature extraction.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand the difference between feature extraction and finetuning\n",
        "> * Perform feature extraction on a pre-trained ResNet\n",
        "\n",
        "### ☆ Bonus - Convolutions From Scratch\n",
        "\n",
        "This section takes you through the low-level details of how to actually implement convolutions. It's not necessary to understand this section to complete the exercises, but it's a good way to get a deeper understanding of how convolutions work.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand how array strides work, and why they're important for efficient linear operations\n",
        "> * Learn how to use `as_strided` to perform simple linear operations like trace and matrix multiplication\n",
        "> * Implement your own convolutions and maxpooling functions using stride-based methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xpzt7ZBjBUE"
      },
      "source": [
        "## Setup code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "X3SaGqsSjBUE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "repo = \"ARENA_3.0\"\n",
        "branch = \"main\"\n",
        "\n",
        "# Install dependencies\n",
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    %pip install torchinfo jaxtyping\n",
        "\n",
        "# Get root directory, handling 3 different cases: (1) Colab, (2) notebook not in ARENA repo, (3) notebook in ARENA repo\n",
        "root = (\n",
        "    \"/content\"\n",
        "    if IN_COLAB\n",
        "    else \"/root\"\n",
        "    if repo not in os.getcwd()\n",
        "    else str(next(p for p in Path.cwd().parents if p.name == repo))\n",
        ")\n",
        "\n",
        "if Path(root).exists() and not Path(f\"{root}/{chapter}\").exists():\n",
        "    if not IN_COLAB:\n",
        "        !sudo apt-get install unzip\n",
        "        %pip install jupyter ipython --upgrade\n",
        "\n",
        "    if not os.path.exists(f\"{root}/{chapter}\"):\n",
        "        !wget -P {root} https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/{branch}.zip\n",
        "        !unzip {root}/{branch}.zip '{repo}-{branch}/{chapter}/exercises/*' -d {root}\n",
        "        !mv {root}/{repo}-{branch}/{chapter} {root}/{chapter}\n",
        "        !rm {root}/{branch}.zip\n",
        "        !rmdir {root}/{repo}-{branch}\n",
        "\n",
        "\n",
        "if f\"{root}/{chapter}/exercises\" not in sys.path:\n",
        "    sys.path.append(f\"{root}/{chapter}/exercises\")\n",
        "\n",
        "os.chdir(f\"{root}/{chapter}/exercises\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "J760KjlEjBUF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "from collections import namedtuple\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import einops\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchinfo\n",
        "from IPython.display import display\n",
        "from jaxtyping import Float, Int\n",
        "from PIL import Image\n",
        "from rich import print as rprint\n",
        "from rich.table import Table\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Make sure exercises are in the path\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "section = \"part2_cnns\"\n",
        "root_dir = next(p for p in Path.cwd().parents if (p / chapter).exists())\n",
        "exercises_dir = root_dir / chapter / \"exercises\"\n",
        "section_dir = exercises_dir / section\n",
        "if str(exercises_dir) not in sys.path:\n",
        "    sys.path.append(str(exercises_dir))\n",
        "\n",
        "\n",
        "import part2_cnns.tests as tests\n",
        "import part2_cnns.utils as utils\n",
        "from plotly_utils import line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt1-bUz3jBUF"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I get a NumPy-related error</summary>\n",
        "\n",
        "This is an annoying colab-related issue which I haven't been able to find a satisfying fix for. If you restart runtime (but don't delete runtime), and run just the imports cell above again (but not the `%pip install` cell), the problem should go away.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlzN3uFYjBUF"
      },
      "source": [
        "# 1️⃣ Making your own modules\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn how to create your own modules in PyTorch, by inheriting from `nn.Module`\n",
        "> - Assemble the pieces together to create a simple fully-connected network, to classify MNIST digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amANK1ZwjBUF"
      },
      "source": [
        "Note - from this point on we'll start referring to the PyTorch documentation pages quite a lot. We will also include a lot of content within this material if we want to highlight it for you, however it's also an important skill to be able to use documentation pages to find answers to specific questions & assist you in debugging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u7TDJr8jBUF"
      },
      "source": [
        "## Subclassing `nn.Module`\n",
        "\n",
        "One of the most basic parts of PyTorch that you will see over and over is the `nn.Module` class. All types of neural net components inherit from it, from the simplest `nn.Relu` to the most complex `nn.Transformer`. Often, a complex `nn.Module` will have sub-`Module`s which implement smaller pieces of its functionality.\n",
        "\n",
        "Other common `Module`s  you'll see include\n",
        "\n",
        "- `nn.Linear`, for fully-connected layers with or without a bias\n",
        "- `nn.Conv2d`, for a two-dimensional convolution (we'll see more of these in a future section)\n",
        "- `nn.Softmax`, which implements the [softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) function\n",
        "\n",
        "The list goes on, including activation functions, normalizations, pooling, attention, and more. You can see all the `Module`s that PyTorch provides [here](https://pytorch.org/docs/stable/nn.html). You can also create your own `Module`s, as we will do often!\n",
        "\n",
        "The `Module` class provides a lot of functionality, but we'll only cover a little bit of it here.\n",
        "\n",
        "In this section, we'll add another layer of abstraction to all the linear operations we've done in previous sections, by packaging them inside `nn.Module` objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd35tEeHjBUF"
      },
      "source": [
        "### `__init__` and `forward`\n",
        "\n",
        "A subclass of `nn.Module` usually looks something like this:\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, arg1, arg2, ...):\n",
        "        super().__init__()\n",
        "        # Initialization code\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        # Forward pass code\n",
        "```\n",
        "\n",
        "The initialization sets up attributes that will be used for the life of the `Module`, like its parameters, hyperparameters, or other sub-`Module`s it might need to use. These are usually added to the instance with something like `self.attribute = attr`, where `attr` might be provided as an argument. Some modules are simple enough that they don't need any persistent attributes, and in this case you can skip the `__init__`.\n",
        "\n",
        "The `forward` method is called on each forward pass of the `Module`, possibly using the attributes that were set up in the `__init__`. It should take in the input, do whatever it's supposed to do, and return the result. Subclassing `nn.Module` automatically makes instances of your class callable, so you can do `model(x)` on an input `x` to invoke the `forward` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR3NHdlijBUF"
      },
      "source": [
        "### The `nn.Parameter` class\n",
        "\n",
        "A `nn.Parameter` is a special type of `Tensor`. Basically, this is the class that torch has provided for storing the weights and biases of a `Module`. It has some special properties for doing this:\n",
        "\n",
        "- If a `Parameter` is set as an attribute of a `Module`, it will be auto-detected by torch and returned when you call `module.parameters()` (along with all the other `Parameters` associated with the `Module`, or any of the `Module`'s sub-modules!).\n",
        "- This makes it easy to pass all the parameters of a model into an optimizer and update them all at once.\n",
        "\n",
        "When you create a `Module` that has weights or biases, be sure to wrap them in `nn.Parameter` so that torch can detect and update them appropriately:\n",
        "\n",
        "```python\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, weights: t.Tensor, biases: t.Tensor):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(weights) # wrapping a tensor in nn.Parameter\n",
        "        self.biases = nn.Parameter(biases)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygSJWmByjBUF"
      },
      "source": [
        "### Printing information with `extra_repr`\n",
        "\n",
        "Another useful method is called `extra_repr`. This allows you to format the string representation of your `Module` in a way that's more informative than the default. For example, the following:\n",
        "\n",
        "```python\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, arg1, arg2, ...):\n",
        "        super().__init__()\n",
        "        # Initialization code\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"arg1={self.arg1}, arg2={self.arg2}, ...\"\n",
        "```\n",
        "\n",
        "will result in the output `\"MyModule(arg1=arg1, arg2=arg2, ...)\"` when you print an instance of this module. You might want to take this opportunity to print out useful invariant information about the module. The Python built-in function `getattr` might be helpful here (it can be used e.g. as `getattr(self, \"arg1\")`, which returns the same as `self.arg1` would). For simple modules, it's fine not to implement `extra_repr`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Tq7dwBjBUF"
      },
      "source": [
        "## ReLU\n",
        "\n",
        "The first module you should implement is `ReLU`. This will relatively simple, since it doesn't involve any argument (so we only need to implement `forward`). Make sure you look at the PyTorch documentation page for [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) so that you're comfortable with how they work.\n",
        "\n",
        "ReLU is defined as the element-wise maximum between the input and a tensor of zeros. It's one of the simplest types of **nonlinear activation functions**. These are essential because linear operations compose to make more linear operations, which is very limiting. On the other hand, the **universal approximation theorem** tells us that we can approximate any continuous function using a sufficiently large neural network, if we use nonlinear activation functions. It's worth emphasizing that the theory of the UAT and what networks look like in practice are very different - in particular, many versions of the UAT are based on a shallow but extremely wide neural network, on the other hand most of the power of modern neural networks comes from their ability to compose between layers: feeding the output of one layer into the input of another, and create increasingly expressive functions. We'll explore this idea more when we study circuits in next week's interpretability material."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmarEv11jBUF"
      },
      "source": [
        "### Exercise - implement `ReLU`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should fill in the `forward` method of the `ReLU` class below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9sfqUqfjBUF",
        "outputId": "2baebef6-4ac6-402f-883c-3a6e7b723ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.3721, -0.3637,  0.0325, -0.1997, -2.0387, -2.4537, -1.8001, -1.5583,\n",
            "        -0.9321, -0.1306])\n",
            "All tests in `test_relu` passed!\n"
          ]
        }
      ],
      "source": [
        "class ReLU(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "      print(x)\n",
        "      return t.max(t.tensor(0.0), x)\n",
        "\n",
        "\n",
        "tests.test_relu(ReLU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHxhtlaRjBUF"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ReLU(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return t.maximum(x, t.tensor(0.0))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNQObgqGjBUF"
      },
      "source": [
        "## Linear\n",
        "\n",
        "Now implement your own `Linear` module. This applies a simple linear transformation, with a weight matrix and optional bias vector. The PyTorch documentation page is [here](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html). Note that this is the first `Module` you'll implement that has learnable weights and biases.\n",
        "\n",
        "<details>\n",
        "<summary>Question - what type do you think these variables should be?</summary>\n",
        "\n",
        "They have to be `torch.Tensor` objects wrapped in `nn.Parameter` in order for `nn.Module` to recognize them. If you forget to do this, `module.parameters()` won't include your `Parameter`, which prevents an optimizer from being able to modify it during training.\n",
        "        \n",
        "Also, in tomorrow's exercises we'll be building a ResNet and loading in weights from a pretrained model, and this is hard to do if you haven't registered all your parameters!\n",
        "</details>\n",
        "\n",
        "For any layer, initialization is very important for the stability of training: with a bad initialization, your model will take much longer to converge or may completely fail to learn anything. The default PyTorch behavior isn't necessarily optimal and you can often improve performance by using something more custom, but we'll follow it for today because it's simple and works decently well.\n",
        "\n",
        "Each float in the weight and bias tensors are drawn independently from the uniform distribution on the interval:\n",
        "\n",
        "$$\n",
        "\\bigg[-\\frac{1}{\\sqrt{N_{in}}}, \\frac{1}{\\sqrt{N_{in}}}\\bigg]\n",
        "$$\n",
        "\n",
        "where $N_{in}$ is the number of inputs contributing to each output value. The rough intuition for this is that it keeps the variance of the activations at each layer constant, since each one is calculated by taking the sum over $N_{in}$ inputs multiplied by the weights (and standard deviation of the sum of independent random variables scales as the square root of number of variables).\n",
        "\n",
        "This initialization technique is called **uniform Kaiming initialization**. A few last notes on initialization methods:\n",
        "\n",
        "- Kaiming often has a different constant in the numerator depending on what the target variance is, also there are uniform & normal variants of it (we'll only be using the uniform variant)\n",
        "- **Xavier initialization** is the other well-known technique, and differs in that it uses $N_{in} + N_{out}$ in the denominator (this makes sense when also considering variance scaling of backward passes as well as forward passes - see the next dropdown for technical details)\n",
        "\n",
        "<details>\n",
        "<summary>Technical details (derivation of distribution)</summary>\n",
        "\n",
        "The key intuition behind Kaiming initialisation (and others like it) is that we want the variance of our activations to be the same through all layers of the model when we initialize. Suppose $x$ and $y$ are activations from two adjacent layers, and $w$ are the weights connecting them (so we have $y_i = \\sum_j w_{ij} x_j + b_i$, where $b$ is the bias). With $N_{x}$ as the number of neurons in layer $x$, we have:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\operatorname{Var}\\left(y_i\\right)=\\sigma_x^2 & =\\operatorname{Var}\\left(\\sum_j w_{i j} x_j\\right) \\\\\n",
        "& =\\sum_j \\operatorname{Var}\\left(w_{i j} x_j\\right) \\quad \\text { Inputs and weights are independent of each other } \\\\\n",
        "& =\\sum_j \\operatorname{Var}\\left(w_{i j}\\right) \\cdot \\operatorname{Var}\\left(x_j\\right) \\quad \\text { Variance of product of independent RVs with zero mean is product of variances } \\\\\n",
        "& = N_x \\cdot \\sigma_x^2 \\cdot \\operatorname{Var}\\left(w_{i j}\\right) \\quad \\text { Variance equal for all } N_x \\text { neurons, call this value } \\sigma_x^2\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "For this to be the same as $\\sigma_x^2$, we need $\\operatorname{Var}(w_{ij}) = \\frac{1}{N_x}$, so the standard deviation is $\\frac{1}{\\sqrt{N_x}}$.\n",
        "\n",
        "This is not exactly the case for the Kaiming uniform distribution (which has variance $\\frac{12}{(2 \\sqrt{N_x})^2} = \\frac{3}{N_x}$), and as far as I'm aware there's no principled reason why PyTorch does this. But the most important thing is that the variance scales as $O(1 / N_x)$, rather than what the exact scaling constant is.\n",
        "\n",
        "There are other initializations with some theoretical justification. For instance, **Xavier initialization** has a uniform distribution in the interval:\n",
        "\n",
        "$$\n",
        "\\bigg[-\\frac{\\sqrt{6}}{\\sqrt{N_{in} + N_{out} + 1}}, \\frac{\\sqrt{6}}{\\sqrt{N_{in} + N_{out} + 1}}\\bigg]\n",
        "$$\n",
        "\n",
        "which is motivated by the idea of both keeping the variance of activations constant and keeping the ***gradients*** constant when we backpropagate.\n",
        "\n",
        "However, you don't need to worry about any of this here, just implement Kaiming He uniform with a bound of $\\frac{1}{\\sqrt{N_{in}}}$!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sayc08FRjBUG"
      },
      "source": [
        "### Exercise - implement `Linear`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Remember, you should define the weights (and bias, if `bias=True`) in the `__init__` block. Also, make sure not to mix up `bias` (which is the boolean parameter to `__init__`) and `self.bias` (which should either be the actual bias tensor, or `None` if `bias` is false).\n",
        "\n",
        "You should also fill in `forward` (which will multiply the input by the weight matrix and add the bias, if present).\n",
        "\n",
        "Lastly, you should fill in `extra_repr` to give a string representation of the `Linear` module. There are no tests for this method, you should just make sure it's suitably informative (this will help when printing out your model later on)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_XQjEHcjBUG",
        "outputId": "2cfdfe05-524f-4926-a69a-8da158eb7ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_linear_parameters` passed!\n",
            "All tests in `test_linear_parameters` passed!\n",
            "All tests in `test_linear_forward` passed!\n",
            "All tests in `test_linear_forward` passed!\n"
          ]
        }
      ],
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
        "        \"\"\"\n",
        "        A simple linear (technically, affine) transformation.\n",
        "\n",
        "        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n",
        "        If `bias` is False, set `self.bias` to None.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.bias = bias\n",
        "        self.weight = nn.Parameter(nn.init.kaiming_uniform_(t.empty(out_features, in_features)))\n",
        "        if bias:\n",
        "          self.bias = nn.Parameter(t.zeros(out_features))\n",
        "        else:\n",
        "          self.bias = None\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (*, in_features)\n",
        "        Return: shape (*, out_features)\n",
        "        \"\"\"\n",
        "        x = einops.einsum(x, self.weight, 'batch input, output input -> batch output')\n",
        "        if self.bias is not None:\n",
        "            x += self.bias  # Add the bias if it exists\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"input_shape={self.in_features}, output_shape={self.out_features}\"\n",
        "\n",
        "\n",
        "tests.test_linear_parameters(Linear, bias=False)\n",
        "tests.test_linear_parameters(Linear, bias=True)\n",
        "tests.test_linear_forward(Linear, bias=False)\n",
        "tests.test_linear_forward(Linear, bias=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTo8VirAjBUG"
      },
      "source": [
        "<details>\n",
        "<summary>Help - when I print my Linear module, it also prints a large tensor.</summary>\n",
        "\n",
        "This is because you've (correctly) defined `self.bias` as either `torch.Tensor` or `None`, rather than set it to the boolean value of `bias` used in initialisation.\n",
        "        \n",
        "To fix this, you will need to change `extra_repr` so that it prints the boolean value of `bias` rather than the value of `self.bias`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
        "        \"\"\"\n",
        "        A simple linear (technically, affine) transformation.\n",
        "\n",
        "        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n",
        "        If `bias` is False, set `self.bias` to None.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.bias = bias\n",
        "\n",
        "        sf = 1 / np.sqrt(in_features)\n",
        "\n",
        "        weight = sf * (2 * t.rand(out_features, in_features) - 1)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "\n",
        "        if bias:\n",
        "            bias = sf * (2 * t.rand(out_features) - 1)\n",
        "            self.bias = nn.Parameter(bias)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (*, in_features)\n",
        "        Return: shape (*, out_features)\n",
        "        \"\"\"\n",
        "        x = einops.einsum(x, self.weight, \"... in_feats, out_feats in_feats -> ... out_feats\")\n",
        "        if self.bias is not None:\n",
        "            x += self.bias\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        # note, we need to use `self.bias is not None`, because `self.bias` is either a tensor or None, not bool\n",
        "        return f\"in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}\"\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GmLM-WkjBUG"
      },
      "source": [
        "## Flatten\n",
        "\n",
        "Lastly, we've given you the `Flatten` module rather than including it as an exercise (because it's simple but quite finnicky to implement). This is a standardised way to rearrange our tensors so that they can be fed into a linear layer. It's a bit like `einops.rearrange`, but more specialised and less flexible (it flattens over some contiguous range of dimensions, rather than allowing for general reshape operations). By default we use `Flatten(start_dim=1, end_dim=-1)` which means flattening over the dimensions from `input.shape[1:]`, in other words over all except the batch dimension.\n",
        "\n",
        "Make sure you understand what this module is doing before moving on.\n",
        "\n",
        "<!-- <details>\n",
        "<summary>Help - I can't figure out what shape the output should be in Flatten.</summary>\n",
        "\n",
        "If `input.shape = (n0, n1, ..., nk)`, and the `Flatten` module has `start_dim=i, end_dim=j`, then the new shape should be `(n0, n1, ..., ni*...*nj, ..., nk)`. This is because we're **flattening** over the dimensions `(ni, ..., nj)`.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I can't see why my Flatten module is failing the tests.</summary>\n",
        "\n",
        "The most common reason is failing to correctly handle indices. Make sure that:\n",
        "* You're indexing up to **and including** `end_dim`.\n",
        "* You're correctly managing the times when `end_dim` is negative (e.g. if `input` is an nD tensor, and `end_dim=-1`, this should be interpreted as `end_dim=n-1`).\n",
        "</details> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kJ8_fjZ3jBUG"
      },
      "outputs": [],
      "source": [
        "class Flatten(nn.Module):\n",
        "    def __init__(self, start_dim: int = 1, end_dim: int = -1) -> None:\n",
        "        super().__init__()\n",
        "        self.start_dim = start_dim\n",
        "        self.end_dim = end_dim\n",
        "\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Flatten out dimensions from start_dim to end_dim, inclusive of both.\n",
        "        \"\"\"\n",
        "        shape = input.shape\n",
        "\n",
        "        # Get start & end dims, handling negative indexing for end dim\n",
        "        start_dim = self.start_dim\n",
        "        end_dim = self.end_dim if self.end_dim >= 0 else len(shape) + self.end_dim\n",
        "\n",
        "        # Get the shapes to the left / right of flattened dims, as well as the size of the flattened middle\n",
        "        shape_left = shape[:start_dim]\n",
        "        shape_right = shape[end_dim + 1 :]\n",
        "        shape_middle = t.prod(t.tensor(shape[start_dim : end_dim + 1])).item()\n",
        "\n",
        "        return t.reshape(input, shape_left + (shape_middle,) + shape_right)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in [\"start_dim\", \"end_dim\"]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = t.rand((2,3,4))\n",
        "print(test.shape)\n",
        "test_flat = Flatten(0, 1)(test)\n",
        "print(test_flat.shape)"
      ],
      "metadata": {
        "id": "dsCF-TbI1GfW",
        "outputId": "5574a225-b666-482e-e342-b591348b005a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n",
            "torch.Size([6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVmSiz4CjBUG"
      },
      "source": [
        "## Simple Multi-Layer Perceptron\n",
        "\n",
        "Now, we can put together these two modules to create a neural network. We'll create one of the simplest networks which can be used to separate data that is non-linearly separable: a single linear layer, followed by a nonlinear function (ReLU), followed by another linear layer. This type of architecture (alternating linear layers and nonlinear functions) is often called a **multi-layer perceptron** (MLP).\n",
        "\n",
        "The output of this network will have 10 dimensions, corresponding to the 10 classes of MNIST digits. We can then use the **softmax function** $x_i \\to \\frac{e^{x_i}}{\\sum_i e^{x_i}}$ to turn these values into probabilities. However, it's common practice for the output of a neural network to be the values before we take softmax, rather than after. We call these pre-softmax values the **logits**.\n",
        "\n",
        "<details>\n",
        "<summary>Question - can you see what makes logits non-unique (i.e. why any given set of probabilities might correspond to several different possible sets of logits)?</summary>\n",
        "\n",
        "Logits are **translation invariant**. If you add some constant $c$ to all logits $x_i$, then the new probabilities are:\n",
        "\n",
        "$$\n",
        "p_i' = \\frac{e^{x_i + c}}{\\sum_j e^{x_j + c}} = \\frac{e^{x_i}}{\\sum_j e^{x_j}} = p_i\n",
        "$$\n",
        "\n",
        "in other words, the probabilities don't change.\n",
        "\n",
        "We can define **logprobs** as the log of the probabilities, i.e. $y_i = \\log p_i$. Unlike logits, these are uniquely defined.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKzRBaB8jBUG"
      },
      "source": [
        "### Exercise - implement the simple MLP\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to ~20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "The diagram below shows what your MLP should look like:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mlp-mermaid.svg\" width=\"170\">\n",
        "\n",
        "Please ask a TA (or message the Slack group) if any part of this diagram is unclear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-Iaj1re_jBUG",
        "outputId": "58f00709-05e0-4128-eb93-13fe56e9b280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleMLP(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Linear(input_shape=784, output_shape=100)\n",
            "  (relu): ReLU()\n",
            "  (linear2): Linear(input_shape=100, output_shape=10)\n",
            ")\n",
            "All tests in `test_mlp_module` passed!\n",
            "tensor([[ 3.4285e-01, -6.1601e-03, -3.7715e-01,  2.4169e-02,  2.5006e-01,\n",
            "          3.5956e-01,  3.4541e-01, -1.5000e-02, -3.4939e-01, -2.1713e-01,\n",
            "         -4.6145e-02, -3.7654e-02,  2.7433e-01, -2.6143e-01, -3.3458e-01,\n",
            "          3.6712e-01,  5.1302e-01, -4.4635e-01,  8.4211e-01,  7.2216e-01,\n",
            "         -4.5391e-02,  2.8981e-01, -2.0634e-01, -1.6741e-02,  3.8753e-01,\n",
            "          2.7649e-01, -1.8525e-01,  1.5513e-01,  4.1363e-02,  3.3607e-01,\n",
            "         -1.4376e-01, -1.0149e-01, -1.0697e-02, -5.3468e-01,  3.2247e-01,\n",
            "         -2.6557e-02, -2.3390e-01, -6.3460e-01, -2.9898e-01, -1.0511e-02,\n",
            "          5.0677e-01,  3.0823e-01, -2.9879e-01, -7.3876e-03, -1.1232e-01,\n",
            "          6.7045e-02, -4.7715e-01,  4.1386e-01,  2.1734e-01, -1.5581e-01,\n",
            "         -5.1890e-01,  1.4476e-01, -5.3369e-01,  1.4435e-01,  1.8422e-01,\n",
            "          2.5007e-02, -4.6608e-02,  1.5031e-01,  5.9623e-02,  4.8124e-02,\n",
            "         -1.7743e-01, -2.8480e-01, -7.2009e-02,  7.6824e-01, -4.0736e-01,\n",
            "         -5.4760e-01, -2.9369e-01, -4.0398e-01,  2.1476e-01,  1.9327e-03,\n",
            "         -1.0289e-01,  2.5838e-01,  6.3114e-01, -1.4074e-01, -3.0347e-01,\n",
            "         -1.9259e-01,  1.9784e-01,  3.0321e-02, -5.2170e-01,  3.1122e-01,\n",
            "          7.1347e-01,  1.8943e-01, -2.8688e-01, -3.3597e-01,  6.3311e-02,\n",
            "         -1.2917e-01,  5.8269e-02, -2.8023e-01, -1.3562e-01,  5.4913e-01,\n",
            "          6.3953e-02, -1.3199e-01,  3.7820e-01,  3.3835e-01,  4.2744e-02,\n",
            "          4.9230e-02,  2.3956e-01, -1.3588e-01,  2.0019e-01,  3.9641e-01],\n",
            "        [ 8.8928e-02, -2.7992e-01, -4.3655e-01,  2.1350e-01,  9.5500e-02,\n",
            "          1.7020e-01,  7.1213e-01, -1.0769e-01, -1.6613e-01, -1.9800e-01,\n",
            "          2.3983e-01,  1.0872e-01,  1.1085e-01, -6.1446e-02, -2.3736e-01,\n",
            "          4.9388e-01,  5.2959e-01, -4.1936e-01,  9.6527e-01,  7.5726e-01,\n",
            "          1.2814e-01, -6.1481e-02, -3.3522e-01, -2.0712e-01,  5.9824e-01,\n",
            "         -8.3469e-03, -2.7599e-01,  1.6908e-01, -1.2885e-02, -5.9997e-02,\n",
            "         -1.4152e-01, -9.0142e-03, -3.2981e-02, -3.7243e-01,  3.3271e-01,\n",
            "          5.1435e-02,  1.2479e-01, -3.8201e-01, -2.5129e-01, -2.0750e-01,\n",
            "          1.3193e-01, -2.6366e-02, -1.7606e-01, -1.1415e-01, -2.4950e-01,\n",
            "         -3.0598e-01, -3.7747e-01,  7.5130e-02,  2.1574e-01, -5.3942e-01,\n",
            "         -2.8332e-01,  1.8978e-01, -3.4052e-01,  2.2123e-01,  2.8815e-01,\n",
            "         -8.2406e-03,  9.6955e-02,  3.8977e-01, -4.4934e-02,  2.6658e-01,\n",
            "          1.4141e-01,  8.4096e-03,  2.2454e-01,  8.2271e-01, -4.9867e-01,\n",
            "         -3.0450e-01, -1.3977e-01, -3.4795e-01,  3.3655e-01, -2.8327e-01,\n",
            "         -3.5825e-02,  3.5720e-01,  3.0359e-01, -2.1114e-02, -1.2947e-01,\n",
            "         -5.9589e-01,  1.1501e-01,  1.6324e-01, -3.2243e-01,  3.5925e-01,\n",
            "          5.2243e-01,  3.4933e-01, -1.9142e-01, -2.4745e-01, -3.7199e-01,\n",
            "         -1.3547e-01,  8.6544e-02, -4.0666e-01, -3.2461e-03,  1.7740e-01,\n",
            "          5.7951e-02,  1.8507e-01,  8.1088e-01, -6.5040e-02, -1.4958e-02,\n",
            "          1.8273e-01,  2.1039e-01, -1.8529e-01,  2.5866e-01,  5.3416e-01],\n",
            "        [ 3.4908e-01, -1.9498e-01, -3.3851e-02,  2.1717e-01,  1.4799e-01,\n",
            "          5.0840e-01,  6.5062e-01, -4.1424e-02, -2.5075e-01, -5.2602e-02,\n",
            "         -4.9192e-02, -3.6233e-01,  6.4720e-02, -2.8024e-01, -6.4902e-01,\n",
            "          3.9453e-01,  4.0386e-01, -6.9708e-01,  6.7443e-01,  8.5467e-01,\n",
            "          1.9521e-01,  9.7445e-02, -7.7365e-02, -2.1962e-01,  6.9281e-02,\n",
            "          2.2181e-01, -3.0128e-01, -5.7160e-02, -3.8564e-01,  5.2598e-01,\n",
            "         -3.1653e-01, -3.3484e-03, -1.9106e-01, -2.1298e-01,  8.8113e-02,\n",
            "         -4.1210e-01, -2.3369e-01, -5.3709e-01, -1.9816e-01,  7.2225e-02,\n",
            "          4.2019e-01,  3.9211e-01, -2.6736e-01, -1.6033e-01,  4.8894e-04,\n",
            "         -9.9189e-02, -8.7880e-01,  3.3408e-01,  2.3005e-01, -2.5916e-01,\n",
            "         -4.0324e-02,  1.6342e-01, -1.9005e-01,  2.6055e-01,  5.1926e-01,\n",
            "          6.0269e-02, -1.5006e-02,  2.5416e-01, -1.1454e-01, -1.5573e-01,\n",
            "          4.3420e-03,  7.0605e-02,  3.3859e-01,  4.0993e-01, -6.4465e-01,\n",
            "         -2.2229e-01, -1.7775e-01, -3.6354e-01,  4.2496e-01,  4.0978e-02,\n",
            "         -2.9696e-01,  2.3964e-01,  3.6091e-01, -5.3418e-02, -4.8504e-01,\n",
            "         -4.6023e-01, -7.6631e-02,  9.1921e-03, -6.4432e-01,  5.6802e-01,\n",
            "          6.7456e-01,  1.6179e-01, -1.4798e-01, -2.4392e-01, -4.0296e-01,\n",
            "          4.1891e-03,  3.6300e-01, -5.0548e-01, -3.0331e-01,  2.7969e-01,\n",
            "         -1.7899e-01,  9.7432e-02,  5.3629e-01,  1.8911e-01,  2.0186e-01,\n",
            "         -1.4345e-01,  4.4122e-01, -1.6086e-01,  5.1273e-01,  2.9957e-02],\n",
            "        [ 1.8471e-01,  2.5214e-01, -2.1762e-01,  1.1326e-01,  1.8112e-01,\n",
            "          5.6114e-01,  6.0941e-01, -2.9151e-01, -1.3318e-02, -3.4337e-01,\n",
            "          2.6139e-01,  3.8962e-02,  2.0798e-01,  1.2377e-02,  1.9773e-02,\n",
            "          4.0800e-01,  2.0746e-01, -4.0649e-01,  6.0523e-01,  5.7638e-01,\n",
            "          4.2430e-01,  2.3900e-01, -3.0535e-01,  1.3152e-01,  3.0471e-01,\n",
            "          8.8699e-02, -1.3217e-01,  3.6625e-01, -4.4137e-01,  1.7134e-01,\n",
            "         -3.4647e-01, -1.0956e-01, -1.0530e-01, -2.5932e-01,  5.4835e-01,\n",
            "          3.7532e-02, -2.0674e-01, -4.3212e-01, -1.8144e-01, -1.5570e-01,\n",
            "          3.0239e-01,  2.3137e-01, -3.0333e-01,  1.7836e-01, -1.2822e-01,\n",
            "          2.4379e-01, -6.2296e-01,  2.7385e-01,  3.5918e-01, -1.9570e-01,\n",
            "         -2.6988e-01,  2.4496e-01, -3.3450e-01,  2.4515e-01,  6.8120e-01,\n",
            "         -6.7634e-03, -1.5690e-01,  2.8587e-01, -2.2908e-01,  1.2216e-01,\n",
            "         -9.6370e-02,  2.9217e-01,  5.3991e-01,  3.7784e-01, -6.5785e-01,\n",
            "         -5.0035e-01, -1.2226e-02, -6.0526e-01,  3.7031e-01, -2.4237e-01,\n",
            "         -4.4629e-01, -3.5385e-02,  4.3114e-01, -1.7264e-01, -1.9772e-01,\n",
            "         -6.0452e-01, -8.5809e-02, -1.1828e-03, -4.8643e-01, -5.3872e-03,\n",
            "          2.4798e-01,  2.1417e-01, -1.8256e-01, -4.4799e-02, -1.3080e-02,\n",
            "         -3.9312e-02, -2.4092e-02, -6.7285e-01, -2.1704e-01,  1.9266e-01,\n",
            "          7.7631e-02, -2.2904e-01,  5.2917e-01,  1.1144e-01,  2.0748e-01,\n",
            "          4.2417e-01,  5.1944e-01, -1.3993e-01,  3.3171e-01,  9.8392e-02],\n",
            "        [ 2.3701e-01, -2.6625e-01, -4.4722e-02, -2.1752e-01,  4.2773e-02,\n",
            "          4.9368e-01,  5.8075e-01,  5.0478e-03, -6.8612e-02, -3.4382e-01,\n",
            "          2.0221e-01,  2.0843e-01, -1.6460e-01, -1.2439e-01, -1.6812e-01,\n",
            "          3.3200e-01,  5.4479e-01, -5.6335e-01,  5.8236e-01,  6.5049e-01,\n",
            "         -4.0892e-02,  1.7919e-01, -7.2249e-01,  1.4035e-01,  8.0700e-01,\n",
            "         -2.8527e-01, -3.0356e-01,  2.6233e-01, -1.0135e-01,  5.7815e-01,\n",
            "         -3.0117e-01, -1.6028e-01,  8.4203e-04, -2.8488e-01,  9.4957e-02,\n",
            "         -1.1173e-01, -1.6731e-01, -5.4753e-01, -5.0431e-01, -3.7910e-01,\n",
            "          5.9069e-01,  1.5581e-01, -3.1248e-01, -3.1620e-01, -2.8498e-01,\n",
            "          2.7953e-02, -5.5491e-01, -7.3338e-02,  4.7655e-01, -1.1016e-01,\n",
            "         -4.3155e-01,  1.1069e-01, -5.4900e-01,  7.0407e-02,  3.8229e-01,\n",
            "         -2.9564e-02, -2.9927e-01,  4.9710e-01,  9.4613e-02, -2.5436e-01,\n",
            "         -2.0530e-02, -6.0851e-02,  2.7728e-01,  5.0393e-01, -5.3184e-01,\n",
            "         -3.2542e-01, -1.4064e-01, -4.0700e-01,  2.4325e-01, -5.5881e-01,\n",
            "         -5.1595e-02,  3.8447e-01,  5.6830e-01,  3.8869e-01, -3.4823e-01,\n",
            "         -7.6811e-01,  7.2731e-02,  4.0963e-03, -3.2272e-01, -1.7861e-01,\n",
            "          4.7672e-01,  3.6341e-01, -1.8272e-01, -4.0112e-01, -2.0247e-01,\n",
            "         -4.6782e-01,  1.7498e-01, -1.5716e-01, -3.5441e-01,  2.0377e-01,\n",
            "          5.9479e-02,  1.8385e-01,  6.5218e-01,  2.4612e-01, -3.4620e-01,\n",
            "         -1.3001e-01,  2.6272e-01, -1.9037e-01,  2.5284e-01,  4.5320e-01],\n",
            "        [ 5.0227e-03, -4.4569e-01, -9.5183e-02,  1.3923e-01, -4.8498e-02,\n",
            "          1.9360e-01,  8.3404e-01, -2.5726e-01, -2.4554e-01, -2.4930e-01,\n",
            "          1.6854e-01,  1.8645e-01,  2.5515e-01,  6.8188e-02, -3.6275e-01,\n",
            "          3.8894e-01,  3.1706e-01, -5.4354e-01,  9.7675e-01,  4.9001e-01,\n",
            "          3.5407e-01,  2.3232e-02, -4.2486e-01,  2.2935e-02,  5.3498e-01,\n",
            "          8.5715e-02, -1.3109e-01, -1.2388e-01, -3.7036e-01,  8.8258e-02,\n",
            "         -6.5066e-02, -4.7527e-02, -3.5906e-01, -9.2909e-02,  2.5343e-01,\n",
            "         -1.6869e-01, -2.6707e-03, -4.0341e-01, -3.7131e-01, -1.2270e-01,\n",
            "          1.2552e-01, -1.5181e-02, -1.6528e-01,  3.4380e-02, -2.1775e-01,\n",
            "         -7.1809e-02, -2.8057e-01,  1.1098e-02,  5.6491e-01, -5.3512e-01,\n",
            "         -4.0979e-01, -4.0536e-02, -3.0666e-01,  5.4031e-02,  3.5964e-01,\n",
            "          5.2631e-02, -5.3461e-01,  1.6927e-01, -7.1196e-02,  5.6489e-02,\n",
            "         -3.1070e-01,  1.4450e-01, -4.8924e-02,  7.7331e-01, -1.9486e-01,\n",
            "         -2.5943e-01, -1.9134e-01, -1.2484e-01,  4.4426e-02, -1.9382e-01,\n",
            "         -2.3660e-01,  2.9561e-01,  5.3246e-01, -1.2796e-01, -1.7719e-01,\n",
            "         -4.0780e-01,  1.9601e-02, -2.6062e-02, -7.8546e-01,  2.6394e-01,\n",
            "          5.2225e-01,  5.2123e-01, -2.0060e-01, -5.0464e-01, -3.1799e-01,\n",
            "         -4.1041e-01,  2.2159e-01, -6.4928e-01, -4.1275e-01,  3.4928e-01,\n",
            "          3.7631e-01, -1.3458e-01,  7.7504e-01, -2.8885e-01, -1.5850e-01,\n",
            "          2.4059e-01,  2.4227e-01, -1.4872e-01,  1.8112e-01,  9.3954e-02],\n",
            "        [ 1.5687e-01, -4.8191e-01, -1.8194e-01, -4.2389e-02,  4.0424e-02,\n",
            "          3.4521e-01,  5.7940e-01, -4.2662e-01, -3.2768e-01, -3.2063e-01,\n",
            "          2.3917e-01,  2.6578e-01,  2.2833e-01, -3.6460e-02, -2.8868e-01,\n",
            "          2.3865e-01,  5.7697e-01, -4.8572e-01,  7.0907e-01,  4.3882e-01,\n",
            "          2.5655e-01, -1.1826e-01, -2.1728e-01, -3.8551e-01,  1.6929e-01,\n",
            "          8.5488e-02, -1.0166e-01,  1.6894e-01, -5.6596e-01,  2.9247e-01,\n",
            "         -2.0069e-01,  1.7983e-01, -9.4742e-03, -5.1121e-01,  4.0711e-01,\n",
            "          8.4705e-02, -2.8128e-01, -5.3828e-02, -2.4785e-01,  8.1917e-02,\n",
            "          2.1623e-01,  1.2949e-01, -4.4734e-01, -3.6446e-01, -2.7762e-01,\n",
            "          5.9904e-02, -3.6936e-01, -1.7540e-01,  3.4654e-01, -2.6435e-01,\n",
            "         -7.8882e-02,  2.6134e-01, -3.9889e-01,  1.9401e-01,  4.7344e-01,\n",
            "         -2.1268e-01, -4.0471e-01,  2.1210e-01,  2.2860e-01, -1.2177e-01,\n",
            "          2.7218e-01, -8.1362e-02,  2.3480e-01,  6.3987e-01, -4.7243e-01,\n",
            "         -5.1992e-01, -4.2538e-02, -2.5340e-01,  2.9812e-01,  1.6294e-02,\n",
            "         -1.9988e-01,  3.0041e-01,  5.9213e-01,  2.4801e-02, -1.1427e-01,\n",
            "         -6.7060e-01,  3.1897e-01,  1.7598e-01, -8.6792e-01,  3.4450e-01,\n",
            "          2.7668e-01,  1.3571e-01, -1.9798e-01, -7.0464e-02, -1.1521e-01,\n",
            "         -3.5890e-01,  3.3735e-01, -5.1242e-01, -2.8461e-01,  5.1045e-02,\n",
            "          6.4146e-02, -2.7425e-01,  7.3501e-01,  1.4959e-01, -7.1734e-02,\n",
            "         -1.4496e-02,  2.8125e-01, -5.1307e-01,  1.6881e-01,  1.6141e-01],\n",
            "        [ 5.4293e-02, -2.9593e-01, -2.9539e-01,  8.0519e-03,  7.2956e-02,\n",
            "          1.8205e-01,  5.7803e-01, -1.3168e-01, -1.1193e-02, -6.5897e-02,\n",
            "          1.0162e-01,  3.6174e-01,  2.6237e-01, -3.1030e-01, -9.9887e-02,\n",
            "          6.2392e-01,  4.6642e-01, -6.6562e-01,  7.1037e-01,  6.6443e-01,\n",
            "          3.4528e-01,  2.2149e-01, -3.2264e-01,  2.1281e-01,  6.8492e-01,\n",
            "          5.2619e-02, -6.1649e-01,  2.1234e-01, -5.7580e-02,  1.2306e-01,\n",
            "         -3.2816e-01, -7.0579e-01,  4.2620e-02, -2.6242e-01,  3.6069e-01,\n",
            "         -1.6506e-01, -3.3157e-01, -6.8665e-01, -2.6369e-01, -3.8245e-01,\n",
            "          4.8402e-01,  2.7532e-01, -2.8814e-01,  7.1434e-02, -5.1456e-01,\n",
            "         -1.6809e-01, -4.8998e-01, -7.7872e-04,  2.0059e-01, -7.7549e-02,\n",
            "          6.2893e-02, -2.1502e-02, -4.4635e-01, -7.5380e-02,  3.0085e-01,\n",
            "         -1.2816e-01, -5.3753e-01,  3.3057e-01,  2.7464e-01,  2.1744e-01,\n",
            "          3.0851e-01,  4.7988e-02,  3.3809e-01,  8.3589e-01, -3.8560e-01,\n",
            "         -3.6884e-01, -5.8851e-01, -4.2439e-01,  4.5387e-01, -6.6377e-02,\n",
            "         -3.3053e-01,  1.8140e-01,  3.0324e-01, -2.8507e-01, -3.9060e-01,\n",
            "         -4.9441e-01, -7.3070e-02,  3.2369e-02, -5.5195e-01,  6.7086e-01,\n",
            "          2.2245e-01,  6.8826e-02, -1.2781e-01, -6.2389e-01, -1.1517e-01,\n",
            "         -3.3220e-01, -1.0351e-01, -6.3622e-01, -1.3359e-01,  1.3601e-01,\n",
            "          3.7229e-01, -9.6400e-02,  3.0434e-01,  1.6045e-01,  1.8769e-02,\n",
            "         -9.9961e-02,  1.9117e-01, -2.8052e-01,  1.2653e-01,  3.3236e-01],\n",
            "        [ 2.1886e-01, -4.8078e-01, -1.2518e-01,  1.4932e-01,  2.8128e-01,\n",
            "          1.8214e-01,  7.4081e-01,  1.3082e-02, -3.0608e-01, -1.9546e-01,\n",
            "          1.7318e-01, -1.0778e-02,  4.1041e-01,  1.1040e-01,  1.2276e-01,\n",
            "          4.0497e-01,  6.4950e-01, -3.6187e-01,  7.0710e-01,  5.3809e-01,\n",
            "          2.7835e-01,  2.7103e-01, -5.5996e-02, -1.0095e-01,  6.8447e-01,\n",
            "          2.3102e-01, -2.4571e-01,  1.6417e-01,  2.4236e-02,  4.4176e-01,\n",
            "         -2.3705e-01, -3.0673e-01,  1.0569e-01, -2.7581e-01,  1.1936e-01,\n",
            "         -4.5950e-01, -6.5184e-02, -2.8891e-01, -2.9122e-01, -1.4740e-01,\n",
            "          2.5505e-01,  3.3030e-01, -3.7235e-01,  7.6535e-02, -4.5810e-01,\n",
            "          2.2186e-01, -6.4712e-01,  5.1158e-01,  1.7783e-01, -3.2386e-01,\n",
            "         -1.9934e-01,  2.9790e-01, -2.9435e-01,  2.3579e-01,  6.1943e-01,\n",
            "         -6.2616e-02, -2.1638e-01,  3.2425e-01,  2.7075e-01, -2.1713e-02,\n",
            "         -1.9911e-02, -2.5013e-02,  3.8286e-01,  9.0481e-01, -6.5964e-01,\n",
            "         -6.8742e-01, -1.1590e-01, -4.3978e-01,  4.4826e-01, -1.2930e-01,\n",
            "         -1.4390e-01,  1.7747e-01,  3.4565e-01, -3.4770e-01, -3.0433e-01,\n",
            "         -6.7706e-01,  3.7743e-02, -1.4149e-02, -6.5224e-01, -9.1065e-02,\n",
            "          4.5864e-01,  4.8607e-01,  6.4400e-02, -2.6962e-01,  1.4861e-02,\n",
            "         -5.2632e-01,  1.3189e-02, -3.7119e-01, -2.7654e-01,  3.9329e-01,\n",
            "          2.3851e-01, -3.3425e-01,  5.0011e-01, -5.3016e-02,  2.2526e-01,\n",
            "         -2.9089e-01,  4.6282e-01, -2.3741e-02,  8.5533e-02,  2.5619e-01],\n",
            "        [ 4.1986e-01, -1.1016e-01, -2.4142e-01,  6.4812e-02,  4.5679e-02,\n",
            "          3.2217e-01,  6.9961e-01, -3.5831e-02, -9.9521e-03, -4.4079e-01,\n",
            "          4.4962e-02,  3.3039e-01,  1.5841e-01, -5.3604e-02, -4.9350e-01,\n",
            "          3.2555e-01,  5.9003e-01, -4.4704e-01,  6.5515e-01,  8.7054e-01,\n",
            "          7.6138e-02,  2.8368e-02, -2.7865e-01, -2.0804e-01,  4.3531e-01,\n",
            "          2.4770e-01, -5.1245e-02, -1.4118e-01, -2.4953e-01,  2.8533e-01,\n",
            "         -6.1270e-01, -5.6888e-02, -3.9344e-02, -3.3657e-01,  4.0014e-01,\n",
            "         -3.5453e-01, -1.5354e-01, -6.4440e-01, -3.5065e-01, -1.9055e-01,\n",
            "          3.7889e-01, -3.1110e-02, -3.6547e-01,  1.3380e-01,  7.4229e-02,\n",
            "          1.4718e-01, -4.7111e-01, -1.4275e-01,  4.3341e-01, -3.4578e-01,\n",
            "         -1.7078e-01,  8.2478e-03, -4.3060e-01,  2.2393e-01,  3.6876e-01,\n",
            "          5.1775e-02,  5.2473e-02,  2.0873e-01,  1.1209e-01, -2.0427e-01,\n",
            "         -7.5596e-03, -5.1388e-02,  1.5375e-01,  6.2614e-01, -7.1558e-01,\n",
            "         -5.7056e-01,  8.9122e-02, -6.8657e-01,  3.8695e-01, -8.9547e-02,\n",
            "         -9.1788e-02,  1.5968e-01,  6.0677e-01, -4.1624e-02,  2.0617e-04,\n",
            "         -4.8804e-01,  2.0958e-01,  2.4009e-01, -6.6229e-01,  2.4214e-01,\n",
            "          6.5367e-01,  3.8202e-02, -1.6289e-01, -3.1475e-01, -4.4407e-02,\n",
            "         -5.3839e-01,  6.4923e-02, -4.1897e-01, -3.0976e-01,  2.9017e-01,\n",
            "         -6.4203e-02,  1.0833e-01,  6.4802e-01,  1.6376e-01, -1.1658e-01,\n",
            "          3.5667e-01,  4.5588e-01, -1.0449e-01,  1.5478e-01,  1.0345e-01]],\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "All tests in `test_mlp_forward` passed!\n"
          ]
        }
      ],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = Flatten()\n",
        "        self.linear1 = Linear(in_features=28**2, out_features=100)\n",
        "        self.relu = ReLU()\n",
        "        self.linear2 = Linear(in_features=100, out_features=10)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        logits = self.linear2(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = SimpleMLP()\n",
        "print(model)\n",
        "tests.test_mlp_module(SimpleMLP)\n",
        "tests.test_mlp_forward(SimpleMLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wFEVgZWjBUG"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = Flatten()\n",
        "        self.linear1 = Linear(in_features=28 * 28, out_features=100)\n",
        "        self.relu = ReLU()\n",
        "        self.linear2 = Linear(in_features=100, out_features=10)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.linear2(self.relu(self.linear1(self.flatten(x))))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUsPcuGNjBUG"
      },
      "source": [
        "In the next section, we'll learn how to train and evaluate our model on real data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pual9hHjBUG"
      },
      "source": [
        "# 2️⃣ Training Neural Networks\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand how to work with transforms, datasets and dataloaders\n",
        "> - Understand the basic structure of a training loop\n",
        "> - Learn how to write your own validation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgkKLYK2jBUG"
      },
      "source": [
        "## Transforms, Datasets & DataLoaders\n",
        "\n",
        "Before we use this model to make any predictions, we first need to think about our input data. Below is a block of code to fetch and process MNIST data. We will go through it line by line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EG9SNl8UjBUG",
        "outputId": "58025a77-81d3-475a-ac6d-2978a0ab45b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_batch.shape=torch.Size([64, 1, 28, 28])\n",
            "label_batch.shape=torch.Size([64])\n",
            "\n",
            "img.shape=torch.Size([1, 28, 28])\n",
            "label=7\n",
            "\n"
          ]
        }
      ],
      "source": [
        "MNIST_TRANSFORM = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(0.1307, 0.3081),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def get_mnist(trainset_size: int = 10_000, testset_size: int = 1_000) -> tuple[Subset, Subset]:\n",
        "    \"\"\"Returns a subset of MNIST training data.\"\"\"\n",
        "\n",
        "    # Get original datasets, which are downloaded to \"chapter0_fundamentals/exercises/data\" for future use\n",
        "    mnist_trainset = datasets.MNIST(exercises_dir / \"data\", train=True, download=True, transform=MNIST_TRANSFORM)\n",
        "    mnist_testset = datasets.MNIST(exercises_dir / \"data\", train=False, download=True, transform=MNIST_TRANSFORM)\n",
        "\n",
        "    # # Return a subset of the original datasets\n",
        "    mnist_trainset = Subset(mnist_trainset, indices=range(trainset_size))\n",
        "    mnist_testset = Subset(mnist_testset, indices=range(testset_size))\n",
        "\n",
        "    return mnist_trainset, mnist_testset\n",
        "\n",
        "\n",
        "mnist_trainset, mnist_testset = get_mnist()\n",
        "mnist_trainloader = DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
        "mnist_testloader = DataLoader(mnist_testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Get the first batch of test data, by starting to iterate over `mnist_testloader`\n",
        "for img_batch, label_batch in mnist_testloader:\n",
        "    print(f\"{img_batch.shape=}\\n{label_batch.shape=}\\n\")\n",
        "    break\n",
        "\n",
        "# Get the first datapoint in the test set, by starting to iterate over `mnist_testset`\n",
        "for img, label in mnist_testset:\n",
        "    print(f\"{img.shape=}\\n{label=}\\n\")\n",
        "    break\n",
        "\n",
        "t.testing.assert_close(img, img_batch[0])\n",
        "assert label == label_batch[0].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZPruRoVjBUG"
      },
      "source": [
        "The `torchvision` package consists of popular datasets, model architectures, and common image transformations for computer vision, and `torchvision.transforms` provides access to a suite of functions for preprocessing data. We define a transform for the MNIST data (which is applied to each image in the dataset) by composing `ToTensor` (which converts a `PIL.Image` object into a PyTorch tensor) and `Normalize` (which takes arguments for the mean and standard deviation, and performs the linear transformation `x -> (x - mean) / std`). For the latter, we use `0.1307` and `0.3081` which are the empirical mean & std of the raw data (so after this transformation, the data will have mean 0 and variance 1).\n",
        "\n",
        "Next, we define our datasets using `torchvision.datasets`. The first argument tells us where to save our data to (so that when we run this in the future we won't have to re-save it), and `transform=MNIST_TRANSFORM` tells us that we should apply our previously defined `transform` to each element in our dataset. We also use `Subset` which allows us to return a slice of the dataset rather than the whole thing (because our model won't need much data to train!).\n",
        "\n",
        "Finally, since our dataset only allows for iteration over individual datapoints, we wrap it in `DataLoader` which enables iteration over **batches**. It also provides useful arguments like `shuffle`, which determine whether we randomize the order after each epoch. The code above demonstrates iteration over the dataset & dataloader respectively, showing how the first element in the dataloader's first batch equals the first element in the dataset (note that this wouldn't be true for the training set, because we've shuffled it).\n",
        "\n",
        "<details>\n",
        "<summary>Aside - why batch sizes are often powers of 2</summary>\n",
        "\n",
        "It's common to see batch sizes which are powers of two. The motivation is for efficient GPU utilisation, since processor architectures are normally organised around powers of 2, and computational efficiency is often increased by having the items in each batch split across processors. Or at least, that's the idea. The truth is a bit more complicated, and some studies dispute whether it actually saves time, so at this point it's more of a standard convention than a hard rule which will always lead to more efficient training.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScJ71Ki8jBUG"
      },
      "source": [
        "Before proceeding, try and answer the following questions:\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Question - can you explain why we include a data normalization function in <code>torchvision.transforms</code> ?</summary>\n",
        "\n",
        "One consequence of unnormalized data is that you might find yourself stuck in a very flat region of the domain, and gradient descent may take much longer to converge.\n",
        "\n",
        "Normalization isn't strictly necessary for this reason, because any rescaling of an input vector can be effectively undone by the network learning different weights and biases. But in practice, it does usually help speed up convergence.\n",
        "\n",
        "Normalization also helps avoid numerical issues.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Question - what is the benefit of using <code>shuffle=True</code> when defining our dataloaders? What might the problem be if we didn't do this?</summary>\n",
        "\n",
        "Shuffling is done during the training to make sure we aren't exposing our model to the same cycle (order) of data in every epoch. It is basically done to ensure the model isn't adapting its learning to any kind of spurious pattern.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iTKJ-PCjBUG"
      },
      "source": [
        "### Aside - `tqdm`\n",
        "\n",
        "You might have seen some blue progress bars running when you first downloaded your MNIST data. These were generated using a library called `tqdm`, which is also a really useful tool when training models or running any process that takes a long period of time.\n",
        "\n",
        "The `tqdm` function wraps around an iterable, and displays a progress bar as you iterate through it. The code below shows a minimal example:\n",
        "\n",
        "```python\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "for i in tqdm(range(100)):\n",
        "    time.sleep(0.1)\n",
        "```\n",
        "\n",
        "There are some more advanced features of `tqdm` too, for example:\n",
        "\n",
        "- If you define the progress bar `pbar = tqdm(...)` before your iteration, then you have the option of adding extra information to it using `pbar.set_description` or `pbar.set_postfix`\n",
        "- You can specify the total number of iterations with `tqdm(iterable, total=...)`; this is actually very important when the iterable is something like `enumerate(...)` which doesn't have a length attribute, since tqdm will usually try and infer the total from calling `len` on the iterable you pass it.\n",
        "\n",
        "Here's some code that demonstrates these extra features:\n",
        "\n",
        "```python\n",
        "word = \"hello!\"\n",
        "pbar = tqdm(enumerate(word), total=len(word))\n",
        "t0 = time.time()\n",
        "\n",
        "for i, letter in pbar:\n",
        "    time.sleep(1.0)\n",
        "    pbar.set_postfix(i=i, letter=letter, time=f\"{time.time()-t0:.3f}\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "word = \"hello!\"\n",
        "pbar = tqdm(enumerate(word), total=len(word))\n",
        "t0 = time.time()\n",
        "\n",
        "for i, letter in pbar:\n",
        "    time.sleep(1.0)\n",
        "    pbar.set_postfix(i=i, letter=letter, time=f\"{time.time()-t0:.3f}\")"
      ],
      "metadata": {
        "id": "Ym7-7RaEHc19",
        "outputId": "d3db9a70-33a0-4bb4-e70e-149a5f4f5d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d5b7fbf28619435d9bcc7dbabcb904d2",
            "34803d116fa349648237375ed3cdece0",
            "2348d3d1dc664563be768f1ecb08aff4",
            "18f3efdad1374ee98e175e302b671a55",
            "803f2380903641d998a15831e6cc00f8",
            "bc5c751b33304309a5d7720b21e87eb1",
            "fd4a65d086e74890937d91593b026872",
            "e1b06c76e72440fab828f0901cc2eb4f",
            "706ec976f17b4708869455a94b0a319f",
            "7390c41849ef489280a9dfeac2213aaa",
            "47e6e294860146179d5a67a4c50bf800"
          ]
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5b7fbf28619435d9bcc7dbabcb904d2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfRC2yXljBUG"
      },
      "source": [
        "### Aside - `device`\n",
        "\n",
        "One last thing to discuss before we move onto training our model: **GPUs**. We'll discuss this in more detail in later exercises. For now, [this page](https://wandb.ai/wandb/common-ml-errors/reports/How-To-Use-GPU-with-PyTorch---VmlldzozMzAxMDk) should provide a basic overview of how to use your GPU. A few things to be aware of here:\n",
        "\n",
        "* The `to` method is really useful here - it can move objects between different devices (i.e. CPU and GPU) *as well as* changing a tensor's datatype.\n",
        "    * Note that `to` is never inplace for tensors (i.e. you have to call `x = x.to(device)`), but when working with models, calling `model = model.to(device)` or `model.to(device)` are both perfectly valid.\n",
        "* Errors from having one tensor on cpu and another on cuda are very common. Some useful practices to avoid this:\n",
        "    * Throw in assert statements, to make sure tensors are on the same device\n",
        "    * Remember that when you initialise an array (e.g. with `t.zeros` or `t.arange`), it will be on CPU by default.\n",
        "    * Tensor methods like [`new_zeros`](https://pytorch.org/docs/stable/generated/torch.Tensor.new_zeros.html) or [`new_full`](https://pytorch.org/docs/stable/generated/torch.Tensor.new_full.html) are useful, because they'll create tensors which match the device and dtype of the base tensor.\n",
        "\n",
        "It's common practice to put a line like this at the top of your file, defining a global variable which you can use in subsequent modules and functions (excluding the print statement):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pEYxzx0HjBUG",
        "outputId": "08990356-316e-4994-81e5-ecd164f4cf5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# If this is CPU, we recommend figuring out how to get cuda access (or MPS if you're on a Mac).\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMTdW3bGjBUG"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Below is a very simple training loop, which you can run to train your model.\n",
        "\n",
        "In later exercises, we'll try to **modularize** our training loops. This will involve things like creating a `Trainer` class which wraps around our model, and giving it methods like `training_step` and `validation_step` which correspond to different parts of the training loop. This will make it easier to add features like logging and validation, and will also make our code more readable and easier to refactor. However, for now we've kept things simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TaV3wfVgjBUO",
        "collapsed": true,
        "outputId": "28571738-7fc7-48c8-a5e2-cbaeab446b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5112daefd24543389dc3afc4fb3df1fd",
            "e7f7feee2d29400da204a03191f93a0c",
            "f8043ee4b90544eeb85ae92a7f73a900",
            "1e0027b45da2417fb8eca99b57e254e3",
            "3bcec62be1e349a18ac33e5f38be85c0",
            "ca90ed4dcf0140ae9f0926d291bde5a1",
            "3f4dde5dc1fb4e77b4fd895f59505377",
            "219b1c9f59434430b4f8cff57d49c8c6",
            "3cce3256a17d48dc9c012f4591bbd24c",
            "e5d9d365756b4ec39b148fd7fd568d7a",
            "6a769a7d9fd2451d886ce0bb4876604a",
            "edf0a3235d17423fb311df540fbd49ca",
            "7c7b82d910e243bcbccf1447f3c07156",
            "2f941c123af24d33bfc0db450405320d",
            "f49193d1bef247fa98e31b7348ec0399",
            "ae7bf005a1fc4082948ce336455317a8",
            "db9b0d87a34f4995910daa77e93cbdd6",
            "e05ae5faaa4d453da5866be06126f59e",
            "98cd4f3ae37844ff9b2aa299b78c3637",
            "5c8a02f96798418a95e70c5141912c09",
            "90ca6e8b91084595a875dc08835d2dbd",
            "d22ba470df344a2e87717f68c83f8727",
            "07dab8cca5c346c180a6df0da4e27c58",
            "40ffa7641c8e433ca63acdee7262018e",
            "879aaf6eea614ce59d04ee592c124532",
            "3c904e6d821e4e5995a2503f732bbbbb",
            "d2b1bea5d48b4fc487084c79e152af2c",
            "b9cb617eba934b8c906fa852d39c4197",
            "0308028381de467da056c15d4b77c926",
            "5502d5c16fa14e499710d7c41b388c26",
            "d07d041f846546afaecb20d06515262b",
            "29d5cf65a5b840f5b584387ec660bebe",
            "b321abf3bcdb48f1b4626e6151609a5e"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5112daefd24543389dc3afc4fb3df1fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6439, -0.8978, -1.2377,  ..., -2.2993,  1.4862,  1.1042],\n",
            "        [ 0.6714,  0.3224,  1.1340,  ..., -0.9601,  1.2453, -0.9012],\n",
            "        [ 0.9605, -0.7162,  0.9997,  ..., -2.6302,  3.0559, -0.8547],\n",
            "        ...,\n",
            "        [-0.1504, -0.5710, -0.4122,  ...,  0.3631,  2.0022, -1.9501],\n",
            "        [-3.0196, -1.3667, -1.9004,  ..., -1.1356,  0.5725, -1.0006],\n",
            "        [-0.5474, -0.6341,  2.6418,  ..., -0.7040,  1.3268,  0.8921]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2199, -2.3002, -0.0534,  ..., -2.8882,  2.5300,  0.0425],\n",
            "        [ 1.6581,  0.5380,  0.2652,  ...,  0.1543,  1.4178,  0.7347],\n",
            "        [ 0.2992, -0.3941,  0.3810,  ..., -0.5176,  2.9150,  1.1840],\n",
            "        ...,\n",
            "        [-0.4027,  1.2534,  0.7676,  ...,  0.0110,  3.2487,  2.5523],\n",
            "        [-0.0599, -0.3135,  0.5807,  ..., -1.5747,  0.7253, -1.4682],\n",
            "        [-1.3463, -0.6981, -0.4295,  ..., -0.5801,  1.4432, -1.1126]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2007,  0.0670,  0.7319,  ..., -2.5761,  1.4299, -2.9093],\n",
            "        [-2.3437, -0.2824,  1.3789,  ..., -2.2445,  2.3955, -1.6484],\n",
            "        [ 0.3938,  0.3472, -0.6478,  ..., -0.2632,  1.6676, -1.2904],\n",
            "        ...,\n",
            "        [ 0.0342,  0.1305, -0.2842,  ..., -1.4596,  0.0732, -1.6964],\n",
            "        [ 0.0062,  0.0301,  0.7389,  ..., -1.4494,  3.4838, -1.9270],\n",
            "        [ 0.4118, -0.1322,  0.6103,  ..., -1.8788,  0.7644, -2.3649]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4012,  0.4020, -0.1819,  ...,  0.0889,  0.7461,  0.2937],\n",
            "        [ 0.8168, -0.2520, -1.6065,  ..., -2.5011,  0.3968,  0.9757],\n",
            "        [-1.7649, -0.6340, -1.5043,  ...,  0.8637,  1.8267, -0.2170],\n",
            "        ...,\n",
            "        [ 0.5425,  0.1333,  0.4176,  ..., -0.7029,  0.9485,  1.4993],\n",
            "        [-1.2109,  0.6436, -1.8877,  ..., -2.0355,  2.1750,  2.1443],\n",
            "        [-2.7365, -2.2064,  0.6085,  ..., -1.8118,  1.9021, -3.0573]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6715, -1.8023, -0.5661,  ..., -3.7065,  0.4657, -0.8083],\n",
            "        [-1.4243,  0.0787,  1.2411,  ..., -0.7328,  0.0558,  0.8019],\n",
            "        [-1.3909,  1.8768, -1.3171,  ..., -1.1747, -0.1659,  0.0496],\n",
            "        ...,\n",
            "        [-0.2400, -0.1575, -0.1876,  ..., -3.0338,  3.0247, -3.8550],\n",
            "        [ 2.5488,  0.9392, -1.0118,  ..., -0.4534,  0.5999,  0.1669],\n",
            "        [ 1.3543, -1.1839,  1.9098,  ..., -1.6620,  1.1872, -1.9417]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0611,  0.6646,  0.2505,  ..., -0.5640,  3.0125, -1.3352],\n",
            "        [-0.2939,  0.2094,  0.3862,  ..., -1.6481,  1.5661, -1.3472],\n",
            "        [ 0.4276, -1.1181,  3.2292,  ..., -2.8244,  2.9804, -2.3645],\n",
            "        ...,\n",
            "        [ 1.5999, -0.2894,  0.1507,  ..., -0.4641, -1.7869,  0.7241],\n",
            "        [-1.0384, -0.7954,  1.2966,  ..., -1.5963,  0.7428, -1.6526],\n",
            "        [ 0.0808, -1.0887,  0.4546,  ..., -2.6341,  0.2876,  0.0501]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5379,  1.5618, -0.8810,  ...,  1.9821, -0.6387,  0.3340],\n",
            "        [ 0.5550,  1.5915,  0.0564,  ..., -0.7225,  2.7924, -1.2941],\n",
            "        [ 1.6134, -0.0743, -0.2432,  ..., -4.3922,  0.0265, -1.2010],\n",
            "        ...,\n",
            "        [ 0.1697,  0.6619,  0.3881,  ..., -1.8575,  1.4815,  0.2862],\n",
            "        [-0.4287, -1.4061,  0.7689,  ..., -3.1328,  0.7713, -2.2116],\n",
            "        [-1.2964,  1.6634,  0.0393,  ..., -1.1541,  3.7073,  1.5252]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4798, -1.0275,  2.9887,  ..., -1.6807,  0.4962, -1.5879],\n",
            "        [ 0.5542,  2.4780, -0.3615,  ..., -1.5051,  0.4860, -1.8386],\n",
            "        [-0.9900,  0.0305,  3.2811,  ..., -2.6134,  1.1458, -0.6563],\n",
            "        ...,\n",
            "        [ 0.6082,  1.6494,  0.5389,  ..., -1.8436,  2.4215, -2.4427],\n",
            "        [ 0.6604,  2.8973,  1.6756,  ...,  0.9704,  0.5683, -2.3312],\n",
            "        [-1.9759, -1.8179, -1.2196,  ..., -0.4205, -0.9558, -1.6505]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0429,  2.3272,  0.3363,  ..., -1.6432,  1.1039, -2.8582],\n",
            "        [-0.7938,  1.3249,  0.7353,  ...,  0.2986,  1.0877, -1.2902],\n",
            "        [-0.3964,  1.8051, -0.7744,  ..., -0.0377, -0.2562, -1.1715],\n",
            "        ...,\n",
            "        [-2.1267,  1.5062,  2.3340,  ..., -3.9725,  2.2442, -1.6441],\n",
            "        [ 1.5330,  1.8707,  0.7289,  ..., -4.4524,  0.9923, -2.3798],\n",
            "        [-1.1141, -1.4135, -0.5241,  ..., -0.1400,  3.5488, -1.1615]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2165,  1.6008,  0.5325,  ..., -1.8056,  1.8193, -1.9999],\n",
            "        [-1.0635,  0.7105,  0.4488,  ..., -3.1053, -0.2030,  0.7895],\n",
            "        [ 0.1992,  2.5403,  1.3176,  ...,  0.8854,  0.9105, -2.4714],\n",
            "        ...,\n",
            "        [-0.1265,  2.2187, -0.3580,  ..., -0.0930, -0.7361, -1.7486],\n",
            "        [-0.2753,  2.4728,  1.0309,  ..., -0.5275,  0.5830,  0.1703],\n",
            "        [-3.3158, -2.0939,  1.4601,  ..., -3.1260,  2.1813, -0.6644]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5610,  3.7490, -1.2413,  ..., -2.2068,  0.2774, -0.7724],\n",
            "        [ 0.6943,  2.3225,  3.1522,  ..., -2.7775,  2.0275, -1.1378],\n",
            "        [-1.4704, -0.1356,  1.1068,  ...,  1.3644, -0.4947, -1.1039],\n",
            "        ...,\n",
            "        [-0.3074,  1.9013, -1.5788,  ..., -1.8907, -0.3645,  0.3295],\n",
            "        [ 0.6982,  1.2443,  1.3367,  ..., -0.9817,  2.9803,  1.2429],\n",
            "        [-0.2535,  2.4391,  0.0549,  ..., -1.0104, -0.2813, -2.9820]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5979,  1.5411,  1.8202,  ..., -1.6842,  2.1668,  0.0961],\n",
            "        [ 0.2712,  1.7543,  1.7402,  ..., -3.2767,  0.3582, -3.6395],\n",
            "        [-0.4589, -0.1159,  1.0825,  ...,  1.1173, -0.2354, -1.0031],\n",
            "        ...,\n",
            "        [-0.9330,  1.2809,  4.1330,  ..., -2.8200,  0.7051, -3.9019],\n",
            "        [ 0.7358,  1.8140,  1.2889,  ...,  0.8697,  0.9558, -1.8498],\n",
            "        [-0.3914,  2.1235, -0.2670,  ..., -0.9153,  0.6941,  1.2585]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5611,  0.3169,  2.9398,  ..., -0.3503,  0.2338, -0.5560],\n",
            "        [-2.8702,  0.5998, -0.2673,  ..., -2.7509,  2.5706, -1.7418],\n",
            "        [-0.7154,  3.6358, -0.3368,  ..., -0.5074, -0.9637, -1.7147],\n",
            "        ...,\n",
            "        [-1.8207, -0.6088,  2.3825,  ..., -1.6822,  2.2770, -0.4710],\n",
            "        [-1.5651, -0.3504,  0.3390,  ..., -3.5414,  1.5655,  0.6832],\n",
            "        [ 0.2509,  2.6081,  0.0850,  ..., -0.4484,  2.3667, -0.6836]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2052,  2.7978,  0.1269,  ...,  0.1359,  1.0734, -1.9911],\n",
            "        [-1.5846,  1.6825,  0.3716,  ..., -2.2011,  2.9308, -0.5826],\n",
            "        [-2.3399,  0.7161,  3.3571,  ..., -0.7192,  0.7927,  0.1823],\n",
            "        ...,\n",
            "        [-1.4921,  1.5554, -0.3094,  ..., -5.1898,  2.1150, -0.2496],\n",
            "        [-1.9543, -2.7657, -1.8003,  ...,  2.0216,  0.3492, -0.4370],\n",
            "        [-2.5811,  1.9966,  3.1732,  ..., -3.5476,  3.3324,  0.4356]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7949,  3.6073,  3.0807,  ..., -3.3387,  3.7711, -0.3922],\n",
            "        [ 0.8263,  1.7727, -2.3226,  ...,  0.0916,  0.1128,  0.5510],\n",
            "        [-0.5761,  0.2611,  1.7376,  ..., -1.8735,  0.8872,  1.3918],\n",
            "        ...,\n",
            "        [-1.0712,  1.0501,  0.5059,  ...,  1.7287,  0.4956,  0.3425],\n",
            "        [-1.7777,  0.0730, -0.7368,  ..., -1.2552, -0.3480,  2.3474],\n",
            "        [-2.0529, -0.3904,  3.0306,  ..., -2.2923,  2.7359, -0.0385]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2709,  3.3271,  1.1888,  ..., -3.2097,  0.7298, -3.2965],\n",
            "        [ 0.1031, -0.7580, -0.4619,  ...,  1.6303,  2.2675,  0.8019],\n",
            "        [ 0.9215,  2.2015, -0.0372,  ..., -3.3411,  1.0685,  1.5502],\n",
            "        ...,\n",
            "        [-1.0273,  2.3569, -0.3656,  ..., -0.8917,  0.1599, -0.9307],\n",
            "        [-0.9026,  0.5846,  0.5150,  ...,  1.1274,  2.7796, -0.4972],\n",
            "        [-2.9943,  0.6581, -0.6562,  ..., -0.1924, -0.1159,  1.0252]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6782e-03,  2.1487e-01,  8.7733e-01,  ...,  1.9210e+00,\n",
            "         -9.0612e-01, -7.1351e-01],\n",
            "        [-9.0478e-01,  6.5483e-01, -3.7829e-01,  ...,  1.4479e+00,\n",
            "          1.8530e+00,  2.2264e+00],\n",
            "        [-7.3005e-01, -1.8401e-01,  1.2225e+00,  ..., -1.5278e+00,\n",
            "          3.5087e+00,  2.7905e+00],\n",
            "        ...,\n",
            "        [-9.1999e-01,  2.1932e+00,  1.0562e+00,  ..., -1.5841e-01,\n",
            "          6.7940e-01,  1.0329e+00],\n",
            "        [ 2.8835e-01,  3.1922e+00,  2.4291e+00,  ..., -2.2829e+00,\n",
            "          1.2531e+00, -7.5504e-01],\n",
            "        [ 2.3379e+00,  3.8210e+00,  1.6014e+00,  ..., -9.4472e-01,\n",
            "          8.6014e-01, -9.3486e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2414,  0.8023,  0.1775,  ..., -0.1643,  4.6226, -0.0062],\n",
            "        [ 0.8784,  2.6842,  0.2357,  ..., -1.2548,  2.2825, -0.4962],\n",
            "        [ 1.2830,  1.9347,  2.0566,  ..., -1.9011,  3.7530, -0.2718],\n",
            "        ...,\n",
            "        [ 0.3179,  0.5146, -0.2172,  ...,  1.4190,  0.9488,  1.5910],\n",
            "        [-3.3674, -0.2616,  1.8238,  ..., -0.7750,  0.8316, -0.2634],\n",
            "        [-0.3128,  1.1300,  3.6944,  ..., -1.0134,  0.7287, -1.2237]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8843, -0.9115, -2.1547,  ..., -0.5984,  1.1082,  0.1293],\n",
            "        [-0.5104,  3.1004,  0.5830,  ..., -0.4315,  1.1223,  1.1854],\n",
            "        [ 0.5067,  2.4493,  3.3233,  ..., -3.2919,  3.5148,  0.5475],\n",
            "        ...,\n",
            "        [-2.0941,  2.5208,  1.2999,  ..., -1.1320,  1.1277,  3.1888],\n",
            "        [-1.0560,  3.2790, -0.1335,  ..., -2.0444,  1.2527, -0.5738],\n",
            "        [ 0.2594,  0.0392,  2.7149,  ..., -0.9723,  3.5686, -3.0863]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5232,  1.1983, -0.4861,  ...,  1.5145, -0.5083, -0.4201],\n",
            "        [-1.5236, -0.3704,  0.9428,  ...,  2.4972,  1.9142,  1.1004],\n",
            "        [-3.0887, -0.7653,  0.6394,  ...,  0.0660, -0.4515, -0.2002],\n",
            "        ...,\n",
            "        [-1.7715,  0.5350, -1.8186,  ..., -4.2971,  2.0882,  1.4366],\n",
            "        [ 1.4263,  3.3501,  0.9090,  ...,  0.2000,  2.6470, -0.4381],\n",
            "        [-2.5602,  3.6651,  0.5604,  ...,  0.1234,  2.6224,  1.3228]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4675,  2.8977,  3.4579,  ..., -1.5310,  3.5383, -3.3490],\n",
            "        [ 0.3611,  2.3629,  1.8508,  ..., -0.9860,  3.4933, -1.4652],\n",
            "        [ 0.4442,  2.9009, -0.1857,  ...,  1.0030,  1.1366, -1.7946],\n",
            "        ...,\n",
            "        [-1.9364, -2.3390, -0.3490,  ..., -1.0023,  5.3383,  2.1933],\n",
            "        [ 1.4442,  3.3288,  0.7833,  ...,  2.2684,  0.2037, -0.8606],\n",
            "        [ 0.3770,  2.1038,  1.3955,  ...,  0.5951,  2.3477, -0.6283]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6158,  3.4265,  0.7629,  ..., -0.2142,  2.8924, -1.6123],\n",
            "        [-0.0394,  2.1377,  2.9662,  ..., -2.4749,  4.7122, -1.9493],\n",
            "        [-0.2740,  2.7702,  3.7447,  ..., -3.1238,  2.0113, -1.7229],\n",
            "        ...,\n",
            "        [ 0.3416,  1.3470,  2.1518,  ..., -1.7935,  1.5152, -0.6096],\n",
            "        [-1.0283,  1.6785,  0.3162,  ..., -0.6202,  0.7284,  3.1198],\n",
            "        [-1.1723,  3.5265,  0.9246,  ...,  0.3314,  1.2554,  4.1678]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4546e-03,  2.9552e+00, -4.6563e-02,  ..., -1.9884e+00,\n",
            "          1.2212e+00, -8.0618e-01],\n",
            "        [-1.4168e+00,  4.0537e+00, -5.2454e-02,  ..., -1.5952e+00,\n",
            "          4.4089e-01,  1.2368e-01],\n",
            "        [ 5.1660e-02,  3.6683e-01,  4.9029e+00,  ..., -2.6110e+00,\n",
            "          1.9484e+00, -3.8922e+00],\n",
            "        ...,\n",
            "        [ 4.9171e-01,  1.6786e+00,  3.5657e-01,  ...,  4.3736e-01,\n",
            "          8.8175e-01,  1.6071e+00],\n",
            "        [-6.3598e-01,  3.9247e+00, -2.9368e-02,  ..., -1.6575e+00,\n",
            "         -2.4158e-01, -6.8452e-01],\n",
            "        [-9.6656e-02,  2.6422e+00,  6.1689e+00,  ..., -1.6468e-01,\n",
            "          3.4339e+00, -2.8159e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.8457e-01,  5.2565e-01,  6.6382e-02,  ...,  1.3381e+00,\n",
            "          2.3545e+00, -6.4829e-01],\n",
            "        [ 1.9816e+00, -5.1527e-01,  1.3692e+00,  ...,  8.8057e-01,\n",
            "         -1.8559e-01, -7.3411e-01],\n",
            "        [-7.6660e-01,  1.5818e+00,  2.1495e-01,  ...,  1.4191e+00,\n",
            "          3.2744e+00,  1.4941e+00],\n",
            "        ...,\n",
            "        [ 7.1359e-01,  3.2148e+00,  1.6330e+00,  ..., -8.5341e-01,\n",
            "          6.4313e-04, -1.8523e+00],\n",
            "        [-1.2679e+00,  2.0811e-01,  2.3989e+00,  ..., -3.9058e-01,\n",
            "          2.5015e+00,  2.8014e+00],\n",
            "        [-2.6757e-02,  2.3624e+00, -1.3090e+00,  ..., -5.3616e-01,\n",
            "          1.4132e-01,  3.0699e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7310,  0.0190, -0.0597,  ...,  1.9287,  2.7954,  4.1091],\n",
            "        [-2.1500, -2.8995, -0.9213,  ..., -1.0509,  3.9097, -2.1605],\n",
            "        [ 0.8569,  1.0761,  0.4959,  ..., -1.0341,  0.9977,  1.3061],\n",
            "        ...,\n",
            "        [-0.1111,  0.3891,  1.2210,  ..., -1.9529,  0.5315,  2.2893],\n",
            "        [-2.1097,  1.8788,  0.2322,  ...,  4.0881,  0.1485, -1.4816],\n",
            "        [-2.1968,  0.6023,  0.5138,  ...,  0.2525,  0.0649, -0.1722]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3094,  0.5424, -0.3412,  ...,  0.4866,  2.0543, -1.7016],\n",
            "        [-1.0490,  4.3589,  0.3996,  ...,  0.0515,  2.1563, -0.8526],\n",
            "        [ 1.7282,  2.6865,  1.8963,  ...,  0.0177,  1.9049, -0.6834],\n",
            "        ...,\n",
            "        [-0.2486, -0.3999,  1.5295,  ..., -1.0852,  1.3673, -3.7108],\n",
            "        [ 1.6817,  3.0028,  0.8356,  ...,  0.0572,  1.6781, -0.4979],\n",
            "        [ 0.2739,  3.5835,  0.3883,  ...,  2.5049,  0.8056, -1.0733]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0791,  1.5042,  3.1757,  ...,  1.5655,  1.5990, -0.4723],\n",
            "        [ 1.6190,  2.6831,  0.5277,  ...,  0.4797,  1.1507, -2.1182],\n",
            "        [-3.2375,  0.7056,  3.8691,  ...,  0.9868,  1.1110,  0.6450],\n",
            "        ...,\n",
            "        [-0.3591,  1.6060,  0.2718,  ..., -0.4625,  2.0569, -2.8671],\n",
            "        [-1.4624,  0.2730,  0.3961,  ..., -0.7266,  1.6905, -2.0525],\n",
            "        [-1.0252,  3.5427,  0.2509,  ..., -1.6724,  1.6097,  3.7494]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1748e+00,  1.1938e+00,  3.8770e+00,  ..., -2.6766e+00,\n",
            "          3.2528e+00, -6.8725e-01],\n",
            "        [-1.3093e-01,  3.4519e+00,  4.0153e-01,  ..., -1.5225e+00,\n",
            "          1.2609e+00,  6.9372e-01],\n",
            "        [ 2.0324e+00,  2.1020e+00,  1.8131e+00,  ...,  4.5374e+00,\n",
            "          1.1504e+00, -1.2278e+00],\n",
            "        ...,\n",
            "        [ 1.9920e+00,  1.5132e+00,  1.5000e+00,  ...,  1.3431e+00,\n",
            "          1.3127e+00,  3.4511e+00],\n",
            "        [ 8.1552e-04,  3.0939e+00,  2.1101e+00,  ..., -7.9361e-01,\n",
            "          1.4747e+00, -7.5021e-01],\n",
            "        [-2.2114e+00, -5.2045e-01, -8.0559e-01,  ...,  5.4552e+00,\n",
            "          6.7952e-01,  6.7194e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2779, -0.1237,  0.6977,  ...,  0.8852,  2.5311,  3.3612],\n",
            "        [ 0.0919,  0.1254,  0.1798,  ...,  1.9092,  0.6587,  2.7582],\n",
            "        [ 1.1934,  3.7554,  1.0758,  ...,  0.4781,  2.0679, -1.3070],\n",
            "        ...,\n",
            "        [ 1.1407,  3.1565,  1.4559,  ..., -2.4622,  0.7767, -0.5040],\n",
            "        [ 0.0526,  1.5837,  2.2932,  ..., -0.1086,  3.9960, -1.0451],\n",
            "        [-2.4702,  2.2362, -1.5621,  ...,  2.0443,  1.9606,  1.9942]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4230e-01,  6.0875e-01,  6.6855e-01,  ...,  2.5387e+00,\n",
            "          2.0048e+00,  2.6805e+00],\n",
            "        [-8.8342e-01,  1.6057e+00,  1.5551e+00,  ..., -8.9372e-01,\n",
            "          1.2236e+00,  1.8615e+00],\n",
            "        [ 1.1536e+00,  3.0581e+00,  1.5182e+00,  ..., -1.2192e-02,\n",
            "          1.4395e+00,  2.0856e+00],\n",
            "        ...,\n",
            "        [-1.3793e+00, -1.4711e+00, -8.4046e-01,  ..., -1.5667e-03,\n",
            "          6.1693e-02,  4.9984e+00],\n",
            "        [ 4.6072e-01,  2.2965e+00,  4.6634e+00,  ..., -1.6529e+00,\n",
            "          3.2526e+00, -2.1682e+00],\n",
            "        [-1.4196e+00,  1.5531e+00,  1.2961e-01,  ..., -7.4151e-01,\n",
            "          4.9607e-01,  2.5697e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2897,  2.8526,  3.2450,  ..., -0.2110,  3.1773, -0.0487],\n",
            "        [ 1.9792,  3.6299,  1.2473,  ..., -0.1150,  1.9552, -0.9318],\n",
            "        [-2.2098, -2.5762,  2.1678,  ...,  3.5283,  1.7518, -1.4889],\n",
            "        ...,\n",
            "        [-0.6752,  3.3376,  0.7908,  ..., -2.1294,  0.9393, -0.4305],\n",
            "        [-2.4110,  2.5029,  1.4443,  ..., -1.4167,  0.2160,  1.5422],\n",
            "        [ 1.4557,  4.1463,  0.9109,  ...,  1.3320,  1.2548, -0.7811]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5792,  2.5248,  1.1011,  ..., -1.9285,  1.0921,  2.9885],\n",
            "        [-2.1013,  1.2861, -1.7689,  ...,  1.1563,  0.7255,  2.0627],\n",
            "        [ 2.6464,  5.0312,  2.4587,  ...,  0.3651,  1.2715, -0.7258],\n",
            "        ...,\n",
            "        [-0.8259,  3.1388,  3.7240,  ...,  0.4085,  2.7082,  0.2336],\n",
            "        [ 1.0327,  3.3528,  0.1969,  ...,  1.4954,  1.6126, -0.8415],\n",
            "        [-0.1177,  2.4203, -2.7314,  ..., -0.3536,  0.9818, -0.1929]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9990,  1.9366,  3.8576,  ..., -2.2772,  2.4704, -0.8918],\n",
            "        [-1.1172,  2.6577,  2.2351,  ...,  0.1204, -0.9117,  3.1494],\n",
            "        [-0.6174,  1.0125,  2.7408,  ...,  1.5013, -0.6662,  0.1250],\n",
            "        ...,\n",
            "        [-0.9492,  2.4635,  0.7827,  ...,  0.9011,  1.5229,  2.0904],\n",
            "        [-1.3895,  3.5427, -1.6259,  ...,  1.5604, -0.7625,  0.1147],\n",
            "        [-2.8672,  2.7646,  1.3337,  ..., -0.3068,  3.7054,  0.7005]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2706,  3.3007,  0.9530,  ...,  0.4409,  0.2165,  2.7906],\n",
            "        [ 1.4708,  5.4352,  1.7877,  ...,  2.3294,  0.8024, -0.7365],\n",
            "        [-1.0718,  4.2528,  0.9072,  ...,  1.4810,  2.2778, -0.1643],\n",
            "        ...,\n",
            "        [-2.3328,  1.7879,  1.9513,  ..., -0.6691,  1.1269,  2.4912],\n",
            "        [ 1.0251,  2.1947,  1.3928,  ...,  2.7460, -0.0438, -1.7633],\n",
            "        [-2.2619,  2.9381, -0.3768,  ..., -0.4658,  1.2541,  3.2754]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8852,  3.3523,  0.4755,  ...,  1.4805,  1.7393, -0.7136],\n",
            "        [-1.4197,  5.5062,  1.0568,  ..., -0.0144,  0.1651,  3.3925],\n",
            "        [-0.5746,  2.4192,  5.1868,  ..., -1.8409,  3.0348, -3.5976],\n",
            "        ...,\n",
            "        [-0.2740,  4.5403,  1.2713,  ..., -0.2106,  2.1228,  1.7607],\n",
            "        [-0.4999,  0.7479, -1.9531,  ...,  0.1648,  2.7130,  3.7963],\n",
            "        [ 0.8038,  4.0418,  2.1240,  ..., -2.4593,  2.0737,  2.7478]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5881,  5.6307,  2.0302,  ..., -0.0849,  0.9998, -0.7494],\n",
            "        [ 1.1165,  2.1548,  2.6124,  ..., -0.4546,  1.2233, -1.3934],\n",
            "        [-1.2663,  1.6823,  1.3691,  ..., -2.0212,  2.0193, -0.5054],\n",
            "        ...,\n",
            "        [ 0.9587, -0.3062,  3.2231,  ...,  1.8401,  0.6691,  0.9383],\n",
            "        [ 0.2778,  3.0111,  2.2739,  ..., -0.8810,  1.8631, -1.6616],\n",
            "        [-1.8895,  3.4331,  1.5285,  ..., -3.3218,  1.5789, -3.4518]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3673, -0.3668,  2.6486,  ...,  2.0018,  2.5627, -0.7122],\n",
            "        [-2.4922, -1.7059, -1.1095,  ...,  3.0516,  4.2543, -1.5996],\n",
            "        [ 0.1915,  3.9183,  3.4135,  ..., -3.0309,  1.3427, -2.3315],\n",
            "        ...,\n",
            "        [ 0.8275,  3.6011,  0.7489,  ...,  0.7576,  0.2372,  0.7080],\n",
            "        [-1.0302,  2.1542,  1.3820,  ..., -2.7003,  1.6990,  3.4820],\n",
            "        [-2.1485,  5.5517,  1.4964,  ..., -1.6966, -0.0744,  0.0255]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6078,  2.5470,  4.3643,  ..., -0.2669,  0.2176,  1.6834],\n",
            "        [-1.8401,  2.5423,  2.0045,  ...,  1.4074,  3.4291,  0.4153],\n",
            "        [-0.0782,  3.9144,  4.1530,  ..., -2.2822,  1.7875, -1.7904],\n",
            "        ...,\n",
            "        [ 0.3749,  1.4991,  3.2258,  ..., -0.6663,  4.0633,  0.4253],\n",
            "        [-0.9432, -0.9363,  1.3281,  ...,  2.1330,  3.1792,  1.1586],\n",
            "        [-2.6495,  0.4626, -2.7057,  ...,  1.9466,  1.7542,  1.7361]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8856,  2.0918, -3.5793,  ...,  1.1092, -0.0519,  1.6409],\n",
            "        [-0.6024,  3.6177,  1.7459,  ..., -0.4000,  0.0091,  2.2714],\n",
            "        [-0.2425,  2.8999,  1.8380,  ..., -1.6220,  2.4709, -0.1232],\n",
            "        ...,\n",
            "        [ 1.3835,  4.3142,  1.1618,  ...,  1.8787,  1.2568, -1.3747],\n",
            "        [-3.0595, -1.5564, -0.7052,  ...,  3.1938,  1.8950,  2.6267],\n",
            "        [-0.7830,  4.7805,  1.1153,  ..., -0.5833,  0.5475,  0.2257]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2748,  2.9403,  0.9100,  ..., -0.0951, -2.1105,  3.6071],\n",
            "        [-2.1302,  5.0703,  0.9660,  ..., -2.5034,  0.8549,  1.2802],\n",
            "        [-0.3002,  1.3493,  1.7542,  ..., -0.1461,  1.4541,  2.9015],\n",
            "        ...,\n",
            "        [ 0.7316,  4.2829,  0.6565,  ..., -1.3736,  2.7673,  0.1043],\n",
            "        [ 0.0070,  3.3969,  4.6146,  ..., -1.3219,  2.4196, -0.5729],\n",
            "        [-1.0579,  4.6116,  0.2294,  ..., -0.7927, -0.2116,  1.2433]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4740,  5.1848,  0.9743,  ...,  0.6019,  3.0410, -0.8331],\n",
            "        [ 1.3405,  3.7132, -0.0598,  ...,  0.7667,  0.2029, -0.6657],\n",
            "        [-1.5778,  5.1273,  0.8907,  ..., -1.8176,  0.3031,  2.9007],\n",
            "        ...,\n",
            "        [-2.0171,  2.3996,  3.3794,  ..., -0.8283,  2.2297,  0.0064],\n",
            "        [ 1.0509,  4.3251,  2.4871,  ..., -0.4022,  3.6222, -0.9918],\n",
            "        [-0.2457,  1.6806,  1.4206,  ..., -1.6398,  3.3465, -0.2569]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9110,  4.1787, -0.0856,  ...,  0.0909,  0.6383, -0.6580],\n",
            "        [-1.4843,  3.1926,  0.0472,  ..., -2.3527,  2.2553,  1.8363],\n",
            "        [-0.9101,  3.6247,  1.3824,  ..., -0.2995,  0.7118,  0.7594],\n",
            "        ...,\n",
            "        [ 2.4443,  3.4255,  2.0948,  ..., -0.7337,  2.7517, -1.1839],\n",
            "        [ 0.8472,  3.6829,  1.6111,  ...,  0.4810,  2.7173, -0.1428],\n",
            "        [-0.0750,  2.7715,  0.3075,  ...,  0.8079,  0.6137,  1.4771]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0888,  0.6125, -0.1194,  ...,  3.2425,  2.2010,  0.4145],\n",
            "        [ 1.4298,  4.5331,  0.2660,  ...,  0.6187,  0.2598, -0.4712],\n",
            "        [-0.3391,  4.1668,  2.1291,  ..., -2.8864,  0.0674,  2.4213],\n",
            "        ...,\n",
            "        [ 1.6008,  0.2237,  0.8595,  ..., -0.6339,  1.1604,  1.3956],\n",
            "        [ 0.3779,  4.2284,  0.0958,  ..., -0.2318,  1.9262,  1.3353],\n",
            "        [ 1.0731,  4.4525,  0.3216,  ...,  0.2758,  0.5291, -0.5748]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9614, -0.6219,  0.8788,  ..., -1.9051,  3.1049, -2.4037],\n",
            "        [-1.0028,  7.6163, -0.1940,  ..., -3.6012, -1.1535, -1.0074],\n",
            "        [-0.5562,  2.6463, -0.0512,  ..., -0.0213, -2.4917,  0.8635],\n",
            "        ...,\n",
            "        [ 2.0327,  2.8185,  0.5784,  ..., -1.5226,  1.8670,  0.9603],\n",
            "        [-0.3225,  3.5283,  1.0142,  ..., -1.3755,  1.2491,  0.1540],\n",
            "        [ 0.0800,  3.4746,  1.5499,  ...,  1.5461,  1.8976, -0.8827]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7803,  4.1832,  0.2829,  ..., -2.2775, -1.2848, -0.9717],\n",
            "        [-0.5478,  3.9678,  1.8241,  ..., -0.8670,  0.8734,  2.5060],\n",
            "        [ 0.1830,  2.8828,  0.9145,  ...,  0.7468,  1.2037,  2.5790],\n",
            "        ...,\n",
            "        [ 0.8356,  1.9663,  0.7917,  ...,  1.0543,  2.3993, -1.9030],\n",
            "        [ 0.2150,  4.0772,  3.0769,  ..., -1.4480,  1.2705, -2.5491],\n",
            "        [-1.0881,  4.7986,  3.8131,  ..., -0.5973,  3.6640, -0.2851]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4965,  0.9160,  3.0323,  ..., -1.9080,  3.1887, -0.2903],\n",
            "        [-1.1177,  0.4025,  2.6698,  ..., -2.1695,  0.9176,  0.9524],\n",
            "        [ 0.7545,  3.8419,  1.3215,  ..., -1.7266,  3.0418,  0.5507],\n",
            "        ...,\n",
            "        [-0.5300,  2.8629, -0.0733,  ..., -0.4423, -0.6993, -1.5190],\n",
            "        [-1.1890,  2.8959,  6.8973,  ..., -2.9782,  5.8983,  0.0492],\n",
            "        [-1.9952,  2.9878,  1.3839,  ...,  0.2072,  1.4318,  1.0779]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5835,  5.2303, -2.4944,  ..., -0.0224,  0.1097,  1.0517],\n",
            "        [ 1.1285,  4.4216,  0.1989,  ...,  0.7967,  1.1236, -0.4962],\n",
            "        [-0.5259,  4.1890,  4.4947,  ..., -4.3156,  4.3773, -1.8065],\n",
            "        ...,\n",
            "        [-0.2164,  4.7654,  2.6806,  ..., -1.6198,  2.8571,  0.7958],\n",
            "        [ 1.1462,  0.6495,  1.7843,  ..., -0.9971,  4.1623,  1.4213],\n",
            "        [-0.2077,  0.0374, -2.3386,  ...,  1.5219,  0.1940,  4.4382]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0645,  2.3163,  1.2981,  ..., -2.6191,  1.3453, -0.7156],\n",
            "        [-2.6732, -3.8408, -0.2004,  ..., -0.4156,  3.5439,  3.8115],\n",
            "        [-0.4624,  2.4612,  6.2484,  ..., -3.6788,  1.8828, -2.7938],\n",
            "        ...,\n",
            "        [-0.7280,  3.2037,  3.9236,  ..., -2.6803,  3.3220, -0.3758],\n",
            "        [ 1.6157,  3.7877, -0.1473,  ...,  0.0399,  2.0131, -0.7670],\n",
            "        [-3.2503,  3.9281, -0.2020,  ..., -1.7168, -0.8231,  2.8722]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6160,  4.6779,  0.9026,  ..., -0.4485,  1.6085, -1.8779],\n",
            "        [ 0.1623,  4.8474,  3.1287,  ..., -4.1450,  1.6457,  2.6139],\n",
            "        [ 1.2565,  4.5308, -0.0103,  ...,  0.0966,  0.4445, -0.2606],\n",
            "        ...,\n",
            "        [ 0.2979,  4.8351,  3.0711,  ..., -3.0360,  2.4142,  1.9659],\n",
            "        [ 1.8054,  2.4629,  3.0623,  ..., -3.4237,  4.6137,  1.1891],\n",
            "        [-1.0636,  0.3467,  0.6805,  ...,  1.9630,  3.3927,  1.5565]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2926,  5.4012,  0.1329,  ..., -0.9301, -0.1554,  0.0272],\n",
            "        [-1.4809,  3.6956,  0.5825,  ..., -2.2934, -0.3503,  1.2082],\n",
            "        [-2.3577,  0.5213,  4.0531,  ..., -3.5157,  3.8533, -0.5421],\n",
            "        ...,\n",
            "        [ 0.6280, -0.7215,  1.1618,  ..., -0.4760,  3.3584,  3.2333],\n",
            "        [ 0.0747,  4.8311,  5.9132,  ..., -3.6392,  3.0777, -1.1610],\n",
            "        [-0.5160,  2.1964,  7.0089,  ..., -4.0286,  4.7444,  0.5359]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6041,  2.5462, -2.8874,  ..., -0.8730,  0.0883, -0.5090],\n",
            "        [ 2.5452,  3.4076,  1.5592,  ..., -1.9668,  3.6622, -0.8640],\n",
            "        [ 1.5928,  3.5631,  0.6478,  ...,  0.8634,  1.3734, -0.9655],\n",
            "        ...,\n",
            "        [ 1.2995,  0.6899,  1.5518,  ..., -2.3346,  2.8556, -0.9478],\n",
            "        [ 0.4356,  4.2429,  0.8237,  ..., -1.5308,  1.1645, -0.1576],\n",
            "        [-2.7295,  0.1555,  1.1429,  ..., -4.1565,  4.0904, -2.9493]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5775, -0.0877,  2.7556,  ..., -0.8101,  5.0406,  0.3780],\n",
            "        [ 2.6614,  3.7033,  2.3198,  ..., -2.2034,  2.5741, -1.0788],\n",
            "        [-0.9875,  3.3515,  0.6750,  ...,  0.3921, -2.7080,  1.0848],\n",
            "        ...,\n",
            "        [-0.8836,  5.3004,  0.2830,  ..., -0.8720, -1.4090, -0.1294],\n",
            "        [-1.8584, -1.3044,  2.1979,  ..., -2.8649,  5.0855, -2.2746],\n",
            "        [-2.1919,  2.8937,  0.1842,  ..., -1.1586,  0.4176,  3.9831]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1958,  1.2586,  0.6315,  ..., -0.3328,  0.6704,  2.3476],\n",
            "        [-0.6868,  5.2247,  3.0347,  ..., -2.7250,  1.7830, -2.5736],\n",
            "        [ 1.2236,  4.1579,  2.2175,  ...,  3.3073,  2.2823, -1.9843],\n",
            "        ...,\n",
            "        [ 0.5160,  2.9058,  0.8568,  ..., -0.2377, -1.3902,  1.6646],\n",
            "        [ 0.4781,  4.7902,  2.2549,  ..., -1.5011,  1.9794,  3.9848],\n",
            "        [ 0.2484,  0.0753,  2.0373,  ...,  0.5140,  0.9258, -0.2329]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7352e+00,  4.1461e+00,  1.0316e+00,  ..., -2.3786e-01,\n",
            "          2.9882e+00, -1.0005e+00],\n",
            "        [ 1.4456e+00,  1.0684e+00,  2.3079e-01,  ...,  8.8311e-01,\n",
            "          1.8018e+00,  3.3457e+00],\n",
            "        [-2.3110e+00,  2.0921e+00, -8.6963e-01,  ..., -2.3503e+00,\n",
            "         -5.0307e-01,  3.9469e+00],\n",
            "        ...,\n",
            "        [ 7.7411e-01,  2.7141e+00,  3.5361e-01,  ..., -2.7932e+00,\n",
            "          4.2124e+00, -3.5225e-01],\n",
            "        [-8.4059e-04,  1.6178e+00, -3.5419e+00,  ..., -1.2398e+00,\n",
            "          1.9480e+00,  4.3177e+00],\n",
            "        [-5.5133e-01,  9.8273e-01,  7.2618e-01,  ..., -3.3499e-01,\n",
            "          4.6071e+00,  2.3558e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0514,  4.1165,  0.6957,  ..., -0.0361,  2.6908, -0.7084],\n",
            "        [-0.2208,  3.3337,  0.5709,  ..., -1.2512,  0.6899,  0.9851],\n",
            "        [ 0.5208,  3.3350,  0.8250,  ..., -0.9033,  1.8401,  1.0258],\n",
            "        ...,\n",
            "        [-3.4485,  5.8665,  0.1420,  ..., -4.7272, -0.1177,  0.0713],\n",
            "        [-0.6904,  2.4485,  0.6135,  ..., -0.7644,  1.5758,  1.9253],\n",
            "        [-0.2877,  3.1743,  0.1987,  ..., -2.2344,  1.6126, -1.0776]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8442,  1.7073,  3.0973,  ..., -0.5549,  2.4091, -1.6496],\n",
            "        [ 0.3106, -0.6251,  0.2777,  ..., -0.1053,  4.2232,  4.0150],\n",
            "        [ 0.3280,  0.2430,  1.7437,  ...,  0.4004,  3.4050, -0.4985],\n",
            "        ...,\n",
            "        [ 2.5851, -2.4385,  1.5923,  ...,  2.5165,  2.8066, -0.3592],\n",
            "        [ 2.5057, -1.2410,  2.2732,  ...,  2.6116,  1.4899, -0.0072],\n",
            "        [-1.6015,  4.2868,  1.1117,  ..., -0.5616, -0.2414,  1.9628]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7261,  4.0969,  3.8516,  ..., -2.4403,  2.5374, -2.0320],\n",
            "        [ 0.2300, -0.8310,  1.3954,  ...,  1.5617,  0.5273, -1.3925],\n",
            "        [-0.0739,  4.7562,  2.3531,  ..., -2.3968,  0.3201,  2.2795],\n",
            "        ...,\n",
            "        [-2.2355,  1.2583, -2.1243,  ..., -0.4818,  0.8147, -2.5209],\n",
            "        [ 3.1095,  3.4184,  1.3772,  ...,  0.1501,  1.0871, -0.7858],\n",
            "        [ 0.2061,  3.4403,  4.7233,  ..., -3.8059,  3.2574, -0.5634]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1101,  3.6833,  2.5633,  ..., -3.3676,  1.5447, -0.3740],\n",
            "        [-2.0404,  4.5486,  7.2091,  ..., -3.5882,  2.5440, -3.0571],\n",
            "        [ 1.2722,  5.8094,  2.0212,  ..., -0.8572,  0.3674, -1.6101],\n",
            "        ...,\n",
            "        [ 2.1613,  0.5575,  0.5148,  ..., -1.1945,  2.3517,  2.1795],\n",
            "        [-0.3808, -0.7042, -0.3363,  ...,  1.6184,  3.3406,  1.2677],\n",
            "        [-1.9647,  1.8237,  1.5429,  ..., -2.5158,  3.4002, -0.6115]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9922,  2.9384,  0.7977,  ..., -1.3447,  0.7490,  2.8688],\n",
            "        [ 2.1376,  5.5078,  3.7556,  ..., -3.9975,  1.4403, -1.9287],\n",
            "        [ 0.3678,  0.8963,  0.5204,  ...,  3.7446,  2.6410, -1.7105],\n",
            "        ...,\n",
            "        [ 0.8525, -0.8278,  0.6236,  ...,  2.6966,  1.3358, -1.0851],\n",
            "        [-0.4030,  4.5676,  1.9478,  ..., -0.3615,  1.0372,  2.1165],\n",
            "        [-0.2349,  3.4465,  0.9860,  ..., -3.5600,  0.4940,  1.7322]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4417, -0.6495,  0.5626,  ...,  0.5033,  2.7259,  4.4058],\n",
            "        [-0.6594,  5.6687,  3.7308,  ..., -3.8634,  1.6026,  1.4494],\n",
            "        [-1.7845,  0.2425,  0.4958,  ..., -1.9528,  2.2228, -1.2849],\n",
            "        ...,\n",
            "        [-2.4546,  2.1625,  4.3726,  ...,  1.0905,  1.2097, -1.8705],\n",
            "        [-1.7098,  2.9367,  0.2212,  ...,  0.2209,  0.8906,  1.3220],\n",
            "        [ 0.3500,  0.9407,  1.3548,  ...,  1.0491,  3.7294, -0.7575]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 7.5446e-01,  2.9421e+00,  3.0967e-01,  ...,  2.8090e-01,\n",
            "         -4.6050e-01,  2.4152e+00],\n",
            "        [-1.7216e+00,  2.1120e+00,  4.2360e+00,  ..., -3.3552e+00,\n",
            "          3.4088e+00, -4.3370e-01],\n",
            "        [ 2.4047e-01,  3.7092e+00,  4.1018e+00,  ..., -1.9135e+00,\n",
            "          9.9614e-01,  4.1712e-01],\n",
            "        ...,\n",
            "        [ 1.5396e-01,  2.9448e+00,  1.7408e+00,  ..., -1.3024e-01,\n",
            "          2.1311e+00,  1.9021e+00],\n",
            "        [-1.7214e-01,  1.3441e+00,  3.8089e+00,  ..., -1.9069e+00,\n",
            "          1.3530e+00, -7.0472e-01],\n",
            "        [-3.2781e-03,  3.4526e+00,  4.8120e+00,  ..., -3.2455e+00,\n",
            "          2.5514e+00, -3.5440e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5844,  0.0475, -1.0715,  ..., -0.0062,  0.5926,  4.3088],\n",
            "        [-0.6346,  3.6189,  4.9822,  ..., -3.4488,  4.0195, -0.4509],\n",
            "        [-0.9019,  2.5982,  3.5755,  ..., -2.2889,  1.9450, -1.0838],\n",
            "        ...,\n",
            "        [ 1.4782,  4.4778,  2.0829,  ..., -3.1950,  0.6887,  1.0886],\n",
            "        [ 0.4849,  1.3224, -0.1057,  ...,  0.1872,  1.9476,  1.1602],\n",
            "        [-1.4854,  0.4450, -0.5684,  ..., -1.1401,  2.8062, -0.3812]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0035,  3.6435,  1.1144,  ..., -0.7177,  0.0726,  3.1165],\n",
            "        [-0.8286,  0.3858,  0.8226,  ..., -0.7471,  0.6829, -0.6745],\n",
            "        [-0.5039,  5.5345,  3.8941,  ..., -2.6014,  3.3049, -1.4595],\n",
            "        ...,\n",
            "        [-0.4410,  4.0669,  3.5181,  ..., -3.2899,  1.1016, -0.7427],\n",
            "        [ 2.6492,  4.9716,  0.8831,  ...,  4.3174,  2.0265, -1.5115],\n",
            "        [ 0.4978,  4.9675, -0.6418,  ..., -0.0335, -1.6727, -0.0900]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2428,  4.8325,  4.0741,  ..., -0.9490,  4.1717, -0.8284],\n",
            "        [-0.6289, -0.0108, -0.9045,  ..., -0.0415,  4.3756,  3.0134],\n",
            "        [-2.1992,  8.4818,  1.6322,  ..., -5.1453, -0.1897, -2.4107],\n",
            "        ...,\n",
            "        [-3.2196,  4.1714,  2.8662,  ..., -2.8171,  2.3889,  1.4716],\n",
            "        [ 0.7093,  1.6157,  1.2981,  ...,  0.0665,  3.8698,  0.5012],\n",
            "        [-1.3313,  1.7347,  2.8657,  ..., -0.2179,  2.1259, -0.6383]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5401,  5.3516, -0.3564,  ...,  0.2886,  0.8138, -0.1536],\n",
            "        [ 0.9280,  2.3715,  0.3620,  ...,  3.1336,  2.6332,  1.6466],\n",
            "        [ 0.9538,  5.2173,  4.7018,  ..., -2.3278,  1.3656, -3.3959],\n",
            "        ...,\n",
            "        [ 2.8752, -1.1825,  2.4933,  ...,  2.5991,  1.5932, -0.5684],\n",
            "        [ 0.9597,  5.8642,  4.2459,  ..., -5.4020,  2.5979,  1.0003],\n",
            "        [ 3.7301, -0.1972,  2.5745,  ...,  4.0226,  0.2783, -1.2969]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5110,  3.7712,  1.0278,  ...,  0.1232,  0.7350, -0.0216],\n",
            "        [ 1.6213,  2.2177, -0.0797,  ..., -0.0120,  0.3803,  2.8481],\n",
            "        [-0.2810, -0.0688, -5.5141,  ...,  2.1349,  1.5853,  1.2238],\n",
            "        ...,\n",
            "        [ 1.9992,  3.5908,  1.1788,  ..., -0.2198,  3.0150, -0.8193],\n",
            "        [ 1.4660,  0.1908, -1.0245,  ...,  0.6916,  1.1409,  3.5825],\n",
            "        [ 0.4206,  0.0642,  0.5694,  ...,  1.6898,  3.4070,  3.7325]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9433, -0.1802, -1.8339,  ...,  3.0253,  1.2266,  1.4481],\n",
            "        [ 1.0185,  2.6643, -0.3151,  ...,  1.7096,  1.7147,  4.4103],\n",
            "        [ 0.3209,  4.5857,  3.5057,  ..., -4.2696,  1.7569,  2.6289],\n",
            "        ...,\n",
            "        [ 1.4975,  2.1075, -0.1926,  ...,  4.9782,  0.2528, -0.8846],\n",
            "        [-0.7540,  2.8470,  1.7214,  ..., -3.9878,  0.4355,  3.0702],\n",
            "        [ 1.9070,  0.6874,  0.1541,  ...,  0.2889,  4.1056,  1.6464]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5879,  2.8467, -0.9626,  ...,  0.4337, -1.9913,  1.5335],\n",
            "        [ 2.3256,  4.7776,  2.6112,  ..., -3.4060,  1.8421,  1.7005],\n",
            "        [-1.3886,  6.1220,  0.5441,  ..., -1.3790,  0.2912,  0.6167],\n",
            "        ...,\n",
            "        [ 2.3274,  3.5971,  5.8185,  ..., -1.3458,  3.5819, -2.7886],\n",
            "        [ 0.5786,  3.7144,  2.7756,  ..., -0.7464,  3.8389, -0.6975],\n",
            "        [-0.9730,  4.8734, -0.1418,  ..., -0.6698,  1.2291,  3.2812]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8346,  1.9347,  1.4251,  ..., -0.4761,  3.0785, -0.8622],\n",
            "        [ 1.2933,  3.5378,  0.1060,  ..., -3.2498,  0.1164, -0.5889],\n",
            "        [ 2.8130,  4.1393,  1.5666,  ..., -2.5836,  1.6729,  1.3588],\n",
            "        ...,\n",
            "        [ 2.1210,  4.6573,  0.3894,  ..., -0.5195,  0.1533, -1.6835],\n",
            "        [ 1.6223,  4.1559,  1.2275,  ..., -0.0580,  0.1847,  0.0636],\n",
            "        [-0.5603,  4.6124,  1.3161,  ..., -2.3374, -0.8208,  0.5970]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4303,  6.6567, -0.3755,  ..., -3.2002, -0.1825,  0.3503],\n",
            "        [ 1.0129,  3.1069,  1.8229,  ..., -3.0281,  1.9288, -0.5922],\n",
            "        [-0.3521,  1.7122,  3.4062,  ..., -3.8993,  3.1294, -0.6451],\n",
            "        ...,\n",
            "        [-0.3369, -0.0299, -0.9624,  ...,  1.2088,  5.1079,  4.2103],\n",
            "        [ 0.5200,  4.0437, -0.7302,  ...,  0.6317,  0.0971,  3.6729],\n",
            "        [ 0.9822,  3.5525,  4.5245,  ..., -1.6980,  4.5150, -1.5288]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6511,  0.7684,  0.7994,  ..., -0.5870,  4.1487,  1.1434],\n",
            "        [-1.5738,  6.8577,  1.4326,  ...,  0.3491,  1.1586,  5.5139],\n",
            "        [-0.7009,  1.1001, -1.4495,  ...,  0.3056,  1.3072, -0.1253],\n",
            "        ...,\n",
            "        [-1.2412, -0.7163, -1.1503,  ...,  0.5885,  3.3783,  3.3777],\n",
            "        [ 1.5233,  3.1802,  2.4118,  ..., -2.4164, -0.4580, -0.7414],\n",
            "        [-0.0647,  3.2107,  1.6168,  ..., -2.4982,  2.3854,  1.7657]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6878e-03,  7.0489e+00,  1.2100e+00,  ..., -2.3886e+00,\n",
            "         -7.7404e-02,  3.3865e-01],\n",
            "        [-1.3742e+00,  3.0554e+00,  2.7553e+00,  ..., -3.1476e-01,\n",
            "          5.5047e+00, -1.6751e+00],\n",
            "        [ 5.2424e-01,  9.1119e-02, -1.8657e+00,  ...,  2.6929e-01,\n",
            "          1.4322e+00,  1.6355e+00],\n",
            "        ...,\n",
            "        [ 1.1396e+00,  5.2216e+00,  3.3886e+00,  ..., -2.4673e+00,\n",
            "          5.3047e-01, -3.8567e+00],\n",
            "        [ 1.0189e+00, -1.1656e+00, -7.2976e-01,  ...,  1.0377e+00,\n",
            "          4.3236e+00,  4.3585e+00],\n",
            "        [ 1.9761e+00,  2.7143e+00,  2.2162e+00,  ..., -4.1808e+00,\n",
            "          3.4137e+00, -2.7808e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6409e+00,  3.3466e+00,  6.8980e+00,  ...,  1.4730e+00,\n",
            "          3.9144e+00, -1.5852e+00],\n",
            "        [-7.9027e-01, -1.0855e+00,  3.1680e-01,  ...,  3.8055e+00,\n",
            "          2.0626e+00, -1.8574e+00],\n",
            "        [ 8.2243e-01,  8.0415e+00,  2.4688e+00,  ..., -3.2929e+00,\n",
            "          4.1037e-01, -5.2455e-01],\n",
            "        ...,\n",
            "        [ 4.0058e-02,  5.3945e+00,  5.4143e+00,  ..., -1.9605e+00,\n",
            "          3.0373e+00, -1.5594e+00],\n",
            "        [ 3.3665e+00,  2.6608e+00, -5.6201e-04,  ...,  2.1830e+00,\n",
            "          1.5875e+00, -3.9951e-01],\n",
            "        [ 2.5204e+00, -1.0283e+00,  1.0659e+00,  ...,  4.5255e-01,\n",
            "          1.2271e-01,  9.5310e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0168,  2.8101,  1.9816,  ..., -3.0221,  1.4928, -5.5050],\n",
            "        [-2.0957,  2.5128,  5.2754,  ..., -2.4627,  4.2948, -0.6801],\n",
            "        [-0.9923,  3.9403,  1.7437,  ..., -2.0939,  1.0292,  0.3124],\n",
            "        ...,\n",
            "        [ 0.9216,  4.0612,  6.2545,  ..., -3.6024,  1.8605, -3.4752],\n",
            "        [ 0.7856,  3.1385,  6.9784,  ..., -4.3300,  4.5074, -1.7185],\n",
            "        [ 2.4038,  3.4738,  0.0659,  ...,  0.5794,  1.0676, -0.4985]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0370,  3.4735,  3.5197,  ..., -2.7848,  3.3110, -0.4357],\n",
            "        [-0.8796,  2.7522, -1.6767,  ...,  1.5609,  0.3933,  0.1072],\n",
            "        [-0.3967,  4.0949,  1.0321,  ..., -2.7440, -0.2107,  1.0026],\n",
            "        ...,\n",
            "        [-0.5588,  2.4505,  0.5836,  ...,  0.1494,  0.3303,  3.9473],\n",
            "        [ 0.0138,  2.8727,  1.9809,  ...,  0.6229,  2.3508,  0.5178],\n",
            "        [-0.0868,  4.3810,  0.8595,  ..., -0.8209,  1.8484, -1.0274]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 8.4276e-01,  5.2026e-01, -8.8205e-01,  ...,  1.5452e-02,\n",
            "         -3.6448e-03,  3.2611e+00],\n",
            "        [-1.4568e+00,  4.2876e+00,  7.2045e-01,  ..., -3.3249e-01,\n",
            "         -1.5878e-01,  1.9139e+00],\n",
            "        [ 1.4201e+00,  1.2127e+00,  6.1029e-01,  ..., -2.2451e+00,\n",
            "          9.5237e-01, -1.5843e+00],\n",
            "        ...,\n",
            "        [-2.7835e+00,  2.0844e+00,  3.7200e+00,  ..., -2.3053e+00,\n",
            "          3.9899e+00, -1.3757e+00],\n",
            "        [ 6.4257e-01,  4.3028e+00,  1.3847e+00,  ..., -1.0175e+00,\n",
            "          6.3819e-01, -1.7507e+00],\n",
            "        [ 1.5823e+00,  4.3144e+00,  5.7658e-01,  ..., -1.1118e-01,\n",
            "          1.3799e+00, -3.8369e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0918,  2.8575,  0.7929,  ..., -1.3069,  1.0610,  3.8961],\n",
            "        [ 1.6198,  3.9042,  1.3657,  ..., -0.0831,  1.8926, -0.1911],\n",
            "        [-0.3687,  4.3405, -0.9384,  ..., -0.2651,  0.2294,  4.0572],\n",
            "        ...,\n",
            "        [-0.8096,  5.1402,  4.4787,  ..., -3.4653,  3.1830, -1.7704],\n",
            "        [-1.5137,  4.9862, -0.1503,  ..., -2.9358, -0.8487, -0.1869],\n",
            "        [ 1.2053,  4.2382,  0.9306,  ..., -1.8634,  0.9553,  3.1122]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6823,  2.3697, -0.4760,  ..., -1.3595, -0.1478,  4.4856],\n",
            "        [-1.7306,  4.7086, -0.6006,  ...,  0.5310,  0.1570,  3.1154],\n",
            "        [-4.2996,  2.2802,  4.2906,  ...,  0.1085,  3.2588, -1.7795],\n",
            "        ...,\n",
            "        [-0.8445,  4.7613,  3.5159,  ..., -3.4248,  1.7756,  1.9370],\n",
            "        [-3.7971,  3.7597,  3.6504,  ..., -3.5321,  4.5726, -2.1497],\n",
            "        [ 0.0861,  5.5628,  6.5958,  ..., -5.9722,  4.4579, -0.2903]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0996,  0.0321,  3.5341,  ..., -0.4840,  1.9854, -2.8299],\n",
            "        [ 1.4090,  6.6868,  5.5403,  ..., -3.9188,  1.3263, -3.8274],\n",
            "        [ 2.1402,  3.3163,  4.0590,  ..., -1.1237,  4.2676, -1.2040],\n",
            "        ...,\n",
            "        [ 2.3394,  2.7088,  4.5985,  ..., -1.3199,  0.7918, -2.2710],\n",
            "        [ 0.7006,  5.6092,  1.4210,  ..., -1.4456, -0.6265, -0.1342],\n",
            "        [ 1.9338,  6.0511,  2.2040,  ..., -1.2117,  1.3508, -1.6559]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edf0a3235d17423fb311df540fbd49ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5159,  3.7495,  0.6444,  ..., -0.1274, -0.4480,  1.7871],\n",
            "        [ 1.3622,  6.7228,  5.6471,  ..., -1.6295,  0.9340, -5.6634],\n",
            "        [ 4.6731,  2.3490,  5.2730,  ..., -1.4465,  4.0328, -3.0161],\n",
            "        ...,\n",
            "        [-3.7060,  4.4188,  4.2603,  ..., -1.8687,  3.8270, -3.4657],\n",
            "        [ 0.3652,  5.4259,  3.4609,  ..., -3.1741,  1.5435, -3.9004],\n",
            "        [-3.6521,  5.4308,  4.6176,  ..., -3.0466,  3.9577, -1.0233]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9441,  5.9893,  2.7672,  ..., -2.7436,  2.1500,  2.2785],\n",
            "        [ 0.5437,  4.0534,  2.0660,  ...,  0.6229,  0.4380,  0.0105],\n",
            "        [-3.9523,  2.5150,  5.3733,  ..., -2.3310,  4.9972, -1.8758],\n",
            "        ...,\n",
            "        [ 0.0421,  2.2071,  2.3733,  ..., -1.3166,  3.5518,  0.0820],\n",
            "        [-2.6327,  3.2790,  3.0067,  ..., -4.0773,  2.7975, -4.6829],\n",
            "        [-1.5303,  0.7985, -1.2463,  ...,  2.7349,  2.4408, -0.6311]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1916,  2.6153,  2.9243,  ...,  0.3721,  1.0481,  1.3014],\n",
            "        [-2.6868,  3.2341,  3.1122,  ..., -3.0686,  4.3136, -3.7290],\n",
            "        [ 0.6897,  4.6829,  4.0413,  ..., -3.4061,  3.4112,  0.0983],\n",
            "        ...,\n",
            "        [-4.1026,  2.0194,  3.7289,  ..., -2.2963,  2.1052, -1.0208],\n",
            "        [ 1.6244,  1.4593,  2.6609,  ...,  1.3213,  2.6102, -2.0334],\n",
            "        [-0.5233,  5.5751,  1.2781,  ..., -3.2128,  0.3809,  0.2330]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3940,  0.3631, -0.8434,  ...,  1.2519,  1.6512, -0.8320],\n",
            "        [ 1.4428,  5.3440,  4.5704,  ..., -3.6033,  2.7012, -2.1821],\n",
            "        [-1.6645,  2.6852,  2.2390,  ..., -1.2521,  1.6622,  1.6073],\n",
            "        ...,\n",
            "        [ 0.4636,  4.8028,  3.4102,  ..., -3.1338,  2.4745, -3.3348],\n",
            "        [ 0.1594,  4.5464,  0.3446,  ...,  1.0383, -0.1712,  0.1263],\n",
            "        [ 0.7010,  3.8627, -0.3973,  ..., -2.0279, -0.3029,  0.9012]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2932e-01,  2.9243e-01,  2.4937e+00,  ..., -4.7568e+00,\n",
            "          5.0509e+00, -2.3119e-01],\n",
            "        [ 2.3405e+00,  5.2212e+00,  2.1589e+00,  ..., -1.7835e+00,\n",
            "          1.4917e+00, -1.6722e+00],\n",
            "        [ 2.2191e+00,  4.1951e+00,  1.4865e+00,  ..., -3.5656e-01,\n",
            "         -1.8133e-03, -9.7066e-02],\n",
            "        ...,\n",
            "        [ 2.5826e+00,  4.1362e+00,  5.8169e+00,  ..., -3.9860e+00,\n",
            "          3.4071e+00, -2.1986e+00],\n",
            "        [ 2.1331e+00,  3.2777e+00,  4.3772e+00,  ..., -1.6336e+00,\n",
            "          4.1535e+00, -1.9437e+00],\n",
            "        [-6.1252e-02, -4.4387e-02,  1.5786e+00,  ..., -6.0978e-01,\n",
            "          5.8597e+00,  2.7062e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4413,  4.5271,  2.0967,  ..., -0.8162,  2.1103,  3.2299],\n",
            "        [-1.2029,  6.8042,  6.0593,  ..., -1.2375,  3.5062, -2.8145],\n",
            "        [ 0.5449,  3.6788,  0.6229,  ..., -0.7470,  1.3202,  1.5208],\n",
            "        ...,\n",
            "        [ 0.5770,  2.2808,  3.3042,  ..., -0.3666,  1.0095, -0.0385],\n",
            "        [ 1.7146,  3.2650,  4.2088,  ..., -1.5647,  2.3188, -2.0124],\n",
            "        [-0.1264,  4.5883,  5.5072,  ..., -2.2106,  4.6053, -2.7676]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1931,  4.1356,  1.7334,  ..., -3.2719,  1.2984,  1.3278],\n",
            "        [-0.3307,  7.5187, -0.3255,  ..., -2.4006,  0.7779,  0.5543],\n",
            "        [ 4.2690,  1.8550,  3.0575,  ...,  0.2899,  2.8433, -2.1725],\n",
            "        ...,\n",
            "        [-2.5392,  2.3713,  2.3894,  ...,  2.8271,  2.9951, -1.1805],\n",
            "        [ 1.2005,  3.3641,  2.6517,  ..., -2.1922,  1.4188, -0.7063],\n",
            "        [-0.5901,  5.1356,  3.0238,  ..., -1.6259,  2.7197,  0.7057]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.4615,  1.6403,  5.2611,  ..., -2.2909,  5.1900, -1.8654],\n",
            "        [ 0.0563,  0.7812, -0.7064,  ..., -2.0625,  2.6640, -1.5579],\n",
            "        [ 0.7659,  5.2419,  5.5737,  ..., -4.4497,  3.4436, -6.1969],\n",
            "        ...,\n",
            "        [-1.3163,  0.3677,  3.0420,  ..., -0.8652,  4.7829,  2.1437],\n",
            "        [ 0.9512,  6.1915,  2.7665,  ..., -2.0883,  0.8834,  1.4994],\n",
            "        [ 0.5950,  3.9487,  1.7697,  ..., -0.6059,  1.0286,  2.8135]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.9631e-01,  1.3878e+00, -2.5634e-03,  ...,  1.1914e+00,\n",
            "          1.4000e-01,  2.1470e+00],\n",
            "        [ 8.0425e-01,  5.5845e+00,  1.2968e+00,  ..., -1.3055e+00,\n",
            "         -8.0831e-01,  5.3407e-01],\n",
            "        [ 2.0941e+00,  4.6295e+00,  5.8679e-01,  ..., -5.8804e-01,\n",
            "          2.1083e+00, -1.2624e+00],\n",
            "        ...,\n",
            "        [ 5.4532e-02,  2.1497e+00,  2.0981e+00,  ..., -9.5090e-01,\n",
            "          3.4392e+00,  5.6954e-01],\n",
            "        [ 2.1223e+00, -3.1860e-01,  1.7122e+00,  ..., -9.8493e-01,\n",
            "          4.3353e+00,  1.0106e+00],\n",
            "        [-3.8020e+00,  2.8027e+00,  5.1763e+00,  ..., -3.6081e+00,\n",
            "          3.4453e+00, -2.3089e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2889,  5.4752,  4.5586,  ..., -1.5540,  4.1228, -1.0775],\n",
            "        [-0.4671,  0.5248,  0.8033,  ..., -1.5358,  3.6780,  1.9496],\n",
            "        [ 1.0602,  4.9396,  1.7394,  ..., -2.4923,  0.4864,  1.5404],\n",
            "        ...,\n",
            "        [-2.5682,  3.1597,  4.2275,  ..., -0.9507,  1.9767, -0.5043],\n",
            "        [ 0.3789,  5.3977,  1.0893,  ..., -1.7087, -0.1798,  3.2241],\n",
            "        [ 1.4136,  5.1225,  1.6103,  ..., -2.3380,  2.3431,  1.2606]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1008,  2.4853, -0.5205,  ..., -1.0154, -0.3641,  2.5863],\n",
            "        [-0.5654,  4.6299,  0.3381,  ..., -0.8413,  0.8661,  4.9731],\n",
            "        [ 0.5065,  5.0024,  1.6671,  ..., -1.7095,  2.8943, -1.2586],\n",
            "        ...,\n",
            "        [ 2.3347,  4.1848,  0.4787,  ..., -0.4822,  2.3658, -1.7073],\n",
            "        [ 1.6866,  2.3271,  2.6712,  ..., -3.6016,  3.0741,  0.2179],\n",
            "        [-3.7465,  3.4978, -0.6240,  ...,  0.1760,  3.7608,  3.7221]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0988,  1.8998,  3.8064,  ..., -2.1819,  4.0292,  0.5045],\n",
            "        [ 1.6838,  3.5857,  5.0576,  ..., -3.4630,  3.0098, -4.2895],\n",
            "        [-1.4202,  3.9016,  0.0400,  ..., -1.3027,  0.5370,  2.7183],\n",
            "        ...,\n",
            "        [-1.0523,  2.7098, -0.3603,  ...,  0.5835,  0.0452,  1.8827],\n",
            "        [-0.0343,  3.2454,  0.5828,  ..., -0.2964, -0.2920, -2.4765],\n",
            "        [ 1.8384,  4.5095,  1.0961,  ..., -2.7910,  1.6914,  1.4847]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7576,  3.6421,  1.2129,  ...,  1.5976,  0.8291,  0.3808],\n",
            "        [-0.5520,  4.0148,  0.0128,  ..., -2.2450,  0.8625,  1.6794],\n",
            "        [ 2.5139,  2.7674,  0.4631,  ..., -0.0941,  1.1644, -1.7539],\n",
            "        ...,\n",
            "        [ 1.7167,  3.7204,  0.7360,  ..., -2.0247,  2.7138,  0.7399],\n",
            "        [-2.8116,  0.5597,  3.1257,  ..., -2.4195,  6.8497,  0.3169],\n",
            "        [ 0.4289,  3.0065, -1.0574,  ..., -0.1692,  0.2974,  2.4217]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5451,  2.6907,  5.2549,  ..., -2.5218,  4.5216, -1.1311],\n",
            "        [-0.4451,  3.9071,  6.8690,  ..., -2.0380,  2.8099, -2.9874],\n",
            "        [ 1.6210,  4.9803,  1.3191,  ...,  3.3592,  1.5169, -0.7294],\n",
            "        ...,\n",
            "        [ 3.6318,  2.2136,  2.1705,  ..., -1.1184,  3.9115, -3.6196],\n",
            "        [ 1.0011,  4.5223,  4.5196,  ..., -1.3022,  5.2065, -1.4269],\n",
            "        [-0.6263,  3.4193,  1.2536,  ...,  0.1942,  3.6559, -0.6395]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7855,  5.2544,  7.6023,  ..., -3.0537,  5.9076, -2.7789],\n",
            "        [ 0.8681,  6.0291,  1.3827,  ..., -1.2340,  0.3589, -0.6495],\n",
            "        [-1.2545,  3.0659,  5.0536,  ..., -3.4995,  4.3988, -2.3711],\n",
            "        ...,\n",
            "        [ 0.7232,  6.0962,  0.4548,  ...,  2.2281,  1.0401, -1.1840],\n",
            "        [-0.6132,  4.5817,  1.1769,  ...,  0.0612, -0.5228, -0.9721],\n",
            "        [-1.8684, -0.5012, -0.8630,  ..., -0.2827,  3.6995,  6.1223]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2683,  3.4574,  2.7106,  ..., -3.9336,  2.5348,  0.6760],\n",
            "        [-0.3584,  4.0633,  0.5603,  ...,  0.2173,  0.0177,  3.7522],\n",
            "        [ 0.3093,  0.9645,  5.3153,  ..., -3.6420,  4.2540, -0.4495],\n",
            "        ...,\n",
            "        [ 2.1563,  3.2000,  1.7469,  ..., -2.2054,  2.6151, -1.0932],\n",
            "        [-1.7288,  4.3615,  3.8475,  ..., -2.0869,  2.7175, -2.1435],\n",
            "        [-0.4482,  3.2776,  0.1954,  ...,  2.3113, -2.3744,  1.6114]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4137,  4.9799,  0.7159,  ..., -0.6914, -0.7893,  0.2632],\n",
            "        [-3.3746,  1.8702,  0.9914,  ..., -1.9151,  4.1672, -3.1837],\n",
            "        [ 0.6446,  5.8937,  2.3043,  ..., -1.7852,  1.5521, -2.1927],\n",
            "        ...,\n",
            "        [-1.3309,  2.7478,  3.4782,  ..., -1.4502,  2.5495, -0.9972],\n",
            "        [-1.3144,  4.0906,  3.3880,  ..., -2.5542,  3.3795, -1.0111],\n",
            "        [-0.7231,  2.0640,  1.1058,  ..., -0.1511,  3.3739, -1.1924]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5177,  3.1141,  5.0350,  ..., -2.4341,  2.8789, -0.0173],\n",
            "        [ 0.8859,  2.2990,  0.0386,  ..., -1.1387,  2.4602, -0.8401],\n",
            "        [ 4.1296,  3.5429,  2.1479,  ..., -1.9221,  2.8648,  1.5484],\n",
            "        ...,\n",
            "        [ 0.7461,  4.4975,  0.2876,  ..., -0.8647,  1.1603,  2.8068],\n",
            "        [ 2.0882,  4.8831,  2.0666,  ..., -1.9667,  0.6393, -0.9736],\n",
            "        [-1.2114,  4.0404, -1.1746,  ..., -1.1938,  0.0222,  3.7778]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6624,  1.8974, -0.4101,  ...,  1.0778,  2.2211, -1.4436],\n",
            "        [ 0.5731,  3.0367,  2.1045,  ...,  0.7563,  0.7510,  1.9356],\n",
            "        [ 3.3513,  5.0008,  1.8935,  ..., -2.1233,  3.0749,  0.7928],\n",
            "        ...,\n",
            "        [-0.1557,  3.0341,  4.2941,  ..., -3.9973,  2.5932, -3.0507],\n",
            "        [-1.8675,  2.6652,  2.0486,  ..., -3.6949,  0.9433,  2.2837],\n",
            "        [ 1.7656,  3.4552,  3.7251,  ..., -4.2622,  2.6995, -1.5990]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6571,  0.2309,  1.4008,  ...,  0.8890,  4.6616,  1.6270],\n",
            "        [ 2.5730,  4.5781,  0.0401,  ...,  0.3108,  0.6764, -0.5618],\n",
            "        [-0.9660,  4.9434,  1.1939,  ..., -2.3722,  0.0061,  0.3363],\n",
            "        ...,\n",
            "        [ 1.5749,  3.9033,  1.8018,  ..., -3.2954,  1.5899,  0.9156],\n",
            "        [-1.9922,  2.4492,  3.0851,  ..., -3.3432,  4.9204, -2.8300],\n",
            "        [-0.2006, -0.0061,  1.6383,  ..., -0.1143,  3.9873,  3.2709]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5324,  2.1565,  1.4725,  ..., -0.2844,  2.9768,  0.4157],\n",
            "        [ 0.4544,  4.8681,  0.7090,  ..., -0.3355,  0.9632,  0.4450],\n",
            "        [ 2.1626,  0.6825, -0.1574,  ...,  0.1666,  2.3015,  2.2190],\n",
            "        ...,\n",
            "        [-1.1492,  4.4950,  0.7367,  ..., -3.7989, -0.3630, -0.3592],\n",
            "        [-0.2642, -0.5979, -1.8408,  ...,  1.9916,  2.0078,  2.2207],\n",
            "        [-3.5128,  1.8444,  0.7189,  ..., -2.6769,  1.1457,  1.5696]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5541,  2.6193,  3.4707,  ..., -2.0307,  5.2090,  0.6295],\n",
            "        [ 1.3702,  5.0466,  1.9446,  ..., -3.2384,  1.6865,  1.7482],\n",
            "        [-0.2183,  6.6695,  3.7850,  ..., -2.1649,  2.0994, -2.6024],\n",
            "        ...,\n",
            "        [ 1.3499, -0.0448, -0.5136,  ...,  1.4319,  2.2728,  3.2470],\n",
            "        [-0.5282,  4.0489,  2.7499,  ..., -1.6036,  1.6819, -1.8080],\n",
            "        [ 0.7444,  2.6786,  4.7099,  ..., -4.0479,  4.1536, -1.5844]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6181,  2.6247,  5.1008,  ..., -4.4399,  4.6470, -1.1934],\n",
            "        [ 1.2359,  4.5743,  4.6757,  ..., -2.3776,  3.0756, -2.9212],\n",
            "        [-0.7730,  2.3410,  2.3031,  ..., -0.6006,  3.6354, -1.7802],\n",
            "        ...,\n",
            "        [-5.1820,  0.5223,  4.1410,  ..., -1.9719,  4.2970, -2.5890],\n",
            "        [ 1.7038,  4.4986,  5.4536,  ..., -2.6443,  2.2565, -3.9506],\n",
            "        [ 1.5014,  3.9298, -0.1013,  ...,  0.3934,  3.2843, -0.3912]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1435,  4.5893,  0.5617,  ..., -0.1198,  0.4777,  1.3625],\n",
            "        [ 0.2412,  1.3278, -0.4420,  ...,  0.1975,  1.3140,  2.3603],\n",
            "        [ 3.5482,  4.1701,  0.9124,  ..., -1.9827,  3.0516, -1.2414],\n",
            "        ...,\n",
            "        [-2.1254,  1.4951,  0.7395,  ..., -1.2904,  0.8408, -1.1484],\n",
            "        [ 1.1986,  5.6174,  4.7011,  ..., -5.5594,  3.1511, -3.0561],\n",
            "        [-0.1654, -0.9219, -1.8946,  ..., -2.8412,  2.9151, -1.6722]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0736,  3.5010,  1.3960,  ..., -2.5979,  2.8737,  0.9221],\n",
            "        [-4.2288,  1.2324,  3.3815,  ..., -3.8258,  6.0806, -3.9720],\n",
            "        [ 0.8421,  4.3134,  0.4018,  ..., -0.4288, -0.8132, -0.4101],\n",
            "        ...,\n",
            "        [ 0.4314,  4.0228,  0.3845,  ..., -0.5469,  0.6158, -0.3888],\n",
            "        [-2.2055, -0.8327,  3.6505,  ..., -0.5352,  1.7772, -1.8953],\n",
            "        [-0.8184,  3.2404,  2.5604,  ..., -1.0418,  1.5314, -0.8920]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5454,  0.6009,  5.4230,  ..., -3.9348,  4.4777, -0.8044],\n",
            "        [ 1.9574,  3.3813,  0.3724,  ...,  3.0445,  2.3925, -1.6329],\n",
            "        [-2.2659,  2.3059,  1.5812,  ..., -3.0357,  4.2286, -5.0964],\n",
            "        ...,\n",
            "        [-0.3144,  5.0866,  2.9152,  ..., -1.1221,  1.6073, -2.1773],\n",
            "        [ 1.1467,  3.9172,  2.5204,  ..., -2.0304,  2.0536, -0.5786],\n",
            "        [ 0.2583,  2.1047,  0.3312,  ..., -0.5047,  0.1186,  1.4805]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1645,  3.4213, -1.8419,  ..., -2.1447,  1.2067,  1.8300],\n",
            "        [-3.6006,  3.4216,  4.2380,  ..., -5.3217,  5.6154, -7.2198],\n",
            "        [ 3.5209,  3.7387,  2.9214,  ..., -1.5372,  3.0257, -0.8499],\n",
            "        ...,\n",
            "        [ 0.5890,  0.0569, -0.8019,  ...,  0.2521,  3.5457,  3.4969],\n",
            "        [-3.2299,  4.4323,  4.6918,  ..., -1.4608,  1.8918, -2.8272],\n",
            "        [-0.6686, -3.2094,  0.5921,  ...,  4.1327,  2.0661, -3.4570]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3908,  0.5373,  2.2611,  ..., -0.4294,  3.0806, -2.5484],\n",
            "        [-1.7109,  4.2013,  1.6711,  ..., -2.7356,  1.3254, -0.3018],\n",
            "        [ 0.4589,  3.8803,  2.7753,  ...,  0.4640,  2.0689, -2.2401],\n",
            "        ...,\n",
            "        [-0.6198,  2.6674, -0.2277,  ..., -0.3980,  2.5471,  1.7718],\n",
            "        [-1.7424,  5.1640,  4.5456,  ..., -2.6273,  2.4426, -2.2604],\n",
            "        [ 0.6781,  4.2104,  0.7412,  ..., -1.3282,  0.9180, -0.8504]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2755,  0.4534,  2.4036,  ..., -2.3395,  2.7211,  0.4730],\n",
            "        [-0.3774,  6.4621,  1.5490,  ..., -4.4348, -1.0659, -1.3390],\n",
            "        [ 0.1457,  4.3219, -0.3914,  ..., -2.6408,  1.3181, -0.9298],\n",
            "        ...,\n",
            "        [ 1.4473,  4.6520,  0.9408,  ..., -2.2213,  2.1131,  0.1715],\n",
            "        [-1.0733,  3.1168, -1.3758,  ...,  0.4407,  2.3236,  2.3697],\n",
            "        [ 4.3321,  3.6221, -0.0151,  ..., -1.5290,  3.7778, -1.3858]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2025,  4.8147,  0.7865,  ..., -1.0146,  0.2541,  1.6250],\n",
            "        [-1.4709,  5.4387, -2.0320,  ..., -0.7183, -0.7043,  4.7141],\n",
            "        [-0.2619,  0.5947,  3.5287,  ..., -0.9648,  3.9577, -1.2430],\n",
            "        ...,\n",
            "        [ 2.3035,  4.3730,  0.1770,  ..., -0.0719,  2.6728, -0.5855],\n",
            "        [-0.6194,  4.2376, -0.6592,  ..., -1.9548, -0.6867,  1.3640],\n",
            "        [ 1.5587,  4.2337,  4.2377,  ..., -4.1143,  4.2030, -0.2095]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6855,  2.6054,  3.6656,  ..., -0.7814,  2.9798, -2.5673],\n",
            "        [ 0.7398,  5.5511,  4.4653,  ..., -3.6749,  1.9951, -1.0538],\n",
            "        [ 1.0996,  3.0513,  0.6918,  ..., -1.7469,  1.3068, -1.0120],\n",
            "        ...,\n",
            "        [-0.8377, -1.5611, -0.6426,  ...,  1.5167,  2.5135,  4.2421],\n",
            "        [-1.8666, -1.5102,  2.9115,  ...,  0.9044,  3.1854, -4.1139],\n",
            "        [-0.3311,  3.5638,  4.3710,  ..., -3.2895,  4.0139, -2.0075]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2726,  4.8029,  0.6429,  ..., -0.8471, -0.7723, -0.5483],\n",
            "        [-3.0320,  1.5233, -1.4585,  ..., -2.6167,  0.7581,  3.6963],\n",
            "        [-1.6198,  4.8536,  2.4129,  ..., -3.3445,  2.8749, -2.1905],\n",
            "        ...,\n",
            "        [ 0.3072,  1.1482, -2.8210,  ..., -0.0773,  0.8584,  0.5344],\n",
            "        [ 2.2643,  3.9370, -0.1309,  ..., -0.2887,  1.7419, -0.9243],\n",
            "        [-0.2207,  3.6640,  3.7531,  ..., -2.7174,  5.6135, -2.3766]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8616,  6.1545,  0.7248,  ...,  2.0703,  1.4426, -0.9312],\n",
            "        [ 1.6438,  2.2130,  1.6029,  ..., -2.4424,  5.0759, -1.4711],\n",
            "        [-1.7493,  3.3319, -1.0232,  ...,  0.2378,  0.1448,  1.6146],\n",
            "        ...,\n",
            "        [ 1.8956,  2.6109,  2.3897,  ..., -1.8656,  2.8458, -1.1082],\n",
            "        [ 0.5442,  0.9009,  2.2329,  ..., -2.6686,  2.1952, -1.5561],\n",
            "        [ 2.5776,  3.8404,  0.1977,  ..., -0.3215,  1.8925, -2.0405]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8803,  3.5092, -3.1883,  ...,  2.2737, -1.3560, -0.6287],\n",
            "        [ 0.2583,  2.1957,  2.7533,  ..., -2.6915,  1.4106, -0.4520],\n",
            "        [ 0.2064,  2.6711, -1.8535,  ...,  0.6649,  1.1327,  1.8807],\n",
            "        ...,\n",
            "        [-5.1450, -0.6260,  4.3951,  ..., -2.7383,  5.4305, -3.7175],\n",
            "        [ 3.9714, -2.7632,  1.4664,  ...,  3.1799,  4.4948, -3.6721],\n",
            "        [ 0.3841, -0.6740, -1.4786,  ...,  1.6435,  1.8973,  3.5950]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8455,  0.7699, -1.4638,  ...,  1.4105,  3.1004,  2.3946],\n",
            "        [ 0.1254, -0.1185, -0.3738,  ..., -0.5033,  3.6852,  2.0816],\n",
            "        [ 0.9234,  6.4803,  1.2593,  ..., -1.4409,  0.2287,  0.4420],\n",
            "        ...,\n",
            "        [ 1.7791,  2.4035,  2.2938,  ..., -3.4463,  2.1054,  0.3317],\n",
            "        [ 0.8074,  0.1752, -2.6733,  ..., -0.9172,  3.3238,  4.3573],\n",
            "        [-1.6682,  2.5448,  2.3679,  ..., -1.9941,  4.2845, -3.5797]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7540,  6.5416,  0.0144,  ..., -1.9474,  0.2896,  1.5107],\n",
            "        [ 3.7610,  3.6343,  2.2176,  ..., -0.4042,  1.1538, -1.7223],\n",
            "        [ 2.2809,  4.3863,  0.3579,  ..., -3.1940, -0.9167, -2.8841],\n",
            "        ...,\n",
            "        [-1.6903,  4.4917,  0.2083,  ..., -3.0093,  2.2962,  1.4812],\n",
            "        [ 1.0563,  3.1405, -2.4246,  ...,  0.3322, -2.2062,  1.4626],\n",
            "        [ 1.3068,  5.0862,  1.7954,  ..., -1.7606,  0.6789,  1.4741]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8977,  4.5868,  2.6134,  ..., -2.2145,  0.8583,  1.9414],\n",
            "        [-0.8345, -0.4733,  0.6775,  ..., -3.6519,  4.1757, -1.8683],\n",
            "        [ 1.4964,  2.4859,  0.1117,  ..., -1.6170,  2.2162,  0.4919],\n",
            "        ...,\n",
            "        [ 0.4378,  6.9985,  0.2201,  ..., -3.4571,  0.0323,  0.0413],\n",
            "        [-0.3434,  0.7388,  2.3392,  ..., -2.4034,  3.5191,  0.0776],\n",
            "        [-0.4159,  4.0672,  1.2646,  ..., -0.4627,  0.6247,  3.3005]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2066,  2.8813, -0.9605,  ..., -2.9839,  0.6529,  1.4476],\n",
            "        [ 1.2197,  0.2232, -0.3191,  ..., -1.7167,  4.0818,  3.7869],\n",
            "        [ 0.8562,  6.3818,  2.1407,  ..., -6.1416,  1.7044, -0.2520],\n",
            "        ...,\n",
            "        [-1.9145,  1.8774,  1.2703,  ..., -1.6465,  3.9460, -1.0732],\n",
            "        [ 1.6831,  5.5719, -0.4337,  ...,  3.6581,  2.0649, -1.0099],\n",
            "        [ 2.6092,  3.3433,  5.2581,  ..., -2.6060,  1.8905, -2.5621]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3250, -0.9953, -2.0211,  ...,  0.1062,  3.1924, -2.2656],\n",
            "        [-2.4192,  1.2113, -3.2363,  ...,  4.6529,  1.8006, -0.7424],\n",
            "        [ 4.4768,  2.8289,  1.4849,  ...,  0.2246,  2.1058, -2.3083],\n",
            "        ...,\n",
            "        [ 2.2844, -0.0322, -0.7106,  ..., -1.5731,  4.3292,  3.6095],\n",
            "        [ 3.2024, -0.8731, -0.0597,  ...,  0.2637,  0.3247,  0.5197],\n",
            "        [-1.6657,  1.8251,  1.0268,  ..., -1.7781,  2.5397, -0.0310]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4842,  3.3105,  1.0741,  ..., -2.5245,  0.8307,  2.5430],\n",
            "        [ 1.7724,  4.6844,  2.6825,  ..., -3.6246,  3.3357,  1.0841],\n",
            "        [-5.5721,  2.3031,  3.1181,  ..., -1.5726,  3.1217, -0.8589],\n",
            "        ...,\n",
            "        [ 0.4405,  3.1736,  0.8532,  ..., -0.4325, -0.8076,  2.8913],\n",
            "        [ 2.5346,  4.5091,  0.0411,  ..., -1.6385,  0.2301, -1.1349],\n",
            "        [ 0.3062,  5.0359, -1.5654,  ..., -0.6793,  0.6811,  4.1728]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2409,  1.6376,  2.7874,  ..., -3.0447,  5.8278,  0.7373],\n",
            "        [ 0.6277,  4.4791, -0.7490,  ..., -0.6730, -0.0391,  0.8318],\n",
            "        [-1.2437,  2.8339,  5.9674,  ..., -3.5866,  2.6001, -4.2784],\n",
            "        ...,\n",
            "        [ 0.9992,  5.4772,  0.1672,  ...,  0.0879,  0.4754, -0.5461],\n",
            "        [-2.2877,  5.9741, -0.3476,  ..., -2.3323,  0.0584,  1.6392],\n",
            "        [-1.5162,  2.4713,  1.9383,  ..., -3.3630,  2.3741,  2.3903]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6151,  2.5482, -4.0060,  ...,  0.9778, -1.1302,  0.7013],\n",
            "        [-0.1426,  3.5514, -0.3103,  ..., -0.2839,  2.0529,  3.1822],\n",
            "        [ 1.9966,  4.7471, -0.2168,  ...,  0.2791,  0.0577, -0.8124],\n",
            "        ...,\n",
            "        [-0.1171,  5.0932,  0.9783,  ..., -3.3519,  0.9161,  0.2242],\n",
            "        [ 0.8292,  4.5904,  0.6330,  ..., -0.6348,  0.5145,  2.3877],\n",
            "        [-2.3201,  0.2640,  2.8477,  ..., -1.2467,  4.0827,  0.8876]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4308,  3.6915,  2.1807,  ..., -2.8352,  0.4792,  2.7236],\n",
            "        [ 2.6028,  0.3291,  1.4163,  ...,  1.1911,  1.9743, -1.1075],\n",
            "        [-3.7123, -0.3939, -0.4934,  ..., -2.0062,  4.0115,  1.8799],\n",
            "        ...,\n",
            "        [ 0.8758, -0.6339,  1.5502,  ...,  0.4995,  1.4224, -0.4853],\n",
            "        [-0.3303,  4.6433,  0.1507,  ..., -1.8646,  1.2851, -0.8792],\n",
            "        [ 2.2114,  6.4315, -0.6983,  ...,  3.8032,  1.6090,  0.5941]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8029,  2.8663, -2.5562,  ...,  2.7536,  0.0940,  1.4883],\n",
            "        [-1.1165,  7.1628,  5.2601,  ..., -1.9823,  2.5695, -2.9160],\n",
            "        [ 0.0715,  6.3992,  2.0494,  ..., -3.4857,  0.4931,  1.2879],\n",
            "        ...,\n",
            "        [-0.0708,  6.0132,  0.5827,  ..., -1.0517,  2.4992,  0.5943],\n",
            "        [-0.1528,  3.6064,  0.6342,  ..., -3.0727,  3.1653, -2.5716],\n",
            "        [-1.5969,  2.4668,  5.1534,  ..., -4.6476,  3.7033, -1.4083]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2576, -2.6404, -1.4059,  ...,  3.7618,  3.2481, -2.1318],\n",
            "        [ 3.0685,  4.3638,  1.0418,  ..., -2.1806,  0.4833,  0.3221],\n",
            "        [ 1.9141,  3.4114,  0.8508,  ..., -0.7904,  3.4375,  0.6528],\n",
            "        ...,\n",
            "        [-3.0520,  0.0334,  3.7727,  ..., -4.7025,  4.4258, -1.3035],\n",
            "        [-0.0684,  2.4260, -3.6061,  ...,  1.6180,  0.1384,  2.3156],\n",
            "        [ 0.0624,  2.3548, -1.4998,  ...,  1.9762,  0.6411,  1.0515]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6365,  0.4582,  2.4335,  ..., -1.0566,  2.1110,  1.9490],\n",
            "        [ 0.1410,  0.5629,  0.2684,  ...,  1.7422,  3.2549, -4.1209],\n",
            "        [ 0.0736,  2.8872,  1.7632,  ..., -3.1109,  3.0148,  0.6355],\n",
            "        ...,\n",
            "        [ 0.7975,  4.5414,  0.0352,  ..., -0.5614,  0.4077,  2.5185],\n",
            "        [-0.6183,  0.7813, -1.7888,  ..., -1.8502,  1.4121, -0.0809],\n",
            "        [-2.4523,  1.0265, -4.5485,  ...,  0.2736,  0.3123,  2.3763]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6353,  2.3352, -2.2176,  ..., -0.0775,  1.4170,  2.9915],\n",
            "        [ 1.6610,  3.3558,  2.3590,  ...,  0.0570, -0.3379, -3.2916],\n",
            "        [-1.5155,  0.9108,  0.0254,  ...,  5.5680, -0.4456,  0.5873],\n",
            "        ...,\n",
            "        [ 0.7260,  3.2192,  3.2483,  ..., -3.9896,  4.4965,  1.9150],\n",
            "        [ 2.0270,  4.3915,  1.9695,  ..., -1.6232,  1.7612,  1.1142],\n",
            "        [ 2.7967, -0.2074,  0.3345,  ..., -1.3154,  4.5562,  1.3520]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8490,  1.5299, -3.6113,  ..., -0.5954, -1.0561,  1.8443],\n",
            "        [-1.7505,  0.5427,  2.3106,  ..., -2.4639,  0.2761, -1.7750],\n",
            "        [-1.3492,  3.3693,  4.5593,  ..., -3.8463,  4.2227, -2.2494],\n",
            "        ...,\n",
            "        [-2.1302,  3.4500,  2.8302,  ..., -1.6815,  2.0724, -2.0204],\n",
            "        [-1.3733,  1.0007, -0.1640,  ...,  0.5817,  3.3847,  2.3860],\n",
            "        [ 1.7061,  5.4020,  3.6737,  ..., -0.3053,  2.6693, -1.9444]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0308,  3.2401, -1.8382,  ..., -3.7598,  0.2107,  3.7011],\n",
            "        [ 2.5889,  4.5552, -0.0664,  ..., -1.6474,  1.2717, -1.4721],\n",
            "        [-2.2655,  2.7325,  2.2202,  ..., -1.8851,  1.0985,  1.4258],\n",
            "        ...,\n",
            "        [ 1.4145,  5.2509,  2.5032,  ..., -2.2125,  1.6587, -1.8721],\n",
            "        [-2.0608,  3.5436,  4.4966,  ...,  1.4120,  1.6936, -4.2368],\n",
            "        [-1.4558,  2.6894, -1.3153,  ..., -0.6972,  0.8117,  3.7876]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2091,  5.8038,  4.3799,  ..., -1.6137,  2.4465, -1.9881],\n",
            "        [-1.8420,  1.9904, -3.4751,  ...,  0.7148, -1.5130,  4.0408],\n",
            "        [ 0.4143,  3.5708,  2.5615,  ..., -2.8993,  2.2111, -2.9088],\n",
            "        ...,\n",
            "        [ 0.3352, -0.3933, -0.3505,  ...,  0.0698,  3.8848,  3.7461],\n",
            "        [-1.0860,  1.5655,  1.4795,  ..., -0.4700,  3.5088, -1.3508],\n",
            "        [ 1.0997,  4.4532, -0.7248,  ...,  2.6430,  0.9016, -0.6062]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.8439,  0.7567,  3.7784,  ..., -3.0375,  4.6724, -2.7879],\n",
            "        [-0.4231,  4.7191,  1.8715,  ..., -1.1151,  2.0863, -1.5334],\n",
            "        [ 2.0604,  4.4388,  0.5522,  ...,  4.5627,  2.0346, -1.4923],\n",
            "        ...,\n",
            "        [-2.1907, -0.8425,  2.7430,  ..., -0.5782,  6.9695,  0.2284],\n",
            "        [-1.6293, -2.8493,  0.8554,  ...,  2.5788,  2.0653, -3.1246],\n",
            "        [ 1.0270,  5.6616, -0.3528,  ..., -1.0816, -0.8798, -0.2908]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2727,  0.8727,  2.4212,  ..., -1.5474,  3.6597,  0.1591],\n",
            "        [-1.5655,  5.1742,  0.6847,  ..., -3.4398, -0.3911, -1.6622],\n",
            "        [ 1.6577,  0.6095,  0.9435,  ..., -0.0926,  3.8027,  1.5555],\n",
            "        ...,\n",
            "        [ 0.9671,  4.0189, -0.6175,  ...,  2.8689,  1.7962, -1.2103],\n",
            "        [-2.4366, -0.4586,  1.9904,  ...,  3.7276,  0.7836, -1.7070],\n",
            "        [ 1.7097,  4.5676,  0.0598,  ..., -0.4928,  0.9330, -0.8806]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1319,  1.8907,  2.0970,  ..., -2.4628,  3.4730, -0.3252],\n",
            "        [ 6.2146,  2.5090,  3.5635,  ..., -1.7968,  2.0749, -2.4452],\n",
            "        [ 1.3900,  2.9834, -1.0463,  ..., -1.3010,  4.0066,  0.4684],\n",
            "        ...,\n",
            "        [-1.5784,  2.3212,  2.9716,  ..., -2.1845,  2.5780, -1.8789],\n",
            "        [-1.3104,  0.4981,  2.0631,  ..., -3.1415,  2.7973, -0.9873],\n",
            "        [ 1.2493,  4.8134, -0.7408,  ..., -0.5865,  0.3318, -1.1491]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5085,  7.8473,  0.7081,  ..., -0.7823,  1.4255,  0.7554],\n",
            "        [-0.3525,  4.7977, -2.2635,  ...,  0.7331,  0.4082,  4.3308],\n",
            "        [ 3.5773,  0.1930, -0.0469,  ...,  3.9106,  0.1129,  2.1148],\n",
            "        ...,\n",
            "        [ 0.0163,  0.8239, -1.9152,  ...,  0.8951,  3.6484,  3.0562],\n",
            "        [ 2.3119,  3.8320,  0.5412,  ..., -0.4683,  1.3672,  0.0869],\n",
            "        [-0.8495,  1.0578,  3.2302,  ...,  0.1793,  4.6115,  2.1057]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5263,  3.2992,  0.3958,  ..., -0.4252,  3.3307, -0.8612],\n",
            "        [-0.1383,  2.1022,  0.3152,  ...,  0.2083,  0.7928,  0.9134],\n",
            "        [-0.3854,  3.4967, -1.4682,  ...,  0.6101,  1.4128,  4.6437],\n",
            "        ...,\n",
            "        [ 0.9442,  3.0479, -0.5511,  ...,  0.5926,  0.9622, -0.4547],\n",
            "        [-1.2870,  1.5608,  3.7062,  ..., -1.2174,  4.0904, -3.3149],\n",
            "        [-0.9117, -1.6267,  4.0049,  ..., -1.4855,  6.1202, -1.6149]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2922,  4.4675, -0.7154,  ...,  0.2465,  0.7488, -0.6043],\n",
            "        [ 0.0200,  3.8063,  3.8647,  ..., -3.5580,  3.9557,  0.0713],\n",
            "        [ 1.0628,  1.8392,  2.8587,  ..., -3.6195,  5.4163, -3.6303],\n",
            "        ...,\n",
            "        [ 0.7125, -0.0599, -0.8849,  ...,  1.3305,  3.8766,  4.3068],\n",
            "        [ 3.6440,  4.3291,  0.8536,  ..., -0.6614,  0.4021, -0.9890],\n",
            "        [ 0.3691, -1.3821,  0.9631,  ..., -1.1733,  3.6100, -5.4606]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6816,  1.2460, -2.1891,  ...,  3.7066,  2.1196, -0.1323],\n",
            "        [ 2.9781,  0.3531, -0.5667,  ...,  0.8893,  3.7436, -2.0669],\n",
            "        [ 0.5329,  0.5421,  2.2269,  ..., -1.8373,  4.9777, -2.8136],\n",
            "        ...,\n",
            "        [ 1.6593,  3.1390,  0.8939,  ..., -0.5193,  1.7551,  1.8078],\n",
            "        [ 1.8009, -1.0065, -0.0307,  ...,  4.2049,  1.9475, -1.6445],\n",
            "        [ 1.7430,  2.8889,  3.3038,  ..., -3.0271,  2.2009, -1.3876]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2325,  4.5368,  3.2464,  ..., -3.1365,  2.4894, -1.6446],\n",
            "        [-2.5236,  1.3803,  4.0547,  ..., -2.1015,  5.0883, -5.8564],\n",
            "        [ 0.8777, -0.9274, -1.4454,  ...,  1.7674,  4.2832,  3.5370],\n",
            "        ...,\n",
            "        [ 1.5309,  4.3115, -0.1577,  ...,  4.8166,  2.3233, -1.7728],\n",
            "        [-0.5412,  1.0380,  0.7943,  ...,  0.2145,  3.3105, -1.9951],\n",
            "        [ 3.0646,  5.3708,  2.9525,  ..., -3.2872,  3.8739,  1.5189]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8557e-01,  1.8746e+00,  7.1147e-01,  ...,  1.1333e+00,\n",
            "          5.4200e+00, -1.6128e-01],\n",
            "        [-1.2044e+00,  4.9265e+00, -3.6984e+00,  ...,  1.5573e+00,\n",
            "          2.0198e+00,  1.8006e-01],\n",
            "        [ 1.3553e+00,  3.2507e+00,  1.0265e-01,  ..., -2.7674e+00,\n",
            "          1.0795e-01, -3.1707e+00],\n",
            "        ...,\n",
            "        [ 2.6539e-01,  1.5840e+00,  1.7989e-01,  ...,  2.6594e-01,\n",
            "          3.7726e+00,  1.3505e+00],\n",
            "        [-5.9734e-01,  5.7611e+00,  4.0853e+00,  ..., -1.9400e-03,\n",
            "          2.4560e+00, -3.2906e+00],\n",
            "        [ 1.0587e+00,  3.8099e+00, -1.7341e+00,  ...,  1.2607e+00,\n",
            "          1.7295e+00,  1.4964e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1102,  0.2125,  0.8451,  ..., -2.4764,  3.1238,  1.5923],\n",
            "        [ 2.1280,  4.5382,  1.3338,  ..., -1.6296,  1.0733, -0.1504],\n",
            "        [-1.1750,  3.7723,  0.5027,  ...,  1.2961,  2.7566, -0.7865],\n",
            "        ...,\n",
            "        [ 1.1612,  4.8045, -1.5372,  ...,  0.0337,  2.7775,  2.3504],\n",
            "        [-0.3470,  5.1480,  0.7328,  ..., -2.6840, -0.8696, -0.6714],\n",
            "        [ 1.2879,  4.2548, -0.6770,  ..., -3.6163,  0.5372, -1.5011]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4845,  4.7688,  3.2338,  ..., -0.0352,  3.0527, -2.9254],\n",
            "        [ 5.1144,  5.1554,  2.8282,  ..., -1.1847,  0.6432, -0.1575],\n",
            "        [ 3.2837,  3.1159,  1.7048,  ..., -0.1313,  2.8105, -0.4054],\n",
            "        ...,\n",
            "        [-4.0577,  1.7144,  4.7407,  ..., -2.8127,  6.0283, -2.7173],\n",
            "        [ 2.3684,  1.9356,  2.9213,  ...,  0.2969,  0.8379, -1.3777],\n",
            "        [ 1.1431,  3.4358,  1.1882,  ...,  5.8050,  2.1957, -2.2580]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3856,  4.9577,  0.1570,  ...,  0.4629,  0.3264, -1.6508],\n",
            "        [-2.7363,  2.0493,  3.8307,  ..., -3.1211,  5.6319, -2.3717],\n",
            "        [-0.4069,  3.2502,  0.3600,  ...,  0.1735,  1.7737,  2.0563],\n",
            "        ...,\n",
            "        [-0.4143,  2.8395, -0.2340,  ...,  0.7428,  2.6516, -0.7596],\n",
            "        [-1.2409,  3.5694, -2.9698,  ...,  0.4048,  0.1817,  0.6774],\n",
            "        [ 0.3435,  5.7865, -0.7714,  ..., -0.7483,  0.0623,  3.1280]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9795,  4.0639, -0.0406,  ..., -0.6714,  2.7228, -1.3820],\n",
            "        [ 0.6043,  4.2624,  3.2020,  ..., -2.6020,  1.4084, -2.6527],\n",
            "        [-0.3635,  1.2353, -2.4854,  ...,  0.9864,  0.8943,  3.3495],\n",
            "        ...,\n",
            "        [ 3.3961,  4.7004,  0.9131,  ..., -2.1830,  1.6588,  0.6733],\n",
            "        [ 1.8819,  3.6255, -0.3637,  ...,  0.1393,  0.9242, -1.0789],\n",
            "        [ 0.2594,  1.5108,  2.9891,  ..., -1.0564,  4.4130,  0.1138]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0704,  4.0725, -0.5085,  ...,  0.0341,  0.5914, -1.7683],\n",
            "        [ 2.7617,  5.6983,  0.1896,  ...,  2.9218,  0.7196, -1.2555],\n",
            "        [ 2.9485, -0.7508, -0.8737,  ..., -0.0990,  3.1842,  1.2239],\n",
            "        ...,\n",
            "        [ 2.0840, -2.3589,  2.1362,  ...,  1.9067,  1.4181, -2.8780],\n",
            "        [ 2.7098,  1.4358,  5.4515,  ..., -3.2398,  5.2962, -1.5963],\n",
            "        [ 1.3503,  1.1843,  0.6086,  ...,  0.8812,  4.3063,  2.2116]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1249,  4.1965,  0.8026,  ..., -0.6684,  2.9382, -0.2231],\n",
            "        [ 0.3279,  3.7969,  0.8385,  ..., -0.9418,  0.2351,  2.8140],\n",
            "        [ 1.2633,  3.1172, -1.6728,  ...,  1.3339,  0.6366,  1.0317],\n",
            "        ...,\n",
            "        [-0.2974, -0.3152, -1.3873,  ...,  0.4236,  4.3583,  3.9547],\n",
            "        [ 2.0991,  5.2484,  2.5371,  ..., -4.2767,  2.1870, -0.3497],\n",
            "        [ 1.0023,  6.1743, -0.8042,  ...,  1.6337,  0.1561, -1.1445]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0724,  7.3310, -0.4655,  ..., -1.1230,  0.6665,  2.2208],\n",
            "        [ 2.5325,  4.1002, -0.4703,  ...,  3.4149,  1.2827, -1.1161],\n",
            "        [ 0.6136,  4.8157, -0.9258,  ...,  0.7753, -0.7597, -1.2995],\n",
            "        ...,\n",
            "        [ 1.4553,  1.5887, -1.7709,  ...,  1.0897, -2.0192,  1.7878],\n",
            "        [ 0.9516,  1.6017,  5.2508,  ..., -3.5357,  3.0763, -6.4215],\n",
            "        [ 1.9378,  0.1310,  0.2038,  ..., -0.5692,  2.9273,  2.3363]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5344,  3.0972,  0.1503,  ..., -1.8321,  2.8860,  2.4294],\n",
            "        [ 0.3919,  5.1856,  3.5560,  ..., -2.4029,  0.7731, -1.0941],\n",
            "        [ 4.9204,  2.9520,  3.0374,  ..., -1.2164,  2.7162, -1.6094],\n",
            "        ...,\n",
            "        [ 1.9678, -0.9821,  0.2604,  ..., -2.7435,  4.0721,  1.1583],\n",
            "        [ 0.6552,  3.6771, -1.6332,  ..., -0.7885,  0.1978,  1.9902],\n",
            "        [-2.9308,  2.1187,  0.2095,  ..., -1.3845,  1.7262, -3.4673]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9037,  5.2463,  1.0958,  ..., -1.6389,  2.2159, -2.4302],\n",
            "        [ 2.1491,  4.2610,  1.1428,  ..., -0.5504,  3.1911, -0.7709],\n",
            "        [ 4.3026,  3.8067, -0.2837,  ..., -1.4685,  1.9491, -1.5811],\n",
            "        ...,\n",
            "        [ 2.0221,  4.9643,  0.9382,  ...,  4.9014,  2.5537, -1.7169],\n",
            "        [ 1.0074,  5.0296, -2.3566,  ...,  1.2672,  0.1642,  3.6834],\n",
            "        [ 1.4283,  3.2301,  2.0335,  ..., -2.2741,  3.2889,  1.8585]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8945,  0.9546,  5.5163,  ..., -0.5837,  4.5520, -1.6206],\n",
            "        [-1.4165,  8.1897,  0.1672,  ..., -2.0388,  0.7522, -1.7099],\n",
            "        [ 0.6490,  4.9471,  1.0544,  ..., -0.8426,  0.7776,  1.4434],\n",
            "        ...,\n",
            "        [-2.8516,  3.7725,  2.5026,  ..., -2.1948,  4.0315, -3.0074],\n",
            "        [ 1.4435,  4.0790, -0.2440,  ..., -0.4301,  2.6047, -0.5257],\n",
            "        [-2.4670, -1.3255,  0.2507,  ..., -0.2993,  3.8539,  1.8451]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0727,  1.6043,  2.0203,  ...,  1.5591,  0.4138, -0.8846],\n",
            "        [-0.1655,  0.6295,  1.1773,  ...,  0.7952,  1.7499, -0.6889],\n",
            "        [ 2.3142,  6.6858,  1.1431,  ..., -1.7461,  2.3912,  0.1272],\n",
            "        ...,\n",
            "        [ 3.6771,  5.1308,  0.1063,  ..., -1.0855,  1.5049, -2.2365],\n",
            "        [-2.0073, -2.6602, -3.1085,  ...,  1.3908,  3.0295,  2.0293],\n",
            "        [ 1.7631,  3.7164,  1.3362,  ..., -0.4916,  1.8925, -0.4054]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1480e+00,  4.0625e+00,  1.7513e-01,  ..., -1.9221e+00,\n",
            "          3.5244e+00, -1.3309e+00],\n",
            "        [ 1.9911e+00,  3.9595e+00,  5.6838e+00,  ..., -2.5451e+00,\n",
            "          3.3397e+00, -3.9602e+00],\n",
            "        [ 1.6262e+00, -7.3222e-03,  7.2953e-01,  ...,  2.4834e+00,\n",
            "          2.1584e+00, -1.2938e+00],\n",
            "        ...,\n",
            "        [-1.3508e-01,  2.9051e+00,  2.9500e+00,  ..., -1.2574e+00,\n",
            "          3.3752e+00,  1.3855e-01],\n",
            "        [ 1.7404e+00,  5.2798e+00,  1.4992e+00,  ..., -2.5818e+00,\n",
            "          1.2754e+00, -2.2217e+00],\n",
            "        [-5.6769e-03, -3.0375e+00, -1.5831e+00,  ...,  4.9040e+00,\n",
            "          1.5086e+00, -1.2110e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1230,  2.2670,  2.0220,  ..., -4.0593,  5.4199, -2.9587],\n",
            "        [-0.8902,  1.3256,  1.2205,  ...,  3.6768,  0.6302, -1.0343],\n",
            "        [-0.6904,  3.1449,  1.0071,  ..., -4.1095,  0.6399,  2.6690],\n",
            "        ...,\n",
            "        [ 0.7113,  2.0906, -0.6748,  ...,  1.4136,  2.6764,  1.5779],\n",
            "        [-0.8413,  1.9196,  1.7645,  ...,  2.5209,  1.2494, -0.3481],\n",
            "        [ 2.3022,  6.1002,  2.3082,  ..., -3.5990, -0.0628,  0.0107]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5192,  4.4655,  0.3515,  ...,  0.5610, -0.4849,  0.4485],\n",
            "        [ 1.2154,  4.0464,  4.5681,  ..., -4.9474,  4.6304, -2.7889],\n",
            "        [-0.2724, -0.9690, -0.5156,  ..., -0.7272,  1.9880, -5.0364],\n",
            "        ...,\n",
            "        [-5.1146, -0.8790,  2.7498,  ...,  0.3766,  5.4252, -3.4826],\n",
            "        [-2.8526, -1.3314, -2.4152,  ...,  3.5098,  1.9442,  0.7832],\n",
            "        [-0.0747,  0.7455, -0.0271,  ..., -0.5886,  3.1863,  0.6293]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0889,  3.6575,  3.0392,  ..., -1.8764,  4.1426, -3.4092],\n",
            "        [-0.1826,  3.3299, -1.5609,  ...,  3.8284, -0.5330,  1.0625],\n",
            "        [-1.5650,  4.3947,  2.8633,  ..., -2.2803,  4.1988, -4.9188],\n",
            "        ...,\n",
            "        [ 2.6108,  4.1555, -0.9587,  ...,  0.8728,  0.9198, -0.8390],\n",
            "        [ 0.3899,  3.8980,  0.6456,  ..., -1.7953, -0.1328, -1.9054],\n",
            "        [-1.7209,  4.6087, -0.4940,  ..., -2.0167,  0.4980,  4.6602]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8181,  2.3783, -5.6199,  ...,  1.2826, -0.8790,  1.9444],\n",
            "        [-0.9220,  3.5772,  0.9828,  ...,  1.4770,  1.4478, -1.0176],\n",
            "        [-0.3019,  4.8977, -1.2036,  ..., -1.3697,  0.0955,  3.5372],\n",
            "        ...,\n",
            "        [-0.3076,  2.6703,  0.0331,  ..., -1.4052,  2.2212,  0.6395],\n",
            "        [ 2.0286,  4.5193, -0.3631,  ...,  2.8204,  0.9332, -1.1346],\n",
            "        [-0.1924,  1.2441, -0.0293,  ..., -0.0799,  4.5480,  3.8394]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9683,  5.0402,  0.2786,  ..., -1.0249,  1.4524,  0.2085],\n",
            "        [-0.9401,  3.6612,  5.2282,  ..., -3.3033,  4.5830, -1.9757],\n",
            "        [ 3.9047,  0.2681,  1.5650,  ..., -0.4994,  3.4964, -2.6272],\n",
            "        ...,\n",
            "        [-6.4420,  0.2298,  4.0270,  ..., -2.8276,  6.2864, -2.1192],\n",
            "        [ 0.0289,  0.3361,  2.1552,  ..., -2.4647,  1.5870, -0.5997],\n",
            "        [-0.3765,  4.7044,  0.9781,  ..., -2.2053, -0.5101, -1.4395]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1144,  3.5268, -0.5620,  ..., -0.2820,  1.2221, -1.0055],\n",
            "        [ 1.5262,  4.6828,  1.6624,  ..., -1.3075,  2.1766, -0.1748],\n",
            "        [ 0.9748,  2.8777,  1.5017,  ..., -2.5224,  2.8966, -0.0328],\n",
            "        ...,\n",
            "        [ 1.8067,  6.4632, -0.6629,  ..., -0.4232, -0.3457,  0.2316],\n",
            "        [ 0.9399,  0.4179,  1.3023,  ...,  1.4606,  3.8636, -0.1444],\n",
            "        [-0.9300,  1.5831,  0.9349,  ..., -2.3370,  4.0101, -1.3393]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4461,  4.6680, -1.2852,  ..., -1.6941, -0.7156,  1.6462],\n",
            "        [-2.8596,  1.9363, -2.9569,  ...,  1.8291,  0.7393,  0.9618],\n",
            "        [-1.4063,  0.5616,  2.9864,  ..., -3.1752,  4.3111, -4.6708],\n",
            "        ...,\n",
            "        [-0.8917,  1.7126,  4.4802,  ..., -1.0283,  4.1294, -2.6226],\n",
            "        [ 2.2504,  3.3293, -1.0510,  ...,  0.5391,  1.1760, -1.2662],\n",
            "        [ 0.9681,  0.2576,  0.4578,  ...,  0.6781,  4.2418,  0.3856]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3864,  3.0399,  1.2643,  ...,  0.0152,  1.7683,  1.6465],\n",
            "        [ 4.5373,  4.1338,  2.9440,  ..., -4.0865,  3.8536,  1.9152],\n",
            "        [ 0.1262, -0.3115, -1.5221,  ...,  1.1621,  4.5166,  3.6935],\n",
            "        ...,\n",
            "        [ 0.6874,  4.4362,  0.9329,  ..., -2.2314,  0.1733,  0.3307],\n",
            "        [ 0.8541,  5.2882,  0.8557,  ..., -2.1206,  0.2334,  0.7707],\n",
            "        [ 0.1306,  6.3934,  5.1750,  ..., -1.5283,  3.8185, -3.5940]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07dab8cca5c346c180a6df0da4e27c58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2946,  2.1824,  1.6897,  ..., -2.4766,  4.1164, -4.1503],\n",
            "        [ 4.9506,  0.5917, -0.5100,  ...,  1.0104,  0.8803, -2.5865],\n",
            "        [ 0.8120,  4.7378,  0.9153,  ..., -2.1278, -0.5079,  0.2051],\n",
            "        ...,\n",
            "        [ 3.7800,  2.8089,  1.0131,  ..., -1.3242,  1.6692,  2.0200],\n",
            "        [ 0.0444,  4.1183,  0.4296,  ...,  1.0922,  1.7258,  2.0750],\n",
            "        [ 0.2640,  4.0980,  6.0761,  ..., -3.8340,  3.1337, -6.1969]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3768,  3.6121,  0.6155,  ..., -0.3937,  1.8811, -0.5426],\n",
            "        [ 1.0218,  5.1912,  3.3000,  ..., -3.0773,  1.1357,  0.2252],\n",
            "        [ 1.0485,  0.8232,  2.5131,  ...,  4.4636,  0.0958, -1.0535],\n",
            "        ...,\n",
            "        [ 5.4881,  1.5717,  2.6268,  ...,  0.5726,  2.9632, -2.3298],\n",
            "        [-0.6891, -0.6951, -0.5194,  ...,  1.8565,  5.5198,  4.1124],\n",
            "        [ 0.6752,  4.7083,  2.9005,  ..., -1.9957,  3.6400,  0.3390]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8965,  0.9066,  3.3793,  ...,  2.4480,  2.9113,  0.4630],\n",
            "        [ 2.2612,  8.4426,  2.0140,  ..., -3.3176,  0.7336, -1.3501],\n",
            "        [ 3.0863,  3.6914,  0.2515,  ..., -0.4217,  2.4499, -2.2688],\n",
            "        ...,\n",
            "        [-5.0359,  4.4453,  5.6955,  ..., -2.3523,  3.7168, -3.6622],\n",
            "        [ 0.9676,  1.9915, -3.2691,  ...,  1.6640, -0.5135,  2.2880],\n",
            "        [-1.6508,  1.7668,  5.7427,  ..., -4.2832,  4.3128, -2.1010]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4892,  1.9510,  0.8086,  ..., -1.7257,  2.9085,  0.1513],\n",
            "        [ 2.1735,  4.5813,  3.0219,  ..., -4.6113,  3.3557, -4.1170],\n",
            "        [-2.1231, -4.2375, -1.0153,  ...,  2.9212,  5.6840,  3.8224],\n",
            "        ...,\n",
            "        [ 1.8475,  4.1792, -0.6971,  ...,  0.9571,  0.1338, -0.3291],\n",
            "        [ 2.8581,  3.1994,  0.3875,  ..., -0.5350,  2.8116, -0.2330],\n",
            "        [-0.7670,  3.3551,  1.2791,  ..., -4.1645,  1.6760,  1.2354]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1130,  6.7704,  1.2133,  ..., -3.7652,  1.6753,  2.3653],\n",
            "        [ 1.8223,  3.6477,  0.6721,  ..., -0.4173,  3.1341, -1.0835],\n",
            "        [ 1.2357,  0.1516, -2.5286,  ..., -0.4453,  2.9983,  5.0769],\n",
            "        ...,\n",
            "        [ 3.6268,  3.7155,  0.1246,  ..., -0.4996,  1.9214, -0.5089],\n",
            "        [ 0.1931,  2.3008, -1.0755,  ..., -0.5794,  1.7535,  1.5396],\n",
            "        [-0.3070,  6.9021,  4.0415,  ...,  0.1105,  3.2070, -3.0679]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4642,  5.8931,  2.1402,  ..., -2.0534,  2.2411, -2.4045],\n",
            "        [ 0.8716, -0.6950,  3.4902,  ...,  3.4626,  2.1331, -2.4610],\n",
            "        [-0.6067,  4.3627,  0.4914,  ..., -3.2256,  0.5408,  1.0338],\n",
            "        ...,\n",
            "        [-0.2840,  2.8468, -1.7281,  ...,  2.6274, -0.4555,  2.7552],\n",
            "        [-3.9188,  0.8645, -4.7801,  ...,  1.1986,  0.4086,  1.8199],\n",
            "        [ 0.3087, -3.0050,  0.9657,  ...,  3.2179,  0.8687, -1.8240]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8890,  3.5513,  6.5593,  ..., -2.9882,  2.8104, -3.8922],\n",
            "        [ 2.8826,  4.4011,  1.5647,  ..., -1.5156,  2.4697, -1.9488],\n",
            "        [ 0.1329,  4.7726,  3.4942,  ..., -2.1708,  4.2554,  0.2248],\n",
            "        ...,\n",
            "        [ 2.2361,  4.5772,  3.4506,  ..., -3.7682,  3.0339, -0.5662],\n",
            "        [ 0.1856,  4.4752,  2.6038,  ..., -1.3121,  2.4808, -1.8419],\n",
            "        [ 2.7905,  0.1289,  3.3738,  ...,  2.3202,  1.1737, -3.0635]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.1944,  2.8167,  2.7535,  ..., -2.1777,  4.9590, -1.4669],\n",
            "        [ 3.0025,  1.5046,  0.9511,  ..., -0.1485,  2.3153,  0.1855],\n",
            "        [ 1.6418,  4.3738,  1.2809,  ..., -2.6754,  3.3963, -1.4463],\n",
            "        ...,\n",
            "        [ 5.1379,  2.9356,  2.3212,  ..., -1.4275,  1.5560, -1.0086],\n",
            "        [-3.0347,  2.7558,  3.4881,  ..., -0.3696,  2.5245, -1.0915],\n",
            "        [ 2.6799,  3.2709,  0.1228,  ..., -0.4580,  3.6468, -1.2999]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7933,  6.5909,  0.3815,  ...,  0.1234,  0.1423,  0.0955],\n",
            "        [ 1.5528,  5.8410, -0.1952,  ...,  2.5103,  0.8399, -0.7679],\n",
            "        [ 1.7823,  4.6749,  1.1695,  ..., -2.4046,  2.4816, -0.5491],\n",
            "        ...,\n",
            "        [-0.0875,  4.5007,  1.9996,  ..., -2.2621,  1.9812,  0.9452],\n",
            "        [ 1.4734,  4.0493, -0.4159,  ...,  2.7366,  1.0783, -0.8669],\n",
            "        [ 3.4477,  4.6127,  1.1530,  ..., -1.1459,  3.1664, -1.3987]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 7.8784e-01,  3.9322e+00,  2.7457e+00,  ..., -2.1980e+00,\n",
            "          5.9742e+00,  3.2764e-03],\n",
            "        [-1.5869e+00,  1.6042e+00,  1.7777e+00,  ..., -2.0466e+00,\n",
            "          5.3228e+00, -3.4845e+00],\n",
            "        [-8.5777e-01,  2.6968e+00, -1.5972e+00,  ..., -3.6616e-01,\n",
            "          1.3946e+00,  3.0015e+00],\n",
            "        ...,\n",
            "        [-2.0154e+00,  1.1280e+00,  3.8403e+00,  ..., -3.3195e+00,\n",
            "          2.8192e+00, -2.0071e+00],\n",
            "        [ 6.5747e-01,  5.2564e+00,  1.5052e+00,  ..., -3.5556e+00,\n",
            "          1.7004e+00, -3.2618e+00],\n",
            "        [-6.3588e-01,  2.2490e+00, -2.1319e+00,  ...,  2.4848e+00,\n",
            "          2.0367e+00, -1.0289e-03]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8286,  1.7473, -3.0611,  ..., -0.0730, -0.2250,  0.3397],\n",
            "        [-0.1153,  5.3949,  7.9173,  ..., -2.8641,  2.4963, -4.6407],\n",
            "        [-4.4616,  2.2034, -3.1941,  ...,  0.1977,  1.1605,  4.1013],\n",
            "        ...,\n",
            "        [ 3.6506,  0.3170,  1.6935,  ..., -0.2574,  3.6396, -2.9170],\n",
            "        [ 2.7836,  5.0003,  0.4512,  ..., -0.6633,  0.9477, -1.7044],\n",
            "        [-0.7528,  3.0165,  2.2014,  ..., -2.8441,  1.4273, -4.5767]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7695,  3.8179,  4.6297,  ..., -3.3017,  4.5954, -2.6045],\n",
            "        [ 2.2140,  3.8002, -0.5113,  ...,  0.8375,  1.0096, -0.6361],\n",
            "        [ 2.3870,  4.5545,  1.1923,  ..., -1.7057,  3.4954, -1.7077],\n",
            "        ...,\n",
            "        [ 1.4315,  4.3458, -0.2833,  ...,  0.3745,  1.5145,  1.8569],\n",
            "        [-2.7323,  4.2526,  2.3833,  ..., -3.1990,  4.8354, -1.0448],\n",
            "        [ 0.1270,  7.2200, -0.3395,  ..., -2.3108,  0.2073, -0.1252]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3101,  6.0755,  7.1256,  ..., -5.7118,  3.9087, -7.8512],\n",
            "        [-0.7961,  2.0432, -0.2358,  ..., -0.5745,  3.6877,  1.8828],\n",
            "        [ 0.7071,  0.7277,  1.3379,  ..., -1.9019,  3.8330,  1.0527],\n",
            "        ...,\n",
            "        [ 1.6238,  1.7129, -3.3610,  ...,  2.5487, -1.4329,  1.3885],\n",
            "        [ 1.7869,  3.6900,  4.4886,  ..., -3.2527,  5.5594,  0.1614],\n",
            "        [ 0.5649,  3.7388,  0.4785,  ..., -0.2289,  1.3632,  2.7167]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5922,  1.4463,  0.2864,  ..., -2.5134,  2.9817,  0.3327],\n",
            "        [-0.9662,  3.2204, -3.4779,  ...,  1.8661, -1.2338,  2.8676],\n",
            "        [ 0.5262,  2.7560,  1.6051,  ..., -0.4291,  1.9969,  0.6164],\n",
            "        ...,\n",
            "        [ 4.8808,  5.6627,  2.0030,  ..., -2.7672,  0.8785,  1.8470],\n",
            "        [-6.8371,  2.2807,  3.3767,  ..., -2.7984,  4.9484, -5.1078],\n",
            "        [ 2.7682,  0.0528,  4.1661,  ...,  0.2475,  5.0197, -2.5594]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3482, -1.7090, -1.7977,  ...,  2.8360,  2.8701,  3.6447],\n",
            "        [-1.7752, -1.2831, -0.3413,  ..., -0.6281,  2.9165,  2.8517],\n",
            "        [ 1.2512,  3.7148, -1.2680,  ...,  1.0994,  0.3634,  0.1066],\n",
            "        ...,\n",
            "        [ 2.1391,  3.6392, -0.7294,  ..., -0.1904,  1.7387, -1.0967],\n",
            "        [ 2.3244,  6.4970,  4.7197,  ..., -4.6672,  4.0519, -1.8219],\n",
            "        [-0.8116,  3.9200,  2.9369,  ..., -3.4370,  5.9979, -0.4229]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1782,  5.3754, -0.9477,  ...,  0.9665, -0.4127,  0.5504],\n",
            "        [ 1.3250, -2.0005, -1.1100,  ...,  5.0323,  0.2412,  0.6047],\n",
            "        [ 1.6953,  5.0609,  1.9115,  ..., -5.4398,  1.4658, -0.9962],\n",
            "        ...,\n",
            "        [-1.9050, -1.8875,  0.0145,  ...,  1.9209,  3.6629, -0.6511],\n",
            "        [ 2.1392,  3.3955, -0.9669,  ..., -0.3961,  1.2731, -0.6486],\n",
            "        [ 0.4534,  5.9787,  1.1950,  ..., -2.0868,  0.6088,  1.2719]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8390,  2.6304,  1.2913,  ..., -1.2409,  3.3864, -4.5037],\n",
            "        [-2.5488,  2.8760, -0.3691,  ...,  0.5730,  2.5828,  3.7060],\n",
            "        [-1.3167, -2.4714,  0.6488,  ...,  3.4921, -0.7387, -2.2752],\n",
            "        ...,\n",
            "        [-2.4044,  4.3077,  1.9905,  ..., -3.2661,  2.5431,  1.6751],\n",
            "        [ 0.4026,  2.6227,  4.2853,  ..., -1.7925,  5.6492,  0.8596],\n",
            "        [ 0.4030,  1.5379, -1.4852,  ...,  2.1278, -0.5675,  3.6042]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4382,  3.8720,  0.1437,  ..., -3.0902, -0.7169, -2.1765],\n",
            "        [-4.3910,  3.5857,  1.4188,  ..., -5.3627,  5.9042, -6.4677],\n",
            "        [ 0.9900,  5.9285,  1.0841,  ..., -2.3547,  0.7243, -0.3267],\n",
            "        ...,\n",
            "        [-0.9886,  6.1055, -0.1581,  ..., -2.7225,  1.2176, -0.9280],\n",
            "        [-0.5881,  0.5448, -3.2338,  ...,  1.0628, -0.6388,  2.4587],\n",
            "        [-7.9307,  3.4922,  1.6825,  ..., -2.2575,  2.2342, -4.3714]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9990,  1.9119, -1.5790,  ...,  4.0986,  0.7378, -1.0012],\n",
            "        [-2.7370,  4.0753,  5.6859,  ...,  0.0463,  4.7460, -3.2668],\n",
            "        [-0.3983,  0.8758,  2.4313,  ..., -2.9853,  2.9379, -3.3809],\n",
            "        ...,\n",
            "        [-0.6162,  0.7425,  2.5390,  ...,  2.8037,  1.5991, -0.6468],\n",
            "        [ 3.2553, -1.2645, -0.7113,  ...,  2.1154,  4.7497, -2.5028],\n",
            "        [ 3.1730,  3.4693,  0.7476,  ..., -1.3928,  2.4526, -0.4028]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8209,  3.5641, -2.3593,  ...,  3.0763,  0.6182,  2.2554],\n",
            "        [-2.7603,  0.1844,  0.7757,  ...,  4.2225,  1.8623, -1.2434],\n",
            "        [-2.3822,  1.1962, -2.4458,  ...,  2.3673,  0.8326, -0.0710],\n",
            "        ...,\n",
            "        [-1.1794,  4.3801, -0.3791,  ..., -0.5831,  0.4225,  1.5865],\n",
            "        [-0.4789,  4.8007,  0.2648,  ..., -2.9759,  0.7769,  0.4366],\n",
            "        [ 0.7587,  5.1002,  0.3852,  ..., -1.7470,  0.5279,  1.9043]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0514, -0.5607, -1.9986,  ...,  4.6189,  1.1994, -0.2724],\n",
            "        [-3.0452,  2.8536,  0.0404,  ..., -0.6385,  4.2499,  0.1874],\n",
            "        [ 1.3837,  1.3455,  1.1959,  ...,  1.8227, -0.7111, -0.6539],\n",
            "        ...,\n",
            "        [ 0.9993,  4.7152,  0.9477,  ...,  1.7202,  4.2755, -1.1054],\n",
            "        [ 0.2297,  5.5241, -0.6776,  ..., -1.5096,  1.0220, -0.6373],\n",
            "        [-2.6568,  3.2011,  8.6247,  ..., -2.6225,  7.8433, -4.5764]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3450,  1.6608,  2.7882,  ...,  0.7446,  2.4948, -0.5004],\n",
            "        [-0.2939,  3.4469, -2.6899,  ...,  1.6800,  0.0785,  3.8439],\n",
            "        [ 1.7693,  3.8129,  0.4263,  ...,  4.3158,  1.5770, -0.9172],\n",
            "        ...,\n",
            "        [-0.8669,  3.4083,  2.6510,  ..., -1.2985,  5.7016,  1.0618],\n",
            "        [ 0.1717,  3.8774,  0.0955,  ...,  0.7960,  0.1944,  1.6918],\n",
            "        [-0.3090,  3.9258, -0.7574,  ...,  1.6748, -0.0415,  2.1003]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2332,  2.9821, -1.4663,  ...,  0.3116,  0.3564,  1.1273],\n",
            "        [-0.0433, -0.5232, -2.5365,  ...,  0.3124,  0.8542, -2.2774],\n",
            "        [-1.5894,  1.3627, -0.8476,  ..., -0.1059,  2.6517,  0.5573],\n",
            "        ...,\n",
            "        [-1.9863,  4.5650, -3.3380,  ..., -3.5734,  1.0048,  2.6180],\n",
            "        [-3.7283, -0.9362,  0.9108,  ..., -1.1040,  3.5210, -6.0449],\n",
            "        [ 5.3007,  3.6615,  0.3918,  ...,  1.0190,  1.1186,  1.1954]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3620,  5.8380,  3.4279,  ..., -3.2122,  2.5021, -2.2318],\n",
            "        [-0.5247,  5.2422,  4.2711,  ..., -3.2384,  1.1904, -1.8562],\n",
            "        [-0.2638,  1.0414, -3.5448,  ...,  0.4095,  0.8006,  0.8003],\n",
            "        ...,\n",
            "        [ 2.9688,  4.4754, -0.8722,  ..., -0.0849,  1.2736, -0.7339],\n",
            "        [-0.4195,  2.2468, -1.5433,  ...,  2.6629,  1.5343,  1.9157],\n",
            "        [ 2.9061,  3.0077, -0.6882,  ...,  1.7439,  1.4996, -1.5014]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4120,  2.6363, -4.2568,  ...,  3.0327,  0.5190,  4.6835],\n",
            "        [ 2.7056,  4.2755,  0.8843,  ..., -1.7897,  3.1229, -0.4820],\n",
            "        [-0.3007,  2.9005,  2.5589,  ..., -1.1744,  1.3068,  0.4905],\n",
            "        ...,\n",
            "        [-1.7722,  3.9188, -2.8739,  ...,  0.0484,  0.7911,  4.5119],\n",
            "        [ 4.8963,  2.5875,  0.2554,  ...,  0.8335,  0.2799, -1.6585],\n",
            "        [-1.4891,  1.6950, -0.4228,  ...,  2.2655,  0.6098, -1.7232]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9851,  0.1489, -0.5866,  ...,  1.1188,  2.3533,  1.8103],\n",
            "        [-3.0126,  0.5554, -0.0664,  ...,  6.6517, -0.1225,  0.4356],\n",
            "        [-1.1506,  4.7936,  4.0791,  ..., -4.3097,  3.7892, -0.5057],\n",
            "        ...,\n",
            "        [ 1.3481,  1.8627,  3.2346,  ..., -3.3808,  5.9885,  0.1202],\n",
            "        [ 2.0366, -0.3068,  1.9299,  ...,  1.3891,  7.1528, -3.0410],\n",
            "        [ 0.3792,  3.9525,  1.7780,  ...,  0.5643,  2.6699, -0.3787]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0456,  3.5114,  4.0694,  ..., -2.1315,  3.0508, -0.6046],\n",
            "        [-3.7264, -0.9951, -1.3150,  ...,  0.5335,  6.4032, -1.4871],\n",
            "        [-2.8811,  3.5591,  4.9607,  ..., -1.1676,  5.3405, -0.8056],\n",
            "        ...,\n",
            "        [ 2.3117,  7.7442,  1.1670,  ..., -2.7242,  1.6774,  1.2162],\n",
            "        [ 3.3075,  3.2745,  0.5897,  ..., -1.4935,  4.3064, -1.4920],\n",
            "        [-2.1212, -0.1188,  0.9282,  ..., -2.0157,  3.1731, -0.1697]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9812,  4.9590,  0.2365,  ..., -1.7833,  1.4863, -1.2648],\n",
            "        [-0.8709,  4.0261,  0.5023,  ...,  1.4102,  1.1931,  1.5362],\n",
            "        [-1.2978, -0.5750,  3.3927,  ...,  5.5002,  2.8399, -1.0265],\n",
            "        ...,\n",
            "        [-0.3848,  4.4898,  1.1739,  ..., -0.8962,  2.4256,  0.6780],\n",
            "        [ 2.3147,  4.5200,  2.5502,  ..., -3.0903,  3.4427,  1.6193],\n",
            "        [-1.1522,  2.2870,  6.7127,  ..., -0.0824,  3.1179, -6.0595]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7192,  0.5253, -2.3358,  ...,  1.8211,  3.0107, -1.0302],\n",
            "        [-0.1821,  2.5529, -2.3504,  ..., -1.5008, -0.1254,  2.3195],\n",
            "        [ 1.0294,  5.9068, -0.3995,  ..., -2.1484, -1.3198,  0.3398],\n",
            "        ...,\n",
            "        [ 2.1514,  5.0945,  0.8293,  ...,  0.9649,  2.5466, -1.6925],\n",
            "        [-1.1748,  3.8631,  4.9762,  ..., -1.0472,  1.8568, -2.6145],\n",
            "        [ 2.3841,  2.4671,  0.8454,  ..., -2.0077,  3.0217, -1.1202]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5603,  5.1622,  0.8384,  ..., -1.0492,  0.8596,  1.3012],\n",
            "        [-1.0014,  3.9896,  2.9298,  ..., -3.3120,  4.5446, -0.7657],\n",
            "        [-2.0921,  2.4261,  1.2725,  ..., -2.8416,  2.4836, -7.0716],\n",
            "        ...,\n",
            "        [ 0.8589,  1.7885, -1.9519,  ...,  1.8342, -0.7015,  0.6991],\n",
            "        [ 1.1171,  4.4568,  3.9509,  ..., -3.3096,  6.2435, -0.3905],\n",
            "        [-0.8234,  3.4831, -4.2783,  ...,  2.7058,  0.4694, -0.8839]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4983,  1.4451, -0.7104,  ..., -0.0076,  0.0123, -0.3377],\n",
            "        [-0.7973,  2.1429, -1.9930,  ...,  0.6456,  1.1985,  1.2688],\n",
            "        [ 1.1123,  1.8146, -0.8877,  ..., -1.7505,  1.4681, -0.4227],\n",
            "        ...,\n",
            "        [-1.2433,  3.0550, -2.3787,  ..., -0.0433,  0.0923,  4.3063],\n",
            "        [ 1.3784,  3.2574,  0.9655,  ...,  0.1261,  1.4564, -1.2571],\n",
            "        [-0.1949,  7.2951,  1.9821,  ..., -1.4696,  2.4969,  0.7414]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6998,  0.5541,  2.2789,  ..., -4.0029,  5.4938, -6.2957],\n",
            "        [ 1.9717,  1.5862, -0.4222,  ..., -2.4948,  4.7735,  0.8755],\n",
            "        [-2.2458, -0.2038,  2.5395,  ..., -3.1773,  6.6375, -0.9710],\n",
            "        ...,\n",
            "        [ 4.0755,  6.3124,  0.5070,  ...,  0.1663,  1.3783, -1.4858],\n",
            "        [-4.8668,  3.6720,  4.5686,  ..., -2.9728,  6.0570, -5.3091],\n",
            "        [ 0.2958,  4.0787,  1.3992,  ..., -1.8024,  1.6575,  2.9796]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2436,  3.7989, -1.1034,  ...,  0.0907,  0.4251,  0.5856],\n",
            "        [ 2.6951,  5.1449, -0.1520,  ..., -0.4897,  1.7805, -0.8912],\n",
            "        [-4.8887, -2.2746, -1.4131,  ...,  5.5150,  1.0970, -0.4938],\n",
            "        ...,\n",
            "        [ 1.4560,  7.5418,  0.3460,  ..., -0.5400,  0.8216,  0.8349],\n",
            "        [ 1.1823,  4.5737,  4.8672,  ..., -3.0044,  2.3812, -4.1208],\n",
            "        [ 0.0728,  2.4957,  2.4198,  ..., -3.2808,  3.8837, -2.9843]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1171,  6.3773, -0.3898,  ...,  3.8811,  1.2910, -0.4975],\n",
            "        [-0.3006,  3.5530, -0.7339,  ...,  0.7523,  2.1034,  3.1850],\n",
            "        [ 2.8896,  4.4722,  1.3739,  ..., -1.8892,  0.1360, -4.1638],\n",
            "        ...,\n",
            "        [-0.4733,  3.0476,  0.2297,  ...,  1.5185,  1.3473,  1.6175],\n",
            "        [ 0.5812,  0.1061,  0.9729,  ..., -1.2496,  6.2603,  2.1702],\n",
            "        [ 1.4022, -1.1719,  3.2465,  ...,  2.3757,  6.9554,  0.1267]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7627,  5.1842,  1.7886,  ..., -2.3689,  2.9638, -1.3447],\n",
            "        [ 2.6995,  4.1371, -0.5327,  ...,  0.4386,  0.7735, -1.3808],\n",
            "        [-3.0011,  1.7588,  3.5376,  ..., -2.5402,  3.0429, -6.6132],\n",
            "        ...,\n",
            "        [ 3.2029,  4.5861,  0.4245,  ..., -1.3304,  2.9824, -1.3839],\n",
            "        [-3.0226,  0.4145, -4.6785,  ...,  3.2742,  0.4492,  0.5755],\n",
            "        [-2.8815, -1.1562, -1.4871,  ...,  6.0850,  1.6659, -2.7847]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8752,  4.0857,  1.8080,  ..., -3.6692,  2.3034,  2.0620],\n",
            "        [ 0.1594,  4.8089,  1.3136,  ..., -2.8143,  1.4959, -0.3921],\n",
            "        [ 1.0262,  0.4802,  0.8683,  ..., -1.5997,  4.4442,  0.4873],\n",
            "        ...,\n",
            "        [ 2.5539,  5.8756,  2.1816,  ..., -2.4481,  4.0356, -1.7710],\n",
            "        [ 1.3204,  4.1326,  0.2898,  ..., -1.4583,  1.8733, -1.9570],\n",
            "        [-0.3949,  5.2757, -0.1626,  ..., -4.1498,  1.0039, -0.2048]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9910,  1.4108, -0.8785,  ...,  1.0338,  1.1018,  0.7054],\n",
            "        [-0.5653,  2.8654, -3.2515,  ...,  0.2658,  1.3956, -0.8112],\n",
            "        [ 1.2383,  3.6086,  0.3497,  ..., -0.5245,  2.4198, -0.2398],\n",
            "        ...,\n",
            "        [ 1.7074,  3.7007, -0.4663,  ...,  0.2522,  0.7672,  0.8463],\n",
            "        [-2.0991,  2.4597,  3.6737,  ...,  1.0148,  3.1899, -1.6088],\n",
            "        [-0.9373,  0.8137, -2.5842,  ..., -0.4360,  1.7208,  3.4132]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1747,  3.7722, -0.7939,  ..., -2.5277,  1.1255,  2.2512],\n",
            "        [ 0.7821,  2.4168,  0.4424,  ...,  1.0153,  1.4539,  0.1400],\n",
            "        [-5.8593,  1.3378, -3.5479,  ...,  6.0996,  1.7621, -0.5865],\n",
            "        ...,\n",
            "        [ 3.3473,  3.6228,  2.0228,  ..., -3.4247,  1.8723, -0.9930],\n",
            "        [ 0.8358,  0.1550, -2.1404,  ..., -0.4102,  2.8440,  3.2469],\n",
            "        [-2.1600,  2.3037,  2.3912,  ...,  0.3238,  2.7678, -1.6414]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9024,  5.0654,  4.9016,  ..., -2.0754,  6.3425, -1.5314],\n",
            "        [ 1.6256,  0.5009,  0.1247,  ...,  0.9770,  4.3420, -1.5987],\n",
            "        [-1.8300,  2.6207, -3.3823,  ..., -1.4353, -0.0130,  4.8587],\n",
            "        ...,\n",
            "        [ 2.3524,  3.4877, -0.9408,  ...,  0.1849,  1.2525, -1.4120],\n",
            "        [ 3.2966,  6.3719,  2.1829,  ..., -1.7168,  3.1655, -1.8121],\n",
            "        [ 3.0851,  4.6042,  0.5508,  ..., -0.9454,  3.7198,  0.4039]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9681,  3.5878,  0.1878,  ..., -1.7227,  3.4312, -1.7090],\n",
            "        [ 0.6383,  1.4456, -0.1964,  ..., -0.9603,  4.0355,  1.0629],\n",
            "        [ 2.4067,  3.5662, -0.1182,  ..., -0.3379,  2.8668, -0.7652],\n",
            "        ...,\n",
            "        [ 2.0191,  4.7509, -0.1269,  ..., -0.0840,  1.1938, -0.7890],\n",
            "        [ 2.6384,  5.0251, -0.0938,  ...,  0.0372,  1.2353, -1.6331],\n",
            "        [-0.4162,  5.0723, -1.9400,  ..., -0.4473,  3.6910,  2.4369]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2452,  2.9401,  2.3743,  ..., -2.4088,  2.4301, -1.3005],\n",
            "        [ 2.3185,  3.4242,  0.6489,  ...,  0.5773,  1.5764, -0.3609],\n",
            "        [-0.9338,  2.4891, -2.0702,  ...,  3.0631,  0.6163,  2.7629],\n",
            "        ...,\n",
            "        [ 0.5995,  3.1799, -2.0761,  ...,  1.9154,  2.2134,  0.0572],\n",
            "        [ 1.9362,  3.3798,  6.8261,  ..., -1.8005,  3.0228, -3.2871],\n",
            "        [-6.7484,  1.5420,  3.1372,  ..., -1.1151,  3.5876, -3.9925]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6752,  4.5853, -1.1259,  ...,  2.9263, -0.2975, -0.0670],\n",
            "        [-1.1978, -1.9510, -0.6808,  ...,  2.8398,  3.5431,  4.0107],\n",
            "        [-1.1857,  5.1734,  4.2113,  ..., -4.3052,  3.2669, -2.5599],\n",
            "        ...,\n",
            "        [ 0.0481,  3.2255,  3.9277,  ..., -3.0337,  2.2682, -1.8700],\n",
            "        [ 1.5782,  5.1878, -0.8537,  ...,  4.3735,  1.5619, -0.0559],\n",
            "        [ 3.4528,  4.6382,  0.2823,  ..., -0.3033,  2.4358, -1.2107]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8274e+00,  1.6222e+00, -3.6506e+00,  ...,  2.5570e+00,\n",
            "         -9.2557e-01,  1.0150e+00],\n",
            "        [ 1.4081e-01,  6.0663e+00, -1.1961e+00,  ...,  1.1093e+00,\n",
            "         -5.1319e-01,  5.4805e-01],\n",
            "        [-7.1504e-01,  4.7743e+00, -3.8676e+00,  ...,  2.5826e+00,\n",
            "          5.2913e-01,  1.4355e+00],\n",
            "        ...,\n",
            "        [ 4.9991e+00,  1.8364e+00,  1.9703e+00,  ...,  3.7323e+00,\n",
            "         -3.8342e-03, -1.2944e+00],\n",
            "        [ 5.0032e+00,  4.1984e+00, -7.0533e-01,  ..., -7.8339e-03,\n",
            "          1.3567e+00, -1.6934e+00],\n",
            "        [ 2.2438e+00,  3.5054e+00, -4.6238e-01,  ...,  8.5649e-01,\n",
            "          1.5915e+00, -9.2692e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7442,  0.2952,  2.2143,  ..., -0.1507,  5.0918,  0.9727],\n",
            "        [ 1.3253,  2.5993, -0.8610,  ...,  1.8089,  0.8157,  0.8502],\n",
            "        [ 0.6178,  4.9152, -0.5214,  ..., -0.6879,  0.9344, -0.5266],\n",
            "        ...,\n",
            "        [ 0.7227,  7.0851,  2.9288,  ..., -0.7090,  1.5645, -2.5742],\n",
            "        [ 2.7334,  3.5820, -0.2796,  ..., -0.0759,  2.2856, -0.9088],\n",
            "        [ 1.9326, -2.2485,  1.7085,  ...,  6.5986,  1.7761, -6.1048]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6110,  5.0814,  4.9674,  ...,  0.6997,  4.3006, -4.4608],\n",
            "        [ 2.4177,  3.4019,  4.6152,  ..., -2.5642,  4.6752, -0.9326],\n",
            "        [ 4.3032,  5.4644,  0.6682,  ...,  0.1004,  1.6793, -0.2650],\n",
            "        ...,\n",
            "        [ 0.8476, -0.2036, -0.5698,  ...,  0.6857,  5.5243,  4.9313],\n",
            "        [ 1.2559,  4.5797,  0.0890,  ...,  0.3917, -1.4994, -0.6563],\n",
            "        [-1.6106, -3.4795, -1.4063,  ...,  6.3431,  1.3120, -2.3702]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3739,  2.7194,  7.7195,  ..., -1.0954,  5.3841, -3.9660],\n",
            "        [-2.3488,  2.8537,  7.7296,  ...,  1.0083,  3.5869, -3.8060],\n",
            "        [-1.5345,  5.4756, -0.7350,  ..., -2.5346,  0.2348,  1.1040],\n",
            "        ...,\n",
            "        [ 0.7400,  3.3220, -0.6842,  ...,  1.8477,  0.3221,  3.4446],\n",
            "        [ 2.2791,  5.2699,  0.9370,  ..., -0.8993,  0.6023,  0.0975],\n",
            "        [-0.8737,  0.1636, -0.3046,  ...,  1.2863,  3.6380,  1.8383]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3750e+00,  3.3039e+00, -2.9651e-02,  ..., -5.2292e-03,\n",
            "          1.2252e+00, -1.6770e+00],\n",
            "        [-5.3432e+00,  2.5970e+00,  1.9887e+00,  ...,  4.9780e-02,\n",
            "          2.3618e+00, -4.3237e+00],\n",
            "        [ 2.1760e+00,  2.5258e+00,  3.0979e+00,  ..., -1.2219e-02,\n",
            "          5.0050e+00, -1.2436e+00],\n",
            "        ...,\n",
            "        [ 1.4523e+00,  5.1953e+00,  8.1891e-02,  ...,  3.3701e-01,\n",
            "          8.5363e-01, -3.9436e-01],\n",
            "        [ 3.2630e+00,  3.2189e+00,  2.6731e-01,  ...,  3.2769e+00,\n",
            "          1.3644e+00, -1.3626e+00],\n",
            "        [ 1.1461e+00,  3.3874e+00,  9.9410e-01,  ..., -1.1311e+00,\n",
            "          2.1057e+00, -1.5724e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.5402,  4.4720, -0.7605,  ..., -0.1167,  1.4114, -0.4953],\n",
            "        [ 0.2690, -2.7935, -1.3225,  ...,  1.0659,  3.9123,  1.7119],\n",
            "        [ 0.4775,  3.3555,  2.3642,  ..., -1.5701,  4.1694, -0.6523],\n",
            "        ...,\n",
            "        [ 3.1506,  4.3564,  2.1495,  ..., -1.5482,  1.5198,  1.7610],\n",
            "        [ 2.2801,  2.3355,  2.8790,  ..., -2.2301,  4.7682,  0.2812],\n",
            "        [ 0.9942,  6.4755,  6.9019,  ..., -4.4369,  7.2866, -1.6660]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1833,  2.7890,  0.4492,  ...,  1.9067,  1.8801,  0.1213],\n",
            "        [-0.3301,  2.0314,  1.9451,  ..., -1.7450,  4.0626, -3.5086],\n",
            "        [ 0.4222,  2.0160, -2.4921,  ...,  0.2463, -0.9539,  2.8598],\n",
            "        ...,\n",
            "        [-1.2672,  5.4158, -1.3846,  ...,  0.6147,  1.4570,  2.5559],\n",
            "        [ 0.6110,  5.6423,  0.4114,  ..., -2.8554,  2.6630,  2.9542],\n",
            "        [-0.3953,  4.6195,  4.2865,  ..., -2.3282,  3.8315, -4.7341]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0799,  7.5175,  5.9831,  ..., -3.8429,  3.4572, -4.6713],\n",
            "        [-1.4566,  1.4985,  3.2783,  ..., -1.0780,  4.7081, -2.0790],\n",
            "        [-3.0154,  1.9075, -3.5821,  ...,  2.0090,  1.3884,  2.2506],\n",
            "        ...,\n",
            "        [ 1.9994,  5.2127, -0.9303,  ...,  1.2066, -0.2489, -0.6572],\n",
            "        [ 0.7389,  4.8834, -0.2866,  ...,  0.5514, -0.0336,  0.6108],\n",
            "        [ 0.6062,  4.1913,  3.8034,  ..., -4.0363,  1.3834, -3.0584]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.4194,  0.5733,  1.7421,  ..., -3.9580,  6.2595, -3.3210],\n",
            "        [ 3.0197,  3.0623,  1.8688,  ..., -0.2787,  2.1098,  0.8275],\n",
            "        [ 0.6226,  2.6620,  1.7656,  ...,  2.6460,  3.5221,  2.4039],\n",
            "        ...,\n",
            "        [ 3.4493,  3.8559,  0.3812,  ..., -1.6402,  3.2981, -1.1048],\n",
            "        [-1.4762,  4.4458,  4.5616,  ..., -2.6835,  5.3269, -2.6488],\n",
            "        [ 4.0690,  4.1669,  3.0532,  ...,  0.2276,  4.1700, -1.9346]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0913,  5.7195,  1.9679,  ..., -1.1719,  1.6980, -2.1048],\n",
            "        [ 3.3682,  5.0404,  0.4951,  ...,  0.0246,  1.7543, -1.1456],\n",
            "        [ 1.2846,  4.3559,  4.4359,  ..., -3.5553,  1.4875, -5.7807],\n",
            "        ...,\n",
            "        [ 1.4883,  5.9113, -0.8454,  ..., -2.1945,  0.6202, -0.6118],\n",
            "        [ 6.3184,  2.6751,  1.8321,  ..., -0.7051,  0.5112, -0.9311],\n",
            "        [-0.6069,  2.5675, -4.6059,  ...,  2.3618, -3.0323,  0.0744]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5567,  4.8490,  0.0616,  ..., -0.4135,  0.0769, -1.3808],\n",
            "        [ 1.1031,  0.3204,  3.5733,  ..., -3.2383,  0.7099, -5.9974],\n",
            "        [ 0.0329,  1.9361, -3.6374,  ...,  1.8867,  1.2028,  1.5278],\n",
            "        ...,\n",
            "        [ 2.5634,  4.1763,  0.7325,  ..., -0.3110,  1.8747, -0.5342],\n",
            "        [-1.3760,  4.7112,  5.7304,  ..., -2.9935,  4.8522, -4.2877],\n",
            "        [ 3.4400,  4.8704,  1.6171,  ..., -0.1614,  2.9940, -0.5180]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5891,  5.0475,  0.1269,  ...,  4.4441,  0.8891, -0.6461],\n",
            "        [-6.8515,  0.2930,  0.7094,  ..., -1.9936,  4.1971, -3.8960],\n",
            "        [ 4.0001,  2.6620,  0.4566,  ..., -0.9337,  3.1256, -0.4338],\n",
            "        ...,\n",
            "        [ 1.6983,  1.9049, -2.2952,  ...,  2.5546,  0.3103,  2.0463],\n",
            "        [-1.8878,  4.1440, -0.7930,  ..., -1.6707,  2.1990,  4.4336],\n",
            "        [ 1.3721,  1.6180, -0.8606,  ...,  0.2523,  2.3118,  3.7630]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7666,  6.6587,  1.5597,  ..., -3.8450, -1.0435, -2.1696],\n",
            "        [ 2.9758,  2.8379,  2.9778,  ..., -2.9509,  1.2485, -2.0606],\n",
            "        [ 2.8428,  4.7890,  0.4929,  ..., -1.8774,  0.3277, -0.0545],\n",
            "        ...,\n",
            "        [ 1.4250,  5.9902,  2.1577,  ..., -2.1835,  2.3468,  1.6359],\n",
            "        [ 3.0928,  3.4604,  0.6713,  ..., -1.8087,  2.4493,  2.4491],\n",
            "        [-0.8776,  4.7457,  3.0287,  ..., -3.6929,  2.5090, -1.2655]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8222,  3.9863,  3.2769,  ..., -2.5854,  0.4138, -3.7669],\n",
            "        [ 3.0289,  5.8217,  1.8726,  ..., -1.4106,  2.8078,  0.7848],\n",
            "        [ 0.9806,  1.6711,  2.2551,  ...,  1.3814,  3.4464,  0.0183],\n",
            "        ...,\n",
            "        [ 1.2627,  2.7058,  0.2297,  ..., -1.8967,  1.3958, -1.1099],\n",
            "        [ 3.3062,  5.0072,  0.1993,  ..., -0.7015,  2.7160,  0.5145],\n",
            "        [ 1.1427,  4.2115, -0.8145,  ...,  2.5017,  1.3360, -1.5883]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.9164e-01,  3.1265e+00,  3.7762e-01,  ...,  2.0428e+00,\n",
            "          1.7993e+00,  4.6779e-01],\n",
            "        [-3.4401e+00, -2.7628e-01, -2.6983e-01,  ...,  3.1521e-01,\n",
            "          3.3779e+00,  1.2809e+00],\n",
            "        [ 7.9326e-01,  4.6494e+00, -6.6609e-01,  ..., -1.4628e+00,\n",
            "          2.4987e-01,  2.4950e+00],\n",
            "        ...,\n",
            "        [ 2.3153e+00,  3.3846e+00, -3.6874e-01,  ...,  4.4109e-03,\n",
            "          8.4711e-01, -1.0812e+00],\n",
            "        [ 2.2174e+00,  1.7613e+00,  1.5964e+00,  ..., -1.6557e+00,\n",
            "          3.5378e+00,  9.4790e-01],\n",
            "        [ 1.4293e+00,  4.3020e+00,  2.6257e+00,  ..., -3.8684e+00,\n",
            "          7.5605e-01,  1.1092e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8951,  2.7639,  3.6256,  ..., -2.3691,  3.8723, -0.9521],\n",
            "        [-1.5207,  4.5119,  3.5646,  ..., -1.6295,  2.6435, -0.5223],\n",
            "        [ 1.4173,  4.6054,  3.9826,  ..., -1.6347,  3.7487, -2.2822],\n",
            "        ...,\n",
            "        [ 5.8905,  2.9063,  0.3664,  ..., -0.3345,  2.0113, -3.5998],\n",
            "        [-1.2323,  1.6742, -3.0799,  ...,  4.2674,  2.8540,  0.8647],\n",
            "        [ 0.2441,  3.8900,  0.6718,  ..., -1.2252,  1.2158,  4.4772]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6635, -2.3210, -2.8546,  ...,  3.1894,  0.8528,  3.3057],\n",
            "        [ 4.0830,  2.2901,  5.5505,  ..., -5.2290,  2.5744, -4.5564],\n",
            "        [-0.1391,  1.3306, -2.3061,  ...,  0.0870,  1.0914, -0.5463],\n",
            "        ...,\n",
            "        [ 1.6060,  2.9250,  0.8755,  ...,  0.6036,  1.4398,  4.1240],\n",
            "        [ 1.9937,  1.3442,  0.3080,  ...,  1.9699,  1.1126,  0.6361],\n",
            "        [ 3.9492,  2.8542,  0.4452,  ..., -1.1781,  2.9889, -1.2200]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7515,  2.4393, -0.3092,  ...,  2.0210,  1.3403, -0.7255],\n",
            "        [ 0.5260,  4.3743,  5.8658,  ..., -3.1797,  1.8112, -5.0224],\n",
            "        [ 3.1464,  1.0516,  0.9367,  ..., -1.6812,  4.1000,  1.3084],\n",
            "        ...,\n",
            "        [ 1.9665,  0.7966, -0.1646,  ..., -2.5763,  2.9232, -1.6292],\n",
            "        [-0.2187,  3.0731,  1.5562,  ...,  0.3215,  1.7330,  1.3667],\n",
            "        [-0.1653,  2.8655, -4.2321,  ...,  0.6920, -0.8803,  4.8008]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9314,  3.5604,  1.6628,  ..., -2.1228,  1.8288,  1.5513],\n",
            "        [ 0.0552,  1.9837,  2.0782,  ..., -2.3702,  3.3891, -0.9595],\n",
            "        [ 1.4157,  1.7703,  1.4635,  ..., -3.5151,  3.1762, -0.0791],\n",
            "        ...,\n",
            "        [ 1.6360,  6.5001, -1.4034,  ..., -1.8782, -0.8478,  1.6055],\n",
            "        [ 5.7865,  2.8504,  0.7766,  ..., -1.4918,  2.1004,  0.4703],\n",
            "        [ 2.3536, -1.1921,  1.1818,  ..., -0.1151,  5.0372,  1.0161]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3257e+00,  7.6964e-02, -9.5377e-02,  ...,  2.2028e+00,\n",
            "          3.2959e+00,  4.1891e+00],\n",
            "        [ 4.3930e-01,  3.6950e+00, -1.2472e+00,  ..., -1.4665e-03,\n",
            "          9.5018e-01,  2.3348e+00],\n",
            "        [-1.1287e+00, -2.6243e-01, -9.9891e-01,  ...,  2.1021e+00,\n",
            "          3.7496e+00,  1.3420e+00],\n",
            "        ...,\n",
            "        [ 3.1937e+00,  5.5886e+00,  5.6364e+00,  ..., -3.7530e+00,\n",
            "          2.0746e+00, -5.4217e+00],\n",
            "        [ 2.3021e+00,  4.2006e+00, -6.7018e-01,  ...,  3.1932e+00,\n",
            "          1.1870e+00, -5.4202e-01],\n",
            "        [ 7.1375e-01,  4.1271e+00,  9.9505e-01,  ..., -6.1134e-01,\n",
            "          1.1751e+00, -2.0291e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1435,  4.7524,  6.8932,  ..., -3.4694,  6.3317, -1.5960],\n",
            "        [ 3.4555,  3.4177,  0.4168,  ...,  3.3067,  1.9170, -0.4822],\n",
            "        [-0.5347,  2.5763,  2.5152,  ..., -3.2145,  1.7848, -0.5388],\n",
            "        ...,\n",
            "        [ 1.1911,  4.0993,  0.3174,  ...,  0.2258,  1.2275,  0.6652],\n",
            "        [ 0.0626,  1.2074, -2.0797,  ...,  3.2486,  1.8044,  4.5851],\n",
            "        [ 3.4547,  8.3725,  0.8340,  ..., -1.4130, -0.5317, -2.7398]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1476,  0.8718,  2.9284,  ..., -3.7294,  6.5639, -0.6138],\n",
            "        [ 2.4797,  5.4417, -0.3641,  ...,  5.1020,  2.6626, -0.3402],\n",
            "        [ 2.1434,  1.1872, -0.4091,  ..., -0.4585,  2.8599,  2.4234],\n",
            "        ...,\n",
            "        [-0.0924,  4.4569, -1.2394,  ..., -5.2658,  1.3534,  5.2403],\n",
            "        [ 1.5168,  6.3988,  1.1334,  ..., -1.3472,  0.6833,  0.8408],\n",
            "        [-0.0987,  2.6914,  0.0959,  ..., -1.1539,  1.2136, -0.5835]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3846,  2.0522,  1.7942,  ...,  1.0374,  2.2850, -0.4660],\n",
            "        [ 4.0331,  4.4769,  1.2211,  ..., -2.1582,  1.7453, -1.4236],\n",
            "        [-0.0877, -2.3072, -0.1738,  ..., -0.2402,  2.7798,  4.7651],\n",
            "        ...,\n",
            "        [ 0.9812,  1.8424,  2.7352,  ...,  0.1056,  1.4163, -0.4395],\n",
            "        [ 0.9484,  2.1771,  3.8653,  ..., -4.3150,  3.7030, -0.8473],\n",
            "        [-1.4777,  2.0138, -3.6288,  ...,  2.3004, -1.9688,  1.0011]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5711,  4.7101, -1.5461,  ..., -1.7355,  2.9073,  4.4234],\n",
            "        [ 0.5610,  1.1892, -0.4166,  ...,  0.0276,  1.5869,  0.5272],\n",
            "        [ 1.2964,  3.6597, -0.0683,  ..., -1.4047,  2.3447,  1.4726],\n",
            "        ...,\n",
            "        [ 3.9518,  4.6655,  0.4702,  ..., -0.8765,  2.8558,  2.0182],\n",
            "        [ 4.8883, -1.2632,  2.3725,  ...,  1.7082,  3.5184, -2.0461],\n",
            "        [ 1.4898,  5.1967,  1.0765,  ..., -3.4659,  2.5371,  2.5130]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5624,  3.1641, -0.4123,  ..., -0.1760,  1.1878, -0.4147],\n",
            "        [ 0.0976,  1.6621, -0.3429,  ...,  1.5905,  2.9660,  4.0848],\n",
            "        [ 2.6710,  5.1356, -0.8813,  ...,  4.5285,  2.7931, -0.4044],\n",
            "        ...,\n",
            "        [ 0.0494,  2.5835, -2.0640,  ..., -0.2282,  0.2520,  0.4418],\n",
            "        [ 1.0689,  2.8103,  0.5414,  ...,  0.9301, -0.4545,  3.4872],\n",
            "        [ 2.5325,  2.9257,  4.1362,  ..., -1.3293,  2.7018, -0.7497]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1441e+00,  3.2053e+00,  3.1108e+00,  ..., -2.1816e+00,\n",
            "          1.0089e+00, -1.0863e+00],\n",
            "        [ 3.7796e-01, -1.0906e+00,  8.1623e-01,  ..., -3.7578e+00,\n",
            "          5.3949e+00, -2.8520e+00],\n",
            "        [ 1.0080e+00,  4.3581e+00,  8.8142e-01,  ..., -5.5012e-01,\n",
            "          9.4599e-01,  2.0274e+00],\n",
            "        ...,\n",
            "        [-6.2552e+00, -6.2347e-01,  3.1891e+00,  ...,  4.7234e-03,\n",
            "          5.1370e+00, -1.9473e-01],\n",
            "        [ 2.2804e+00,  3.3927e-01,  3.9160e-01,  ..., -1.9883e+00,\n",
            "          2.1186e+00,  1.4048e+00],\n",
            "        [ 3.0002e+00,  3.5631e+00, -3.1010e-01,  ..., -1.2221e-01,\n",
            "          1.6274e+00, -8.5048e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1327,  3.9299,  2.0061,  ..., -2.4990,  4.2463, -1.1176],\n",
            "        [ 2.0653,  4.4683,  2.0426,  ..., -3.3252,  1.4631,  1.9931],\n",
            "        [ 6.0842,  3.6373,  2.7494,  ..., -1.7340,  2.9659, -0.3607],\n",
            "        ...,\n",
            "        [-1.1749, -0.2862,  0.5406,  ..., -3.2686,  5.7515, -2.9359],\n",
            "        [ 0.6885,  7.8640, -2.6884,  ...,  2.7397, -1.7245, -2.5869],\n",
            "        [ 4.3886,  3.6624, -0.6747,  ..., -0.6265,  1.4882,  0.3345]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4617,  2.8448, -0.1911,  ..., -0.5813,  3.7854,  0.1321],\n",
            "        [ 5.1435,  1.8466,  1.0189,  ...,  0.1763,  3.9053,  1.5007],\n",
            "        [-1.1335,  1.8051,  4.3691,  ..., -4.3572,  4.6932, -2.9986],\n",
            "        ...,\n",
            "        [ 1.8943,  4.7702,  1.4874,  ..., -3.2389,  0.5506, -2.2997],\n",
            "        [-1.7574,  3.6305,  5.3897,  ..., -4.3097,  4.0582, -5.8584],\n",
            "        [ 0.5135,  5.3512,  3.5592,  ..., -2.3992,  3.0130, -0.8258]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2912, -1.7766, -4.3643,  ..., -0.4299,  2.9168, -1.3292],\n",
            "        [ 1.0794, -0.2264,  4.2915,  ..., -3.8812,  5.2125, -1.4704],\n",
            "        [ 4.1278,  5.9460,  1.6522,  ..., -1.9443,  2.4958, -1.0971],\n",
            "        ...,\n",
            "        [ 4.9783,  1.9539,  1.9128,  ..., -3.0862,  0.9815, -1.1066],\n",
            "        [ 1.4809,  3.5118, -0.3110,  ..., -1.2213,  1.9885,  0.2548],\n",
            "        [ 2.0990,  3.3917,  0.5669,  ..., -1.1705,  2.3563,  0.6942]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1390,  3.2555, -3.4322,  ...,  0.5209,  0.6110,  5.7188],\n",
            "        [ 5.8721,  1.7415,  2.1959,  ..., -0.4449,  2.7511, -2.4265],\n",
            "        [ 1.3786, -0.3936,  0.6548,  ..., -2.2696,  5.4433,  0.1640],\n",
            "        ...,\n",
            "        [-0.3413,  1.0410,  1.7237,  ..., -1.9001,  1.3758, -0.2761],\n",
            "        [-0.1397,  2.1694, -0.4754,  ...,  1.9483,  1.0808,  0.8034],\n",
            "        [-0.4377,  2.5717, -2.1560,  ...,  0.9325,  0.4639,  5.1909]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6010,  4.6544,  1.1632,  ..., -1.5978,  1.0664, -1.2005],\n",
            "        [ 1.0249, -0.6231,  2.5004,  ..., -2.6256,  6.0549,  0.3761],\n",
            "        [ 2.3296,  2.6454,  5.3163,  ..., -1.7919,  5.0915,  0.0085],\n",
            "        ...,\n",
            "        [ 2.3146,  4.3906,  3.0044,  ..., -3.0288,  2.8934,  3.1711],\n",
            "        [ 1.2925,  7.0920, -1.4263,  ..., -0.9734, -0.3047, -0.4397],\n",
            "        [ 0.4441, -0.9409,  0.6273,  ...,  1.1566,  5.8933,  3.6567]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8495,  2.8815,  5.6033,  ..., -3.5980,  5.3440, -0.7150],\n",
            "        [ 0.0676,  2.9742,  0.7401,  ...,  1.0171,  1.1658,  3.8433],\n",
            "        [-0.8740,  0.6637, -0.9174,  ...,  1.9010,  0.3291,  0.9295],\n",
            "        ...,\n",
            "        [ 2.2398,  1.4105,  2.3206,  ..., -1.7466,  2.5995, -1.0526],\n",
            "        [ 2.4458,  0.1627, -0.9991,  ..., -1.0785,  2.6099,  2.3734],\n",
            "        [ 1.0654,  4.1923, -0.3763,  ..., -3.8209,  0.4400, -0.2414]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4294,  3.1374,  3.3977,  ..., -0.9426,  3.4821, -1.9514],\n",
            "        [ 4.1677,  3.6517,  0.0998,  ..., -0.2500,  1.1286, -0.3031],\n",
            "        [-0.1659, -2.4611,  0.3801,  ...,  5.2219,  4.6455, -1.2756],\n",
            "        ...,\n",
            "        [ 3.8546,  3.0679, -0.4358,  ...,  0.8340,  1.8253, -0.1343],\n",
            "        [-1.3104,  3.3829, -0.2886,  ..., -0.6796,  2.6256, -0.7608],\n",
            "        [-0.5645,  1.5307, -3.8077,  ...,  3.1535,  1.3270, -1.0658]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5641,  0.9707,  3.4186,  ..., -1.8175,  0.5902,  0.9139],\n",
            "        [ 1.3602,  5.3790,  1.8706,  ..., -1.4471,  1.3567, -0.5120],\n",
            "        [-1.1851,  2.7574,  5.1417,  ..., -0.6875,  6.3136,  0.0693],\n",
            "        ...,\n",
            "        [ 2.9127,  4.8035,  0.5869,  ..., -1.4486,  3.1290, -0.0950],\n",
            "        [ 1.8421,  6.7578,  1.6409,  ..., -1.4398, -0.2309, -0.1334],\n",
            "        [ 1.7519,  5.3019, -0.9094,  ..., -0.1453,  0.4717,  2.4529]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3128,  0.1488,  0.9155,  ..., -0.1174,  0.8775,  2.6001],\n",
            "        [ 0.7152,  2.1913,  2.3543,  ..., -2.7839,  3.2918, -0.5271],\n",
            "        [ 3.8652,  2.0890,  2.6602,  ..., -1.9034,  4.0406, -1.3897],\n",
            "        ...,\n",
            "        [-2.5196, -0.8181,  1.5268,  ..., -0.3103,  3.7089, -4.8030],\n",
            "        [-4.0704, -0.8736, -4.2948,  ...,  2.9677,  3.3882,  2.9424],\n",
            "        [ 0.6399,  5.2240,  0.7978,  ..., -2.7329,  2.0489, -0.7322]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0363e-02,  8.7955e-01,  2.5782e-01,  ...,  7.5939e-01,\n",
            "          3.0026e+00,  2.7139e-01],\n",
            "        [-4.1408e+00,  2.1019e+00,  5.6028e+00,  ..., -2.1983e+00,\n",
            "          6.7234e+00, -4.5789e+00],\n",
            "        [ 2.0610e+00,  5.2981e+00,  2.2642e-02,  ...,  3.4027e+00,\n",
            "          1.5070e+00, -2.5457e-01],\n",
            "        ...,\n",
            "        [-1.6638e-03,  4.4848e+00, -2.5437e+00,  ...,  4.1563e+00,\n",
            "          2.5451e+00,  7.3253e-01],\n",
            "        [ 4.2340e+00,  4.1093e+00, -3.6379e-01,  ...,  4.1384e-01,\n",
            "          5.6861e-01, -2.8598e-01],\n",
            "        [-1.4355e+00,  2.6545e+00, -9.3905e-01,  ...,  3.2212e+00,\n",
            "          2.3118e+00,  1.7844e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8732,  4.7447, -1.3372,  ...,  0.4562, -0.3590,  4.7255],\n",
            "        [ 0.3848,  4.5288,  4.0273,  ..., -4.4617,  2.1266, -3.2093],\n",
            "        [ 0.5460,  4.1547,  3.3907,  ..., -2.8580,  4.2663, -0.3891],\n",
            "        ...,\n",
            "        [ 1.9264,  1.9717,  2.8853,  ..., -1.5145,  5.9044,  0.6280],\n",
            "        [ 0.5305,  2.4221,  2.1938,  ..., -3.5469,  3.6102, -1.2632],\n",
            "        [ 1.0540,  3.6484, -1.5509,  ...,  0.8279, -0.6076,  2.2238]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = SimpleMLP().to(device)\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 3\n",
        "\n",
        "mnist_trainset, _ = get_mnist()\n",
        "mnist_trainloader = DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "optimizer = t.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    pbar = tqdm(mnist_trainloader)\n",
        "\n",
        "    for imgs, labels in pbar:\n",
        "        # Move data to device, perform forward pass\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        logits = model(imgs)\n",
        "\n",
        "        # Calculate loss, perform backward pass\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Update logs & progress bar\n",
        "        loss_list.append(loss.item())\n",
        "        pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VkiH-f3sjBUO",
        "outputId": "1e746aa7-0828-4d6f-e137-f15b761a1261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"be135d5d-47a2-4a84-8044-dc500788f559\" class=\"plotly-graph-div\" style=\"height:525px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"be135d5d-47a2-4a84-8044-dc500788f559\")) {                    Plotly.newPlot(                        \"be135d5d-47a2-4a84-8044-dc500788f559\",                        [{\"hovertemplate\":\"Examples seen=%{x}\\u003cbr\\u003eCross entropy loss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,127.11864406779661,254.23728813559322,381.35593220338984,508.47457627118644,635.5932203389831,762.7118644067797,889.8305084745763,1016.9491525423729,1144.0677966101696,1271.1864406779662,1398.3050847457628,1525.4237288135594,1652.542372881356,1779.6610169491526,1906.7796610169491,2033.8983050847457,2161.0169491525426,2288.135593220339,2415.2542372881358,2542.3728813559323,2669.491525423729,2796.6101694915255,2923.728813559322,3050.8474576271187,3177.9661016949153,3305.084745762712,3432.2033898305085,3559.322033898305,3686.4406779661017,3813.5593220338983,3940.677966101695,4067.7966101694915,4194.9152542372885,4322.033898305085,4449.152542372882,4576.271186440678,4703.389830508475,4830.5084745762715,4957.627118644068,5084.745762711865,5211.864406779661,5338.983050847458,5466.1016949152545,5593.220338983051,5720.338983050848,5847.457627118644,5974.576271186441,6101.6949152542375,6228.813559322034,6355.932203389831,6483.050847457627,6610.169491525424,6737.28813559322,6864.406779661017,6991.525423728814,7118.64406779661,7245.762711864407,7372.881355932203,7500.0,7627.118644067797,7754.237288135593,7881.35593220339,8008.474576271186,8135.593220338983,8262.71186440678,8389.830508474577,8516.949152542373,8644.06779661017,8771.186440677966,8898.305084745763,9025.42372881356,9152.542372881357,9279.661016949152,9406.77966101695,9533.898305084746,9661.016949152543,9788.135593220339,9915.254237288136,10042.372881355932,10169.49152542373,10296.610169491525,10423.728813559323,10550.847457627118,10677.966101694916,10805.084745762711,10932.203389830509,11059.322033898305,11186.440677966102,11313.559322033898,11440.677966101695,11567.796610169491,11694.915254237289,11822.033898305084,11949.152542372882,12076.271186440677,12203.389830508475,12330.50847457627,12457.627118644068,12584.745762711864,12711.864406779661,12838.983050847457,12966.101694915254,13093.22033898305,13220.338983050848,13347.457627118643,13474.57627118644,13601.694915254237,13728.813559322034,13855.93220338983,13983.050847457627,14110.169491525423,14237.28813559322,14364.406779661016,14491.525423728814,14618.64406779661,14745.762711864407,14872.881355932202,15000.0,15127.118644067796,15254.237288135593,15381.355932203389,15508.474576271186,15635.593220338982,15762.71186440678,15889.830508474575,16016.949152542373,16144.067796610168,16271.186440677966,16398.305084745763,16525.42372881356,16652.542372881355,16779.661016949154,16906.77966101695,17033.898305084746,17161.01694915254,17288.13559322034,17415.254237288136,17542.372881355932,17669.491525423728,17796.610169491527,17923.728813559323,18050.84745762712,18177.966101694914,18305.084745762713,18432.20338983051,18559.322033898305,18686.4406779661,18813.5593220339,18940.677966101695,19067.79661016949,19194.915254237287,19322.033898305086,19449.15254237288,19576.271186440677,19703.389830508473,19830.508474576272,19957.627118644068,20084.745762711864,20211.86440677966,20338.98305084746,20466.101694915254,20593.22033898305,20720.338983050846,20847.457627118645,20974.57627118644,21101.694915254237,21228.813559322032,21355.93220338983,21483.050847457627,21610.169491525423,21737.28813559322,21864.406779661018,21991.525423728814,22118.64406779661,22245.762711864405,22372.881355932204,22500.0,22627.118644067796,22754.23728813559,22881.35593220339,23008.474576271186,23135.593220338982,23262.711864406778,23389.830508474577,23516.949152542373,23644.06779661017,23771.186440677964,23898.305084745763,24025.42372881356,24152.542372881355,24279.66101694915,24406.77966101695,24533.898305084746,24661.01694915254,24788.13559322034,24915.254237288136,25042.372881355932,25169.491525423728,25296.610169491527,25423.728813559323,25550.84745762712,25677.966101694914,25805.084745762713,25932.20338983051,26059.322033898305,26186.4406779661,26313.5593220339,26440.677966101695,26567.79661016949,26694.915254237287,26822.033898305086,26949.15254237288,27076.271186440677,27203.389830508473,27330.508474576272,27457.627118644068,27584.745762711864,27711.86440677966,27838.98305084746,27966.101694915254,28093.22033898305,28220.338983050846,28347.457627118645,28474.57627118644,28601.694915254237,28728.813559322032,28855.93220338983,28983.050847457627,29110.169491525423,29237.28813559322,29364.406779661018,29491.525423728814,29618.64406779661,29745.762711864405,29872.881355932204,30000.0],\"xaxis\":\"x\",\"y\":[3.139275074005127,2.700077533721924,2.231292724609375,1.9897119998931885,1.9314875602722168,1.6121081113815308,1.4073071479797363,1.3064149618148804,1.225632905960083,1.1001051664352417,0.9204452633857727,0.8654161095619202,0.8498693108558655,1.0997865200042725,0.6395558714866638,0.7210549116134644,0.8098824620246887,0.7798863053321838,0.6228044629096985,0.5997288227081299,0.6102089881896973,0.6807070970535278,0.4424653649330139,0.4583073556423187,0.40705612301826477,0.5587802529335022,0.4999381899833679,0.49788177013397217,0.5056505799293518,0.4696795642375946,0.43200284242630005,0.5598903894424438,0.49328064918518066,0.6545947790145874,0.4370099604129791,0.5143271684646606,0.437704473733902,0.423370361328125,0.48608312010765076,0.4205201268196106,0.4300767183303833,0.5305047631263733,0.4063243269920349,0.45874473452568054,0.3254154920578003,0.37073108553886414,0.22458399832248688,0.38098496198654175,0.28450658917427063,0.2873058319091797,0.31784963607788086,0.37793129682540894,0.33327561616897583,0.29731255769729614,0.3382469117641449,0.3248558044433594,0.46073412895202637,0.36087945103645325,0.4624461531639099,0.43986815214157104,0.3422057032585144,0.40408843755722046,0.3140139579772949,0.31148871779441833,0.2724732756614685,0.24288979172706604,0.31866559386253357,0.3057934641838074,0.3281542956829071,0.4227842390537262,0.27843421697616577,0.40106335282325745,0.33764535188674927,0.3639274537563324,0.3431922197341919,0.2771231532096863,0.4026981592178345,0.2880851924419403,0.5517910718917847,0.2010493129491806,0.27056869864463806,0.3290416896343231,0.5040509104728699,0.25730159878730774,0.42618075013160706,0.36292243003845215,0.2719874083995819,0.1773943156003952,0.2150745689868927,0.29058581590652466,0.2553158402442932,0.29397374391555786,0.2919554114341736,0.3257324993610382,0.21894504129886627,0.30110880732536316,0.20183303952217102,0.269334614276886,0.32775336503982544,0.26290157437324524,0.32685744762420654,0.1857226938009262,0.2828311622142792,0.20587021112442017,0.25780433416366577,0.2521316707134247,0.23074187338352203,0.24723252654075623,0.24635934829711914,0.2599676847457886,0.2740926742553711,0.25919437408447266,0.18741686642169952,0.15913432836532593,0.18664595484733582,0.31345874071121216,0.3144782781600952,0.2977369725704193,0.23833568394184113,0.18895551562309265,0.2145986706018448,0.4349868595600128,0.389273464679718,0.23204302787780762,0.34158584475517273,0.3827540874481201,0.23825931549072266,0.3250773847103119,0.2011164277791977,0.2624116837978363,0.2375931739807129,0.21024975180625916,0.24564966559410095,0.18542402982711792,0.18152739107608795,0.274484246969223,0.2113891988992691,0.2569754123687744,0.20657341182231903,0.27615487575531006,0.2863907516002655,0.23514768481254578,0.2411421686410904,0.30092015862464905,0.25968700647354126,0.21566256880760193,0.23712672293186188,0.1687757521867752,0.2226349413394928,0.23873090744018555,0.3428128659725189,0.3197086453437805,0.22421985864639282,0.3056628108024597,0.21910199522972107,0.30441874265670776,0.16520905494689941,0.13816964626312256,0.2672555148601532,0.24345307052135468,0.2651646137237549,0.13984866440296173,0.3211420774459839,0.205362930893898,0.20202945172786713,0.2006988674402237,0.1344156712293625,0.12831008434295654,0.19283080101013184,0.16454485058784485,0.17899879813194275,0.14690057933330536,0.16186656057834625,0.2125488817691803,0.17843525111675262,0.14729537069797516,0.10479151457548141,0.20658287405967712,0.19127804040908813,0.2721300423145294,0.20102888345718384,0.2079666554927826,0.16344918310642242,0.11073436588048935,0.15742436051368713,0.15232467651367188,0.3111593425273895,0.1662798821926117,0.16503793001174927,0.251517653465271,0.15810421109199524,0.2302849292755127,0.10193038731813431,0.21127276122570038,0.15070602297782898,0.1620091199874878,0.1246422529220581,0.18038859963417053,0.26667940616607666,0.21069759130477905,0.14432044327259064,0.1287655234336853,0.1824546903371811,0.10712922364473343,0.19014358520507812,0.28023597598075867,0.20453087985515594,0.15283088386058807,0.21772818267345428,0.20485815405845642,0.06295472383499146,0.2539428174495697,0.1463601440191269,0.11861830949783325,0.2466813623905182,0.2056533396244049,0.153836190700531,0.34742051362991333,0.24501273036003113,0.27324312925338745,0.21587811410427094,0.15736716985702515,0.2150869518518448,0.17754364013671875,0.3046931028366089,0.1978454291820526,0.20136630535125732,0.14257845282554626,0.19362887740135193,0.19539110362529755,0.1765628159046173,0.2599892020225525,0.19643059372901917,0.1417771577835083,0.14851322770118713,0.22466738522052765,0.3651037812232971],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Examples seen\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Cross entropy loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"SimpleMLP training on MNIST\"},\"width\":700,\"hovermode\":\"x unified\"},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('be135d5d-47a2-4a84-8044-dc500788f559');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "line(\n",
        "    loss_list,\n",
        "    x_max=epochs * len(mnist_trainset),\n",
        "    labels={\"x\": \"Examples seen\", \"y\": \"Cross entropy loss\"},\n",
        "    title=\"SimpleMLP training on MNIST\",\n",
        "    width=700,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViY0EL5jjBUO"
      },
      "source": [
        "Let's break down the important parts of this code.\n",
        "\n",
        "The batch size is the number of samples in each batch (i.e. the number of samples we feed into the model at once). While training our model, we differentiate with respect to the average loss over all samples in the batch (so a smaller batch usually means the loss is more noisy). However, if you're working with large models, then often having a batch size too large will result in a memory error. This will be relevant for models later on in the course, but for now we're working with very small models so this isn't an issue.\n",
        "\n",
        "Next, we get our training set, via the helper function `get_mnist`. This helper function used `torchvision.datasets.MNIST` to load in data, and then (optionally) the `torch.utils.data.Subset` function to return a subset of this data. Don't worry about the details of this function, it's not the kind of thing you'll need to know by heart.\n",
        "\n",
        "We then define our optimizer, using `torch.optim.Adam`. The `torch.optim` module gives a wide variety of modules, such as Adam, SGD, and RMSProp. Adam is generally the most popular and seen as the most effective in the majority of cases. We'll discuss optimizers in more detail tomorrow, but for now it's enough to understand that the optimizer calculates the amount to update parameters by (as a function of those parameters' gradients, and sometimes other inputs), and performs this update step. The first argument passed to our optimizer is the parameters of our model (because these are the values that will be updated via gradient descent), and you can also pass keyword arguments to the optimizer which change its behaviour (e.g. the learning rate).\n",
        "\n",
        "Lastly, we have the actual training loop. We iterate through our training data, and for each batch we:\n",
        "\n",
        "1. Evaluate our model on the batch of data, to get the logits for our class predictions,\n",
        "2. Calculate the loss between our logits and the true class labels,\n",
        "3. Backpropagate the loss through our model (this step accumulates gradients in our model parameters),\n",
        "4. Step our optimizer, which is what actually updates the model parameters,\n",
        "5. Zero the gradients of our optimizer, ready for the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUesBrjkjBUO"
      },
      "source": [
        "### Cross entropy loss\n",
        "\n",
        "The formula for cross entropy loss over a batch of size $N$ is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "l &= \\frac{1}{N} \\sum_{n=1}^{N} l_n \\\\\n",
        "l_n &=-\\log p_{n, y_{n}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $p_{n, c}$ is the probability the model assigns to class $c$ for sample $n$, and $y_{n}$ is the true label for this sample.\n",
        "\n",
        "<details>\n",
        "<summary>See this dropdown, if you're still confused about this formula, and how this relates to the information-theoretic general formula for cross entropy.</summary>\n",
        "\n",
        "The cross entropy of a distribution $p$ relate to a distribution $q$ is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "H(q, p) &= -\\sum_{n} q(n) \\log p(n)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "In our case, $q$ is the true distribution (i.e. the one-hot encoded labels, which equals one for $n = y_n$, zero otherwise), and $p$ is our model's output. With these subsitutions, this formula becomes equivalent to the formula for $l$ given above.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>See this dropdown, if you're confused about how this is the same as the <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\">PyTorch definition</a>.</summary>\n",
        "\n",
        "The PyTorch definition of cross entropy loss is:\n",
        "\n",
        "$$\n",
        "\\ell(x, y)=\\frac{1}{N}\\sum_{n=1}^{N} l_n, \\quad l_n=-\\sum_{c=1}^C w_c \\log \\frac{\\exp \\left(x_{n, c}\\right)}{\\sum_{i=1}^C \\exp \\left(x_{n, i}\\right)} y_{n, c}\n",
        "$$\n",
        "\n",
        "$w_c$ are the weights (which all equal one by default), $p_{n, c} = \\frac{\\exp \\left(x_{n, c}\\right)}{\\sum_{i=1}^C \\exp \\left(x_{n, i}\\right)}$ are the probabilities, and $y_{n, c}$ are the true labels (which are one-hot encoded, i.e. their value is one at the correct label $c$ and zero everywhere else). With this, the formula for $l_n$ reduces to the one we see above (i.e. the mean of the negative log probabilities).\n",
        "\n",
        "</details>\n",
        "\n",
        "The function `torch.functional.cross_entropy` expects the **unnormalized logits** as its first input, rather than probabilities. We get probabilities from logits by applying the softmax function:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p_{n, c} &= \\frac{\\exp(x_{n, c})}{\\sum_{c'=1}^{C} \\exp(x_{n, c'})}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $x_{n, c}$ is the model's output for class $c$ and sample $n$, and $C$ is the number of classes (in the case of MNIST, $C = 10$).\n",
        "\n",
        "Some terminology notes:\n",
        "\n",
        "* When we say **logits**, we mean the output of the model before applying softmax. We can uniquely define a distribution with a set of logits, just like we can define a distribution with a set of probabilities (and sometimes it's easier to think of a distribution in terms of logits, as we'll see later in the course).\n",
        "\n",
        "* When we say **unnormalized**, we mean the denominator term $\\sum_{c'} \\exp(x_{n, c'})$ isn't necessarily equal to 1. We can add a constant value onto all the logits which makes this term 1 without changing any of the actual probabilities, then we have the relation $p_{n, c} = \\exp(-l_{n, c})$. Here, we call $-l_{n, c}$ the **log probabilities** (or log probs), since $-l_{n, c} = \\log p_{n, c}$.\n",
        "\n",
        "If you're interested in the intuition behind cross entropy as a loss function, see [this post on KL divergence](https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence) (note that KL divergence and cross entropy differ by an amount which is independent of our model's predictions, so minimizing cross entropy is equivalent to minimizing KL divergence). Also see these two videos:\n",
        "\n",
        "* [Intuitively Understanding the Cross Entropy Loss](https://www.youtube.com/watch?v=Pwgpl9mKars&amp;ab_channel=AdianLiusie)\n",
        "* [Intuitively Understanding the KL Divergence](https://www.youtube.com/watch?v=SxGYPqCgJWM&amp;ab_channel=AdianLiusie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nld1gt2XjBUO"
      },
      "source": [
        "### Aside - `dataclasses`\n",
        "\n",
        "Sometimes, when we have a lot of different input parameters to our model, it can be helpful to use dataclasses to keep track of them all. Dataclasses are a special kind of class which come with built-in methods for initialising and printing (i.e. no need to define an `__init__` or `__repr__`). Another advantage of using them is autocompletion: when you type in `args.` in VSCode, you'll get a dropdown of all your different dataclass attributes, which can be useful when you've forgotten what you called a variable!\n",
        "\n",
        "Here's an example of how we might rewrite our training code above using dataclasses. We've wrapped all the training code inside a single argument called `train`, which takes a `SimpleMLPTrainingArgs` object as its only argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Cffn85qGjBUO",
        "outputId": "12552a9f-d63d-404f-9663-56419e14176c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5b38b3fae2f54652a7c703f49470a8fa",
            "0f535714ebb9464d9cc6990f0c60d238",
            "5a9c5458c7be4ce28b8eec194f2966d5",
            "2d00aa6729d143afbdf074590cca9848",
            "97f5ebf3cc414449bb5f858d282b2984",
            "591dae181ebb46459f927b7997cdfcff",
            "63d275a5af9c4c288381bd47da9b407e",
            "6ea5e11fabad4aacb6071b487459237f",
            "12eabe16d264417aa5d70fd1bf8ac5aa",
            "e6f27f3907624673a54bf7f19049efd8",
            "c515d6ca91fa4a65a1a4a5b8a623eb40",
            "2debff0803204027bff3c57eb38d8f6d",
            "79ca56223d9d4eaba484a80673038b42",
            "fa88248ca696491ba23cdba48139a251",
            "8f2448256cfd491ebc28784b40f06866",
            "5144345cbf15422d86d321e9dee6c4e1",
            "78965ab5dade4ee7adab76a9434da30c",
            "570da9e26b2b495a9c7730bdc51421e3",
            "e0810ab1db0a44d1b2376e2cb5761dcb",
            "de5027064b704c01adb1971603793531",
            "4db3f3aca813405686a5b788a9025620",
            "2ff76fe9988a4bb4ae448e4f150f3048",
            "9654d83d4e6641f9b701e26deedc49e7",
            "134a1d2cc29c4c8b92ef7d7a4baaf8f6",
            "5d089a36f60f406faa8319d17d334451",
            "f9840bf9ea5e4735b1368d7527f8ac6a",
            "525ed5c645a84937bb6fdf74f0b46393",
            "b137652c8626431cacf32b8aedf11b5a",
            "e7a1dc53602b4d3fbcd4947d83308677",
            "de4fee3f17874ff1850dcca4d9ef060d",
            "1f4de19481a148f984a2fa89d4b70603",
            "6e9f53a627f8482db87b132fd0efcb3c",
            "ec445910df0d441689f36d6a244fbd11"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b38b3fae2f54652a7c703f49470a8fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.8350,  0.1506,  1.0938,  ...,  0.6183, -0.8396, -0.0046],\n",
            "        [ 0.3980, -2.1863,  2.7754,  ...,  0.6361,  2.8115, -0.4818],\n",
            "        [ 2.2658, -2.1520,  0.0188,  ...,  0.5398,  0.5079, -0.6481],\n",
            "        ...,\n",
            "        [ 3.2682, -1.3462, -0.8363,  ..., -0.0532,  1.1128, -1.8793],\n",
            "        [ 1.1440, -0.5841,  1.1871,  ...,  0.8640, -0.8669,  0.2710],\n",
            "        [-0.6671, -0.4363,  0.1174,  ..., -1.5950, -1.9801,  0.8817]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3076, -1.2863,  0.6357,  ..., -0.8748, -0.5686, -0.7816],\n",
            "        [ 0.8038, -1.6776, -1.1882,  ...,  2.4414, -0.2782, -0.7636],\n",
            "        [ 1.9499, -0.4254,  0.0875,  ..., -2.2451,  4.2296,  0.1748],\n",
            "        ...,\n",
            "        [ 0.2044, -2.3812,  1.5068,  ..., -0.8221,  2.0331, -1.6366],\n",
            "        [-1.9444, -1.0380,  0.2956,  ...,  2.0024, -1.2434,  0.2800],\n",
            "        [-0.5677,  1.1664, -0.1440,  ..., -0.1914,  1.9865,  0.4540]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3011e+00, -1.2866e+00, -4.4041e-01,  ..., -2.4595e+00,\n",
            "          1.3246e+00, -2.6336e-01],\n",
            "        [-8.8696e-01, -2.2070e+00,  2.3708e-01,  ..., -5.8005e-01,\n",
            "          4.0787e-01, -4.2390e-01],\n",
            "        [ 1.7554e+00, -1.6297e+00,  8.1354e-01,  ..., -2.6198e-04,\n",
            "          3.0686e+00,  9.6534e-01],\n",
            "        ...,\n",
            "        [-7.6035e-01, -2.4832e+00,  1.3034e+00,  ..., -3.4043e-01,\n",
            "          1.9323e+00, -1.0034e+00],\n",
            "        [-2.1853e+00, -2.2914e+00,  2.1590e-01,  ..., -1.4177e+00,\n",
            "         -1.0016e+00,  4.0717e-01],\n",
            "        [ 1.5135e+00, -1.3855e+00, -2.3231e-02,  ..., -1.3100e+00,\n",
            "          3.7450e+00,  8.6561e-02]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7007, -1.9139,  1.5145,  ...,  0.6857, -0.8100, -0.4204],\n",
            "        [ 1.1075, -1.9703,  2.4308,  ..., -1.0687,  1.8906, -1.8093],\n",
            "        [-0.1292, -0.1325, -0.6043,  ..., -0.8011,  0.4610, -0.5722],\n",
            "        ...,\n",
            "        [ 0.4991, -1.2438,  2.3047,  ..., -1.5130,  1.5581, -1.0135],\n",
            "        [ 2.0692,  1.9890, -0.8188,  ..., -0.1234,  4.8377, -0.4620],\n",
            "        [-0.0930,  0.4522, -0.2931,  ...,  1.1604,  2.1132, -0.5937]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1555,  0.0966,  1.8960,  ..., -1.4360, -0.5557, -0.6349],\n",
            "        [-0.0783, -1.4420,  2.4784,  ..., -0.1173, -0.3399, -0.8389],\n",
            "        [-1.6882, -0.4253,  2.0670,  ..., -0.5755,  3.3519, -1.4968],\n",
            "        ...,\n",
            "        [ 0.1994, -3.0098, -1.9540,  ...,  0.5082,  0.2844, -0.8466],\n",
            "        [ 1.8544,  0.2694,  0.5465,  ...,  1.9718,  1.1299, -0.1936],\n",
            "        [ 0.7126, -1.4836,  2.7953,  ..., -2.4217,  0.6623, -1.2354]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5849, -0.9273,  0.5345,  ..., -0.5042, -0.6012, -1.4661],\n",
            "        [ 1.5360, -3.1496, -0.7198,  ...,  0.6581,  0.0964, -3.0590],\n",
            "        [-0.8788, -1.2696,  2.6238,  ..., -2.4085,  3.4302, -0.6610],\n",
            "        ...,\n",
            "        [ 0.4294, -1.7293,  0.9380,  ..., -2.3836,  1.7406, -0.2090],\n",
            "        [ 0.0508, -1.1412,  0.8465,  ..., -0.1409, -0.3984, -1.8861],\n",
            "        [-0.9980, -2.9502,  2.2381,  ..., -1.8388,  1.8161, -1.4194]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1173, -3.1244, -0.3131,  ...,  1.0106,  0.9486, -1.9292],\n",
            "        [ 0.4146, -1.2925,  1.4727,  ..., -0.8164,  0.2650, -1.6340],\n",
            "        [-0.3938, -0.5926,  0.8737,  ..., -3.9263,  3.4086, -1.1746],\n",
            "        ...,\n",
            "        [-2.1080, -0.9623,  1.9698,  ...,  0.1571,  0.5382, -1.0432],\n",
            "        [-1.5564, -2.1167,  0.8392,  ..., -0.1296, -0.8770, -1.6963],\n",
            "        [-0.4494, -0.8152, -0.8946,  ..., -0.5658,  0.1215, -1.8797]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0654e+00, -2.1652e-01,  2.9311e+00,  ..., -9.9956e-01,\n",
            "          7.1252e-02, -9.5191e-01],\n",
            "        [-7.8608e-01, -2.2724e+00,  6.4275e-01,  ...,  4.0244e-01,\n",
            "          1.6451e+00, -1.7529e+00],\n",
            "        [-9.6243e-01, -1.1869e+00,  1.3232e+00,  ..., -7.5213e-01,\n",
            "          9.2574e-01, -9.7206e-01],\n",
            "        ...,\n",
            "        [-5.3166e-01, -3.4381e+00,  9.0907e-01,  ..., -2.6783e+00,\n",
            "          1.6927e+00, -3.6297e+00],\n",
            "        [ 2.0255e-01, -1.5972e+00, -8.5041e-01,  ..., -5.7908e-02,\n",
            "          6.9847e-01, -1.6861e+00],\n",
            "        [-6.9242e-01, -4.5116e-01,  2.0876e-01,  ...,  4.6479e-01,\n",
            "          1.9441e-01, -1.9936e-03]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1607, -3.6542, -0.4110,  ..., -0.6867, -0.4376, -3.0812],\n",
            "        [-1.6207, -1.3794,  1.8004,  ...,  0.0476,  2.4647, -1.0315],\n",
            "        [-1.7245, -1.7624,  2.9641,  ...,  0.4266, -1.8148, -2.7834],\n",
            "        ...,\n",
            "        [-1.5515, -1.4322,  1.7684,  ..., -0.7384,  0.3204, -1.7603],\n",
            "        [ 1.6147, -3.3020,  0.8317,  ...,  1.2586,  3.3878, -1.6988],\n",
            "        [-0.0696, -0.2023, -0.6871,  ..., -1.6653,  1.6012,  0.7552]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4466,  0.8776,  3.7620,  ..., -0.0155,  1.6867, -0.9516],\n",
            "        [-0.4521, -0.4527,  3.7829,  ..., -0.9222,  0.2768, -1.2940],\n",
            "        [-0.8310, -1.3716,  2.7500,  ..., -2.6014,  2.1925, -2.7429],\n",
            "        ...,\n",
            "        [ 0.6760,  0.9972, -1.4964,  ...,  0.3360,  3.6306, -3.9430],\n",
            "        [-1.8473, -0.3047,  3.2261,  ..., -0.9696,  1.2873, -2.2906],\n",
            "        [-1.0491,  0.6994,  2.0121,  ..., -1.4698, -1.5441, -1.0459]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3219, -3.7465,  0.6678,  ...,  3.4248,  3.8327, -4.6653],\n",
            "        [-0.3772, -1.6120,  4.3799,  ..., -2.0470,  1.3979, -2.8087],\n",
            "        [-1.1807, -3.5382,  0.3819,  ...,  0.0644,  1.5015, -2.4007],\n",
            "        ...,\n",
            "        [-0.2960, -1.6643,  0.7324,  ...,  0.1047,  2.0744, -2.5560],\n",
            "        [-2.7336, -2.0554,  2.8070,  ..., -1.8175,  0.6365, -0.9338],\n",
            "        [-1.5781, -1.7485,  2.3104,  ..., -2.3256,  0.8683, -2.6703]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3876, -0.6028,  0.8814,  ...,  2.4583,  3.8764, -1.4041],\n",
            "        [-1.3665,  0.0528,  3.1253,  ..., -0.4757,  0.5366, -0.2391],\n",
            "        [-1.7638, -2.8350,  1.0584,  ..., -1.2776,  0.9945, -2.4336],\n",
            "        ...,\n",
            "        [ 0.3539, -0.8993, -0.2930,  ..., -2.0701,  2.9436, -0.1816],\n",
            "        [-1.1333, -3.0670,  3.1285,  ..., -0.8658,  1.1839, -1.4226],\n",
            "        [-0.0743, -0.1014, -0.7082,  ...,  0.5866,  0.8185, -0.0519]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1287, -1.1499,  0.7111,  ..., -1.6266,  1.0566, -2.2028],\n",
            "        [-0.7233, -0.1020,  2.4313,  ..., -3.4902,  3.3062, -4.2394],\n",
            "        [-0.8699, -2.0470,  1.0809,  ..., -2.4420,  1.3336, -2.1772],\n",
            "        ...,\n",
            "        [-2.0139, -1.1135,  2.0929,  ..., -2.5764,  2.1401, -2.3629],\n",
            "        [-1.3567, -0.3355,  0.5156,  ..., -2.9462, -0.9908, -0.7270],\n",
            "        [ 0.5875, -0.9447, -0.8332,  ...,  1.7249,  0.3694, -4.2737]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7709e+00, -1.0696e-01,  2.2826e+00,  ..., -1.4003e+00,\n",
            "         -1.1096e+00, -6.5233e-01],\n",
            "        [-1.7120e+00, -3.2785e+00,  2.9737e+00,  ...,  9.3912e-03,\n",
            "          2.0159e+00, -2.2684e+00],\n",
            "        [-4.0357e-01, -9.1314e-01,  2.2007e+00,  ...,  4.2704e-03,\n",
            "         -3.1673e-01, -3.2044e+00],\n",
            "        ...,\n",
            "        [-2.6305e+00, -1.7750e+00,  2.4698e+00,  ..., -1.1061e+00,\n",
            "          4.1052e+00, -4.9597e+00],\n",
            "        [-7.8183e-02,  5.1407e-01,  1.4410e+00,  ..., -4.0522e+00,\n",
            "          5.6312e+00, -1.3982e+00],\n",
            "        [-1.1932e+00, -1.0256e+00, -1.4446e+00,  ...,  4.8499e-01,\n",
            "          2.7822e+00, -3.5141e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3046, -1.0347, -1.0284,  ...,  0.7421,  2.3839, -1.6045],\n",
            "        [-0.7519, -0.3324,  2.6257,  ..., -2.3285,  0.5051, -2.0121],\n",
            "        [-1.1493, -1.2790,  1.4930,  ..., -2.8899,  2.7223, -2.2062],\n",
            "        ...,\n",
            "        [ 1.1324, -1.8610, -1.0386,  ...,  0.1170,  0.1397, -3.4574],\n",
            "        [ 2.5663, -0.1491, -0.2803,  ..., -0.5369,  5.9549, -0.1484],\n",
            "        [ 0.4906, -1.7805,  0.7664,  ..., -0.5975,  3.4795, -5.4055]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7229e+00, -9.4189e-01,  2.1137e+00,  ..., -4.7498e-02,\n",
            "         -7.6642e-01, -2.8549e+00],\n",
            "        [-3.7288e-03,  9.0752e-01,  4.9564e-01,  ..., -1.2780e+00,\n",
            "          2.9242e+00, -1.2497e+00],\n",
            "        [-2.2296e+00, -2.9483e-01,  2.4824e+00,  ...,  1.8610e+00,\n",
            "         -8.3084e-01, -6.3705e-01],\n",
            "        ...,\n",
            "        [-1.4277e+00, -2.5313e+00,  1.0799e+00,  ..., -1.9902e+00,\n",
            "          2.4838e+00, -3.9219e+00],\n",
            "        [-1.4343e+00, -2.1519e+00,  2.7595e+00,  ..., -1.4646e+00,\n",
            "          1.7450e+00, -2.3787e+00],\n",
            "        [-2.5511e+00, -2.4840e+00,  1.0128e+00,  ...,  1.1068e+00,\n",
            "          8.7230e-01, -3.0840e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2900, -1.5666,  2.4693,  ..., -0.1777, -0.3817, -1.1981],\n",
            "        [-3.2267, -2.2716, -0.1397,  ..., -0.2004, -1.3467, -2.9866],\n",
            "        [-0.0384, -0.9052, -0.6647,  ..., -1.3696,  1.4676, -2.5582],\n",
            "        ...,\n",
            "        [-0.6550, -1.8584,  2.4244,  ..., -2.7417,  3.4300, -0.1830],\n",
            "        [-0.4346, -2.9363, -1.3606,  ...,  4.9385,  2.6122, -3.2998],\n",
            "        [-2.5051, -0.8954,  3.4926,  ..., -2.4307,  3.0883, -3.4848]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9138e+00, -3.4821e+00,  2.1200e+00,  ..., -2.6581e+00,\n",
            "          1.1409e-01, -2.8911e+00],\n",
            "        [-1.2182e+00, -1.8192e+00,  2.7572e+00,  ...,  3.4702e-03,\n",
            "         -9.0081e-01, -2.3054e+00],\n",
            "        [-1.6999e+00, -1.7226e+00,  1.6776e+00,  ..., -1.6348e+00,\n",
            "          1.6291e+00, -2.6355e+00],\n",
            "        ...,\n",
            "        [-9.5836e-01, -1.1406e+00,  4.1168e+00,  ..., -1.7017e+00,\n",
            "          1.1787e+00, -2.8934e+00],\n",
            "        [-7.8435e-01,  3.7233e-01, -4.0086e-01,  ..., -1.9327e+00,\n",
            "          3.0995e+00, -9.7245e-01],\n",
            "        [ 5.0696e-01,  3.8816e-01, -1.2991e+00,  ..., -5.4494e-01,\n",
            "         -2.9797e-01, -1.9627e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7519, -1.8975,  1.3656,  ...,  0.9369,  5.2440, -3.6293],\n",
            "        [-2.2828, -0.4527,  1.4505,  ..., -1.8149,  0.6154, -1.7976],\n",
            "        [-1.9263, -3.8361,  0.8474,  ..., -0.5538,  4.0038, -5.7604],\n",
            "        ...,\n",
            "        [ 0.5489,  0.0321,  1.5508,  ..., -1.2672,  2.5909, -2.6444],\n",
            "        [ 1.5316, -1.9926, -0.9968,  ..., -1.4976,  5.7352, -3.9466],\n",
            "        [-0.7834, -2.1560,  0.9858,  ..., -1.4362,  2.5562, -3.0835]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1187, -2.0291,  3.1217,  ..., -1.6257,  3.0619, -3.7836],\n",
            "        [-2.1995, -1.7431,  2.5056,  ..., -0.8905,  0.4057, -2.3677],\n",
            "        [-1.6186,  0.6121,  3.0684,  ..., -1.2194, -0.4305, -2.6815],\n",
            "        ...,\n",
            "        [ 0.8644,  1.0306,  0.2918,  ..., -1.4216,  2.4454, -0.5850],\n",
            "        [-0.2076, -0.6316, -1.3270,  ...,  0.9905,  1.8287, -2.4390],\n",
            "        [-0.6264, -2.1854,  3.3873,  ...,  0.0607,  0.9906, -2.2797]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2023e+00, -3.4283e+00,  3.3769e+00,  ...,  8.2311e-01,\n",
            "          5.4984e-01, -4.2024e+00],\n",
            "        [-4.2479e-01, -1.5160e+00,  4.1614e+00,  ..., -1.2601e+00,\n",
            "          4.1325e+00, -3.8180e+00],\n",
            "        [-5.7007e-01, -7.3464e-01,  3.8243e+00,  ..., -1.0705e+00,\n",
            "          5.8872e+00, -3.4013e+00],\n",
            "        ...,\n",
            "        [-1.0935e+00, -8.6071e-01,  8.0977e-01,  ..., -9.3031e-01,\n",
            "          2.9630e+00, -9.0972e-01],\n",
            "        [-6.6233e-01, -6.8001e-01,  3.5200e-01,  ..., -4.3234e-03,\n",
            "          2.2971e+00, -2.7363e+00],\n",
            "        [-1.8817e-01, -2.1619e+00,  3.7502e+00,  ..., -1.1625e+00,\n",
            "          2.2534e+00, -2.8423e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3980, -0.5029,  0.0832,  ...,  0.3985,  1.1380, -2.6484],\n",
            "        [-0.7122, -0.8552,  3.0932,  ...,  0.6993, -0.8100, -2.2917],\n",
            "        [-1.8990, -3.5372, -3.5386,  ...,  4.1738,  4.1564, -4.4955],\n",
            "        ...,\n",
            "        [-2.0229, -2.3236,  1.4969,  ..., -0.9120, -0.7307, -1.8510],\n",
            "        [-0.7273, -1.1200,  2.1694,  ..., -0.1816,  3.7524, -2.8568],\n",
            "        [-1.3451, -1.1776,  1.4431,  ...,  0.3531,  1.9173, -3.1426]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8119, -0.7083,  1.3737,  ..., -1.2725,  3.4316, -2.6639],\n",
            "        [-3.0924, -1.5490,  1.0623,  ..., -0.9963,  3.5085, -0.6466],\n",
            "        [-2.6413, -1.6713,  0.4154,  ...,  0.2144,  2.7298, -2.7837],\n",
            "        ...,\n",
            "        [-1.6718, -1.2112,  1.8901,  ..., -1.4747,  2.2350, -1.9617],\n",
            "        [-0.8885, -1.3513,  1.1811,  ..., -3.7077,  5.5004, -3.7337],\n",
            "        [-0.4139, -4.8457,  0.8333,  ...,  1.7347,  5.2084, -7.0050]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9979, -0.3337,  1.5539,  ..., -0.5813,  2.7800, -4.4785],\n",
            "        [-0.6621, -1.1373, -1.4727,  ...,  1.3991,  3.4209, -4.0733],\n",
            "        [ 1.6868, -0.8337, -1.8354,  ...,  0.8866,  6.4662, -6.0066],\n",
            "        ...,\n",
            "        [-3.3243, -2.5681,  2.7301,  ..., -2.0514,  1.2982, -3.6652],\n",
            "        [ 0.1065, -1.9895, -2.6189,  ...,  1.2561,  6.6132, -6.5149],\n",
            "        [-1.0622, -2.0166, -0.8457,  ...,  0.6661,  5.3780, -4.7615]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3755, -2.7643,  2.8347,  ..., -0.5558,  2.6752, -3.6265],\n",
            "        [-0.4131, -0.8463,  3.2211,  ..., -1.8580,  1.6420, -4.3905],\n",
            "        [-1.0312, -1.0123,  5.0672,  ..., -2.3259,  2.3611, -3.0553],\n",
            "        ...,\n",
            "        [ 0.1523, -0.7258,  2.8935,  ..., -0.5594,  3.1484, -2.7660],\n",
            "        [-0.5527, -2.2803,  4.4177,  ..., -0.9240,  2.7797, -3.5275],\n",
            "        [ 0.1597, -1.0980,  0.2431,  ..., -1.6738,  4.3728, -3.4616]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7917, -3.7900,  2.2276,  ..., -0.5879,  3.4479, -3.3505],\n",
            "        [-1.2138, -3.3307, -0.5036,  ...,  2.0277,  2.0936, -5.6477],\n",
            "        [-0.2725, -1.5980,  0.7698,  ..., -1.0141,  4.7283, -4.4208],\n",
            "        ...,\n",
            "        [-1.8254, -4.6801, -0.1422,  ...,  4.6639,  2.8287, -6.0422],\n",
            "        [-1.1780, -1.9330,  3.1734,  ..., -0.2813,  1.1002, -1.6505],\n",
            "        [ 0.6649, -1.7934, -1.9945,  ..., -0.7009,  5.4510, -2.0756]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9970, -0.5994, -0.2448,  ..., -1.4148,  3.8084, -2.6414],\n",
            "        [-1.6554, -2.5692,  0.4702,  ...,  1.4548, -0.4006, -3.7122],\n",
            "        [ 0.8814, -2.1092, -0.0061,  ..., -1.6890,  5.1537, -2.5082],\n",
            "        ...,\n",
            "        [-0.1955, -1.8785,  1.4408,  ..., -2.3241,  3.3828, -4.7504],\n",
            "        [ 0.5721,  2.0706, -1.1030,  ...,  0.1530,  2.0217, -1.5012],\n",
            "        [-0.2244, -1.8799, -0.2703,  ..., -1.2377,  3.0023, -3.1869]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2202, -1.4834,  3.5013,  ..., -0.3053,  4.3813, -2.9829],\n",
            "        [-2.0409, -2.0365,  0.3588,  ...,  2.1101,  2.0791, -5.2466],\n",
            "        [-1.5705,  0.7397,  4.0056,  ..., -1.0090,  2.2403, -2.8887],\n",
            "        ...,\n",
            "        [-2.3528, -2.7670,  1.4151,  ..., -0.5143,  3.0928, -2.1301],\n",
            "        [-0.8528, -3.7572,  2.9839,  ...,  4.3945,  0.8631, -5.1498],\n",
            "        [ 0.9242, -1.9174, -1.0098,  ..., -1.4566,  2.1540, -6.1209]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8655, -0.1048,  1.2472,  ..., -1.5148,  4.7475, -3.5642],\n",
            "        [ 0.4747, -2.1743, -1.6117,  ..., -0.9148,  5.6159, -4.1368],\n",
            "        [ 0.7749, -1.2770, -1.1748,  ...,  1.8592, -0.1839, -3.3598],\n",
            "        ...,\n",
            "        [-0.6724, -2.3329,  0.4082,  ..., -2.5181,  5.0702, -3.9526],\n",
            "        [-1.4352, -2.7558,  1.8479,  ..., -1.0411,  3.4265, -3.4580],\n",
            "        [-0.4564, -0.2256,  2.5542,  ..., -2.2905,  3.7171, -3.8216]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5888, -3.6851, -1.1008,  ...,  1.3912, -0.7942, -5.2170],\n",
            "        [-3.0386, -1.8800,  1.9321,  ..., -1.2900,  1.2671, -2.6802],\n",
            "        [-1.2868, -1.2486,  4.5717,  ...,  0.6150,  0.5631, -3.0034],\n",
            "        ...,\n",
            "        [-1.4631, -3.1013,  2.2369,  ...,  4.5319,  1.3833, -5.2559],\n",
            "        [-3.4755, -2.4210,  0.3936,  ...,  3.2988,  1.0456, -4.2868],\n",
            "        [-0.7828, -1.5838,  0.4555,  ..., -0.3311,  2.2370, -2.6776]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7680, -1.0030,  3.9731,  ...,  1.3105,  0.8546, -3.6852],\n",
            "        [-0.7929, -2.2983,  0.5008,  ..., -0.6827,  6.2896, -3.7271],\n",
            "        [-1.4574, -0.7800,  1.7797,  ..., -2.1593,  3.8709, -2.9592],\n",
            "        ...,\n",
            "        [ 0.6708, -0.9907, -1.7692,  ...,  2.3910, -2.3503, -3.4596],\n",
            "        [-1.9266, -2.0335,  3.9280,  ..., -1.5782,  2.1749, -4.8084],\n",
            "        [ 0.2590, -0.1095, -0.2388,  ..., -0.7940,  2.2112, -0.1091]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4108, -2.1817, -0.6704,  ...,  0.9529,  1.9043, -4.3382],\n",
            "        [-1.1294, -1.8143,  0.1313,  ...,  0.3378,  2.0997, -3.4272],\n",
            "        [-2.0608, -1.8915,  4.6296,  ...,  1.4487,  1.2059, -4.6684],\n",
            "        ...,\n",
            "        [-1.5650, -1.6986,  0.3844,  ...,  0.6772,  1.7035, -3.2272],\n",
            "        [ 0.1222, -0.6601, -3.8938,  ...,  2.1158,  0.7426, -4.0764],\n",
            "        [-0.5579,  0.3719,  1.0045,  ..., -0.7349,  0.8609, -3.8772]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5526, -3.4581, -0.9148,  ...,  2.8590,  0.2988, -4.9994],\n",
            "        [-3.0908, -3.1502,  2.3132,  ...,  1.8529,  2.0015, -1.8368],\n",
            "        [ 0.6788, -2.2334, -1.2492,  ..., -0.5858,  1.6586, -5.3186],\n",
            "        ...,\n",
            "        [-2.8066, -2.0750,  2.6380,  ..., -1.0482,  4.9736, -5.4509],\n",
            "        [-1.0339, -2.7677, -2.5574,  ...,  0.0874,  0.1977, -5.1699],\n",
            "        [-3.8531, -0.6264,  0.9252,  ...,  0.2257,  1.1617, -3.3320]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7911, -1.3841,  4.2752,  ...,  0.4999, -0.2783, -3.1024],\n",
            "        [-0.7137, -0.6845, -0.3057,  ..., -1.1067,  3.6750, -1.8192],\n",
            "        [-1.1423, -0.4572,  1.6204,  ..., -1.0273,  2.3449, -3.6357],\n",
            "        ...,\n",
            "        [-0.9048, -4.7519, -0.2791,  ...,  4.3889,  2.6935, -6.2353],\n",
            "        [-2.9962, -4.4466,  1.3592,  ...,  2.6512,  0.8003, -4.0746],\n",
            "        [ 0.1429,  0.1656, -0.4426,  ...,  0.2844,  1.0891, -3.0227]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8330, -0.5446,  1.5133,  ...,  1.5579,  1.2939, -2.6382],\n",
            "        [-1.2507,  0.9131,  2.2729,  ..., -0.8500,  0.8224, -1.6133],\n",
            "        [-0.6901, -2.4012,  3.9818,  ..., -0.8720,  3.6905, -4.0032],\n",
            "        ...,\n",
            "        [-2.7471, -2.6662,  0.8608,  ...,  4.6966,  1.6000, -3.6872],\n",
            "        [-3.3479, -0.0765,  3.1782,  ..., -0.7439, -0.7443, -2.6637],\n",
            "        [-1.4723, -0.7642, -1.0674,  ..., -1.6049,  2.0736, -4.4294]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1861, -0.5901,  2.6247,  ..., -1.1096,  3.6832, -3.7710],\n",
            "        [-0.8904, -2.7261,  1.6094,  ...,  3.0142,  3.1334, -2.8468],\n",
            "        [-1.7498, -1.7774,  3.2764,  ..., -1.8411,  3.3445, -4.1055],\n",
            "        ...,\n",
            "        [ 0.3169, -2.5254,  0.6394,  ...,  2.2466, -0.5585, -4.8273],\n",
            "        [-2.9678, -0.8153,  3.1303,  ...,  0.4499, -0.4580, -3.2115],\n",
            "        [-2.8441, -1.4178,  3.5917,  ..., -1.3926,  2.7525, -3.3157]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2031e-01, -9.9896e-01, -1.6908e-01,  ..., -2.0197e+00,\n",
            "          2.1503e+00, -2.4507e+00],\n",
            "        [-2.0160e+00, -1.2486e+00,  6.0350e-01,  ...,  1.9303e+00,\n",
            "          8.4487e-01, -4.8590e+00],\n",
            "        [-3.9677e-01, -5.7133e-01, -1.7214e+00,  ...,  1.0777e+00,\n",
            "          1.4867e+00, -3.9816e+00],\n",
            "        ...,\n",
            "        [-2.8272e+00, -8.1336e-01,  4.0119e-02,  ...,  3.9392e-03,\n",
            "          1.6093e+00, -1.8714e+00],\n",
            "        [-7.0613e-01, -1.8197e+00,  4.7126e-01,  ..., -8.3666e-01,\n",
            "          6.2777e-01, -1.4209e+00],\n",
            "        [ 5.3608e-01, -3.6125e-01, -1.8271e+00,  ..., -9.4089e-01,\n",
            "          2.8759e+00, -2.7890e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8304, -2.3078,  0.7194,  ...,  2.9606,  4.0058, -7.0125],\n",
            "        [ 0.1747, -1.0874, -0.7831,  ..., -0.0107,  4.0828, -1.0059],\n",
            "        [-1.6068, -1.3392,  1.2141,  ..., -0.4991,  0.6992, -5.5344],\n",
            "        ...,\n",
            "        [-4.5627, -0.5990,  2.2426,  ...,  2.8363, -0.2159, -3.2767],\n",
            "        [-1.9886, -2.9648, -2.2416,  ..., -0.5551,  1.3382, -3.0865],\n",
            "        [-0.8256, -1.8068, -1.7259,  ...,  0.6219,  2.6354, -5.8342]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9399, -3.1301,  3.4653,  ...,  3.8913,  1.6914, -5.1367],\n",
            "        [-2.4408, -1.3763,  2.4987,  ..., -1.9250,  1.0218, -5.3572],\n",
            "        [-2.0131,  1.0098,  2.9756,  ..., -0.7483,  0.5786, -2.1779],\n",
            "        ...,\n",
            "        [-1.6833, -0.1469,  5.4610,  ..., -1.4027,  2.6856, -2.2088],\n",
            "        [-0.0470, -2.9397, -0.2478,  ...,  2.1772,  6.3045, -3.4195],\n",
            "        [-2.8851, -1.1544,  4.4587,  ..., -1.9863,  3.3747, -4.2990]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6414, -0.9547,  1.9581,  ...,  0.2210,  6.7694, -3.9500],\n",
            "        [-1.0997, -1.1914,  5.0795,  ...,  1.2400,  1.3383, -3.6000],\n",
            "        [-1.0670, -0.9022, -0.9955,  ..., -0.7535,  3.8013, -2.3984],\n",
            "        ...,\n",
            "        [-2.6656, -2.9561,  2.1830,  ..., -0.7870,  4.0895, -3.8388],\n",
            "        [-0.0660, -1.7977, -1.1795,  ...,  1.9229,  1.4676, -1.1413],\n",
            "        [-1.5119, -0.5050,  3.5513,  ..., -0.0096,  1.2630, -4.0160]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6568, -3.0200,  1.7907,  ...,  2.9189,  4.0253, -5.6071],\n",
            "        [-1.1188, -1.0208,  3.4817,  ...,  0.1336,  1.2745, -4.2005],\n",
            "        [-1.5620,  0.4599,  2.1018,  ..., -2.3813,  4.2751, -3.4446],\n",
            "        ...,\n",
            "        [-1.6563,  0.9198,  2.8347,  ..., -0.8087, -1.1753, -1.6849],\n",
            "        [-1.4104,  0.3776,  4.5389,  ..., -1.3958,  1.7450, -2.8938],\n",
            "        [-2.0128, -3.3330, -1.7674,  ...,  4.4984,  4.7976, -4.1593]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3750, -2.1024,  2.1995,  ...,  3.2369,  2.1430, -1.0464],\n",
            "        [-0.8593, -0.4745, -0.5558,  ..., -0.4547,  1.4057, -2.4492],\n",
            "        [-0.0877, -1.2958, -1.1145,  ..., -0.1058,  5.1104, -2.6182],\n",
            "        ...,\n",
            "        [-1.9864, -1.5402,  2.0827,  ..., -0.4172,  3.6908, -2.4068],\n",
            "        [-0.7811,  0.6785,  3.9808,  ...,  0.6791,  0.3170, -3.6540],\n",
            "        [-2.2521, -1.5260,  1.4573,  ...,  2.2481,  3.4148, -4.1805]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0041, -0.7886,  3.9522,  ...,  0.2305,  0.7677, -3.1526],\n",
            "        [ 1.0399, -2.4584, -0.7647,  ...,  4.3618,  2.1326, -5.1313],\n",
            "        [-1.2131, -1.6927,  4.1257,  ...,  0.4292,  4.4918, -4.4286],\n",
            "        ...,\n",
            "        [-1.8764, -2.0538,  3.3374,  ..., -1.5620,  2.0742, -3.5631],\n",
            "        [-0.4685,  0.9117,  0.8013,  ..., -0.8522,  5.5993, -2.4672],\n",
            "        [ 0.1142, -1.1748,  2.1849,  ...,  0.0795,  7.1532, -3.3977]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2084, -0.4992,  2.9798,  ..., -1.0028,  4.3631, -3.4006],\n",
            "        [-2.1871, -1.4905,  0.6970,  ..., -0.6392,  1.7097, -2.8320],\n",
            "        [-1.8960, -0.7348, -0.7274,  ..., -1.2393,  4.6051, -3.2725],\n",
            "        ...,\n",
            "        [-0.5597, -2.8678, -1.5000,  ...,  2.1165,  6.9728, -4.2835],\n",
            "        [-1.1329, -3.0117,  4.3615,  ...,  2.5805,  1.2574, -2.7680],\n",
            "        [-0.8435, -0.3630,  4.5190,  ...,  0.9287,  1.0059, -2.3699]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1837,  0.8910,  3.2734,  ..., -2.3386, -1.2198, -2.8684],\n",
            "        [-0.9966,  1.2122,  4.6045,  ...,  0.6272,  1.0774, -2.3687],\n",
            "        [-2.9465, -2.2605,  1.7067,  ...,  2.8016,  5.4317, -6.4304],\n",
            "        ...,\n",
            "        [ 0.7971, -4.9316, -3.2759,  ...,  6.5959,  4.8821, -3.9797],\n",
            "        [-0.8891, -1.7975,  3.1284,  ...,  0.7174,  1.2198, -2.7364],\n",
            "        [ 0.7096, -1.5637, -0.2811,  ..., -1.6702,  4.3797, -1.7922]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7066, -1.1627,  2.8036,  ..., -1.8198,  4.6112, -3.5754],\n",
            "        [-2.8092, -1.0629,  1.3776,  ...,  0.7236,  4.4229, -3.7784],\n",
            "        [ 1.1410, -1.2995,  3.3353,  ..., -0.6784,  4.2791, -3.3236],\n",
            "        ...,\n",
            "        [-1.1680, -2.2952, -0.2019,  ..., -1.2335,  3.7078, -4.6278],\n",
            "        [-1.8457,  0.6032,  5.1627,  ..., -1.2847,  0.3725, -2.8622],\n",
            "        [-0.8034, -1.4490,  5.5811,  ..., -1.0003,  3.4597, -2.5222]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5482, -2.1961,  3.6206,  ...,  0.3041,  1.5575, -4.8188],\n",
            "        [-2.9613, -0.1012,  1.6748,  ..., -0.9967, -0.9241, -1.1207],\n",
            "        [-1.2891, -0.8611,  3.8329,  ..., -1.0672,  3.1028, -3.6663],\n",
            "        ...,\n",
            "        [ 0.2859, -1.3668,  4.3973,  ...,  0.1941,  3.2096, -2.5651],\n",
            "        [ 0.2356, -1.0810, -1.2892,  ...,  3.0083,  3.3495, -4.3772],\n",
            "        [ 0.6269, -2.3081, -3.3230,  ...,  2.5013,  1.8430, -2.8123]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3978,  2.1940, -0.1739,  ..., -1.0992,  3.4398, -2.5567],\n",
            "        [ 0.3153, -3.4222, -0.1067,  ...,  1.9999,  3.7714, -5.7058],\n",
            "        [-1.8655, -2.4822,  0.7659,  ...,  0.9977,  1.3903, -3.0674],\n",
            "        ...,\n",
            "        [ 4.0235, -1.1904,  0.7383,  ..., -0.0765,  8.9407, -1.1710],\n",
            "        [ 0.1565, -1.0566,  1.9265,  ..., -1.3867,  2.3674, -2.8598],\n",
            "        [-0.0778, -1.1833, -2.9072,  ...,  1.5651,  5.9383, -0.6031]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0286, -1.8487,  4.0344,  ..., -0.5587,  6.0602, -1.1897],\n",
            "        [-0.3840, -1.1475,  3.4773,  ..., -1.8105,  3.8241, -4.5578],\n",
            "        [-2.3416, -0.9293,  3.7066,  ..., -0.9915,  2.8586, -3.5353],\n",
            "        ...,\n",
            "        [-0.5714, -2.0133, -0.9981,  ..., -1.8452,  4.8945, -2.1865],\n",
            "        [-0.9246, -1.5062,  3.7428,  ..., -2.1749,  2.6617, -1.9056],\n",
            "        [-1.5931,  0.2484,  1.7764,  ...,  0.5462,  2.7463, -1.4231]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4656, -1.2455, -3.5065,  ...,  1.7993, -0.4811, -4.7870],\n",
            "        [-1.8902, -0.5032,  0.1023,  ..., -0.3593,  0.7208, -1.3998],\n",
            "        [-1.4610, -1.2032,  2.1472,  ...,  0.4210,  5.6148, -4.7376],\n",
            "        ...,\n",
            "        [-2.3413,  0.4851,  2.6051,  ..., -0.9394, -0.5499, -1.5305],\n",
            "        [-0.0463, -0.9435, -0.5835,  ..., -1.4749,  4.9682, -0.9592],\n",
            "        [-2.6783,  0.5893,  2.4970,  ..., -2.0520, -1.2230, -1.3938]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4011, -0.2960, -1.2924,  ..., -1.1826,  2.9215, -3.6096],\n",
            "        [-2.7836, -2.9462,  2.4053,  ..., -1.1527,  1.1005, -5.0463],\n",
            "        [-1.1143, -2.4561,  0.5908,  ...,  0.6328,  7.6426, -4.8791],\n",
            "        ...,\n",
            "        [-1.8690,  0.4265,  0.2193,  ..., -1.6410,  2.1370, -3.9763],\n",
            "        [-0.6931, -1.6049,  4.2766,  ..., -0.7792,  2.6038, -2.9343],\n",
            "        [-1.0049, -1.7500,  0.2480,  ..., -2.4795,  5.0674, -1.9294]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4438, -1.5079, -0.8189,  ..., -1.5730,  4.0971, -5.1683],\n",
            "        [-1.0416, -2.1054,  3.1888,  ..., -1.5008,  1.1052, -4.3672],\n",
            "        [ 0.0426, -0.2007,  3.5384,  ..., -1.8694,  4.0950, -4.9217],\n",
            "        ...,\n",
            "        [-4.3552, -1.8348,  3.3710,  ...,  0.1730,  2.8251, -4.1149],\n",
            "        [-2.6652, -3.0623, -0.1861,  ...,  2.9028,  4.2463, -6.8594],\n",
            "        [-1.7803,  1.7256,  2.4601,  ..., -1.4344,  2.9595, -2.2067]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9724, -1.4998, -3.2508,  ...,  3.3346,  4.9246, -4.1102],\n",
            "        [-0.2282, -0.5089,  0.3586,  ..., -2.0884,  2.9366, -2.3540],\n",
            "        [-0.0978, -2.4029,  5.2088,  ..., -1.2703,  4.2815, -5.1916],\n",
            "        ...,\n",
            "        [-3.6850, -2.4745,  4.0646,  ...,  1.4147,  1.5069, -5.7895],\n",
            "        [-0.8133,  0.5035,  2.1524,  ..., -1.9469,  8.0197, -4.1848],\n",
            "        [-1.8585,  0.3083,  2.4892,  ..., -2.5472,  1.0833, -2.9654]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5460, -1.0532,  5.4705,  ..., -0.8137,  3.0316, -3.4663],\n",
            "        [-2.6799, -1.3233,  0.2562,  ..., -0.5073,  5.1585, -3.2678],\n",
            "        [-1.6501, -1.2746,  1.7933,  ..., -1.0963,  6.4017, -3.9169],\n",
            "        ...,\n",
            "        [-0.3210, -0.2666,  1.5891,  ..., -0.9770,  6.2749, -3.3567],\n",
            "        [-2.6964, -0.6979,  2.2643,  ..., -1.6737,  0.8505, -3.0049],\n",
            "        [-2.1279, -3.3289, -0.1452,  ...,  4.5536,  3.6449, -4.6880]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-9.0958e-01, -1.0044e+00,  2.3728e+00,  ..., -8.7612e-01,\n",
            "          3.5499e+00, -4.1334e+00],\n",
            "        [-9.5050e-01, -1.0613e+00,  3.1444e+00,  ...,  1.7205e+00,\n",
            "         -1.3992e-01, -3.3466e+00],\n",
            "        [-2.3778e-03, -2.9466e+00, -7.8063e-01,  ...,  4.2624e+00,\n",
            "         -7.8644e-01, -2.8280e+00],\n",
            "        ...,\n",
            "        [-1.7789e+00, -2.9734e+00, -1.1894e+00,  ...,  2.7140e+00,\n",
            "          3.3644e+00, -6.9864e+00],\n",
            "        [-1.5220e+00,  1.3209e-01,  3.1255e+00,  ..., -1.1580e+00,\n",
            "          2.3164e+00, -2.3901e+00],\n",
            "        [-2.8763e+00, -2.1592e+00,  1.1120e+00,  ...,  1.5084e+00,\n",
            "          4.1108e+00, -4.9245e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8219, -1.7532,  3.1147,  ..., -0.6874,  5.4386, -4.4730],\n",
            "        [-1.3081, -2.1370, -1.4228,  ...,  2.3682,  3.5886, -2.1330],\n",
            "        [-1.7475, -2.2616,  1.3026,  ...,  1.5445,  2.6259, -4.7616],\n",
            "        ...,\n",
            "        [-0.9130, -1.1819, -2.1629,  ...,  1.9018,  2.8181, -4.4577],\n",
            "        [-0.1018, -1.3245, -0.8986,  ...,  2.2750,  7.7022, -5.9653],\n",
            "        [-0.0203, -1.0903,  1.4077,  ..., -0.4160,  4.2109, -1.8569]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8158, -3.6309,  2.7540,  ...,  4.1282,  0.4081, -4.8369],\n",
            "        [-1.8188, -0.0519,  0.4541,  ..., -0.8365,  3.9586, -1.9834],\n",
            "        [-1.4323, -1.4893, -0.5598,  ...,  0.4760,  1.2901, -3.4945],\n",
            "        ...,\n",
            "        [-1.5534, -2.7439,  1.5057,  ..., -0.4483,  3.9592, -1.9839],\n",
            "        [-0.3524, -0.0981,  3.7457,  ..., -0.0055,  3.7341, -3.7114],\n",
            "        [-1.9091, -0.8998,  4.2707,  ..., -0.6662,  0.8439, -5.2038]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8025, -0.2920,  1.8867,  ..., -0.9288,  1.6054, -1.7278],\n",
            "        [-0.6198,  0.5631,  4.9089,  ..., -0.9270,  3.2350, -4.6346],\n",
            "        [-0.1267,  0.4187,  3.4328,  ...,  1.6349,  4.7646, -3.8741],\n",
            "        ...,\n",
            "        [-2.0121, -1.2836,  1.2090,  ...,  0.1028,  2.5467, -6.1662],\n",
            "        [-2.2401, -3.2403,  1.0565,  ..., -1.1877,  6.9467, -4.7975],\n",
            "        [-1.6272, -0.8081, -1.9034,  ..., -1.7257,  3.7108, -1.5903]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8838,  0.9352,  2.0221,  ..., -0.9192, -0.8127, -1.2630],\n",
            "        [-0.3114, -5.1788, -1.2070,  ...,  3.4129,  1.1879, -3.0847],\n",
            "        [-1.8176, -0.1877,  1.6632,  ..., -0.4440,  4.7674, -2.9457],\n",
            "        ...,\n",
            "        [-1.5165, -2.1732,  1.6238,  ..., -0.3336,  5.6991, -5.5364],\n",
            "        [-1.2635, -1.7094,  1.8789,  ...,  1.1033,  1.9389, -3.3797],\n",
            "        [-1.7705, -1.5084, -0.6470,  ...,  0.9587,  1.1091, -4.9296]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6441, -1.5436,  2.7873,  ..., -0.6684,  3.1941, -4.1396],\n",
            "        [-2.0744,  0.9782,  3.3196,  ...,  0.0417,  0.1446, -1.9571],\n",
            "        [-2.0729, -0.6469,  1.9577,  ..., -0.3797,  2.6378, -3.4540],\n",
            "        ...,\n",
            "        [-2.3079, -2.1971, -1.4539,  ...,  1.7104,  1.8312, -3.1015],\n",
            "        [-2.8324, -0.2398,  1.0326,  ...,  0.6384,  6.6056, -3.9975],\n",
            "        [-2.1770, -0.0550,  1.3330,  ..., -0.1140, -0.1885, -1.8272]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5021, -1.0775,  0.4802,  ...,  0.2781,  0.9701, -1.2208],\n",
            "        [-3.4537, -3.3343, -1.8354,  ...,  5.1686, -1.7175, -4.9147],\n",
            "        [-4.5376, -1.4566,  1.1936,  ...,  2.5164, -0.0335, -4.4524],\n",
            "        ...,\n",
            "        [-1.7179, -1.7025,  0.6092,  ..., -0.6226,  3.1408, -2.9879],\n",
            "        [-2.4330, -0.0930,  1.2487,  ..., -0.8245,  0.6258, -3.2292],\n",
            "        [ 0.5425, -3.4312, -1.3908,  ...,  3.6071,  3.8518, -4.6217]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8063, -0.8949,  2.5201,  ..., -0.7232,  5.9173, -5.2490],\n",
            "        [-1.8295, -0.8049,  2.7174,  ..., -1.8542,  2.3613, -3.1628],\n",
            "        [-3.2378, -0.4195,  1.9406,  ..., -1.1965,  2.2343, -2.3660],\n",
            "        ...,\n",
            "        [ 0.6289,  0.0144, -1.5738,  ...,  2.2977,  3.1914, -3.1292],\n",
            "        [-1.8073,  1.1528,  3.9327,  ...,  0.3576,  0.4390, -2.0343],\n",
            "        [-0.7346,  0.4910,  3.4163,  ...,  0.7353,  0.7621, -3.9160]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0822,  0.9103, -1.4069,  ..., -0.1592,  7.7387, -0.6662],\n",
            "        [-0.9658, -2.7000, -0.6163,  ...,  2.6456,  1.1264, -4.4234],\n",
            "        [-1.9435,  0.2865,  0.0899,  ..., -0.9215,  1.4590, -3.1175],\n",
            "        ...,\n",
            "        [-1.3610,  0.1534,  0.3379,  ..., -0.1872,  4.4180, -3.9064],\n",
            "        [-0.4979, -3.3548,  2.2843,  ..., -0.4815,  3.7199, -4.5995],\n",
            "        [-2.7975, -3.0208,  2.3221,  ...,  1.8132,  1.9849, -2.4939]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8735, -0.2799,  1.9435,  ..., -0.8672,  3.3741, -2.5096],\n",
            "        [-1.7023, -0.0760, -1.6838,  ..., -0.0758,  4.0681, -3.4356],\n",
            "        [-2.0559, -4.2871,  0.2338,  ...,  0.6273,  3.2845, -6.4596],\n",
            "        ...,\n",
            "        [-2.3848, -0.2590,  4.4657,  ..., -0.7118,  1.8145, -4.7888],\n",
            "        [-2.0697, -1.2639,  5.0690,  ..., -2.0314,  2.7624, -3.7311],\n",
            "        [-2.5131, -0.4804,  1.7161,  ..., -1.2086,  4.2132, -4.9364]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1853, -1.7912,  5.2935,  ..., -0.5781,  4.8103, -4.0025],\n",
            "        [-3.7254, -1.2719,  3.1325,  ...,  0.7564,  1.4840, -4.4132],\n",
            "        [-2.4584, -0.9922,  2.8438,  ..., -0.1914,  2.7575, -3.8677],\n",
            "        ...,\n",
            "        [-3.6795,  0.8829,  0.7987,  ...,  3.1959,  2.9728, -3.4697],\n",
            "        [-1.6232, -2.3588, -1.2400,  ...,  1.7411,  0.4149, -3.5454],\n",
            "        [-0.3707, -2.1864,  3.2265,  ...,  0.0316,  5.3970, -5.5849]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9103, -2.1218,  0.2029,  ..., -1.1620,  3.9830, -4.3176],\n",
            "        [-0.9960, -1.2713,  2.8486,  ...,  1.6381,  0.2014, -4.2832],\n",
            "        [ 0.0140, -2.8091, -0.1351,  ...,  4.0224,  3.3518, -3.1378],\n",
            "        ...,\n",
            "        [-1.9948,  0.7119,  4.4166,  ..., -1.3762, -0.3162, -3.2152],\n",
            "        [-2.4444,  0.9005,  3.9584,  ..., -0.2543,  0.1160, -2.1993],\n",
            "        [-1.7173, -0.0466,  3.3964,  ...,  0.1622,  1.0133, -3.9904]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0837, -3.0545, -2.2962,  ...,  3.8029,  6.2888, -2.3258],\n",
            "        [-3.0696, -0.4870,  2.7441,  ..., -0.7802, -0.5079, -2.7140],\n",
            "        [-2.7860, -3.3910, -0.4725,  ...,  5.2491,  4.9907, -5.5108],\n",
            "        ...,\n",
            "        [-1.4776,  0.0494,  3.8339,  ..., -0.3600,  2.5716, -2.4234],\n",
            "        [-3.0932, -0.2123,  1.3351,  ..., -0.2386, -0.5056, -1.8758],\n",
            "        [-2.0323, -2.2846,  4.9167,  ..., -1.1797,  2.9931, -4.7329]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7085, -3.7182, -1.1826,  ...,  3.2578,  2.7348, -2.4775],\n",
            "        [-1.8879,  0.6634,  3.2887,  ..., -0.7959,  3.4279, -3.5803],\n",
            "        [-2.0742, -2.1218, -0.2858,  ..., -0.0628, -0.9498, -3.3142],\n",
            "        ...,\n",
            "        [-3.9276, -1.6486,  2.4858,  ..., -0.9001,  1.6181, -2.8102],\n",
            "        [-1.2782, -0.3074,  4.4911,  ...,  0.5527,  1.3445, -4.2571],\n",
            "        [-2.0640, -2.6876, -1.3569,  ...,  0.8048,  4.7626, -3.8374]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4314, -0.5123,  3.2534,  ...,  0.7733,  1.0244, -3.4186],\n",
            "        [-1.1808, -2.1040,  0.7066,  ...,  2.6139,  0.1925, -4.6217],\n",
            "        [-1.1581, -5.3070, -0.8102,  ...,  1.2907,  6.0755, -5.2322],\n",
            "        ...,\n",
            "        [-1.0848, -0.3401,  3.9480,  ...,  0.9299,  1.1043, -3.6592],\n",
            "        [ 1.7881, -5.4460, -2.3654,  ...,  5.3970,  4.4981, -5.1799],\n",
            "        [-1.6997, -2.3612,  0.4009,  ..., -0.3037,  4.0748, -3.1732]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5468, -1.1710,  3.0737,  ..., -0.2306,  3.8670, -4.5768],\n",
            "        [-0.9094, -3.6438,  0.8862,  ...,  5.0906,  0.7087, -6.2991],\n",
            "        [-4.1306,  0.5363,  2.9045,  ...,  0.3261,  3.4253, -3.7461],\n",
            "        ...,\n",
            "        [-1.8423, -0.4538,  1.4920,  ...,  0.6847,  2.1978, -2.2120],\n",
            "        [-2.7275, -2.4434, -2.9636,  ...,  3.0857,  4.5352, -2.2795],\n",
            "        [-2.3241, -0.0815,  4.0668,  ..., -1.1748,  5.6509, -2.7046]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1948, -3.3228,  1.3339,  ...,  2.5266,  0.6534, -4.0052],\n",
            "        [-2.6374, -0.2089,  1.5059,  ..., -1.4488, -1.0860, -2.8161],\n",
            "        [-1.1987, -1.2900, -0.5806,  ..., -2.7295,  4.4109, -1.6188],\n",
            "        ...,\n",
            "        [-1.3943, -2.2385,  0.4434,  ..., -0.9121,  5.6132, -2.3969],\n",
            "        [-2.0104, -1.8598,  1.1032,  ...,  0.7423,  3.7750, -4.4441],\n",
            "        [-1.2478, -0.1906,  0.1582,  ..., -1.1310,  2.5642, -2.9150]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3600, -0.1770,  2.6447,  ...,  1.8975,  1.3544, -3.0446],\n",
            "        [-1.3354, -1.8008,  4.0122,  ...,  0.7651,  0.7640, -3.8594],\n",
            "        [-2.9272,  1.8273,  0.9903,  ..., -1.4125, -1.8216, -2.5340],\n",
            "        ...,\n",
            "        [-0.8347, -0.8626,  3.1294,  ...,  1.8027,  0.4379, -3.3883],\n",
            "        [-1.2964, -2.3806, -1.5344,  ...,  0.8648,  4.0948, -6.1386],\n",
            "        [ 0.4467, -4.3396, -2.3331,  ...,  6.2461,  3.4071, -5.6832]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8272, -1.1450,  1.4950,  ...,  0.2648,  4.9756, -3.6200],\n",
            "        [ 0.6627, -3.7133, -0.5741,  ...,  4.1263,  1.3631, -2.4840],\n",
            "        [-0.7644, -4.8974,  0.6746,  ...,  4.8981,  2.9625, -3.8075],\n",
            "        ...,\n",
            "        [-2.3931, -2.0923,  1.3291,  ..., -0.2559,  2.1719, -6.4154],\n",
            "        [-2.6915, -0.7910,  1.7812,  ...,  0.1616,  0.8876, -0.8484],\n",
            "        [-1.3877, -1.4132,  2.9445,  ...,  1.0861,  0.1541, -3.9809]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3198, -3.2793, -2.4681,  ...,  2.7006,  5.3233, -5.3261],\n",
            "        [-1.0100, -0.6333,  2.8486,  ..., -2.0851,  2.2378, -3.8599],\n",
            "        [-0.3269, -1.9725, -1.6916,  ..., -1.4815,  6.8898, -3.7623],\n",
            "        ...,\n",
            "        [-2.0485, -2.2295,  2.5549,  ...,  0.0930,  1.7860, -3.2182],\n",
            "        [-2.0789, -0.4194,  0.6922,  ..., -0.7544,  5.0596, -2.4267],\n",
            "        [-0.8706, -3.0276,  1.0107,  ...,  2.9110,  5.7204, -3.7162]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2824, -3.9724,  0.3752,  ...,  1.2967,  3.3784, -5.5176],\n",
            "        [-1.0798, -2.5237,  3.2927,  ..., -1.0052,  0.7766, -4.3161],\n",
            "        [-2.5324, -2.0963,  1.4976,  ..., -1.1535,  2.9647, -3.4127],\n",
            "        ...,\n",
            "        [-3.0613, -3.9428,  4.7594,  ...,  2.3119,  2.0543, -5.9840],\n",
            "        [ 0.2105, -3.9359, -0.3013,  ...,  3.1300,  6.3638, -6.3600],\n",
            "        [-1.3960, -1.1740,  1.4152,  ..., -0.8191,  3.5189, -4.5455]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7893, -1.1676,  3.4128,  ..., -1.3278,  2.7325, -3.2021],\n",
            "        [-2.2470, -3.1876,  3.3920,  ..., -0.9034,  4.9160, -4.2973],\n",
            "        [-0.4688,  0.2483,  3.3701,  ..., -2.1210,  7.5396, -5.7363],\n",
            "        ...,\n",
            "        [-2.7558, -1.2598, -2.0633,  ...,  0.0085,  4.9026, -5.0581],\n",
            "        [-0.8564, -1.5802,  2.6992,  ...,  0.9174,  0.8743, -2.9377],\n",
            "        [-1.2269, -1.8872,  0.8046,  ...,  5.4746,  3.6326, -6.2315]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4917, -1.0682, -1.5746,  ...,  2.7763, -0.3604, -4.0117],\n",
            "        [-0.9416, -1.3172,  2.8259,  ...,  0.8383,  0.9723, -3.5680],\n",
            "        [-1.5546,  1.4587,  2.3508,  ...,  0.4818, -0.5955, -4.7464],\n",
            "        ...,\n",
            "        [-0.1724, -0.2043, -0.6604,  ..., -2.5031,  6.2128, -2.2220],\n",
            "        [-1.0038, -1.2780,  0.5464,  ...,  1.4437,  5.3843, -3.8608],\n",
            "        [-1.4777, -1.6748,  3.6366,  ...,  0.6099,  4.3031, -3.7620]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0833, -1.9762,  2.0458,  ...,  1.1011,  0.9410, -3.8787],\n",
            "        [-1.4097, -1.7701,  4.5820,  ...,  0.4436,  1.3512, -2.4945],\n",
            "        [-1.2826, -0.8722,  3.4404,  ...,  1.1075,  0.2989, -3.8483],\n",
            "        ...,\n",
            "        [-3.3905, -0.4126,  1.2806,  ...,  0.1242, -0.6632, -2.3811],\n",
            "        [-2.4243, -1.1233,  2.5254,  ..., -1.8698,  2.6876, -2.0760],\n",
            "        [-1.6749, -1.0250,  2.7626,  ..., -0.6564,  4.6938, -3.0972]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0434, -2.1105,  3.6277,  ...,  0.4373,  3.5566, -2.2987],\n",
            "        [-2.1719, -1.3027,  1.0264,  ..., -0.5216,  0.7256, -2.0364],\n",
            "        [-0.3667, -1.1681, -1.5670,  ...,  0.5772,  3.6693, -2.8912],\n",
            "        ...,\n",
            "        [-2.7250, -1.8191,  2.6802,  ...,  0.0105,  2.8374, -2.0031],\n",
            "        [-1.4020, -3.3586,  2.0144,  ...,  1.4705,  6.2168, -3.5823],\n",
            "        [-1.4699, -2.7730, -0.2208,  ...,  1.3307,  2.7762, -3.8621]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7081,  0.5177,  4.9206,  ..., -1.3635,  5.0343, -3.2926],\n",
            "        [-0.6603, -0.6281, -0.0529,  ...,  0.8049,  4.0271, -2.7046],\n",
            "        [ 0.3184,  0.5333,  2.0163,  ..., -1.5471,  6.9988, -3.8255],\n",
            "        ...,\n",
            "        [-1.7924, -1.2703, -1.3573,  ..., -1.0291,  2.9388, -1.8566],\n",
            "        [-1.1665, -0.0559, -2.3687,  ..., -0.8221,  3.4479, -4.1178],\n",
            "        [-3.4734,  0.3923,  2.9010,  ..., -1.5002,  0.0586, -3.9666]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5103, -1.4414,  0.6573,  ...,  1.7160, -0.1040, -3.7248],\n",
            "        [-2.1052,  1.2427,  3.3857,  ...,  0.4357,  0.1022, -2.6584],\n",
            "        [-0.9074, -0.5393,  2.6639,  ..., -0.3357,  4.9458, -3.3470],\n",
            "        ...,\n",
            "        [-0.6314, -0.3524, -0.6301,  ...,  2.2261,  1.5568, -3.3863],\n",
            "        [ 0.2860,  0.9315,  3.8320,  ..., -2.7376,  2.6375, -2.8292],\n",
            "        [-2.0115, -0.9937,  2.7197,  ..., -0.4098,  2.6874, -2.3048]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2314, -2.2668,  1.3375,  ...,  1.9531,  4.2774, -5.0393],\n",
            "        [-1.1333, -2.4788,  1.0532,  ...,  1.3015,  3.5638, -3.8735],\n",
            "        [ 0.6844,  2.0404, -2.2552,  ..., -2.0894,  3.5289, -2.5225],\n",
            "        ...,\n",
            "        [-1.7431, -1.8518,  3.7422,  ..., -0.7126,  3.2080, -2.9202],\n",
            "        [-1.7760,  0.1709,  3.4460,  ...,  0.5641,  0.4171, -3.1459],\n",
            "        [-1.8995, -1.8561,  0.1583,  ..., -2.7623,  4.0459, -2.2126]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6573, -0.7947, -3.3838,  ..., -1.9070,  5.3296, -5.7809],\n",
            "        [-1.3641, -1.7250,  1.2019,  ..., -0.0072,  3.1062, -3.9060],\n",
            "        [-1.0875, -0.3865,  1.0703,  ...,  1.5197,  3.8614, -3.7495],\n",
            "        ...,\n",
            "        [-3.0398, -1.0043,  3.2441,  ..., -0.9906,  0.2321, -3.5386],\n",
            "        [-2.2197, -0.4877,  2.5177,  ..., -3.2323,  1.0310, -1.2033],\n",
            "        [-1.9667, -1.1924,  1.7563,  ..., -0.2259,  2.1951, -2.4157]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6220, -2.3777, -0.0521,  ...,  1.7221,  2.7503, -2.7843],\n",
            "        [ 0.3121, -3.8506, -0.7845,  ...,  3.3097,  2.1771, -4.3475],\n",
            "        [-3.3444, -2.2231,  3.2440,  ...,  0.8133,  1.9193, -3.6187],\n",
            "        ...,\n",
            "        [-1.7725, -2.3323,  2.9650,  ...,  3.6824,  1.9833, -0.9926],\n",
            "        [-3.4522, -2.7393,  0.6065,  ...,  1.9841,  0.0094, -2.5386],\n",
            "        [-2.6234, -0.8376,  1.0099,  ...,  2.4317,  2.9219, -1.3078]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3888, -0.7233, -0.3815,  ..., -0.1904,  2.3268, -3.7397],\n",
            "        [-1.5859, -0.7240, -0.2047,  ...,  0.5948,  3.3672, -1.3806],\n",
            "        [-0.0354, -3.3880, -3.4080,  ...,  3.8004,  1.3688, -5.1647],\n",
            "        ...,\n",
            "        [ 0.1429, -2.8214, -0.6453,  ...,  2.4480,  3.0166, -5.9390],\n",
            "        [ 0.6069, -0.5337,  0.4500,  ..., -0.0405,  2.5307, -2.0405],\n",
            "        [-3.1434, -2.9645, -1.0062,  ...,  2.1791,  3.6980, -4.8865]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3246, -0.3845, -0.4126,  ...,  0.5443,  3.2260, -3.1948],\n",
            "        [-0.7793, -0.7136,  1.8913,  ..., -1.3302,  3.2359, -2.1525],\n",
            "        [-2.4693,  0.2799,  2.6719,  ..., -1.8600,  3.7020, -4.1848],\n",
            "        ...,\n",
            "        [-2.6617, -1.1096,  0.6399,  ...,  1.5753, -1.8134, -2.6268],\n",
            "        [-1.5863, -1.3812,  1.3540,  ...,  3.0847,  1.8649, -2.1886],\n",
            "        [-2.6662, -2.8228,  2.6905,  ...,  2.1946,  3.0848, -4.3541]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0157, -4.7394,  0.3770,  ...,  4.4838,  1.5944, -6.7485],\n",
            "        [-1.8975, -1.2977,  5.8172,  ..., -0.0313,  3.5575, -3.2380],\n",
            "        [-2.0747,  0.4935,  3.5702,  ...,  0.1589,  0.2939, -2.8721],\n",
            "        ...,\n",
            "        [-2.4751,  1.3307,  2.9332,  ..., -0.6321, -0.6213, -2.4345],\n",
            "        [-3.0452, -3.3538,  0.2992,  ...,  0.4261,  2.5450, -4.7896],\n",
            "        [-2.2621, -2.1941,  2.8395,  ...,  0.8927,  2.6875, -2.8921]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5367,  0.3427,  1.5151,  ..., -0.1080,  2.7025, -2.5884],\n",
            "        [-1.3965,  0.4827,  4.1653,  ...,  1.9761,  0.2478, -3.2796],\n",
            "        [-0.8980, -2.0149,  1.2650,  ..., -0.3547,  7.8221, -3.5955],\n",
            "        ...,\n",
            "        [-2.1605,  0.9025,  4.2361,  ...,  1.0712,  0.2539, -1.8388],\n",
            "        [-1.8369, -1.2975,  2.3108,  ...,  0.6669,  2.1261, -3.5915],\n",
            "        [-2.5749,  1.0393,  0.3534,  ..., -0.6284,  1.8355, -2.5347]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0093, -1.2476,  1.0808,  ...,  3.0783, -0.8039, -2.9078],\n",
            "        [-3.5335, -2.5236,  3.0413,  ...,  2.9561, -0.0200, -3.4118],\n",
            "        [-3.3297, -3.6453,  1.9701,  ...,  2.4095,  1.0818, -4.5738],\n",
            "        ...,\n",
            "        [-0.2447, -2.3507,  1.2119,  ..., -1.0586,  4.5951, -3.7689],\n",
            "        [-2.0046, -3.1743, -0.2816,  ...,  2.9315,  2.7858, -4.2581],\n",
            "        [-0.0113,  0.5562, -0.3491,  ...,  0.5780,  6.4152, -4.1230]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0218, -3.2388, -1.1802,  ...,  2.0551,  7.9011, -5.6451],\n",
            "        [-2.2169, -1.4579,  0.3015,  ...,  0.1866,  2.1581, -2.9687],\n",
            "        [-2.8291, -0.1833,  0.3228,  ..., -0.7219,  2.3225, -3.6446],\n",
            "        ...,\n",
            "        [-1.3732, -3.4816, -1.8887,  ...,  3.0468,  3.8108, -4.7815],\n",
            "        [-3.1847, -0.7002,  1.1822,  ..., -0.8154,  3.2480, -3.4132],\n",
            "        [-0.8162, -0.5180,  0.9977,  ...,  0.9620,  3.4170, -3.5174]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0653, -5.0512, -2.7162,  ...,  2.4906,  4.1435, -5.6215],\n",
            "        [-2.4666,  0.6088,  3.0973,  ...,  1.0574, -0.1116, -1.9850],\n",
            "        [-1.7369, -3.0641,  3.4346,  ..., -1.3787,  7.7756, -3.2836],\n",
            "        ...,\n",
            "        [-1.5764, -3.9036, -1.2900,  ...,  5.2435,  2.9259, -5.2530],\n",
            "        [-1.4526, -2.2329, -1.2048,  ...,  2.9667,  1.6063, -4.6168],\n",
            "        [-2.2485, -3.6461, -0.0303,  ...,  1.5487,  4.4647, -4.8692]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3263, -5.4385, -0.7105,  ...,  5.4571,  3.9631, -6.2086],\n",
            "        [-1.8063, -3.3166, -1.3005,  ..., -0.7498,  5.5926, -3.0388],\n",
            "        [-3.2370, -1.8863,  1.4371,  ...,  1.7062,  1.0021, -3.6555],\n",
            "        ...,\n",
            "        [-2.8198, -2.9088, -1.0072,  ...,  1.0597,  3.2019, -5.4341],\n",
            "        [-0.4250, -2.1730,  0.0409,  ..., -0.3466,  2.4461, -0.4976],\n",
            "        [-2.8607, -0.9269,  3.5002,  ...,  0.1893,  3.1478, -4.5853]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1684e-01, -1.7003e+00, -1.3098e+00,  ...,  3.6627e+00,\n",
            "          1.1257e+00, -3.6641e+00],\n",
            "        [-3.6713e+00, -1.5713e+00,  2.6500e+00,  ...,  1.1079e+00,\n",
            "         -1.1648e+00, -3.1566e+00],\n",
            "        [-2.9609e+00,  3.9004e-01,  2.4055e+00,  ...,  4.7008e-01,\n",
            "          2.0337e-01, -1.4347e+00],\n",
            "        ...,\n",
            "        [-1.5399e+00, -9.0223e-01, -1.8550e-01,  ...,  2.7864e+00,\n",
            "          2.1441e+00, -3.7790e+00],\n",
            "        [-2.9639e+00, -2.6406e-03, -2.2037e+00,  ..., -1.0060e+00,\n",
            "          3.7434e+00, -2.3684e+00],\n",
            "        [-1.4936e+00, -1.4531e+00,  3.8018e+00,  ...,  1.9541e+00,\n",
            "          5.1717e-01, -3.2295e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5759, -1.6146,  2.4891,  ...,  2.2540,  2.0296, -1.8954],\n",
            "        [-2.8324, -1.7630,  2.2525,  ...,  3.2627,  2.1371, -5.6902],\n",
            "        [-2.2907, -2.0055,  1.9026,  ...,  0.3922,  3.7980, -3.3519],\n",
            "        ...,\n",
            "        [-0.9262, -2.3179, -0.5352,  ...,  3.7075,  2.8042, -3.3285],\n",
            "        [-1.1033, -1.8078,  0.7884,  ...,  3.7818,  0.1249, -3.5608],\n",
            "        [-1.6268, -1.8628, -0.7644,  ...,  4.3707,  1.4974, -4.4716]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0348,  0.1180,  0.3610,  ..., -2.4334,  6.7947, -3.2662],\n",
            "        [-1.5606, -4.4581, -1.2794,  ...,  3.9093,  6.0942, -4.7537],\n",
            "        [-3.6079, -0.5491,  1.7802,  ...,  2.6991,  0.5055, -3.6303],\n",
            "        ...,\n",
            "        [-1.7991, -2.2086,  1.5556,  ...,  1.1743,  3.0834, -3.3714],\n",
            "        [-1.9623, -3.0779,  0.0323,  ...,  3.9098,  3.5662, -4.9224],\n",
            "        [-2.7987,  0.0805,  2.2706,  ..., -1.0220,  5.8428, -2.6062]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9879, -2.2375, -3.7863,  ...,  3.2796,  6.6275, -5.1204],\n",
            "        [-0.2667, -2.1818, -0.2345,  ...,  1.9063,  3.4200, -3.9152],\n",
            "        [-2.2803, -1.8382,  0.9759,  ...,  4.3752,  0.7580, -4.2013],\n",
            "        ...,\n",
            "        [ 0.9868,  0.3137, -1.0316,  ..., -3.4078,  7.8423, -2.4591],\n",
            "        [-2.9509, -1.6243,  1.6176,  ..., -0.3443,  1.9709, -3.7402],\n",
            "        [-2.8074,  0.7760,  2.3718,  ..., -0.6853,  3.5748, -2.9558]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5816, -1.8241,  2.3493,  ...,  0.6562,  1.6462, -2.4344],\n",
            "        [-3.0253, -0.8139, -0.8503,  ..., -0.2217,  4.8135, -1.8675],\n",
            "        [ 1.5549, -0.7981, -1.1087,  ..., -0.4993,  2.9214, -2.8802],\n",
            "        ...,\n",
            "        [ 0.3514, -3.0935,  1.1434,  ...,  1.0686,  7.0690, -3.4942],\n",
            "        [-2.0494, -2.1434,  0.9379,  ...,  0.1792,  4.6501, -3.8976],\n",
            "        [ 0.2775, -0.9455, -1.5571,  ..., -0.7473,  4.1326, -0.5883]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6366, -1.1779,  2.5555,  ...,  1.8170,  3.6492, -2.7031],\n",
            "        [-2.3318, -3.6906, -0.1540,  ...,  3.2875,  6.4551, -8.3254],\n",
            "        [ 1.3438, -1.0509, -3.3358,  ...,  0.5126,  0.2519, -2.4230],\n",
            "        ...,\n",
            "        [-1.8764, -0.9928,  3.3924,  ...,  0.0366,  2.7346, -4.6820],\n",
            "        [-2.1526, -2.0747,  2.6339,  ...,  4.1924,  1.8254, -5.0690],\n",
            "        [-3.1698, -1.1674,  3.3792,  ...,  0.7557,  2.0564, -2.5944]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0313,  0.2781,  2.4208,  ...,  1.3972,  5.5312, -3.4878],\n",
            "        [-2.4373, -2.1109,  0.9558,  ...,  0.7814,  4.5367, -3.6283],\n",
            "        [-0.8356, -0.3798, -1.6950,  ...,  2.5048, -0.5380, -5.2143],\n",
            "        ...,\n",
            "        [-1.5435, -0.0446,  3.7745,  ...,  2.5762,  0.8641, -2.9491],\n",
            "        [-3.4927,  1.6204,  1.1294,  ...,  0.2100, -1.2431, -2.4949],\n",
            "        [-2.1412, -2.4124,  0.8318,  ...,  1.4666,  4.1600, -4.4764]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2251, -0.0269,  1.1408,  ...,  0.2461,  2.6249, -2.5835],\n",
            "        [-3.6950, -2.6471, -0.6395,  ...,  1.4275,  0.1376, -3.7380],\n",
            "        [-3.1850, -0.1952, -1.3527,  ...,  0.2908,  5.3271, -1.2758],\n",
            "        ...,\n",
            "        [-2.0177,  0.9409,  3.4634,  ...,  1.4600,  0.5794, -2.8712],\n",
            "        [ 0.5392, -1.3205, -0.4499,  ...,  3.3121,  1.5672, -2.2710],\n",
            "        [-1.6280, -1.3962,  4.0956,  ...,  1.9888,  2.2866, -4.5197]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0606, -2.0583, -1.7195,  ...,  2.2884,  4.0807, -2.3345],\n",
            "        [-3.3163, -1.9127,  1.2330,  ...,  2.6420,  0.5678, -2.9004],\n",
            "        [-2.5151,  1.1582,  3.0908,  ...,  0.7444,  0.0139, -1.7860],\n",
            "        ...,\n",
            "        [ 0.5768, -2.0850, -1.1600,  ...,  4.7886,  2.9692, -3.6615],\n",
            "        [-3.7108,  0.3676,  3.2853,  ..., -3.0461,  1.9835,  0.1730],\n",
            "        [-2.3794, -2.1485, -0.2225,  ...,  3.5768,  3.9229, -6.2478]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5136, -0.5061,  3.8298,  ...,  0.2707,  3.7857, -3.0363],\n",
            "        [-0.5830,  0.7223,  1.8041,  ..., -1.9064,  7.7726, -4.1552],\n",
            "        [-1.5426, -1.6504,  0.5860,  ..., -0.6889,  7.8404, -4.4336],\n",
            "        ...,\n",
            "        [-1.6840, -0.9506,  2.6885,  ..., -0.2735,  4.1216, -1.4652],\n",
            "        [-6.3425, -3.7858,  2.0217,  ...,  3.0499,  1.1943, -4.6941],\n",
            "        [-2.5017, -1.7568, -2.6798,  ...,  0.6574,  4.1549, -3.9496]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7693, -1.5951,  1.2115,  ...,  1.4995,  0.5363, -4.5944],\n",
            "        [-2.3737, -2.6167, -0.2646,  ..., -2.6155,  5.7928, -3.6657],\n",
            "        [-0.9274, -2.5488, -3.0202,  ...,  3.4002,  3.2786, -3.7851],\n",
            "        ...,\n",
            "        [-0.5816,  1.8526, -1.5100,  ..., -3.8149,  6.8760, -1.9696],\n",
            "        [-1.0556, -1.4875, -2.2951,  ...,  2.5313,  3.9392, -3.2461],\n",
            "        [-2.2535, -1.0285,  1.3767,  ...,  0.7897,  0.3774, -3.1421]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0642e+00, -1.9527e+00,  1.4554e+00,  ..., -5.7886e-02,\n",
            "          7.1307e-01, -3.0879e+00],\n",
            "        [-3.3446e+00, -1.3547e+00,  1.5025e-01,  ...,  5.5643e-01,\n",
            "          1.8878e+00, -6.3406e+00],\n",
            "        [-1.4043e+00, -3.2819e-02,  3.3138e+00,  ..., -7.9525e-01,\n",
            "          1.6600e+00, -4.5723e+00],\n",
            "        ...,\n",
            "        [-3.6202e+00,  1.3686e+00,  2.7182e-01,  ...,  2.1090e-01,\n",
            "         -1.5513e+00, -2.0234e+00],\n",
            "        [-1.8523e+00, -4.2114e+00, -1.4654e+00,  ...,  5.0584e+00,\n",
            "          1.9827e+00, -5.9594e+00],\n",
            "        [-3.5731e-03, -1.4308e-01, -9.2715e-01,  ...,  1.4652e+00,\n",
            "          3.0526e+00, -3.1234e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9909, -0.0149,  0.9302,  ...,  4.0854,  1.0096, -3.3282],\n",
            "        [-3.6545,  1.4509,  0.3147,  ..., -0.3584, -1.6293, -2.6713],\n",
            "        [-2.3911, -0.6598,  0.0251,  ...,  0.8380,  0.2313, -1.3901],\n",
            "        ...,\n",
            "        [ 0.4706, -0.8320, -2.7816,  ...,  3.2678,  1.8150, -3.1498],\n",
            "        [-0.3289, -1.3606,  3.4756,  ...,  1.5561,  3.7852, -2.8878],\n",
            "        [-3.5783,  2.2614,  0.6028,  ..., -0.7990, -1.3590, -1.9577]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0225, -2.0545,  2.3845,  ...,  1.2614,  1.0665, -3.9663],\n",
            "        [-2.7024, -1.8311, -0.3046,  ...,  1.5516,  2.5846, -4.4757],\n",
            "        [-2.4461, -1.4650, -1.9203,  ...,  0.1142,  5.7163, -3.3769],\n",
            "        ...,\n",
            "        [-3.2185, -1.4816,  3.3430,  ..., -1.4687,  2.3264, -2.8848],\n",
            "        [-2.3267, -0.6237, -2.5165,  ...,  0.4422,  5.1441, -5.3681],\n",
            "        [-3.8147, -3.4141, -0.8386,  ...,  4.8845,  1.0783, -5.4102]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0004, -0.4777,  1.5686,  ...,  0.4861,  3.5060, -2.5265],\n",
            "        [-1.4775, -0.0950,  2.7380,  ...,  1.3536,  2.4360, -1.9853],\n",
            "        [-0.8446, -1.8958,  2.2384,  ...,  0.1310,  1.1807, -4.8444],\n",
            "        ...,\n",
            "        [-2.1574, -0.4833,  3.1776,  ...,  2.1802,  3.4871, -3.3014],\n",
            "        [-2.9436,  1.5791,  0.7835,  ...,  0.5512,  0.5868, -1.7776],\n",
            "        [-2.4852, -3.2163,  0.3473,  ...,  3.8263,  0.8970, -6.0438]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3557, -4.6846, -0.5766,  ...,  4.3781,  5.3365, -4.1780],\n",
            "        [-0.0359,  0.1540, -0.7192,  ..., -1.1530,  2.3327, -1.2273],\n",
            "        [-2.9061, -0.7806, -1.6558,  ...,  0.1412,  3.7369, -2.3676],\n",
            "        ...,\n",
            "        [-3.8495, -0.5569,  3.7568,  ..., -1.3783,  0.3260, -1.8416],\n",
            "        [-0.8990, -3.6247, -2.4959,  ..., -1.0401,  5.1225, -1.6985],\n",
            "        [-1.8304, -1.5656,  0.3235,  ...,  1.0341,  2.0585, -3.2846]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3488, -1.8297, -0.5084,  ...,  1.0775,  2.6741, -3.3884],\n",
            "        [-1.4380, -1.9781, -1.3159,  ..., -1.5521,  4.7773, -3.9069],\n",
            "        [-1.5055, -0.3105,  2.8409,  ...,  1.6979, -0.3808, -3.1666],\n",
            "        ...,\n",
            "        [-2.3015, -0.0606, -2.6766,  ..., -1.0439,  4.1037, -3.0351],\n",
            "        [-0.8410, -3.2603, -3.2267,  ...,  2.5706,  4.9887, -4.6347],\n",
            "        [-4.0128, -4.4451,  1.1621,  ...,  1.2201,  3.1976, -4.2440]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1669,  1.8240, -1.9011,  ..., -0.9514,  2.8223, -1.2704],\n",
            "        [-3.1702,  1.5873,  1.9798,  ..., -0.5112, -1.4475, -2.2391],\n",
            "        [-1.4800, -0.9940,  1.1693,  ...,  1.2414,  3.6288, -3.5296],\n",
            "        ...,\n",
            "        [-2.8401, -1.1269,  1.2299,  ...,  2.7716, -0.9454, -3.3743],\n",
            "        [-1.0712, -0.1985,  1.3024,  ...,  0.5856,  1.3092, -1.6925],\n",
            "        [-2.0182, -0.5116, -0.2360,  ...,  1.7843,  2.2904, -3.1087]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7980, -1.1725,  1.7955,  ...,  0.8646,  6.9697, -4.8572],\n",
            "        [-4.1331, -1.5690, -1.4401,  ...,  2.1523, -0.0351, -2.9323],\n",
            "        [-2.5801, -0.2368, -0.9581,  ..., -1.1730,  3.0389, -2.3954],\n",
            "        ...,\n",
            "        [-2.9021, -1.8310,  2.2836,  ...,  1.9528,  1.7416, -3.1530],\n",
            "        [-2.3587, -0.1100, -0.2164,  ..., -0.4079,  1.2283, -3.8733],\n",
            "        [-1.5873, -3.3523, -0.5303,  ...,  3.1437, -0.9883, -3.3136]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8639, -0.2372,  3.3277,  ...,  0.9803,  0.6129, -2.6210],\n",
            "        [-1.7995, -1.7490,  4.4728,  ...,  1.8226,  1.6849, -5.9663],\n",
            "        [-1.1104, -1.0226, -1.2224,  ...,  1.9422,  1.0180, -1.7998],\n",
            "        ...,\n",
            "        [-3.7190, -2.4099, -1.2952,  ...,  1.2919,  2.2151, -3.7648],\n",
            "        [-1.1755,  0.6727, -0.8748,  ...,  1.8379,  1.9603, -1.7586],\n",
            "        [-2.8804, -1.5247,  3.0076,  ..., -0.5504,  2.5391, -4.8433]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.0856, -2.5008,  1.6745,  ...,  5.5628,  1.4318, -6.1544],\n",
            "        [-1.2367,  0.5250,  0.4421,  ..., -1.1959,  3.2308, -1.3060],\n",
            "        [-1.2134, -0.8862, -1.5539,  ...,  1.1533,  2.5174, -2.8203],\n",
            "        ...,\n",
            "        [-2.3791, -1.0798, -0.8313,  ...,  0.7391, -1.2482, -2.6576],\n",
            "        [-1.6261, -2.6240, -1.0943,  ...,  1.5426,  3.0290, -3.8066],\n",
            "        [-2.7462, -2.1952,  4.1327,  ...,  1.9221,  2.0130, -5.7502]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4286, -1.5811,  0.1164,  ...,  3.7545, -1.1541, -5.6791],\n",
            "        [-1.8436, -2.1152, -1.6163,  ...,  0.4157, -0.0276, -4.6706],\n",
            "        [-3.3381, -1.4822,  0.6831,  ...,  1.0884,  0.3203, -3.1924],\n",
            "        ...,\n",
            "        [-2.1370, -1.3679,  2.8014,  ...,  1.5627,  0.9626, -4.9040],\n",
            "        [-3.5037, -1.8213,  4.8062,  ...,  0.5419,  1.6184, -4.8315],\n",
            "        [-2.5927, -2.1100, -0.5222,  ...,  1.7234,  2.3049, -5.1592]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6216, -0.7660, -1.9759,  ...,  0.6293,  3.9470, -3.8900],\n",
            "        [-1.7067, -0.0266,  0.8597,  ...,  1.2671,  5.1433, -4.4753],\n",
            "        [-1.4193,  1.2583,  1.1769,  ..., -1.0289,  6.6918, -3.3442],\n",
            "        ...,\n",
            "        [-2.4793, -0.3554,  0.1982,  ...,  0.0160,  5.7058, -3.4165],\n",
            "        [-0.9586, -2.2470,  1.3016,  ...,  4.6011,  0.7700, -5.2967],\n",
            "        [-2.3561,  0.6032,  4.1771,  ..., -0.0190,  2.3299, -2.5198]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1285, -1.1721,  2.4559,  ...,  0.5027,  2.3950, -4.4081],\n",
            "        [-0.2261, -4.1577, -2.7573,  ...,  4.7135,  2.5913, -3.9725],\n",
            "        [-3.3565, -0.8007,  0.6804,  ...,  2.9444,  0.6692, -1.9298],\n",
            "        ...,\n",
            "        [-1.6847,  0.9513,  1.1826,  ...,  1.9984,  4.5741, -4.0258],\n",
            "        [-3.2921,  0.8898,  0.9549,  ...,  0.0263,  4.7048, -4.8226],\n",
            "        [-3.2865,  1.5840,  2.5421,  ..., -0.7394, -0.8792, -2.0259]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1836,  1.3277, -1.0284,  ..., -0.7297,  1.5989, -2.0630],\n",
            "        [-4.2010,  1.5344,  0.6104,  ..., -1.1488,  3.8718, -4.2354],\n",
            "        [-2.8212, -2.8518,  1.2652,  ..., -1.2253,  3.4363, -1.4827],\n",
            "        ...,\n",
            "        [-2.4530, -2.1929, -0.7904,  ...,  2.8400,  0.2754, -4.4785],\n",
            "        [-1.4119, -1.7078,  4.4577,  ...,  0.0800,  3.7292, -3.4780],\n",
            "        [-0.2845, -2.9990, -1.8453,  ...,  3.6867,  0.2974, -4.6525]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0650, -1.3097, -3.3775,  ...,  0.4062,  2.3853, -2.8788],\n",
            "        [-3.0049,  0.8991,  0.0521,  ..., -1.2263,  2.8507, -1.7227],\n",
            "        [-1.0914, -0.8283,  3.6309,  ...,  1.6391,  0.0288, -3.3195],\n",
            "        ...,\n",
            "        [-1.8378, -0.3609,  3.7824,  ...,  0.3474,  5.2327, -3.2398],\n",
            "        [-3.1354, -3.9333, -2.6611,  ...,  3.9684,  1.1951, -5.2276],\n",
            "        [-1.4987, -1.5670, -3.6077,  ...,  2.8227,  1.3529, -3.7893]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7748, -1.9273, -0.5942,  ...,  5.1439,  1.6095, -5.6185],\n",
            "        [-2.8425,  3.1232, -0.7874,  ...,  0.0631,  3.6344, -2.2026],\n",
            "        [-3.2141, -0.6767,  0.4280,  ..., -0.2564,  4.5555, -4.8086],\n",
            "        ...,\n",
            "        [-0.6304, -3.6227, -1.6860,  ...,  0.8647,  6.9320, -3.8124],\n",
            "        [ 0.0872,  0.1221, -1.6202,  ...,  0.8944,  5.1671, -4.2539],\n",
            "        [-1.2599, -0.6048, -2.5735,  ..., -1.8362,  4.0738, -5.3378]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6538, -0.9141, -4.5565,  ..., -0.4562,  2.4091, -3.9193],\n",
            "        [-3.4815, -0.8577,  0.7834,  ..., -1.4798,  2.8537, -4.3195],\n",
            "        [-1.4142, -3.8343, -1.1397,  ...,  6.4747, -1.2346, -5.8329],\n",
            "        ...,\n",
            "        [-2.4718, -1.7099,  4.5224,  ...,  0.8567,  5.8041, -4.4156],\n",
            "        [-3.2075, -0.6803,  2.2988,  ..., -0.3885,  3.3590, -3.3991],\n",
            "        [-3.7101, -2.2288,  2.9023,  ..., -2.2321,  5.5440, -6.0379]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2841, -1.9614,  5.5287,  ..., -1.0122,  4.9769, -4.0846],\n",
            "        [-2.5354,  0.1802,  2.4231,  ..., -0.7829,  3.8950, -4.7883],\n",
            "        [-3.4732, -0.8770, -0.1485,  ...,  0.8985,  3.6177, -4.9483],\n",
            "        ...,\n",
            "        [-2.3181, -0.5205,  1.3990,  ..., -0.5932,  5.6849, -3.7802],\n",
            "        [-1.0022, -2.5997,  0.1346,  ...,  1.0833,  4.0802, -2.1136],\n",
            "        [-2.2546,  1.0092,  2.3208,  ..., -0.7909,  2.8202, -2.3504]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8899, -2.4326, -2.6073,  ...,  0.6743,  2.3990, -3.9113],\n",
            "        [-1.6751, -0.1009, -0.8876,  ...,  1.8216,  1.1718, -2.1645],\n",
            "        [-2.0800, -0.7822,  0.7468,  ...,  2.2598,  1.4051, -4.5266],\n",
            "        ...,\n",
            "        [-2.2284, -0.0145,  2.9133,  ..., -0.8251,  2.1685, -3.1197],\n",
            "        [-3.2020, -1.6259, -0.3142,  ..., -1.8102,  2.9475, -3.7092],\n",
            "        [-1.7574, -1.6074, -1.4772,  ..., -0.1674,  6.2075, -4.7835]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0203, -1.3099,  1.0603,  ...,  2.1240,  0.0614, -2.9068],\n",
            "        [-3.0540,  0.1432,  0.9530,  ..., -0.4036,  2.0765, -2.7679],\n",
            "        [-0.3534, -2.3188, -3.9648,  ...,  5.6748,  1.4728, -3.4414],\n",
            "        ...,\n",
            "        [-1.6518,  1.3445,  0.3257,  ..., -0.5007,  1.7910, -1.2095],\n",
            "        [-2.5767, -3.2858, -1.3443,  ...,  0.8796,  2.8004, -5.4576],\n",
            "        [-2.6000,  1.5351,  2.8814,  ..., -0.2659, -0.1216, -1.9847]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8188, -1.4848,  0.8604,  ...,  1.3386, -0.4211, -2.3867],\n",
            "        [-2.7779, -1.1939,  2.7815,  ..., -0.5932,  3.7240, -2.9650],\n",
            "        [-0.9810, -1.4737,  0.7934,  ...,  1.6890,  0.1049, -2.8965],\n",
            "        ...,\n",
            "        [-2.4610,  1.5737,  2.4612,  ..., -0.4208, -1.0308, -2.1006],\n",
            "        [-1.1023,  0.4853,  4.0191,  ..., -1.3889,  2.4567, -3.7519],\n",
            "        [ 0.5601,  4.1630, -0.7734,  ..., -2.8881,  5.0193, -0.2535]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7963, -0.4693,  0.3839,  ..., -1.2347,  3.4901, -5.8912],\n",
            "        [ 0.4209, -0.0957,  0.9998,  ..., -1.1554,  2.3057, -1.2309],\n",
            "        [-3.1872, -0.9661,  1.0103,  ..., -0.3392,  2.5898, -3.2730],\n",
            "        ...,\n",
            "        [-1.5942, -1.2083, -2.1547,  ...,  3.9993, -1.8424, -4.3983],\n",
            "        [-1.7198, -1.2813,  1.0552,  ...,  0.0078,  3.9084, -6.8187],\n",
            "        [-0.7350, -0.2425,  1.4753,  ..., -0.0699,  4.9157, -1.6774]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6888,  0.9934,  2.8136,  ..., -1.0826,  4.6139, -2.7622],\n",
            "        [-2.2889, -2.1265,  1.4614,  ...,  0.0149,  2.2183, -4.4284],\n",
            "        [-1.7370, -2.1194, -2.9304,  ...,  2.5796,  4.3326, -4.4008],\n",
            "        ...,\n",
            "        [-2.9398, -1.4453,  1.4721,  ..., -2.7693,  6.7305, -3.3249],\n",
            "        [-2.9398,  1.8562,  0.5760,  ..., -1.7314,  0.8883, -3.3249],\n",
            "        [ 0.8289, -0.2064, -0.7736,  ..., -0.5143,  3.1379, -3.7792]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4426, -1.2977,  1.8896,  ..., -1.0484,  5.3143, -5.3876],\n",
            "        [-2.6785, -1.5741,  2.8802,  ...,  0.5904,  5.1664, -3.9879],\n",
            "        [-1.6450, -0.2409, -1.5646,  ...,  0.0318,  1.9416, -0.6316],\n",
            "        ...,\n",
            "        [-3.0782, -0.0299, -1.5692,  ...,  0.0720,  1.8031, -3.8558],\n",
            "        [-4.4323,  0.2885,  0.6549,  ...,  0.0629,  0.6981, -3.0497],\n",
            "        [-3.3431,  1.4655,  1.3853,  ..., -1.4370,  0.6879, -1.7318]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1672,  0.0499, -3.1150,  ..., -1.7392,  7.2067, -2.3154],\n",
            "        [-1.4464,  2.3023, -1.8174,  ...,  0.7236,  1.8481, -2.6866],\n",
            "        [-1.1133,  1.4350,  2.0337,  ..., -2.4813,  2.3247, -4.7414],\n",
            "        ...,\n",
            "        [-0.3703,  0.9816, -1.0678,  ..., -0.3739,  6.7749, -4.2250],\n",
            "        [ 0.8365, -2.8883,  3.5091,  ..., -2.1592,  3.1120, -3.4990],\n",
            "        [-1.0009, -0.6559,  4.6782,  ...,  0.2353,  0.5015, -4.0713]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1652, -1.6749, -2.0701,  ...,  2.1283,  0.3195, -4.8705],\n",
            "        [-0.2864, -3.1192, -1.4728,  ...,  3.2824,  1.6830, -3.9202],\n",
            "        [-1.9351, -1.0270,  1.5742,  ...,  1.5345, -1.7372, -4.1027],\n",
            "        ...,\n",
            "        [-2.4762, -0.5399,  2.9936,  ..., -0.3790,  1.9038, -3.4828],\n",
            "        [ 0.6993, -3.7057, -3.5421,  ...,  3.8712,  1.3029, -3.8437],\n",
            "        [-2.1697, -1.9462,  3.0438,  ..., -0.4768,  3.6996, -2.9710]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6903,  3.9259,  1.0131,  ..., -1.9191,  5.1882, -0.0163],\n",
            "        [-0.5191,  1.4743,  0.7963,  ..., -2.1775,  4.1014, -0.3883],\n",
            "        [ 0.2078, -0.2307, -1.8291,  ...,  0.5632,  6.9877, -3.2110],\n",
            "        ...,\n",
            "        [-1.5726,  0.4403, -0.3412,  ..., -1.0760,  5.2351, -4.7839],\n",
            "        [-1.5949, -1.9065,  0.1457,  ..., -0.0951,  1.4003, -4.0038],\n",
            "        [-0.7571, -0.8617,  2.0026,  ...,  0.4635,  3.5290, -3.8701]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5925, -1.3633,  0.1362,  ...,  0.0479,  3.5243, -6.1246],\n",
            "        [-1.2357, -2.4061, -2.6366,  ...,  2.2869,  0.2828, -4.4125],\n",
            "        [-2.1372, -0.1750,  3.7625,  ..., -0.3241, -0.4293, -4.2300],\n",
            "        ...,\n",
            "        [-3.5187, -0.8169,  1.3110,  ...,  0.8193,  2.6080, -3.0168],\n",
            "        [-1.2342,  1.9181,  1.4092,  ...,  0.0431,  5.6827, -1.7078],\n",
            "        [ 1.0963, -1.5089,  2.0551,  ..., -0.5148,  5.8594, -3.9023]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0749, -3.4402, -1.0513,  ...,  5.7135,  4.8911, -5.0581],\n",
            "        [-1.3537, -0.0438, -0.8672,  ...,  0.6899, -0.1085, -1.8460],\n",
            "        [-2.3757,  2.7136,  0.7398,  ..., -2.1153,  3.9029, -1.6249],\n",
            "        ...,\n",
            "        [-0.1000, -1.3855,  2.8852,  ...,  0.3872,  3.3660, -4.8225],\n",
            "        [-2.0783, -0.4358, -0.6622,  ...,  2.0092,  3.8003, -1.5616],\n",
            "        [-3.2375, -1.8473,  0.2721,  ...,  3.9599,  1.4443, -4.2244]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9570e-01, -4.0256e-01,  3.8899e+00,  ..., -2.7769e+00,\n",
            "          3.8066e+00, -3.8017e+00],\n",
            "        [-9.7864e-01, -2.2196e+00, -7.4979e-01,  ...,  4.5478e+00,\n",
            "          1.9096e+00, -3.6713e+00],\n",
            "        [-1.5023e+00, -1.1652e-03, -2.5975e-01,  ..., -2.4911e+00,\n",
            "          4.0374e+00, -1.9853e+00],\n",
            "        ...,\n",
            "        [ 2.7969e+00,  1.4347e+00, -7.0734e-01,  ..., -1.4891e+00,\n",
            "          4.8028e+00, -1.8967e+00],\n",
            "        [-2.4323e+00, -1.5010e+00,  1.5029e+00,  ...,  8.1798e-02,\n",
            "          4.4444e+00, -4.4062e+00],\n",
            "        [-2.3736e+00, -1.0817e+00,  1.4675e+00,  ..., -1.8159e+00,\n",
            "          4.1923e+00, -4.4457e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5250, -2.0238, -1.1439,  ...,  1.5395,  5.0470, -6.7948],\n",
            "        [-2.6393, -0.7042,  2.7154,  ..., -0.2371,  1.1181, -2.5937],\n",
            "        [ 1.1898, -1.5762, -0.8051,  ...,  3.4040,  2.1988, -1.1013],\n",
            "        ...,\n",
            "        [-2.8618,  1.0842,  1.1099,  ..., -0.7897, -0.4944, -2.4960],\n",
            "        [-2.9796,  1.0020,  0.3423,  ...,  0.2671,  4.7680, -3.1736],\n",
            "        [-1.8747, -0.8363, -0.2259,  ...,  1.2636,  0.8236, -2.6081]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9571, -2.0530, -2.2928,  ...,  0.1472,  1.3979, -3.6178],\n",
            "        [-3.3409, -1.6431,  0.5992,  ...,  0.5878,  1.9361, -3.2940],\n",
            "        [-2.7429, -0.5604,  2.3527,  ..., -1.5765,  3.1019, -2.6062],\n",
            "        ...,\n",
            "        [-2.5852, -1.8146,  1.4084,  ...,  0.5597,  4.5964, -2.2896],\n",
            "        [-3.3777, -0.9157, -2.3642,  ..., -0.1647,  4.4941, -5.3011],\n",
            "        [-3.5881, -2.3601,  0.9995,  ...,  2.1787,  1.1876, -1.3040]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5242, -0.8888,  2.6812,  ..., -0.9970,  2.4875, -3.6537],\n",
            "        [-2.9824, -2.1714, -2.1459,  ...,  3.0153,  1.6524, -4.4769],\n",
            "        [-3.1281,  1.1746,  3.3592,  ..., -0.0638,  0.3969, -1.3013],\n",
            "        ...,\n",
            "        [-1.4025,  1.3326,  1.1300,  ...,  1.5368,  3.4648, -2.8590],\n",
            "        [-0.9560, -1.2683,  3.9359,  ..., -1.4342,  6.3341, -3.6316],\n",
            "        [-2.4290, -2.2312, -1.8778,  ...,  2.0368,  4.4031, -3.6200]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1969, -0.6804,  0.5709,  ..., -2.7693,  1.4811, -1.7287],\n",
            "        [-3.0270, -1.0690,  1.7123,  ..., -0.8434,  4.7931, -4.6448],\n",
            "        [-0.6959, -0.6593, -1.1812,  ..., -0.5742,  2.3217, -1.3129],\n",
            "        ...,\n",
            "        [-1.5572,  4.7210, -0.1330,  ..., -1.8077,  6.4471, -1.1804],\n",
            "        [-1.5750,  0.4650,  3.0110,  ..., -0.6443,  6.8540, -1.3318],\n",
            "        [-2.1662, -1.0449,  0.7188,  ...,  0.6240,  2.0024, -5.4014]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9396, -2.0832,  1.7990,  ...,  1.5491,  6.1414, -3.9639],\n",
            "        [-1.5492,  1.6727,  0.6040,  ...,  0.4624, -0.9648, -2.5462],\n",
            "        [-2.2722, -1.5730, -0.0553,  ...,  0.9944,  0.5511, -4.3076],\n",
            "        ...,\n",
            "        [-2.0948, -0.4645,  1.2416,  ...,  0.3169,  1.2341, -5.0141],\n",
            "        [-2.9934, -3.8426,  0.0583,  ...,  0.4033,  2.5928, -4.3321],\n",
            "        [-2.7996, -1.8034,  1.0583,  ..., -1.1061,  7.3740, -3.6625]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6945, -0.5554,  3.5295,  ...,  0.2261,  4.4871, -3.7807],\n",
            "        [-0.5887, -2.6363, -0.1152,  ...,  3.5366,  0.8194, -6.4022],\n",
            "        [-2.0506,  1.2249, -0.1946,  ..., -0.0178, -1.1977, -2.9598],\n",
            "        ...,\n",
            "        [-1.9056,  0.2533,  2.2659,  ..., -0.3714,  2.8100, -3.3474],\n",
            "        [-1.2922, -0.6034,  4.5200,  ..., -0.2527,  3.4908, -2.5737],\n",
            "        [-0.9120, -1.5399,  2.8320,  ..., -0.2379,  2.5274, -2.7307]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8464, -2.5975, -2.5510,  ...,  4.3776,  3.6788, -5.7962],\n",
            "        [-2.9574, -1.4924, -2.1822,  ...,  3.1068,  5.2199, -5.7667],\n",
            "        [-0.9673,  0.6932,  0.7161,  ...,  0.4070,  2.9017, -3.4759],\n",
            "        ...,\n",
            "        [-1.4435, -1.9664,  4.4773,  ..., -1.2476,  4.0494, -3.7110],\n",
            "        [-2.0862,  1.5849,  3.0255,  ..., -0.1414, -0.7923, -2.2897],\n",
            "        [-1.4691,  2.7591,  1.1477,  ..., -1.6551,  5.8076, -3.0919]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9367, -1.0032, -3.1207,  ..., -0.1252,  1.8512, -4.3832],\n",
            "        [-0.3824, -1.3343,  0.3465,  ...,  0.5143,  2.2479, -4.5921],\n",
            "        [-3.7166, -1.2093,  2.0744,  ..., -1.1496,  4.0552, -3.3402],\n",
            "        ...,\n",
            "        [ 0.1601, -3.9262, -3.0593,  ...,  5.3396,  2.0366, -3.6999],\n",
            "        [-2.1766, -0.2127,  0.5962,  ...,  0.0745, -1.4801, -3.1792],\n",
            "        [-2.1094, -0.2916,  3.4384,  ...,  0.1282,  1.1954, -3.5272]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3646,  0.5956,  2.2852,  ...,  0.0554, -0.6750, -3.9353],\n",
            "        [-0.8268,  0.8114,  1.1910,  ..., -2.7373,  2.3930, -2.9979],\n",
            "        [-1.6945,  0.2355,  0.9913,  ...,  2.2801,  0.7484, -2.6184],\n",
            "        ...,\n",
            "        [-0.6631, -2.5602, -0.6859,  ...,  3.4908, -0.8478, -3.8065],\n",
            "        [-4.2868, -1.8926,  1.3654,  ...,  3.4483,  0.2583, -5.4865],\n",
            "        [-1.5601, -0.1720, -1.7107,  ..., -1.4225,  2.5392, -7.0430]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8758, -2.0172,  2.0584,  ...,  1.1760,  2.1878, -4.6013],\n",
            "        [-0.1024, -3.7226, -3.5842,  ...,  2.5993,  7.0405, -4.6888],\n",
            "        [-0.1756, -1.2461,  0.4263,  ...,  0.9433,  0.6942, -4.6641],\n",
            "        ...,\n",
            "        [-0.9443, -1.7816,  3.8501,  ...,  0.7549, -0.2116, -3.7154],\n",
            "        [-0.7160, -1.8128, -3.8502,  ..., -3.0682,  5.8871, -3.0415],\n",
            "        [ 0.0835, -2.3815,  0.8969,  ..., -1.8329,  4.5508, -2.5476]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7927, -2.2580,  3.3069,  ...,  0.5566,  2.6812, -6.0588],\n",
            "        [ 1.6415, -2.1296, -1.8645,  ...,  4.1340,  2.9515, -5.6881],\n",
            "        [-0.1774,  3.1280, -2.6139,  ..., -2.7724,  9.2556, -4.0200],\n",
            "        ...,\n",
            "        [ 1.1846,  1.0373, -1.8290,  ...,  0.1648,  6.9560, -2.8944],\n",
            "        [ 0.6835, -3.9745, -3.7282,  ...,  5.2237,  0.1187, -2.6356],\n",
            "        [-3.2323, -0.5341,  0.7057,  ..., -2.0341,  3.3779, -4.1969]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2746, -1.0600,  1.2141,  ...,  0.2011,  5.7588, -4.3709],\n",
            "        [-1.2470, -2.3504, -0.4992,  ..., -0.1393,  7.1462, -5.2884],\n",
            "        [-2.1238, -2.5709,  0.2776,  ...,  2.8298,  4.6427, -5.4343],\n",
            "        ...,\n",
            "        [-0.3300,  0.5246, -2.3558,  ..., -3.3769,  4.4580, -1.4504],\n",
            "        [-0.3355, -1.6369, -2.0303,  ..., -0.2981,  3.9905, -1.9275],\n",
            "        [-3.1266, -1.2471,  2.7633,  ...,  0.1782,  2.6958, -2.2780]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4067, -3.6602,  0.3170,  ...,  1.9847,  1.0078, -5.8813],\n",
            "        [-2.7670, -4.7097, -1.9225,  ...,  0.9953,  1.6521, -4.4911],\n",
            "        [-1.6495, -0.8094,  5.0034,  ..., -0.1947,  1.7328, -3.7723],\n",
            "        ...,\n",
            "        [-1.8494,  1.1756,  0.2265,  ..., -0.6014,  4.6391, -3.1833],\n",
            "        [-3.5502,  0.3926,  1.3527,  ..., -1.6762,  0.5446, -3.2630],\n",
            "        [-1.4215, -1.4541, -1.8308,  ..., -1.9143,  4.7987, -3.2769]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5925, -1.1858,  3.5401,  ..., -0.4491,  2.1861, -4.5598],\n",
            "        [-4.8432, -1.6574,  0.2935,  ...,  1.9523, -1.8396, -1.8739],\n",
            "        [ 0.2399, -1.6102,  0.7204,  ...,  1.5456,  5.7090, -2.0472],\n",
            "        ...,\n",
            "        [-0.5901, -1.0260, -1.6397,  ...,  0.3573,  4.1132, -5.3060],\n",
            "        [-3.3744,  0.0661, -1.2335,  ..., -1.1186,  2.1894, -2.1740],\n",
            "        [-1.1115, -2.7857, -1.6665,  ...,  3.2549,  0.2245, -4.5131]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9157, -3.4251, -0.4438,  ...,  1.3713,  0.9967, -3.5168],\n",
            "        [-1.4082, -1.8135,  2.0496,  ...,  0.5543,  0.5421, -4.3664],\n",
            "        [-2.0602, -1.2779, -0.6681,  ..., -2.9529,  4.5350, -5.2523],\n",
            "        ...,\n",
            "        [ 0.4282, -1.3781, -2.3317,  ...,  0.7464,  7.3350, -3.7603],\n",
            "        [-1.1592, -0.0422,  0.3257,  ..., -2.5926,  4.1165, -1.7147],\n",
            "        [-3.3051,  1.1668, -0.5279,  ..., -0.6327, -1.9575, -3.0428]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5298, -2.1742,  1.5641,  ...,  1.8625,  1.0399, -4.3851],\n",
            "        [-2.3244, -3.6593, -3.4868,  ...,  3.8154, -0.5622, -5.4096],\n",
            "        [-2.1176, -2.4626,  3.6117,  ..., -0.3886,  2.0721, -3.0120],\n",
            "        ...,\n",
            "        [-1.8612, -3.7741, -0.2296,  ...,  1.7458,  1.8996, -2.4376],\n",
            "        [-4.1494, -0.2696,  2.0741,  ...,  0.5932,  0.6013, -3.7277],\n",
            "        [-0.0996, -1.8040, -2.1039,  ..., -3.2385,  6.6955, -4.7645]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0996,  0.3840,  1.7474,  ..., -1.1205,  5.4974, -3.6713],\n",
            "        [-0.4657, -0.5581,  0.6802,  ...,  0.9991, -0.6344, -3.0402],\n",
            "        [-0.2991, -4.2079,  1.1685,  ...,  5.5610,  0.5002, -3.6789],\n",
            "        ...,\n",
            "        [-1.2757, -2.0852,  3.0140,  ...,  1.0651, -0.8298, -3.3993],\n",
            "        [-0.8304, -0.3869, -0.4338,  ...,  3.5059,  4.4642, -1.0500],\n",
            "        [-0.3981, -2.9912, -1.0873,  ..., -0.4389,  2.6272, -4.2620]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8960,  3.4629, -0.9658,  ..., -1.3670,  4.3122, -1.9242],\n",
            "        [-1.5882, -2.5420,  3.2954,  ...,  0.4163,  1.0766, -2.2360],\n",
            "        [-2.8348, -2.4017, -1.7751,  ..., -0.2234,  2.9636, -6.7124],\n",
            "        ...,\n",
            "        [-1.2496, -2.5549, -0.8451,  ..., -0.1828,  3.8273, -2.5289],\n",
            "        [-2.7465, -1.2161,  2.3107,  ..., -5.6234,  5.5125, -4.7380],\n",
            "        [-0.5814, -0.1263,  1.3361,  ..., -0.5278,  4.3727, -2.8062]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3101, -1.2529,  1.9894,  ..., -1.0461,  4.8378, -3.0688],\n",
            "        [-2.0115, -3.2597, -2.8879,  ...,  2.7097,  4.8275, -2.7961],\n",
            "        [-3.4927,  0.3668,  1.3136,  ..., -1.5927,  3.0639, -1.5969],\n",
            "        ...,\n",
            "        [-1.4675, -0.8658,  2.2658,  ..., -0.3304,  0.8077, -2.3984],\n",
            "        [-2.1507, -2.3986,  1.4756,  ..., -0.6588,  2.1218, -2.7452],\n",
            "        [-3.1038, -3.5974, -1.8868,  ...,  0.3675, -0.1433, -6.0527]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2843, -1.7566, -0.4385,  ...,  1.3001,  0.0149, -2.7011],\n",
            "        [-1.8915, -1.5582,  0.7324,  ..., -0.6657,  1.9520, -4.2327],\n",
            "        [-2.5479, -0.8788, -0.0611,  ...,  0.2237,  2.0094, -2.5484],\n",
            "        ...,\n",
            "        [-2.3645, -1.5386,  1.7323,  ..., -0.6372,  2.5341, -3.8374],\n",
            "        [-2.3806, -2.9361,  2.1267,  ..., -0.5389,  2.4322, -7.7319],\n",
            "        [-1.9623, -1.9356,  0.1225,  ...,  0.2176,  1.2295, -2.3127]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.4259, -2.6631, -0.1125,  ..., -0.7765,  1.4787, -3.8834],\n",
            "        [-2.1408, -1.6714,  0.8969,  ..., -2.6280,  3.3562, -5.5691],\n",
            "        [ 0.2762, -0.1136, -2.7852,  ...,  2.5034,  5.6750, -3.1490],\n",
            "        ...,\n",
            "        [-0.7322, -2.2013, -3.0289,  ...,  3.6732,  1.0774, -5.1680],\n",
            "        [ 1.0242, -0.4428, -1.6464,  ...,  1.2843,  2.9694, -4.8045],\n",
            "        [-2.2757, -0.4524,  1.3130,  ..., -1.9359,  2.2493, -5.1353]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0671,  0.8355,  0.1468,  ...,  1.3598,  2.4750, -4.7828],\n",
            "        [-2.4988, -1.2040, -0.7985,  ..., -2.3217,  3.4534, -2.5084],\n",
            "        [-0.5806, -1.1211,  3.5464,  ..., -4.2551,  2.9035, -3.0294],\n",
            "        ...,\n",
            "        [-0.4682, -1.2258,  2.3162,  ...,  1.1237,  5.8411, -5.6298],\n",
            "        [-1.1088, -2.0841,  2.3055,  ...,  0.7235,  0.7565, -4.1241],\n",
            "        [-1.8198,  0.2565,  1.4336,  ...,  0.3761,  0.9427, -3.8236]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8430, -4.7009, -2.4714,  ...,  5.1447,  0.2406, -4.4989],\n",
            "        [-1.4435, -1.6144,  0.7596,  ..., -1.4682,  2.8529, -1.5422],\n",
            "        [-1.7794, -2.2811, -1.1875,  ...,  4.1471,  0.4558, -4.2329],\n",
            "        ...,\n",
            "        [-1.1398, -1.6174, -0.9357,  ..., -0.8239,  4.9101, -2.5460],\n",
            "        [-2.6669, -1.3932, -1.9093,  ...,  1.0493,  2.3139, -2.8958],\n",
            "        [-2.8630,  0.3198, -0.2447,  ..., -0.6746,  0.5171, -1.6646]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0960,  0.0335, -0.8429,  ...,  2.1855,  4.1528, -3.4789],\n",
            "        [-2.2790, -1.5828, -0.7739,  ...,  0.2497,  2.8229, -4.3569],\n",
            "        [-3.0957, -3.9249,  2.7112,  ..., -0.0566,  5.5445, -3.4648],\n",
            "        ...,\n",
            "        [-2.2975, -2.6387, -1.6459,  ...,  4.0270,  0.7360, -5.4688],\n",
            "        [-4.3808, -3.5536, -0.8319,  ...,  4.5675,  1.6809, -5.5243],\n",
            "        [ 0.6359, -0.0474, -0.9360,  ...,  1.3175,  2.1316, -2.8181]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2debff0803204027bff3c57eb38d8f6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8878,  1.5030, -3.8139,  ...,  0.9021,  6.2306, -3.7213],\n",
            "        [-3.1904, -3.7035,  1.9368,  ..., -1.2036,  3.1625, -2.2736],\n",
            "        [-1.3049, -2.2190,  4.5997,  ..., -0.5383,  3.6115, -3.1990],\n",
            "        ...,\n",
            "        [-2.0923, -2.9039,  2.8553,  ..., -1.4693,  5.4003, -4.7540],\n",
            "        [-1.8942, -3.2763,  3.3881,  ...,  4.7722,  1.5163, -3.6152],\n",
            "        [-1.9865, -0.2954, -0.2918,  ..., -2.2306,  3.4686, -3.2119]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2964, -1.1211, -2.1993,  ...,  1.3312,  3.0603, -3.0751],\n",
            "        [-3.1151,  0.3096, -0.0430,  ..., -1.8688,  4.3983, -4.1348],\n",
            "        [ 0.6850, -3.6995, -1.5074,  ...,  4.8597,  1.1651, -5.8044],\n",
            "        ...,\n",
            "        [-1.7724, -2.4189,  2.5375,  ...,  0.2919,  0.6525, -4.5293],\n",
            "        [-1.9246,  2.1987, -0.1565,  ..., -0.8820,  4.0651, -3.4194],\n",
            "        [ 0.7232, -0.6212, -2.0803,  ...,  1.9188,  3.7361, -3.4563]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9616, -1.2388, -1.4428,  ...,  2.2848,  3.0943, -3.3768],\n",
            "        [-2.8854,  0.4724,  3.0690,  ..., -0.2327, -0.7643, -2.7746],\n",
            "        [-3.9342,  0.3832,  1.9933,  ..., -1.1368,  2.1024, -5.1463],\n",
            "        ...,\n",
            "        [-0.6295, -1.4895, -2.0716,  ..., -1.6539,  5.0621, -2.6315],\n",
            "        [-3.3694, -2.1607,  0.4555,  ...,  1.3888,  0.8960, -2.8110],\n",
            "        [-2.9812, -3.3059,  0.0665,  ...,  0.1512,  1.0056, -2.9700]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2558, -0.5953,  1.6777,  ..., -3.8266,  5.4841, -2.8587],\n",
            "        [-2.5953, -1.1311,  2.6960,  ...,  0.8690,  3.1035, -2.6036],\n",
            "        [-2.4368, -0.3388,  0.2827,  ...,  0.2500,  4.5671, -3.4510],\n",
            "        ...,\n",
            "        [-2.0195, -0.9996, -2.5513,  ..., -0.7914,  2.6375, -2.3637],\n",
            "        [-2.5731, -3.4848,  0.7548,  ...,  1.7371, -0.1151, -4.9372],\n",
            "        [-1.2407, -3.7138, -2.5519,  ...,  1.2691,  1.5250, -4.2726]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0063,  0.0528,  2.8329,  ..., -0.0898,  3.7987, -2.9926],\n",
            "        [-2.2754, -0.8664,  0.9293,  ..., -0.6554,  2.5446, -2.8753],\n",
            "        [-3.5213, -1.4137, -1.3281,  ..., -1.8455,  2.4623, -4.3416],\n",
            "        ...,\n",
            "        [-2.6402, -1.5900, -1.0641,  ...,  0.4535, -1.1778, -3.5927],\n",
            "        [-1.5430, -2.5560, -1.0180,  ...,  4.4081,  0.7544, -5.0858],\n",
            "        [-2.2844, -0.4888,  1.7619,  ..., -1.2114,  5.1593, -4.5744]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3454,  1.3430, -2.4507,  ...,  1.8831,  2.5470, -2.1553],\n",
            "        [-3.4564,  0.4077,  0.0518,  ..., -0.5474,  1.9378, -3.9074],\n",
            "        [ 0.3107, -0.3489,  0.8599,  ..., -0.8817,  2.0740, -1.1591],\n",
            "        ...,\n",
            "        [-1.2263,  3.4515, -3.4360,  ...,  0.4327,  4.5615, -3.4870],\n",
            "        [-1.9054, -2.5037,  0.3705,  ...,  4.5914, -1.3554, -3.4887],\n",
            "        [-1.0179, -4.1709, -1.7783,  ...,  2.2414,  5.7435, -6.8093]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8147, -3.4769,  1.3401,  ...,  4.5382,  1.3837, -5.9793],\n",
            "        [-0.4423, -2.5227,  0.9883,  ...,  1.8920,  0.2676, -4.3261],\n",
            "        [-2.0501, -0.5943, -1.3848,  ..., -2.6692,  4.4048, -3.1449],\n",
            "        ...,\n",
            "        [ 0.1081, -2.2237,  3.3733,  ...,  0.4200,  4.5630, -3.5079],\n",
            "        [-3.0717, -1.6517, -0.9049,  ..., -1.0193,  3.0906, -3.5367],\n",
            "        [-3.5693,  0.6839,  1.2970,  ..., -1.8857, -2.2533, -2.7742]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3663, -2.2830,  4.4292,  ..., -0.7682,  3.8225, -3.4103],\n",
            "        [-2.3234, -2.5188, -1.3400,  ...,  4.1797,  0.2422, -5.4601],\n",
            "        [-2.8826, -3.1159, -0.6897,  ...,  1.2954,  2.2973, -3.7736],\n",
            "        ...,\n",
            "        [-4.4056, -1.3801,  1.8704,  ..., -1.4379,  3.5591, -3.3206],\n",
            "        [-2.4310, -1.6377, -0.6870,  ...,  1.7741,  3.0953, -2.2208],\n",
            "        [-1.7975, -3.1770,  1.8801,  ...,  2.9483,  0.2307, -2.0216]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0532,  0.0636,  0.2481,  ..., -4.1760,  7.9197, -2.3797],\n",
            "        [-2.4236, -2.0678, -2.1955,  ...,  2.0079,  3.2292, -3.3972],\n",
            "        [-0.2503, -1.7643,  0.9892,  ..., -1.9188,  0.3130, -4.8266],\n",
            "        ...,\n",
            "        [-4.0474, -0.5117,  1.6244,  ..., -1.2638,  2.8110, -3.2746],\n",
            "        [-2.1806,  0.2278,  2.7991,  ...,  0.7314, -0.0176, -2.1524],\n",
            "        [-1.8783, -1.7098,  1.1480,  ..., -3.1005,  2.6790, -1.9135]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6251,  0.8520,  1.5422,  ...,  0.8976,  0.5842, -3.9295],\n",
            "        [-0.7018,  2.2911, -1.4743,  ..., -0.3641,  2.7967, -2.6220],\n",
            "        [-3.1091,  1.1619,  0.9721,  ..., -0.6076, -1.0652, -1.3616],\n",
            "        ...,\n",
            "        [-3.2876, -2.9290,  1.1056,  ...,  1.0951,  2.7773, -3.8229],\n",
            "        [-2.7952, -0.2114,  1.8164,  ..., -0.0896,  0.5803, -2.5760],\n",
            "        [-3.3918, -2.3605, -1.7831,  ...,  2.5289,  3.4281, -5.8074]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9869, -2.7276, -1.0396,  ...,  4.3694,  2.2968, -3.6309],\n",
            "        [-3.1592, -1.2949,  1.5891,  ..., -0.2850,  3.2772, -3.6623],\n",
            "        [-0.1448, -2.5902,  3.2198,  ...,  1.0628,  4.0900, -5.4708],\n",
            "        ...,\n",
            "        [-0.9057, -0.3200, -2.2821,  ...,  4.8585,  3.4052, -4.3011],\n",
            "        [-1.3963, -2.8266, -3.2246,  ...,  3.2256,  3.8546, -4.3983],\n",
            "        [-2.8683, -3.1930,  2.7067,  ...,  3.6687,  0.6073, -3.8315]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8629, -1.3520,  1.9987,  ...,  3.7813,  0.5285, -4.5516],\n",
            "        [-1.1054, -2.1452, -0.5963,  ...,  0.8438,  0.4568, -4.0466],\n",
            "        [-2.1941, -4.0562,  4.9182,  ...,  0.0097,  2.8422, -4.0234],\n",
            "        ...,\n",
            "        [-2.1390,  1.5240,  2.7164,  ...,  0.4678,  6.0931, -2.9036],\n",
            "        [-0.0240, -2.1981, -0.8130,  ...,  2.6609,  0.4783, -2.7852],\n",
            "        [-1.9248, -0.5306,  2.7967,  ...,  0.4489, -0.3586, -3.0831]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5985, -1.4538,  0.6047,  ..., -1.9558,  6.2463, -4.3124],\n",
            "        [-2.7152,  0.8999,  0.6420,  ...,  0.6324, -0.2695, -2.2637],\n",
            "        [-0.4396,  1.1610,  0.1309,  ...,  1.8003, -0.6631, -2.5797],\n",
            "        ...,\n",
            "        [-0.4356, -2.7441, -1.5848,  ...,  2.3040,  1.2446, -4.9716],\n",
            "        [-3.1167, -1.4483,  1.2530,  ...,  1.4168, -0.2876, -3.5698],\n",
            "        [-1.6271, -0.2909,  3.5379,  ...,  1.1711, -0.2914, -2.2975]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0053, -2.2411, -5.7645,  ...,  5.6738,  0.1638, -4.9705],\n",
            "        [-0.1720,  0.2635, -0.7236,  ..., -2.6173,  5.3580, -1.1941],\n",
            "        [-0.3529, -1.1845, -3.1985,  ..., -1.0232,  2.4193, -1.1825],\n",
            "        ...,\n",
            "        [-2.0857, -0.3479,  1.2547,  ..., -2.7611,  3.2608, -2.8257],\n",
            "        [-1.5202,  2.3952, -2.7387,  ..., -0.1343,  3.4014, -3.4573],\n",
            "        [-3.8476, -1.7423,  1.8594,  ..., -0.3703,  1.5002, -4.0706]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0468, -2.3369,  2.5911,  ..., -1.1528,  2.4473, -3.9610],\n",
            "        [-1.1491, -1.7706, -0.0348,  ...,  4.6237,  2.1365, -2.9237],\n",
            "        [-2.3765, -2.9688,  1.3181,  ...,  0.4220,  1.5135, -3.9020],\n",
            "        ...,\n",
            "        [-0.1378, -3.3839, -2.0979,  ...,  5.5536,  3.1173, -6.5071],\n",
            "        [-1.2691, -0.6926,  3.4147,  ..., -1.0187,  2.8434, -2.1729],\n",
            "        [-2.4595, -3.1521,  1.9795,  ...,  4.0100,  1.2167, -5.5890]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0463, -0.7796, -1.3461,  ...,  1.6716,  3.5244, -3.5201],\n",
            "        [-1.3154, -2.9101,  4.8563,  ...,  0.5360,  0.6460, -3.7855],\n",
            "        [-0.5425, -0.6840, -0.8980,  ..., -1.8020,  2.5645, -1.2164],\n",
            "        ...,\n",
            "        [-3.3423, -2.6851,  0.8991,  ..., -0.3559, -0.2116, -2.8961],\n",
            "        [-2.1822, -1.9546, -0.7966,  ...,  4.9880,  4.6770, -5.4177],\n",
            "        [-2.4595, -0.5482,  0.8476,  ...,  2.0929,  2.6889, -6.9259]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6133,  0.7173, -3.2403,  ...,  3.6960,  2.7466, -3.0826],\n",
            "        [-0.8152, -1.3164,  5.7605,  ..., -0.0566,  2.9205, -3.4479],\n",
            "        [-2.4447,  1.0817,  2.6206,  ..., -0.2895, -1.4196, -3.6472],\n",
            "        ...,\n",
            "        [-4.1002, -3.4439, -0.7294,  ...,  2.9347, -2.3537, -3.9281],\n",
            "        [-3.4883, -4.2212,  3.7350,  ...,  2.2003,  1.1055, -5.7285],\n",
            "        [ 0.3235, -0.4120, -0.7910,  ...,  0.8870,  1.4376, -0.8298]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2752, -3.0148, -1.8143,  ...,  1.8491,  0.4482, -5.0231],\n",
            "        [-1.7107, -2.1028,  4.0444,  ...,  0.4364,  0.1670, -4.0417],\n",
            "        [-0.8192, -1.4055,  5.2879,  ..., -1.7989,  2.9397, -2.9800],\n",
            "        ...,\n",
            "        [-3.1668, -3.2658,  1.3720,  ...,  1.9747,  0.2243, -1.0698],\n",
            "        [-0.3422,  0.3153,  0.3104,  ...,  2.1905,  4.1642, -4.0622],\n",
            "        [-2.3511,  1.2418,  2.2794,  ..., -0.2780, -1.4731, -1.5051]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6764,  0.8913,  1.8545,  ...,  1.4810,  3.6101, -3.3060],\n",
            "        [-0.0179, -3.4857, -2.4850,  ...,  2.6535,  4.0926, -8.6611],\n",
            "        [-1.8666, -0.5151,  1.1670,  ...,  0.3000,  1.6814, -3.1939],\n",
            "        ...,\n",
            "        [-1.2329, -1.5169,  0.0396,  ...,  3.5517, -1.1506, -3.0162],\n",
            "        [-1.7424, -2.2410,  3.9670,  ...,  0.9293,  2.0571, -2.2449],\n",
            "        [-1.4059, -0.7910, -0.4661,  ..., -4.0301,  6.0048, -2.1281]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2222, -3.5630,  4.2660,  ..., -0.7226,  1.0936, -5.0836],\n",
            "        [-0.1846, -2.2394,  0.5905,  ...,  0.6956,  3.1955, -6.0246],\n",
            "        [-2.1942, -1.9133,  3.0360,  ...,  0.7659,  2.3434, -3.7850],\n",
            "        ...,\n",
            "        [-2.5176, -0.6141,  2.7473,  ..., -0.9747,  1.5955, -2.8406],\n",
            "        [-1.8734, -2.3032,  2.7698,  ..., -0.2616, -1.2839, -4.1032],\n",
            "        [-1.6509, -1.9571,  3.9583,  ..., -0.0708,  0.4517, -3.5830]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1931, -1.9520,  1.8355,  ...,  0.7074,  0.5159, -3.1051],\n",
            "        [-2.1616,  1.3042,  1.8810,  ...,  0.5939, -0.2507, -3.4711],\n",
            "        [-1.4380,  2.2074, -0.4397,  ..., -1.1315,  3.0401, -1.7704],\n",
            "        ...,\n",
            "        [-2.2702, -4.6662, -0.8625,  ...,  2.4742,  1.3678, -4.8097],\n",
            "        [-2.1493,  0.5846,  2.4879,  ..., -0.1667, -1.5181, -2.7148],\n",
            "        [ 0.4407, -0.4733, -0.8965,  ...,  1.4067,  4.2711, -4.2245]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9135, -1.4481, -2.1736,  ...,  1.2473,  1.7612, -2.3737],\n",
            "        [-1.4873, -2.0255, -0.1345,  ...,  0.8307,  1.2446, -3.0852],\n",
            "        [-2.1797, -2.3701,  1.4998,  ...,  2.7507,  0.9839, -4.5746],\n",
            "        ...,\n",
            "        [ 0.5664, -3.4057, -0.5951,  ...,  3.1146,  1.1429, -2.7497],\n",
            "        [-2.6602, -2.0556, -2.5554,  ..., -2.7857,  0.5852, -2.1661],\n",
            "        [-0.0266, -1.9157, -1.6241,  ...,  3.9398,  3.0038, -3.6184]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8756, -2.8758,  2.9798,  ...,  2.3084,  1.6899, -4.7087],\n",
            "        [-0.5756,  3.7705, -4.1156,  ..., -0.4173,  2.9520, -3.2041],\n",
            "        [-1.8969,  1.2672,  1.1809,  ..., -1.6908,  5.7069, -3.2979],\n",
            "        ...,\n",
            "        [-2.0534, -2.5460,  2.0327,  ...,  3.1869,  1.2661, -4.5695],\n",
            "        [ 0.3194, -0.0694, -0.9117,  ..., -2.6486,  6.5703, -1.9067],\n",
            "        [-2.5550, -0.6174,  3.3091,  ...,  0.7475,  4.9210, -3.8523]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3698,  3.0385, -0.7839,  ..., -0.9573,  1.8074, -2.5224],\n",
            "        [-1.8244, -1.0328,  5.9557,  ..., -1.0271,  2.3368, -2.2535],\n",
            "        [-0.9610, -1.3911, -1.0524,  ..., -2.3942,  3.1284, -2.1483],\n",
            "        ...,\n",
            "        [-4.3120, -3.4145,  0.4319,  ...,  2.3993, -0.2212, -5.1970],\n",
            "        [-1.7233, -1.8974,  4.2137,  ...,  2.4130,  0.1917, -4.7166],\n",
            "        [-3.7799,  0.1199,  1.5349,  ..., -1.1721, -1.1590, -1.9095]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1911, -1.2053,  5.6849,  ..., -0.2286,  3.4132, -2.8845],\n",
            "        [-2.9104, -0.8867,  3.4832,  ...,  0.8075,  3.5815, -2.7727],\n",
            "        [ 1.4004, -1.0311, -4.9381,  ...,  4.1651,  3.0142, -4.4122],\n",
            "        ...,\n",
            "        [-3.1117, -0.5325,  1.5553,  ..., -1.7672,  4.9623, -4.0712],\n",
            "        [-1.5085, -1.0926,  3.8169,  ..., -0.8485,  2.7774, -4.6421],\n",
            "        [-1.9852, -0.4654, -2.7029,  ..., -0.0690,  1.8575, -3.5559]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0575, -1.0467,  2.5864,  ...,  1.7279, -0.9293, -2.8906],\n",
            "        [ 0.2196, -2.4597, -2.4193,  ...,  4.6292,  5.7025, -4.2582],\n",
            "        [-3.0003, -0.4764,  0.2782,  ..., -0.9842,  0.7832, -0.5306],\n",
            "        ...,\n",
            "        [-1.4856, -2.0144,  2.5342,  ..., -0.3113,  3.4066, -3.3059],\n",
            "        [ 0.0103, -0.8150, -1.4538,  ..., -0.8412,  5.7757, -2.7631],\n",
            "        [-0.4544, -1.6430, -1.8719,  ...,  1.5873,  4.3397, -1.9018]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0708, -0.6379,  0.1923,  ...,  2.8273,  4.6500, -3.1301],\n",
            "        [-1.4061, -1.8059, -3.7252,  ...,  1.1440,  5.5381, -2.7586],\n",
            "        [-0.0312,  1.8456, -1.7662,  ...,  0.5931,  6.6701, -2.7677],\n",
            "        ...,\n",
            "        [-1.3122, -2.1358,  2.1651,  ...,  1.6072,  3.3505, -5.6592],\n",
            "        [-2.7240, -1.9504,  1.9972,  ..., -1.8096,  3.5721, -6.3866],\n",
            "        [-1.7064, -2.0136,  4.6786,  ..., -1.6307,  0.8614, -4.4171]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6708, -2.1647,  4.5702,  ..., -1.5020,  4.1138, -3.4248],\n",
            "        [-1.2914, -0.9380,  3.9722,  ...,  1.1915,  1.3609, -3.0215],\n",
            "        [-4.5998, -1.0734,  1.0453,  ...,  0.3704, -0.5124, -3.0073],\n",
            "        ...,\n",
            "        [-0.0630,  0.0803,  0.3884,  ...,  0.0744,  1.9751, -3.0244],\n",
            "        [-2.4407, -1.4960,  3.6425,  ..., -0.0426,  0.2002, -2.8040],\n",
            "        [-1.9220, -0.6437,  3.9128,  ..., -1.0489,  5.9884, -1.7235]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2424, -3.7771,  1.4297,  ...,  2.2022,  1.6291, -4.7580],\n",
            "        [-0.5352, -1.3690,  1.7010,  ...,  0.9935,  5.0292, -4.3543],\n",
            "        [-0.5991, -1.7923, -3.8935,  ...,  4.3125,  2.3471, -3.9153],\n",
            "        ...,\n",
            "        [-3.2815,  0.9350, -3.4260,  ..., -0.1393,  4.8637, -4.2556],\n",
            "        [-0.0251, -2.3405, -4.3194,  ...,  3.9064,  1.4260, -2.1905],\n",
            "        [-0.3594, -1.9260,  0.0826,  ...,  1.3965,  2.8035, -3.7787]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0515,  0.2039,  0.4845,  ...,  1.6373,  0.2345, -2.7950],\n",
            "        [ 1.4852,  2.6965, -1.2173,  ...,  2.2272,  5.3733, -3.1294],\n",
            "        [ 1.1403, -1.3568, -2.1821,  ..., -2.8085,  7.2610, -6.2389],\n",
            "        ...,\n",
            "        [-2.2372,  2.6652,  0.3088,  ..., -1.5195,  1.5927, -2.0262],\n",
            "        [-1.8879, -1.2487, -1.8157,  ...,  1.8758,  3.5123, -6.1406],\n",
            "        [-1.6014, -3.0289,  2.0940,  ...,  2.0669,  1.8958, -2.9697]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3291,  0.4518,  1.0484,  ...,  0.0615,  4.5395, -3.2965],\n",
            "        [-0.4277, -0.7911,  5.3661,  ..., -0.3404,  3.9847, -5.9390],\n",
            "        [-1.5990, -2.3552,  3.3550,  ..., -0.3186,  2.5808, -3.7483],\n",
            "        ...,\n",
            "        [-2.5073, -1.0632, -1.6705,  ...,  3.2706,  3.7006, -6.3201],\n",
            "        [ 0.2341, -2.4980,  6.5489,  ..., -0.6334,  3.8527, -3.6960],\n",
            "        [-1.0034, -2.8119,  2.8840,  ..., -0.4011,  3.9718, -4.0455]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4143,  1.2336,  2.3595,  ..., -2.2431,  6.6399, -3.3199],\n",
            "        [-0.8979,  0.5857,  0.5566,  ..., -0.4520,  5.4113, -4.1272],\n",
            "        [-0.7155, -1.9964,  2.9679,  ...,  1.7241, -0.2287, -3.2893],\n",
            "        ...,\n",
            "        [-4.6369, -2.9093,  0.5666,  ..., -0.7270,  1.1185, -3.8754],\n",
            "        [-0.8274, -3.8357, -0.5258,  ...,  4.9881,  1.0077, -5.5290],\n",
            "        [-1.9451, -0.9319,  0.1982,  ..., -0.7149, -1.3556, -5.1334]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6808, -1.6013,  1.2483,  ...,  1.4981,  1.9688, -4.5645],\n",
            "        [-2.2869, -0.5387,  0.9187,  ..., -0.1292,  5.4540, -3.4243],\n",
            "        [-0.3831, -3.8848,  0.9560,  ...,  5.1254,  2.1130, -6.1862],\n",
            "        ...,\n",
            "        [-1.5949,  0.5818,  2.4872,  ..., -1.0205,  2.4464, -1.8828],\n",
            "        [-2.3685, -0.6499, -0.7791,  ..., -0.6688,  3.1972, -4.6726],\n",
            "        [-1.7700,  0.2529,  3.1142,  ...,  0.3336, -0.2628, -1.9862]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9442, -1.6908,  3.6045,  ..., -1.3889,  1.7987, -2.8077],\n",
            "        [ 0.6688, -4.3089, -0.9697,  ...,  6.3584, -0.6032, -1.8218],\n",
            "        [-2.7774, -0.6343,  2.2439,  ...,  1.1008,  2.1278, -5.7483],\n",
            "        ...,\n",
            "        [-1.4418, -0.2871, -0.1653,  ..., -0.1302, -0.5362, -3.1343],\n",
            "        [-1.3966, -2.4716,  2.4247,  ...,  0.0602,  4.5075, -4.6698],\n",
            "        [-2.2591, -0.0724,  1.8777,  ..., -1.0514,  4.2564, -3.2941]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1949,  1.0703,  1.9455,  ..., -0.1835, -2.1050, -3.1763],\n",
            "        [-1.8325,  0.7990,  1.9403,  ...,  1.4397,  3.0135, -2.8052],\n",
            "        [-2.6276,  0.9711, -0.0171,  ..., -0.8688,  1.4233, -2.3194],\n",
            "        ...,\n",
            "        [-1.5031, -0.6930,  2.5711,  ..., -0.1460,  2.4623, -3.8507],\n",
            "        [-3.4620, -1.7454,  2.5031,  ..., -0.1575,  2.1592, -2.8476],\n",
            "        [-1.3567, -3.2274,  2.6182,  ...,  0.2559,  2.3663, -4.1201]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8334, -1.2411,  3.2571,  ...,  0.0277,  2.3140, -3.8928],\n",
            "        [ 0.5202, -0.1556,  0.8356,  ...,  1.7603,  1.1284, -3.8919],\n",
            "        [-1.7868, -0.9356,  0.2113,  ...,  1.5399,  0.0462, -3.6308],\n",
            "        ...,\n",
            "        [-3.3532, -2.2328,  1.6985,  ...,  1.5876,  0.3238, -2.5144],\n",
            "        [-3.0326, -3.6892, -1.3520,  ...,  3.8184,  4.0906, -4.1597],\n",
            "        [-4.8884, -1.0619,  2.2045,  ..., -1.7527,  0.0967, -2.2143]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9926, -1.3514, -1.3521,  ..., -3.0308,  5.5441, -3.3812],\n",
            "        [-1.0663,  1.3354, -1.4563,  ...,  0.5496,  0.8505, -4.5746],\n",
            "        [ 0.2040,  0.8784,  1.5461,  ...,  0.7307,  4.4941, -2.2226],\n",
            "        ...,\n",
            "        [ 0.0126, -0.3345, -2.9858,  ..., -2.3110,  4.7281, -1.7708],\n",
            "        [-2.0878, -0.1085,  2.1174,  ...,  0.2446, -0.4310, -3.0418],\n",
            "        [-1.8034, -0.8340, -1.5658,  ..., -1.1317,  1.9547, -1.8862]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0180,  0.7713, -0.5235,  ...,  3.6611,  2.4780, -2.2540],\n",
            "        [-0.7717, -0.7675,  1.1468,  ...,  0.8602,  2.9161, -2.8598],\n",
            "        [-0.8595,  1.3549, -4.9489,  ...,  0.2861,  1.5397, -3.7733],\n",
            "        ...,\n",
            "        [-3.0583, -0.7468,  1.0770,  ...,  0.9260, -0.2834, -2.3117],\n",
            "        [ 0.8614, -0.2662, -1.6837,  ...,  3.4035,  5.8699, -5.0457],\n",
            "        [-1.4798, -2.1839, -1.1894,  ...,  0.8702,  0.6739, -4.2300]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3049, -0.9637,  3.5713,  ..., -3.7415,  6.4727, -4.5198],\n",
            "        [-1.5612, -1.0263, -2.7034,  ...,  2.3883,  2.9797, -3.4034],\n",
            "        [-2.9603, -3.3612,  3.2456,  ..., -1.1680,  2.4892, -4.3274],\n",
            "        ...,\n",
            "        [-1.4988, -0.5829,  0.3373,  ...,  0.1739, -1.6430, -3.7967],\n",
            "        [-1.6888, -3.7945,  1.7278,  ...,  4.7820,  0.6407, -5.5406],\n",
            "        [-1.6852, -2.2851,  0.5279,  ..., -0.3931,  2.4408, -3.4847]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3313,  0.1338,  1.2528,  ..., -2.5305,  1.5488, -3.8548],\n",
            "        [-3.3463, -1.9698,  0.2366,  ...,  2.8453, -1.0242, -1.7418],\n",
            "        [-1.2788, -2.7415, -1.7911,  ...,  3.9406,  3.2642, -3.9427],\n",
            "        ...,\n",
            "        [-0.8160, -1.4562,  0.2006,  ...,  3.4956, -0.0292, -2.4628],\n",
            "        [-3.3949, -1.9592, -1.1028,  ...,  2.1105, -0.7588, -3.9512],\n",
            "        [-0.4439, -2.2844, -0.8254,  ...,  3.5402, -0.4713, -5.1064]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2248, -0.1159,  0.0323,  ...,  0.1968,  3.2241, -3.6925],\n",
            "        [-3.6045, -0.7460,  0.0254,  ..., -1.6342,  3.2614, -3.8934],\n",
            "        [ 0.0658,  1.2193,  3.4666,  ..., -2.5852,  1.0569, -3.0220],\n",
            "        ...,\n",
            "        [-2.4586, -0.2181, -1.6267,  ..., -5.2852,  2.1942, -1.5238],\n",
            "        [-3.1867, -0.6313,  1.5431,  ..., -0.0630,  1.7610, -2.7398],\n",
            "        [-3.1550, -0.4828, -0.2479,  ..., -0.8749,  3.4396, -3.4511]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9176, -3.1311,  1.9324,  ..., -0.2686,  2.9203, -4.5719],\n",
            "        [ 1.4644, -0.9695, -4.4631,  ...,  4.9129,  0.9058, -3.0456],\n",
            "        [ 0.6346, -0.4787, -2.4319,  ...,  5.4374,  0.7767, -3.3878],\n",
            "        ...,\n",
            "        [-4.7858, -1.3860,  2.0174,  ..., -1.9383,  3.7918, -3.0918],\n",
            "        [-2.4692, -0.7826,  4.0201,  ..., -0.3131,  1.2247, -2.5134],\n",
            "        [-1.0383, -0.9033, -2.2361,  ..., -3.5649,  5.4005, -2.2109]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6425, -2.3922, -0.3249,  ...,  2.5097,  5.2002, -4.6106],\n",
            "        [-1.4636, -2.5659,  1.7940,  ..., -1.4732,  2.8020, -2.9533],\n",
            "        [-3.3695, -3.8000,  0.9164,  ...,  3.4815, -0.0770, -4.5722],\n",
            "        ...,\n",
            "        [-2.2196, -2.9978, -3.2874,  ...,  1.7418,  2.6121, -2.2166],\n",
            "        [-2.1023,  1.5396,  2.3233,  ..., -0.6349, -1.0613, -1.5971],\n",
            "        [-3.0477,  1.0111, -0.1394,  ..., -1.1477,  1.3538, -2.5337]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2865,  0.4678,  2.0857,  ..., -0.9564,  3.6606, -1.7370],\n",
            "        [-0.4537,  2.8700, -0.2025,  ..., -1.2095,  5.5255, -3.1780],\n",
            "        [-2.9944,  1.2690,  2.7952,  ..., -0.6141,  2.7288, -1.9607],\n",
            "        ...,\n",
            "        [-1.1018,  2.1268, -2.0173,  ..., -0.1542,  6.5678, -3.4321],\n",
            "        [-2.5025,  2.1170,  1.6858,  ..., -0.8022, -1.9534, -2.0578],\n",
            "        [-0.3487,  0.1086, -1.3579,  ...,  1.8215,  2.5832, -3.8943]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4104,  2.3800,  0.2398,  ..., -2.3030,  3.3947, -1.6396],\n",
            "        [-1.5125,  0.3107, -0.8378,  ...,  0.5572,  0.6790, -2.8708],\n",
            "        [-3.3193,  1.2619,  2.2013,  ..., -2.3241,  2.5534, -2.8806],\n",
            "        ...,\n",
            "        [-1.5797,  1.7004,  3.0847,  ...,  1.0400,  6.1888, -3.2183],\n",
            "        [-2.5227, -1.3542,  0.1055,  ...,  4.6535, -2.1544, -2.2987],\n",
            "        [-2.7977, -2.1693,  4.9594,  ..., -0.8050,  1.7390, -4.6836]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3750, -0.7534, -0.9522,  ..., -3.7631,  3.4708, -2.0513],\n",
            "        [-2.1496, -1.1246,  0.8331,  ...,  1.7636,  3.6969, -4.6172],\n",
            "        [ 0.4279,  1.4718, -1.2947,  ...,  0.3672,  6.1908, -2.8565],\n",
            "        ...,\n",
            "        [-3.2612, -3.2862,  4.7231,  ..., -1.0341,  1.5242, -5.5652],\n",
            "        [-0.7704, -2.1997,  4.3646,  ..., -0.6059,  3.3340, -3.3391],\n",
            "        [-1.9491,  1.5951,  3.9379,  ..., -0.3204, -0.6746, -2.8830]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1484, -2.2822, -0.1262,  ...,  1.4424,  5.3755, -3.2717],\n",
            "        [-1.3401, -1.1090,  3.9543,  ..., -0.1780, -0.1883, -3.6901],\n",
            "        [-2.9696,  0.6164,  3.6300,  ..., -0.8154, -0.0994, -3.6622],\n",
            "        ...,\n",
            "        [-1.1800, -1.5135,  3.8633,  ...,  0.3285, -0.8078, -3.4284],\n",
            "        [-1.7806, -2.7425, -0.1537,  ..., -2.2135,  4.1862, -7.7792],\n",
            "        [-2.4366, -0.4187,  3.6640,  ..., -1.8290,  2.0647, -2.2690]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9330, -2.0845, -3.0095,  ...,  2.6532,  1.3070, -4.9754],\n",
            "        [-1.2555, -0.4817, -0.4729,  ...,  1.4677,  2.8572, -2.5693],\n",
            "        [-3.1372,  0.2431,  1.4227,  ..., -2.1635, -0.4854, -4.6382],\n",
            "        ...,\n",
            "        [-1.6534, -0.3351, -2.0248,  ...,  0.0151,  4.1575, -4.5478],\n",
            "        [-1.5498, -1.8372, -2.5765,  ...,  2.4558,  1.8940, -4.4676],\n",
            "        [-3.7632, -2.0798,  1.2020,  ..., -2.0294, -0.1540, -2.6613]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3622, -0.8902,  0.2777,  ..., -0.1970,  4.0158, -3.4419],\n",
            "        [-2.8639, -1.1896,  1.8296,  ...,  0.7414,  1.7510, -4.2458],\n",
            "        [-3.7210, -2.4395,  1.0083,  ...,  0.3047,  5.1183, -6.2567],\n",
            "        ...,\n",
            "        [-1.2293, -1.9923,  7.3898,  ..., -0.8816,  4.0479, -4.2287],\n",
            "        [-2.5237, -1.3943, -1.2693,  ...,  2.9707,  3.5258, -4.9066],\n",
            "        [-1.6106, -1.8281,  4.6175,  ..., -0.0713,  1.4217, -3.6305]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0786, -0.3656,  2.3585,  ...,  0.0089,  1.4915, -1.7310],\n",
            "        [-3.1885, -3.1781,  3.8515,  ..., -1.8283,  2.3744, -4.7939],\n",
            "        [-1.5102, -1.5186,  3.9829,  ...,  0.2995,  0.6097, -3.4376],\n",
            "        ...,\n",
            "        [-3.0358, -1.7727,  2.4363,  ..., -1.5665,  2.3324, -3.0200],\n",
            "        [-2.5009, -1.8719,  1.7930,  ..., -1.2214,  1.0721, -2.6748],\n",
            "        [-2.2365, -2.5658, -2.3987,  ...,  2.6935,  3.8726, -5.4713]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5973,  0.2094,  3.1612,  ..., -2.8165,  4.3616, -0.7021],\n",
            "        [-1.5379, -0.3611,  0.0075,  ..., -1.3915,  3.7388, -2.7106],\n",
            "        [-3.3821, -0.3708,  1.0198,  ..., -1.7641,  4.1845, -4.1518],\n",
            "        ...,\n",
            "        [-1.9525, -1.0139,  0.8828,  ..., -0.7704,  0.9642, -2.7518],\n",
            "        [-3.1380, -2.4462, -2.8059,  ...,  2.1180,  1.9709, -3.7794],\n",
            "        [-2.2977,  0.9332,  2.7502,  ..., -0.6981, -0.0651, -2.7555]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6269,  1.1504,  1.8278,  ..., -0.2695,  4.7470, -4.2607],\n",
            "        [-2.9578, -1.7882,  3.9971,  ..., -0.6083,  2.8050, -1.9750],\n",
            "        [-3.0556,  0.0969,  0.8494,  ..., -1.7331,  3.6472, -2.9623],\n",
            "        ...,\n",
            "        [-3.1455,  0.0584,  1.3188,  ..., -2.0953,  2.6015, -4.1246],\n",
            "        [-2.3696, -2.0738,  1.1116,  ...,  1.0511,  1.5343, -5.0340],\n",
            "        [-3.4663, -0.5380,  1.6451,  ...,  2.2824,  0.6640, -3.7083]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2022, -0.4838, -0.5349,  ...,  0.6123, -0.0865, -4.0650],\n",
            "        [-0.9153,  1.8166,  2.2394,  ..., -2.2851,  0.6164, -1.2239],\n",
            "        [-2.9991,  0.4425, -1.1846,  ..., -1.2706,  1.4219, -2.0626],\n",
            "        ...,\n",
            "        [-2.2739,  2.2603,  2.3257,  ..., -3.9548,  6.4036, -4.1938],\n",
            "        [-1.9844, -2.0178,  0.6160,  ...,  1.5980,  1.7202, -3.9732],\n",
            "        [-1.7398,  0.3553,  3.7832,  ..., -0.8252,  2.5007, -2.0763]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6212, -1.8330, -1.1301,  ..., -0.0805,  1.3869, -4.4640],\n",
            "        [-2.1312,  1.5453,  3.0695,  ..., -0.5884, -0.4694, -2.2686],\n",
            "        [-0.4468,  5.1014, -2.9267,  ...,  1.4711,  7.6989, -0.9248],\n",
            "        ...,\n",
            "        [ 0.7083, -3.8288, -3.5997,  ...,  5.3678, -0.3340, -2.6041],\n",
            "        [-3.4641, -4.4957, -1.0975,  ...,  2.3957,  0.8294, -5.9149],\n",
            "        [-2.0124, -3.8426,  2.9734,  ..., -0.4054,  2.1171, -2.5444]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7000e+00, -2.2992e+00,  1.2692e+00,  ..., -1.4964e+00,\n",
            "          3.2689e+00, -5.5857e+00],\n",
            "        [-3.0019e+00,  2.0155e+00,  1.7939e+00,  ..., -2.7445e+00,\n",
            "         -2.0739e+00, -2.8622e+00],\n",
            "        [-1.1685e+00, -1.7647e+00,  1.9564e+00,  ...,  1.8946e-01,\n",
            "          3.0997e+00, -3.4673e+00],\n",
            "        ...,\n",
            "        [-2.2888e+00,  6.1043e-01, -1.1436e+00,  ..., -1.7970e+00,\n",
            "          2.3453e-03, -4.7660e+00],\n",
            "        [-2.8796e+00,  2.9330e+00,  1.5248e+00,  ..., -2.3490e+00,\n",
            "          5.2635e+00, -3.1630e+00],\n",
            "        [-2.9470e+00,  1.7775e-01,  6.7185e-01,  ..., -6.8730e-01,\n",
            "          4.2033e+00, -4.4934e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8568, -1.0307,  2.8088,  ...,  1.4222, -0.0785, -3.1509],\n",
            "        [-2.4332, -1.4633,  5.3032,  ...,  0.4515,  2.1154, -4.8715],\n",
            "        [-1.7437, -0.3255,  2.7821,  ...,  0.3182,  2.5790, -2.4524],\n",
            "        ...,\n",
            "        [-3.2808, -1.0255, -2.9491,  ..., -0.8464,  2.4244, -1.1025],\n",
            "        [-2.9697,  0.9655,  0.0627,  ..., -1.9333, -2.0190, -2.7348],\n",
            "        [-2.5495, -1.0456,  2.5685,  ...,  0.3747,  0.8007, -2.3290]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.5748, -2.1610, -0.1843,  ...,  0.2886, -1.1110, -5.0414],\n",
            "        [-2.6584, -0.6174,  0.0367,  ..., -0.7759,  2.6008, -6.0862],\n",
            "        [-2.5717, -1.6775, -2.0548,  ...,  0.1700,  2.3847, -2.5292],\n",
            "        ...,\n",
            "        [-2.6285,  0.6223,  3.2818,  ..., -1.4693,  3.6622, -4.2046],\n",
            "        [-2.2350, -2.4094, -2.3831,  ...,  1.7572,  4.6592, -4.5245],\n",
            "        [-1.0644, -2.8067,  0.6704,  ...,  2.9912,  3.6743, -4.6816]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3526, -2.0991,  2.3089,  ...,  0.7493,  0.8002, -2.6591],\n",
            "        [ 1.0655, -0.0246, -1.1444,  ..., -0.5471,  2.6459, -2.7849],\n",
            "        [-1.0531, -1.5464,  3.3415,  ...,  0.6384,  3.6603, -3.4525],\n",
            "        ...,\n",
            "        [-2.5802, -1.2567,  0.9065,  ...,  1.2147,  4.0525, -4.9528],\n",
            "        [-1.8978, -1.5198,  3.7220,  ..., -0.8059,  1.4970, -4.2395],\n",
            "        [-2.1203, -4.5610, -0.3986,  ...,  0.1080,  3.0289, -6.3747]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3368, -0.6146,  0.8570,  ..., -2.1058,  1.5995, -1.9296],\n",
            "        [-2.8204, -0.2167,  3.0462,  ...,  0.0411,  0.5405, -2.5471],\n",
            "        [-3.5962, -0.2274, -3.4131,  ..., -1.5012,  1.6864, -1.2559],\n",
            "        ...,\n",
            "        [-3.5985, -1.1463, -1.7132,  ..., -0.2655,  0.7549, -6.0550],\n",
            "        [ 1.1957, -3.5294, -0.7053,  ...,  3.8910, -0.5985, -3.7271],\n",
            "        [-2.8701, -0.8965,  0.8946,  ..., -1.3882,  0.9369, -6.8048]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3396, -1.9288,  0.7178,  ...,  1.1839,  0.1260, -2.8370],\n",
            "        [-1.1803, -1.6879,  5.7195,  ...,  0.0751,  3.2709, -3.7467],\n",
            "        [-1.1531, -0.6714,  2.8519,  ...,  0.1125,  1.7572, -4.0261],\n",
            "        ...,\n",
            "        [-1.2200,  0.1047,  2.9194,  ...,  0.4400,  0.5373, -2.8175],\n",
            "        [-1.8745, -0.4505,  2.8547,  ..., -0.2702,  0.2178, -3.6951],\n",
            "        [-3.6512,  1.1844, -0.2564,  ..., -1.0906,  3.1272, -2.3349]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2842, -3.7440,  2.7236,  ...,  2.7907,  0.9290, -6.1071],\n",
            "        [-1.6425, -3.9403, -0.1430,  ...,  1.6936, -1.2473, -3.1612],\n",
            "        [-2.0878, -1.5751,  2.4090,  ..., -0.0879,  0.3504, -2.0784],\n",
            "        ...,\n",
            "        [-3.1037, -1.5622,  0.0527,  ..., -0.2031,  0.5321, -5.7511],\n",
            "        [-1.7060,  0.6842,  0.6563,  ...,  0.6931,  1.5171, -0.8769],\n",
            "        [-3.0121,  2.0630,  1.3159,  ..., -1.1411, -1.9351, -1.8886]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6015, -1.8732,  3.7033,  ...,  0.1126,  0.3533, -5.0087],\n",
            "        [ 0.6113, -0.3178, -1.1913,  ...,  3.7763,  3.8490, -4.7264],\n",
            "        [-3.4407, -1.0876,  0.9334,  ...,  1.7631,  2.9605, -5.8207],\n",
            "        ...,\n",
            "        [-2.8913, -0.6767, -2.0550,  ...,  3.9295, -0.3496, -0.7363],\n",
            "        [-2.9303, -0.3214,  2.1591,  ..., -2.9871,  2.0820, -1.9732],\n",
            "        [-2.4042, -1.0321,  0.1646,  ...,  0.7512,  1.4432, -3.5675]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8836, -3.2602, -1.2814,  ...,  1.4425,  1.2871, -4.8688],\n",
            "        [-5.4333, -1.6699,  1.5357,  ...,  0.9835,  1.6902, -1.0689],\n",
            "        [-2.9049,  0.9437,  0.9090,  ..., -0.0756,  0.1587, -2.4475],\n",
            "        ...,\n",
            "        [-1.6860, -3.1663,  4.3170,  ...,  0.9418,  3.5081, -2.7487],\n",
            "        [-2.0683, -2.0598,  1.0981,  ..., -0.4979,  1.5936, -3.7186],\n",
            "        [-2.5726, -0.8273, -1.6675,  ..., -3.6668,  2.5679, -0.8462]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8276, -1.2679,  1.3010,  ...,  3.6617, -0.3323, -3.4879],\n",
            "        [-3.0016, -1.4971,  0.4621,  ...,  0.0845,  3.5424, -3.4557],\n",
            "        [-0.9345,  0.0405, -2.7050,  ...,  1.4565,  1.3336, -3.4631],\n",
            "        ...,\n",
            "        [-4.2478, -3.1264,  2.3826,  ..., -0.1750,  2.3319, -3.9674],\n",
            "        [-1.2779, -1.2341,  2.3982,  ...,  4.4125,  0.8106, -2.9442],\n",
            "        [-4.8105, -1.5437,  2.8105,  ..., -1.0551,  2.7020, -3.1692]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3633, -0.6835, -1.0002,  ..., -3.5115,  4.2764, -5.6170],\n",
            "        [ 0.0330, -0.6486,  0.4119,  ...,  2.3993,  4.9274, -4.6970],\n",
            "        [-2.3178,  0.7320,  0.9305,  ..., -1.5010,  4.5838, -3.6082],\n",
            "        ...,\n",
            "        [-1.9526, -0.8260, -1.1901,  ...,  4.1041,  3.8190, -5.1486],\n",
            "        [-2.7489, -2.8311, -0.2567,  ...,  5.0570,  1.2513, -4.6579],\n",
            "        [ 0.8081,  0.7572,  0.0681,  ...,  1.0973,  7.2020, -4.7870]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6699, -1.6766,  2.0138,  ..., -1.2435,  1.7423, -2.1556],\n",
            "        [-1.6479, -3.0654, -2.8684,  ...,  3.1513,  2.0587, -6.5975],\n",
            "        [-3.6820,  0.7057,  1.0115,  ..., -2.1828,  0.0805, -2.0862],\n",
            "        ...,\n",
            "        [-1.8671, -2.0064,  6.5698,  ...,  0.2598,  3.2174, -4.1455],\n",
            "        [ 1.6187, -1.7277, -1.9552,  ...,  2.8213,  0.8184, -5.0932],\n",
            "        [-1.4592, -0.1035, -1.1915,  ...,  0.6929,  0.1439, -1.8126]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4142, -1.5352,  1.6794,  ..., -1.7261,  3.8557, -4.5422],\n",
            "        [-1.9656,  0.4139, -2.1434,  ..., -1.7099,  4.8077, -2.4932],\n",
            "        [-1.7030, -1.1141,  4.2710,  ...,  0.6159,  0.5555, -3.2137],\n",
            "        ...,\n",
            "        [ 0.2100, -2.4235, -0.0697,  ...,  2.9784, -0.0132, -3.2971],\n",
            "        [-0.9687,  2.7723, -0.6612,  ..., -1.3541,  5.4431, -0.5632],\n",
            "        [-1.5952, -2.5867, -0.8552,  ...,  0.3038,  1.2000, -3.8176]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8003, -2.8097, -0.2638,  ...,  0.1838,  1.8162, -5.6547],\n",
            "        [-0.3862, -0.8584, -2.9287,  ...,  4.8574,  4.3285, -5.7699],\n",
            "        [-2.9272,  1.8326,  2.8641,  ..., -2.0381, -0.6625, -1.6030],\n",
            "        ...,\n",
            "        [-1.2018, -0.1597,  0.6595,  ..., -0.7486,  1.0870, -1.1543],\n",
            "        [-2.4295, -1.6342,  5.0757,  ...,  0.3197,  2.8514, -2.6124],\n",
            "        [-2.3529, -0.0450,  2.9317,  ..., -0.0654,  1.9333, -3.6549]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9461, -1.7909, -2.8736,  ...,  1.1953,  2.9976, -4.7326],\n",
            "        [-2.6687,  0.3434,  1.1402,  ..., -1.6317,  2.2388, -2.6788],\n",
            "        [-1.4112,  0.1515,  1.6361,  ..., -0.5941,  4.4206, -3.4558],\n",
            "        ...,\n",
            "        [-2.9683, -0.5497,  3.9112,  ..., -1.2073,  3.9259, -3.0007],\n",
            "        [-1.0239, -1.3863,  5.8013,  ..., -1.1837,  3.8519, -4.3313],\n",
            "        [-1.2504, -0.3193,  2.7689,  ..., -1.4999,  1.3933, -4.4610]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4920,  2.2909, -1.0439,  ..., -1.1888,  3.5350, -2.4694],\n",
            "        [-1.8619, -3.5071,  1.1318,  ...,  3.8531,  0.6130, -5.9940],\n",
            "        [-3.8949, -2.0749,  0.1425,  ..., -4.8086,  0.2902, -2.5891],\n",
            "        ...,\n",
            "        [-1.0341, -1.0221,  2.2048,  ...,  0.9171,  0.0176, -3.2427],\n",
            "        [-2.9962, -2.8242, -0.8532,  ...,  0.3058,  2.3063, -5.2275],\n",
            "        [-1.4301, -0.4858, -1.5100,  ...,  2.9461,  3.1103, -4.4923]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9303,  0.1590,  2.6686,  ..., -0.0171,  0.5164, -2.3516],\n",
            "        [-2.6513, -3.8442,  0.5305,  ..., -1.2957, -0.8704, -5.5605],\n",
            "        [-2.9124,  1.5129,  1.1068,  ..., -5.3328,  5.4239, -4.1815],\n",
            "        ...,\n",
            "        [-1.0531,  0.3222,  4.0014,  ...,  0.0884,  3.6549, -2.8967],\n",
            "        [-1.4005,  0.1284, -0.2998,  ..., -2.1961,  4.1402, -5.2131],\n",
            "        [ 0.6890, -2.1592, -4.7832,  ...,  5.6127,  0.9898, -4.8758]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9006, -0.4483,  0.2262,  ..., -0.9339, -0.0250, -2.2822],\n",
            "        [-2.1162, -1.6649,  0.6673,  ..., -0.5153,  4.3129, -6.0684],\n",
            "        [-2.8393,  0.1966,  4.8458,  ..., -2.4766,  5.1499, -2.6273],\n",
            "        ...,\n",
            "        [-2.5412,  0.9212,  1.6082,  ..., -0.2116, -0.9576, -2.8686],\n",
            "        [-1.8106, -2.0267, -0.0326,  ...,  4.4866,  0.2858, -2.1749],\n",
            "        [-1.1929, -3.3714,  1.5577,  ...,  1.2524,  3.2599, -4.1187]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0426e+00,  1.1759e+00,  1.5263e+00,  ..., -1.5005e+00,\n",
            "         -6.4720e-01, -4.7592e+00],\n",
            "        [-1.1045e+00, -8.4947e-01,  2.2743e-01,  ...,  1.8257e+00,\n",
            "          4.7118e+00, -1.9598e+00],\n",
            "        [-1.1316e+00,  2.6308e+00,  1.1016e+00,  ..., -2.3358e+00,\n",
            "          6.9216e+00, -3.1313e+00],\n",
            "        ...,\n",
            "        [-2.5226e+00, -7.6780e-04, -6.8649e-01,  ..., -4.9158e+00,\n",
            "          5.1429e+00, -3.4545e+00],\n",
            "        [-5.2851e+00, -9.4226e-01,  1.8966e+00,  ..., -1.0463e+00,\n",
            "          2.3864e+00, -2.4625e+00],\n",
            "        [-2.7536e+00, -8.2968e-01,  1.6358e+00,  ..., -3.7759e-01,\n",
            "          5.1235e+00, -3.6286e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3633,  0.2331, -3.4132,  ..., -2.3855,  2.5674, -2.6582],\n",
            "        [-1.0383,  3.1854, -0.0947,  ..., -2.9183,  3.7234,  0.1052],\n",
            "        [-1.3791, -0.5100,  0.7008,  ...,  0.4570,  1.9484, -2.4786],\n",
            "        ...,\n",
            "        [-1.8630, -4.2112,  3.8085,  ...,  4.6473,  0.8602, -4.9760],\n",
            "        [ 0.3477,  4.3468, -2.4633,  ..., -3.9613,  3.5162, -1.0899],\n",
            "        [-2.1589, -1.2272, -0.4850,  ..., -0.2698,  0.7109, -2.9647]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8314,  1.7762,  2.8228,  ..., -1.2711, -0.7590, -1.8815],\n",
            "        [-2.3322, -3.0784,  3.4894,  ...,  1.9582, -0.1583, -4.3767],\n",
            "        [-2.7724, -1.5383, -0.8997,  ...,  3.2252, -1.4753, -2.2295],\n",
            "        ...,\n",
            "        [-1.9651, -2.0946, -0.9629,  ...,  2.5146, -0.6549, -4.8417],\n",
            "        [-2.2493, -0.5373,  1.4056,  ...,  0.4186,  5.6870, -5.5775],\n",
            "        [-1.0971, -1.8402,  1.4920,  ...,  3.2021, -0.9387, -4.6384]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6377, -1.5931,  2.8990,  ...,  0.3024,  0.6259, -3.6277],\n",
            "        [-0.9290, -0.9176,  2.6810,  ..., -1.4900,  4.0507, -5.0560],\n",
            "        [-2.2300,  1.3067,  3.6685,  ...,  0.5775, -0.3273, -1.7309],\n",
            "        ...,\n",
            "        [-4.8332, -2.7130, -0.4391,  ...,  3.1618, -2.3850, -4.5338],\n",
            "        [-2.0677, -0.0427, -3.2793,  ...,  0.2572, -0.4977, -0.8758],\n",
            "        [-3.1611,  0.0471, -0.6063,  ..., -0.9865,  0.9882, -5.4762]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7083, -1.2657,  0.2276,  ...,  2.5972,  0.9126, -3.9629],\n",
            "        [-3.4279, -1.0309,  1.6163,  ...,  0.6091,  3.0258, -3.5256],\n",
            "        [ 0.0086,  1.8365, -2.3520,  ..., -0.6937,  2.9315, -1.5311],\n",
            "        ...,\n",
            "        [-3.4904, -1.9555,  0.9678,  ..., -1.4562,  3.0429, -5.3629],\n",
            "        [-0.5112, -0.6717,  2.3703,  ...,  1.2342,  4.3462, -3.9637],\n",
            "        [-3.0539, -0.8618, -0.5551,  ..., -1.6111,  3.5459, -4.9486]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8641,  0.6022, -0.2196,  ..., -0.7890,  0.4599, -1.6266],\n",
            "        [-3.3113, -2.1523,  4.0476,  ..., -0.9807,  3.1739, -3.9743],\n",
            "        [-0.5359, -3.9070, -1.9400,  ...,  3.9142, -0.3125, -4.0072],\n",
            "        ...,\n",
            "        [-2.6806, -0.0558,  1.6467,  ..., -3.9277,  4.1559, -3.1178],\n",
            "        [-1.4976, -2.4923, -2.4864,  ...,  2.1661, -1.6143, -4.9695],\n",
            "        [-0.4164, -2.2344,  1.1748,  ...,  3.9391,  0.8614, -6.3044]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8266, -2.2848,  0.6846,  ...,  2.9374,  6.4090, -7.0116],\n",
            "        [-0.6812, -1.5521,  4.9679,  ..., -1.4127,  4.7681, -3.7645],\n",
            "        [-1.5046,  0.4471,  0.4263,  ..., -1.1139,  7.1792, -3.6350],\n",
            "        ...,\n",
            "        [-3.9596, -0.7709,  0.2269,  ..., -2.5968,  1.8785, -3.4383],\n",
            "        [-0.0872, -0.5029,  0.3744,  ...,  2.9833,  0.4789, -4.2690],\n",
            "        [-1.0675,  0.8464, -1.9618,  ..., -2.9944,  2.9589, -1.1353]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7647, -5.1439,  1.4033,  ...,  4.4571,  0.2343, -4.7698],\n",
            "        [-0.8523, -0.3290,  3.8335,  ...,  0.3245,  2.3584, -4.4842],\n",
            "        [-2.0999,  0.1302, -0.6112,  ..., -2.3653,  3.3698, -2.4916],\n",
            "        ...,\n",
            "        [-2.9347, -1.5676,  1.4033,  ..., -3.9907,  0.7269, -3.2023],\n",
            "        [-2.4638, -1.2664,  1.6701,  ...,  0.4625, -0.3880, -2.4621],\n",
            "        [-3.7469, -0.8428,  1.4100,  ...,  1.0517, -0.9490, -2.5507]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7806, -0.6426,  4.7940,  ..., -0.2279,  3.3520, -2.6313],\n",
            "        [-1.8909, -1.6901, -0.4595,  ...,  4.6756,  4.1744, -4.6309],\n",
            "        [-2.2261,  0.7199,  2.7256,  ..., -0.8463,  2.6873, -4.3349],\n",
            "        ...,\n",
            "        [-2.4924, -0.8457, -1.6051,  ...,  1.6851, -0.4684, -2.9682],\n",
            "        [-1.3988,  0.8470,  2.0421,  ..., -3.9759,  2.9469, -2.1291],\n",
            "        [-4.4117, -3.3323, -0.6574,  ..., -1.4958,  2.7871, -5.3458]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8095e+00, -7.3041e-01,  2.9053e+00,  ...,  1.5894e+00,\n",
            "          4.0145e-01, -2.2040e+00],\n",
            "        [-2.6491e+00, -3.8353e-01,  3.6209e+00,  ..., -6.1389e-01,\n",
            "          2.4731e+00, -3.5871e+00],\n",
            "        [-1.8298e+00, -3.0801e+00, -7.3315e-01,  ...,  4.2838e+00,\n",
            "          7.8350e-01, -5.1648e+00],\n",
            "        ...,\n",
            "        [-2.4789e+00, -1.9554e+00,  3.4156e+00,  ...,  4.8595e-02,\n",
            "          2.1995e+00, -2.5968e+00],\n",
            "        [-1.9865e+00, -6.4116e-01,  2.2997e+00,  ...,  1.4015e+00,\n",
            "          2.2749e+00, -1.5963e+00],\n",
            "        [-3.9016e+00, -2.9077e+00,  2.2331e+00,  ...,  8.9062e-01,\n",
            "          3.5158e+00, -3.6196e-03]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2647, -2.3183,  3.5510,  ..., -2.1027,  7.0855, -5.4047],\n",
            "        [-2.1852, -1.8656,  3.7704,  ..., -0.3238, -0.1873, -4.2009],\n",
            "        [-0.9060, -0.7010, -1.4172,  ...,  2.3629,  1.4500, -1.0168],\n",
            "        ...,\n",
            "        [-1.4100, -3.3325,  2.0797,  ...,  3.4564,  0.9641, -3.2112],\n",
            "        [-1.6377, -1.3302,  2.8189,  ...,  0.9713,  0.5396, -3.4314],\n",
            "        [-1.3986, -2.6947,  4.3431,  ...,  0.5914,  3.4669, -3.8270]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3310,  1.0340,  1.4257,  ..., -1.9782,  3.0449, -3.0720],\n",
            "        [-2.6587,  2.7042,  2.7145,  ..., -2.7618,  4.5784, -2.8773],\n",
            "        [-3.4956,  0.0701, -0.5739,  ..., -1.3524, -1.9532, -2.6030],\n",
            "        ...,\n",
            "        [-4.1784, -2.4387,  1.4850,  ..., -0.4193,  1.5499, -3.3712],\n",
            "        [-2.1586, -3.4656,  1.1595,  ..., -0.6488,  1.4160, -2.4177],\n",
            "        [-2.0799,  0.9914,  2.5617,  ..., -0.7002,  1.6922, -4.9955]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2847, -3.7576, -4.0356,  ...,  7.2154,  1.4123, -5.7764],\n",
            "        [-3.5022, -1.0503,  1.9458,  ...,  1.3893,  0.9146, -2.5177],\n",
            "        [-2.9497,  1.5699,  0.3440,  ...,  0.1330,  2.2865, -3.0240],\n",
            "        ...,\n",
            "        [-1.2805, -1.5834,  3.2260,  ..., -1.1812,  5.8504, -4.6792],\n",
            "        [-1.6054, -2.7310, -1.8669,  ...,  1.8729,  5.4909, -7.0146],\n",
            "        [-2.7338,  2.0515,  1.9728,  ..., -1.6059,  4.1550, -4.6834]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2979, -1.3902, -3.5597,  ...,  2.4445,  5.6565, -3.8393],\n",
            "        [-2.3386, -2.5165,  0.3396,  ...,  0.3021,  1.9221, -3.2165],\n",
            "        [-3.0339,  0.0849,  1.8245,  ..., -0.9477,  2.0103, -4.8015],\n",
            "        ...,\n",
            "        [-0.4864, -3.2220, -2.6831,  ...,  4.8409,  2.8847, -4.1109],\n",
            "        [-4.3408, -4.0775,  1.5011,  ..., -0.9733,  2.0066, -3.8863],\n",
            "        [-1.8826, -3.0122, -1.0963,  ...,  2.2282,  7.2636, -4.7091]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3999,  1.9449, -0.1110,  ..., -0.3120,  5.7354, -3.6841],\n",
            "        [ 0.4190,  2.8094, -1.8671,  ..., -1.7241,  8.9428, -2.6586],\n",
            "        [-0.6687,  5.3018, -2.3642,  ..., -4.0952,  2.9825, -1.4448],\n",
            "        ...,\n",
            "        [-1.3173,  0.6047, -0.9942,  ...,  0.4637,  3.5927, -3.8094],\n",
            "        [-4.2873, -1.0112,  0.3775,  ...,  0.9298,  0.8025, -2.6274],\n",
            "        [-3.8236,  3.0263, -0.3045,  ..., -2.4583,  3.5475, -2.5999]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3126, -1.4269,  0.3926,  ..., -0.5549,  0.9222, -4.2158],\n",
            "        [-3.8841, -0.0582,  1.1387,  ..., -0.8153,  3.9693, -4.2084],\n",
            "        [ 2.1051, -1.1948, -2.3245,  ...,  5.0625, -0.2765, -1.7304],\n",
            "        ...,\n",
            "        [-1.7312, -3.9161,  1.4279,  ...,  2.2230,  4.1848, -7.5937],\n",
            "        [-1.6452, -4.7054, -1.5080,  ...,  2.6704,  0.9414, -4.5854],\n",
            "        [-2.0226, -2.1577,  4.2335,  ...,  0.5875,  0.5234, -3.5556]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3604e+00, -1.2025e+00,  2.2836e+00,  ..., -7.7100e-01,\n",
            "         -2.0248e-01, -3.4225e+00],\n",
            "        [-1.4911e+00, -6.0152e-01,  3.5945e+00,  ...,  1.6727e+00,\n",
            "         -5.0641e-01, -3.2971e+00],\n",
            "        [-1.1265e+00, -2.1262e+00, -2.1854e-01,  ...,  4.5246e-01,\n",
            "          8.0554e+00, -4.7431e+00],\n",
            "        ...,\n",
            "        [-1.4928e+00, -3.2979e+00, -2.4498e+00,  ...,  2.4240e+00,\n",
            "          1.2924e+00, -5.1710e+00],\n",
            "        [-3.6800e+00, -5.6161e-01,  2.2076e+00,  ..., -2.3068e+00,\n",
            "          3.9462e+00, -2.7454e+00],\n",
            "        [-7.7371e-01, -2.5578e+00, -7.6550e-03,  ..., -7.2837e-01,\n",
            "          4.5342e+00, -4.4338e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3859,  0.0840,  2.5939,  ...,  0.1198, -0.6225, -2.0989],\n",
            "        [-3.2072, -2.4656, -1.1373,  ...,  0.3272,  1.0441, -3.1262],\n",
            "        [ 0.0856, -1.4148, -2.5489,  ..., -2.4685,  4.6305, -2.5525],\n",
            "        ...,\n",
            "        [-1.7849, -3.8941,  0.4809,  ...,  0.7810,  1.5344, -4.0445],\n",
            "        [-1.5350, -1.1383,  2.7703,  ..., -1.0084,  1.5885, -3.7893],\n",
            "        [-3.6220,  0.8230, -0.0372,  ..., -1.0808, -1.8474, -1.3097]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6135, -3.1608, -1.0944,  ..., -3.0379,  4.8161, -6.1138],\n",
            "        [-1.5566,  0.3747, -0.5027,  ..., -1.6627,  2.3831, -3.5411],\n",
            "        [-1.1584, -2.7016, -2.1272,  ...,  0.3307,  0.9982, -2.2637],\n",
            "        ...,\n",
            "        [-2.0466, -3.6806,  3.9509,  ..., -1.6438,  2.0428, -4.6602],\n",
            "        [-0.2611,  4.1238, -1.0053,  ..., -1.2727,  5.7040, -3.4552],\n",
            "        [-0.3336, -0.4817, -2.0422,  ...,  1.5195,  0.1229, -2.9683]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5864, -2.5008,  1.2326,  ...,  1.0411, -0.1433, -2.8791],\n",
            "        [-3.0509, -2.3884,  2.8580,  ..., -1.7298,  1.5468, -3.8912],\n",
            "        [-0.6553, -2.1719,  2.4605,  ...,  0.2292,  2.1942, -2.6682],\n",
            "        ...,\n",
            "        [-2.2240, -2.6403,  2.5483,  ..., -1.5847,  1.0315, -3.2040],\n",
            "        [-0.4431, -4.8393, -2.7117,  ...,  2.7750,  0.4806, -6.0236],\n",
            "        [-0.9768, -3.0321,  0.7767,  ..., -0.5673,  2.4279, -3.4487]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2338, -3.0443,  0.2646,  ...,  2.5642,  1.8235, -5.8611],\n",
            "        [-2.6825, -1.2100,  4.9756,  ..., -1.3779,  3.7306, -3.2032],\n",
            "        [-1.6793, -2.4678,  1.4449,  ...,  0.8715,  2.4049, -4.0132],\n",
            "        ...,\n",
            "        [-4.2501, -2.3996, -0.2822,  ...,  0.5743,  0.3877, -3.4826],\n",
            "        [-0.8383, -0.1638,  0.9532,  ...,  3.7525,  0.6296, -1.5715],\n",
            "        [-4.3726, -1.9019,  1.2017,  ...,  0.1711, -0.9036, -4.2896]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4999e+00, -4.6894e-01,  1.0604e+00,  ..., -2.3214e+00,\n",
            "          2.1152e+00, -4.9702e+00],\n",
            "        [-9.2496e-02, -1.7503e+00,  5.4689e+00,  ...,  2.2283e-01,\n",
            "          2.5583e+00, -2.9004e+00],\n",
            "        [-1.0064e+00, -2.1220e-01, -8.6893e-01,  ..., -1.7714e+00,\n",
            "          2.2819e+00, -1.2567e+00],\n",
            "        ...,\n",
            "        [-2.5437e+00,  1.3367e-02, -1.1655e+00,  ..., -8.9516e-01,\n",
            "          1.6201e+00, -2.4146e+00],\n",
            "        [-7.1007e-01, -2.9685e+00,  2.0746e+00,  ...,  2.0226e+00,\n",
            "         -1.6421e-03, -4.3077e+00],\n",
            "        [-4.6387e-01, -3.5531e+00,  6.6108e-01,  ...,  2.0253e+00,\n",
            "          1.3788e+00, -4.0946e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3230, -0.4982, -3.8959,  ..., -2.7281,  4.0910, -1.8728],\n",
            "        [-0.4215, -3.7300, -5.5641,  ...,  3.3315,  4.3664, -4.7107],\n",
            "        [-1.8526, -3.4550,  1.5135,  ...,  1.2349,  3.9113, -3.9857],\n",
            "        ...,\n",
            "        [-2.0948, -1.0316,  2.7203,  ...,  0.6238, -0.1274, -2.2734],\n",
            "        [-1.0684, -1.3007,  2.1157,  ..., -1.6069,  2.8797, -3.1925],\n",
            "        [ 0.1654, -2.6956, -4.8848,  ...,  2.2854,  5.5252, -5.6582]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9664, -0.1049, -1.2812,  ..., -0.0273,  4.3595, -5.2911],\n",
            "        [-2.2354, -2.9839,  0.2647,  ...,  2.3960,  1.3303, -4.2869],\n",
            "        [-2.2270, -3.3818, -0.2426,  ...,  1.6757, -0.5260, -6.9141],\n",
            "        ...,\n",
            "        [-1.0401, -2.7511,  3.4538,  ...,  0.9847, -0.3191, -3.4858],\n",
            "        [-1.2305, -3.6011,  0.4566,  ...,  2.2376,  1.5567, -3.9448],\n",
            "        [-2.4161, -0.5956, -0.3915,  ..., -3.6409,  3.6876, -2.8300]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8229, -3.7773,  1.1169,  ...,  3.3527, -0.3849, -4.1042],\n",
            "        [-0.2397,  2.2213, -0.6134,  ..., -1.3842,  6.8157, -2.0305],\n",
            "        [-3.3629, -1.4040, -1.2588,  ...,  0.3533,  3.6465, -2.8622],\n",
            "        ...,\n",
            "        [-2.0873, -1.6993,  2.6035,  ..., -0.4423,  2.3237, -3.0780],\n",
            "        [-0.8292,  0.0181, -1.9989,  ...,  0.9871,  2.1666, -3.6514],\n",
            "        [-2.7726, -1.8307,  2.4474,  ...,  1.0917,  2.7791, -5.6531]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9097,  1.5099,  0.4953,  ..., -1.4077,  3.9355, -2.4890],\n",
            "        [-0.5532, -1.8819, -2.6108,  ...,  1.6130,  0.0523, -1.5643],\n",
            "        [ 0.6865, -0.1799, -1.7991,  ...,  0.3323,  2.8484, -5.4065],\n",
            "        ...,\n",
            "        [-3.1598,  0.9114, -0.3644,  ..., -2.8102,  2.6636, -1.8528],\n",
            "        [-1.4871, -2.0881, -3.6845,  ...,  2.6360,  3.7518, -4.7565],\n",
            "        [-1.5731, -3.3416, -0.2659,  ..., -0.1263,  2.7707, -3.1862]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0559,  0.6525,  1.5321,  ...,  0.3926,  5.7338, -2.3019],\n",
            "        [-1.8889, -4.4010,  0.2183,  ..., -0.0727,  1.7335, -5.4923],\n",
            "        [ 0.1219,  0.3540, -2.6222,  ..., -3.9416,  9.0965, -2.5360],\n",
            "        ...,\n",
            "        [-1.9080, -2.9296,  3.7872,  ..., -2.1091,  2.0505, -4.3463],\n",
            "        [-3.3310, -3.2642,  2.8846,  ..., -0.5099,  2.9874, -3.6953],\n",
            "        [-2.8518, -0.8912, -0.4170,  ..., -1.5944,  0.3768, -2.5051]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6997, -1.9635,  5.7114,  ...,  0.7838,  3.8772, -5.5809],\n",
            "        [-1.6648, -2.3974, -1.6015,  ...,  4.4977,  4.1992, -4.1304],\n",
            "        [-1.6108,  1.0292,  3.2778,  ..., -1.6288,  7.3425, -1.2762],\n",
            "        ...,\n",
            "        [-2.1355, -0.8775, -1.8662,  ..., -1.7396,  4.9282, -4.3232],\n",
            "        [-1.8758, -2.1522, -1.5734,  ...,  1.2676,  3.3863, -3.6604],\n",
            "        [-1.1666, -4.5610, -1.4416,  ...,  2.8753, -0.2698, -5.9606]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2049,  0.8637, -0.7453,  ..., -2.2105,  1.5748, -2.1128],\n",
            "        [-0.7413,  4.0130,  0.7414,  ..., -3.2302,  7.5683, -3.5729],\n",
            "        [-1.3637, -4.1466, -0.5894,  ...,  0.5880,  3.0151, -5.0505],\n",
            "        ...,\n",
            "        [-1.9422, -0.6108, -0.9721,  ..., -0.4881,  5.3894, -1.2385],\n",
            "        [-2.0109,  1.0742,  0.4797,  ..., -0.3261,  5.5724, -2.8834],\n",
            "        [-2.6092, -0.4786,  4.8168,  ..., -3.7113,  5.5607, -1.8371]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5029, -0.9875, -2.0625,  ...,  0.6734,  1.1386, -3.2621],\n",
            "        [-0.2075,  3.2563, -3.0441,  ..., -5.1305,  3.8355, -1.5804],\n",
            "        [-0.8248, -1.6074,  1.1873,  ...,  1.3868,  1.3773, -1.7490],\n",
            "        ...,\n",
            "        [-2.8756,  1.9376,  1.7206,  ..., -0.4904, -1.7684, -2.0746],\n",
            "        [-2.5473,  0.4918,  2.4276,  ..., -0.4392,  0.4257, -2.3640],\n",
            "        [-3.0426, -1.7710, -0.2165,  ...,  3.1325,  3.8434, -3.6084]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2713, -2.2817,  1.6349,  ...,  1.5555,  0.9142, -2.1889],\n",
            "        [-2.5313, -1.4418,  1.1058,  ...,  2.0816, -0.7987, -3.4146],\n",
            "        [-3.7993, -2.9675,  1.2400,  ..., -2.5416,  2.3573, -4.3693],\n",
            "        ...,\n",
            "        [-1.8493, -0.7292,  0.8291,  ...,  0.6974,  4.3454, -3.8904],\n",
            "        [-3.7753,  1.1242, -0.1952,  ..., -1.3772, -2.3615, -2.7155],\n",
            "        [-0.7391, -2.4308, -0.7644,  ...,  3.3365, -0.7636, -4.4109]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3218,  3.7293, -1.1533,  ..., -1.7240,  7.5805, -4.0797],\n",
            "        [-0.6797,  1.6074, -3.5588,  ..., -0.8791,  7.8506, -2.0208],\n",
            "        [ 0.2547, -1.2152,  6.1323,  ...,  0.7071,  3.5618, -4.9714],\n",
            "        ...,\n",
            "        [-2.4586, -1.6747, -0.0180,  ...,  1.9528,  4.1517, -7.1281],\n",
            "        [-1.5646, -1.0127,  3.8871,  ...,  0.3207,  0.7861, -2.5108],\n",
            "        [-0.3423, -3.0168, -3.5652,  ...,  2.5477,  1.6054, -3.7011]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0170, -0.4285,  0.1219,  ..., -3.1411,  5.5818, -2.8325],\n",
            "        [-2.6372, -2.6838,  5.2203,  ..., -0.0207,  3.5290, -2.5812],\n",
            "        [-1.2757, -3.1387, -3.5733,  ...,  4.4535,  4.7010, -3.4282],\n",
            "        ...,\n",
            "        [-2.6289,  1.0456,  2.4900,  ..., -0.4903, -0.5235, -1.8384],\n",
            "        [-3.2486, -0.1316,  3.0281,  ..., -1.0552,  4.9116, -2.1942],\n",
            "        [-2.5368, -0.6629,  0.2542,  ..., -1.2171,  1.5034, -3.2655]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4801, -1.7852,  5.2529,  ...,  0.7756,  3.7043, -3.2649],\n",
            "        [-0.7569, -3.1197, -2.6004,  ...,  4.7537,  2.5660, -6.5685],\n",
            "        [-1.1855,  0.9826, -3.1539,  ...,  3.6712,  4.1576, -3.2991],\n",
            "        ...,\n",
            "        [-2.4281, -1.9636,  2.2525,  ..., -2.0799,  1.9162, -1.6753],\n",
            "        [-0.8006,  1.5223, -1.7537,  ...,  0.8886,  3.0314, -2.6388],\n",
            "        [-1.7507,  2.6420,  0.5386,  ..., -2.0669,  4.8132, -1.9269]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4884,  0.6775,  2.6417,  ..., -0.5869,  0.1570, -1.6961],\n",
            "        [ 0.2413, -1.4786, -0.5092,  ...,  0.7041,  2.9451, -4.0312],\n",
            "        [-1.5831, -2.0950,  1.4329,  ...,  1.9845,  1.7600, -5.3206],\n",
            "        ...,\n",
            "        [-0.4163, -0.2236, -3.1468,  ...,  0.7083,  4.3795, -1.2798],\n",
            "        [-1.0182,  2.5819,  0.6202,  ..., -4.6238,  5.1060, -0.8204],\n",
            "        [-1.9747, -1.5103, -2.4478,  ...,  1.5678,  4.5724, -6.3808]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0710, -1.3491, -1.4628,  ..., -3.6258,  2.3566, -3.1850],\n",
            "        [-1.4605,  2.4803, -1.3621,  ..., -1.5482,  7.2764, -3.6229],\n",
            "        [-1.5645,  4.5830, -1.2588,  ..., -1.7326,  7.0116, -1.5763],\n",
            "        ...,\n",
            "        [-0.9907, -4.6970,  1.4754,  ...,  1.8012,  5.2506, -7.0211],\n",
            "        [-2.2080,  1.4019,  1.3508,  ..., -2.1224,  7.6530, -4.1623],\n",
            "        [-0.8477, -3.1985,  5.6356,  ..., -1.2841,  3.9753, -4.0822]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4118, -4.1440,  2.9421,  ...,  3.9251,  1.6819, -4.8027],\n",
            "        [-1.6828, -1.1043,  1.1636,  ..., -2.5543,  3.4537, -2.7191],\n",
            "        [-1.5370, -1.6510,  3.9495,  ..., -0.8396,  1.0793, -4.5459],\n",
            "        ...,\n",
            "        [-3.0381, -1.1851, -3.4450,  ...,  1.5634,  4.2921, -4.0112],\n",
            "        [-2.4684,  0.5222,  2.3221,  ..., -0.2823, -0.5063, -2.8970],\n",
            "        [-2.5021, -3.7785,  4.9354,  ..., -1.8260,  3.2049, -5.9424]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8726, -1.6960, -1.9576,  ...,  1.8996,  0.0241, -4.6531],\n",
            "        [-1.5750,  0.3859,  0.6563,  ...,  4.1062,  2.7560, -2.7668],\n",
            "        [-2.2630, -4.5275,  4.7749,  ...,  1.9130,  2.8542, -5.8307],\n",
            "        ...,\n",
            "        [-1.3607, -2.4787, -1.8611,  ...,  4.2784, -0.1328, -4.8632],\n",
            "        [-2.4793, -0.1080, -2.6208,  ...,  1.2448,  3.2567, -2.8747],\n",
            "        [-1.9521, -4.6147, -0.8526,  ...,  2.0549,  0.8126, -6.5499]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.1501, -0.8733, -0.9383,  ...,  3.4088,  1.8587, -1.8859],\n",
            "        [-1.6007, -2.2500,  2.9624,  ...,  3.4025,  0.7459, -4.0940],\n",
            "        [-1.9209, -3.6391,  1.6275,  ...,  3.1882,  1.0384, -5.9783],\n",
            "        ...,\n",
            "        [-3.7227, -1.2599,  2.3951,  ..., -2.9897,  5.1398, -1.4716],\n",
            "        [-2.8443, -1.2044,  1.1950,  ..., -0.7599,  2.5841, -2.7351],\n",
            "        [-3.4072, -0.6841, -0.2147,  ...,  1.4678,  4.3961, -7.0559]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9561,  1.3124,  1.8691,  ..., -0.3594, -0.3207, -1.7309],\n",
            "        [-0.1908,  0.6968, -3.1799,  ..., -0.0626,  0.0809, -3.1840],\n",
            "        [-0.6207, -1.2639, -3.4419,  ...,  4.6127,  1.9547, -6.0328],\n",
            "        ...,\n",
            "        [-2.7934, -0.2628,  1.4770,  ..., -3.2210,  2.2960, -1.8085],\n",
            "        [-3.1836, -2.7460,  0.5422,  ...,  0.4998,  1.0450, -3.1644],\n",
            "        [-0.7699,  4.5216, -1.2733,  ..., -1.5385,  7.8246, -1.1826]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8275,  2.8804, -1.7877,  ..., -0.2552,  5.4628, -4.2646],\n",
            "        [-1.3844, -0.8979,  0.4311,  ...,  2.0669,  5.3370, -5.6781],\n",
            "        [-2.4189, -1.9316, -0.2099,  ...,  0.3140,  1.4522, -2.9200],\n",
            "        ...,\n",
            "        [-2.3125, -1.5278,  1.2699,  ...,  0.5284,  2.7599, -3.4558],\n",
            "        [-3.0291, -2.0027,  0.8623,  ..., -1.8774,  2.6411, -3.4262],\n",
            "        [-2.3458, -0.4539, -0.3061,  ..., -4.1519,  5.0744, -5.5252]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8082,  0.0231,  0.4157,  ..., -4.3639,  2.3389, -2.5148],\n",
            "        [-4.0407,  1.1433,  1.7345,  ..., -2.5514,  6.2654, -4.5848],\n",
            "        [-2.3906, -0.3150,  3.8439,  ..., -0.7268,  3.4095, -3.6559],\n",
            "        ...,\n",
            "        [-3.1051, -2.0380,  3.8090,  ..., -1.8773,  1.8028, -4.6730],\n",
            "        [-2.4211,  0.6365,  3.0894,  ..., -0.4051,  0.2812, -1.9888],\n",
            "        [-2.8778, -1.5311, -0.6138,  ..., -0.1939, -0.9938, -1.0796]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1458, -2.3550,  0.3199,  ...,  1.7163, -1.6421, -5.2543],\n",
            "        [-1.7886,  3.1633, -1.9104,  ..., -2.5250,  2.3687, -2.5433],\n",
            "        [-3.3170, -0.1297,  0.2241,  ...,  0.0224,  1.7594, -1.9171],\n",
            "        ...,\n",
            "        [-3.5551, -1.7189,  2.4019,  ..., -0.9073,  2.9181, -3.4616],\n",
            "        [-2.3752, -4.4001,  1.4686,  ...,  3.9077,  2.5791, -4.1966],\n",
            "        [-1.6309, -1.3323, -2.3979,  ...,  3.8042,  3.0146, -2.8932]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7814,  1.0919,  1.1926,  ..., -0.6523,  4.0504, -2.6830],\n",
            "        [-2.5495, -1.0561,  3.6271,  ...,  0.7242,  1.1614, -3.3602],\n",
            "        [-3.3013,  0.5083, -0.4122,  ..., -2.0632,  3.7247, -3.3258],\n",
            "        ...,\n",
            "        [-1.5163, -2.1801, -4.0994,  ...,  0.7454,  2.1820, -4.8823],\n",
            "        [-0.1642,  0.1348, -3.7091,  ...,  1.9455,  4.7061, -3.9595],\n",
            "        [-3.1191, -0.3887,  2.3158,  ..., -0.6308,  1.9932, -2.2836]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3728, -2.7352,  1.2393,  ..., -1.8817,  0.8859, -2.3610],\n",
            "        [-3.0568,  1.8650,  1.9970,  ..., -0.5386, -1.0483, -3.0172],\n",
            "        [-3.7532,  1.0110, -1.0246,  ..., -0.8842,  4.2356, -3.2603],\n",
            "        ...,\n",
            "        [-1.5152, -0.2607,  3.2986,  ...,  1.2294,  0.0401, -2.2551],\n",
            "        [ 1.5853, -0.4865, -4.0513,  ...,  6.1787,  1.1480, -3.0914],\n",
            "        [ 0.5103, -0.4627, -1.9127,  ...,  4.6733,  2.0872, -3.9016]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.4076,  0.6524, -0.5438,  ..., -5.8447, -0.1821, -2.0407],\n",
            "        [-3.1207, -3.7283, -1.6616,  ...,  1.2186,  0.4273, -5.5671],\n",
            "        [-1.5014,  1.7845,  2.7992,  ..., -2.6491,  4.7782, -4.3005],\n",
            "        ...,\n",
            "        [-3.1176, -2.0817,  2.0143,  ..., -0.1685,  0.5269, -4.1602],\n",
            "        [-2.0186, -2.8021,  0.0648,  ...,  0.9116,  2.6904, -3.0405],\n",
            "        [ 0.0708,  1.9801, -0.7257,  ..., -0.4360,  2.1685, -2.5603]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9230,  1.7841,  1.6700,  ..., -2.1139, -1.3731, -2.3735],\n",
            "        [-3.3523, -2.2259, -1.1610,  ...,  2.1350,  1.5545, -5.3234],\n",
            "        [-2.8510,  3.8735,  0.8753,  ..., -0.3865,  5.5571, -3.6940],\n",
            "        ...,\n",
            "        [-3.3520, -1.7831,  2.6624,  ..., -0.4933,  3.8433, -4.3521],\n",
            "        [-1.2705, -0.6830,  0.0300,  ...,  0.5105,  3.5445, -4.1041],\n",
            "        [-1.9864,  0.3990, -1.4421,  ..., -3.3085,  2.8196, -0.2478]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0581,  2.5493,  1.4993,  ..., -0.9482, -2.4114, -2.0563],\n",
            "        [-1.9369, -1.5622,  0.3606,  ...,  0.7630,  3.1136, -3.9489],\n",
            "        [-0.6070,  1.0892, -0.3458,  ...,  4.3245,  3.7735, -3.2334],\n",
            "        ...,\n",
            "        [-3.9087, -0.5991,  2.1004,  ..., -3.1122,  1.0999, -1.5710],\n",
            "        [-2.1408,  0.7386, -1.7891,  ...,  2.5794,  5.0514, -3.3290],\n",
            "        [-1.9076, -0.2119,  0.9438,  ..., -0.6807,  3.6570, -6.7278]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9449,  0.1730,  3.1938,  ..., -5.5680,  2.6261, -3.7528],\n",
            "        [-3.9114,  0.1892,  0.6566,  ..., -4.7718,  6.5323, -8.1214],\n",
            "        [-2.6339,  1.6258, -1.6369,  ...,  3.2755,  3.0732, -4.8316],\n",
            "        ...,\n",
            "        [-1.6588, -1.8081,  2.6285,  ...,  3.9040, -0.2462, -1.6395],\n",
            "        [-1.6259, -2.0890,  1.7121,  ...,  0.3012,  0.9743, -3.9632],\n",
            "        [-1.4833,  0.4257, -2.7139,  ...,  1.3964,  3.2895, -4.0314]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1265,  3.0989,  0.3164,  ...,  4.1095,  4.1015, -6.1949],\n",
            "        [-1.4847, -0.3416,  5.3188,  ..., -1.5747,  4.7709, -4.8505],\n",
            "        [-2.0381,  2.5648,  0.3991,  ..., -4.9761,  4.7249, -2.5306],\n",
            "        ...,\n",
            "        [-3.6787, -1.0838,  1.7618,  ..., -0.2240,  3.7131, -3.2960],\n",
            "        [-3.7557, -0.3709, -0.3459,  ..., -0.2820,  1.4258, -2.7967],\n",
            "        [-2.3644,  3.3362, -3.6856,  ..., -1.8330,  1.3073, -2.6607]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6561, -0.9172,  4.3144,  ..., -1.0597,  3.3626, -3.9305],\n",
            "        [-3.1775,  1.1589,  0.2807,  ...,  3.0687,  2.4777, -2.2015],\n",
            "        [-2.6789, -1.3683,  4.5985,  ..., -1.5736,  0.3370, -4.7824],\n",
            "        ...,\n",
            "        [-3.9104,  1.8577,  0.5445,  ..., -2.0280, -2.7178, -3.0735],\n",
            "        [-3.2197, -0.0225, -2.0884,  ...,  0.6078,  1.2759, -2.5909],\n",
            "        [-3.7371, -0.6337,  2.6082,  ..., -1.3455,  4.9865, -4.6919]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1637, -0.0551,  1.9508,  ..., -0.7083,  2.3067, -2.6427],\n",
            "        [-3.2140, -0.6291,  0.3497,  ..., -2.0297,  2.5072, -4.9518],\n",
            "        [-2.0956,  2.3695, -0.3595,  ..., -1.5733,  2.6866, -0.7981],\n",
            "        ...,\n",
            "        [-2.5680, -1.2226,  1.0825,  ..., -1.9500,  2.5797, -3.6410],\n",
            "        [-2.3337, -2.4696, -3.6715,  ...,  2.9777,  1.1732, -4.4089],\n",
            "        [-1.7143,  1.4326, -2.1161,  ...,  2.5443,  6.3057, -4.3412]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9402e+00, -9.6681e-01,  1.4862e+00,  ..., -1.2035e+00,\n",
            "          3.2037e+00, -3.7127e+00],\n",
            "        [-2.1952e+00,  4.3500e-03,  4.1425e+00,  ..., -1.4427e+00,\n",
            "          2.1544e+00, -2.5465e+00],\n",
            "        [-7.8253e-01,  1.8840e+00, -8.6847e-01,  ...,  2.8863e-01,\n",
            "          3.4599e+00, -4.0699e+00],\n",
            "        ...,\n",
            "        [-3.9591e+00, -6.2352e-01,  6.4270e-01,  ..., -1.3798e+00,\n",
            "         -6.6617e-01, -2.3496e+00],\n",
            "        [-1.9907e+00, -6.6639e-02,  3.0885e+00,  ..., -8.3084e-01,\n",
            "          1.7588e-01, -4.5985e+00],\n",
            "        [-3.4741e+00,  1.5367e+00,  2.4035e+00,  ..., -1.1895e+00,\n",
            "         -9.7836e-01, -2.0689e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3637,  1.3613, -0.3373,  ..., -2.0352,  2.0418, -6.4125],\n",
            "        [-3.0445,  0.2100, -2.0267,  ..., -0.5259,  7.0692, -6.4594],\n",
            "        [-2.0636,  1.6147, -0.6922,  ..., -0.0771,  6.5682, -3.8876],\n",
            "        ...,\n",
            "        [-3.4115,  2.6770, -0.9524,  ..., -1.7675,  5.7637, -4.2146],\n",
            "        [-2.1351,  1.5097, -0.4124,  ..., -2.0590,  4.3362, -3.3497],\n",
            "        [-1.0670, -0.1149,  5.7716,  ..., -2.0862,  3.3900, -3.4515]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5348,  4.3496,  3.0059,  ..., -1.9702,  2.1728, -3.9660],\n",
            "        [-2.3296,  0.5234,  3.8970,  ...,  0.7103,  1.3368, -3.6150],\n",
            "        [-3.0226, -1.4381,  6.1144,  ..., -1.1359,  3.6064, -5.2109],\n",
            "        ...,\n",
            "        [-2.0742, -1.4902, -3.2200,  ...,  0.0665,  2.5473, -6.7610],\n",
            "        [-3.1649,  0.2825,  0.8720,  ...,  0.2308,  4.8098, -3.6719],\n",
            "        [-3.2975, -0.9354,  3.0137,  ...,  2.3006,  0.6533, -5.2885]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5596,  0.8404,  3.4964,  ...,  0.2332, -0.6788, -2.7037],\n",
            "        [-0.6973,  0.3980,  0.3827,  ...,  0.9108,  3.4002, -3.8239],\n",
            "        [-2.0731,  1.0704, -1.1139,  ..., -1.1161,  6.9748, -4.2632],\n",
            "        ...,\n",
            "        [-1.1357, -1.1292,  1.2689,  ...,  0.7622,  4.6228, -3.3819],\n",
            "        [-1.8324,  1.3483,  0.9046,  ..., -0.2856,  1.7923, -0.8811],\n",
            "        [-0.3596, -1.9207, -0.6355,  ...,  0.1140,  2.4636, -4.4628]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5020, -0.8171,  1.8610,  ..., -0.1242,  2.3205, -3.0524],\n",
            "        [ 0.5242,  1.7113, -1.9404,  ...,  0.2700,  2.7499, -0.1219],\n",
            "        [-2.4628,  1.0968,  1.1181,  ..., -0.8721,  3.2842, -2.2772],\n",
            "        ...,\n",
            "        [-0.1122,  0.5469,  3.2732,  ...,  1.0912,  4.8024, -4.4761],\n",
            "        [ 0.2545,  1.1525,  4.3135,  ...,  0.5172,  3.5484, -2.9813],\n",
            "        [-1.1591, -4.1611,  2.9631,  ...,  2.1736,  3.3382, -3.1109]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6252, -1.3910,  3.7774,  ...,  1.8303,  1.5058, -3.8200],\n",
            "        [ 1.0377, -0.5199, -4.5425,  ...,  4.8398,  3.1797, -5.6575],\n",
            "        [-3.9637, -0.5066,  2.0076,  ..., -1.6401,  0.7465, -1.9672],\n",
            "        ...,\n",
            "        [-3.3235, -2.0171, -1.3270,  ...,  0.2455,  2.6852, -5.5630],\n",
            "        [ 0.7231, -1.2755, -2.0043,  ...,  4.9693,  1.1126, -4.3790],\n",
            "        [-1.3548,  1.9013,  2.4385,  ...,  1.3306,  3.1450, -3.4803]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3110,  2.4481,  2.9197,  ..., -2.0285,  6.7516, -5.3613],\n",
            "        [-0.4758,  4.5772, -1.4698,  ..., -1.2441,  2.9202, -2.7210],\n",
            "        [-2.6405, -0.5663,  0.8668,  ..., -3.4784,  2.4172, -3.1352],\n",
            "        ...,\n",
            "        [ 1.6491,  0.2059,  3.5323,  ...,  2.7485,  5.3000, -5.5904],\n",
            "        [-3.2308,  1.2357,  1.3846,  ...,  0.3472,  9.4812, -5.6518],\n",
            "        [ 1.0936,  0.5616,  4.2647,  ..., -1.4655,  3.8535, -4.8849]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0387, -2.4269,  3.6582,  ..., -0.4761,  1.7320, -2.9854],\n",
            "        [-3.7288, -1.5868,  3.2155,  ...,  0.3620,  0.8055, -1.5136],\n",
            "        [-2.7197,  1.7075,  2.7770,  ..., -0.6155, -0.4659, -2.2467],\n",
            "        ...,\n",
            "        [-2.1797,  0.9837, -2.4428,  ..., -3.7560,  2.3140, -1.3110],\n",
            "        [ 2.2706,  2.1296, -0.7037,  ...,  1.7463,  2.9844, -2.8769],\n",
            "        [-2.8899,  0.8564,  0.2081,  ..., -4.0576,  3.9605, -4.0834]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5296, -3.8154,  4.5018,  ...,  1.4309,  1.1792, -5.0016],\n",
            "        [-2.9230, -0.8902,  2.3328,  ...,  1.5957, -0.5295, -3.2352],\n",
            "        [-3.0141,  0.0858, -2.0355,  ..., -1.9211,  4.9006, -3.1710],\n",
            "        ...,\n",
            "        [-3.9942,  3.1224,  0.8295,  ..., -2.7675,  2.5507, -2.6993],\n",
            "        [ 0.6356, -3.8238, -1.4068,  ...,  3.0104,  1.3936, -4.6850],\n",
            "        [-2.8506, -1.0706,  1.7315,  ..., -2.9188,  3.4821, -1.5697]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4121, -2.2830,  3.5260,  ..., -0.7146,  1.1629, -3.0046],\n",
            "        [-2.1063, -1.7864,  2.9540,  ...,  0.1994,  1.2590, -2.3528],\n",
            "        [-2.5449,  2.5922, -2.6143,  ..., -0.3624,  1.7667, -2.7188],\n",
            "        ...,\n",
            "        [-1.9417,  0.5792, -0.2049,  ..., -1.0021,  1.8134, -4.9781],\n",
            "        [-2.2568,  1.2964,  2.3844,  ..., -2.9372,  5.0119, -3.4511],\n",
            "        [-2.8292, -0.9953,  2.6423,  ..., -0.8620,  2.1878, -2.9986]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1666, -2.0451,  4.2113,  ...,  3.7034,  1.9986, -5.6546],\n",
            "        [-1.4333, -1.8175,  2.9647,  ..., -0.0087,  0.6369, -2.3627],\n",
            "        [-2.6632, -1.3708, -1.5764,  ..., -0.8959,  2.6471, -4.7239],\n",
            "        ...,\n",
            "        [-2.5616,  1.7353,  2.8981,  ..., -0.3416, -0.3500, -3.1108],\n",
            "        [-1.1980,  0.0495, -3.5559,  ...,  1.7957,  6.9354, -4.1868],\n",
            "        [-3.6579,  0.1656, -2.2246,  ..., -0.9145,  1.3972, -3.9505]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9698, -2.1378,  5.0686,  ..., -1.6268,  2.6923, -3.5521],\n",
            "        [-1.0093,  4.5572,  0.6515,  ..., -3.4742,  5.4158, -4.5059],\n",
            "        [-0.7436, -0.1582, -3.2195,  ...,  1.6371,  2.4429, -4.1684],\n",
            "        ...,\n",
            "        [-1.1797,  1.4896, -1.9680,  ..., -2.6560,  3.1383, -1.1076],\n",
            "        [-3.4581,  0.3198, -1.7007,  ..., -1.9779,  4.6335, -5.3162],\n",
            "        [-2.7538,  2.5344,  2.3682,  ..., -0.5062, -1.0685, -2.6606]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8990, -0.5209,  2.9652,  ..., -0.6850,  0.3375, -3.3848],\n",
            "        [-1.3208,  5.5728, -3.2910,  ..., -3.0507,  3.4405, -1.6263],\n",
            "        [-0.2039, -1.2991, -0.9962,  ...,  2.8055,  5.3716, -6.3996],\n",
            "        ...,\n",
            "        [-3.1343,  1.7420,  1.2716,  ..., -3.2253,  3.5668, -3.6421],\n",
            "        [-1.4086, -2.7664,  0.9652,  ...,  1.3303,  1.3426, -5.0586],\n",
            "        [-2.9099,  0.8598,  1.5278,  ...,  0.6117,  3.7536, -2.6530]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6372,  0.6614,  0.7287,  ..., -1.8081,  2.2756, -2.4976],\n",
            "        [ 0.2603,  1.4873, -3.2768,  ..., -3.8472,  5.5038, -3.4533],\n",
            "        [-1.6782, -0.3096,  0.3472,  ..., -1.7923,  5.9956, -4.0080],\n",
            "        ...,\n",
            "        [-0.9436,  0.8910, -3.8746,  ..., -3.8457,  5.5796, -3.7486],\n",
            "        [-0.5468,  0.5799, -1.6402,  ..., -2.3711,  0.2829, -3.4678],\n",
            "        [-1.9141, -0.8337,  2.6073,  ...,  0.1123,  0.6133, -0.6215]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5360,  0.2258,  1.9322,  ...,  1.0949, -0.5409, -3.5956],\n",
            "        [-0.5741,  4.3769, -2.1420,  ..., -1.1665,  8.8809, -3.5592],\n",
            "        [-3.3143,  1.5729,  0.0920,  ..., -2.2894,  1.9067, -4.1807],\n",
            "        ...,\n",
            "        [-0.0511,  8.9092, -1.3852,  ..., -3.1537,  9.4054, -2.4082],\n",
            "        [-2.9666,  2.0108,  1.6294,  ..., -1.3261, -1.8980, -2.8254],\n",
            "        [-3.6110,  1.1458,  1.9429,  ..., -3.8752,  4.3291, -2.5127]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0869,  0.2597,  0.9949,  ..., -2.7029,  1.0406, -2.5827],\n",
            "        [-3.8839, -0.2854, -1.3745,  ..., -1.2057,  2.4237, -3.4421],\n",
            "        [-1.1587, -2.4957,  3.7297,  ...,  0.0771,  1.2546, -2.2391],\n",
            "        ...,\n",
            "        [-0.8352, -2.4557, -1.2211,  ..., -0.6898,  3.7208, -3.9042],\n",
            "        [-2.1377,  2.6523, -0.5201,  ...,  0.1532,  3.3098, -2.1855],\n",
            "        [-2.9291,  1.5132, -1.7106,  ..., -2.5325,  4.3811, -3.8876]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.5532, -0.1790, -1.4053,  ...,  0.1406,  1.7353, -3.0459],\n",
            "        [-2.7880,  2.9845,  2.3623,  ..., -0.3408, -1.1583, -2.0163],\n",
            "        [-3.0385,  0.2446,  2.8674,  ..., -1.1667,  1.2983, -4.6178],\n",
            "        ...,\n",
            "        [ 0.4669,  2.3126, -1.3644,  ..., -3.3020,  4.8499, -1.6853],\n",
            "        [-1.1641, -0.6602, -0.0376,  ...,  2.4334,  0.7036, -3.6605],\n",
            "        [-1.3008, -1.6011,  2.4721,  ...,  0.3830,  0.6937, -3.5800]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6869, -0.3511,  1.7567,  ...,  0.2273,  1.0614, -1.0607],\n",
            "        [ 0.0197, -2.3147,  4.0405,  ...,  5.4057,  1.3052, -5.5028],\n",
            "        [-2.2452, -2.5297, -3.5196,  ...,  2.1668,  1.9278, -6.1629],\n",
            "        ...,\n",
            "        [-1.9370, -1.0634,  4.6377,  ..., -1.1507,  1.7040, -3.7246],\n",
            "        [-2.0896, -1.0083, -2.1365,  ...,  4.0106, -2.7048, -2.9808],\n",
            "        [-1.9011, -1.9306,  3.5514,  ..., -1.5603,  3.5745, -4.9284]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1928,  6.1486, -3.1170,  ..., -3.1235,  8.8711, -2.9312],\n",
            "        [ 1.1000,  0.8404, -0.5180,  ..., -1.0481,  2.5482, -3.0568],\n",
            "        [-1.8541, -2.5693,  0.0986,  ...,  0.6552,  3.6233, -4.8467],\n",
            "        ...,\n",
            "        [ 0.5750,  2.6176, -5.0829,  ..., -2.0372,  3.8177, -3.4080],\n",
            "        [ 1.0951, -0.6517, -1.3931,  ...,  1.7064,  7.3113, -4.5091],\n",
            "        [-2.5388, -2.6163, -0.6897,  ..., -0.9740,  2.8559, -6.2674]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2855, -3.7974, -2.1145,  ...,  3.5879,  0.3043, -4.3253],\n",
            "        [-1.3988,  0.7236, -1.8825,  ...,  3.4082,  1.5366, -1.8243],\n",
            "        [-2.7958,  2.7432, -0.2217,  ..., -0.5719,  3.1816, -2.1935],\n",
            "        ...,\n",
            "        [-2.3160, -0.6165, -2.6714,  ...,  1.2401,  0.7484, -3.1407],\n",
            "        [-1.8743,  0.0433,  0.2183,  ..., -0.2547,  4.3511, -5.4098],\n",
            "        [-1.7837, -1.4282,  2.6976,  ...,  1.7639,  0.9624, -3.2369]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2733,  0.7713, -3.5388,  ...,  2.7376,  3.2386, -4.0873],\n",
            "        [-3.0572,  0.8380, -1.3363,  ...,  1.1509,  4.0595, -4.3761],\n",
            "        [-3.4194, -1.7170,  1.2015,  ..., -0.2689,  1.2127, -2.3580],\n",
            "        ...,\n",
            "        [-2.7693, -2.5137, -2.6563,  ...,  1.9642,  2.8277, -3.4189],\n",
            "        [-2.4540,  0.6456,  3.0778,  ...,  0.8858,  1.4721, -3.9792],\n",
            "        [ 0.0770,  1.7060,  3.7050,  ..., -0.1383,  5.2273, -4.1001]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3207,  0.3111,  5.0318,  ..., -0.9630,  3.3526, -3.1947],\n",
            "        [-3.4862,  0.7783, -1.9375,  ..., -0.5021,  1.5983, -3.4555],\n",
            "        [-0.9020,  2.5109,  1.1085,  ..., -0.4008,  6.8436, -4.7367],\n",
            "        ...,\n",
            "        [-2.0849,  2.0997,  0.4648,  ..., -0.6918,  5.5280, -4.7328],\n",
            "        [-3.3086, -0.6902,  0.2461,  ...,  1.1519,  0.5618, -2.7800],\n",
            "        [-1.5468,  0.3779, -2.7066,  ..., -1.6898,  2.7610, -1.3557]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2404,  0.0496,  1.7898,  ..., -4.3066,  3.4540, -5.3290],\n",
            "        [-1.9578, -1.5364,  1.7645,  ..., -0.7675,  1.6401, -3.0846],\n",
            "        [-3.9764, -0.5607,  3.4429,  ...,  1.5492,  1.3819, -2.6710],\n",
            "        ...,\n",
            "        [-1.8100, -0.0221,  4.5936,  ..., -0.2694,  0.7200, -4.5934],\n",
            "        [-2.4543,  0.1793,  1.6572,  ..., -0.0376,  1.8972, -3.0919],\n",
            "        [-2.9638, -1.2160,  3.1260,  ..., -0.2546,  2.9348, -3.4292]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2146, -0.6408, -4.1979,  ...,  2.8956,  7.0944, -5.3500],\n",
            "        [-3.2566,  0.0245,  2.8161,  ...,  1.3259,  3.0571, -2.4475],\n",
            "        [-2.8001,  2.3777,  2.5206,  ...,  0.2745, -0.0933, -1.8001],\n",
            "        ...,\n",
            "        [-1.4718, -1.1348,  0.3504,  ...,  0.8883,  2.0500, -3.3863],\n",
            "        [-1.2806,  2.3304, -0.5996,  ...,  0.6226,  4.5696, -4.3732],\n",
            "        [-1.2397, -3.1935, -0.3623,  ...,  2.0864,  2.1610, -3.3355]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0537,  0.4094,  0.8134,  ...,  0.5938,  3.6686, -4.1341],\n",
            "        [-2.3928,  0.6628,  0.8701,  ...,  0.0576,  3.9998, -3.0013],\n",
            "        [-0.0266, -2.8668, -0.1262,  ...,  4.0229,  3.0320, -5.3254],\n",
            "        ...,\n",
            "        [-2.3590,  1.3316,  2.7680,  ...,  0.3968, -0.0435, -2.4778],\n",
            "        [-3.3862, -0.7333,  1.3796,  ...,  2.7608,  0.0474, -3.5952],\n",
            "        [-1.6888, -2.4856,  4.8109,  ..., -0.6407,  3.9437, -4.2318]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4359e+00, -8.9006e-01,  1.6593e-01,  ..., -3.3512e+00,\n",
            "         -5.2349e-01, -3.3411e+00],\n",
            "        [ 1.5546e+00,  1.0990e+00, -1.6849e+00,  ...,  1.5883e+00,\n",
            "          5.1925e+00, -2.7734e+00],\n",
            "        [-2.6190e+00,  1.0664e+00,  7.4426e-01,  ...,  4.3812e-01,\n",
            "          4.3354e+00, -4.6643e+00],\n",
            "        ...,\n",
            "        [-3.4378e+00, -3.3910e-01,  5.0428e-01,  ...,  2.7183e+00,\n",
            "          3.6798e+00, -3.5377e+00],\n",
            "        [-2.0243e+00,  8.7261e-04,  1.5262e-01,  ..., -3.3650e+00,\n",
            "          2.1185e+00, -1.8820e+00],\n",
            "        [-2.7911e+00, -7.5781e-01, -3.5055e-01,  ..., -1.9689e-01,\n",
            "          3.5956e+00, -3.0779e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2532, -1.0604,  3.7512,  ..., -0.4792,  3.5225, -3.2758],\n",
            "        [-2.1900, -1.3661,  4.2637,  ...,  0.5565,  2.7591, -3.1051],\n",
            "        [ 0.5140, -1.5416, -3.4366,  ...,  4.2748,  2.3223, -4.3691],\n",
            "        ...,\n",
            "        [-0.6080, -1.6517,  1.4815,  ...,  2.6402,  2.2481, -6.0973],\n",
            "        [-0.2762, -0.1124, -3.4671,  ...,  2.2654,  4.8791, -3.6847],\n",
            "        [-1.2386,  0.3873, -1.2353,  ..., -1.4654,  4.0690, -0.1784]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6775,  2.3987,  1.0902,  ..., -1.1197, -2.6398, -2.3928],\n",
            "        [-3.8552, -0.3857,  1.8219,  ..., -1.0986,  4.1544, -3.5486],\n",
            "        [-2.5941,  0.0646,  0.8286,  ...,  0.6532,  0.8187, -2.5639],\n",
            "        ...,\n",
            "        [-0.8530,  0.9020, -1.6771,  ..., -0.4983,  7.6662, -3.1845],\n",
            "        [ 0.3284,  0.2860,  0.8969,  ...,  2.3622,  0.9360, -3.4752],\n",
            "        [-0.1042,  0.6278, -2.1367,  ...,  2.5022,  6.4509, -3.2003]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5285, -2.2673, -6.0262,  ...,  2.6658,  1.4248, -3.4104],\n",
            "        [-2.9478, -0.9498, -1.1638,  ...,  5.5625,  0.9933, -3.0958],\n",
            "        [-2.5614, -0.9855,  5.0314,  ..., -2.4169,  3.1516, -3.0556],\n",
            "        ...,\n",
            "        [-3.7511,  1.1207, -0.3053,  ..., -2.2270,  3.9706, -3.6205],\n",
            "        [-3.3224, -0.5687, -2.1106,  ..., -3.0680,  3.6132, -3.0133],\n",
            "        [-1.9082, -1.8868, -2.8285,  ...,  2.0686,  4.6096, -5.0052]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8433,  1.5232, -0.2773,  ..., -1.5620,  0.7605, -3.2270],\n",
            "        [-1.1387,  0.6659, -2.2349,  ...,  0.9337,  7.2707, -4.3108],\n",
            "        [-1.0168, -2.3278,  3.2375,  ...,  4.1835,  3.2191, -5.0910],\n",
            "        ...,\n",
            "        [-3.5535,  0.4996, -1.1606,  ...,  1.9474,  0.7602, -2.9339],\n",
            "        [-2.8143, -2.1656,  4.0170,  ..., -1.0157,  1.9026, -3.2214],\n",
            "        [-2.6074, -2.0350,  0.0704,  ...,  0.0510,  5.0379, -5.8751]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4801e+00, -3.9168e+00,  1.6849e+00,  ...,  1.6624e+00,\n",
            "          3.5634e+00, -5.9298e+00],\n",
            "        [-3.9739e+00, -1.9603e+00,  2.3130e+00,  ..., -1.5934e+00,\n",
            "          2.1181e+00, -3.3887e+00],\n",
            "        [-1.1409e+00,  6.2445e+00, -2.0700e-03,  ..., -2.5076e+00,\n",
            "          8.4714e+00, -1.6866e+00],\n",
            "        ...,\n",
            "        [-1.5468e+00, -1.3129e+00,  4.3573e+00,  ..., -1.9457e+00,\n",
            "          2.4799e+00, -2.7749e+00],\n",
            "        [-2.6324e+00, -9.4093e-01, -3.3017e+00,  ...,  1.8864e+00,\n",
            "          3.2223e+00, -5.3801e+00],\n",
            "        [-8.1803e-03, -3.6794e+00,  1.1063e+00,  ...,  5.0205e+00,\n",
            "          2.4516e+00, -4.5194e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0594, -0.9035,  1.2877,  ...,  3.8001, -0.9624, -3.8611],\n",
            "        [-2.3484,  0.4038,  4.8308,  ...,  0.8607,  3.3839, -3.7809],\n",
            "        [-0.2718, -0.6373,  0.5353,  ...,  2.6961,  6.3613, -3.6594],\n",
            "        ...,\n",
            "        [-0.7268,  0.5699, -3.6239,  ...,  1.0542,  6.8439, -3.8564],\n",
            "        [-2.8692, -0.5448, -1.5710,  ..., -0.5418,  2.9667, -2.5803],\n",
            "        [-1.2227, -0.5965,  0.4099,  ...,  0.7841,  0.6719, -3.5902]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0264, -0.2441,  4.8610,  ..., -1.1360,  3.3995, -2.9450],\n",
            "        [-0.6145, -4.5361,  1.2248,  ...,  3.3940,  2.9558, -4.1127],\n",
            "        [-2.8838, -1.7702,  1.2357,  ...,  1.4348,  4.0911, -3.0655],\n",
            "        ...,\n",
            "        [-2.3077, -1.2374, -3.1485,  ..., -2.6937,  4.7820, -4.1740],\n",
            "        [-2.0015, -2.1330,  2.8893,  ...,  0.8985,  0.7686, -2.5206],\n",
            "        [-4.3442, -1.0485,  0.6352,  ..., -1.1085,  1.9707, -4.2034]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9654d83d4e6641f9b701e26deedc49e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.6675, -1.2115,  4.0104,  ...,  2.2080,  2.6053, -2.6046],\n",
            "        [-1.9644, -1.8461, -0.6106,  ...,  3.4031,  0.2274, -4.7013],\n",
            "        [-2.2365, -0.1295, -1.6609,  ..., -2.2154,  3.6917, -2.7618],\n",
            "        ...,\n",
            "        [-2.1457, -1.6883,  4.1503,  ..., -0.9018,  2.4151, -2.3552],\n",
            "        [-3.5476, -3.5565,  2.3350,  ...,  2.1787,  0.7751, -4.2278],\n",
            "        [-2.8895, -2.1691, -2.7524,  ..., -0.3566,  1.4925, -3.4044]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4454, -2.0473, -0.2568,  ..., -0.4239,  1.2272, -2.3625],\n",
            "        [-1.2026, -0.5874,  1.3257,  ...,  0.9772,  2.4820, -2.2544],\n",
            "        [-1.0368, -3.0051,  1.3646,  ...,  3.0784,  0.4481, -4.1622],\n",
            "        ...,\n",
            "        [-2.5793, -2.2334,  2.1369,  ..., -1.1402,  3.3143, -1.5083],\n",
            "        [-0.1890, -1.7305,  1.6576,  ..., -0.7101,  2.4665, -2.6450],\n",
            "        [-1.2966, -1.5579, -0.0849,  ...,  3.1864,  0.9636, -3.3525]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0967, -2.1756, -2.3681,  ...,  1.3662,  1.8216, -5.2364],\n",
            "        [-0.6999, -3.1336, -0.4842,  ...,  1.0575,  2.6741, -2.1694],\n",
            "        [-3.1966,  1.3425,  2.3340,  ..., -1.2628, -1.1887, -1.7540],\n",
            "        ...,\n",
            "        [-2.0428, -1.3003, -3.6155,  ..., -2.6427,  4.1987, -4.4648],\n",
            "        [-2.4733, -0.3661, -1.3260,  ..., -3.8533,  1.3241, -2.8006],\n",
            "        [-1.7016,  0.6759, -2.1451,  ..., -3.6131,  3.4492, -1.9028]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3949,  0.7403, -0.9263,  ..., -1.4334,  1.6590, -3.8507],\n",
            "        [-1.1259,  0.6251,  1.8033,  ...,  0.3777,  4.3533, -3.8441],\n",
            "        [-2.7031, -2.4366, -0.9626,  ...,  1.9688,  5.1745, -4.5833],\n",
            "        ...,\n",
            "        [-3.6705, -3.2959,  1.1930,  ...,  0.2788,  3.3254, -3.9916],\n",
            "        [-4.1412,  1.2529,  0.6948,  ..., -3.4051,  1.8536, -4.0579],\n",
            "        [-2.3202, -2.3205, -5.1726,  ...,  1.2157,  4.8880, -4.5751]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5959, -0.4489,  0.4422,  ...,  0.3423,  2.0764, -3.0710],\n",
            "        [-5.2785, -2.4261,  1.6542,  ..., -0.3094,  1.9686, -4.0455],\n",
            "        [-2.3862, -2.3594,  1.5656,  ..., -0.4508,  4.1117, -7.1051],\n",
            "        ...,\n",
            "        [-2.9285,  0.0873,  1.0470,  ..., -0.5424, -0.8023, -4.2167],\n",
            "        [-1.9292, -0.8352,  3.8643,  ...,  0.3758,  0.4508, -2.5177],\n",
            "        [ 0.3935,  0.1645,  2.5079,  ...,  0.5761,  3.0185, -3.9683]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9823,  5.7096, -0.0130,  ..., -3.2425,  6.7803, -1.3505],\n",
            "        [ 1.1964,  1.5980, -1.2014,  ..., -0.5027,  5.7468, -3.8060],\n",
            "        [-2.4764, -1.6125,  3.4184,  ..., -1.2740,  1.9640, -3.3288],\n",
            "        ...,\n",
            "        [-2.9635, -3.5037,  2.4039,  ...,  3.3426,  2.2711, -4.3715],\n",
            "        [-1.3291, -0.7341,  5.2254,  ..., -1.3563,  3.8553, -3.3735],\n",
            "        [-1.3535, -2.0938,  0.2966,  ...,  0.2305,  1.5687, -4.5879]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5896, -2.8423,  1.4413,  ..., -1.0592,  1.6947, -3.4818],\n",
            "        [-1.0298, -2.9367,  4.5959,  ...,  1.0141,  0.7600, -3.2964],\n",
            "        [-3.4051, -3.1439,  2.2583,  ...,  2.9735,  1.4411, -5.6624],\n",
            "        ...,\n",
            "        [ 0.5074, -2.6063, -3.7168,  ..., -1.1854,  1.0875, -4.2671],\n",
            "        [-4.6511,  0.9039,  1.8572,  ..., -6.3613,  0.7497, -2.8862],\n",
            "        [-4.1134,  0.5966,  3.6965,  ..., -4.1774,  3.3476, -4.5894]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9259,  0.7442,  1.3056,  ..., -1.1788,  3.2032, -2.3657],\n",
            "        [-2.1391, -2.3125,  0.6792,  ...,  1.0412,  1.6685, -5.4934],\n",
            "        [-0.7117, -0.3087, -1.7405,  ..., -0.0153,  4.8309, -2.6092],\n",
            "        ...,\n",
            "        [-1.6989, -1.7827,  4.4735,  ..., -2.3707,  1.8827, -2.7746],\n",
            "        [-4.6848, -2.8341,  5.0430,  ..., -4.5545,  3.3013, -5.4225],\n",
            "        [-2.9497,  0.4255, -0.2008,  ..., -0.6118,  4.0071, -2.5774]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5499, -0.2736,  1.1353,  ...,  2.2644, -0.4309, -4.1696],\n",
            "        [-2.4835, -2.5512,  5.0691,  ..., -1.0371,  1.8181, -2.8647],\n",
            "        [-1.9451, -1.6177,  5.1788,  ..., -1.0083,  4.2334, -3.8266],\n",
            "        ...,\n",
            "        [-1.6685,  0.1226, -1.5027,  ..., -5.0036,  4.7835, -4.5907],\n",
            "        [-0.7831, -2.0840,  0.2359,  ..., -1.0563, -1.6894, -2.5047],\n",
            "        [ 0.4497,  1.5150, -0.4273,  ...,  4.1711,  2.5551, -4.7117]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5278,  1.6522, -1.8780,  ...,  1.5915,  6.5598, -5.2868],\n",
            "        [-0.2041,  0.9381,  1.2773,  ..., -0.6400,  7.2122, -3.0053],\n",
            "        [-3.3012, -0.2004,  1.1827,  ..., -2.0532,  3.8985, -4.7514],\n",
            "        ...,\n",
            "        [-4.1497, -3.0902,  1.8957,  ...,  0.2102,  0.6628, -0.9221],\n",
            "        [ 1.0828, -0.2793,  1.7600,  ...,  1.7627,  1.6863, -3.7439],\n",
            "        [-3.6290,  4.4619,  2.8477,  ..., -3.8296,  4.6493, -2.8661]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2130, -0.6700,  1.0208,  ...,  1.1738,  4.4132, -4.6138],\n",
            "        [ 0.1028, -0.5644, -0.9608,  ...,  1.1743,  6.3223, -6.5674],\n",
            "        [ 0.1768, -1.2696, -0.6296,  ...,  1.8745,  6.5370, -5.6614],\n",
            "        ...,\n",
            "        [-2.2601,  0.9830,  0.3434,  ..., -2.0230,  3.0174, -1.2694],\n",
            "        [-1.3793,  0.4295,  3.8676,  ..., -2.9133,  4.6123, -4.4610],\n",
            "        [-3.9836, -2.3551,  0.6060,  ..., -3.4932,  6.4230, -4.3756]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8884,  0.0130, -1.4972,  ..., -0.0289,  0.2437, -2.2134],\n",
            "        [-4.8406, -0.5971,  2.6172,  ..., -2.9184,  3.8567, -4.7696],\n",
            "        [-1.6326, -2.6146,  3.6073,  ...,  0.9935,  0.3565, -3.5407],\n",
            "        ...,\n",
            "        [-2.6882,  0.3642,  2.7514,  ..., -3.7959,  2.4441, -4.0592],\n",
            "        [-0.6888, -2.2375,  6.8646,  ..., -1.4249,  4.0099, -3.8462],\n",
            "        [-0.6819,  1.7435, -0.8502,  ..., -4.2299,  5.3031, -2.2099]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7931, -2.6659, -1.3995,  ...,  3.2837,  0.1378, -5.1648],\n",
            "        [-1.8788, -2.7088,  5.5304,  ..., -1.1448,  0.9378, -4.5970],\n",
            "        [ 1.5378, -1.0614, -3.2928,  ...,  3.3706,  0.6171, -4.2030],\n",
            "        ...,\n",
            "        [-4.1525, -0.9647,  1.8328,  ..., -0.5536,  2.1501, -0.2237],\n",
            "        [-5.1553, -0.9064,  0.5079,  ..., -2.8144,  4.6282, -3.8353],\n",
            "        [-3.9831, -2.2420,  0.9932,  ..., -0.0781,  2.2646, -2.8794]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6785,  0.8862,  4.7785,  ..., -1.1417,  0.0811, -2.8220],\n",
            "        [-4.2991, -1.8598,  2.4301,  ..., -1.5724,  1.3669, -4.1495],\n",
            "        [-1.5803, -1.1693, -2.4750,  ..., -1.1251,  2.7887, -3.9433],\n",
            "        ...,\n",
            "        [-1.0898, -0.3996, -0.6583,  ..., -0.2494,  5.5700, -3.2522],\n",
            "        [-3.4753,  3.6815,  0.7632,  ..., -2.6909,  3.4222, -3.1621],\n",
            "        [-2.4676,  0.2640, -1.9980,  ..., -3.9614,  2.9516, -2.6598]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1196,  0.0682, -3.1626,  ...,  1.7356,  5.4947, -3.5469],\n",
            "        [-4.9370, -1.9773,  1.7373,  ..., -2.3259,  2.5910, -5.7950],\n",
            "        [-2.8694, -1.4947,  3.8541,  ..., -1.2983, -0.6270, -4.2376],\n",
            "        ...,\n",
            "        [-3.5754, -1.4242,  1.0310,  ..., -2.1562,  2.0664, -3.8465],\n",
            "        [-0.6890, -3.4399,  0.8817,  ...,  3.7124,  0.9784, -3.5447],\n",
            "        [-3.2953,  0.1092, -1.6566,  ..., -3.1434,  3.4623, -3.0211]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0536, -0.4198,  0.4962,  ...,  1.8113, -0.4598, -2.9460],\n",
            "        [-5.2723, -0.1891,  2.8366,  ..., -3.7631,  5.6660, -6.0844],\n",
            "        [-2.2893,  1.6596, -0.2798,  ..., -1.9255,  3.4310, -6.5195],\n",
            "        ...,\n",
            "        [-1.9129, -2.6549,  2.6336,  ..., -1.9827,  3.9366, -4.4019],\n",
            "        [-4.3475, -3.1452,  2.1364,  ..., -1.9713,  1.3657, -4.3441],\n",
            "        [-1.4146, -1.7079,  2.0340,  ...,  1.4437,  0.3966, -1.8200]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3273, -1.1180, -1.9576,  ..., -1.3884,  1.8255, -2.3679],\n",
            "        [-2.9822, -2.3503,  2.7284,  ..., -1.7887,  3.3685, -4.8252],\n",
            "        [-0.3975,  1.9978, -2.7966,  ..., -1.2619,  6.0686, -3.9827],\n",
            "        ...,\n",
            "        [-1.5051, -2.3066, -2.2197,  ...,  0.7478,  1.3797, -5.4246],\n",
            "        [-0.2214,  0.9398,  1.7121,  ...,  0.0306,  4.2829, -3.6131],\n",
            "        [ 0.1973, -1.2276, -0.9978,  ...,  3.0037,  2.4786, -4.7772]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.7180,  2.2777,  1.0967,  ..., -3.2635,  5.2156, -4.5700],\n",
            "        [-2.9901,  0.6780, -2.9587,  ..., -1.4588,  1.1812, -2.7572],\n",
            "        [-2.7244,  0.6668,  0.7503,  ..., -0.8078,  5.8622, -4.3914],\n",
            "        ...,\n",
            "        [-2.6503, -2.3949, -0.0634,  ..., -3.1224,  6.9502, -4.7716],\n",
            "        [-3.5055,  1.8521, -1.0268,  ..., -0.8550, -3.3402, -2.5940],\n",
            "        [-3.7625,  1.8823,  0.3693,  ..., -2.3032, -0.0414, -2.2311]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8094, -1.6123,  2.9612,  ..., -0.1326,  1.6421, -4.3605],\n",
            "        [-0.6151, -3.2855,  1.5647,  ...,  1.4319,  1.5728, -3.5220],\n",
            "        [-3.4785,  1.8108,  0.7583,  ..., -0.6355,  1.4276, -2.2313],\n",
            "        ...,\n",
            "        [-2.5600, -0.1367,  2.8406,  ..., -1.0784,  2.8664, -2.5023],\n",
            "        [-4.8352, -1.2654, -0.4867,  ...,  0.2278,  0.6744, -2.3852],\n",
            "        [-1.6820, -0.1903,  4.3445,  ..., -1.0919, -0.5426, -4.2645]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3059, -1.1098,  2.4005,  ...,  0.1325,  5.4269, -5.2039],\n",
            "        [ 0.3806, -0.1929, -0.1453,  ...,  0.8545, -0.5001, -5.0607],\n",
            "        [-0.7298,  0.0396,  1.5372,  ..., -1.5988,  4.7023, -3.0306],\n",
            "        ...,\n",
            "        [ 0.8290, -1.7294, -1.8343,  ...,  6.4137, -2.0044, -1.7908],\n",
            "        [-0.9460, -3.3229, -3.7715,  ...,  5.3138,  0.5726, -6.2009],\n",
            "        [-1.0772, -2.2357,  3.5687,  ...,  2.4593,  2.5163, -5.4550]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3946, -0.9829,  2.6586,  ..., -0.4777,  1.8447, -2.5668],\n",
            "        [-3.9056,  2.6144,  1.1461,  ..., -3.2393,  7.4053, -3.9665],\n",
            "        [-4.0976,  0.6410,  0.6582,  ..., -4.5601,  3.1578, -3.1616],\n",
            "        ...,\n",
            "        [-2.6991, -2.3141, -0.0588,  ...,  1.0131,  0.8649, -3.6049],\n",
            "        [-0.8552,  1.2856,  0.3609,  ...,  2.0044,  3.5547, -4.0888],\n",
            "        [-1.5333, -1.1123,  2.5465,  ..., -3.3389,  3.3320, -3.9122]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1452,  0.1887, -2.1644,  ..., -4.6992,  3.9465, -3.9265],\n",
            "        [-2.6530, -2.6153,  1.0787,  ..., -1.5381,  3.1741, -3.6771],\n",
            "        [-0.2265, -2.5879, -0.4334,  ...,  1.5438,  2.2602, -5.0732],\n",
            "        ...,\n",
            "        [-0.4385, -0.5438,  0.4572,  ...,  0.8875,  1.4163, -3.1102],\n",
            "        [-3.2825,  0.3830, -2.4321,  ..., -3.1618,  1.7969, -1.8514],\n",
            "        [-1.7300,  5.5283, -1.4311,  ..., -4.4114,  6.0860, -4.0795]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3493,  0.4698,  2.2035,  ...,  1.1532,  4.9692, -3.6058],\n",
            "        [-1.6964, -0.8528, -2.0749,  ...,  3.6674,  4.7602, -4.1385],\n",
            "        [-3.9693, -0.5390, -0.3165,  ...,  4.2149,  0.3304, -3.6913],\n",
            "        ...,\n",
            "        [-0.8752, -2.2800,  1.2688,  ...,  1.6140,  1.1058, -5.5086],\n",
            "        [ 0.7614, -2.9025, -5.5774,  ...,  0.2536,  4.8094, -5.1104],\n",
            "        [-2.5788, -2.1161,  0.5037,  ..., -0.3745,  3.9610, -6.3193]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.1524,  1.4717, -1.1974,  ..., -1.8527,  1.8748, -2.1906],\n",
            "        [ 0.4472,  0.8992,  2.7627,  ...,  0.7031,  5.1221, -3.8915],\n",
            "        [-3.0869,  1.8677,  1.4138,  ..., -0.9095, -1.0215, -1.6468],\n",
            "        ...,\n",
            "        [ 0.0947,  4.4339, -2.0727,  ..., -3.0524,  8.4103, -2.9390],\n",
            "        [-2.2573, -1.4891,  0.5813,  ..., -0.8677,  1.2695, -1.7746],\n",
            "        [-2.8226,  1.1959,  2.3252,  ..., -0.1084, -0.2528, -3.1137]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3613,  5.9452, -0.8077,  ..., -2.9796,  8.2292, -3.9834],\n",
            "        [-4.1914, -0.2843,  0.6686,  ..., -2.1473, -0.6303, -3.8997],\n",
            "        [-3.2676,  1.4274,  1.6812,  ..., -0.0722, -0.5212, -1.8857],\n",
            "        ...,\n",
            "        [-4.2742,  5.0162, -1.3091,  ..., -3.6665,  5.0389, -1.3188],\n",
            "        [-1.5608,  0.4138, -2.4483,  ...,  1.1940,  3.5155, -3.3286],\n",
            "        [-4.1856, -3.3824,  1.5391,  ..., -1.9514,  4.1487, -5.7042]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5091,  0.8822,  3.2437,  ..., -2.1581,  8.1354, -4.5297],\n",
            "        [-0.2259,  1.3554, -0.8826,  ..., -5.0159,  4.2920, -1.1009],\n",
            "        [-1.2502,  0.9959, -1.6726,  ..., -3.4191,  5.0425, -4.4678],\n",
            "        ...,\n",
            "        [-0.6564,  0.4148,  1.9690,  ...,  0.5658,  3.9210, -3.7518],\n",
            "        [-1.2435,  2.4180, -0.6785,  ..., -2.4365,  4.7211, -3.0997],\n",
            "        [-3.6219,  1.5834, -1.2469,  ..., -4.4197,  2.1689, -4.2933]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2128,  0.3124, -2.5390,  ..., -4.1212,  3.8896, -3.6947],\n",
            "        [-1.9278,  0.9266, -1.9969,  ..., -4.6677,  5.4965, -3.9102],\n",
            "        [-2.2341, -3.6086,  1.8055,  ...,  2.2362,  2.2302, -5.5728],\n",
            "        ...,\n",
            "        [-2.7269,  0.2518,  4.2062,  ..., -0.6275,  4.9085, -2.2530],\n",
            "        [-2.5251,  3.1848,  1.4137,  ..., -2.8175,  2.5518, -2.9720],\n",
            "        [ 0.4251, -1.5515, -3.8753,  ...,  5.2471,  0.3618, -4.2545]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.1747,  0.4218,  1.6667,  ...,  2.1327,  0.7870, -3.6535],\n",
            "        [-4.7731,  2.2718,  1.1429,  ..., -2.4623,  5.5675, -5.1780],\n",
            "        [-0.0409,  0.5489,  4.2628,  ..., -0.9885,  3.5065, -3.2036],\n",
            "        ...,\n",
            "        [-1.3944, -2.8543,  1.1591,  ...,  1.7339,  1.8456, -2.3721],\n",
            "        [-3.1114, -0.8681,  2.4333,  ...,  2.7261, -0.4459, -3.2969],\n",
            "        [-1.0267, -1.1888, -2.0573,  ...,  0.9926,  1.7669, -3.1177]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2405,  1.4152,  2.2332,  ..., -0.9689,  2.7278, -2.8834],\n",
            "        [-3.6008,  1.7150,  2.7739,  ..., -3.0880,  3.8011, -5.1335],\n",
            "        [-0.0630,  2.1002,  0.7756,  ...,  0.8068,  2.6845, -3.8975],\n",
            "        ...,\n",
            "        [-3.1265,  0.4753, -2.9080,  ..., -4.6721,  2.5197, -3.4320],\n",
            "        [-3.3710,  0.2564,  2.6128,  ..., -2.7550,  2.9263, -2.9717],\n",
            "        [-0.4042,  0.5107, -2.6371,  ...,  3.0298,  1.7381, -4.9743]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8174, -2.5178,  3.0015,  ...,  1.8416,  1.4553, -4.0694],\n",
            "        [-0.1219, -3.2962,  3.0355,  ...,  3.0723,  2.2482, -3.9936],\n",
            "        [-2.0353, -0.4730,  0.1250,  ..., -3.4165,  1.8180, -1.8825],\n",
            "        ...,\n",
            "        [-2.9301,  0.8177, -1.1785,  ...,  2.7005,  3.5963, -5.8660],\n",
            "        [-4.2356, -0.3082,  1.6774,  ...,  1.6576,  0.8666, -4.4487],\n",
            "        [-2.2733, -3.3765, -1.6664,  ...,  0.7319,  2.1811, -5.3016]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0955, -2.3495, -2.1955,  ..., -3.6191,  4.5282, -4.8391],\n",
            "        [-1.6072,  1.0995,  4.4202,  ..., -1.2717,  5.6140, -3.7534],\n",
            "        [-1.7265, -0.9572,  4.1512,  ...,  1.0068,  2.5125, -2.3222],\n",
            "        ...,\n",
            "        [-3.3195, -3.3197,  3.5558,  ...,  1.2766,  0.5742, -3.4117],\n",
            "        [-0.8018, -1.8574,  0.1127,  ...,  5.3096, -0.1710, -4.1021],\n",
            "        [-1.6379, -1.5087,  5.0980,  ..., -1.3406,  3.9491, -4.1791]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7131, -2.4068,  2.9621,  ...,  2.4823,  2.1967, -4.6739],\n",
            "        [-3.9344, -0.1923,  2.5551,  ..., -0.8735,  1.9637, -3.8476],\n",
            "        [ 0.2985,  1.2094, -1.7795,  ...,  4.3076,  0.6227, -2.4853],\n",
            "        ...,\n",
            "        [-1.1937,  6.7286, -3.8878,  ..., -1.4457,  5.7697, -1.3382],\n",
            "        [-2.6438,  1.9796,  2.1397,  ...,  0.4805, -1.5050, -2.5324],\n",
            "        [-2.7328, -3.5119,  4.0273,  ..., -0.7028,  1.8169, -4.7916]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6579, -1.5661,  2.4879,  ...,  0.3920,  1.5127, -1.8575],\n",
            "        [-3.1530,  0.4155,  1.3217,  ..., -2.2349,  1.2537, -4.2176],\n",
            "        [-3.4221, -2.0782,  3.9086,  ..., -1.0014,  1.9927, -4.9873],\n",
            "        ...,\n",
            "        [-2.2402, -1.0998,  2.8168,  ..., -0.2768,  0.2419, -3.4803],\n",
            "        [-2.6878,  0.3317,  0.2419,  ..., -0.9872,  4.8201, -2.8950],\n",
            "        [ 2.8282,  1.8576, -1.2854,  ..., -1.6437,  5.0297, -2.0143]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1331,  2.5121, -4.7339,  ..., -0.5641,  2.7549, -2.0672],\n",
            "        [ 0.5600, -3.0495, -1.1887,  ...,  1.8332,  2.9895, -6.0194],\n",
            "        [-4.6923,  1.7441,  0.7435,  ..., -2.6698,  2.2153, -4.1298],\n",
            "        ...,\n",
            "        [-3.3172,  0.7435,  2.0030,  ..., -3.2704,  4.1080, -3.8938],\n",
            "        [ 0.1952,  0.9939, -5.3819,  ...,  0.9721,  6.4703, -7.2785],\n",
            "        [-2.6314, -3.4684, -1.3023,  ...,  0.5508,  3.3440, -5.1809]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4472,  0.4480,  4.2856,  ..., -2.1458,  5.7658, -1.6262],\n",
            "        [-1.6229, -1.1097, -1.5722,  ...,  1.8733,  0.2403, -4.2628],\n",
            "        [-0.1955, -0.0867, -0.5280,  ...,  1.2963,  4.0923, -4.3987],\n",
            "        ...,\n",
            "        [-2.0308, -1.0187, -1.4844,  ...,  1.5116,  1.1527, -1.5464],\n",
            "        [ 1.5183,  3.6688, -1.5160,  ...,  2.0504,  5.3893, -3.3121],\n",
            "        [-4.1416, -2.6138,  2.5278,  ...,  1.0303,  2.9954,  0.0402]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0722,  1.5033, -1.0905,  ...,  1.9386,  6.7608, -4.6990],\n",
            "        [-1.8130,  0.3371, -1.3516,  ...,  3.9175,  5.7328, -5.6464],\n",
            "        [ 0.8849, -2.0994, -2.4551,  ...,  5.2430,  2.9573, -5.8485],\n",
            "        ...,\n",
            "        [-2.7510, -1.0202,  2.5896,  ..., -1.5527,  2.4901, -4.0906],\n",
            "        [-2.5208, -1.2509,  2.7410,  ...,  1.5188,  0.8189, -5.6826],\n",
            "        [-0.5350, -0.2236, -2.2767,  ..., -4.4869,  5.1878, -0.7392]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3218, -0.1270,  0.3849,  ...,  2.5655,  5.0596, -5.7722],\n",
            "        [-2.9380,  1.3711,  1.9921,  ..., -5.0397,  3.5018, -5.9419],\n",
            "        [-3.6965, -2.4742,  2.0349,  ...,  0.1647,  1.9876, -2.0988],\n",
            "        ...,\n",
            "        [-1.1992, -2.6089,  4.2763,  ...,  2.9197, -1.2170, -3.6034],\n",
            "        [ 0.2141,  0.2336, -1.1639,  ...,  3.0070,  2.4303, -4.2308],\n",
            "        [-2.1431, -0.8570, -1.8308,  ..., -3.1191,  3.3850, -3.2339]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7617,  1.1845,  4.0624,  ..., -0.9185, -0.9573, -3.0920],\n",
            "        [-2.8554,  0.4913,  5.4709,  ..., -0.6740,  5.7943, -4.6676],\n",
            "        [-1.0085, -2.1901,  0.2502,  ...,  1.1077,  3.4231, -3.8648],\n",
            "        ...,\n",
            "        [-3.2610,  1.0155, -0.4239,  ..., -1.7444,  2.3796, -3.2338],\n",
            "        [-1.9233,  2.5190, -1.7801,  ...,  0.0090,  2.0459, -2.8001],\n",
            "        [-0.9876, -2.2221, -3.5187,  ...,  3.2325, -0.1466, -5.6589]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3962, -1.4167,  0.0778,  ...,  1.9029,  3.3419, -4.3435],\n",
            "        [-1.2822, -1.3885,  3.1678,  ...,  0.1805,  2.6595, -6.2995],\n",
            "        [-3.9811,  0.5741, -0.9279,  ..., -1.0238,  1.0838, -3.2473],\n",
            "        ...,\n",
            "        [-2.3864,  2.5845,  0.7599,  ..., -2.5498,  1.8506, -5.1186],\n",
            "        [-3.3760, -0.4417,  4.9709,  ..., -1.6021,  4.5010, -4.8594],\n",
            "        [-3.5479,  0.9708, -1.9448,  ...,  2.4633,  3.2796, -4.5577]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8528, -1.9479, -1.3449,  ...,  4.7327,  0.0160, -5.3594],\n",
            "        [ 0.4090,  1.9008, -0.6992,  ...,  3.9222,  4.1768, -4.9522],\n",
            "        [-3.3004, -3.0295,  1.9708,  ...,  4.1116,  3.0850, -6.0751],\n",
            "        ...,\n",
            "        [-2.5610, -0.4170,  4.1330,  ...,  0.6535,  1.4275, -2.6910],\n",
            "        [-0.9403,  0.6359, -3.0158,  ..., -3.1812,  5.7145, -2.9892],\n",
            "        [-2.2461, -1.1777,  1.7894,  ...,  0.7222,  3.3628, -3.7476]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3072,  0.0160,  2.4899,  ...,  0.2410,  0.9605, -4.0402],\n",
            "        [-3.5300, -0.4403, -0.9532,  ..., -0.9583,  0.7740, -2.0991],\n",
            "        [-1.7619, -0.0975,  0.0458,  ...,  2.1178,  3.2910, -3.7696],\n",
            "        ...,\n",
            "        [-1.6567,  3.9379, -1.4411,  ...,  0.6962,  5.0524, -3.9783],\n",
            "        [-4.5594, -0.6863, -1.8930,  ...,  2.4383,  1.8200, -3.6163],\n",
            "        [-0.8349, -0.7090, -1.1917,  ..., -0.2756,  2.4630, -3.6724]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7594,  0.5732, -2.0652,  ..., -2.4298,  3.5567, -0.8100],\n",
            "        [-2.7383,  0.5648, -3.3118,  ..., -2.2071,  3.8027, -5.5404],\n",
            "        [-3.1325,  0.3400,  0.8938,  ..., -1.8503,  2.3798, -3.6530],\n",
            "        ...,\n",
            "        [-4.3919,  2.0727, -2.4401,  ..., -0.4466,  4.1057, -4.6145],\n",
            "        [-3.4035,  1.4719, -1.6827,  ..., -3.1302,  3.8803, -4.7432],\n",
            "        [-2.8611, -0.6667,  4.0196,  ..., -0.4574,  5.2962, -4.6556]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1350, -1.0441,  6.5804,  ...,  0.8431,  3.1795, -4.1083],\n",
            "        [-0.7882, -1.5934,  3.6628,  ...,  0.7316,  2.6773, -2.4862],\n",
            "        [-3.0151,  1.7436,  2.5868,  ...,  0.4226,  0.1813, -2.3823],\n",
            "        ...,\n",
            "        [-4.8407,  1.1192,  2.8429,  ..., -1.3198,  3.2309, -2.8797],\n",
            "        [-3.9868, -1.3456,  0.0623,  ...,  3.5545, -1.3508, -3.8023],\n",
            "        [ 0.4076,  2.0021, -1.1149,  ..., -5.0804,  5.5412, -2.6816]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8841, -1.9316,  6.6830,  ...,  0.5014,  3.0580, -6.6623],\n",
            "        [-3.0868,  2.4200,  2.4756,  ...,  0.1962, -0.9384, -1.8531],\n",
            "        [-0.5668, -2.7072, -1.1867,  ...,  4.1200,  1.6665, -3.6124],\n",
            "        ...,\n",
            "        [-2.7382, -0.0689,  2.2003,  ...,  0.6404,  1.8944, -3.6246],\n",
            "        [-4.1037,  3.6675,  1.1681,  ..., -2.1602,  2.3048, -2.7192],\n",
            "        [-1.8645, -1.5498,  3.4825,  ...,  1.5866,  0.5156, -2.0126]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0090, -1.7574,  5.0389,  ..., -1.1743,  1.3227, -3.7318],\n",
            "        [-3.9211,  0.6760,  1.1844,  ..., -3.2932,  0.9701, -2.9486],\n",
            "        [-2.3196, -0.9124,  1.1837,  ...,  0.6946,  2.9946, -3.8534],\n",
            "        ...,\n",
            "        [-3.2821,  1.0651, -0.9612,  ..., -0.9161,  2.9489, -2.7903],\n",
            "        [-1.3604,  1.3326,  0.2089,  ..., -1.2030,  9.3463, -7.0815],\n",
            "        [-1.4729, -1.2618,  3.1061,  ..., -1.8976,  2.7753, -4.2863]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3329, -2.6828,  3.7335,  ..., -2.2973,  0.8198, -4.5247],\n",
            "        [-0.0367,  1.8389, -1.4837,  ...,  0.3197,  2.8614, -3.4160],\n",
            "        [-2.1928, -0.9839,  3.5853,  ...,  2.1208, -0.1764, -2.7914],\n",
            "        ...,\n",
            "        [-2.8203,  4.0718,  0.3718,  ..., -1.2809,  2.5245, -3.0028],\n",
            "        [-5.3826,  1.1686,  1.1469,  ..., -3.8112,  2.1328, -4.5862],\n",
            "        [-1.8400, -1.1979,  4.4891,  ...,  1.4142,  0.4426, -3.0388]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3530, -0.8850, -1.6021,  ..., -0.7114,  4.8417, -5.4890],\n",
            "        [-1.6847, -0.9870,  2.0946,  ...,  2.1300,  1.2623, -2.5493],\n",
            "        [-3.8861,  1.2365, -1.2678,  ..., -0.4536,  3.2387, -2.9176],\n",
            "        ...,\n",
            "        [-3.2383,  0.9201,  3.1208,  ...,  0.6712,  1.3706, -3.9882],\n",
            "        [-2.1937,  5.9728, -1.2776,  ..., -2.8895,  7.7022, -4.3417],\n",
            "        [-0.2977,  0.0570,  0.4479,  ...,  0.1072,  3.3563, -3.9074]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.2762,  2.2076,  1.3718,  ..., -1.9870,  1.2255, -3.3789],\n",
            "        [-2.7661, -1.6845,  0.8312,  ...,  2.7264, -0.6801, -2.8761],\n",
            "        [-2.5500,  5.2820, -0.6104,  ..., -0.6024,  5.7901, -0.9941],\n",
            "        ...,\n",
            "        [-3.3161,  0.1544,  4.8478,  ...,  0.2528,  3.4814, -3.2135],\n",
            "        [-0.7559,  1.0910, -2.3337,  ...,  0.0887,  4.7063, -4.7987],\n",
            "        [-3.2350,  0.3957,  4.7154,  ..., -3.8835,  3.6466, -5.3602]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9945,  2.0569, -0.7043,  ..., -0.5660,  4.0360, -3.3333],\n",
            "        [-3.2366, -0.6331,  1.0743,  ...,  0.0159, -1.2994, -3.3508],\n",
            "        [-2.1484, -1.2971,  4.6208,  ..., -0.3898,  0.5959, -3.0984],\n",
            "        ...,\n",
            "        [-4.9712,  1.9308,  0.9257,  ..., -1.5940,  2.4441, -2.5881],\n",
            "        [-4.0039,  0.7110,  2.6307,  ..., -0.3659,  4.1836, -3.8128],\n",
            "        [-1.4532, -0.5809, -3.7768,  ...,  2.1464,  2.1029, -4.2265]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.4153, -0.9109,  0.9284,  ..., -0.8941,  1.8198, -3.5127],\n",
            "        [-3.0725,  1.9959,  1.4390,  ..., -0.8546, -2.4676, -2.0231],\n",
            "        [-3.8470,  1.9075,  0.6267,  ...,  1.7714,  4.2268, -1.8737],\n",
            "        ...,\n",
            "        [-1.5957,  5.1885, -5.7843,  ..., -6.9968,  4.1162, -2.5173],\n",
            "        [-4.1456,  2.9664, -0.0115,  ...,  0.1123, -2.7996, -2.5119],\n",
            "        [-1.6411, -1.4423, -2.0475,  ...,  6.3956,  1.3416, -4.6721]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0044, -0.8076,  2.7102,  ...,  2.1996, -0.7218, -3.1204],\n",
            "        [-3.0117,  0.4629, -0.9590,  ..., -2.6804,  4.8958, -6.2508],\n",
            "        [-4.2400,  1.1375,  2.0352,  ..., -4.3462,  4.0170, -3.1039],\n",
            "        ...,\n",
            "        [-1.3579, -3.8016,  0.0560,  ...,  2.9130,  2.1060, -4.2700],\n",
            "        [-2.6834, -3.0247,  5.5549,  ..., -1.4901,  2.2299, -4.8099],\n",
            "        [-2.9625,  4.0353, -1.9893,  ..., -4.0942,  4.8417, -4.4576]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4095e+00,  4.3270e+00, -3.2854e+00,  ..., -1.9302e+00,\n",
            "          3.7219e+00, -3.6424e+00],\n",
            "        [-8.1896e-01, -2.4369e+00,  3.8628e+00,  ...,  3.8701e+00,\n",
            "          1.1881e+00, -3.6451e+00],\n",
            "        [-1.8078e+00, -2.5633e+00,  3.9960e+00,  ...,  3.0881e-02,\n",
            "          8.5323e-01, -3.8502e+00],\n",
            "        ...,\n",
            "        [-6.2613e+00,  1.4288e-01, -6.8470e-01,  ...,  8.3664e-01,\n",
            "         -9.5685e-01, -3.1154e+00],\n",
            "        [-5.1637e+00, -7.7863e-01, -2.6647e-03,  ..., -6.7648e-02,\n",
            "         -4.7736e-02, -5.8922e+00],\n",
            "        [-3.4102e+00,  1.1328e+00,  1.8209e+00,  ..., -3.7363e-01,\n",
            "         -2.2440e+00, -3.5282e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1515,  0.1625, -2.4115,  ..., -0.2262,  1.1255, -5.9879],\n",
            "        [-0.4956,  1.2188, -1.0723,  ...,  3.4624,  2.1691, -3.7963],\n",
            "        [-3.3416, -2.0819,  2.0998,  ..., -0.7622,  2.0963, -3.3588],\n",
            "        ...,\n",
            "        [-3.6008,  0.1293, -0.0161,  ..., -4.2358,  1.3249, -4.4308],\n",
            "        [-1.4411,  0.4457,  4.9949,  ...,  0.7508,  3.5124, -3.7195],\n",
            "        [-2.9382, -2.4323,  2.4796,  ..., -0.4275,  3.3807, -3.5739]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5352, -2.6603,  5.4228,  ..., -4.9247,  5.5283, -5.1156],\n",
            "        [-3.5929,  2.1201, -0.5503,  ..., -1.5246,  2.0350, -3.8933],\n",
            "        [-1.7276,  1.4687,  1.3949,  ...,  0.9398, -1.4818, -0.6762],\n",
            "        ...,\n",
            "        [-3.5801, -0.5316, -0.9209,  ..., -1.2332,  3.5640, -7.2640],\n",
            "        [-2.4302,  0.9830,  4.5377,  ..., -0.6276, -0.6924, -3.6913],\n",
            "        [ 0.7517,  0.7665,  0.3024,  ...,  1.0355,  3.9125, -3.2204]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3305, -0.2105,  0.8730,  ..., -0.4050,  1.0836, -0.2646],\n",
            "        [-2.1024, -0.6726,  2.5830,  ...,  1.4480, -0.4127, -2.9135],\n",
            "        [-0.3843, -0.3241, -3.0912,  ...,  0.7687,  3.9528, -4.9619],\n",
            "        ...,\n",
            "        [-0.2421, -2.3899, -3.3757,  ...,  4.9262,  1.2642, -5.2124],\n",
            "        [-0.7762,  1.1161, -1.2914,  ...,  0.3691,  5.2120, -3.5666],\n",
            "        [-1.8722,  0.8130,  3.8969,  ..., -0.8680,  6.6152, -2.8497]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0811, -3.2544,  3.7480,  ..., -1.6010,  0.2219, -5.2621],\n",
            "        [-4.6315,  2.6331,  3.8490,  ..., -3.9586,  5.2938, -3.6754],\n",
            "        [-3.1319,  1.0833,  0.7895,  ...,  0.1071,  2.9467, -3.1488],\n",
            "        ...,\n",
            "        [-0.3064, -0.6407, -4.3943,  ..., -0.1693,  0.9512, -5.1425],\n",
            "        [-3.6324, -1.3937,  3.0817,  ..., -1.7222,  3.5436, -3.7574],\n",
            "        [-1.4825, -0.3954, -1.9595,  ...,  2.9786,  4.2789, -3.7025]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1247, -0.1197, -2.6131,  ...,  2.5267,  1.7282, -3.9592],\n",
            "        [-3.0661, -1.2346, -3.1973,  ..., -3.0529,  1.4941, -2.6521],\n",
            "        [-2.1689,  2.3718,  1.0620,  ...,  0.0301,  5.0745, -3.0492],\n",
            "        ...,\n",
            "        [-3.2837, -4.0204,  2.3528,  ..., -1.4106,  1.6356, -4.5222],\n",
            "        [-0.2451, -2.5593,  0.6028,  ..., -0.5188,  3.0512, -2.1869],\n",
            "        [-2.9618,  1.0785,  2.8024,  ...,  0.1503, -0.3838, -2.0613]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3476e+00,  2.4093e+00,  2.0404e+00,  ..., -2.6825e+00,\n",
            "          4.6505e+00, -2.9060e+00],\n",
            "        [ 3.8253e-01,  4.4958e-01, -4.8903e+00,  ...,  3.5256e+00,\n",
            "          3.2521e+00, -4.2339e+00],\n",
            "        [-4.2043e+00, -1.0333e+00,  8.5199e-01,  ..., -3.9740e-01,\n",
            "          2.2169e+00, -3.2562e+00],\n",
            "        ...,\n",
            "        [-3.6409e+00,  1.2310e+00,  3.0045e-01,  ...,  4.6038e-01,\n",
            "         -1.3837e+00, -1.2275e+00],\n",
            "        [-1.3364e+00, -4.0262e-01, -8.8225e-01,  ..., -2.6051e-03,\n",
            "          3.3016e+00, -3.6301e+00],\n",
            "        [-3.1675e+00, -8.4866e-01,  2.4325e+00,  ..., -4.8346e-01,\n",
            "          1.3545e+00, -3.0131e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8483, -1.9822, -0.0570,  ...,  3.8538,  0.3273, -2.3977],\n",
            "        [-4.3976, -2.4850,  2.4461,  ..., -1.3582,  1.6196, -3.1624],\n",
            "        [-3.1146,  0.1849, -0.6925,  ...,  0.1386,  1.1480, -3.1527],\n",
            "        ...,\n",
            "        [-3.6292, -3.1320,  1.6246,  ..., -0.2812,  1.7634, -3.6130],\n",
            "        [-4.2982, -1.4669,  2.7790,  ..., -0.9015,  2.9997, -3.8724],\n",
            "        [-0.6638, -2.0764,  0.7834,  ...,  1.7334, -2.4145, -3.4143]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9325, -1.5610,  4.0134,  ...,  0.8022,  0.3513, -3.7247],\n",
            "        [-3.3621,  3.7691, -0.7184,  ...,  2.6312,  3.2321, -1.5644],\n",
            "        [-2.9562, -1.1092,  0.5850,  ..., -1.8394,  1.1396, -3.0157],\n",
            "        ...,\n",
            "        [-2.1322, -0.8947,  3.1202,  ...,  0.5027,  1.2434, -2.0025],\n",
            "        [-3.0678,  1.8270,  2.6332,  ...,  0.2992, -0.3715, -1.8080],\n",
            "        [-1.7315, -2.8351,  2.8532,  ...,  0.4825,  0.4983, -3.9897]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5943, -0.4755, -1.1950,  ..., -1.2028,  2.1230, -4.4095],\n",
            "        [-0.9158,  0.9881, -2.6777,  ..., -3.5726,  5.4530, -2.9642],\n",
            "        [-3.9628,  4.8541, -6.3981,  ..., -5.3178,  4.2896, -5.8879],\n",
            "        ...,\n",
            "        [-4.0563,  4.0954, -2.1190,  ..., -2.3758,  0.8681, -2.2951],\n",
            "        [-1.4611, -2.6364,  3.3460,  ...,  1.1399,  1.3075, -2.2232],\n",
            "        [-0.8109, -4.1189, -0.1273,  ...,  3.2744,  1.3553, -5.1120]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1598, -1.1907,  7.0987,  ...,  0.3813,  1.6522, -3.4110],\n",
            "        [-2.7216, -4.5269, -0.6456,  ...,  2.8521,  0.6014, -4.1183],\n",
            "        [-2.3753, -3.5725, -3.4858,  ...,  0.4839,  0.3520, -3.0692],\n",
            "        ...,\n",
            "        [-1.4503, -3.0479,  4.4250,  ...,  0.8386, -0.4351, -3.4981],\n",
            "        [-3.6674, -0.1544, -1.9694,  ..., -0.9145, -2.8414, -2.8012],\n",
            "        [-0.7058,  0.2748, -1.5240,  ...,  1.8534,  4.0177, -6.4051]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.1509, -1.0365,  0.0259,  ..., -2.2569,  1.0370, -2.4454],\n",
            "        [-2.7315, -1.7904,  1.3077,  ..., -0.1350,  3.8746, -4.3839],\n",
            "        [-3.6827,  0.3575,  0.8260,  ..., -0.2027,  3.1081, -3.3831],\n",
            "        ...,\n",
            "        [-2.2804, -1.1987, -1.7118,  ..., -0.9795,  3.6839, -3.1299],\n",
            "        [-4.1676, -2.7648,  3.3192,  ..., -2.3344,  1.7313, -3.2371],\n",
            "        [-4.5699,  0.8736,  2.3019,  ..., -1.3170, -0.2685, -2.3659]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0993, -1.8983,  0.8574,  ...,  2.3227,  1.8492, -4.1808],\n",
            "        [-1.3130,  7.0336, -2.5659,  ..., -4.3710, 10.6928, -3.7091],\n",
            "        [-3.2650, -4.1096,  1.0756,  ...,  0.4033,  1.9821, -5.4945],\n",
            "        ...,\n",
            "        [-1.7227,  0.7585,  1.6781,  ..., -1.8729,  4.7794, -3.9791],\n",
            "        [ 0.5998, -2.0371,  1.1276,  ...,  1.8337,  3.5512, -3.2713],\n",
            "        [-3.3479, -3.1627,  2.7474,  ..., -1.0279,  0.7713, -3.9997]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8527,  1.3393,  1.4819,  ...,  0.1984, -2.4649, -3.6940],\n",
            "        [-2.9752, -2.1300,  1.5187,  ...,  0.1748,  3.2087, -3.0816],\n",
            "        [-2.4445, -1.8843, -0.3095,  ...,  5.8085, -2.9195, -5.2826],\n",
            "        ...,\n",
            "        [-1.3461, -2.3306, -2.1012,  ...,  2.4181,  3.7701, -5.3823],\n",
            "        [-4.3967, -0.5916,  2.2857,  ..., -4.8265,  1.7237, -4.9998],\n",
            "        [-2.1235, -1.8240,  2.8660,  ..., -0.2244,  0.0108, -3.2467]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8839,  2.1503,  2.7438,  ...,  0.3509,  4.1632, -4.4130],\n",
            "        [-3.4531,  1.6885,  1.3047,  ..., -0.2003, -1.7475, -2.0973],\n",
            "        [-1.1033, -3.1906,  4.5366,  ...,  0.8363, -0.3074, -3.1485],\n",
            "        ...,\n",
            "        [-2.9034, -2.1983,  1.6198,  ...,  0.7966,  2.8605, -2.7607],\n",
            "        [-3.9382, -2.7335,  1.0940,  ..., -4.1302,  2.7970, -6.4707],\n",
            "        [-2.7386, -0.4750,  2.2883,  ...,  1.3922,  5.1054, -5.1237]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0160, -2.4147,  1.8821,  ..., -0.3314,  0.7119, -2.8157],\n",
            "        [-5.6821, -0.5222,  1.9106,  ..., -2.0155,  2.8484, -3.5409],\n",
            "        [-1.4936, -2.5582,  0.1087,  ...,  0.1424, -0.5165, -5.3065],\n",
            "        ...,\n",
            "        [-4.4183, -3.3806,  1.8537,  ..., -2.2760,  0.7745, -3.9408],\n",
            "        [-1.5381, -0.8642, -1.6325,  ..., -3.3761,  1.8496, -0.6821],\n",
            "        [ 0.0878, -0.0297,  0.7086,  ...,  1.7384,  5.2947, -4.0716]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3491, -3.5365, -0.4124,  ...,  1.0237,  2.6094, -5.2990],\n",
            "        [-4.9336,  5.5359, -1.7728,  ..., -2.5838,  1.2585, -2.7815],\n",
            "        [ 1.8741, -3.7403, -2.6127,  ...,  3.5139,  1.6904, -3.1687],\n",
            "        ...,\n",
            "        [-1.3424, -1.7714, -0.8622,  ...,  1.9522,  7.7613, -6.2281],\n",
            "        [-3.5159,  0.5454,  0.3699,  ..., -1.1138, -0.6715, -1.8164],\n",
            "        [-3.4489, -3.0630,  2.7133,  ..., -1.2108,  2.1823, -3.9994]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7431, -0.3428, -2.2099,  ...,  1.0262,  5.4672, -4.6656],\n",
            "        [-2.9723,  3.7411, -3.2905,  ..., -5.9802,  7.4158, -3.0621],\n",
            "        [ 1.1409,  0.6139, -1.6569,  ...,  1.6378,  3.4214, -3.3813],\n",
            "        ...,\n",
            "        [ 0.7415,  0.3884, -1.4693,  ..., -6.2987,  4.0880, -1.0738],\n",
            "        [-3.5910,  2.7406,  1.9062,  ..., -2.6235,  6.1199, -3.4744],\n",
            "        [-3.9994,  2.4039, -1.7968,  ..., -3.4350,  2.5373, -2.8942]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5843, -1.0027,  1.3418,  ..., -6.3702,  0.0326, -3.0671],\n",
            "        [-2.0055, -1.8658, -2.4329,  ..., -6.3825,  5.5764, -2.6924],\n",
            "        [-0.1202, -0.5119, -2.9319,  ...,  0.8759,  5.5961, -3.1741],\n",
            "        ...,\n",
            "        [-0.1391, -1.9487, -3.8642,  ...,  2.4372,  4.4155, -2.2435],\n",
            "        [-2.1370, -0.8038,  0.2032,  ..., -1.3733,  3.5978, -3.2849],\n",
            "        [-1.4929, -3.8740, -2.8734,  ...,  1.6784,  0.4094, -4.2343]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6217, -1.3293,  0.1169,  ...,  0.2872,  4.3157, -4.3205],\n",
            "        [-3.5080, -3.5360,  1.3517,  ..., -2.9700,  3.1757, -2.7630],\n",
            "        [-3.6647, -1.5311,  1.8311,  ...,  1.9075, -1.5795, -2.9792],\n",
            "        ...,\n",
            "        [-1.5888, -1.6331, -0.6957,  ..., -0.1537, -0.2998, -0.4764],\n",
            "        [-1.3827, -4.3664,  1.1186,  ...,  3.2440,  0.5382, -5.2582],\n",
            "        [-3.8181,  0.4007,  3.1500,  ..., -5.4584,  3.2172, -4.4361]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2995, -3.3227, -0.2329,  ..., -0.1960,  7.3749, -7.0154],\n",
            "        [-2.8114, -1.5377, -0.1106,  ..., -0.5942, -1.4174, -5.1792],\n",
            "        [ 0.0075, -3.4931,  4.3533,  ...,  5.2144,  1.1325, -3.7712],\n",
            "        ...,\n",
            "        [-2.7908, -2.1312,  4.0072,  ..., -0.3286,  3.7345, -4.0979],\n",
            "        [-1.7770, -3.0724,  4.0912,  ..., -2.4288,  3.2936, -2.9961],\n",
            "        [-1.2381,  5.3386, -1.0101,  ..., -4.1661,  7.0893, -3.0214]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4258, -1.2132,  4.8686,  ..., -2.1034,  3.4444, -4.4806],\n",
            "        [-0.5888,  2.2686, -3.0057,  ..., -8.6096,  6.3469, -2.6204],\n",
            "        [-2.4544,  3.1911, -0.9797,  ..., -1.7395,  4.5297, -3.7308],\n",
            "        ...,\n",
            "        [-1.9233, -1.0179,  5.3405,  ..., -0.1059,  3.8419, -3.3606],\n",
            "        [-2.7215, -3.5838,  4.1347,  ..., -1.4657,  6.5122, -3.2973],\n",
            "        [-3.5482, -0.4339,  2.6082,  ...,  3.2236, -2.6300, -3.1681]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3177,  2.5749,  0.1277,  ..., -3.0468,  6.7311, -4.0702],\n",
            "        [-4.4582, -1.8232,  0.4544,  ...,  0.4479,  3.7601, -3.8876],\n",
            "        [-4.1598, -1.6175, -0.0631,  ...,  3.5309,  2.4899, -3.9520],\n",
            "        ...,\n",
            "        [-2.3084, -1.1636,  3.1907,  ..., -0.7280,  4.7756, -4.3189],\n",
            "        [-1.4596, -1.4600, -0.4217,  ..., -0.8094,  7.3684, -5.5077],\n",
            "        [-2.7774,  0.3843,  2.7538,  ..., -0.1169, -1.2846, -2.9222]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9574, -4.4464,  0.4411,  ...,  0.8126,  0.9343, -5.4047],\n",
            "        [-2.8783, -5.0197, -1.4806,  ..., -2.9039,  0.6202, -2.0599],\n",
            "        [ 0.6202,  0.6287, -3.5889,  ...,  0.3725,  6.0452, -4.1736],\n",
            "        ...,\n",
            "        [-3.8928,  0.3660,  1.7290,  ..., -2.6006,  3.7958, -4.6802],\n",
            "        [-4.1123, -0.9105,  0.4491,  ..., -2.7150,  0.1986, -3.0834],\n",
            "        [-2.6617,  2.5643,  0.9336,  ..., -1.1619,  3.1439, -1.7728]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3749,  0.3379, -2.1352,  ..., -0.9608,  1.6205, -3.7243],\n",
            "        [-1.7438, -1.5545,  2.0196,  ...,  2.9134,  4.2595, -4.4834],\n",
            "        [-5.3345, -1.2539,  2.0657,  ...,  0.0266, -0.8621, -2.8995],\n",
            "        ...,\n",
            "        [-2.2528, -2.6882,  3.2912,  ...,  0.8899,  0.9077, -2.5312],\n",
            "        [-1.4969, -2.1481,  5.8057,  ..., -1.3491,  3.1032, -3.1329],\n",
            "        [ 3.2555, -1.5326, -1.5595,  ...,  6.0098,  3.1771, -4.0514]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9637, -0.9487,  2.1428,  ...,  1.1333, -0.6760, -4.3631],\n",
            "        [-2.6646,  0.9433,  3.0669,  ...,  0.1434, -0.4620, -2.5966],\n",
            "        [-2.7868, -3.3062, -1.7817,  ...,  0.3152,  3.1930, -3.7188],\n",
            "        ...,\n",
            "        [-1.8884, -2.9714,  3.3921,  ..., -0.2130,  0.6171, -3.1563],\n",
            "        [-4.6666,  0.4015,  5.0395,  ..., -2.1262,  3.2477, -3.9183],\n",
            "        [-3.2187,  2.2104, -3.2576,  ..., -2.2801,  3.6729, -3.8745]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7352,  6.2219, -3.0398,  ..., -1.4209,  4.7327, -2.2538],\n",
            "        [-0.6620, -0.7392, -1.8106,  ...,  0.7048,  6.3969, -4.7766],\n",
            "        [-3.5230, -2.1120, -0.8582,  ...,  0.3594,  2.2252, -3.5656],\n",
            "        ...,\n",
            "        [-4.0601, -3.3833,  1.5108,  ...,  2.3195,  0.9616, -3.9095],\n",
            "        [-2.2641, -1.6933,  1.3583,  ..., -0.2134,  3.6667, -2.9995],\n",
            "        [-2.1109, -3.4021, -2.1559,  ...,  0.9708,  1.5477, -6.1580]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1695, -6.2952, -1.3598,  ...,  0.0417,  2.1317, -5.7225],\n",
            "        [-3.0104, -2.6602,  5.1309,  ...,  0.3936,  0.1446, -3.7680],\n",
            "        [ 0.1710,  2.2405, -2.0823,  ...,  0.2255,  3.2808, -1.6970],\n",
            "        ...,\n",
            "        [-1.2601, -1.9312, -1.0776,  ...,  3.7042, -1.1333, -4.9844],\n",
            "        [ 0.8563, -3.3781,  3.0052,  ..., -2.3824,  2.8838, -3.5812],\n",
            "        [-2.7191, -2.7845, -1.7173,  ..., -2.7310,  4.1207, -3.6284]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5481, -2.7848,  2.0503,  ...,  1.1441,  0.8919, -2.2071],\n",
            "        [-1.6458, -3.7454,  5.7546,  ...,  0.1559,  0.9706, -3.4563],\n",
            "        [-1.6928,  2.4100,  0.2409,  ..., -1.0407,  0.2789, -2.3438],\n",
            "        ...,\n",
            "        [-3.6156, -2.4633,  4.4905,  ..., -2.2849,  0.9302, -2.9273],\n",
            "        [-4.9439, -3.4683,  1.8062,  ..., -1.8186,  1.6230, -3.3847],\n",
            "        [-3.9225,  3.0730, -0.2114,  ..., -0.7876,  4.8724, -3.9878]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.5575,  0.5279,  0.4393,  ...,  3.0680,  0.4038, -3.3244],\n",
            "        [-3.0213,  0.6708,  3.1899,  ..., -0.2206, -1.4339, -2.3021],\n",
            "        [-3.5648, -1.0609,  4.8929,  ..., -1.8422, -0.6296, -3.8774],\n",
            "        ...,\n",
            "        [-4.2797, -1.7371,  0.3050,  ...,  1.2098,  4.4872, -5.7656],\n",
            "        [-2.3235, -1.7501, -2.9728,  ..., -0.6190,  1.8679, -2.9373],\n",
            "        [-4.9785, -0.9108,  2.2185,  ..., -0.4775,  1.6991, -2.6738]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9349, -1.5831,  1.6042,  ..., -0.7547,  3.2964, -3.7657],\n",
            "        [-2.0757,  0.8349,  3.8537,  ..., -2.6179,  4.2026, -3.4824],\n",
            "        [-2.3732, -1.6581,  4.7125,  ...,  0.5651,  0.1397, -4.4508],\n",
            "        ...,\n",
            "        [-0.9893, -1.8930, -2.3719,  ...,  2.0127, -0.5366, -4.6550],\n",
            "        [-3.8201, -4.2948,  1.6708,  ...,  2.4864,  0.3932, -4.5772],\n",
            "        [-5.4999,  0.5558,  0.6148,  ..., -3.3573,  1.7722, -3.8579]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3443,  0.5385,  0.6743,  ..., -3.6397, -0.8309, -1.9623],\n",
            "        [-0.3072, -0.8383, -5.9926,  ...,  0.8366,  4.7455, -5.2700],\n",
            "        [-3.2747, -0.1622, -0.8546,  ..., -0.6204, -1.0444, -2.9701],\n",
            "        ...,\n",
            "        [-2.0458,  6.5299, -4.1997,  ..., -3.8615,  6.4097, -3.6211],\n",
            "        [-1.4933, -3.8067,  6.7070,  ..., -0.5719,  4.6309, -3.9085],\n",
            "        [-1.5253, -4.9123,  3.3755,  ...,  2.6492,  0.9043, -5.8496]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9722, -3.4517,  4.6910,  ...,  3.8757,  1.8144, -2.9230],\n",
            "        [ 0.1487, -0.7778, -0.6455,  ...,  1.5546,  3.3074, -3.1225],\n",
            "        [-1.1227, -1.6992, -0.4190,  ...,  1.3737, -1.9988, -4.2854],\n",
            "        ...,\n",
            "        [-1.5287, -5.9009,  3.4904,  ...,  4.1636,  0.8197, -6.3199],\n",
            "        [-3.2870, -0.1884,  2.9218,  ..., -3.2151,  4.4735, -4.1833],\n",
            "        [-2.3227, -2.6798,  4.5236,  ...,  2.6365,  1.7851, -3.0534]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6161, -0.0636,  3.6345,  ..., -2.4036,  2.9315, -3.1250],\n",
            "        [-2.9008,  0.1374,  3.7619,  ..., -1.8316,  5.0892, -3.3449],\n",
            "        [-3.4565, -2.4780,  2.9868,  ..., -0.3961,  2.6054, -3.1882],\n",
            "        ...,\n",
            "        [-4.4349, -2.6476,  0.7085,  ...,  1.6869,  1.8252, -5.4347],\n",
            "        [-2.2306, -0.3675, -1.0462,  ..., -1.7480,  4.6414, -0.7926],\n",
            "        [-2.2033,  1.1359, -1.8442,  ..., -0.3856,  1.2496, -3.7697]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6449,  3.8547,  2.2005,  ..., -1.7167,  5.3574, -4.7748],\n",
            "        [-0.9735, -2.4950, -2.0050,  ...,  0.2163,  6.8425, -5.3246],\n",
            "        [-3.5834, -1.9164,  2.4769,  ..., -3.6183,  1.9431, -6.3727],\n",
            "        ...,\n",
            "        [-2.7059, -2.3032,  0.5039,  ...,  1.7221,  1.3500, -2.4025],\n",
            "        [-3.3524, -2.5563,  1.4098,  ...,  0.5319,  0.0329, -2.8615],\n",
            "        [-3.0554, -2.2101,  0.6465,  ..., -1.2898,  0.3120, -5.5541]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2957, -3.0663,  2.2737,  ...,  0.4619,  0.9160, -3.7195],\n",
            "        [-0.1006, -0.7387, -1.0539,  ...,  3.1171,  2.5780, -2.8050],\n",
            "        [-1.4815,  5.4207, -1.3285,  ..., -2.8577,  7.1203, -0.9776],\n",
            "        ...,\n",
            "        [-1.1762, -1.1493,  3.8026,  ...,  0.1686,  3.1831, -4.0141],\n",
            "        [-4.0614, -2.3671,  1.3055,  ..., -2.4837,  2.7723, -4.6062],\n",
            "        [-2.2404, -3.3335,  1.9777,  ...,  0.4317,  1.0556, -3.1247]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7065, -3.0987,  5.4706,  ..., -0.4715,  0.7427, -3.0995],\n",
            "        [-1.0065, -3.0542,  0.8179,  ...,  2.8060,  0.9419, -4.1281],\n",
            "        [-2.3391, -2.9779,  0.6088,  ..., -0.4224,  0.9336, -2.1852],\n",
            "        ...,\n",
            "        [-2.1901, -1.2082, -2.5369,  ..., -0.1957,  2.7908, -5.2418],\n",
            "        [-2.9850, -1.6063,  2.2984,  ...,  1.0965, -0.4488, -0.9125],\n",
            "        [-3.3856,  1.1953,  2.2672,  ..., -0.3667, -0.7668, -1.7194]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6415,  0.6475,  3.7553,  ..., -0.3704, -0.2743, -2.2834],\n",
            "        [-1.9617, -0.8016,  0.6605,  ...,  1.8280,  0.4546, -3.6086],\n",
            "        [-4.6387,  0.4398,  2.3802,  ..., -2.1132,  3.4731, -1.8716],\n",
            "        ...,\n",
            "        [ 1.7288, -1.7063, -2.0715,  ...,  6.0923,  4.3111, -3.5766],\n",
            "        [-1.6919, -2.3782,  4.3111,  ..., -0.6578,  0.9568, -1.3562],\n",
            "        [-2.8329,  3.7221, -0.4608,  ..., -1.3107,  6.3506, -3.7490]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9064, -0.1889, -2.2246,  ..., -3.5240,  2.5834, -2.1357],\n",
            "        [-2.2599, -4.0369, -2.1352,  ..., -0.3576,  1.8822, -4.7722],\n",
            "        [-3.9335, -2.5841, -1.2322,  ...,  2.7961, -0.1618, -4.4790],\n",
            "        ...,\n",
            "        [-3.9403, -1.4722,  0.4856,  ...,  0.7379,  0.4443, -1.8007],\n",
            "        [-3.6394,  0.2352,  1.5032,  ..., -2.9670,  4.9840, -3.5499],\n",
            "        [-0.8431, -0.1825, -3.0833,  ..., -0.8564,  2.7318, -3.0331]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7029,  0.0649, -1.0216,  ..., -2.3053,  5.2206, -2.2088],\n",
            "        [-2.2605,  3.6575, -1.4990,  ..., -0.8693,  1.8515, -2.5679],\n",
            "        [-1.6002, -1.3133, -0.0690,  ..., -2.1457,  4.5567, -4.3745],\n",
            "        ...,\n",
            "        [-1.7430, -0.5245, -0.8430,  ..., -1.4208,  2.5445, -1.7608],\n",
            "        [ 0.6550, -1.1024, -5.2923,  ...,  3.2604,  3.0748, -2.7293],\n",
            "        [-1.5459, -2.2090, -1.8697,  ...,  0.4256,  1.8891, -3.3298]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6459, -4.0927,  2.3151,  ...,  3.3266,  1.5892, -4.8666],\n",
            "        [-2.4659,  0.1816,  0.0504,  ..., -1.0184,  1.8379, -1.8893],\n",
            "        [-3.7384, -3.9472,  2.6285,  ...,  1.6475,  5.5521, -5.0574],\n",
            "        ...,\n",
            "        [-2.4451, -0.0539, -1.5615,  ..., -0.4440,  4.3395, -3.8684],\n",
            "        [-4.3279,  3.4146,  1.0729,  ..., -2.6717,  4.2020, -3.1167],\n",
            "        [-1.9860, -0.4341,  2.3584,  ..., -0.3029,  0.8001, -3.4926]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8803, -5.5156,  3.9742,  ..., -0.3279,  1.8472, -5.8830],\n",
            "        [-2.7841,  0.5243,  2.5606,  ..., -1.2535,  3.3578, -3.7113],\n",
            "        [-1.2241, -2.5439, -1.6455,  ...,  4.1377,  1.1965, -5.5154],\n",
            "        ...,\n",
            "        [-1.3032,  1.8512,  2.2677,  ...,  1.6936,  3.0828, -3.4315],\n",
            "        [-0.7498,  1.1846,  4.1969,  ...,  1.7287,  2.2483, -3.1617],\n",
            "        [-3.0469, -1.2525, -2.2430,  ..., -3.0496,  2.5906, -2.9815]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0050,  3.5805, -0.5020,  ..., -1.1476,  5.2433, -5.6024],\n",
            "        [-2.5373, -1.3757,  2.0916,  ..., -3.7607,  4.6231, -4.2962],\n",
            "        [-1.9015, -3.8521,  4.4087,  ..., -0.5669,  0.8943, -4.2144],\n",
            "        ...,\n",
            "        [-1.5043, -2.8180,  1.4487,  ...,  0.3070,  2.5567, -5.3792],\n",
            "        [-2.9727,  1.3924,  2.2504,  ..., -0.6295, -0.7618, -1.6899],\n",
            "        [-3.7487, -1.5830,  2.6998,  ..., -1.5710,  3.0813, -5.1341]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5979,  1.1730,  4.9146,  ..., -5.4758,  7.2122, -5.3443],\n",
            "        [-3.1759, -1.7904,  1.9053,  ...,  1.8351,  1.1408, -3.0308],\n",
            "        [-5.9407,  0.5244,  4.3190,  ..., -0.3282,  2.0705, -3.6630],\n",
            "        ...,\n",
            "        [-4.5286,  1.1325,  1.9111,  ..., -3.2613,  3.1508, -3.1630],\n",
            "        [-3.8283,  0.7838,  5.2022,  ..., -3.1919,  3.8649, -4.6451],\n",
            "        [-1.2931, -2.2368,  2.7821,  ...,  0.4958, -0.4252, -2.2745]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5150, -2.1590,  7.3344,  ..., -2.1378,  4.8088, -4.9093],\n",
            "        [-2.4938, -0.8308, -1.5615,  ..., -4.8836,  3.7938, -1.6242],\n",
            "        [ 0.9207, -6.3038, -1.6693,  ...,  3.0361,  0.6456, -2.6946],\n",
            "        ...,\n",
            "        [-2.8248, -3.0375,  2.3921,  ..., -1.2830, -1.2591, -5.4639],\n",
            "        [-2.3587, -0.0735,  2.4003,  ...,  0.6411,  0.7994, -2.2859],\n",
            "        [-1.1102, -2.8536, -0.2115,  ...,  4.6568,  1.4925, -5.7250]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5787, -1.8142, -3.7307,  ..., -2.2006, -0.5497, -2.4941],\n",
            "        [-4.9719, -0.8761,  0.9947,  ..., -3.1467,  3.9917, -5.6713],\n",
            "        [-3.7182,  0.4817,  3.7531,  ..., -3.3613,  2.7801, -3.7852],\n",
            "        ...,\n",
            "        [-4.3893, -2.4329,  2.2568,  ..., -1.4291,  1.5292, -3.2748],\n",
            "        [-1.3937, -4.2733,  1.9110,  ...,  1.0463,  0.2050, -4.5904],\n",
            "        [-1.8129, -1.7758, -1.9138,  ..., -3.0652, -1.2980, -2.7682]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5595, -0.0820,  2.3611,  ..., -2.1535,  3.9197, -2.4504],\n",
            "        [-0.8794, -2.7591, -3.9813,  ..., -1.5808,  1.6771, -2.2134],\n",
            "        [ 0.8270, -1.0540, -4.6251,  ...,  2.1128,  4.9508, -5.7057],\n",
            "        ...,\n",
            "        [-3.2227,  5.2854,  0.4004,  ..., -1.0241,  3.9700, -2.9496],\n",
            "        [-2.6503, -2.0250,  3.2045,  ..., -0.5430,  2.9610, -3.7135],\n",
            "        [-2.3388, -4.5463,  0.8292,  ...,  0.3941,  0.6900, -4.0495]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9412, -3.1296,  2.0525,  ...,  0.1775, -0.9899, -3.8328],\n",
            "        [-3.6495, -1.0041,  2.6347,  ..., -1.9766,  2.4615, -2.7398],\n",
            "        [-3.3143,  2.6835, -0.1634,  ..., -3.5499,  1.5582, -2.5126],\n",
            "        ...,\n",
            "        [-4.8507, -1.8492,  0.0337,  ..., -0.0882,  1.5510, -3.4407],\n",
            "        [-2.1252, -2.9169, -0.1946,  ...,  2.3402, -0.4008, -3.8063],\n",
            "        [-3.7686,  0.6379, -0.2117,  ..., -1.9802,  2.1859, -3.1452]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4629,  1.5077, -0.7205,  ..., -3.8972,  1.9559, -1.8311],\n",
            "        [-3.3402,  1.2085, -1.4654,  ...,  0.6068,  1.9142, -2.1386],\n",
            "        [-0.3192, -2.9434, -6.2540,  ...,  2.6257,  2.2553, -4.4546],\n",
            "        ...,\n",
            "        [-3.4140,  0.0476,  3.8399,  ..., -2.3165, -1.8599, -2.9755],\n",
            "        [-2.6446, -0.9651,  4.9772,  ..., -0.2946,  2.2609, -3.0511],\n",
            "        [-1.3954,  4.9301, -1.1556,  ..., -0.7336,  5.7628, -4.1671]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9437, -0.3778,  0.9553,  ...,  1.4407,  3.7848, -3.8216],\n",
            "        [-3.3386,  1.1412,  1.4244,  ..., -1.3052, -3.0203, -2.0157],\n",
            "        [ 0.0096, -8.2751,  1.0259,  ...,  2.2279,  1.1910, -5.9625],\n",
            "        ...,\n",
            "        [-1.1003, -2.6320, -1.5514,  ..., -0.0421,  0.4123, -4.1531],\n",
            "        [-0.8655, -4.5248, -4.0410,  ...,  3.0500,  1.1874, -3.0078],\n",
            "        [-4.0893, -1.8522,  0.5514,  ...,  0.5212, -1.2437, -2.3879]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2224e+00,  7.5723e+00, -3.9948e+00,  ..., -5.3484e+00,\n",
            "          5.1902e+00, -1.6325e-01],\n",
            "        [-2.2213e+00, -3.9251e+00,  1.7889e+00,  ..., -1.9852e+00,\n",
            "         -2.0618e-03, -2.2962e+00],\n",
            "        [-1.6601e+00, -1.2477e+00,  1.8308e+00,  ..., -2.1076e+00,\n",
            "          6.2248e+00, -2.9367e+00],\n",
            "        ...,\n",
            "        [-4.1952e+00,  3.4281e-01, -7.3081e-01,  ..., -1.3637e+00,\n",
            "         -3.1753e+00, -2.6358e+00],\n",
            "        [-7.8000e-01, -3.4017e+00,  1.9128e+00,  ...,  4.4984e+00,\n",
            "          2.1321e-01, -3.7887e+00],\n",
            "        [-1.8140e+00, -7.2483e-01, -7.0289e-01,  ...,  2.7193e+00,\n",
            "          2.1955e+00, -3.9932e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.1493, -1.0546,  0.4299,  ...,  2.3193,  1.1835, -2.0152],\n",
            "        [-1.9342, -3.9319,  3.2528,  ...,  0.0402,  1.7431, -2.9906],\n",
            "        [-1.7656, -3.1923,  5.5666,  ...,  0.7932,  3.4039, -2.7486],\n",
            "        ...,\n",
            "        [-2.3292, -1.2457,  3.8493,  ..., -1.9867,  5.3027, -4.7007],\n",
            "        [-2.2989, -0.5809, -0.9842,  ..., -1.4691,  2.0888, -4.4706],\n",
            "        [-0.8389, -1.9497, -1.0196,  ..., -1.9912,  7.7808, -4.6802]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7068, -1.1915, -0.1822,  ..., -1.5155,  2.9954, -2.8285],\n",
            "        [-3.3526, -1.5962,  1.8335,  ..., -1.4678,  2.1657, -3.3044],\n",
            "        [ 0.2882,  0.7624, -0.1147,  ..., -0.6463,  3.0333, -3.1898],\n",
            "        ...,\n",
            "        [-3.5377, -0.6500, -2.6793,  ..., -0.6681,  0.9446, -4.4005],\n",
            "        [-0.2433, -1.1311, -4.5960,  ..., -5.9013,  3.9323, -1.7445],\n",
            "        [ 0.9895, -0.3261, -3.1275,  ...,  1.0078,  4.6121, -3.0313]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7924, -0.2129,  3.0293,  ..., -0.6822,  3.7503, -3.7175],\n",
            "        [-1.5836,  0.2122, -2.3396,  ...,  1.3613,  3.5653, -5.0730],\n",
            "        [-2.1289, -1.6484,  0.4593,  ..., -4.6047,  2.9478, -2.4601],\n",
            "        ...,\n",
            "        [-1.4488, -4.2758, -0.6391,  ...,  1.0681,  0.2136, -4.3438],\n",
            "        [-2.4014, -1.9005,  5.1588,  ...,  0.3746,  0.2311, -2.9217],\n",
            "        [ 2.0113, -7.2097,  0.6268,  ..., -1.0810,  4.0238, -5.6257]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8177, -3.9763, -2.9822,  ...,  1.4340,  0.8665, -1.5757],\n",
            "        [-2.5200, -0.6765, -2.5715,  ..., -6.1481,  5.6998, -4.1982],\n",
            "        [-2.3598, -0.6845, -1.2507,  ...,  1.0507,  1.0039, -1.9404],\n",
            "        ...,\n",
            "        [ 0.3015, -1.1135, -0.0570,  ...,  2.9006,  0.4204, -5.5200],\n",
            "        [-0.2290, -1.1589, -0.3761,  ..., -2.4928,  1.3456, -4.7231],\n",
            "        [-3.6130,  1.7493, -0.3529,  ..., -1.1654, -3.0960, -2.0249]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9947, -0.4172, -0.1999,  ..., -0.2000,  2.1325, -0.5581],\n",
            "        [-2.5751, -0.3579,  2.4443,  ...,  0.5570,  2.0944, -3.8482],\n",
            "        [-3.1621, -0.8591,  2.0352,  ..., -3.2877, -0.4217, -2.7796],\n",
            "        ...,\n",
            "        [-0.8578, -1.6576, -4.7506,  ...,  0.9736,  3.4242, -4.5893],\n",
            "        [-2.1640, -2.0114,  6.5963,  ...,  0.1232,  2.9616, -2.1804],\n",
            "        [-4.0336, -4.9968,  2.1655,  ...,  1.7046, -0.3033, -5.4103]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6866, -2.0938,  0.8378,  ..., -0.4249,  0.7872, -2.9664],\n",
            "        [-3.6040,  1.1702,  1.0010,  ..., -1.7772, -2.3828, -2.1593],\n",
            "        [-1.9854, -1.9148,  0.7092,  ...,  3.0970,  0.8788, -1.0121],\n",
            "        ...,\n",
            "        [-1.3655, -1.8666, -3.5765,  ..., -2.8188,  3.7229, -5.1497],\n",
            "        [-1.5626, -2.1895,  1.1527,  ...,  1.5721,  1.9620, -4.0238],\n",
            "        [-2.7675, -3.2919, -3.9589,  ..., -0.5478,  4.6285, -5.3809]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7252, -0.9008,  1.9760,  ..., -1.5230,  0.1599, -3.8755],\n",
            "        [-2.4187,  2.7525,  0.5038,  ..., -4.1752, -0.0527, -4.6771],\n",
            "        [-4.6509,  0.8554, -0.2088,  ..., -1.9343,  4.0725, -5.5422],\n",
            "        ...,\n",
            "        [-0.3915, -1.3760, -2.9627,  ..., -3.1946,  4.4701, -1.4937],\n",
            "        [-2.3824,  1.0202,  2.3129,  ..., -0.0400, -0.5132, -2.0195],\n",
            "        [-3.2282, -0.5574,  1.8489,  ..., -0.8236,  1.9724, -2.5282]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9936, -3.1109,  2.6392,  ..., -0.6042,  0.4228, -4.3344],\n",
            "        [-1.2860, -3.7650, -0.5858,  ..., -2.9892,  1.5722, -4.8382],\n",
            "        [-3.0987,  1.5092,  1.4158,  ..., -0.6459, -0.9580, -1.9419],\n",
            "        ...,\n",
            "        [-2.4464, -2.3624, -1.2891,  ..., -1.9558,  0.6288, -0.7658],\n",
            "        [-1.0690, -3.1511, -1.5628,  ...,  4.8596,  0.8725, -2.2132],\n",
            "        [-1.5188, -1.6156,  0.7440,  ...,  4.8311,  2.0213, -2.9995]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8032,  3.5779,  1.0750,  ..., -2.0559,  5.3820, -3.0536],\n",
            "        [-2.4433, -1.4895,  1.6132,  ...,  0.2518,  2.9184, -3.5716],\n",
            "        [-3.0129, -0.1637, -0.3779,  ..., -0.1872,  0.7226, -2.2323],\n",
            "        ...,\n",
            "        [-3.2325,  1.0365,  1.4066,  ..., -1.5301, -0.3149, -2.4682],\n",
            "        [-3.1000, -1.9784,  3.1747,  ..., -0.5753,  1.0079, -2.7414],\n",
            "        [-2.1291, -0.4729,  3.5304,  ..., -0.7450,  2.2762, -2.1019]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5501, -3.5633, -1.4580,  ..., -1.5439,  2.8774, -3.6096],\n",
            "        [-1.3327, -2.5448,  0.5091,  ...,  0.0269,  1.7585, -3.8082],\n",
            "        [-2.8725, -0.3919,  0.4485,  ..., -0.8437, -0.8598, -2.5520],\n",
            "        ...,\n",
            "        [-2.1527, -2.2413, -4.7376,  ..., -0.9932,  1.8446, -6.6684],\n",
            "        [-2.2678, -1.9463,  0.2114,  ..., -0.7611,  0.5092, -2.7917],\n",
            "        [-0.7384,  0.5169, -1.6023,  ..., -1.5145,  4.8364, -5.0742]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2406, -1.9131, -4.9383,  ...,  1.7953, -0.0699, -1.3833],\n",
            "        [-2.4806, -0.1508, -0.4527,  ...,  0.1056, -0.1200, -3.1361],\n",
            "        [-1.8903, -6.9728,  0.1929,  ...,  1.2052,  1.1718, -5.8997],\n",
            "        ...,\n",
            "        [-0.9013, -0.3663, -2.0177,  ...,  0.5694,  2.0991, -2.4176],\n",
            "        [-1.8767, -2.2481,  6.2645,  ..., -0.5333,  4.2328, -4.3865],\n",
            "        [-0.9682, -3.5261, -1.3253,  ...,  0.4646, -0.8680, -2.7075]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.1632, -2.6874,  1.3454,  ..., -0.0881,  1.1783, -0.6887],\n",
            "        [-3.3079,  0.6009,  3.1077,  ..., -1.6844,  3.0792, -3.2911],\n",
            "        [-2.7138, -1.1215,  1.3780,  ...,  0.4596,  3.8466, -3.8415],\n",
            "        ...,\n",
            "        [-4.6362, -2.7269,  1.1571,  ..., -1.0400,  0.3934, -2.6188],\n",
            "        [-1.6981, -1.9625,  2.8753,  ...,  1.5972, -0.8586, -2.6918],\n",
            "        [-1.9776, -3.1528,  3.0291,  ..., -0.0702,  2.8820, -3.8095]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6871, -1.3642, -0.1883,  ...,  2.4264, -0.0073, -3.0413],\n",
            "        [-1.9826, -4.9250,  3.3003,  ...,  2.6644,  3.1330, -4.0880],\n",
            "        [-0.1937, -0.1925,  2.5871,  ..., -0.0221,  4.3919, -3.2660],\n",
            "        ...,\n",
            "        [-1.7432, -3.0903,  1.4885,  ...,  2.1647,  1.0927, -4.3503],\n",
            "        [ 1.7717, -0.3805, -2.0540,  ..., -0.7023,  2.3729, -2.8542],\n",
            "        [-2.1690, -5.2835,  3.4353,  ...,  2.4466,  1.1437, -4.4583]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3545,  2.3418,  1.9182,  ..., -0.2568, -1.7068, -1.8831],\n",
            "        [-4.0923,  1.9831,  1.9375,  ..., -0.1457,  5.4481, -3.7550],\n",
            "        [-0.2967, -2.7713,  0.6865,  ...,  0.9761,  0.8339, -3.2348],\n",
            "        ...,\n",
            "        [-3.6071, -0.6944, -3.0363,  ..., -1.0834, -1.0771, -3.2114],\n",
            "        [-1.1836,  1.4807, -1.2427,  ...,  0.0727,  3.4010, -3.7711],\n",
            "        [-2.1882, -2.9526,  4.3789,  ..., -0.3462,  0.1005, -3.0966]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2707, -0.1541, -1.3735,  ..., -2.9306,  1.7532, -0.9900],\n",
            "        [-1.8863,  0.7847,  1.5122,  ..., -0.8437,  3.3956, -4.4181],\n",
            "        [-2.4308, -0.4542,  4.0992,  ..., -1.1463, -0.1605, -3.3447],\n",
            "        ...,\n",
            "        [-1.8131, -1.6351, -3.6150,  ..., -4.1180,  2.7080, -2.0756],\n",
            "        [ 1.1702, -1.0338, -2.8834,  ...,  4.8305, -1.8950, -2.6710],\n",
            "        [ 0.3968,  8.9535, -1.9847,  ..., -5.5888,  8.6346, -1.7839]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2480, -6.0557, -4.1514,  ...,  3.3460, -0.2917, -5.1779],\n",
            "        [-2.5426, -1.1786, -1.0787,  ..., -3.0052,  0.2427, -1.4115],\n",
            "        [-1.4023,  0.2429, -0.3129,  ..., -0.8373,  2.8072, -1.9211],\n",
            "        ...,\n",
            "        [-1.0606, -3.2434,  2.4879,  ...,  1.7906,  4.4023, -5.4137],\n",
            "        [ 0.6836, -1.3774,  1.2070,  ..., -1.5246,  5.2668, -4.1802],\n",
            "        [-2.1394, -2.5577,  2.5284,  ...,  2.2120,  2.2050, -2.7189]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9587, -2.6868, -1.8744,  ...,  0.6901, -0.4525, -3.3909],\n",
            "        [-2.5435, -2.3064, -0.7872,  ...,  1.1983, -1.7668, -4.8792],\n",
            "        [-3.9974, -0.8756,  3.8777,  ...,  0.2644,  1.9530, -3.1203],\n",
            "        ...,\n",
            "        [-3.2206, -1.2132,  2.9800,  ..., -1.8458,  1.0288, -3.0090],\n",
            "        [-1.6676, -3.3508, -2.2938,  ...,  1.0431, -0.4731, -5.6815],\n",
            "        [-3.2095, -3.5799, -0.1784,  ...,  4.0835,  0.8182, -2.5765]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2734, -0.2326,  4.7397,  ..., -1.4138,  2.8174, -2.7818],\n",
            "        [-0.7397, -0.3054, -2.6505,  ...,  0.1230,  0.4207, -1.3243],\n",
            "        [ 2.5570, -0.2466, -5.9851,  ...,  3.2109,  1.1346, -2.9207],\n",
            "        ...,\n",
            "        [-3.4128, -1.4359, -1.0852,  ..., -3.2371,  3.7725, -4.1078],\n",
            "        [-2.5453,  0.0190, -3.0607,  ..., -2.1723,  2.4089, -1.8604],\n",
            "        [-3.0865, -3.1566,  2.9099,  ..., -1.3412,  1.2046, -3.1181]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.5208, -2.1403,  0.4772,  ..., -2.2511,  2.9138, -3.9975],\n",
            "        [-4.8091,  2.9960, -0.5375,  ..., -3.4502,  2.5149, -3.4168],\n",
            "        [ 1.7585, -3.2385, -3.2581,  ...,  4.8218,  1.4088, -5.8178],\n",
            "        ...,\n",
            "        [-1.1166,  1.8635,  0.1870,  ..., -1.0658,  6.6732, -4.9025],\n",
            "        [-0.6776,  2.0971,  0.8536,  ..., -2.0254,  4.9515, -2.6542],\n",
            "        [-2.0477, -1.4225,  4.3342,  ..., -0.5268,  2.3385, -3.8719]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2427,  1.2035,  0.1579,  ...,  3.9259,  1.5120, -2.1783],\n",
            "        [-1.6263, -5.2871,  2.6218,  ...,  3.5583,  0.5221, -5.1324],\n",
            "        [-4.9259, -0.1847,  0.9831,  ..., -5.9575,  6.5072, -3.3006],\n",
            "        ...,\n",
            "        [-2.1984, -1.8620,  4.0928,  ..., -2.3421,  0.6674, -2.9187],\n",
            "        [ 0.5858, -1.0654, -2.7890,  ..., -1.1693,  1.3752, -0.7536],\n",
            "        [-3.2073, -3.7107, -0.6597,  ...,  0.6596,  1.5415, -5.0582]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4488, -0.7942,  4.2706,  ..., -0.3913,  0.3173, -3.6875],\n",
            "        [-0.0451,  0.5227, -2.3886,  ...,  0.7252,  1.6503, -3.7912],\n",
            "        [-1.0591,  8.1421, -4.3017,  ..., -4.3024,  8.3087, -0.9848],\n",
            "        ...,\n",
            "        [-1.8433, -2.0157, -2.9308,  ..., -1.4875,  2.6482, -3.3990],\n",
            "        [ 0.8928, -2.4339, -6.3298,  ..., -1.5470,  6.7861, -6.8161],\n",
            "        [-4.4579, -0.7089, -1.7788,  ...,  2.6803, -0.5210, -2.9310]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1179, -2.4525, -3.6207,  ...,  1.6178,  1.6981, -4.5565],\n",
            "        [-1.4290, -2.0702, -5.2144,  ..., -4.5724,  5.2393, -4.1829],\n",
            "        [-2.6389,  0.4417, -2.4576,  ..., -4.4695,  3.7206, -2.2133],\n",
            "        ...,\n",
            "        [-2.4058,  2.8023, -0.2781,  ..., -5.8937,  4.2431, -2.2184],\n",
            "        [-1.4558, -1.4347,  1.9586,  ..., -0.7858,  3.0647, -3.0570],\n",
            "        [-1.6808, -1.6867, -5.5946,  ..., -5.3536,  2.0106, -4.5733]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2648, -1.8797,  0.3860,  ...,  2.6902, -1.1792, -3.9276],\n",
            "        [ 2.2333, -2.1086, -4.6300,  ...,  4.7767,  3.2422, -3.4655],\n",
            "        [ 0.5041, -2.4655,  1.7151,  ...,  3.3703,  1.5152, -4.1716],\n",
            "        ...,\n",
            "        [ 0.2129, -3.0170, -1.3005,  ...,  2.3664,  3.9103, -2.3915],\n",
            "        [-0.0344, -0.9975,  5.8906,  ...,  1.3092,  3.1463, -4.5306],\n",
            "        [-3.6505, -3.1697,  2.4466,  ..., -0.1112,  2.2584, -3.8051]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6287,  2.2010, -0.2247,  ..., -0.8177, -3.0432, -2.2832],\n",
            "        [-1.0879, -3.1022,  2.0956,  ...,  0.9653,  1.9699, -5.3860],\n",
            "        [-2.4477,  0.2957, -2.8906,  ..., -3.2846,  4.8106, -5.4602],\n",
            "        ...,\n",
            "        [-0.6734, -0.3301,  2.3826,  ..., -0.8420,  1.9560, -2.1878],\n",
            "        [-4.2000,  2.7813, -2.3558,  ..., -1.6982,  2.1178, -2.5706],\n",
            "        [-1.7182, -0.2717,  0.9034,  ..., -1.6920,  4.5830, -4.2276]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1334, -1.6485, -3.7366,  ..., -1.7152,  1.5363, -3.3574],\n",
            "        [-3.2483,  2.8032,  1.1181,  ..., -0.0157, -2.5211, -1.9623],\n",
            "        [-2.8633, -2.5423,  3.1978,  ..., -0.6175,  1.6976, -2.2547],\n",
            "        ...,\n",
            "        [-3.6844,  2.2971,  1.2665,  ..., -0.5051, -2.1610, -1.4866],\n",
            "        [-0.0235,  3.2256,  1.6989,  ...,  0.4841,  1.3712, -3.1027],\n",
            "        [ 1.6071,  6.7298, -1.9346,  ..., -5.1162,  7.0515, -2.0983]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2320, -5.7082,  5.0704,  ...,  1.7796,  0.6536, -2.4263],\n",
            "        [-1.9414,  0.1287, -2.5740,  ..., -7.7205,  5.4301, -2.1163],\n",
            "        [-3.4009,  1.5481,  1.2313,  ...,  2.0111,  0.6115, -2.5838],\n",
            "        ...,\n",
            "        [-3.6722, -1.6820,  1.6565,  ..., -3.5172,  0.5048, -1.4165],\n",
            "        [-2.2492, -2.2316,  3.7103,  ...,  0.7370,  0.1231, -1.8930],\n",
            "        [-3.5146, -2.0288, -3.9929,  ...,  3.6976,  0.3998, -5.1582]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4736, -1.4615,  3.5071,  ...,  0.5211,  1.6977, -3.6713],\n",
            "        [-2.6308, -4.3484,  1.9622,  ...,  1.8062,  1.1366, -0.8661],\n",
            "        [ 0.9585, -0.5786, -1.9443,  ..., -2.6878,  3.0472, -4.9416],\n",
            "        ...,\n",
            "        [ 1.9566, -5.1649, -2.8603,  ...,  4.6807,  3.9393, -2.5353],\n",
            "        [-0.3913, -0.4202, -0.7006,  ..., -1.4971,  3.1021, -3.5374],\n",
            "        [-4.9520,  2.5589, -0.2125,  ..., -2.9473, -0.2695, -1.5597]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8906, -3.7757,  1.6048,  ..., -0.4935,  1.1241, -1.7811],\n",
            "        [-2.9385, -0.1148,  2.6656,  ..., -2.2367,  2.3917, -3.5433],\n",
            "        [-4.4794, -2.7571, -0.5235,  ..., -2.9138, -1.7448, -2.6245],\n",
            "        ...,\n",
            "        [-0.1797,  1.7085,  2.2731,  ..., -3.7494,  1.0226, -2.7603],\n",
            "        [ 0.0833, -2.0396,  2.0748,  ...,  3.8142, -0.4520, -3.4304],\n",
            "        [-1.5704, -2.1346,  2.7980,  ..., -2.6087,  3.2034, -4.5240]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5244, -3.2478,  0.2536,  ...,  2.0967,  4.2756, -4.9588],\n",
            "        [-1.9320,  0.9368,  1.7396,  ...,  0.1938,  4.2565, -3.3556],\n",
            "        [-2.4134, -2.3321, -5.7234,  ..., -7.1755,  2.8297, -3.8812],\n",
            "        ...,\n",
            "        [-4.2407, -0.4342,  2.0158,  ..., -3.3264,  3.8997, -3.3053],\n",
            "        [-3.6704, -1.2380,  1.7870,  ..., -1.6345, -1.4001, -3.7428],\n",
            "        [-2.2571, -1.3036,  3.7426,  ..., -1.7186, -0.2609, -2.5349]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9959,  0.2489, -0.3114,  ..., -0.2138,  4.0267, -4.0687],\n",
            "        [-4.6647, -1.3232,  1.7440,  ..., -1.2562,  1.5589, -2.9041],\n",
            "        [-3.3797, -0.4541,  2.2000,  ..., -2.1471,  0.8911, -2.7063],\n",
            "        ...,\n",
            "        [ 0.3810, -5.8868,  1.6893,  ..., -0.4415, -0.2686, -5.3599],\n",
            "        [-0.0964, -0.3328, -4.3726,  ..., -1.1888,  3.1914, -0.9783],\n",
            "        [-1.5797, -3.8162, -0.0879,  ...,  1.0641,  0.1936, -5.2416]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0186, -0.7084,  1.1274,  ...,  0.2226,  2.1036, -2.7915],\n",
            "        [-1.8672, -1.2850, -3.4882,  ..., -0.5614,  0.1781, -4.3581],\n",
            "        [-0.4615, -0.2973, -2.7869,  ...,  0.9426,  4.1443, -4.0182],\n",
            "        ...,\n",
            "        [-4.6708, -0.5960,  1.7836,  ..., -2.1935, -0.9456, -3.2019],\n",
            "        [-4.4015,  2.1073,  0.1174,  ..., -2.8977,  1.9805, -2.3597],\n",
            "        [-4.1216, -5.1760, -0.6158,  ...,  2.2018,  0.6755, -3.4701]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8054, -7.4720,  1.3106,  ...,  5.0776,  0.7115, -5.5187],\n",
            "        [-1.9953, -3.8783,  5.7218,  ..., -0.1502,  1.4698, -2.8941],\n",
            "        [-4.7100,  0.1037,  1.6639,  ..., -2.3081,  1.2195, -3.5143],\n",
            "        ...,\n",
            "        [-3.7440,  1.7411,  1.3113,  ..., -1.7355,  5.1287, -4.2578],\n",
            "        [-2.8870,  1.0140,  2.6472,  ..., -0.9274,  3.8764, -3.6538],\n",
            "        [-2.4526, -2.6323,  1.5073,  ...,  1.4632, -0.0191, -4.0946]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6725,  1.3159,  0.6594,  ..., -1.1966, -2.6823, -1.8985],\n",
            "        [-2.8334, -4.9598,  0.8415,  ...,  1.2307,  1.3982, -1.6728],\n",
            "        [-0.8962, -0.8700, -1.5853,  ...,  4.0236,  2.4578, -4.8756],\n",
            "        ...,\n",
            "        [-0.5530,  0.5587,  0.2982,  ..., -1.4762,  2.4088, -2.5681],\n",
            "        [-0.0499, -1.6644,  0.2989,  ...,  1.3712,  1.0764, -4.1807],\n",
            "        [-1.8502, -2.6474,  1.1884,  ..., -0.6238,  0.2729, -2.2563]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4708, -1.7136, -2.3197,  ..., -0.5900,  1.1616, -1.6811],\n",
            "        [-4.1845,  3.6846,  1.6761,  ..., -2.9486,  1.9495, -1.0614],\n",
            "        [ 1.3265, -4.8950, -3.9371,  ...,  2.4076,  0.4739, -3.6675],\n",
            "        ...,\n",
            "        [ 3.2095, -6.2658, -5.0553,  ...,  3.9138, -1.5388, -3.5610],\n",
            "        [-1.5801, -3.0605,  2.6110,  ...,  0.0946,  0.2625, -3.4274],\n",
            "        [-0.4576,  1.8886, -2.9958,  ..., -2.0632,  2.9341, -2.1694]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7085,  5.3105, -4.5490,  ..., -0.9457,  4.7253, -2.1524],\n",
            "        [-0.5406,  3.7918, -3.2078,  ..., -2.0481,  6.9731, -5.1465],\n",
            "        [-5.1072, -1.1793,  1.2251,  ..., -4.2206,  5.4545, -1.2015],\n",
            "        ...,\n",
            "        [-1.9439, -4.8402,  5.2668,  ..., -1.7219,  2.2348, -3.5591],\n",
            "        [-1.8851,  4.6454, -1.7585,  ..., -1.4978,  4.1697, -2.8319],\n",
            "        [-0.5895, -1.2771,  6.4693,  ...,  0.6456,  2.0942, -2.7285]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8469,  1.0871,  2.8789,  ..., -0.7365, -1.4651, -2.8080],\n",
            "        [-3.3978, -4.0060,  0.9428,  ..., -2.7134,  0.7891, -4.6577],\n",
            "        [-3.0031, -2.5944,  2.5274,  ...,  0.0175,  1.3705, -2.8080],\n",
            "        ...,\n",
            "        [-1.9743,  0.1116, -2.9027,  ..., -2.4895,  2.4079, -2.4776],\n",
            "        [-2.0221, -1.4755, -1.7051,  ...,  0.8940,  0.8334, -3.3189],\n",
            "        [ 0.5990, -1.9614, -0.5011,  ...,  4.3554,  2.5647, -3.7236]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4616, -0.5000, -5.1284,  ..., -0.1001,  5.6831, -4.7201],\n",
            "        [-2.6127,  6.2287,  0.5176,  ..., -3.7037,  6.1775, -4.0661],\n",
            "        [-1.5997, -3.6321,  4.6298,  ..., -0.6836,  0.1933, -3.7256],\n",
            "        ...,\n",
            "        [-1.3684, -1.0621, -3.8661,  ...,  0.5925,  2.5258, -3.9359],\n",
            "        [-3.1605,  0.1414,  2.4620,  ..., -1.4251, -1.9206, -3.5633],\n",
            "        [-2.1949, -1.8323, -4.9451,  ..., -1.6313,  1.8382, -2.9138]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2919, -2.8038,  3.7275,  ...,  0.2469, -0.4804, -3.4595],\n",
            "        [ 1.8205, -5.1149, -3.3075,  ...,  3.0966, -2.0505, -1.2373],\n",
            "        [-5.1483,  1.3870,  0.6370,  ..., -5.7765,  3.1996, -5.1379],\n",
            "        ...,\n",
            "        [-2.8077, -1.1552,  3.5104,  ...,  0.4929, -0.2100, -2.0708],\n",
            "        [-2.1124, -1.0419,  2.8089,  ...,  0.7168, -0.2474, -2.1064],\n",
            "        [-1.9284, -1.6482,  4.1001,  ...,  1.3134,  3.4474, -3.4017]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8383, -3.1865, -6.0618,  ..., -0.4801,  2.8831, -5.1053],\n",
            "        [-1.2979, -0.2841,  0.2152,  ..., -1.5038,  3.7536, -2.5358],\n",
            "        [-2.0373, -3.3013,  3.6144,  ..., -0.9404,  0.0958, -4.0651],\n",
            "        ...,\n",
            "        [ 0.5409,  0.8125, -3.6812,  ..., -0.2549,  1.8791, -2.9073],\n",
            "        [-2.6642, -3.9605, -0.9329,  ..., -0.7605,  0.6305, -2.3336],\n",
            "        [-1.9172, -0.7796,  0.9760,  ..., -4.0486,  1.7994, -3.6539]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4513, -3.3092, -0.5723,  ...,  1.3093,  0.3536, -3.1644],\n",
            "        [-0.8511,  0.1712, -2.8897,  ...,  2.5342,  2.6175, -4.0166],\n",
            "        [-1.8199, -3.2878,  5.2707,  ...,  0.3240,  0.1445, -2.4389],\n",
            "        ...,\n",
            "        [-2.3808,  0.3433, -1.7687,  ..., -6.2029,  3.7515, -5.1740],\n",
            "        [-0.2005, -5.0550, -4.2916,  ..., -0.3106,  0.2201, -2.9169],\n",
            "        [-0.1137,  5.0368, -0.8027,  ..., -0.9079,  4.1249, -2.8379]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2035, -2.9664, -6.1248,  ...,  0.8573,  3.4234, -6.9509],\n",
            "        [-3.1055,  1.8832, -0.4315,  ..., -3.1063,  0.7334, -2.7946],\n",
            "        [-3.0447, -0.5618, -1.2751,  ..., -9.3076,  2.4899,  0.5148],\n",
            "        ...,\n",
            "        [-1.4494, -1.7373,  3.5903,  ...,  0.3593,  1.3667, -1.5642],\n",
            "        [ 0.7798,  1.1741, -2.5568,  ...,  3.6314,  2.2095, -2.3839],\n",
            "        [-1.0734, -1.1291,  3.3927,  ..., -0.6259,  5.3777, -4.7228]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2339, -2.5956,  3.3396,  ..., -2.5431,  1.1766, -0.3598],\n",
            "        [-2.4558, -0.7639,  3.0007,  ...,  0.4555, -0.5607, -2.1360],\n",
            "        [-3.5165, -2.8542,  1.3693,  ..., -2.4463,  1.6543, -1.2525],\n",
            "        ...,\n",
            "        [-4.9799, -0.5665, -0.0115,  ..., -2.0557,  4.7435, -4.1884],\n",
            "        [-1.6686, -0.8641,  3.4321,  ...,  0.5303,  1.5589, -3.5584],\n",
            "        [-1.1914, -3.4532,  0.5833,  ..., -0.1710,  0.9877, -3.1139]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6350, -1.2651,  0.4842,  ...,  0.4368,  2.6537, -2.3131],\n",
            "        [-3.6645, -4.0046, -1.3969,  ..., -0.5106,  1.3431, -5.4293],\n",
            "        [-0.3447, -0.1933, -0.8282,  ...,  1.4058,  3.2754, -3.1004],\n",
            "        ...,\n",
            "        [-2.4354, -3.6992,  3.4573,  ..., -3.1905,  0.2655, -4.8511],\n",
            "        [-0.2844, -2.0055, -0.8328,  ..., -4.0155, -0.5044, -4.5210],\n",
            "        [-3.2680,  2.5204,  1.7916,  ..., -4.3857,  3.3187, -1.9052]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7168,  0.5431,  1.8104,  ...,  0.5028, -0.7137, -2.4568],\n",
            "        [-3.5446, -0.4840,  5.1678,  ...,  0.1498,  2.0267, -2.8651],\n",
            "        [-2.0993, -4.1494, -0.1541,  ...,  0.9215,  1.3674, -4.6822],\n",
            "        ...,\n",
            "        [-2.5604, -6.7098,  4.2975,  ...,  1.0201,  1.2094, -5.5452],\n",
            "        [-2.8469,  1.8286,  0.1933,  ..., -0.0220, -2.5370, -2.2970],\n",
            "        [-2.4189, -3.6648,  1.0059,  ...,  0.8560,  0.8482, -3.3513]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7532, -2.2632, -0.2840,  ...,  0.1107,  6.2139, -6.1329],\n",
            "        [-1.6272, -0.6223,  1.9952,  ..., -2.2578,  1.0947, -1.2637],\n",
            "        [-1.6558,  0.0190, -4.3415,  ..., -2.6187,  0.5979, -4.1190],\n",
            "        ...,\n",
            "        [-1.7618, -0.1877,  3.3366,  ...,  1.5175,  5.4120, -1.5883],\n",
            "        [-3.2087, -0.1955,  2.3013,  ...,  0.8842, -1.6980, -3.1394],\n",
            "        [-5.2435,  2.2429,  2.8941,  ..., -2.4986,  2.8497, -4.0096]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.6336,  4.4649, -2.0300,  ...,  0.5047,  4.0984, -4.3078],\n",
            "        [-1.5994, -3.7866,  5.9177,  ..., -0.3700,  0.3155, -2.5390],\n",
            "        [-2.5124, -1.5721,  3.4269,  ..., -0.8197,  0.9310, -2.5017],\n",
            "        ...,\n",
            "        [-0.8358,  1.3676, -0.3092,  ..., -2.0183,  0.5593,  0.3175],\n",
            "        [-1.3331, -2.3103, -3.2218,  ...,  1.3800, -1.4682, -5.2003],\n",
            "        [-2.8018, -0.4085, -1.2575,  ..., -3.2456,  2.7191, -4.6657]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4760, -2.5024,  4.4186,  ..., -1.4367,  1.0601, -1.9796],\n",
            "        [-3.4475, -0.5868, -1.0339,  ..., -4.3090, -1.7509, -1.2201],\n",
            "        [-1.4565, -3.1437, -1.5509,  ...,  3.4046, -3.4884, -5.2412],\n",
            "        ...,\n",
            "        [-3.3891,  0.2392, -1.4271,  ..., -3.7931,  2.4705, -2.7111],\n",
            "        [-3.8859, -0.5954, -2.3670,  ..., -1.1475, -1.5974, -2.8507],\n",
            "        [-0.3960, -2.0533, -4.2974,  ..., -1.9655,  2.8893, -2.7078]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7044,  0.6628, -0.1655,  ...,  2.3095,  2.0554, -6.1525],\n",
            "        [-2.2478, -4.7996,  3.3136,  ...,  1.1617,  1.6618, -3.6697],\n",
            "        [-1.1013, -3.2981, -0.7856,  ...,  0.3988,  1.0248, -3.7882],\n",
            "        ...,\n",
            "        [-1.6544, -2.3799, -1.4364,  ..., -0.2738,  4.4603, -8.1963],\n",
            "        [-0.9310,  0.7650, -5.3903,  ..., -0.5158,  1.8589, -4.0128],\n",
            "        [-1.6784, -1.0114,  1.4972,  ..., -1.4392,  2.5564, -4.9016]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9983,  0.0991,  0.6889,  ...,  2.3572,  2.1106, -2.7748],\n",
            "        [-2.1020, -0.5756, -1.9166,  ...,  2.2409,  0.0449, -1.4346],\n",
            "        [-1.1420, -1.9414, -1.8664,  ..., -0.6564,  2.9095, -4.0780],\n",
            "        ...,\n",
            "        [-1.9868, -1.7497,  1.2697,  ..., -2.7036,  1.0759, -4.9027],\n",
            "        [-3.9135,  4.6304, -2.5526,  ..., -2.8201,  2.6779, -3.7255],\n",
            "        [-3.0432, -0.3921, -1.8967,  ..., -2.3735,  3.7377, -3.2933]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0619, -2.4485, -2.7728,  ...,  2.1081,  4.3567, -4.0336],\n",
            "        [-2.6379, -0.8330,  0.9374,  ...,  2.0258,  2.6341, -3.4296],\n",
            "        [-1.9921, -3.2461, -5.9203,  ..., -3.4121,  2.8071, -2.9640],\n",
            "        ...,\n",
            "        [-2.4698, -0.0911, -0.9452,  ..., -6.8294,  4.0252, -4.6867],\n",
            "        [-4.7176, -1.1069,  2.6324,  ..., -1.9473,  1.8977, -2.5986],\n",
            "        [-3.8812,  0.4930, -0.6121,  ..., -2.9535,  2.2681, -3.4317]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4703,  0.9842, -1.3944,  ..., -2.8861,  4.0604, -3.0863],\n",
            "        [-1.0148, -5.7156,  2.3606,  ...,  1.8251,  1.4865, -5.0306],\n",
            "        [-5.6435,  1.0816, -1.6038,  ..., -2.5717,  2.1777, -3.9454],\n",
            "        ...,\n",
            "        [-2.7347,  2.6607,  1.6480,  ...,  0.3543, -1.7860, -1.8689],\n",
            "        [-2.6307, -2.5646, -2.2656,  ...,  0.6503,  1.3475, -2.9555],\n",
            "        [-1.2734, -3.6159,  0.1229,  ...,  3.7782, -0.6326, -5.8094]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6114, -1.9733, -0.4645,  ..., -1.1737,  0.6349, -6.1448],\n",
            "        [-0.6979, -2.9151,  3.8193,  ...,  2.9873,  1.3293, -3.8340],\n",
            "        [-0.0962, -2.4777, -2.9638,  ..., -3.0798, -0.4532, -2.6031],\n",
            "        ...,\n",
            "        [-1.9520, -0.1549, -0.9617,  ..., -0.5824,  0.6663, -4.5223],\n",
            "        [ 0.9601, -4.9441,  3.2093,  ...,  3.2359, -0.2729, -4.8088],\n",
            "        [-3.7661,  5.4398,  0.7307,  ..., -0.5645,  3.8781, -3.9850]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4327, -2.6291, -3.2379,  ...,  0.7870, -0.3675, -2.9420],\n",
            "        [ 0.2666, -1.7388, -4.0340,  ...,  1.4044,  3.7501, -6.8331],\n",
            "        [-2.7227,  0.5964,  2.7917,  ...,  0.6996,  3.7134, -3.1758],\n",
            "        ...,\n",
            "        [-2.2041, -1.2559, -0.8575,  ...,  1.5455,  2.2922, -3.6976],\n",
            "        [-0.3192,  0.2430, -0.9295,  ...,  2.9525,  3.4766, -2.9018],\n",
            "        [-2.1543, -0.8975,  1.3484,  ...,  1.4157,  3.1615, -4.9378]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6696, -2.0501,  4.0996,  ...,  2.1830,  0.9659, -3.1535],\n",
            "        [-3.0738,  0.6258, -0.9473,  ..., -0.7559, -3.1274, -3.3861],\n",
            "        [ 0.7612, -3.9464,  5.5147,  ...,  5.7199,  2.5409, -5.3197],\n",
            "        ...,\n",
            "        [-2.0743, -2.5203,  4.2512,  ...,  0.9504, -0.9548, -2.9008],\n",
            "        [-2.5667,  1.2786,  3.2829,  ..., -0.3663, -1.0937, -2.1121],\n",
            "        [-1.7631,  2.4778, -0.0387,  ...,  0.7143,  1.6609, -1.9271]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3280, -0.3821, -2.0855,  ..., -1.8960,  2.4355, -0.9305],\n",
            "        [-1.8374,  0.1431, -2.1369,  ..., -1.4593,  2.5609, -1.6443],\n",
            "        [-1.1528, -4.6297,  4.7060,  ...,  2.3555,  0.4959, -3.8099],\n",
            "        ...,\n",
            "        [-1.1105, -0.1705, -1.5061,  ...,  2.1412,  4.1110, -2.4238],\n",
            "        [ 1.9990, -1.5150, -3.6536,  ...,  3.4382,  6.7882, -4.9367],\n",
            "        [-2.3955,  1.3302, -1.8967,  ...,  2.0065,  4.1163, -4.9028]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class SimpleMLPTrainingArgs:\n",
        "    \"\"\"\n",
        "    Defining this class implicitly creates an __init__ method, which sets arguments as below, e.g. self.batch_size=64.\n",
        "    Any of these fields can also be overridden when you create an instance, e.g. SimpleMLPTrainingArgs(batch_size=128).\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 3\n",
        "    learning_rate: float = 1e-3\n",
        "\n",
        "\n",
        "def train(args: SimpleMLPTrainingArgs) -> tuple[list[float], SimpleMLP]:\n",
        "    \"\"\"\n",
        "    Trains & returns the model, using training parameters from the `args` object. Returns the model, and loss list.\n",
        "    \"\"\"\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    mnist_trainset, _ = get_mnist()\n",
        "    mnist_trainloader = DataLoader(mnist_trainset, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "    loss_list = []\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        pbar = tqdm(mnist_trainloader)\n",
        "\n",
        "        for imgs, labels in pbar:\n",
        "            # Move data to device, perform forward pass\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            # Calculate loss, perform backward pass\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update logs & progress bar\n",
        "            loss_list.append(loss.item())\n",
        "            pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")\n",
        "\n",
        "    return loss_list, model\n",
        "\n",
        "\n",
        "args = SimpleMLPTrainingArgs()\n",
        "loss_list, model = train(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ENfdZdxajBUO",
        "outputId": "13c5c778-66c9-4028-ec37-7fdca2cecfa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"62b591d6-5b70-4343-8f84-d48ab3f39762\" class=\"plotly-graph-div\" style=\"height:525px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"62b591d6-5b70-4343-8f84-d48ab3f39762\")) {                    Plotly.newPlot(                        \"62b591d6-5b70-4343-8f84-d48ab3f39762\",                        [{\"hovertemplate\":\"Examples seen=%{x}\\u003cbr\\u003eCross entropy loss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,63.829787234042556,127.65957446808511,191.48936170212767,255.31914893617022,319.1489361702128,382.97872340425533,446.8085106382979,510.63829787234044,574.468085106383,638.2978723404256,702.1276595744681,765.9574468085107,829.7872340425532,893.6170212765958,957.4468085106383,1021.2765957446809,1085.1063829787236,1148.936170212766,1212.7659574468084,1276.595744680851,1340.4255319148938,1404.2553191489362,1468.0851063829787,1531.9148936170213,1595.744680851064,1659.5744680851064,1723.404255319149,1787.2340425531916,1851.0638297872342,1914.8936170212767,1978.723404255319,2042.5531914893618,2106.3829787234044,2170.212765957447,2234.0425531914893,2297.872340425532,2361.7021276595747,2425.531914893617,2489.3617021276596,2553.191489361702,2617.021276595745,2680.8510638297876,2744.68085106383,2808.5106382978724,2872.340425531915,2936.1702127659573,3000.0,3063.8297872340427,3127.6595744680853,3191.489361702128,3255.31914893617,3319.148936170213,3382.9787234042556,3446.808510638298,3510.6382978723404,3574.468085106383,3638.297872340426,3702.1276595744685,3765.9574468085107,3829.7872340425533,3893.617021276596,3957.446808510638,4021.276595744681,4085.1063829787236,4148.936170212766,4212.765957446809,4276.595744680852,4340.425531914894,4404.255319148936,4468.085106382979,4531.914893617021,4595.744680851064,4659.574468085107,4723.404255319149,4787.234042553192,4851.063829787234,4914.893617021276,4978.723404255319,5042.553191489362,5106.382978723404,5170.212765957447,5234.04255319149,5297.8723404255325,5361.702127659575,5425.531914893617,5489.36170212766,5553.191489361702,5617.021276595745,5680.851063829788,5744.68085106383,5808.510638297873,5872.340425531915,5936.170212765957,6000.0,6063.829787234043,6127.659574468085,6191.489361702128,6255.319148936171,6319.148936170213,6382.978723404256,6446.808510638298,6510.63829787234,6574.468085106383,6638.297872340426,6702.127659574468,6765.957446808511,6829.787234042554,6893.617021276596,6957.446808510638,7021.276595744681,7085.106382978724,7148.936170212766,7212.765957446809,7276.595744680852,7340.425531914894,7404.255319148937,7468.085106382979,7531.914893617021,7595.744680851064,7659.574468085107,7723.404255319149,7787.234042553192,7851.063829787235,7914.893617021276,7978.723404255319,8042.553191489362,8106.382978723404,8170.212765957447,8234.04255319149,8297.872340425532,8361.702127659575,8425.531914893618,8489.36170212766,8553.191489361703,8617.021276595746,8680.851063829788,8744.68085106383,8808.510638297872,8872.340425531915,8936.170212765957,9000.0,9063.829787234043,9127.659574468085,9191.489361702128,9255.31914893617,9319.148936170213,9382.978723404256,9446.808510638299,9510.638297872341,9574.468085106384,9638.297872340427,9702.127659574468,9765.95744680851,9829.787234042553,9893.617021276596,9957.446808510638,10021.27659574468,10085.106382978724,10148.936170212766,10212.765957446809,10276.595744680852,10340.425531914894,10404.255319148937,10468.08510638298,10531.914893617022,10595.744680851065,10659.574468085108,10723.40425531915,10787.234042553191,10851.063829787234,10914.893617021276,10978.72340425532,11042.553191489362,11106.382978723404,11170.212765957447,11234.04255319149,11297.872340425532,11361.702127659575,11425.531914893618,11489.36170212766,11553.191489361703,11617.021276595746,11680.851063829788,11744.68085106383,11808.510638297872,11872.340425531915,11936.170212765957,12000.0,12063.829787234043,12127.659574468085,12191.489361702128,12255.31914893617,12319.148936170213,12382.978723404256,12446.808510638299,12510.638297872341,12574.468085106384,12638.297872340427,12702.12765957447,12765.957446808512,12829.787234042553,12893.617021276596,12957.446808510638,13021.27659574468,13085.106382978724,13148.936170212766,13212.765957446809,13276.595744680852,13340.425531914894,13404.255319148937,13468.08510638298,13531.914893617022,13595.744680851065,13659.574468085108,13723.40425531915,13787.234042553191,13851.063829787234,13914.893617021276,13978.72340425532,14042.553191489362,14106.382978723404,14170.212765957447,14234.04255319149,14297.872340425532,14361.702127659575,14425.531914893618,14489.36170212766,14553.191489361703,14617.021276595746,14680.851063829788,14744.680851063831,14808.510638297874,14872.340425531915,14936.170212765957,15000.0,15063.829787234043,15127.659574468085,15191.489361702128,15255.31914893617,15319.148936170213,15382.978723404256,15446.808510638299,15510.638297872341,15574.468085106384,15638.297872340427,15702.12765957447,15765.957446808512,15829.787234042553,15893.617021276596,15957.446808510638,16021.27659574468,16085.106382978724,16148.936170212766,16212.765957446809,16276.595744680852,16340.425531914894,16404.255319148935,16468.08510638298,16531.91489361702,16595.744680851065,16659.574468085106,16723.40425531915,16787.23404255319,16851.063829787236,16914.893617021276,16978.72340425532,17042.55319148936,17106.382978723406,17170.212765957447,17234.04255319149,17297.872340425532,17361.702127659577,17425.531914893618,17489.36170212766,17553.191489361703,17617.021276595744,17680.85106382979,17744.68085106383,17808.510638297874,17872.340425531915,17936.17021276596,18000.0,18063.829787234044,18127.659574468085,18191.48936170213,18255.31914893617,18319.148936170215,18382.978723404256,18446.808510638297,18510.63829787234,18574.468085106382,18638.297872340427,18702.127659574468,18765.957446808512,18829.787234042553,18893.617021276597,18957.44680851064,19021.276595744683,19085.106382978724,19148.936170212768,19212.76595744681,19276.595744680853,19340.425531914894,19404.255319148935,19468.08510638298,19531.91489361702,19595.744680851065,19659.574468085106,19723.40425531915,19787.23404255319,19851.063829787236,19914.893617021276,19978.72340425532,20042.55319148936,20106.382978723406,20170.212765957447,20234.04255319149,20297.872340425532,20361.702127659577,20425.531914893618,20489.36170212766,20553.191489361703,20617.021276595744,20680.85106382979,20744.68085106383,20808.510638297874,20872.340425531915,20936.17021276596,21000.0,21063.829787234044,21127.659574468085,21191.48936170213,21255.31914893617,21319.148936170215,21382.978723404256,21446.8085106383,21510.63829787234,21574.468085106382,21638.297872340427,21702.127659574468,21765.957446808512,21829.787234042553,21893.617021276597,21957.44680851064,22021.276595744683,22085.106382978724,22148.936170212768,22212.76595744681,22276.595744680853,22340.425531914894,22404.25531914894,22468.08510638298,22531.91489361702,22595.744680851065,22659.574468085106,22723.40425531915,22787.23404255319,22851.063829787236,22914.893617021276,22978.72340425532,23042.55319148936,23106.382978723406,23170.212765957447,23234.04255319149,23297.872340425532,23361.702127659577,23425.531914893618,23489.36170212766,23553.191489361703,23617.021276595744,23680.85106382979,23744.68085106383,23808.510638297874,23872.340425531915,23936.17021276596,24000.0,24063.829787234044,24127.659574468085,24191.48936170213,24255.31914893617,24319.148936170215,24382.978723404256,24446.8085106383,24510.63829787234,24574.468085106382,24638.297872340427,24702.127659574468,24765.957446808512,24829.787234042553,24893.617021276597,24957.44680851064,25021.276595744683,25085.106382978724,25148.936170212768,25212.76595744681,25276.595744680853,25340.425531914894,25404.25531914894,25468.08510638298,25531.914893617024,25595.744680851065,25659.574468085106,25723.40425531915,25787.23404255319,25851.063829787236,25914.893617021276,25978.72340425532,26042.55319148936,26106.382978723406,26170.212765957447,26234.04255319149,26297.872340425532,26361.702127659577,26425.531914893618,26489.361702127662,26553.191489361703,26617.021276595744,26680.85106382979,26744.68085106383,26808.510638297874,26872.340425531915,26936.17021276596,27000.0,27063.829787234044,27127.659574468085,27191.48936170213,27255.31914893617,27319.148936170215,27382.978723404256,27446.8085106383,27510.63829787234,27574.468085106382,27638.297872340427,27702.127659574468,27765.957446808512,27829.787234042553,27893.617021276597,27957.44680851064,28021.276595744683,28085.106382978724,28148.936170212768,28212.76595744681,28276.595744680853,28340.425531914894,28404.25531914894,28468.08510638298,28531.914893617024,28595.744680851065,28659.574468085106,28723.40425531915,28787.23404255319,28851.063829787236,28914.893617021276,28978.72340425532,29042.55319148936,29106.382978723406,29170.212765957447,29234.04255319149,29297.872340425532,29361.702127659577,29425.531914893618,29489.361702127662,29553.191489361703,29617.021276595748,29680.85106382979,29744.68085106383,29808.510638297874,29872.340425531915,29936.17021276596,30000.0],\"xaxis\":\"x\",\"y\":[2.9424922466278076,2.0459983348846436,2.022003173828125,1.8192449808120728,1.7942999601364136,1.5723577737808228,1.576575756072998,1.4022310972213745,1.3312149047851562,1.2924692630767822,0.9800588488578796,0.9877893328666687,1.1935282945632935,0.9052134156227112,0.5562201142311096,0.7399792671203613,0.7855170369148254,1.0205339193344116,0.49924036860466003,0.9610416889190674,0.48603159189224243,0.5363451242446899,0.63824063539505,0.6551759839057922,0.47010278701782227,0.6949347257614136,0.4537440836429596,0.47876179218292236,0.6532052755355835,0.4771643579006195,0.47299373149871826,0.42586228251457214,0.535905659198761,0.5524765253067017,0.5362340211868286,0.4581897556781769,0.34343191981315613,0.45919063687324524,0.7385305762290955,0.3297238051891327,0.35371237993240356,0.3836040496826172,0.5266587734222412,0.8190119862556458,0.6381719708442688,0.42265334725379944,0.29530850052833557,0.4093383848667145,0.5683684349060059,0.15861931443214417,0.41278547048568726,0.5460613965988159,0.6815308332443237,0.4898287057876587,0.40192732214927673,0.23883330821990967,0.5402660965919495,0.2524411082267761,0.46127068996429443,0.36717045307159424,0.2695695757865906,0.5340055227279663,0.26669275760650635,0.35666581988334656,0.4966862201690674,0.2922273874282837,0.5946241021156311,0.2804601490497589,0.3640575706958771,0.42202287912368774,0.34011805057525635,0.2840535044670105,0.45824840664863586,0.4962024688720703,0.32646191120147705,0.26349273324012756,0.26450881361961365,0.3164439797401428,0.5752330422401428,0.30058062076568604,0.28055575489997864,0.37709537148475647,0.3126826286315918,0.30188921093940735,0.4117449223995209,0.4838087260723114,0.2800121307373047,0.44763681292533875,0.48092779517173767,0.32832440733909607,0.22358925640583038,0.32666468620300293,0.29831168055534363,0.31441017985343933,0.21773752570152283,0.20233143866062164,0.20236486196517944,0.33683109283447266,0.23192372918128967,0.2580721974372864,0.2401401698589325,0.3054778277873993,0.2727641463279724,0.3032550513744354,0.14904853701591492,0.26886534690856934,0.43916651606559753,0.4468015730381012,0.2437881976366043,0.3921770453453064,0.25506672263145447,0.2735804617404938,0.4815566837787628,0.3109170198440552,0.2566867768764496,0.4204675257205963,0.3704827129840851,0.27813929319381714,0.3007238209247589,0.3629628121852875,0.3438355624675751,0.3435945212841034,0.3002864420413971,0.1794165074825287,0.24510593712329865,0.3262083828449249,0.37735745310783386,0.3609726130962372,0.3353724777698517,0.2203144133090973,0.2951337993144989,0.26944389939308167,0.26227667927742004,0.36208561062812805,0.25798919796943665,0.4460865259170532,0.37293365597724915,0.2330484837293625,0.2472047656774521,0.35566815733909607,0.24420548975467682,0.2220253050327301,0.25669345259666443,0.3626595437526703,0.42417702078819275,0.2487727403640747,0.44194597005844116,0.1395362764596939,0.2067393660545349,0.2919946312904358,0.415534645318985,0.23975679278373718,0.3792189359664917,0.16521070897579193,0.2517892122268677,0.3212186098098755,0.18328408896923065,0.20102211833000183,0.24557125568389893,0.11128391325473785,0.243248850107193,0.13325545191764832,0.1870221346616745,0.2979074716567993,0.19077946245670319,0.21146875619888306,0.1647530198097229,0.12399580329656601,0.15880732238292694,0.22925926744937897,0.21716967225074768,0.3169955611228943,0.4705589711666107,0.22249552607536316,0.11028997600078583,0.18689532577991486,0.24053430557250977,0.3494339883327484,0.2304854691028595,0.19848306477069855,0.3562338650226593,0.2541826665401459,0.3456321060657501,0.2990507185459137,0.28859689831733704,0.27645447850227356,0.2822931706905365,0.33868518471717834,0.19379150867462158,0.14878082275390625,0.14478260278701782,0.12105526775121689,0.12296846508979797,0.14653296768665314,0.2609685957431793,0.27894917130470276,0.2141258418560028,0.2842452824115753,0.20994243025779724,0.1805969625711441,0.1800307184457779,0.1277657002210617,0.03555522486567497,0.3231489658355713,0.12468989938497543,0.2834153175354004,0.23480041325092316,0.13987989723682404,0.1061464250087738,0.18374814093112946,0.1348997801542282,0.17024104297161102,0.21502253413200378,0.2542215585708618,0.17266827821731567,0.3518218994140625,0.36812469363212585,0.08297736942768097,0.17319482564926147,0.3803231716156006,0.19279466569423676,0.1916222870349884,0.21984164416790009,0.18551436066627502,0.11600250750780106,0.12238818407058716,0.35646572709083557,0.1845715492963791,0.2804558575153351,0.23645859956741333,0.2922804355621338,0.3627932667732239,0.21094852685928345,0.11137425899505615,0.15676192939281464,0.19861741364002228,0.18882927298545837,0.20520447194576263,0.21850945055484772,0.09711620211601257,0.21111047267913818,0.1577613204717636,0.19249501824378967,0.13798099756240845,0.0760018602013588,0.2788086533546448,0.20662763714790344,0.17515522241592407,0.3505675196647644,0.2589365839958191,0.08440350741147995,0.20288361608982086,0.4275255799293518,0.17651057243347168,0.1487685889005661,0.15797145664691925,0.36275339126586914,0.18151810765266418,0.3423459231853485,0.20314806699752808,0.3828237056732178,0.40671172738075256,0.1473919302225113,0.1328892558813095,0.06866466253995895,0.14390282332897186,0.10509707033634186,0.3962172269821167,0.1773846596479416,0.16618677973747253,0.243714839220047,0.07529619336128235,0.22197739779949188,0.2748710811138153,0.09994010627269745,0.10784750431776047,0.14969635009765625,0.14845013618469238,0.32559657096862793,0.15708769857883453,0.19470804929733276,0.24655279517173767,0.12544050812721252,0.2807844579219818,0.17811468243598938,0.19926996529102325,0.1402226835489273,0.22623798251152039,0.20476236939430237,0.16186276078224182,0.10079661011695862,0.18172864615917206,0.18614619970321655,0.14506472647190094,0.074835404753685,0.142414391040802,0.13304628431797028,0.3360392153263092,0.13439862430095673,0.15396741032600403,0.1494659185409546,0.25931763648986816,0.2596692740917206,0.20661617815494537,0.2234499752521515,0.30018356442451477,0.20733009278774261,0.1644730269908905,0.13008686900138855,0.31817054748535156,0.12689512968063354,0.27773377299308777,0.0803075060248375,0.2738807499408722,0.1223965585231781,0.20989185571670532,0.0882403776049614,0.1823149472475052,0.16217908263206482,0.3466206192970276,0.1199500635266304,0.15338541567325592,0.12696035206317902,0.15982556343078613,0.11419957876205444,0.24836848676204681,0.12083080410957336,0.155303493142128,0.1093125119805336,0.11041801422834396,0.13567152619361877,0.0971459373831749,0.1768714189529419,0.22463113069534302,0.12539486587047577,0.19716140627861023,0.07227379828691483,0.09533622860908508,0.24711012840270996,0.16096231341362,0.19811557233333588,0.10622918605804443,0.12848980724811554,0.12299689650535583,0.07016948610544205,0.1653999239206314,0.18929022550582886,0.12595608830451965,0.18893158435821533,0.21893151104450226,0.13304266333580017,0.06469321250915527,0.23723933100700378,0.15815740823745728,0.06555385142564774,0.2078404575586319,0.1804455667734146,0.1347106695175171,0.1349128633737564,0.0735568106174469,0.07389077544212341,0.08626656234264374,0.2426031529903412,0.19377948343753815,0.10906842350959778,0.11524837464094162,0.2461223304271698,0.08403642475605011,0.09891987591981888,0.2036881446838379,0.20054973661899567,0.1349579095840454,0.33097267150878906,0.12791644036769867,0.2518339157104492,0.19922009110450745,0.1709194928407669,0.18105067312717438,0.13381162285804749,0.12804798781871796,0.21638014912605286,0.06233364716172218,0.15233388543128967,0.22793301939964294,0.08393897116184235,0.0922129824757576,0.13623414933681488,0.044526923447847366,0.18166235089302063,0.08121844381093979,0.17752766609191895,0.235303595662117,0.09785082191228867,0.0729256123304367,0.08197598159313202,0.21648962795734406,0.2142637073993683,0.1226743757724762,0.10955572128295898,0.13186690211296082,0.27455976605415344,0.16444982588291168,0.15059734880924225,0.09419668465852737,0.14807875454425812,0.31251001358032227,0.2141454815864563,0.0571114718914032,0.0728505402803421,0.12371137738227844,0.1443438082933426,0.28955748677253723,0.08315042406320572,0.11954256147146225,0.07967200875282288,0.07255790382623672,0.3253495395183563,0.0658368170261383,0.17112275958061218,0.10069300979375839,0.09280717372894287,0.17858853936195374,0.11385434865951538,0.14592808485031128,0.14355428516864777,0.14658325910568237,0.16566382348537445,0.09621027857065201,0.08578287065029144,0.05863279849290848,0.08859151601791382,0.24742570519447327,0.1253509521484375,0.16450399160385132,0.1677177995443344,0.06874120980501175,0.10027363151311874,0.2502034306526184,0.04562344774603844,0.10152748972177505,0.19999584555625916,0.06360872089862823,0.17874613404273987,0.09107013791799545,0.22372464835643768,0.10799144953489304,0.0556689128279686,0.10216835141181946,0.09981107711791992,0.07023840397596359,0.17199604213237762,0.16436736285686493,0.05265210568904877,0.16192926466464996,0.19363272190093994,0.07392363995313644,0.1616048514842987,0.17421163618564606,0.1848713755607605,0.15730012953281403,0.1337566077709198,0.033252786844968796,0.13989119231700897,0.19759762287139893,0.24361295998096466,0.11745525151491165,0.1315106302499771,0.19642367959022522,0.16004091501235962,0.13803735375404358,0.10405883938074112],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Examples seen\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Cross entropy loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"SimpleMLP training on MNIST\"},\"width\":700,\"hovermode\":\"x unified\"},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('62b591d6-5b70-4343-8f84-d48ab3f39762');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "line(\n",
        "    loss_list,\n",
        "    x_max=args.epochs * len(mnist_trainset),\n",
        "    labels={\"x\": \"Examples seen\", \"y\": \"Cross entropy loss\"},\n",
        "    title=\"SimpleMLP training on MNIST\",\n",
        "    width=700,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_sh7yNCjBUO"
      },
      "source": [
        "### Exercise - add a validation loop\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵🔵\n",
        ">\n",
        "> You should spend up to ~20 minutes on this exercise.\n",
        "> It is very important that you understand training loops and how they work, because we'll be doing a lot of model training in this way.\n",
        "> ```\n",
        "\n",
        "Edit the `train` function above to include a validation loop. Train your model, making sure you measure the accuracy at the end of each epoch.\n",
        "\n",
        "Here are a few tips to help you:\n",
        "\n",
        "* You'll need a dataloader for the testset, just like we did for the trainset. It doesn't matter whether you shuffle the testset or not, because we're not updating our model parameters during validation (we usually set `shuffle=False` for testsets).\n",
        "    * You can set the same batch size as for your training set (we'll discuss more optimal choices for this later in the course).\n",
        "* During the validation step, you should be measuring **accuracy**, which is defined as **the fraction of correctly classified images**.\n",
        "    * Note that (unlike loss) accuracy should only be logged after you've gone through the whole validation set. This is because your model doesn't update between computing different accuracies, so it doesn't make sense to log all of them separately.\n",
        "    * Computing accuracy is meant to be a very short operation, so you shouldn't need a progress bar.\n",
        "    * You can wrap your forward pass in `with t.inference_mode():` to make sure that your model is in inference mode during validation (i.e. gradients don't propagate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3TpwzEitjBUO",
        "outputId": "b8f04419-ec1a-409a-8ddc-4f1d85c690e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f58fe3314854471db7278d95a76e721a",
            "51d6e74fbdbe472f8649d06f04c5e784",
            "9c8b382c1517407eb521cf5b1b159e56",
            "b9c49f2e93ce45198f95c4218f15d283",
            "c4c0c6fe49e6406eaa3eead1dae65b83",
            "c8738c061e2a4193867113e812c4947f",
            "97ba1fec96814367affa199bba528174",
            "17dd6fffddcb42b190363655d27dd507",
            "aa39c26a08bb4d0ab6d2733c1de7f1d3",
            "5b726cbd76e149478cbf9862e7e7460e",
            "b691a363e9ee44aca69a6d441ed22226",
            "50a2da2f02ef42ae9d8c40dc9e381685",
            "12027d4027a04a3389b5c5c0be2b998c",
            "f7e5d1a5dce645a1820c5abd61dd392a",
            "bfdb353281e34fefae43eb03d7315c1f",
            "0665b7343ed34e42bdf31e11d5d3d615",
            "203cbe3f70cf4e8db4430ff1661122ea",
            "35a045ecfa494907a24a708d4d93306f",
            "8469e99a99dd4f37beb8cdf3c4f0e8a8",
            "6edc847aab7d497b94d16f114dbf269b",
            "78245a0f5a624778944a36f010979056",
            "637f3ab4b3d1480591543fde6c3a5b93",
            "826e171b8de24ae28ae08f07284cff68",
            "8b38d4a570e34ea88f6b96377cae3499",
            "6352d3fc81754747ba0dc557bf5bc3a9",
            "401051a3f83e43c6b96cb11e370c7a12",
            "b7c10368a74a40e0937ff10df97798cf",
            "5b2cbf8a16fc41f7b5a87609fe2149d6",
            "75dfd3d784fd4a028b21d3ea30dacbf3",
            "d06be3dc4c764701beddc338074c6e63",
            "e8f54e31a750473491485ae8918b20df",
            "a070e145f9eb4f79b1e1949ca2baff06",
            "17a8bf7aa2b24666941d8377e8fa92e8"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f58fe3314854471db7278d95a76e721a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0197, -1.1912, -2.5309,  ..., -0.9673, -1.7551, -0.7401],\n",
            "        [ 0.4593, -1.4049, -0.5626,  ..., -1.2474, -1.4822, -2.1616],\n",
            "        [-1.4620, -0.4521, -0.4349,  ..., -0.3434,  0.1285, -0.6179],\n",
            "        ...,\n",
            "        [ 0.4590, -2.1432, -1.3808,  ..., -2.2509, -2.5331, -3.7608],\n",
            "        [-0.2435, -2.2305, -0.9856,  ..., -1.6414, -3.0950, -2.9615],\n",
            "        [-0.1719,  0.8345,  1.1984,  ..., -0.0452, -1.2833, -1.9918]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0706e+00,  3.2458e-01, -1.1740e+00,  ..., -2.1017e+00,\n",
            "          6.4523e-01, -2.2529e+00],\n",
            "        [-2.8139e-01, -1.0034e+00, -1.2137e+00,  ..., -1.7475e+00,\n",
            "         -1.8226e+00,  3.8942e-01],\n",
            "        [ 8.7268e-01, -3.1419e+00, -9.2538e-01,  ..., -6.1826e-01,\n",
            "         -1.5474e+00, -4.8972e-01],\n",
            "        ...,\n",
            "        [ 3.4808e+00, -2.8586e-04, -1.2643e+00,  ...,  1.5709e+00,\n",
            "          1.0858e+00,  1.1966e-01],\n",
            "        [ 5.2974e-01, -2.7767e+00, -1.4791e+00,  ..., -6.1496e-01,\n",
            "         -1.7619e+00, -2.9444e+00],\n",
            "        [ 1.4401e+00, -1.7889e-01, -2.2425e+00,  ...,  2.1482e-01,\n",
            "         -1.5846e+00, -7.0058e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0862, -3.2064, -1.8760,  ..., -1.1219, -1.8943, -0.2637],\n",
            "        [-0.7320, -1.8525, -0.2705,  ..., -0.3360, -4.0005, -3.0086],\n",
            "        [ 0.9625, -2.4631, -0.2842,  ..., -1.0913, -1.7994, -2.8132],\n",
            "        ...,\n",
            "        [-1.4712, -2.6308, -3.1109,  ..., -0.6179, -0.7771,  1.2713],\n",
            "        [ 0.8835, -3.2859, -1.7628,  ...,  1.6939, -0.5247, -0.3086],\n",
            "        [-1.5126,  0.1481, -0.7729,  ...,  0.2263,  0.2026,  0.5714]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0204, -2.9121, -1.3392,  ..., -0.4780, -3.7616, -3.0797],\n",
            "        [ 0.9424, -3.1642, -1.9066,  ..., -1.0067, -3.7367, -4.0830],\n",
            "        [-1.1413, -0.2581, -0.0545,  ..., -1.7393,  0.4732, -1.3934],\n",
            "        ...,\n",
            "        [-2.8647,  1.0852, -0.1594,  ...,  1.2687, -1.1545, -1.7734],\n",
            "        [ 0.3760, -0.5133,  0.5822,  ..., -1.3589, -1.3718, -0.8202],\n",
            "        [ 0.2210, -0.9053, -0.0256,  ..., -2.7730, -0.1097, -0.9937]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6229, -0.2124, -0.3621,  ..., -0.9871, -1.7188, -2.4822],\n",
            "        [ 0.5054, -0.0092,  0.4773,  ..., -1.3802, -1.3495, -2.2922],\n",
            "        [ 0.3315,  0.6027, -2.4528,  ..., -1.6869, -0.7566, -1.8251],\n",
            "        ...,\n",
            "        [ 1.6982, -3.6691, -2.4005,  ..., -1.6500, -3.6211, -4.0849],\n",
            "        [ 0.0904, -2.6918, -2.2466,  ..., -2.1706, -4.7411, -2.0031],\n",
            "        [-1.0891, -0.9390, -2.8474,  ..., -1.0464, -1.0967, -0.2714]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3735, -1.2970, -1.8699,  ..., -1.9501,  0.8262, -2.7286],\n",
            "        [ 1.3304,  0.4032, -2.0455,  ..., -2.7364,  0.8933, -2.4595],\n",
            "        [ 1.3196, -0.8429, -0.0471,  ..., -1.6359, -1.8430, -1.7641],\n",
            "        ...,\n",
            "        [ 0.1053, -0.2994,  0.2492,  ..., -2.5053, -0.1854, -0.7985],\n",
            "        [ 0.7706,  0.1115, -0.5123,  ..., -2.5758, -0.8421,  0.8073],\n",
            "        [ 1.3760, -0.8481,  0.7536,  ..., -2.2291,  0.9082,  0.7997]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0429, -0.9344, -0.2383,  ...,  0.3994, -1.5386, -0.1693],\n",
            "        [ 1.5211, -0.7983, -0.3656,  ..., -2.1647, -1.7477, -2.8371],\n",
            "        [ 1.3361, -1.9040, -4.2851,  ...,  0.4065, -0.8650, -0.5914],\n",
            "        ...,\n",
            "        [ 1.6455,  0.3622, -2.8198,  ...,  1.0321, -1.1047, -0.3759],\n",
            "        [ 1.7042, -2.0706, -2.3691,  ..., -1.8902, -1.7172, -0.5082],\n",
            "        [ 2.6951, -1.0895, -3.6451,  ...,  0.5318, -0.5606, -3.3973]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5053,  0.2130, -1.3238,  ..., -0.6214, -1.1556, -0.4208],\n",
            "        [ 0.3301, -0.7979,  0.3647,  ..., -2.7170, -2.3295, -1.0385],\n",
            "        [ 0.5306, -1.5320, -0.7192,  ..., -1.7778, -2.4332, -2.4130],\n",
            "        ...,\n",
            "        [ 1.7955,  0.2123, -0.7912,  ..., -0.6754, -0.5067, -1.7206],\n",
            "        [ 0.7277, -3.7184, -2.2490,  ..., -1.1384, -1.4789, -0.3415],\n",
            "        [-1.0924, -3.5427, -3.8188,  ..., -2.5400, -1.8127, -3.5115]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0964,  0.6201, -2.9869,  ..., -0.9520, -0.8028, -1.6937],\n",
            "        [-1.2370, -0.3332, -1.7242,  ..., -1.9219, -1.2093, -1.4612],\n",
            "        [-2.5771,  1.9961, -2.9822,  ..., -1.5651,  0.5912, -0.4046],\n",
            "        ...,\n",
            "        [-0.0472, -1.7679, -0.6255,  ..., -1.8069, -1.3176, -1.9079],\n",
            "        [-0.2028, -2.9769, -2.3822,  ..., -1.8783, -3.1526, -4.3582],\n",
            "        [ 3.7130, -1.4993, -0.6583,  ...,  1.1093, -1.2697, -1.6797]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9544, -3.2213, -1.9062,  ...,  0.3515, -1.9435, -2.9920],\n",
            "        [ 0.7483, -0.1011, -0.6654,  ..., -1.3379, -1.3531, -1.4453],\n",
            "        [ 0.3036,  0.0871, -0.6774,  ...,  0.2059, -2.4170, -0.6391],\n",
            "        ...,\n",
            "        [-1.4143, -2.1774,  0.3884,  ..., -2.4458, -2.9929, -2.3129],\n",
            "        [ 0.0583, -2.1421, -1.5892,  ..., -2.0801, -1.8613, -1.3104],\n",
            "        [ 0.4856, -2.2121, -1.4498,  ..., -2.1059,  0.3367, -2.2149]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6305, -0.8743, -1.1721,  ..., -3.2699,  1.1945, -1.8844],\n",
            "        [-0.4440, -1.4345, -1.4689,  ...,  1.3732, -1.3176, -0.7763],\n",
            "        [ 1.1138, -1.2212,  0.1466,  ..., -1.6006, -1.7594, -1.4636],\n",
            "        ...,\n",
            "        [-1.4379, -1.3913, -2.4391,  ..., -1.0523, -1.1792, -2.6439],\n",
            "        [-0.3441, -1.7123, -3.3484,  ..., -1.1201, -0.8450, -3.0877],\n",
            "        [-0.4721, -1.2836, -0.7544,  ..., -1.4002, -1.1515, -2.1586]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5898, -1.7500, -1.2750,  ..., -1.5523, -1.0552, -0.3359],\n",
            "        [ 1.1089,  0.0933,  0.0540,  ..., -1.4122, -0.5774, -2.4766],\n",
            "        [-0.6684, -0.2850, -1.7551,  ...,  0.0269, -0.5198, -3.3444],\n",
            "        ...,\n",
            "        [-0.5620, -0.7997, -2.5377,  ..., -3.0534, -1.4862, -2.2877],\n",
            "        [-0.3843, -1.5659, -2.1083,  ..., -1.0117, -0.2450, -4.0669],\n",
            "        [ 0.9064, -2.8977, -3.9914,  ..., -1.0631, -0.9571, -3.4725]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8138, -0.4704, -0.4548,  ..., -0.6595, -2.1681, -3.0799],\n",
            "        [-0.2775, -1.8932, -3.8292,  ..., -1.3346, -0.9003, -3.5259],\n",
            "        [ 1.7554,  0.3257,  0.1724,  ..., -1.6637, -0.5650, -1.9917],\n",
            "        ...,\n",
            "        [-0.9620,  0.0133,  0.4278,  ..., -0.9601, -1.5474, -2.8980],\n",
            "        [ 1.8771, -4.4305, -3.8398,  ...,  0.0485, -1.9027, -4.5902],\n",
            "        [ 2.5068, -0.2996, -2.2774,  ...,  2.5563,  0.6755, -1.4289]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7812e-02,  1.2041e-01, -1.1038e+00,  ..., -6.2266e-01,\n",
            "         -3.8581e-01, -1.3851e+00],\n",
            "        [ 1.4360e-01, -7.5720e-01, -5.3246e+00,  ..., -5.8429e-01,\n",
            "          9.0500e-01, -1.9162e+00],\n",
            "        [ 3.1152e-01,  1.1411e+00, -6.4524e-01,  ..., -6.2571e-04,\n",
            "          9.7240e-02, -9.0276e-01],\n",
            "        ...,\n",
            "        [ 3.0053e+00, -2.2964e-01, -2.0850e+00,  ...,  5.4572e-01,\n",
            "         -9.5499e-01, -1.9456e+00],\n",
            "        [-7.6626e-01, -1.8327e+00, -1.8752e+00,  ..., -2.8129e+00,\n",
            "         -2.0607e+00, -3.4635e+00],\n",
            "        [ 1.6491e+00, -3.0130e+00, -4.7954e+00,  ...,  8.8304e-01,\n",
            "         -2.4220e+00, -2.6502e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7856, -3.0040, -2.8432,  ..., -0.3669,  0.3055, -3.2561],\n",
            "        [-0.9086, -1.0420, -1.0382,  ..., -1.3570,  0.0853, -1.3462],\n",
            "        [-0.5536, -1.8712, -1.4910,  ..., -0.5798, -1.2536, -1.8939],\n",
            "        ...,\n",
            "        [ 0.7567, -3.7122, -3.2402,  ...,  1.2178,  0.2606, -0.9176],\n",
            "        [ 0.8445, -0.8553, -2.4333,  ...,  1.5325, -0.2007, -1.2037],\n",
            "        [ 1.7405, -2.2582, -1.8961,  ..., -0.8207, -2.0326, -2.4371]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5209, -0.4637, -2.5247,  ..., -0.2099,  0.5384, -1.4217],\n",
            "        [ 2.6639, -2.5045, -2.0824,  ..., -0.7064, -1.5704, -2.2708],\n",
            "        [-0.4737, -0.2622, -1.4904,  ...,  0.2994, -1.4377, -0.9130],\n",
            "        ...,\n",
            "        [ 1.8162, -2.3101, -1.3806,  ..., -1.1278, -1.1313, -1.5361],\n",
            "        [-1.8075, -0.7443, -1.9523,  ..., -0.5594,  1.7450, -0.9485],\n",
            "        [ 0.3373, -3.2149, -1.2472,  ...,  0.8063,  1.0408, -3.1659]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1751,  0.2363, -3.0227,  ..., -1.2730,  1.0927, -1.1148],\n",
            "        [ 0.0600, -1.5143, -2.6296,  ..., -0.6479, -0.9599, -1.0710],\n",
            "        [-0.9047,  2.1786, -1.6591,  ..., -0.2284, -0.3017, -1.2176],\n",
            "        ...,\n",
            "        [ 0.4528,  1.2153, -0.1393,  ..., -0.7062,  0.0405, -1.1430],\n",
            "        [ 0.1350, -2.7251, -0.1115,  ..., -0.9856, -1.4027, -3.1707],\n",
            "        [ 0.9482, -1.3880, -3.2529,  ..., -0.6535, -0.4433, -3.0082]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3318,  0.0806,  0.2068,  ..., -0.6557,  0.5755, -1.5298],\n",
            "        [ 1.9601, -0.7062, -1.9137,  ..., -1.0011, -0.9409, -2.0019],\n",
            "        [ 0.4919, -0.7465, -2.0731,  ..., -0.7563, -0.2845, -2.7004],\n",
            "        ...,\n",
            "        [ 0.1502, -1.1822, -0.8377,  ..., -0.3779, -2.6200,  0.0929],\n",
            "        [-1.0128, -0.1565, -1.4684,  ...,  0.2608,  0.1809, -2.0884],\n",
            "        [ 0.6745, -0.8574, -3.8749,  ...,  3.2087,  1.8445,  0.3262]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9712, -3.0710, -3.1756,  ...,  0.5153, -1.6778, -2.4704],\n",
            "        [ 1.6184, -0.6331, -1.0943,  ..., -2.5389, -1.4350, -3.2077],\n",
            "        [ 1.6292, -0.7492, -0.5084,  ..., -0.5290, -1.4165, -1.5583],\n",
            "        ...,\n",
            "        [ 0.4462,  0.2165, -0.5115,  ..., -0.6683, -0.0492, -0.7737],\n",
            "        [ 0.0150, -1.8223, -1.1030,  ...,  0.1679, -0.8718, -1.5983],\n",
            "        [ 0.2053, -1.8477, -0.8379,  ..., -0.9664,  1.5898, -3.3750]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0746, -1.2124, -3.2946,  ..., -1.0499, -0.1702, -2.8151],\n",
            "        [ 1.5687, -1.7837, -1.8576,  ...,  1.1471, -0.7375, -2.7998],\n",
            "        [-0.0945, -1.1458, -1.7803,  ..., -0.6221, -0.1923, -2.5591],\n",
            "        ...,\n",
            "        [-0.6763, -2.4372, -3.0823,  ..., -1.5514, -2.4144, -3.1461],\n",
            "        [-0.5334,  0.2499, -2.4431,  ...,  0.7112, -0.5694, -2.1601],\n",
            "        [-0.3032, -2.2434, -2.2520,  ..., -0.6918,  1.0043, -1.7619]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6571,  1.2728, -1.2688,  ..., -0.1336,  1.2887, -1.7338],\n",
            "        [-0.0162, -1.5666, -2.1489,  ..., -1.6299, -1.3050, -1.9477],\n",
            "        [-1.2664,  0.5692, -2.9647,  ..., -1.4370,  1.4053, -2.3130],\n",
            "        ...,\n",
            "        [-0.9772, -1.5541, -2.6684,  ..., -0.9632,  0.0813, -4.5558],\n",
            "        [ 0.3508, -0.3536, -1.0844,  ..., -2.0030, -0.6982, -3.2208],\n",
            "        [-0.6186, -0.9630, -4.5740,  ..., -1.9002,  0.2544, -3.8373]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0223, -0.1695, -3.4292,  ..., -1.2671,  4.3564, -3.2028],\n",
            "        [-0.8742, -1.9638, -1.3830,  ..., -1.2429, -1.3578, -1.4702],\n",
            "        [ 0.2726,  0.8757, -0.8441,  ..., -0.9598,  0.7861, -1.7780],\n",
            "        ...,\n",
            "        [ 1.8723, -0.5259, -3.4545,  ..., -3.4932,  4.3795, -3.4197],\n",
            "        [-0.5784,  0.6161, -2.3915,  ..., -1.3514,  2.0464, -3.8964],\n",
            "        [ 0.5814, -0.2762, -1.2065,  ..., -1.2457, -0.4691, -2.9695]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1857,  0.6451, -1.4510,  ..., -0.7839,  0.5653, -0.9776],\n",
            "        [-0.5715, -0.5786, -2.5492,  ..., -2.0245,  0.9600, -1.0566],\n",
            "        [ 0.3773, -1.4128, -0.7759,  ..., -0.2012,  0.2913, -2.3321],\n",
            "        ...,\n",
            "        [ 0.1354, -3.1491, -4.3611,  ...,  1.0002,  0.0527, -2.9382],\n",
            "        [-0.8198, -2.0568, -2.6878,  ...,  0.1493,  0.1027, -2.6797],\n",
            "        [ 0.5508,  0.7899, -1.4181,  ..., -2.0056, -0.1435, -2.8562]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4960, -0.0626, -0.5064,  ..., -0.5164,  0.1459, -1.3532],\n",
            "        [-0.8976, -2.0023, -1.8419,  ...,  0.5829, -1.6792, -3.9520],\n",
            "        [ 0.1963, -0.3517, -3.6068,  ..., -0.9026,  0.6245, -4.7967],\n",
            "        ...,\n",
            "        [-0.0319, -1.3698, -2.1355,  ..., -2.1919,  1.9416, -3.4781],\n",
            "        [-0.3189, -1.0115, -2.9467,  ...,  0.9375, -2.1363, -2.8953],\n",
            "        [ 0.6624,  0.8058, -0.5028,  ..., -1.6073,  1.1012, -2.2105]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6629, -2.1286,  0.9634,  ..., -1.0428, -0.0692, -2.0107],\n",
            "        [ 2.0715, -2.2365, -0.5526,  ...,  1.3195, -0.2574, -0.2630],\n",
            "        [-0.0275,  1.0493, -0.0173,  ...,  0.1831,  1.4379, -1.8311],\n",
            "        ...,\n",
            "        [ 2.4725, -1.6083, -1.5602,  ...,  2.5139, -1.1303, -1.8749],\n",
            "        [-0.6208, -2.0873, -1.4786,  ..., -0.1123,  0.4227, -2.3826],\n",
            "        [-1.6861, -0.7219, -0.6461,  ..., -0.6708,  1.4462, -2.3466]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6089,  0.2438, -2.4487,  ...,  0.2068, -0.2225, -1.2356],\n",
            "        [-0.8159,  0.7999, -0.5564,  ..., -1.0947,  0.8462, -0.4184],\n",
            "        [-2.7959,  0.6459, -3.6211,  ..., -1.2401,  3.3651, -0.7473],\n",
            "        ...,\n",
            "        [-1.5229, -1.4205, -3.2940,  ..., -0.5365,  1.8154, -3.1857],\n",
            "        [-0.4541,  0.4063, -1.8111,  ..., -1.7760, -0.2390, -1.5240],\n",
            "        [ 1.3469, -1.9814, -2.2587,  ..., -0.1421,  0.7898, -2.5875]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5920, -2.3507, -2.4080,  ...,  1.0133,  0.5527, -3.5092],\n",
            "        [-1.5500,  0.6516, -1.3660,  ..., -0.3962,  1.0561, -1.0713],\n",
            "        [ 0.7597, -0.9577, -1.6424,  ..., -0.6243, -0.0463, -1.4424],\n",
            "        ...,\n",
            "        [-0.8571, -1.0975, -1.1561,  ...,  0.7207,  2.8585, -1.7314],\n",
            "        [-2.5485,  0.6363, -3.0737,  ..., -1.0588,  1.6856, -2.4612],\n",
            "        [ 2.5184, -2.7372, -2.7799,  ...,  1.9746,  0.4510, -1.0188]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0440,  0.5228, -0.0060,  ...,  0.0248,  1.4184, -1.6772],\n",
            "        [ 0.3932, -0.7687, -2.8767,  ...,  1.2104,  2.3286, -2.9058],\n",
            "        [-1.8046,  1.0317, -2.5441,  ..., -0.6511,  3.2707, -2.3454],\n",
            "        ...,\n",
            "        [-2.6377,  1.3146, -2.1006,  ..., -3.4005,  3.7102, -2.8331],\n",
            "        [ 0.8522, -2.5420, -4.0967,  ...,  1.6844, -0.8311, -2.2198],\n",
            "        [-1.6017,  1.5296, -3.7350,  ..., -2.7999,  3.8183, -2.3690]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2629, -1.2118, -2.9210,  ...,  3.1921,  3.0874, -2.4134],\n",
            "        [-0.0047,  1.4983, -1.3080,  ..., -1.0662,  1.7732, -2.4396],\n",
            "        [ 1.5142, -2.0973, -1.2298,  ...,  1.9207,  0.2896, -3.3600],\n",
            "        ...,\n",
            "        [-2.4324,  0.1998, -3.0337,  ...,  1.1435,  2.4320, -1.9395],\n",
            "        [ 0.5240, -0.0690, -2.3278,  ..., -0.1558,  3.4552, -3.3574],\n",
            "        [ 1.2006, -1.6779, -0.6883,  ...,  1.9172, -0.1008, -2.2821]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0110,  0.5327, -0.9989,  ...,  2.2561,  2.4697, -1.6825],\n",
            "        [ 0.8701,  1.2928, -0.2496,  ...,  0.1601,  1.7337, -2.0488],\n",
            "        [-2.2071,  0.9364, -1.9506,  ..., -1.9172,  3.2542, -2.9925],\n",
            "        ...,\n",
            "        [-0.5423, -1.2227, -3.5970,  ...,  0.6403,  1.3889, -2.8637],\n",
            "        [-1.8002,  0.9188, -3.2710,  ..., -0.5124,  3.0607, -2.8933],\n",
            "        [ 0.4414, -1.4655, -1.7226,  ...,  0.1661,  3.9862, -3.0525]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8227,  1.2812, -2.0366,  ..., -1.7332,  0.8943, -1.4323],\n",
            "        [ 4.4049, -3.7024, -2.8332,  ...,  1.0186,  0.9536, -3.6880],\n",
            "        [-2.3567, -0.8984, -2.6851,  ...,  1.0837,  0.0164, -1.3978],\n",
            "        ...,\n",
            "        [ 2.4223, -2.4875,  0.4501,  ...,  0.6340,  5.7832, -5.0625],\n",
            "        [ 1.2831, -2.1147, -1.1620,  ...,  1.8081,  0.3552, -2.0714],\n",
            "        [ 0.5121, -1.1236, -3.8783,  ..., -0.0877,  0.4540, -1.0393]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9771,  2.1085, -0.6046,  ...,  0.6733,  1.3104, -0.7537],\n",
            "        [ 0.3053,  1.1119, -0.1941,  ..., -1.1587,  0.9098, -2.6477],\n",
            "        [-1.6338,  1.7954, -1.7847,  ..., -0.6828,  3.2858, -2.2064],\n",
            "        ...,\n",
            "        [-1.2782,  0.1382, -0.5437,  ...,  0.1497,  2.8040, -0.5320],\n",
            "        [ 1.5329, -1.7228, -0.5114,  ...,  0.5004, -0.0491, -2.1530],\n",
            "        [-0.8470, -0.1878,  0.3610,  ..., -1.0133,  1.7396, -1.8335]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2192,  1.0077,  0.0529,  ..., -0.8936,  2.2085, -1.7166],\n",
            "        [-3.5776, -0.6078, -2.8556,  ..., -2.2353,  5.1606, -1.6528],\n",
            "        [-1.0891, -3.9489, -3.7657,  ...,  2.0468,  0.8788, -3.7373],\n",
            "        ...,\n",
            "        [ 0.4096, -1.0514, -0.8489,  ...,  0.6949,  1.3656, -2.5078],\n",
            "        [-1.7379,  0.6784, -1.7855,  ...,  1.0671,  0.6216, -0.3165],\n",
            "        [-1.1922,  0.4655, -3.3022,  ..., -1.3736,  3.3022, -2.6232]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4061, -0.5452, -1.4256,  ..., -0.4524,  1.5897, -4.2677],\n",
            "        [ 0.9958, -2.3718, -0.3199,  ..., -0.4107,  0.5266, -1.9828],\n",
            "        [ 1.8690, -1.5368, -1.8598,  ...,  0.8527,  1.0538, -5.5628],\n",
            "        ...,\n",
            "        [ 1.0425,  0.4047, -1.8547,  ...,  0.1697,  1.8335, -2.4126],\n",
            "        [ 0.7594,  0.5341, -1.5676,  ..., -0.4826,  4.1065, -2.8105],\n",
            "        [-2.3258,  1.4174, -0.9443,  ...,  0.4832,  0.7183, -0.0786]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7144,  4.0270, -0.3998,  ...,  0.6834,  4.7344, -2.1665],\n",
            "        [ 1.5424, -0.9950, -2.5798,  ...,  2.1459,  1.0529, -3.2934],\n",
            "        [-0.8545, -0.2696, -1.8173,  ...,  2.2581,  0.6189, -2.4221],\n",
            "        ...,\n",
            "        [-0.8259,  2.4074, -0.6457,  ...,  0.6561,  1.5170, -1.4721],\n",
            "        [ 0.5118,  0.9688, -1.3004,  ..., -0.4092,  1.3922, -3.4266],\n",
            "        [ 2.4939, -1.1118, -0.0680,  ...,  1.9925,  0.9220, -2.8739]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3549e+00, -1.7847e+00, -2.8138e+00,  ...,  2.2630e-03,\n",
            "          1.9906e+00, -4.7887e+00],\n",
            "        [-1.0643e-01,  4.4011e-02, -1.9803e+00,  ...,  1.3444e+00,\n",
            "          3.1476e+00, -1.4368e+00],\n",
            "        [ 5.0185e-01, -1.5292e+00, -3.5308e+00,  ...,  1.0037e-01,\n",
            "          4.1391e-01, -2.6059e+00],\n",
            "        ...,\n",
            "        [ 1.5130e+00, -2.6769e+00, -2.3255e+00,  ...,  2.3136e+00,\n",
            "          2.0451e+00, -2.5514e+00],\n",
            "        [-9.7291e-02, -1.8892e+00, -2.7556e+00,  ...,  9.7362e-01,\n",
            "          2.5624e+00, -4.8087e+00],\n",
            "        [ 4.1378e-01,  2.4456e+00,  5.0475e-01,  ...,  5.7426e-01,\n",
            "          1.5003e+00, -1.5870e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8139, -2.4486, -3.3857,  ..., -0.1234,  2.5457, -3.5828],\n",
            "        [ 0.0336,  0.2480, -2.6185,  ..., -2.2620,  1.5160, -2.1223],\n",
            "        [-1.2791,  0.7436, -3.4070,  ..., -0.4079,  1.5471, -1.5290],\n",
            "        ...,\n",
            "        [ 0.8290,  1.2296,  1.0655,  ..., -1.1698,  2.2460, -2.9660],\n",
            "        [ 0.6573, -1.5479, -0.5049,  ...,  1.4120, -0.2589, -4.0165],\n",
            "        [ 2.1371,  1.1594, -0.0972,  ..., -2.0438,  2.0034, -2.6648]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 9.8783e-02, -3.6648e-01, -2.9872e+00,  ...,  6.4589e-02,\n",
            "          3.8852e+00, -3.9695e+00],\n",
            "        [-4.7672e-01,  1.2605e+00,  5.9224e-01,  ..., -1.7037e+00,\n",
            "          6.1721e+00, -1.7822e+00],\n",
            "        [-1.6579e+00,  1.3159e+00, -4.1320e+00,  ..., -8.0726e-01,\n",
            "          4.6122e+00, -4.4489e+00],\n",
            "        ...,\n",
            "        [ 6.5541e-04, -1.2920e+00, -4.2595e+00,  ...,  2.4504e-01,\n",
            "          1.7469e+00, -6.7327e-01],\n",
            "        [ 3.0450e-01, -1.1679e+00, -2.6657e+00,  ..., -9.8173e-01,\n",
            "          6.3573e-01, -4.0183e+00],\n",
            "        [ 1.6094e+00, -1.5901e+00, -1.9909e+00,  ...,  2.6010e-01,\n",
            "          1.1086e+00, -1.8016e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7974, -2.3395, -4.1557,  ..., -0.1504,  2.7611, -4.2169],\n",
            "        [-0.4603, -1.8767, -3.0445,  ...,  2.5588,  2.4257, -2.3092],\n",
            "        [-0.1598, -0.5534, -0.7034,  ...,  1.7222,  0.4865, -4.5269],\n",
            "        ...,\n",
            "        [ 0.5698, -3.9264, -1.6080,  ...,  0.4891,  1.5141, -2.1466],\n",
            "        [-0.5909,  0.4691, -1.2019,  ..., -1.0465,  1.1115, -1.8538],\n",
            "        [ 1.5883, -1.5872, -1.4694,  ...,  3.1539,  1.4244, -2.8135]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7236, -1.2934, -3.9823,  ...,  2.6777,  1.8508, -3.6714],\n",
            "        [-2.1786, -0.0438, -0.8025,  ...,  0.3877,  2.6412, -2.4474],\n",
            "        [ 1.3997, -2.3440, -3.4698,  ...,  0.7559,  4.1921, -3.5651],\n",
            "        ...,\n",
            "        [-1.0022, -0.6302, -1.9385,  ..., -0.5249,  6.2014, -3.3522],\n",
            "        [-0.3078,  0.2211, -1.1013,  ...,  1.0955,  2.9871, -1.2769],\n",
            "        [-0.5942,  0.0624, -1.3929,  ...,  0.1493,  1.7785, -1.4729]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0493, -0.9795, -1.6164,  ..., -0.5129,  2.7591, -2.6558],\n",
            "        [-0.0325,  0.1860, -2.4839,  ..., -0.9306,  4.7927, -2.6605],\n",
            "        [ 0.4019, -1.1465, -2.8819,  ...,  2.9628,  2.1686, -1.8549],\n",
            "        ...,\n",
            "        [-2.4246,  0.2795, -1.8854,  ..., -0.9496,  1.5659, -3.4584],\n",
            "        [ 2.1122, -1.7796, -1.0005,  ..., -1.1385,  2.5045, -2.6686],\n",
            "        [-1.5530,  2.2214, -1.0869,  ..., -0.1823,  1.3617, -2.2831]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2027,  1.0698, -2.3527,  ..., -0.6817,  1.9261, -2.8033],\n",
            "        [ 1.0899, -0.8856, -5.1872,  ...,  0.7498,  0.1808, -3.7414],\n",
            "        [ 1.3734,  1.7176,  0.4507,  ..., -0.0376,  2.1989, -2.5446],\n",
            "        ...,\n",
            "        [-2.2118,  1.7891, -1.3352,  ..., -0.6485,  5.3507, -2.7093],\n",
            "        [-0.1593,  1.9912,  0.5828,  ...,  0.7617,  1.7773, -1.3944],\n",
            "        [-1.1411,  2.5889, -2.9148,  ..., -0.4137,  1.3407, -2.4787]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5292, -1.7682, -0.1172,  ..., -0.6579,  0.2913, -3.7202],\n",
            "        [-0.6619,  0.0085,  0.3919,  ...,  3.8105,  2.0863, -1.8865],\n",
            "        [ 0.2626, -0.9986,  0.9161,  ...,  0.0150,  1.6663, -1.8416],\n",
            "        ...,\n",
            "        [-0.1560,  0.1132, -2.1218,  ..., -1.1265,  2.0056, -1.6827],\n",
            "        [-2.7094,  0.0396, -2.2192,  ...,  0.4679, -0.1204, -1.5365],\n",
            "        [ 1.3380, -1.9174, -1.6526,  ...,  0.2329,  1.8270, -2.8079]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6665, -0.6754, -1.3925,  ...,  0.2832, -1.3206, -2.5182],\n",
            "        [ 1.1897,  0.6655, -4.6810,  ...,  1.1507,  2.3310, -3.6847],\n",
            "        [-0.4724, -1.7774, -1.4430,  ..., -0.3748,  2.1612, -1.1691],\n",
            "        ...,\n",
            "        [-0.8601, -0.6122, -2.2721,  ...,  1.6942,  0.5743, -3.3594],\n",
            "        [-0.7536, -1.1788, -2.0350,  ...,  0.5248,  3.4482, -4.0061],\n",
            "        [ 1.0265,  0.3560, -1.4880,  ..., -1.9254,  0.7907, -1.6436]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1537, -0.3567, -2.4179,  ...,  1.5941,  1.0957, -2.1155],\n",
            "        [-3.2292,  1.1444, -2.6675,  ...,  1.4479,  4.0124, -3.0709],\n",
            "        [-0.3616,  1.5250, -1.6857,  ..., -1.5705,  0.1122, -1.5707],\n",
            "        ...,\n",
            "        [-1.0261, -0.5624, -0.6939,  ..., -0.0466,  3.9675, -3.5060],\n",
            "        [-4.1013, -0.5779, -0.2138,  ..., -0.5712,  0.6851, -3.2876],\n",
            "        [-3.3655,  2.7158, -1.1458,  ...,  0.4793,  2.3756,  0.8062]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6087,  1.3140, -2.6743,  ..., -0.7184,  2.6202, -1.4815],\n",
            "        [ 2.0780, -1.2571, -1.5540,  ...,  0.5709,  1.6496, -3.5656],\n",
            "        [ 1.5005, -0.2574, -2.0400,  ..., -1.1422,  0.7969, -3.5888],\n",
            "        ...,\n",
            "        [-2.1983,  0.5743, -0.4704,  ...,  0.8955,  1.2852, -3.4862],\n",
            "        [ 0.5665, -0.4376, -2.7329,  ..., -0.4949,  1.2298, -1.5830],\n",
            "        [-2.2203, -1.6948, -0.0531,  ...,  0.8242,  1.5402, -4.0861]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0364,  1.0030, -0.9897,  ..., -1.3289,  0.7894, -2.1624],\n",
            "        [-1.3558, -0.0451, -1.7017,  ..., -0.8108,  0.9309, -3.5230],\n",
            "        [-2.2346, -0.2427, -1.5162,  ..., -0.8190,  2.3876, -2.3730],\n",
            "        ...,\n",
            "        [ 3.9876, -3.4334, -1.7315,  ...,  0.7510, -0.4883, -2.8307],\n",
            "        [ 2.4454, -3.0664, -3.5868,  ...,  0.8879,  1.7369, -3.4311],\n",
            "        [ 0.9769, -1.8398, -2.2864,  ...,  1.6497,  2.2097, -3.7317]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4291, -1.3374, -4.2318,  ...,  1.3421,  1.6891, -2.2508],\n",
            "        [ 1.0713, -0.6033, -4.9200,  ...,  0.2453,  1.9374, -2.4008],\n",
            "        [ 2.3166, -3.8886, -2.6776,  ...,  0.1131,  2.1576, -6.5008],\n",
            "        ...,\n",
            "        [-1.3138, -0.2062, -2.4433,  ..., -1.0441,  3.2422, -3.1823],\n",
            "        [-0.2024, -0.5194, -1.7711,  ...,  0.4593,  0.4664, -2.9262],\n",
            "        [-0.5766, -0.2277, -0.5987,  ...,  0.7182,  0.5701, -1.9625]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.2737,  2.8453, -2.7980,  ..., -1.0855,  4.2119, -0.7708],\n",
            "        [-1.4138,  0.6703, -2.2825,  ...,  1.9124,  4.4703, -4.6916],\n",
            "        [-0.9574, -1.5960, -1.3030,  ...,  1.1252,  0.9926, -2.1490],\n",
            "        ...,\n",
            "        [ 0.4765,  1.3550,  1.1809,  ..., -0.9863,  1.3785, -2.8207],\n",
            "        [ 1.0265, -2.1340, -1.6953,  ...,  0.3606,  0.2573, -3.9306],\n",
            "        [ 0.0932,  0.2170, -3.2592,  ..., -2.4897,  3.5640, -4.2942]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1340, -2.0400, -4.5749,  ...,  3.8573,  1.4306, -2.6376],\n",
            "        [-0.8312, -2.6371, -2.5408,  ..., -0.1116,  0.6421, -3.9377],\n",
            "        [-0.9347,  0.6132, -3.8785,  ...,  2.2215,  0.9944, -2.0330],\n",
            "        ...,\n",
            "        [-1.1945,  0.3976, -0.8301,  ...,  1.3645,  0.3753, -2.9328],\n",
            "        [-0.5786, -1.5767, -1.9496,  ...,  0.1926,  1.2245, -2.7762],\n",
            "        [ 0.7623,  1.8847,  0.7307,  ..., -0.0565,  1.2192, -1.7547]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9266,  0.4874, -1.0701,  ...,  1.0776, -0.2176, -1.8423],\n",
            "        [ 0.6260, -1.7117, -2.6470,  ...,  1.0292,  1.0023, -1.1146],\n",
            "        [ 2.4204, -1.6488, -0.6177,  ..., -0.6747, -0.3168, -2.8729],\n",
            "        ...,\n",
            "        [ 4.2300, -4.1433, -2.9766,  ...,  0.6103,  2.5073, -5.7880],\n",
            "        [ 0.1394, -3.8787, -3.3213,  ...,  0.6876,  2.4933, -5.1508],\n",
            "        [-4.1451,  5.0100, -1.4596,  ..., -1.3575,  3.6975, -1.5457]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0834, -1.8508, -2.2313,  ..., -0.4260,  1.6590, -4.9875],\n",
            "        [ 0.7130, -3.5057, -2.9063,  ..., -0.9818,  2.4711, -4.3311],\n",
            "        [ 0.4019,  0.9806,  0.6386,  ..., -1.2203,  1.7505, -1.2783],\n",
            "        ...,\n",
            "        [-3.7140,  2.5639, -1.9202,  ..., -0.2567,  3.5829, -1.1655],\n",
            "        [ 0.8649, -2.3659, -1.8605,  ...,  1.4701,  1.6903, -1.6579],\n",
            "        [-0.4601,  0.4940, -0.0684,  ...,  1.1484, -0.7470, -3.0767]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0552e-02, -3.5994e-02, -7.2629e-01,  ..., -1.2958e+00,\n",
            "          7.8192e-01, -1.7274e+00],\n",
            "        [ 7.7296e-02, -2.5148e+00, -2.0340e+00,  ...,  2.7875e+00,\n",
            "         -3.1495e-01, -3.9621e+00],\n",
            "        [ 2.5896e+00, -3.1494e+00, -3.3251e+00,  ...,  1.5193e+00,\n",
            "          2.7473e+00, -6.7067e+00],\n",
            "        ...,\n",
            "        [-1.5911e+00,  1.4883e+00, -9.1378e-02,  ..., -6.9284e-01,\n",
            "          6.5786e-01, -2.3854e+00],\n",
            "        [-1.1540e+00,  2.0510e+00, -2.9962e-01,  ..., -3.9471e-01,\n",
            "          2.5269e+00,  9.8669e-05],\n",
            "        [ 3.3279e-01,  1.5307e+00,  1.7009e-02,  ...,  3.5291e-01,\n",
            "          1.7318e+00, -2.0262e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5612,  0.0932, -0.5249,  ..., -0.5460,  2.5834, -2.4820],\n",
            "        [ 2.5911, -1.9553, -1.9728,  ...,  1.2127,  0.6349, -2.8629],\n",
            "        [ 0.0566, -3.4883, -2.3831,  ...,  3.9503, -2.0868, -3.7428],\n",
            "        ...,\n",
            "        [-1.2470, -1.0045, -0.1139,  ...,  0.6853,  1.6520, -3.1685],\n",
            "        [-1.8327,  0.5366, -3.5896,  ..., -0.4610,  2.9230, -1.9320],\n",
            "        [-0.2417, -2.1093, -1.4758,  ...,  0.1750,  4.6241, -3.4582]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7659,  0.4115, -0.5508,  ..., -1.3842,  1.7362, -2.4420],\n",
            "        [-2.2435, -0.1343, -2.0408,  ..., -0.9325,  2.7637, -2.0717],\n",
            "        [-0.1064, -3.1018, -2.9409,  ...,  1.9745,  1.6883, -4.2561],\n",
            "        ...,\n",
            "        [-0.4695, -1.4010, -2.1559,  ..., -2.0145,  3.8905, -2.3492],\n",
            "        [-3.0267,  3.8362, -3.6021,  ..., -2.4411,  4.8051, -3.0510],\n",
            "        [-1.8759, -2.4841, -0.9648,  ...,  1.6527, -0.0852, -3.6143]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0782,  0.2712, -0.4187,  ..., -0.6674,  1.4466, -3.2547],\n",
            "        [-0.1742, -3.1041, -2.5944,  ...,  1.5394,  2.4809, -3.2445],\n",
            "        [-0.9970, -1.4608, -2.4972,  ..., -1.6057,  1.8632, -4.3972],\n",
            "        ...,\n",
            "        [-1.2060, -0.4527,  0.6752,  ..., -0.6447,  1.5256, -0.2215],\n",
            "        [ 0.6043, -0.1359, -1.6826,  ..., -1.0835,  2.3283, -2.2462],\n",
            "        [-0.0552, -1.1317, -2.4119,  ...,  2.6567,  0.8722, -1.7107]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7341, -1.2981, -1.7442,  ..., -0.1221,  1.2592, -1.7341],\n",
            "        [-0.5407,  1.7459, -1.4212,  ..., -2.9585,  0.6011, -1.9880],\n",
            "        [-1.1298, -0.9321, -0.7027,  ...,  2.1702,  1.9322, -3.0352],\n",
            "        ...,\n",
            "        [ 1.7808, -4.8746, -5.5110,  ...,  0.8944,  3.6917, -5.2350],\n",
            "        [-0.1388, -1.5557, -2.1753,  ...,  3.3416,  0.8173, -3.0437],\n",
            "        [ 1.0594, -3.0392, -1.7953,  ...,  1.2816,  0.5072, -2.0359]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8702e-01, -1.8133e+00, -4.3108e+00,  ...,  4.2284e-01,\n",
            "          2.5143e+00, -2.2936e+00],\n",
            "        [-1.8798e+00,  1.6336e+00, -1.4156e+00,  ..., -2.5245e+00,\n",
            "          1.3357e+00, -9.2778e-01],\n",
            "        [-1.0330e+00,  1.2251e+00, -1.4600e+00,  ..., -1.0174e+00,\n",
            "          1.0071e+00, -6.9191e-01],\n",
            "        ...,\n",
            "        [ 1.5739e+00, -1.6153e+00, -5.6052e-01,  ...,  3.5798e-01,\n",
            "          3.9725e-01, -4.8385e+00],\n",
            "        [-5.3421e-02, -9.3466e-01, -1.4050e+00,  ..., -1.9252e+00,\n",
            "          6.1621e-01, -2.9686e+00],\n",
            "        [-2.1058e-03,  3.2699e-01, -8.0437e-01,  ...,  2.7370e+00,\n",
            "          1.4744e+00, -1.2241e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9487, -1.6630, -1.5679,  ...,  4.2667,  2.7917, -0.9157],\n",
            "        [ 1.3108, -1.0169, -2.7080,  ...,  0.5471,  2.4800, -0.9493],\n",
            "        [-2.2459,  0.0391, -0.2856,  ...,  0.8830,  0.1663, -2.0705],\n",
            "        ...,\n",
            "        [-2.1997,  0.3611, -1.5661,  ..., -0.2325,  3.3024, -2.3732],\n",
            "        [-0.5660, -1.9044, -2.5255,  ...,  1.7845, -0.1042, -3.2431],\n",
            "        [-0.3001, -1.7667, -2.4085,  ..., -1.2380, -0.1125, -3.2261]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2652, -0.5734, -2.0758,  ..., -0.5701,  0.5726, -3.3099],\n",
            "        [ 0.2205, -4.4689, -3.7772,  ...,  1.5598,  2.5131, -3.5910],\n",
            "        [-2.3036, -1.2524, -3.6483,  ..., -1.8669,  1.4932, -2.0796],\n",
            "        ...,\n",
            "        [-0.4833, -1.1012, -0.3745,  ...,  2.4919,  0.7778, -2.9868],\n",
            "        [ 0.2633, -0.5552, -0.4208,  ...,  1.0560,  4.7250, -2.8768],\n",
            "        [-2.3359,  1.3307, -3.6692,  ...,  0.4406,  3.2534, -2.8204]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5126,  0.7170, -0.0231,  ...,  3.7560,  1.8972, -2.7416],\n",
            "        [-0.2174,  0.9841, -0.5701,  ..., -0.2817,  2.2964, -2.3192],\n",
            "        [-1.0494, -0.4468, -2.2850,  ..., -0.3930,  3.7684, -4.4083],\n",
            "        ...,\n",
            "        [-1.4415, -0.9810, -0.9924,  ..., -1.0569,  2.3772, -4.0066],\n",
            "        [-1.2463,  0.3528, -2.0218,  ..., -1.7961,  2.0603, -1.7510],\n",
            "        [ 1.5855, -2.4649, -4.1517,  ...,  1.3535,  2.3544, -1.5276]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5510,  1.5638, -1.7478,  ..., -1.2937,  1.5675, -1.6714],\n",
            "        [ 0.2361,  0.3606, -1.1416,  ..., -1.1920,  2.0201, -1.6446],\n",
            "        [ 2.8365, -0.5775,  0.1916,  ...,  0.6760,  1.2740, -3.0321],\n",
            "        ...,\n",
            "        [-2.2576,  2.9094, -3.0242,  ..., -1.0108,  3.4845, -3.5474],\n",
            "        [-1.9938, -2.0903, -4.0757,  ...,  1.3723,  0.9819, -3.1638],\n",
            "        [ 1.5932, -1.3887, -5.1859,  ...,  1.1813,  1.1780, -4.3527]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2109e+00, -1.0508e+00, -2.6512e+00,  ...,  2.0150e+00,\n",
            "          1.1363e-01, -2.9127e+00],\n",
            "        [-2.3206e-03,  1.8860e+00,  8.0929e-01,  ..., -8.2940e-01,\n",
            "          1.4668e+00, -1.8470e+00],\n",
            "        [ 1.1801e+00, -2.4913e+00, -4.0229e+00,  ...,  4.4259e+00,\n",
            "          2.6273e+00, -1.1068e+00],\n",
            "        ...,\n",
            "        [-2.0777e+00, -4.2265e-01, -2.4665e+00,  ...,  1.1409e+00,\n",
            "          1.6138e+00, -1.2477e+00],\n",
            "        [ 3.1353e+00, -2.7608e+00,  5.0734e-01,  ...,  3.6259e-01,\n",
            "         -8.1241e-01, -3.2571e+00],\n",
            "        [-8.2986e-01,  7.6182e-01, -1.6466e+00,  ..., -2.1193e+00,\n",
            "          6.2974e-01, -1.7903e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8545, -1.0641, -4.2135,  ...,  2.0220,  3.1558, -1.7044],\n",
            "        [ 3.5419, -3.0812, -0.4813,  ...,  0.5016,  0.2487, -2.2736],\n",
            "        [-0.3625,  1.2256, -3.1491,  ..., -1.6210,  4.6920, -2.1422],\n",
            "        ...,\n",
            "        [ 0.4553, -1.8084, -0.0489,  ..., -0.0142,  0.7883, -1.6746],\n",
            "        [-2.1958,  0.0742, -1.9943,  ..., -0.6640,  1.7294, -3.6832],\n",
            "        [-3.1839,  3.8636, -3.0041,  ..., -1.7784,  4.4484, -2.7612]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4008, -0.1975, -0.8244,  ..., -0.0241,  1.2663, -2.0342],\n",
            "        [-3.1063, -1.0711, -1.4659,  ...,  0.8731,  1.3470, -1.9033],\n",
            "        [ 0.2483,  1.9635,  0.7762,  ..., -1.4160,  1.3997, -2.6053],\n",
            "        ...,\n",
            "        [-2.8318,  0.3514, -1.1923,  ..., -0.6296,  1.0241, -2.2805],\n",
            "        [ 0.2720, -2.0329, -4.6584,  ..., -0.9735,  1.4103, -5.4097],\n",
            "        [-1.1245,  0.5684, -0.4054,  ..., -2.0790,  1.8679, -3.6272]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1754, -2.5636, -2.8778,  ...,  0.3003,  1.3193, -3.9141],\n",
            "        [ 3.0626, -0.0868, -1.7225,  ..., -1.0370,  0.2154, -1.5734],\n",
            "        [-0.2695, -0.1416, -1.5471,  ..., -1.4420,  0.5184, -2.0025],\n",
            "        ...,\n",
            "        [-0.7365, -1.5137, -1.4230,  ..., -0.6867, -0.1855, -1.3422],\n",
            "        [ 1.6385, -3.1197, -2.2612,  ..., -0.4943,  1.5723, -2.8483],\n",
            "        [ 1.1953, -3.1053, -3.2501,  ..., -0.2353,  1.0731, -3.8513]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5791,  0.1631, -2.2797,  ..., -1.0018,  1.4910, -1.1577],\n",
            "        [-1.8225,  1.8046, -2.5111,  ..., -1.4837,  3.2893, -1.5035],\n",
            "        [-0.6699, -2.5147, -3.1356,  ..., -2.3056,  1.6189, -2.4524],\n",
            "        ...,\n",
            "        [ 0.4895, -0.2655, -2.6410,  ..., -1.6333,  0.5437, -2.9718],\n",
            "        [-1.4992, -3.0141, -2.4360,  ...,  0.2775,  1.3585, -3.7233],\n",
            "        [-3.3312,  1.3404, -4.2017,  ...,  0.0316,  5.4123, -2.2646]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8932,  1.6100, -2.8382,  ..., -2.2066,  1.0075, -0.6263],\n",
            "        [-0.9967, -1.1226, -0.6702,  ..., -0.8466,  0.3665, -2.1636],\n",
            "        [-1.6885, -1.7395, -1.8730,  ..., -1.6121,  3.0331, -5.7243],\n",
            "        ...,\n",
            "        [ 1.2663, -0.9079, -1.0535,  ..., -2.8305,  2.7906, -3.6483],\n",
            "        [-1.3188, -1.5066, -0.1750,  ..., -0.9411,  2.8440, -2.6873],\n",
            "        [ 0.3977, -2.6611, -0.1920,  ...,  0.9411,  0.2346, -0.9291]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0681, -3.0221, -4.3788,  ..., -0.6882,  0.7761, -4.4083],\n",
            "        [-0.2209, -2.3731, -2.1230,  ...,  1.1510,  1.4923, -3.9461],\n",
            "        [ 2.8142, -4.1627, -4.5549,  ..., -1.1880,  3.8196, -4.6392],\n",
            "        ...,\n",
            "        [ 0.9521, -2.7246, -0.8582,  ..., -1.3872,  0.9069, -3.7288],\n",
            "        [-0.4322, -3.2128, -1.6419,  ...,  0.2474,  1.4403, -3.2123],\n",
            "        [ 0.2687,  0.5636, -3.8276,  ...,  0.0239,  1.7175, -1.6595]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5673,  0.1274, -0.0512,  ..., -2.3333,  1.9132, -2.5641],\n",
            "        [-0.9011, -0.7606, -1.5671,  ..., -2.0825,  0.7467, -2.5066],\n",
            "        [-0.1536, -1.7684, -1.7386,  ...,  0.0338,  1.9169, -3.2021],\n",
            "        ...,\n",
            "        [-0.0506, -3.2111, -2.3371,  ...,  0.9280, -0.8031, -2.3150],\n",
            "        [ 2.0346, -2.4510, -0.6273,  ..., -1.5519, -0.1026, -3.0699],\n",
            "        [ 2.5080, -2.4538, -1.5105,  ...,  0.4439,  0.2044, -1.6855]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0620, -2.7052,  0.2644,  ..., -1.1786,  0.3087, -2.0786],\n",
            "        [-1.2810,  1.7067, -3.7721,  ..., -3.0218,  4.0507, -1.1611],\n",
            "        [-2.5280, -1.6617, -1.5826,  ..., -1.3144,  3.4746, -2.6252],\n",
            "        ...,\n",
            "        [ 1.1494, -3.2996, -1.4663,  ..., -0.1214,  1.2388, -3.7398],\n",
            "        [-3.6637,  1.2992, -2.1467,  ..., -0.5465,  1.0983, -2.2526],\n",
            "        [-0.2104,  1.3236,  0.4213,  ..., -0.3379,  0.5820, -1.3212]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5530, -0.2615, -1.6856,  ..., -0.7539,  5.3879, -3.2455],\n",
            "        [-0.7440, -2.2150, -0.5004,  ...,  0.9682,  1.0304, -1.5896],\n",
            "        [-0.5260, -3.2092, -0.7187,  ...,  0.1475,  4.0849, -1.3788],\n",
            "        ...,\n",
            "        [-1.2043, -0.8600, -3.1310,  ..., -0.2064,  0.2673, -3.4498],\n",
            "        [-0.7729, -2.8726, -1.0140,  ...,  0.2284,  3.4627, -3.1179],\n",
            "        [-2.8435, -2.9564, -2.3924,  ..., -0.7937,  1.3315, -4.3520]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8731, -0.1741, -0.6676,  ..., -2.9059,  2.7196, -2.3805],\n",
            "        [-0.0572,  1.6892,  0.6272,  ..., -0.2037,  1.1233, -1.8294],\n",
            "        [ 2.7198, -4.0075, -4.3943,  ..., -0.1954,  3.2721, -1.7265],\n",
            "        ...,\n",
            "        [-2.9002,  3.6875, -4.4383,  ..., -1.5205,  4.6785, -0.4549],\n",
            "        [ 1.0189, -4.1905, -5.1394,  ...,  2.2271,  3.3474, -1.0181],\n",
            "        [-2.6796, -0.1378, -1.6812,  ..., -0.5692,  4.5279, -2.8494]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9984, -1.8590, -1.4804,  ...,  0.4409,  0.0128, -0.9308],\n",
            "        [-3.3722,  3.3526, -3.9811,  ...,  0.2799,  2.4379, -0.9810],\n",
            "        [ 0.6492, -2.4995, -2.3219,  ..., -0.9651,  1.7130, -5.2369],\n",
            "        ...,\n",
            "        [-0.2899,  0.8720,  0.2072,  ..., -1.6427,  2.0607, -1.7827],\n",
            "        [-0.8834, -1.5953, -2.1955,  ..., -0.8266,  2.2676, -3.2848],\n",
            "        [ 1.4504, -1.6316, -2.3792,  ..., -0.4013,  0.4152, -3.1696]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3026, -4.2536, -4.4920,  ...,  1.7819,  1.4050, -3.4300],\n",
            "        [ 2.2706, -5.2101, -1.2217,  ...,  0.2488,  0.5782, -4.8040],\n",
            "        [-1.3896, -1.6579, -1.8979,  ...,  1.9516,  1.5101, -1.8499],\n",
            "        ...,\n",
            "        [-1.3551, -1.6284, -3.1472,  ..., -3.3770,  1.1683, -2.3440],\n",
            "        [-3.7645, -0.6498, -2.1327,  ..., -1.4174,  4.2290, -3.2629],\n",
            "        [-0.3331, -3.4823, -1.1775,  ...,  0.5969,  0.7587, -0.2360]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7240, -2.7094, -3.3335,  ...,  0.1092,  1.2734, -2.9499],\n",
            "        [-1.7605, -3.4222, -1.7750,  ...,  0.3628,  0.2160, -4.6453],\n",
            "        [ 0.1474, -2.6210,  0.1021,  ...,  2.9104,  1.9067, -2.0493],\n",
            "        ...,\n",
            "        [-1.1821, -1.4470, -2.2662,  ...,  0.0520,  0.8549, -3.5059],\n",
            "        [-1.2725, -0.8305, -1.7381,  ..., -2.3770,  2.2314, -1.3924],\n",
            "        [-1.6364, -3.3205, -2.2394,  ...,  1.0410,  0.9898, -4.3125]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1242, -3.6510, -1.0451,  ...,  0.9568,  1.7743, -2.9356],\n",
            "        [ 0.3984, -0.8098, -2.2147,  ..., -1.0427,  0.9901, -2.7860],\n",
            "        [ 0.0758, -2.7374, -2.3808,  ..., -2.1632,  1.8074, -3.5253],\n",
            "        ...,\n",
            "        [ 0.5182, -3.4414, -2.5673,  ...,  0.4143,  0.7901, -3.7848],\n",
            "        [ 1.8306, -4.5416, -3.7554,  ..., -2.4681,  4.1427, -5.7275],\n",
            "        [-0.5845,  0.6927, -0.5514,  ..., -2.0450,  1.1917, -3.2002]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6533, -1.7758, -1.6898,  ..., -0.8709, -0.5969, -1.5599],\n",
            "        [-2.4744,  0.7618, -3.5999,  ..., -1.6249,  3.6669, -2.5357],\n",
            "        [ 0.8695, -3.1998, -2.3923,  ...,  0.2066, -0.5390, -5.2284],\n",
            "        ...,\n",
            "        [-0.4674,  1.9769, -0.4188,  ..., -1.4967,  2.2637, -2.8952],\n",
            "        [ 0.4286, -2.4521, -0.4051,  ...,  0.3012,  3.6164, -3.5939],\n",
            "        [ 0.0757, -2.1281, -1.4388,  ..., -0.1850,  3.6663, -3.2518]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6315, -1.9910, -1.8915,  ...,  0.9927,  1.2165, -3.0552],\n",
            "        [-2.3261, -0.9573, -3.3758,  ...,  1.1770,  0.2949, -1.3519],\n",
            "        [-0.4055,  1.5518,  0.9815,  ..., -1.0935,  1.1725, -2.4988],\n",
            "        ...,\n",
            "        [-1.6203, -0.8270, -2.8568,  ..., -1.7067,  0.7632, -2.7709],\n",
            "        [-0.3763, -0.7035, -0.7835,  ..., -1.8414,  1.1866, -2.2987],\n",
            "        [-1.4094, -2.5710, -3.3875,  ...,  0.6387,  3.6032, -3.7293]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2536, -3.4047, -0.8957,  ...,  3.9043,  1.4191, -3.8016],\n",
            "        [ 1.4593, -2.1302, -3.2418,  ...,  1.6647,  0.4798, -2.6736],\n",
            "        [-0.4858, -0.2412, -0.7987,  ..., -0.2065,  1.1455, -2.3251],\n",
            "        ...,\n",
            "        [ 1.8618, -3.7225, -2.8705,  ...,  0.3023,  1.6168, -3.3859],\n",
            "        [-3.2319,  0.2333, -4.1254,  ..., -0.2867,  2.3888, -1.6278],\n",
            "        [ 0.2329,  0.2014,  0.7693,  ..., -1.6218,  1.7384, -2.7015]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2014, -1.5881, -2.3732,  ..., -1.5938,  2.4211, -1.9020],\n",
            "        [ 0.7414, -4.4065, -3.8177,  ...,  1.8459, -0.9616, -5.3540],\n",
            "        [-0.7106,  1.1332,  1.2467,  ...,  0.2261,  0.7578, -1.3190],\n",
            "        ...,\n",
            "        [-1.9213,  0.3640,  0.4220,  ..., -1.0959,  0.9894, -0.9124],\n",
            "        [-2.5463, -1.5975,  0.6039,  ..., -0.8904,  1.0288, -1.2408],\n",
            "        [-1.5742, -3.3839, -0.9472,  ...,  3.0401,  0.5880, -3.0444]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9589, -1.3722, -1.5530,  ...,  2.1025,  1.3665, -1.4384],\n",
            "        [ 0.4646, -1.4248, -1.7365,  ...,  0.5965,  1.9973, -2.2727],\n",
            "        [-3.1908,  0.1326, -0.9486,  ..., -1.7142,  1.6933, -3.0477],\n",
            "        ...,\n",
            "        [ 0.3524, -3.3258, -2.6323,  ...,  0.6319,  1.2703, -4.8931],\n",
            "        [-0.6686, -2.4379, -0.6178,  ..., -0.4221,  0.4391, -2.1015],\n",
            "        [-2.0942, -1.3495,  0.7350,  ...,  1.0474, -0.2441, -3.1220]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4585, -0.6951, -1.2276,  ...,  1.3994,  0.1963, -1.7284],\n",
            "        [-1.0461, -2.8813, -2.0989,  ...,  1.4057, -0.7778, -3.0377],\n",
            "        [ 1.6991, -4.7642, -3.5959,  ...,  4.5953,  3.1159, -2.6896],\n",
            "        ...,\n",
            "        [-1.4923,  2.3445, -1.8181,  ...,  0.3270,  2.0198, -2.1410],\n",
            "        [-1.9772, -1.8742, -5.3172,  ...,  0.1753,  3.3471, -4.1083],\n",
            "        [-0.9698, -2.0586, -5.4568,  ...,  1.1208,  1.5753, -3.1370]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7470, -4.0636, -2.2581,  ...,  0.2931,  1.4411, -5.9037],\n",
            "        [ 1.5792, -2.5900, -1.5766,  ..., -1.6541,  1.6609, -2.4319],\n",
            "        [ 2.1000, -5.7516, -3.1892,  ..., -1.1425,  2.7135, -4.9702],\n",
            "        ...,\n",
            "        [-1.3622, -3.1445, -2.2557,  ...,  0.3597,  1.1104, -2.9805],\n",
            "        [-1.6792, -0.8847, -3.8667,  ..., -1.1830,  4.7439, -2.6373],\n",
            "        [-2.2339, -0.2288,  0.6774,  ..., -1.1476,  1.8945, -2.6930]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0727, -1.3475, -0.6571,  ...,  1.0475,  0.8908, -3.3362],\n",
            "        [-1.5809, -1.8745,  1.5190,  ..., -0.0998,  1.3939, -1.7801],\n",
            "        [-1.0238, -0.9549, -0.3731,  ...,  0.6304,  0.2073, -3.2775],\n",
            "        ...,\n",
            "        [-1.2840, -1.3405,  0.0404,  ..., -0.6437, -0.9026, -2.5029],\n",
            "        [-0.7325, -1.8489, -3.7789,  ..., -1.1716,  0.5861, -2.8362],\n",
            "        [-1.8588, -5.0159, -1.1053,  ...,  2.8153, -0.6179, -2.9218]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7142, -3.5784, -1.1581,  ...,  0.2791,  0.2387, -3.7047],\n",
            "        [-0.2407,  1.5886,  0.8007,  ..., -0.4134,  2.0911, -1.8197],\n",
            "        [-0.3822, -3.0360, -0.1050,  ..., -0.8976,  0.8391, -2.5200],\n",
            "        ...,\n",
            "        [-0.4790,  0.1052, -1.8051,  ..., -1.8223,  0.5501, -2.6546],\n",
            "        [ 0.3454, -1.3430, -4.8765,  ...,  0.2855,  1.4989, -5.0326],\n",
            "        [-2.9593, -0.0295, -1.5835,  ..., -0.6061,  2.2297, -2.3889]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3502, -0.0217, -3.9542,  ...,  0.9468,  2.0287, -1.2900],\n",
            "        [-0.1661,  2.0808,  0.3562,  ..., -0.5164,  1.6283, -1.7883],\n",
            "        [-1.7097, -1.2712, -1.4545,  ...,  4.0955,  1.3053, -2.0878],\n",
            "        ...,\n",
            "        [-0.6566, -3.4187, -2.4691,  ...,  2.1957,  2.0532, -2.3746],\n",
            "        [-2.4899,  1.9025, -0.1283,  ..., -0.9804,  2.4019, -1.9217],\n",
            "        [ 4.2294, -4.5170, -1.8842,  ...,  0.0566,  0.2937, -4.6928]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5127, -1.5851, -0.6879,  ..., -0.0762,  1.2228, -0.8185],\n",
            "        [-1.2008,  0.0239, -3.4647,  ..., -0.8471,  1.5498, -2.6448],\n",
            "        [-1.6870,  0.8561, -1.3570,  ..., -1.7953,  0.2243, -0.8449],\n",
            "        ...,\n",
            "        [ 0.3647, -0.3308, -1.9782,  ..., -1.4623,  1.3633, -1.7953],\n",
            "        [-1.8748, -3.0955, -2.6302,  ...,  1.3048,  0.5342, -4.4482],\n",
            "        [ 1.5963, -2.8175, -1.1230,  ...,  1.5531,  0.6678, -1.9496]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9213, -0.3475, -1.0671,  ..., -1.3065,  1.8797, -0.7133],\n",
            "        [ 0.3815, -0.4525, -2.3883,  ..., -0.7005,  1.2956, -1.5496],\n",
            "        [-3.2867,  4.3348, -0.2494,  ...,  0.2975,  2.9571, -1.6612],\n",
            "        ...,\n",
            "        [-0.9623, -1.9018, -2.8906,  ..., -1.7457,  1.0751, -2.7704],\n",
            "        [-1.3941,  0.0743, -1.9978,  ..., -0.0756,  0.4398, -1.9904],\n",
            "        [-2.1410, -0.1029, -0.5402,  ..., -2.2430,  3.1908, -1.9628]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6028, -0.8754, -3.0275,  ..., -1.6364,  0.7917, -3.1511],\n",
            "        [-0.7758, -2.5604, -2.4761,  ...,  0.4267,  1.9130, -0.4313],\n",
            "        [-0.9815, -0.2139, -2.5140,  ..., -1.5214,  1.9522, -4.7463],\n",
            "        ...,\n",
            "        [-1.4931, -2.0708, -3.3913,  ...,  1.4697,  0.1583, -3.3426],\n",
            "        [-1.6247, -0.2510,  0.7894,  ...,  3.8617,  2.8130, -1.0101],\n",
            "        [-0.7977, -0.0332, -1.8400,  ..., -1.3529,  0.4397, -1.4318]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0349, -3.0452, -3.5726,  ...,  1.2929,  1.2090, -1.9378],\n",
            "        [ 0.8135, -1.7612, -1.5583,  ..., -1.1944,  2.5500, -4.6362],\n",
            "        [-3.0646,  0.1578,  1.0776,  ...,  2.9055,  1.7060, -2.1597],\n",
            "        ...,\n",
            "        [-1.0937, -3.0951, -3.2307,  ...,  0.8216,  1.0869, -4.6029],\n",
            "        [-1.0781, -0.8337, -0.9754,  ..., -0.3602,  0.2036, -2.4594],\n",
            "        [ 0.6291,  0.8826, -1.1968,  ..., -0.5012,  1.1080, -0.9737]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2171, -1.5628, -4.3655,  ...,  2.7380,  2.6185, -2.5628],\n",
            "        [-0.8693,  2.1225,  1.0265,  ..., -0.9081,  1.9092, -2.4967],\n",
            "        [-0.3126, -2.0452, -2.8841,  ...,  3.5109,  1.7435, -2.2139],\n",
            "        ...,\n",
            "        [-2.4477, -0.5218, -2.3221,  ...,  1.4214,  1.8668, -1.3839],\n",
            "        [-0.0892, -0.8084, -3.1885,  ..., -0.1368,  2.1601, -2.3434],\n",
            "        [ 0.8190,  3.2427, -0.3684,  ..., -1.1145,  1.4138, -1.7067]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5284, -0.2681, -1.0906,  ..., -0.8686,  0.3159, -1.9510],\n",
            "        [-0.7136,  1.8803, -2.0393,  ..., -0.9368,  0.3812, -2.4622],\n",
            "        [-1.8011,  0.6129,  0.2299,  ..., -1.1856,  3.0966, -0.5700],\n",
            "        ...,\n",
            "        [-0.8730,  3.0410, -0.4498,  ..., -0.4188, -0.1973, -0.6870],\n",
            "        [-0.3198, -1.4399, -2.0224,  ..., -1.4692,  1.5554, -2.3907],\n",
            "        [-1.6476, -0.5174, -2.9227,  ..., -2.4203,  0.0843, -2.9221]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6758,  0.3046, -0.5679,  ...,  0.0143, -0.6298, -1.8094],\n",
            "        [-0.1397, -0.2617, -3.8170,  ..., -2.0113,  0.1698, -3.9716],\n",
            "        [-1.3759, -0.0125, -1.8775,  ..., -1.8820,  0.3122, -0.8072],\n",
            "        ...,\n",
            "        [-1.6047, -2.2316, -5.9847,  ...,  2.5021,  2.1680, -3.3867],\n",
            "        [-1.6042, -0.4138, -2.1088,  ..., -1.0418,  2.8583, -4.3366],\n",
            "        [-2.3898, -0.5475, -2.1443,  ..., -0.5384,  1.5863, -0.2205]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2109,  2.9155, -1.5695,  ..., -1.2116,  1.4287, -2.9825],\n",
            "        [-2.7938,  2.1634, -2.3498,  ..., -1.0861,  3.2730,  0.3521],\n",
            "        [ 2.4647, -2.7940, -0.7980,  ...,  0.0239,  1.3349, -1.8376],\n",
            "        ...,\n",
            "        [-2.7105,  3.4874, -3.6002,  ..., -3.4545,  6.1622, -2.5588],\n",
            "        [-0.5409, -1.3440, -0.7542,  ..., -0.5298,  0.8660, -0.4073],\n",
            "        [-0.0195, -2.4615, -3.4731,  ..., -3.5823,  3.6433, -2.3057]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5643,  1.9153,  0.2734,  ..., -1.3897,  0.9075, -0.3513],\n",
            "        [-2.1755, -1.7352, -2.4194,  ...,  3.1378,  0.4735, -1.8606],\n",
            "        [ 0.1268, -0.9552, -4.6799,  ...,  1.6300,  1.5050, -4.1579],\n",
            "        ...,\n",
            "        [ 0.7880, -2.6428, -4.2352,  ...,  4.0364,  2.3933, -3.2080],\n",
            "        [-2.4163,  2.3181,  0.2030,  ...,  0.8691, -0.6659, -1.0540],\n",
            "        [-2.2000,  0.8200, -1.3609,  ..., -1.2003,  1.2972, -2.0436]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4187, -1.8725, -0.6380,  ..., -0.3091,  2.0927, -1.1571],\n",
            "        [-3.1909, -0.6610, -3.4874,  ..., -1.6838,  1.6677, -1.6119],\n",
            "        [-1.1913, -0.8918, -2.2296,  ..., -1.7549,  0.1498, -1.8365],\n",
            "        ...,\n",
            "        [-0.0142, -2.1506, -1.5936,  ...,  0.3534,  0.3360, -2.2071],\n",
            "        [-1.2486, -0.4529, -5.7314,  ...,  2.0159,  2.4901, -1.3536],\n",
            "        [-0.4750,  2.5209, -0.7597,  ..., -1.0645,  2.4692, -2.3688]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9800, -1.7474, -4.8372,  ...,  1.5445,  1.8179, -1.8758],\n",
            "        [-0.9737, -3.1963, -3.9805,  ...,  3.6527,  3.5000, -3.1913],\n",
            "        [-1.4681, -5.1015, -3.9886,  ...,  0.9385,  3.2780, -4.2920],\n",
            "        ...,\n",
            "        [ 0.3182, -0.3443, -2.9182,  ..., -1.1655,  1.3311, -3.3966],\n",
            "        [-0.8313,  2.4131, -0.3395,  ..., -1.9150,  1.4493, -2.2169],\n",
            "        [-3.0637,  1.1942, -1.4887,  ..., -1.3214,  0.6316, -1.8062]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.7808,  5.1366, -1.5752,  ...,  0.1863,  5.3969, -0.7217],\n",
            "        [-1.7501, -1.8770, -3.9771,  ...,  0.1759,  4.8583, -2.2008],\n",
            "        [-0.9298, -2.3527, -2.5207,  ...,  0.2442,  1.4296, -3.0563],\n",
            "        ...,\n",
            "        [-0.4165, -1.8737, -1.6663,  ...,  0.3940,  2.0984, -2.1948],\n",
            "        [-0.1331,  0.6247, -1.2641,  ..., -1.5163,  0.8591, -2.2180],\n",
            "        [-1.2952,  0.6684, -3.9744,  ..., -0.3711,  1.3061,  0.0213]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2795, -1.0512, -0.7082,  ..., -0.9766,  2.9535, -0.5606],\n",
            "        [ 1.0947, -3.3566, -3.1284,  ...,  2.2486,  2.8211, -4.1520],\n",
            "        [ 3.8233, -4.5761, -3.8207,  ...,  1.2517,  2.1540, -2.2613],\n",
            "        ...,\n",
            "        [-3.7275,  2.6759, -4.4945,  ..., -1.4500,  2.4057, -2.4891],\n",
            "        [-2.5866,  2.6331, -0.3724,  ...,  0.5375,  0.0984, -0.0577],\n",
            "        [-1.0392, -0.5076, -2.0378,  ...,  0.7405,  2.0294, -3.4711]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1326,  0.7241, -2.4774,  ..., -1.1187,  2.7268,  0.4127],\n",
            "        [ 0.9383, -1.1534, -2.3389,  ...,  1.5934,  1.6685, -0.7785],\n",
            "        [-1.5296, -1.9830, -3.5139,  ...,  1.6334,  1.0311, -1.3926],\n",
            "        ...,\n",
            "        [ 0.2094, -2.6032, -2.8509,  ...,  0.2007,  1.1025, -4.4208],\n",
            "        [-0.8996, -2.2636, -0.9292,  ..., -0.3339,  1.3169, -2.1601],\n",
            "        [-0.4353,  2.1834, -0.3914,  ..., -0.7862,  2.2923, -1.7951]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5099,  2.7433, -1.6654,  ..., -1.2539,  1.5276, -0.9773],\n",
            "        [-2.0319,  0.4630, -1.2012,  ...,  2.6739, -0.1580, -1.7671],\n",
            "        [-0.3135, -0.5857, -2.4839,  ...,  1.6442,  0.3177,  0.4464],\n",
            "        ...,\n",
            "        [ 1.0156, -2.2680, -2.3396,  ...,  1.5960,  2.2954, -2.7370],\n",
            "        [ 2.7791, -2.1424, -4.1690,  ..., -0.1034,  1.2684, -3.0050],\n",
            "        [-2.5469,  2.0441, -4.9070,  ..., -2.7438,  2.6755, -1.5409]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4766,  0.4572, -4.9657,  ...,  0.6892,  0.8522, -1.9940],\n",
            "        [ 1.8103, -1.9125, -5.4586,  ...,  4.2156,  2.9706, -0.7275],\n",
            "        [-2.0800, -1.0280, -2.0008,  ..., -0.0138,  0.0871, -1.2102],\n",
            "        ...,\n",
            "        [-3.7021, -1.3760, -1.1680,  ...,  2.4166,  0.0243, -2.9568],\n",
            "        [-0.5223,  1.7346, -1.2850,  ..., -1.6759,  0.9150, -1.5863],\n",
            "        [-0.0078, -2.2434, -3.0158,  ...,  1.7461,  1.7033, -2.5386]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4387, -2.7733, -0.5629,  ...,  4.4808,  2.5422,  0.6794],\n",
            "        [-1.0940,  1.4197, -4.4959,  ..., -2.5031,  0.4899, -1.1507],\n",
            "        [-3.0282,  0.5716, -3.4537,  ...,  0.7518,  1.4985, -3.8277],\n",
            "        ...,\n",
            "        [-0.4884, -0.2240, -4.8231,  ..., -0.7023,  3.9589, -1.5916],\n",
            "        [ 0.9346, -3.5383, -4.2283,  ...,  1.2644,  1.1550, -2.5707],\n",
            "        [-2.6921,  2.5818, -1.2710,  ..., -0.5749,  2.4922, -1.2540]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1855, -2.6330, -5.5760,  ...,  0.6412,  0.6413, -6.5190],\n",
            "        [-1.6890,  2.4725,  0.9276,  ..., -0.7667,  1.0749, -1.1833],\n",
            "        [-2.1200,  0.0870, -7.4682,  ...,  0.8337,  2.7791, -2.8897],\n",
            "        ...,\n",
            "        [-3.5123, -0.0832, -2.8286,  ...,  2.0360, -0.3194, -0.6337],\n",
            "        [-0.2681,  3.1578,  0.5834,  ..., -1.0425,  1.6662, -1.8849],\n",
            "        [-0.9061,  4.7765, -1.9549,  ..., -0.9053,  1.8647, -1.1819]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4683, -1.5907, -4.2480,  ..., -0.2165, -0.2351, -2.3786],\n",
            "        [-3.4657, -1.0397, -5.1144,  ..., -1.2229,  1.9181, -2.5086],\n",
            "        [ 0.5325,  3.1601, -0.1803,  ..., -0.5090,  0.8203, -2.0159],\n",
            "        ...,\n",
            "        [-2.7903,  0.9554, -2.8081,  ...,  0.4938,  2.1193, -3.4737],\n",
            "        [-1.8964,  5.6448, -2.8063,  ...,  0.0578,  2.3870, -1.2706],\n",
            "        [ 2.2377, -1.4522, -3.3913,  ...,  0.5717, -2.3015, -2.9237]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4386,  0.2135,  0.1466,  ..., -1.4382,  1.4951, -1.5532],\n",
            "        [ 0.3108,  2.6854,  0.3108,  ..., -0.6873,  1.5502, -1.8539],\n",
            "        [-2.7710, -0.1121, -4.4104,  ...,  0.3918,  2.2612, -3.8909],\n",
            "        ...,\n",
            "        [-2.7236,  2.3516, -4.9288,  ..., -0.6500,  2.8246, -3.3706],\n",
            "        [ 1.0196, -3.3469, -2.1543,  ...,  2.3573,  3.1781, -4.6517],\n",
            "        [-4.7609,  4.8004, -4.1026,  ..., -0.3966,  4.0116, -2.4083]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1028e+00, -1.7312e+00, -7.0657e-01,  ...,  1.1880e+00,\n",
            "          1.5723e-01, -1.9214e+00],\n",
            "        [-1.0763e+00,  1.0013e-01, -2.4664e+00,  ...,  4.4828e+00,\n",
            "          4.3518e-03, -1.4577e+00],\n",
            "        [-4.2457e+00, -8.1640e-01, -2.1780e+00,  ...,  5.8971e-01,\n",
            "          8.4486e-01, -3.6811e+00],\n",
            "        ...,\n",
            "        [-2.5721e+00, -1.2560e+00, -3.3377e+00,  ..., -1.1471e+00,\n",
            "          1.3525e+00, -2.0139e+00],\n",
            "        [-1.2788e-02,  5.5432e-01, -5.2277e+00,  ...,  9.6190e-01,\n",
            "          1.1298e+00, -2.5767e+00],\n",
            "        [-1.9506e+00,  6.3731e-01, -2.6672e+00,  ...,  8.1883e-01,\n",
            "         -2.1155e-01, -3.3946e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6846, -1.7697, -3.5913,  ...,  2.9405,  0.7490, -3.4869],\n",
            "        [ 1.1566, -2.8663, -6.2317,  ...,  0.5224,  2.9380, -6.4087],\n",
            "        [ 1.6076, -1.0516, -5.9739,  ...,  1.1146,  1.4574, -5.2081],\n",
            "        ...,\n",
            "        [-4.8114, -0.2466, -5.1763,  ...,  0.6943, -0.1925, -4.9274],\n",
            "        [-1.7487,  4.1014, -2.8076,  ...,  0.3238,  1.3255, -1.5040],\n",
            "        [ 1.8552, -0.5331, -3.7469,  ...,  0.1323,  2.1488, -2.1472]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6636,  4.9989, -3.2955,  ...,  1.0998,  4.3732, -2.8857],\n",
            "        [-0.3835, -3.4402, -3.9481,  ..., -0.6265,  3.0833, -3.5506],\n",
            "        [-0.2165,  0.5138, -2.8314,  ..., -1.6173,  0.8592, -3.5896],\n",
            "        ...,\n",
            "        [ 0.7311, -1.6119, -4.2432,  ...,  0.9140, -0.2227, -2.6130],\n",
            "        [-1.2911, -0.8028, -4.0718,  ..., -0.5389,  0.3035, -2.8252],\n",
            "        [-0.6363,  0.2049, -1.4711,  ...,  0.3267,  2.5198, -2.6226]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0889,  1.2897, -4.5883,  ..., -0.1663,  3.5250, -1.9427],\n",
            "        [-1.0035, -0.7837, -6.1999,  ...,  0.9851,  1.1034, -2.6259],\n",
            "        [-0.5782,  0.2174,  0.5438,  ...,  0.5499,  0.5325, -0.4965],\n",
            "        ...,\n",
            "        [-0.8154, -1.6113, -4.0084,  ...,  2.6620,  2.7037, -2.9585],\n",
            "        [ 1.2588, -2.1226, -4.9916,  ...,  1.7772, -0.3173, -1.5956],\n",
            "        [ 0.8677, -3.3980, -5.1982,  ...,  0.1150,  0.9088, -2.8804]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2203,  0.8733, -2.2607,  ..., -1.7359,  3.2264, -1.0355],\n",
            "        [-0.7623, -1.6553, -2.3708,  ..., -1.1782, -0.4492, -1.2260],\n",
            "        [-5.7218,  3.9533, -3.2714,  ...,  0.1769,  2.7052, -1.0278],\n",
            "        ...,\n",
            "        [ 0.7568, -3.3204, -2.7430,  ...,  3.8516,  0.8919, -2.3281],\n",
            "        [-4.5527, -0.5337, -4.2074,  ...,  1.4741,  1.6997, -2.9755],\n",
            "        [-1.6382, -2.5963, -3.0631,  ..., -1.3773,  2.1938, -3.2941]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2941, -0.2515, -2.0704,  ...,  2.1937,  0.4157, -2.6599],\n",
            "        [-3.3456,  0.3775, -2.8517,  ..., -1.4653,  0.9197, -0.6560],\n",
            "        [ 1.0430, -1.7898, -4.7253,  ...,  2.1600,  1.4531, -2.4778],\n",
            "        ...,\n",
            "        [-0.0202, -1.8952, -6.3854,  ...,  5.2004,  3.9212, -1.0092],\n",
            "        [-0.3999,  2.0680,  0.5718,  ..., -0.2087,  1.7942, -2.0366],\n",
            "        [-4.6453,  0.4545, -4.6416,  ...,  0.6928,  1.5620, -4.8568]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9614,  2.9876, -4.5288,  ..., -0.1904,  2.8248, -1.0487],\n",
            "        [-1.7860, -1.0577, -1.4397,  ..., -1.1876,  0.6233, -2.9622],\n",
            "        [-0.1094,  0.0348, -3.4756,  ..., -2.7116,  0.8471, -2.2174],\n",
            "        ...,\n",
            "        [-0.8406,  0.6513, -2.4837,  ..., -2.5213,  0.2885, -2.4101],\n",
            "        [ 1.4443, -2.6750, -4.0321,  ...,  1.5675, -0.3059, -2.7261],\n",
            "        [-0.5149, -0.6148, -4.5102,  ..., -0.3032,  0.6344, -2.3210]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3192,  1.4402, -2.6974,  ..., -1.6014,  3.3943, -3.0224],\n",
            "        [-3.2488,  2.2976, -3.3113,  ...,  1.3276,  2.3582, -2.4875],\n",
            "        [-0.0497, -1.1555, -0.6744,  ..., -0.0960, -0.7922, -3.0841],\n",
            "        ...,\n",
            "        [ 1.1035, -2.9077, -6.4578,  ...,  0.5023,  1.0506, -4.7470],\n",
            "        [ 1.4437, -1.9387, -0.9006,  ..., -0.0920,  0.3031, -1.6766],\n",
            "        [-2.2910, -0.3574, -1.4227,  ..., -1.9475,  2.5657, -1.8453]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6143,  0.4141, -2.6305,  ...,  0.0408,  2.1491, -2.5365],\n",
            "        [-4.0874,  1.6527, -3.5195,  ..., -0.8846,  2.9235, -3.3723],\n",
            "        [-2.6581, -0.1693, -0.3611,  ...,  0.1340,  0.6276, -1.7477],\n",
            "        ...,\n",
            "        [-1.3896, -1.5130, -2.3477,  ..., -0.3663,  2.6438, -1.1793],\n",
            "        [-2.5769,  1.8494, -0.7835,  ..., -0.4989,  2.5938, -1.8451],\n",
            "        [-1.4067, -2.3809, -1.7986,  ...,  1.6385,  0.8012, -2.3397]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3286, -0.5818, -1.3316,  ...,  2.1254,  1.4444, -1.8376],\n",
            "        [-2.3285,  1.0042, -2.0886,  ..., -1.1825,  1.8287, -0.0826],\n",
            "        [-1.9556, -2.9832, -4.2208,  ...,  1.8767,  1.1318, -4.0822],\n",
            "        ...,\n",
            "        [-2.5875, -0.8735, -4.3337,  ...,  1.5511,  0.6868, -4.4272],\n",
            "        [-2.1733,  0.1362, -4.6521,  ...,  0.5832,  0.0584, -3.0210],\n",
            "        [-3.1667, -0.3130, -0.1112,  ..., -0.9993,  1.8086, -1.3455]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0237e+00,  1.5570e+00, -6.5240e-01,  ..., -1.9761e+00,\n",
            "          1.4100e+00, -3.3157e+00],\n",
            "        [-1.2176e+00, -1.4645e+00, -1.3307e+00,  ..., -1.2125e+00,\n",
            "          3.3820e+00, -4.4640e+00],\n",
            "        [ 1.0306e+00,  6.2439e-01, -2.7527e+00,  ...,  3.5683e+00,\n",
            "         -8.2262e-01, -1.0913e+00],\n",
            "        ...,\n",
            "        [ 2.6284e-01, -1.2136e+00, -2.5800e+00,  ...,  1.3852e-03,\n",
            "          9.0423e-01, -2.3330e+00],\n",
            "        [-8.9142e-01, -7.2148e-01,  1.3660e+00,  ...,  2.3633e+00,\n",
            "          2.4973e+00, -8.8828e-01],\n",
            "        [-5.3452e-01, -7.9551e-01, -6.5890e-01,  ..., -1.3191e+00,\n",
            "          8.9268e-01, -6.6555e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4102,  2.1670, -1.1424,  ..., -0.6928,  1.3095, -3.2994],\n",
            "        [ 1.5613, -3.8553, -4.0316,  ...,  2.8763, -1.1059, -3.5173],\n",
            "        [-2.3829,  1.3633, -4.9275,  ...,  0.4250,  0.7244, -3.0058],\n",
            "        ...,\n",
            "        [ 0.4716, -0.6317, -0.7770,  ...,  0.2266,  0.0259, -2.6787],\n",
            "        [-2.4628,  1.8352, -3.5386,  ..., -0.3262,  0.9718, -1.3027],\n",
            "        [ 0.7546,  0.7649, -4.6032,  ...,  1.1106,  1.4037, -1.3382]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3463,  3.0471, -2.6925,  ..., -0.1334,  0.2948, -1.5068],\n",
            "        [ 0.3297, -2.0732, -3.4150,  ...,  1.1061,  1.3486, -4.9017],\n",
            "        [ 1.7852, -2.9621, -5.0728,  ...,  1.1690,  2.1074, -2.9256],\n",
            "        ...,\n",
            "        [ 0.2621, -1.0252, -0.8441,  ...,  0.5973,  1.0319, -1.8855],\n",
            "        [-1.7300,  2.2757, -0.5694,  ..., -2.7021,  1.8170, -2.7931],\n",
            "        [-1.6530, -0.4347, -4.1928,  ..., -0.9348,  1.4891, -3.8453]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0174, -3.6608, -2.0528,  ..., -0.0480, -2.0525, -5.4449],\n",
            "        [ 0.8021, -2.3713, -3.2879,  ...,  0.4495, -1.2803, -3.4020],\n",
            "        [-3.0098, -0.0542, -2.6586,  ...,  0.6326,  0.0667, -2.3707],\n",
            "        ...,\n",
            "        [-0.4169,  0.4309, -2.5813,  ...,  1.3738,  2.7250, -0.4763],\n",
            "        [-0.8582,  3.1772,  0.2169,  ..., -1.1875,  0.4518, -2.4186],\n",
            "        [-2.0531, -0.3973, -2.2023,  ..., -1.7165,  1.5036, -2.7095]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0941,  0.2661, -1.9962,  ..., -1.0328, -0.2134, -1.2065],\n",
            "        [-1.5148, -1.6449, -2.0154,  ...,  0.3210,  1.2013, -1.9974],\n",
            "        [-1.8152, -2.2942, -1.4364,  ..., -0.1749,  0.1891, -2.7871],\n",
            "        ...,\n",
            "        [-1.6753, -0.2288, -2.3560,  ...,  0.9344,  0.9350, -2.3476],\n",
            "        [ 0.7140, -4.1664, -2.3610,  ...,  3.1500,  0.7543, -1.9542],\n",
            "        [ 0.2364, -2.5111, -2.1273,  ...,  0.6612,  0.9215, -2.3318]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9825,  0.5429, -2.1246,  ..., -2.3697,  0.6878, -3.1634],\n",
            "        [-1.6911,  0.3490, -2.1426,  ..., -2.3744,  0.1364, -1.7748],\n",
            "        [-0.1873,  1.4385, -6.1379,  ..., -2.0697,  2.9118, -2.8381],\n",
            "        ...,\n",
            "        [-1.4692, -2.2585, -4.1171,  ...,  1.7408,  1.8424, -4.4222],\n",
            "        [-2.3582, -1.7234, -3.6376,  ...,  1.7477,  1.3059, -3.5676],\n",
            "        [-3.0083, -1.0842, -4.0229,  ..., -0.2354,  3.9250, -3.6843]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4913, -0.6022, -3.3964,  ...,  0.4068, -0.3224, -3.4054],\n",
            "        [-0.8811, -3.3274, -5.2448,  ...,  2.5945,  1.5206, -4.0437],\n",
            "        [-2.3599, -0.4381, -5.6556,  ..., -0.0718,  1.9406, -4.7494],\n",
            "        ...,\n",
            "        [-0.8004, -1.2674, -2.1377,  ...,  2.6010,  0.5320, -2.7648],\n",
            "        [-1.9500,  1.6216, -1.6345,  ..., -1.9473,  0.4557, -0.9674],\n",
            "        [ 0.7471, -1.8188, -2.7511,  ...,  0.4219, -0.5337, -3.6352]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7906,  1.7824, -2.7279,  ..., -2.4893,  0.6319, -2.8165],\n",
            "        [-1.3552, -0.8855, -2.5355,  ...,  0.8400, -0.3180, -4.1420],\n",
            "        [-0.6206, -1.2682, -2.6299,  ...,  1.1175, -0.7379, -3.3660],\n",
            "        ...,\n",
            "        [ 0.6095, -3.5373, -5.8414,  ...,  2.7753,  0.6125, -4.7472],\n",
            "        [-0.2921, -2.9817, -3.8518,  ...,  1.2968, -0.3856, -4.5653],\n",
            "        [-0.3907, -0.6273, -0.8372,  ..., -1.2688,  0.2695, -1.4955]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.8962,  2.4058, -0.8738,  ..., -0.8680,  1.6280, -2.1669],\n",
            "        [ 0.7921, -4.0706, -4.3031,  ...,  0.6404, -1.2330, -4.4251],\n",
            "        [-1.5115, -1.8104, -2.1806,  ..., -1.1013,  3.2260, -1.7666],\n",
            "        ...,\n",
            "        [-2.4061, -0.9837, -0.3916,  ...,  0.4579, -0.6782, -1.5067],\n",
            "        [ 0.9768, -0.7169,  0.7262,  ...,  0.5062, -0.9269, -2.8259],\n",
            "        [-1.5925,  1.6465,  0.3091,  ...,  1.0338,  1.8489, -1.3011]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6185,  1.8160, -3.2107,  ..., -1.5890,  1.1012, -2.8411],\n",
            "        [-0.6169, -1.6223, -2.5030,  ...,  0.7565,  0.2997, -3.5757],\n",
            "        [-0.2426, -2.3782, -3.3339,  ...,  2.0185,  1.6064, -3.2090],\n",
            "        ...,\n",
            "        [-1.6011,  0.0331, -1.9680,  ..., -1.5457,  0.1976, -1.5082],\n",
            "        [-3.2420,  1.3241, -4.9619,  ..., -2.6229,  2.4734, -3.2690],\n",
            "        [-2.5317, -0.3803, -5.6232,  ...,  1.5082, -0.2214, -2.5039]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3928, -3.0180, -2.6897,  ...,  1.7354,  1.4986, -5.6314],\n",
            "        [ 0.3385, -3.8736, -4.3840,  ...,  1.9534,  0.4104, -3.9673],\n",
            "        [-1.5643,  1.4033, -1.5592,  ..., -1.0589,  1.2138, -2.1952],\n",
            "        ...,\n",
            "        [-0.8829,  1.2516, -2.3050,  ..., -2.7334, -0.1118, -2.2288],\n",
            "        [-1.5406,  2.7789, -1.4056,  ..., -0.2003,  2.1259, -1.6947],\n",
            "        [-0.8766, -0.6866, -0.3507,  ..., -1.5246,  1.4705, -2.7597]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9690, -0.2695, -1.4587,  ...,  0.5257,  0.4313, -1.4992],\n",
            "        [ 1.6445, -0.9962, -2.1995,  ..., -0.5155,  1.8822, -3.7670],\n",
            "        [-0.9577, -1.9456, -1.6420,  ...,  4.4609,  0.7913, -2.3280],\n",
            "        ...,\n",
            "        [-3.4176, -0.4777, -3.0189,  ..., -0.7831,  0.4419, -1.7018],\n",
            "        [-0.8987,  0.5513, -1.6135,  ..., -1.8869,  2.5295, -3.7032],\n",
            "        [-3.4110, -0.7367, -2.3924,  ..., -0.6211,  1.0976, -3.1441]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7827, -2.1133, -4.9538,  ...,  1.4453,  0.5450, -7.0952],\n",
            "        [-4.3547,  0.9189, -3.0094,  ...,  0.5649, -0.3452, -0.5814],\n",
            "        [ 0.3522,  2.4065, -3.7802,  ...,  1.1643,  0.5771, -1.1044],\n",
            "        ...,\n",
            "        [ 0.0529, -2.4393, -4.2117,  ...,  0.6272, -1.5778, -5.5302],\n",
            "        [-2.9608, -0.5454, -2.0187,  ..., -2.1097,  0.1192, -3.6893],\n",
            "        [-0.5077,  1.7625, -1.7174,  ..., -1.9422, -0.3770, -2.6580]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4868, -2.2616, -7.8809,  ...,  3.8197,  0.7954, -4.3679],\n",
            "        [ 2.3128,  0.2025, -4.4420,  ...,  2.1607,  1.3061, -1.8587],\n",
            "        [-2.3744,  0.4504, -2.1161,  ...,  0.5394,  1.0058, -3.0655],\n",
            "        ...,\n",
            "        [-0.6858, -1.7222, -2.6718,  ...,  0.3101,  3.2472, -3.2588],\n",
            "        [-4.4026,  1.1893, -2.1873,  ..., -1.0878,  0.7177, -3.4569],\n",
            "        [ 0.5909,  0.5340, -0.4645,  ..., -1.2354, -0.6259, -3.2966]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6473,  0.5562, -0.9800,  ..., -1.4423,  1.2853, -1.6716],\n",
            "        [-0.4958, -2.1573, -1.5755,  ...,  0.5542,  2.6464, -2.3924],\n",
            "        [ 1.6405, -4.3729, -5.1355,  ...,  2.0149,  1.8297, -4.3825],\n",
            "        ...,\n",
            "        [-0.6476, -2.0462, -4.4165,  ...,  0.2065,  1.9754, -3.0985],\n",
            "        [-3.0453,  1.8421, -4.1309,  ...,  0.7215,  1.1139, -1.6849],\n",
            "        [-2.9560,  1.3891, -3.3631,  ..., -1.8493, -0.1382, -1.6132]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9513,  3.4140,  0.1557,  ..., -0.0443,  2.0570, -2.5567],\n",
            "        [ 0.2757, -1.1490, -0.5666,  ...,  1.0037,  0.8068, -2.3722],\n",
            "        [-7.1310,  4.7944, -4.7750,  ..., -2.9212,  3.5565, -2.1965],\n",
            "        ...,\n",
            "        [ 2.4285, -1.5472, -3.0439,  ...,  0.2645,  0.8437, -2.3328],\n",
            "        [-3.1477,  0.6927, -2.3280,  ...,  0.1621,  1.3881, -1.3043],\n",
            "        [-0.6967,  3.7794,  0.6883,  ..., -1.2328,  1.0023, -2.3975]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4311,  2.1823, -1.2470,  ..., -1.7144,  1.2720, -3.4196],\n",
            "        [-2.5040, -1.6976, -5.1132,  ...,  1.2485,  1.2653, -4.5807],\n",
            "        [ 0.5818, -4.4372, -3.9414,  ...,  5.6303,  1.8473, -2.8713],\n",
            "        ...,\n",
            "        [-1.2659,  0.4403, -5.0097,  ..., -0.9452,  1.1617, -5.0775],\n",
            "        [-3.5129,  4.6058, -4.5219,  ..., -1.3026,  2.1291, -2.4257],\n",
            "        [ 1.7138, -0.6442, -3.3003,  ...,  0.2167, -0.8178, -3.4717]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8381, -1.4711, -3.5964,  ..., -0.1020,  1.0009, -4.3170],\n",
            "        [-1.3868,  1.1127, -2.1525,  ..., -2.2164, -0.0051, -1.5249],\n",
            "        [-2.6816, -1.6872,  1.6380,  ..., -1.2403, -0.8980, -2.6790],\n",
            "        ...,\n",
            "        [ 1.6846, -2.2872, -3.1078,  ...,  1.9670,  1.6758, -3.8190],\n",
            "        [-1.6904,  0.8363, -2.8004,  ..., -0.5284,  1.1182, -3.3860],\n",
            "        [-2.2098,  0.3047, -3.4550,  ..., -2.1177,  1.7083, -2.2770]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0338e+00, -2.4842e+00, -3.4785e+00,  ..., -3.8623e-01,\n",
            "          4.2936e-01, -3.4969e+00],\n",
            "        [-2.4175e+00,  4.6212e-01, -1.3325e+00,  ...,  1.9131e+00,\n",
            "         -3.3631e-01, -1.8987e+00],\n",
            "        [-1.2149e+00, -7.7445e-01, -3.5893e+00,  ...,  2.8778e-01,\n",
            "          2.0112e-03, -2.2085e+00],\n",
            "        ...,\n",
            "        [-2.5582e-01,  2.6688e+00,  1.6741e-01,  ..., -6.7671e-01,\n",
            "          1.4684e+00, -2.7646e+00],\n",
            "        [-1.2862e+00,  3.8944e+00, -3.3534e-01,  ..., -5.6970e-01,\n",
            "          1.3180e+00, -3.2687e+00],\n",
            "        [-3.5046e+00,  2.3591e+00, -4.9981e+00,  ..., -3.5426e-01,\n",
            "          2.2863e+00, -2.4748e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7086, -1.9136, -2.1480,  ..., -0.2230, -0.5527, -3.5578],\n",
            "        [-1.9617,  0.0364, -0.8889,  ...,  0.5492, -0.7185, -2.4977],\n",
            "        [-3.8012, -0.1381, -3.2549,  ..., -1.7989,  3.0729, -4.7155],\n",
            "        ...,\n",
            "        [-0.3904, -3.4330, -1.8366,  ...,  4.4695,  0.3096, -1.3635],\n",
            "        [-0.5343,  0.6441, -2.1471,  ..., -2.1712,  0.0571, -3.0426],\n",
            "        [-1.3751, -0.8167, -7.5606,  ...,  0.4414,  1.8199, -4.9685]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4913, -3.9744, -2.4757,  ...,  0.6047,  1.4227, -4.3588],\n",
            "        [ 0.1374, -0.9220, -1.0216,  ...,  0.6685, -0.3782, -2.7028],\n",
            "        [ 2.0731, -4.7402, -4.2658,  ...,  1.6987,  0.4497, -3.8346],\n",
            "        ...,\n",
            "        [-1.3974, -0.7246, -4.3858,  ...,  1.0380,  2.1160, -4.7248],\n",
            "        [-0.0510, -3.2655, -2.8557,  ...,  0.2658, -1.4169, -3.2510],\n",
            "        [ 1.5544, -3.1393, -4.0551,  ..., -0.0843, -0.9266, -5.1691]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8355,  1.6987, -4.3673,  ..., -1.1517,  1.9173, -3.3827],\n",
            "        [-3.2798,  1.0808, -2.8685,  ...,  1.2029,  2.9590, -4.1488],\n",
            "        [-1.5379, -1.5016, -3.7982,  ..., -1.2971,  1.9283, -4.4217],\n",
            "        ...,\n",
            "        [-0.9618,  0.4037, -2.5041,  ..., -2.5835, -0.5610, -3.2147],\n",
            "        [-1.3094,  2.7577,  0.2881,  ..., -0.8346,  1.4021, -2.1915],\n",
            "        [-3.9775,  0.3968, -4.0840,  ..., -2.1101,  0.5252, -4.2348]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0676, -4.2758, -5.1016,  ...,  0.7793,  0.8169, -4.8163],\n",
            "        [-3.6545,  0.0964, -2.5082,  ...,  2.5896,  2.1145, -2.1860],\n",
            "        [-1.6712,  3.7310, -0.5206,  ..., -0.6878,  1.3865, -3.4406],\n",
            "        ...,\n",
            "        [ 1.6541, -4.2962, -4.6464,  ...,  1.3227, -1.1594, -5.5634],\n",
            "        [ 1.0901, -2.7984, -2.9365,  ...,  0.4621,  1.2584, -5.2305],\n",
            "        [-0.7277, -2.1960, -5.5881,  ..., -0.8192,  1.6689, -4.1539]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4349, -1.8417, -3.2742,  ..., -0.3203,  2.8926, -2.8013],\n",
            "        [-1.8148, -4.0693, -2.5399,  ...,  0.8201,  0.1088, -4.6225],\n",
            "        [-1.2790, -1.0596, -5.9072,  ..., -0.9256,  0.7966, -4.4404],\n",
            "        ...,\n",
            "        [-1.9611, -1.3269, -0.5845,  ...,  0.8010, -0.7080, -1.3218],\n",
            "        [-2.2976,  0.8941,  0.9871,  ..., -0.4427,  0.2870, -1.5927],\n",
            "        [ 0.5559, -2.6524, -4.1869,  ...,  3.8738,  2.1330, -2.5001]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7187, -0.4200, -2.8354,  ...,  0.0953, -0.8806, -3.1771],\n",
            "        [-0.9738,  0.2497, -2.6299,  ...,  1.0542, -1.1011, -4.2260],\n",
            "        [-2.4223,  3.6605, -4.3090,  ..., -2.6973,  0.6161, -3.4036],\n",
            "        ...,\n",
            "        [-3.2359,  3.3924, -1.8315,  ...,  1.5937, -0.2682, -1.4356],\n",
            "        [-1.2764, -0.3500, -6.0235,  ...,  2.1778,  1.5959, -2.4403],\n",
            "        [-0.7173, -5.6977, -3.9896,  ...,  3.4991,  1.2621, -2.8606]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0140, -4.0660, -3.6392,  ...,  5.5061,  1.7153, -2.8890],\n",
            "        [-1.9320, -2.1368, -4.1797,  ...,  1.9754,  1.8885, -4.1765],\n",
            "        [-0.7754, -1.8968, -0.9557,  ...,  1.3256, -0.6135, -1.0037],\n",
            "        ...,\n",
            "        [-2.3666,  2.6644, -3.0296,  ..., -0.2901,  1.4552, -1.1251],\n",
            "        [ 0.4771, -1.9825, -5.4004,  ...,  1.3116,  1.2069, -5.6588],\n",
            "        [-1.4548, -0.1018, -3.7984,  ...,  3.6079,  1.1628, -2.0865]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5916,  2.3011, -2.4558,  ..., -1.3346,  0.3560, -1.6944],\n",
            "        [-2.8446,  0.3858, -1.4698,  ..., -1.6481, -1.1319, -3.2140],\n",
            "        [ 0.2860,  1.7139,  0.0135,  ..., -1.9350, -0.0097, -2.0641],\n",
            "        ...,\n",
            "        [-4.3670,  1.4844, -3.2483,  ..., -1.5131,  1.8993, -3.7333],\n",
            "        [-4.0040,  0.8366, -3.7320,  ..., -1.6248,  2.3743, -3.6314],\n",
            "        [-2.3809,  0.5988, -1.9321,  ..., -0.2967,  0.0576, -3.0774]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0107, -1.2483, -3.3837,  ...,  1.2801,  0.6310, -4.0996],\n",
            "        [-1.5379,  1.4515, -1.6468,  ..., -2.6559, -0.3485, -2.8958],\n",
            "        [-2.6498,  0.6327, -5.0949,  ...,  0.9374,  0.0709, -2.2396],\n",
            "        ...,\n",
            "        [-2.6222,  0.1661, -1.3201,  ...,  0.3808,  0.9804, -1.6246],\n",
            "        [-0.6558, -0.6384, -1.9093,  ..., -1.6192,  2.5008, -4.5396],\n",
            "        [-3.6830,  3.8323, -4.4714,  ...,  0.1865,  3.4139, -2.6194]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8741,  4.0300, -0.1639,  ...,  0.0950, -0.5660, -1.7104],\n",
            "        [-1.1193,  3.6124,  0.0985,  ..., -0.8775,  0.0461, -1.8101],\n",
            "        [-2.7151, -0.3829, -2.6269,  ..., -0.7483, -1.4762, -2.7350],\n",
            "        ...,\n",
            "        [-1.4346, -2.2026, -3.4677,  ..., -0.7201, -0.7724, -3.2089],\n",
            "        [-2.5490, -0.2507, -1.1473,  ...,  0.9089, -0.4446, -3.0527],\n",
            "        [-2.5427, -1.1784, -4.1726,  ..., -0.0260,  0.6313, -3.9710]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6555, -0.5269, -2.0199,  ..., -1.2657,  1.5814, -2.9665],\n",
            "        [ 0.0782,  1.1557, -1.9955,  ...,  1.1788, -0.4522, -0.1325],\n",
            "        [-0.1563, -2.4629, -4.8059,  ..., -0.2795,  1.8900, -5.1822],\n",
            "        ...,\n",
            "        [-1.1171, -2.8239, -7.1868,  ...,  3.4904,  0.2695, -3.9687],\n",
            "        [-1.5997, -0.2395, -4.7040,  ...,  2.1235,  1.6524, -2.7931],\n",
            "        [-0.5753, -1.2965, -1.4594,  ...,  0.4002,  0.8175, -2.9551]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9656, -1.3812, -4.8240,  ...,  0.2682,  1.9095, -3.0842],\n",
            "        [ 0.4067, -0.6360, -2.4873,  ...,  1.2354, -0.6064, -2.3234],\n",
            "        [-4.1119,  4.4247, -2.8573,  ..., -2.2311,  3.9636, -2.6028],\n",
            "        ...,\n",
            "        [-2.4401,  0.2905, -5.3712,  ..., -0.4255,  0.1937, -3.8621],\n",
            "        [-4.6642, -2.4929, -7.6722,  ...,  1.8350, -0.1247, -3.8882],\n",
            "        [-0.5915, -3.3307, -2.5532,  ...,  2.1065,  0.8753, -4.2266]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5469e+00, -1.1321e+00, -3.7831e+00,  ..., -4.0605e-01,\n",
            "          4.2713e-01, -1.8046e+00],\n",
            "        [-5.0801e-01, -3.7733e-01, -5.4103e+00,  ..., -2.5840e-02,\n",
            "          2.2313e+00, -1.9459e+00],\n",
            "        [-3.2160e+00,  3.0796e+00, -1.9807e+00,  ...,  1.1836e-03,\n",
            "          1.2516e+00, -1.6036e+00],\n",
            "        ...,\n",
            "        [ 9.5340e-01, -3.8829e+00, -1.3867e+00,  ...,  9.3518e-01,\n",
            "          1.1812e+00, -3.5326e+00],\n",
            "        [-1.0986e+00, -8.7799e-01, -6.9509e+00,  ..., -1.1418e-01,\n",
            "          1.3314e+00, -3.9405e+00],\n",
            "        [-2.2012e+00, -3.6615e-01, -5.1948e+00,  ...,  1.4214e+00,\n",
            "          5.5751e-02, -3.4384e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0630,  3.8244, -1.8800,  ..., -0.2248,  1.0583, -1.9463],\n",
            "        [-2.9023,  1.5831, -1.1918,  ..., -0.3357,  1.9073, -1.4931],\n",
            "        [-2.2844,  0.9325, -5.1423,  ..., -1.3994,  1.1173, -3.5142],\n",
            "        ...,\n",
            "        [-0.6728, -1.8308, -2.5718,  ...,  1.1569, -0.1854, -3.6401],\n",
            "        [-1.7124, -1.6165, -3.8290,  ..., -1.0831,  1.4808, -3.9854],\n",
            "        [-3.4845,  0.0867, -3.9076,  ..., -0.9705, -1.3557, -1.6062]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1825,  1.2734, -1.3107,  ..., -0.4226,  0.2711, -3.3895],\n",
            "        [-2.8773, -1.3116, -1.7425,  ..., -1.4955, -0.2862, -4.7600],\n",
            "        [-2.5683,  1.5195,  1.7735,  ..., -0.6869, -0.0263, -3.6398],\n",
            "        ...,\n",
            "        [-1.0982, -1.5513, -0.9625,  ..., -1.9478,  1.1623, -3.1635],\n",
            "        [-2.9500,  2.1595, -1.8415,  ..., -0.6639,  0.9076, -2.9158],\n",
            "        [ 0.2091, -2.9194, -5.8744,  ...,  0.7811, -0.5488, -5.7813]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6932, -2.7925, -2.5105,  ..., -1.6106,  2.8376, -3.8705],\n",
            "        [-3.0713,  1.0078, -1.2325,  ..., -1.9093,  1.3657, -2.4396],\n",
            "        [ 0.3447, -1.1536, -3.0922,  ..., -0.1037,  0.9138, -1.6950],\n",
            "        ...,\n",
            "        [-2.7692, -2.7685, -3.6423,  ..., -1.7415, -0.4726, -5.6827],\n",
            "        [-0.0435, -0.5490, -5.2664,  ...,  1.9623, -1.8912, -3.6243],\n",
            "        [-0.0868, -3.1077, -1.4998,  ...,  1.1487,  0.9444, -4.2939]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7825, -3.2415, -6.1865,  ...,  3.7453,  0.4243, -5.4864],\n",
            "        [-1.1379,  1.0744, -0.8971,  ...,  0.6619, -0.5733, -1.7862],\n",
            "        [-2.5396,  0.1772, -0.0565,  ..., -0.2534, -0.2361, -2.6541],\n",
            "        ...,\n",
            "        [-4.1472, -0.3338, -7.7256,  ..., -1.7314,  1.5496, -2.7767],\n",
            "        [-2.7734, -2.1901, -3.2564,  ..., -1.3292, -0.3421, -3.5188],\n",
            "        [-5.0787,  1.3816, -1.9137,  ..., -0.9718,  0.2747, -3.5974]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9491, -2.6626, -4.4408,  ...,  3.6610,  2.7696, -4.4075],\n",
            "        [-1.2229, -0.4526, -1.9684,  ..., -1.7235, -0.2011, -1.8877],\n",
            "        [ 0.2518, -2.7062, -2.3323,  ...,  1.1837, -0.9384, -3.0380],\n",
            "        ...,\n",
            "        [-4.1280, -0.0429, -2.5050,  ..., -2.9840,  0.6021, -3.6454],\n",
            "        [-1.4649, -1.2552, -2.7099,  ...,  0.8020,  0.3028, -1.2690],\n",
            "        [-2.1066, -0.2829, -3.7503,  ..., -2.1398,  3.7542, -5.2674]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4631,  2.7121, -0.8557,  ..., -3.1849,  0.3288, -3.2077],\n",
            "        [-4.5835, -0.2640, -0.7972,  ..., -2.8311, -1.1825, -2.1732],\n",
            "        [-1.5038, -0.3442, -0.0398,  ...,  1.1317,  0.1595, -1.7469],\n",
            "        ...,\n",
            "        [-0.4600, -2.1469, -6.5556,  ..., -0.2396, -0.1996, -6.5903],\n",
            "        [-0.6842, -4.8991, -3.6137,  ...,  0.1229,  0.6239, -4.6408],\n",
            "        [-3.3687, -1.6105, -1.5418,  ..., -1.5171,  1.6511, -4.3272]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8010,  3.5685,  0.4092,  ..., -1.3280,  1.6389, -2.6690],\n",
            "        [-4.1543,  0.1093, -0.8057,  ..., -1.1534,  2.3618, -1.4188],\n",
            "        [-2.8882,  0.7259, -1.5789,  ..., -2.4127,  0.8890, -2.6096],\n",
            "        ...,\n",
            "        [ 0.7530, -0.5238, -3.9333,  ...,  0.8918,  1.4006, -1.9204],\n",
            "        [-2.4222, -1.1338, -1.5872,  ..., -0.8924,  1.4918, -1.3729],\n",
            "        [-1.9557, -2.5266, -3.9555,  ..., -1.7828, -0.0815, -3.5556]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1600, -1.2090, -0.6200,  ..., -0.3098,  1.2089, -2.0457],\n",
            "        [-1.3915, -2.8329, -5.0751,  ...,  2.8616, -0.4836, -3.8717],\n",
            "        [-2.8556, -0.5154, -4.3310,  ..., -0.6710,  0.8790, -2.3390],\n",
            "        ...,\n",
            "        [-0.2016,  1.4976, -2.8107,  ...,  0.6656, -0.0152, -2.0803],\n",
            "        [-0.2337, -1.5436, -1.7996,  ...,  0.5733,  0.5679, -4.1873],\n",
            "        [-2.2021, -0.1899,  0.8139,  ..., -1.0618,  3.8332, -1.1154]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2151, -1.2743, -2.5914,  ..., -1.1787,  1.2852, -3.0770],\n",
            "        [-3.7407,  3.0190, -4.0473,  ..., -1.6737,  4.6322, -0.8393],\n",
            "        [-1.4087,  2.8384,  0.9311,  ..., -1.2662,  0.9404, -2.0500],\n",
            "        ...,\n",
            "        [-2.3222,  0.5027, -3.0151,  ..., -2.6048,  0.0874, -3.4684],\n",
            "        [-2.0499, -0.4823, -1.8677,  ...,  0.6088, -0.0109, -2.4257],\n",
            "        [-4.2436,  1.1864, -0.7413,  ..., -1.0206,  2.8252, -1.3310]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6713, -0.3621, -4.0567,  ...,  2.8891,  0.3966, -2.4716],\n",
            "        [-1.8053, -2.5223, -0.0225,  ...,  1.8153,  1.0447, -2.8171],\n",
            "        [-2.3705,  0.2677, -1.7821,  ...,  0.8851, -0.0359, -4.0378],\n",
            "        ...,\n",
            "        [-0.6542, -1.1380, -4.1553,  ...,  2.1167,  1.2709, -3.7071],\n",
            "        [-0.6109, -0.6885, -2.5944,  ...,  1.2698,  0.7855, -2.4301],\n",
            "        [ 0.5468, -3.2268, -3.5794,  ...,  0.4161, -1.0667, -4.2044]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6694e+00, -1.9522e+00, -4.5481e+00,  ...,  1.2503e+00,\n",
            "          7.6549e-02, -4.7727e+00],\n",
            "        [-2.8324e+00, -3.1324e+00, -3.2085e+00,  ..., -5.2224e-01,\n",
            "          2.1038e-01, -4.8083e+00],\n",
            "        [-2.8799e+00, -1.4316e+00, -3.3201e+00,  ..., -6.4460e-01,\n",
            "          5.4573e-01, -3.4528e+00],\n",
            "        ...,\n",
            "        [-7.2195e-01,  7.8020e-02, -1.3135e+00,  ..., -8.0631e-01,\n",
            "          1.2853e-01, -1.6120e+00],\n",
            "        [-1.3789e+00,  3.6806e+00,  8.3660e-01,  ..., -2.3237e+00,\n",
            "          9.7157e-01, -3.3015e+00],\n",
            "        [-1.4457e+00,  1.5556e-03, -1.4047e+00,  ..., -1.7881e+00,\n",
            "          3.4512e-01, -1.9744e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0962, -2.7480, -0.8757,  ..., -0.1885, -0.8076, -1.9716],\n",
            "        [-1.2354, -3.1464, -2.8882,  ...,  2.4010,  0.2893, -2.5776],\n",
            "        [-1.7423, -2.9382, -4.6326,  ...,  0.2823,  0.1997, -5.6176],\n",
            "        ...,\n",
            "        [-2.2482, -3.6452, -1.6130,  ..., -0.9644, -0.7972, -3.3619],\n",
            "        [ 0.9879, -1.7686, -2.9969,  ...,  0.9256,  1.2715, -3.1896],\n",
            "        [-0.8385, -1.1401, -3.1970,  ..., -0.4987,  0.6908, -3.9889]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0809,  5.1725, -0.9575,  ..., -2.3411,  3.2474, -3.9366],\n",
            "        [-2.3664,  1.7577, -2.5266,  ..., -2.6333,  3.1885, -4.8037],\n",
            "        [-4.4910,  5.3331, -6.2206,  ..., -0.7131,  3.4517, -1.3134],\n",
            "        ...,\n",
            "        [-1.5981, -0.8978,  1.5965,  ..., -0.8211,  0.2162, -2.9561],\n",
            "        [-3.5298, -0.0260, -2.8322,  ...,  0.4887,  1.3716, -2.6864],\n",
            "        [-3.4426, -3.0082, -3.7504,  ...,  2.2443, -0.9302, -1.4989]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7826,  0.2004, -1.3183,  ..., -2.8799,  0.9377, -3.7180],\n",
            "        [-1.9344,  2.0202, -1.2760,  ..., -1.4782,  1.0352, -3.8080],\n",
            "        [ 1.4542, -3.8793, -3.4742,  ...,  2.4941,  1.2710, -3.0705],\n",
            "        ...,\n",
            "        [ 1.2059, -0.6647, -1.4519,  ..., -0.4717,  1.7628, -3.3990],\n",
            "        [-2.9530, -1.9019, -3.6736,  ..., -0.7707,  2.3738, -5.2756],\n",
            "        [ 0.4643, -0.0262, -2.3481,  ..., -0.7222,  0.4773, -1.6608]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4381,  1.2961, -5.2230,  ..., -0.5397,  0.1504, -3.7672],\n",
            "        [-1.7771,  1.7512, -1.0602,  ..., -1.5999,  0.8355, -1.4220],\n",
            "        [-1.7055, -1.4769, -2.9468,  ..., -0.5899,  0.2764, -4.3927],\n",
            "        ...,\n",
            "        [ 0.3552, -1.2857,  0.5182,  ..., -1.5670,  0.2643, -3.0027],\n",
            "        [-2.5241, -0.5759, -3.7697,  ..., -1.0981,  0.5985, -3.5449],\n",
            "        [-0.9390, -0.5533, -0.8692,  ...,  0.1895,  2.4478, -4.0835]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7554, -2.8766, -2.3496,  ..., -1.3267,  0.6219, -4.1626],\n",
            "        [-2.7098, -2.5929, -4.6593,  ..., -0.4916,  1.4002, -4.1845],\n",
            "        [-2.5083, -3.8823, -5.1425,  ..., -2.0775,  1.2786, -5.2000],\n",
            "        ...,\n",
            "        [-1.1571, -3.2971, -2.9306,  ..., -1.8854,  0.1743, -4.8581],\n",
            "        [-3.2532,  1.0335, -4.6509,  ...,  0.8449,  3.0888, -2.3908],\n",
            "        [-2.1350,  0.8172,  0.0215,  ..., -0.7754,  0.1130, -2.5407]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3644,  4.1129, -2.7787,  ..., -0.8867,  2.8249, -2.6872],\n",
            "        [-5.6899,  3.5419, -2.7765,  ..., -0.5660,  5.4345, -2.6794],\n",
            "        [-2.0434, -0.2088, -0.9948,  ...,  0.8525, -1.5952, -5.0489],\n",
            "        ...,\n",
            "        [-3.3267,  0.1055, -3.6124,  ..., -1.6235,  1.0914, -3.8189],\n",
            "        [-0.6976, -0.7928, -1.6173,  ..., -0.4776,  1.8393, -4.3920],\n",
            "        [-0.5697, -6.0367, -3.3609,  ...,  1.9972,  0.4289, -5.1566]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8551e+00,  7.2076e-01, -3.1287e+00,  ..., -1.3113e+00,\n",
            "          3.6456e+00, -5.3097e+00],\n",
            "        [-1.1420e+00, -9.7428e-01, -1.3897e+00,  ..., -8.2744e-01,\n",
            "          1.7592e+00, -5.0672e+00],\n",
            "        [-3.3565e+00,  5.7521e-01, -4.1277e+00,  ..., -1.3082e+00,\n",
            "          1.9905e+00, -4.1698e+00],\n",
            "        ...,\n",
            "        [-2.2809e+00,  1.6927e-01, -2.0427e+00,  ..., -4.5414e-01,\n",
            "          1.5584e+00, -2.7345e+00],\n",
            "        [ 1.9032e+00, -1.1646e+00, -6.4282e-01,  ...,  3.9403e-03,\n",
            "          1.5829e+00, -2.5472e+00],\n",
            "        [-3.4674e-01, -5.7663e-01, -1.8255e+00,  ...,  4.1231e-01,\n",
            "          1.0527e+00, -3.9049e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2532, -0.7969, -2.7523,  ..., -2.7224, -0.3114, -3.0924],\n",
            "        [-2.8426, -1.6022, -3.3455,  ..., -0.8842,  1.1784, -3.9259],\n",
            "        [ 2.2703, -1.8514,  0.0607,  ...,  0.6523, -2.4264, -3.2999],\n",
            "        ...,\n",
            "        [ 1.7309, -6.3930, -4.9259,  ..., -1.3917, -2.5034, -6.0777],\n",
            "        [-0.7120,  0.5406, -2.1536,  ..., -2.3885,  1.6294, -3.5180],\n",
            "        [ 1.1059, -1.6224, -4.3734,  ...,  2.2590, -0.7988, -3.2137]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5485, -2.2373, -2.1891,  ..., -0.7835, -2.6370, -3.5470],\n",
            "        [ 1.7893, -3.5649, -2.5532,  ...,  1.9072,  0.4536, -1.6549],\n",
            "        [-0.4613, -4.4512, -5.0102,  ...,  3.3770,  1.3419, -3.6791],\n",
            "        ...,\n",
            "        [-2.3097, -1.5133, -3.9914,  ...,  1.5330,  0.7827, -1.9108],\n",
            "        [-4.2277, -3.8981, -6.6083,  ...,  1.1893, -1.6659, -4.6410],\n",
            "        [-1.7681,  2.2344,  2.0759,  ..., -0.1157,  1.1003, -2.3649]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9768,  1.7960, -1.1849,  ..., -2.7902,  0.0951, -2.3414],\n",
            "        [-3.7860, -1.5566, -1.2516,  ..., -1.6887,  1.3208, -2.5356],\n",
            "        [-1.4683, -4.8075, -4.3009,  ...,  1.6366,  0.5282, -4.0798],\n",
            "        ...,\n",
            "        [-3.4700, -1.7313, -1.1058,  ...,  2.5743,  1.1407, -2.3516],\n",
            "        [-1.7105,  0.5544, -0.4455,  ..., -0.5209,  2.6525, -1.5273],\n",
            "        [-0.6750,  1.3443,  0.1569,  ..., -1.6709,  0.5092, -2.5861]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7770, -2.0913, -0.8462,  ...,  0.5737, -0.4873, -2.2495],\n",
            "        [ 2.2527, -5.2920, -2.5260,  ...,  2.1171,  0.6432, -4.2618],\n",
            "        [-3.6506,  0.9882, -1.3551,  ..., -2.2762,  1.5185, -2.6406],\n",
            "        ...,\n",
            "        [-0.5559, -2.2738, -4.3509,  ...,  3.9343,  3.0129, -3.3383],\n",
            "        [-2.5655, -0.0612, -5.1045,  ..., -1.6338,  3.2279, -4.4133],\n",
            "        [-1.3236,  0.6011, -5.7458,  ...,  0.3276,  2.5534, -3.6865]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2962, -0.4474, -3.4878,  ..., -1.8160, -2.9590, -3.4082],\n",
            "        [-3.0437, -1.5148, -3.6296,  ...,  1.0369, -2.4192, -3.9005],\n",
            "        [-2.8079,  2.3385, -2.3587,  ..., -0.6063,  1.9060, -4.5545],\n",
            "        ...,\n",
            "        [ 0.8759, -1.3340, -2.4812,  ..., -0.9296,  0.4068, -4.2581],\n",
            "        [-0.7066,  0.0240, -3.0443,  ..., -1.5280,  2.6089, -3.4185],\n",
            "        [-1.8960, -2.0224, -1.5487,  ..., -0.1450, -0.2538, -1.5822]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7865,  1.4109, -1.3035,  ..., -0.8082,  0.7286, -3.3779],\n",
            "        [-2.3272, -0.6839, -1.4293,  ..., -2.1141, -0.3296, -3.5529],\n",
            "        [-0.5474, -3.2420, -1.7957,  ...,  1.8679,  1.5493, -2.7888],\n",
            "        ...,\n",
            "        [ 0.5336, -4.7036, -5.0616,  ..., -1.1664, -1.4719, -5.9327],\n",
            "        [-1.4622, -3.0718, -4.0715,  ...,  1.2309,  0.2365, -5.0403],\n",
            "        [-1.0697, -1.9856, -3.7704,  ...,  3.3812,  0.9765, -2.9167]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50a2da2f02ef42ae9d8c40dc9e381685"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.0757,  0.6302, -5.1339,  ..., -1.3192,  2.4665, -2.6069],\n",
            "        [-1.8959,  0.1267, -0.8442,  ..., -1.6424, -0.0844, -1.0147],\n",
            "        [-0.4960, -2.7713, -0.8611,  ...,  3.2503,  0.6254, -1.6922],\n",
            "        ...,\n",
            "        [-0.7423, -1.1887, -1.1941,  ...,  0.7888,  0.7293, -1.8350],\n",
            "        [-1.9993, -0.4124, -1.5567,  ..., -1.5093,  2.2741, -2.8586],\n",
            "        [-2.0501, -3.5658, -3.0366,  ..., -1.8859,  1.5893, -3.5209]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6228, -0.9266, -2.1603,  ...,  3.5661, -0.8891, -3.2614],\n",
            "        [-1.6123, -1.5779, -4.4284,  ...,  1.5969, -1.1390, -4.6293],\n",
            "        [-1.9495, -1.5741, -1.5283,  ..., -0.7888, -0.3047, -0.9515],\n",
            "        ...,\n",
            "        [-3.3639, -0.3142, -1.2639,  ...,  1.5378, -1.0147, -1.8226],\n",
            "        [-5.2146, -1.1294, -3.0444,  ...,  0.2433,  3.1051, -1.6535],\n",
            "        [-2.5643, -0.4348, -3.8375,  ...,  0.1471,  1.1012, -2.9527]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3878,  0.6158, -1.8387,  ..., -1.9650,  1.3620, -4.8858],\n",
            "        [-2.2270, -4.4438, -2.1597,  ...,  1.3471, -0.2091, -4.8956],\n",
            "        [ 0.7070, -6.9462, -4.8686,  ...,  0.5710,  0.9707, -5.1950],\n",
            "        ...,\n",
            "        [-2.1274, -2.8506, -3.9355,  ...,  0.6569,  1.8978, -5.3448],\n",
            "        [ 0.0518, -1.6945, -1.7279,  ..., -1.7598,  0.9881, -3.0032],\n",
            "        [-1.8543,  3.1332,  0.1660,  ..., -1.6888,  1.4189, -2.5925]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5566e-01, -3.7137e+00, -3.7456e+00,  ...,  1.5534e+00,\n",
            "          2.2027e-01, -2.9595e+00],\n",
            "        [-9.4215e-01, -3.5062e-01, -1.5867e+00,  ..., -1.3792e+00,\n",
            "          3.0070e+00, -4.7870e+00],\n",
            "        [-1.8959e+00, -4.0835e+00, -5.1280e+00,  ...,  4.6942e+00,\n",
            "         -3.0968e-01, -3.7374e+00],\n",
            "        ...,\n",
            "        [ 1.7936e+00, -2.0945e+00, -3.6874e+00,  ..., -8.0073e-01,\n",
            "          1.3546e+00, -3.7437e+00],\n",
            "        [-1.3486e+00,  3.4925e+00,  1.4077e+00,  ..., -2.0373e+00,\n",
            "          1.4565e+00, -2.6399e+00],\n",
            "        [-2.8516e-03, -9.4415e-01, -2.6288e+00,  ...,  1.3777e+00,\n",
            "         -3.6753e-01, -1.5566e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9062,  0.2896, -2.7388,  ...,  0.8618,  0.7971, -2.2649],\n",
            "        [-1.7739, -1.1083, -1.3836,  ..., -0.0900,  0.3661, -3.3889],\n",
            "        [-1.8563,  2.6011, -4.2462,  ..., -1.9569, -0.6456, -1.7714],\n",
            "        ...,\n",
            "        [-3.0425, -2.3035, -4.4242,  ..., -1.4512,  2.2914, -4.6007],\n",
            "        [-1.4274, -4.5781, -1.7465,  ..., -0.8166,  1.9092, -5.9331],\n",
            "        [-4.9141,  0.6914, -1.9641,  ..., -0.1786,  2.6793, -4.4154]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8748, -0.8603, -2.4004,  ..., -1.6968,  1.5290, -4.9100],\n",
            "        [-0.6168, -0.4457, -4.7895,  ...,  0.0825,  2.3087, -2.2731],\n",
            "        [-1.0678, -1.2546, -7.3255,  ...,  1.7207, -0.8928, -3.9265],\n",
            "        ...,\n",
            "        [-2.0261, -0.0230,  1.0212,  ...,  0.8864,  0.3194, -1.4629],\n",
            "        [-0.4338, -1.1480,  0.4307,  ...,  1.0984,  0.0773, -0.9910],\n",
            "        [-4.6348,  0.5132, -2.6391,  ..., -1.1550,  0.8092, -3.6873]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1772,  1.2156, -0.4631,  ..., -2.1805,  0.0288, -2.5926],\n",
            "        [-2.8959,  2.7684, -2.9423,  ..., -0.3074,  2.3725, -2.7229],\n",
            "        [-0.6522, -1.6451, -2.0230,  ..., -1.3387,  0.9282, -4.1423],\n",
            "        ...,\n",
            "        [-1.7668,  2.3780,  0.3895,  ..., -1.6764,  1.4323, -2.7119],\n",
            "        [-2.6906, -0.4684, -3.4799,  ..., -0.7567,  2.0714, -4.9561],\n",
            "        [-3.4256, -0.3128,  0.7086,  ..., -1.2983,  1.3052, -1.8921]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0880, -0.7206, -3.5018,  ...,  0.7113,  1.1365, -2.7332],\n",
            "        [-2.2563,  1.0095, -0.5691,  ...,  0.4838,  2.3604, -1.2320],\n",
            "        [-4.2104,  1.7233, -3.3714,  ..., -1.4213,  2.7271, -4.8773],\n",
            "        ...,\n",
            "        [-2.4759,  0.7390, -3.0456,  ..., -1.6690,  1.6165, -2.9664],\n",
            "        [-2.0541,  0.5450, -2.2083,  ..., -0.2186,  0.1707, -3.5051],\n",
            "        [-3.1224,  5.1022, -2.5355,  ..., -2.9983,  3.6519, -1.8811]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2961, -0.5134, -4.0318,  ...,  2.2102,  0.7777, -4.8742],\n",
            "        [-0.0719, -3.4375, -2.7036,  ...,  1.5606,  1.6019, -4.1761],\n",
            "        [-2.7518,  0.0841, -3.4799,  ...,  1.1833,  2.5096, -3.4427],\n",
            "        ...,\n",
            "        [-2.6968, -3.5104,  0.7422,  ..., -0.3604, -0.1565, -2.7579],\n",
            "        [-3.9221,  1.9513, -2.9247,  ...,  0.7075,  0.9169, -3.7835],\n",
            "        [-2.7782,  0.3921, -1.2278,  ..., -0.9900,  1.6088, -2.6540]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3465, -3.7443, -2.1231,  ...,  0.0544,  0.4728, -4.4524],\n",
            "        [ 0.0857, -0.6424, -3.4544,  ...,  0.2086,  0.2559, -2.8443],\n",
            "        [-0.9453,  0.7445, -0.2976,  ...,  2.1131,  1.7583, -2.0706],\n",
            "        ...,\n",
            "        [-1.6331, -3.2900, -2.9482,  ...,  1.5086,  1.4350, -2.2044],\n",
            "        [-1.3425,  2.4892, -0.4859,  ..., -1.2564,  0.6299, -1.6781],\n",
            "        [ 1.0364, -3.2483, -3.0030,  ...,  3.0409,  0.5557, -1.1522]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3781, -0.6082,  0.6721,  ...,  0.5359, -0.7583, -2.3089],\n",
            "        [-3.3289, -0.1448, -1.6889,  ..., -0.3492,  0.4960, -4.1584],\n",
            "        [-0.3739,  3.3003,  1.9890,  ...,  0.4671,  0.6015, -2.2017],\n",
            "        ...,\n",
            "        [-1.2245,  2.5430,  2.6427,  ..., -0.5373,  0.7375, -2.1382],\n",
            "        [ 2.6289, -3.4882, -2.5018,  ...,  2.1031,  1.0110, -1.7729],\n",
            "        [-2.4771, -0.9677, -2.0995,  ..., -0.7726,  1.2868, -1.6407]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5895, -1.3727, -3.5971,  ..., -1.1636, -0.0961, -3.4261],\n",
            "        [ 0.9575, -1.6657, -2.0393,  ...,  2.9767,  0.2914, -2.7986],\n",
            "        [-3.1407, -2.7033, -2.7931,  ..., -0.1804,  0.5389, -4.6716],\n",
            "        ...,\n",
            "        [-2.0080, -1.9458, -0.5211,  ...,  0.3486, -0.3971, -3.1163],\n",
            "        [ 0.6632, -3.9034, -6.2479,  ...,  1.6896, -0.8559, -6.2442],\n",
            "        [-3.5229,  1.3363, -2.2852,  ...,  0.1029,  2.8833, -5.9611]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.1129,  1.3269, -1.6410,  ..., -1.4686,  0.8022, -3.2339],\n",
            "        [-3.7414,  3.6083, -3.0676,  ..., -0.2917,  3.8146, -3.7597],\n",
            "        [-2.2321,  0.2223, -2.7973,  ...,  0.6068,  0.0208, -0.6365],\n",
            "        ...,\n",
            "        [-0.9014,  0.1346, -0.0357,  ...,  2.2892,  2.6986, -1.2116],\n",
            "        [-3.4728, -0.1324, -4.2064,  ...,  2.0499,  0.0604, -2.3128],\n",
            "        [ 1.0167, -3.5841, -1.0494,  ...,  1.3062,  0.0711, -5.5529]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5382,  1.2599, -1.4343,  ...,  0.8579, -1.8337, -2.4972],\n",
            "        [-3.2051,  4.1342, -3.2328,  ...,  0.5386,  5.1914, -2.3865],\n",
            "        [-2.1801, -4.1910, -2.6761,  ...,  1.6330,  0.4511, -4.6013],\n",
            "        ...,\n",
            "        [-3.1694, -0.8656, -4.0337,  ..., -2.1562,  0.2535, -3.1462],\n",
            "        [-1.6734, -2.3354, -2.5307,  ...,  1.0349,  0.5201, -2.3311],\n",
            "        [-1.6899,  4.2911,  0.6534,  ..., -1.2909,  1.5342, -3.1759]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3843, -4.4188, -0.7778,  ...,  0.3369,  1.2338, -4.4549],\n",
            "        [-4.6498,  2.9842, -2.4781,  ...,  0.1118,  2.3780, -2.0060],\n",
            "        [ 1.4365, -3.3895, -0.1128,  ...,  0.6887, -1.5897, -3.3585],\n",
            "        ...,\n",
            "        [-3.0505,  2.6885, -5.2944,  ..., -1.9926, -0.3588, -2.3880],\n",
            "        [-0.3235, -2.1818, -0.5022,  ...,  1.2758,  0.1776, -2.0956],\n",
            "        [-0.5915,  3.0600,  2.1241,  ..., -0.4136, -0.2161, -3.2287]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6359,  3.5707,  1.6173,  ..., -0.3477, -0.7921, -1.6772],\n",
            "        [ 0.1748, -2.4098, -2.6772,  ...,  3.2650,  1.2520, -3.5699],\n",
            "        [-3.4218, -1.9522, -2.1305,  ...,  2.4506,  0.8162, -1.3183],\n",
            "        ...,\n",
            "        [-0.5709, -1.3667,  0.5815,  ...,  2.2287, -0.2154,  0.0870],\n",
            "        [-2.4972,  1.4133,  1.3139,  ..., -3.6681, -0.5775, -2.0640],\n",
            "        [-1.2221, -0.0933, -1.1232,  ...,  0.9084, -1.1785, -4.4296]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0582,  2.1686, -0.5008,  ..., -1.3591, -0.1258, -1.4590],\n",
            "        [-2.6423, -2.4118, -2.5115,  ...,  3.0285,  0.2761, -3.3387],\n",
            "        [-1.8780,  0.5498, -3.6782,  ...,  0.8456,  0.3665, -1.8100],\n",
            "        ...,\n",
            "        [-2.2163, -2.6734, -1.1265,  ...,  4.0416,  1.5223, -4.0618],\n",
            "        [-0.8920, -0.4998, -0.0890,  ..., -0.7244,  0.8584, -3.6300],\n",
            "        [-5.2315,  0.4426, -0.6648,  ...,  1.5082,  0.6647, -1.5182]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9449, -2.4320, -3.3442,  ...,  2.1774, -0.1172, -1.9233],\n",
            "        [-0.3553, -3.1132, -4.3814,  ...,  1.1650, -3.3838, -5.4775],\n",
            "        [ 0.1121, -3.7992, -2.9536,  ...,  1.2766,  0.3641, -2.3922],\n",
            "        ...,\n",
            "        [ 0.2403, -4.0872, -5.0961,  ...,  1.9102, -0.1426, -5.8890],\n",
            "        [ 1.6090, -1.1933, -4.8463,  ...,  1.3911,  2.1135, -5.4668],\n",
            "        [-0.2806, -1.5521, -1.8529,  ...,  1.0364, -0.7890, -2.4582]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1643,  3.1728, -1.2446,  ..., -2.6125,  1.6891, -2.6324],\n",
            "        [-2.4859,  0.2497, -2.5724,  ..., -2.1871,  0.5508, -4.8833],\n",
            "        [-0.7920, -1.3295, -2.5850,  ..., -2.4798,  2.1883, -5.0254],\n",
            "        ...,\n",
            "        [-0.8835, -1.5911, -0.9295,  ...,  3.3098,  0.5116, -2.6203],\n",
            "        [-1.4886,  0.5462, -1.5515,  ..., -2.6115,  0.9183, -2.2205],\n",
            "        [-2.0010,  1.2455, -0.3824,  ..., -0.5936,  0.2289, -0.9133]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0164, -6.4461, -4.0614,  ...,  2.6366,  0.7407, -4.2012],\n",
            "        [-0.2836,  3.6755,  2.2135,  ..., -1.1034,  0.4619, -3.2945],\n",
            "        [-0.6620,  0.3932, -3.6831,  ...,  1.2993,  0.2906, -1.2733],\n",
            "        ...,\n",
            "        [-1.8541,  1.3950, -3.0296,  ...,  0.8326,  1.5783, -2.0283],\n",
            "        [-3.4659,  0.0253, -2.4192,  ..., -1.4693, -1.1022, -2.8637],\n",
            "        [-4.4639,  0.2549, -2.8334,  ..., -0.7564,  1.6852, -2.6814]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3415,  2.5410, -0.2378,  ..., -1.7841,  1.0004, -2.6814],\n",
            "        [-3.9504, -0.3459, -1.7735,  ...,  1.6323,  1.1322, -1.9449],\n",
            "        [-1.9248,  0.3053, -0.9535,  ...,  0.3655,  1.3699, -3.4538],\n",
            "        ...,\n",
            "        [-4.2266,  0.4474, -1.9301,  ..., -0.5932,  0.9686, -4.2810],\n",
            "        [-4.5332,  4.0229, -2.1358,  ...,  0.2783,  2.1650, -2.8042],\n",
            "        [-1.1167, -0.2358, -1.5706,  ..., -1.8429, -0.4515, -2.5940]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9078,  0.0950,  0.7239,  ...,  1.9771, -0.3423, -2.6739],\n",
            "        [-3.1323, -1.5868, -3.8878,  ..., -0.2272,  2.2068, -4.1672],\n",
            "        [-5.7186,  1.3128, -4.1821,  ...,  0.1652,  3.5453, -3.9158],\n",
            "        ...,\n",
            "        [-3.1894,  1.6272, -1.8870,  ...,  0.7525,  0.4606, -3.5604],\n",
            "        [-1.7806,  1.2610, -1.0750,  ..., -1.0836,  1.4233, -2.1183],\n",
            "        [ 0.3280,  0.7709, -0.3339,  ..., -0.4822,  1.1631, -2.2078]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8976, -1.5460, -4.3689,  ..., -0.7133, -0.1770, -3.2287],\n",
            "        [-2.7363, -0.3818, -6.0401,  ..., -0.0210, -0.0080, -3.6021],\n",
            "        [-0.8623, -0.1623, -1.1580,  ..., -0.3211,  0.6074, -3.3488],\n",
            "        ...,\n",
            "        [-4.0300, -0.1513, -1.7483,  ..., -1.2819, -0.1549, -3.1695],\n",
            "        [-0.0526, -4.7946, -5.7208,  ...,  0.5463,  0.5634, -3.3855],\n",
            "        [-1.5679, -2.9007, -1.6024,  ..., -0.5931,  0.6209, -2.9049]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7529,  0.4220,  0.1785,  ..., -1.1791,  0.9410, -3.9049],\n",
            "        [ 1.8632, -1.4816, -2.2928,  ..., -0.5132,  0.6494, -2.4037],\n",
            "        [-3.7745,  5.5874, -1.1881,  ..., -0.9595,  3.0985, -2.8322],\n",
            "        ...,\n",
            "        [-1.5456,  0.4516, -2.8813,  ..., -1.7963, -1.1394, -5.0001],\n",
            "        [-2.0784,  0.8527, -3.9147,  ...,  0.0154, -0.3607, -3.7060],\n",
            "        [-3.7099,  1.2123, -1.7303,  ...,  0.0475,  0.8875, -4.2035]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9355, -1.5004, -2.1776,  ..., -1.4302, -1.2040, -2.2560],\n",
            "        [-0.7076, -0.1174, -3.1592,  ...,  3.3668,  0.3703, -1.3088],\n",
            "        [-0.3858, -2.7285, -2.1625,  ..., -0.7997,  1.5618, -4.5594],\n",
            "        ...,\n",
            "        [-2.6220, -1.3413, -3.9612,  ..., -1.6006,  0.0279, -5.1123],\n",
            "        [-3.3888, -1.4093, -1.1252,  ..., -1.2946,  1.0798, -3.2983],\n",
            "        [ 0.3791, -0.8466, -0.4473,  ..., -0.4571,  2.6475, -1.1009]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5250, -0.0243, -0.6477,  ...,  1.4298,  0.9571, -2.5816],\n",
            "        [-0.0758, -5.1208, -4.1711,  ...,  0.9404, -2.9585, -5.9249],\n",
            "        [-1.4096, -3.1466, -2.0968,  ...,  0.2258, -0.5485, -3.1853],\n",
            "        ...,\n",
            "        [ 1.8918, -4.7176, -2.5860,  ..., -1.4469,  1.7588, -5.4669],\n",
            "        [-2.5610, -0.4470, -4.0811,  ...,  1.2622, -0.7099, -1.9306],\n",
            "        [-2.1474,  2.1961,  0.1597,  ..., -1.3444,  0.9659, -2.5642]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9812,  0.6330, -1.7968,  ..., -2.7938,  0.1528, -2.7529],\n",
            "        [-1.0114, -2.3519, -1.2896,  ...,  0.9973,  1.9013, -3.8462],\n",
            "        [-0.8915,  3.2766,  2.0765,  ..., -0.4479,  1.6739, -2.4976],\n",
            "        ...,\n",
            "        [-1.2907,  0.2872, -1.3871,  ..., -1.2203,  0.6259, -1.2262],\n",
            "        [-1.2158, -2.2466, -2.5883,  ..., -0.4542,  1.2300, -2.6842],\n",
            "        [ 0.7530, -5.2455, -2.4295,  ..., -0.3358, -2.8225, -5.0740]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9824, -4.6108, -2.0176,  ..., -0.3469,  0.7292, -4.7510],\n",
            "        [-3.1290,  2.5858, -2.3291,  ...,  0.1427,  2.8692, -0.9061],\n",
            "        [-1.9074, -2.1094, -1.3477,  ..., -1.1423, -1.6478, -2.1109],\n",
            "        ...,\n",
            "        [-0.4274, -1.6500,  0.8416,  ...,  2.3785, -0.1469, -0.3321],\n",
            "        [ 1.5068, -4.9406, -2.7769,  ..., -2.2252, -1.0751, -6.5287],\n",
            "        [-1.7230, -2.5396, -0.1168,  ..., -1.2682,  1.1481, -4.6835]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1634,  0.4098, -1.3481,  ...,  0.4295,  1.4357, -3.7115],\n",
            "        [-1.6542, -0.1792,  0.8950,  ...,  1.0599, -0.2415, -0.3894],\n",
            "        [-3.2185,  0.8177, -1.3670,  ..., -1.6896, -0.4333, -2.3977],\n",
            "        ...,\n",
            "        [-2.3781, -1.5722, -3.1688,  ..., -2.1739, -0.8204, -3.8185],\n",
            "        [-1.5188,  3.6882,  1.8646,  ..., -1.0085,  1.1066, -2.1911],\n",
            "        [-3.6510,  0.0956, -1.1556,  ..., -0.3804,  1.4336, -2.1050]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2134,  2.0351,  0.0976,  ..., -2.5139,  0.0521, -2.8870],\n",
            "        [-2.4574, -1.6263, -1.7357,  ..., -2.3249, -3.3946, -2.9569],\n",
            "        [-3.6212,  1.1768, -2.7109,  ..., -2.0610,  0.6508, -4.2269],\n",
            "        ...,\n",
            "        [-4.2984,  3.9892, -0.5258,  ...,  0.5517,  2.0272, -1.1077],\n",
            "        [-1.2184,  3.2725,  2.6615,  ..., -1.0413, -0.0705, -2.6844],\n",
            "        [-4.7131, -1.3348, -1.6765,  ...,  1.9601, -0.0176, -2.9389]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6094e+00,  9.1907e-01, -1.3320e+00,  ..., -2.6618e-01,\n",
            "         -2.9037e-01,  3.1922e-03],\n",
            "        [-2.0201e+00, -1.8519e+00, -5.6807e+00,  ...,  4.6672e-01,\n",
            "          3.5679e+00, -5.6950e+00],\n",
            "        [-1.4037e+00,  5.4038e-01, -3.4361e+00,  ...,  9.3565e-01,\n",
            "         -5.0486e-01, -2.2464e+00],\n",
            "        ...,\n",
            "        [-3.0229e-01,  3.5053e+00,  2.7544e+00,  ..., -6.5509e-01,\n",
            "          2.4116e-01, -2.5280e+00],\n",
            "        [-1.4127e-01,  9.1795e-01, -2.9064e+00,  ...,  3.8154e-01,\n",
            "          1.0547e+00, -1.6773e+00],\n",
            "        [ 7.7501e-01, -2.4193e+00, -2.9978e+00,  ..., -1.0974e+00,\n",
            "          4.7294e-01, -2.3570e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4928, -2.6826, -2.5859,  ..., -0.3499,  1.2241, -5.6068],\n",
            "        [-1.5267, -1.7513, -0.0075,  ..., -0.2209, -0.6774, -1.6356],\n",
            "        [ 3.8057, -7.4590, -0.5203,  ...,  1.5277,  0.2530, -5.5473],\n",
            "        ...,\n",
            "        [-0.6216, -1.4201, -3.0585,  ..., -1.2724,  0.1767, -4.0130],\n",
            "        [-3.3193, -2.8027, -1.6196,  ...,  1.1554,  0.3869, -4.6987],\n",
            "        [ 0.5037, -1.1184, -3.2680,  ...,  0.4398, -0.7324, -2.8580]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6286,  0.0099,  0.4609,  ...,  0.4210,  2.5256, -4.1036],\n",
            "        [-4.9814,  4.3441, -3.7376,  ..., -0.1803,  1.0866, -0.9824],\n",
            "        [-3.1740,  0.1380, -3.8090,  ...,  0.6958,  1.9266, -5.2058],\n",
            "        ...,\n",
            "        [-0.3143,  0.2384, -4.0037,  ...,  1.1338,  1.5993, -1.8402],\n",
            "        [ 0.6972, -1.0707, -2.3229,  ..., -2.3367, -1.0770, -3.5611],\n",
            "        [-0.3383, -0.3688, -2.6371,  ...,  1.5535, -1.6202, -3.3149]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8418, -1.1445, -3.5925,  ...,  1.8762,  0.2729, -2.4796],\n",
            "        [-2.4293, -1.3769, -4.6386,  ...,  3.2343,  1.5975, -4.7274],\n",
            "        [-1.3372,  1.2479,  3.1648,  ...,  0.3622, -0.3737, -1.9760],\n",
            "        ...,\n",
            "        [-3.2949,  0.3744, -3.8480,  ...,  0.2140,  2.3885, -2.8540],\n",
            "        [-1.3724, -2.3989, -1.9571,  ..., -1.2370,  2.0013, -1.5906],\n",
            "        [ 1.8356, -1.9741, -0.4328,  ...,  3.8661, -0.3047, -2.4975]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4993, -2.6646, -2.9408,  ...,  1.7288,  0.7964, -2.2806],\n",
            "        [-1.5534, -2.1859, -2.0067,  ..., -0.2092,  1.7644, -2.4662],\n",
            "        [-0.3801, -3.5710, -5.0632,  ...,  0.8424,  1.7999, -5.2223],\n",
            "        ...,\n",
            "        [-1.5192,  0.5678,  1.9729,  ..., -0.7848,  0.0654, -1.2781],\n",
            "        [-1.1138,  5.0704,  3.2409,  ...,  0.0990, -0.3015, -2.2778],\n",
            "        [-0.4906, -0.8122,  1.6939,  ...,  1.7980, -0.6269, -0.8673]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1633, -4.1971, -4.3575,  ...,  2.9610,  0.8021, -2.3145],\n",
            "        [-1.0219, -3.9081, -3.3019,  ...,  2.9130, -1.4476, -3.0549],\n",
            "        [-2.1206,  1.2123,  0.0112,  ..., -0.9768,  1.3112, -1.6973],\n",
            "        ...,\n",
            "        [-0.8264,  1.0015, -1.2884,  ..., -1.4142, -0.1004, -3.3737],\n",
            "        [-2.5123, -0.4271, -4.6353,  ..., -2.1038,  0.0293, -4.6353],\n",
            "        [ 0.0547, -2.8076, -3.6726,  ...,  1.0235, -1.0317, -4.4520]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7187e+00,  9.7490e-01,  2.3224e+00,  ..., -1.4309e+00,\n",
            "          2.8920e-02, -2.3663e+00],\n",
            "        [ 9.0897e-01, -4.5956e+00, -4.0408e+00,  ...,  1.9366e+00,\n",
            "         -8.7470e-01, -3.6393e+00],\n",
            "        [ 4.0806e+00, -5.8205e+00, -5.6187e+00,  ...,  1.1046e+00,\n",
            "          1.4470e+00, -4.0976e+00],\n",
            "        ...,\n",
            "        [-1.8630e+00,  2.4631e+00, -8.6498e-01,  ..., -2.4928e+00,\n",
            "          9.5934e-02, -1.4273e+00],\n",
            "        [-1.4248e+00,  1.2385e+00,  1.5297e+00,  ...,  6.2805e-04,\n",
            "         -5.8265e-01, -3.3160e+00],\n",
            "        [ 1.1012e+00, -1.7017e+00, -1.4438e+00,  ..., -1.7110e-02,\n",
            "          9.8479e-01, -1.7969e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4999, -1.3499, -0.1823,  ...,  1.0088, -0.5336, -3.0962],\n",
            "        [ 1.8551, -2.0623, -3.0355,  ...,  2.9930, -1.0930, -2.7486],\n",
            "        [-1.1077, -0.6126, -2.4092,  ...,  2.0863,  0.1426, -1.8240],\n",
            "        ...,\n",
            "        [-1.5824, -5.0541, -1.0173,  ...,  1.0016,  0.8591, -3.6174],\n",
            "        [-0.8182, -3.8196, -3.8448,  ...,  5.4461,  2.2299, -3.9435],\n",
            "        [-1.4187, -0.7080, -2.1140,  ...,  1.3866, -0.3070, -2.5367]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0758,  0.0659, -3.3976,  ...,  2.6823,  1.7257, -0.9486],\n",
            "        [-1.6963, -0.4580, -5.4532,  ...,  0.5932, -2.3658, -3.8770],\n",
            "        [-2.3321,  1.0505, -4.3500,  ..., -1.7049,  1.0899, -1.9893],\n",
            "        ...,\n",
            "        [-3.1817,  1.5518, -1.7382,  ..., -0.8724,  1.1784, -5.8475],\n",
            "        [-1.5214,  0.6540, -4.4983,  ...,  2.1357,  3.5336, -1.2784],\n",
            "        [-0.2883, -1.4253,  2.1158,  ...,  2.6477,  1.4960, -1.0708]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7355e+00,  2.0754e-01, -2.6256e+00,  ..., -3.7519e-01,\n",
            "          9.7771e-01, -3.8303e+00],\n",
            "        [-3.2411e+00,  2.0757e+00, -8.8043e-01,  ...,  3.3192e-02,\n",
            "          9.1530e-01, -1.8392e+00],\n",
            "        [-2.0326e-01, -5.3896e-01, -3.8800e+00,  ...,  2.3804e+00,\n",
            "         -4.6651e-03, -3.3192e+00],\n",
            "        ...,\n",
            "        [ 3.7601e+00, -8.1522e+00, -5.9167e+00,  ...,  4.2714e+00,\n",
            "          1.9618e+00, -3.5771e+00],\n",
            "        [ 4.8463e-01, -9.1160e-01, -1.6017e+00,  ...,  3.6612e-01,\n",
            "          1.1040e+00, -1.0477e+00],\n",
            "        [-1.9356e+00, -2.3223e+00, -8.6608e-01,  ...,  8.1976e-01,\n",
            "          5.3089e-01, -3.4236e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7438,  3.4237,  3.5873,  ..., -1.8756,  0.6147, -2.1680],\n",
            "        [-3.1072, -0.0883, -0.0829,  ..., -1.1169,  1.6911, -2.0212],\n",
            "        [-3.4044,  0.8074, -1.7978,  ..., -0.0644,  2.7229, -2.4187],\n",
            "        ...,\n",
            "        [-4.0043,  0.2893, -4.7925,  ...,  2.8940,  0.2653, -5.8471],\n",
            "        [-0.4517, -1.7173, -3.4300,  ...,  4.5729,  2.2475, -2.1664],\n",
            "        [-4.4476, -0.3117, -4.5052,  ...,  0.0664,  0.7748, -4.1201]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6818, -0.4518, -7.0713,  ...,  3.0750, -0.1941, -4.1502],\n",
            "        [ 0.5287, -4.2062, -3.3692,  ...,  2.3915,  1.2914, -4.9507],\n",
            "        [-2.0983, -1.4129, -2.5183,  ..., -0.1035, -1.2775, -3.7952],\n",
            "        ...,\n",
            "        [ 2.1733, -5.4503, -2.6756,  ...,  0.6949,  1.7088, -6.5870],\n",
            "        [ 0.8744, -1.6762, -2.1936,  ...,  0.5405,  1.8605, -4.5876],\n",
            "        [-0.0087, -0.4575, -4.5388,  ...,  1.9431,  0.5457, -2.0980]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3562,  0.2881, -3.5061,  ..., -1.2811, -0.1375, -2.9464],\n",
            "        [-0.5514, -1.0168, -0.1392,  ...,  5.4203,  1.8760, -1.9980],\n",
            "        [-5.0470,  6.1376, -0.8726,  ..., -2.2797,  3.1791, -2.4823],\n",
            "        ...,\n",
            "        [-2.7848,  2.9896,  1.0984,  ..., -1.1036,  0.2204, -0.4426],\n",
            "        [ 2.3016,  1.7181, -1.1941,  ...,  2.9536,  0.8073, -0.9834],\n",
            "        [-0.5860,  0.9788, -1.0871,  ..., -1.3553,  1.5961, -2.6912]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9339e+00,  1.8524e+00, -3.6726e+00,  ...,  4.6728e+00,\n",
            "          2.5791e+00, -4.0557e+00],\n",
            "        [-9.0290e-01, -2.7690e+00,  6.8813e-01,  ..., -7.7708e-01,\n",
            "         -3.5886e-02, -2.5800e+00],\n",
            "        [-2.3649e+00,  1.3256e+00,  1.3391e+00,  ..., -3.0537e-01,\n",
            "         -1.0002e+00, -7.0306e-01],\n",
            "        ...,\n",
            "        [ 1.3617e+00, -4.3392e+00, -2.9489e+00,  ...,  5.8778e+00,\n",
            "         -5.1514e-01, -3.9040e+00],\n",
            "        [-4.7009e+00,  2.2288e-03, -2.0744e+00,  ...,  5.2330e-01,\n",
            "         -3.9919e-01, -1.0300e+00],\n",
            "        [-1.8061e+00, -2.2784e-01, -2.9427e+00,  ...,  5.1122e-01,\n",
            "         -8.6798e-01, -9.6261e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3800,  0.2943, -1.9430,  ...,  0.8125, -0.4803, -2.2901],\n",
            "        [-1.6113,  0.1806,  2.8720,  ...,  0.8941, -0.7624, -0.0763],\n",
            "        [ 0.5060, -1.9420, -4.4278,  ...,  2.8066, -1.0781, -1.5271],\n",
            "        ...,\n",
            "        [-1.8118,  0.4995, -0.9704,  ..., -1.7501, -0.2797, -1.7930],\n",
            "        [-0.9891, -2.2957, -0.8212,  ..., -0.1254,  0.1651, -2.6907],\n",
            "        [-0.3118,  0.5698,  2.9532,  ...,  0.1169,  0.8896, -1.5943]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7011, -0.8154, -3.6308,  ..., -1.5995,  0.2099, -2.7186],\n",
            "        [ 2.8105, -4.1142, -3.8777,  ...,  2.5485,  0.0411, -3.6236],\n",
            "        [-5.0380, -0.0890, -1.6573,  ...,  0.0771,  1.3547, -2.0494],\n",
            "        ...,\n",
            "        [-1.7775, -0.9210, -4.2198,  ...,  1.4389,  0.7652, -1.8497],\n",
            "        [-0.9203, -2.4089, -0.6979,  ..., -0.4589, -1.1028, -3.1361],\n",
            "        [-0.2987,  1.0295, -0.0871,  ..., -0.4886,  0.1397, -2.3140]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4586,  3.4009,  2.1080,  ..., -0.8896,  1.1207, -2.6310],\n",
            "        [-1.7273, -3.5827, -3.8383,  ...,  2.4133,  1.9535, -3.1159],\n",
            "        [ 0.5548, -0.4853, -3.4974,  ...,  2.1255, -1.5869, -3.2802],\n",
            "        ...,\n",
            "        [-2.1032, -2.2493, -0.1744,  ..., -0.6745,  0.4625, -4.3895],\n",
            "        [-1.6004,  1.1535, -2.3636,  ...,  0.3410,  1.2715, -2.3062],\n",
            "        [-3.3097,  2.2424, -2.0649,  ...,  2.0903,  1.5122, -2.6872]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4764, -0.2643, -1.4020,  ..., -0.9825,  0.7906, -2.9103],\n",
            "        [ 1.5161, -3.1840, -6.1618,  ...,  0.9263, -0.2702, -2.7642],\n",
            "        [ 0.2728,  1.2565, -2.9692,  ...,  1.0968,  2.5212, -0.6397],\n",
            "        ...,\n",
            "        [-2.1946,  0.3205,  0.2653,  ..., -1.4880,  0.8246, -2.1830],\n",
            "        [ 2.2954, -2.1440, -2.4812,  ...,  3.3838, -0.2429, -1.0389],\n",
            "        [-0.7349, -2.4635, -2.4938,  ...,  0.7756,  0.2784, -2.9328]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7697,  0.1619,  0.1733,  ...,  1.7411,  2.4792, -2.6553],\n",
            "        [ 1.8499, -4.8646, -4.6680,  ...,  1.7165, -1.2349, -4.3127],\n",
            "        [-1.5761,  4.1388,  2.8964,  ...,  0.1887, -0.6263, -1.3989],\n",
            "        ...,\n",
            "        [-2.3252,  1.6927, -4.1843,  ...,  4.2783,  1.2346, -1.6850],\n",
            "        [-3.0687,  1.1810, -1.0879,  ...,  1.2107,  0.5009, -2.7405],\n",
            "        [-1.5847, -0.8617, -1.5552,  ...,  7.8819,  0.9264, -1.9508]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2967,  1.9494, -2.8848,  ...,  0.1127, -0.6710, -1.5288],\n",
            "        [-3.7993,  0.4047, -0.5080,  ...,  0.9490,  1.8467, -1.9755],\n",
            "        [-2.3200,  0.7126, -1.5846,  ...,  0.5014,  0.3499, -1.5985],\n",
            "        ...,\n",
            "        [-1.4608, -1.5125, -1.5576,  ...,  0.3026, -1.0867, -4.3382],\n",
            "        [ 1.5075,  1.0809, -1.5509,  ..., -0.6917, -0.4362, -1.9045],\n",
            "        [-0.4984, -2.1232, -1.0170,  ...,  1.4531, -0.9058, -0.6530]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1257,  0.4247, -0.1592,  ...,  0.2310,  2.2472, -2.2510],\n",
            "        [ 0.3620, -3.0135, -1.8939,  ...,  3.3689,  1.0227, -2.6870],\n",
            "        [-1.6587, -1.1073,  0.6972,  ...,  1.7035,  0.2623, -1.5816],\n",
            "        ...,\n",
            "        [-3.4324, -0.1872, -0.8469,  ...,  0.2909,  1.1614, -1.4557],\n",
            "        [ 0.3421, -0.3788, -0.1448,  ...,  4.2242, -2.3169, -2.2093],\n",
            "        [-2.9608,  4.9380, -0.9352,  ...,  0.1592,  1.7611, -0.3958]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5954, -3.2614, -1.9944,  ...,  0.6008,  2.4096, -1.7770],\n",
            "        [-2.0689, -0.5285, -2.2149,  ...,  0.5521, -0.5603, -1.5361],\n",
            "        [-2.1995,  1.3388, -2.5068,  ..., -0.6242,  2.9112, -1.8969],\n",
            "        ...,\n",
            "        [-0.0821, -1.2208, -2.8321,  ...,  3.2535, -0.3228, -3.6529],\n",
            "        [-3.8807,  5.1447, -0.9412,  ..., -0.8977,  3.5535, -2.1761],\n",
            "        [-0.5769, -0.3113, -3.5770,  ..., -0.9555, -0.3463, -2.2733]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5889, -3.5936, -5.6083,  ...,  8.2112,  3.1036, -1.9937],\n",
            "        [-1.7669,  1.0902,  0.8026,  ...,  0.7802,  0.5178, -1.9606],\n",
            "        [-1.5778,  3.8026,  4.5827,  ..., -0.8929,  0.1825, -2.2113],\n",
            "        ...,\n",
            "        [-0.6079, -3.0049, -0.9945,  ...,  4.4186,  0.1360, -3.4652],\n",
            "        [-0.1113, -4.0768,  0.3904,  ...,  1.3260,  1.1609, -2.0839],\n",
            "        [-1.4530,  0.2111,  1.8055,  ...,  1.4950, -1.6272, -1.2541]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0902, -3.5746, -1.6683,  ...,  2.6423,  1.5023, -2.7999],\n",
            "        [-2.5522,  3.5663,  0.4833,  ..., -0.5218,  4.8606, -2.9437],\n",
            "        [-0.7055, -1.1974, -3.9639,  ...,  3.4587, -2.4752, -4.2363],\n",
            "        ...,\n",
            "        [-1.5438,  1.3066,  2.7214,  ...,  2.7383, -2.0057, -3.4565],\n",
            "        [-3.0876, -4.6753, -2.3592,  ...,  2.4070, -0.5147, -4.2294],\n",
            "        [-0.3835, -1.6245,  0.7914,  ..., -0.7624, -0.5895, -3.3882]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.0234,  5.2592,  0.4204,  ...,  1.3117,  2.0115, -1.4599],\n",
            "        [-2.8843,  0.2210,  2.0156,  ...,  0.2321, -0.1560, -0.6192],\n",
            "        [-1.9732,  0.4182,  0.4461,  ...,  1.0624, -1.1063, -1.1064],\n",
            "        ...,\n",
            "        [-2.2519,  1.6862,  3.9958,  ...,  2.4524,  0.7673, -1.6512],\n",
            "        [-1.4937,  1.0661, -2.2688,  ...,  3.5483,  0.6868, -1.3459],\n",
            "        [ 2.1775, -1.4732,  0.3012,  ...,  4.0350, -1.3829, -3.0055]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7872,  2.4744,  4.3422,  ...,  0.0797,  0.2901, -1.7103],\n",
            "        [-2.9482,  0.0980,  0.8408,  ...,  2.6839,  1.0180, -0.5820],\n",
            "        [ 1.4575, -5.2271, -3.0067,  ...,  0.8895, -3.0591, -4.9310],\n",
            "        ...,\n",
            "        [-2.9919,  3.5934, -2.1165,  ..., -0.6728, -0.1067,  0.5085],\n",
            "        [ 1.7187, -1.4867, -2.9707,  ...,  2.5434,  0.6575, -1.4899],\n",
            "        [-1.7804,  3.9421,  4.3805,  ..., -1.4890,  0.0244, -2.7520]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3093, -0.3478,  0.4704,  ...,  0.5810,  1.3882, -0.3923],\n",
            "        [ 0.5236, -1.7444, -1.7551,  ...,  0.8395,  1.4087, -2.4276],\n",
            "        [-0.9958, -1.0070,  0.1206,  ...,  0.0677,  0.8990, -0.3764],\n",
            "        ...,\n",
            "        [-0.0601, -2.8412, -2.1134,  ...,  3.5690,  1.1704, -1.4609],\n",
            "        [-3.2595,  1.0679,  0.4785,  ..., -0.2427,  1.7737, -2.9222],\n",
            "        [ 0.1102, -1.0185, -1.5399,  ...,  2.3523,  0.6357, -2.1947]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2483, -1.7378, -0.2479,  ...,  0.8379,  3.3158, -2.7388],\n",
            "        [ 4.3933, -6.3499, -2.3440,  ...,  2.1827,  0.2242, -2.9396],\n",
            "        [-2.1606, -2.1740, -1.6828,  ...,  0.3574,  0.3323, -3.0950],\n",
            "        ...,\n",
            "        [-3.3004,  0.6619, -1.3822,  ...,  1.3698, -0.2857, -1.6565],\n",
            "        [ 3.4182, -2.1240, -0.5530,  ...,  1.2187,  1.8275, -2.3018],\n",
            "        [-0.4457, -0.8298,  4.3969,  ...,  0.9525,  0.7703, -1.3786]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0297, -3.2268, -3.7988,  ...,  6.0297,  2.3753, -1.9261],\n",
            "        [-1.6193,  3.1123,  2.4325,  ..., -1.7321,  1.1276, -1.4057],\n",
            "        [-1.2541, -2.7458,  2.0088,  ...,  1.8955, -2.2640, -2.1347],\n",
            "        ...,\n",
            "        [-2.2771,  2.2166,  1.1503,  ..., -2.5589,  0.4018, -1.7620],\n",
            "        [ 3.4367, -2.6465,  0.2839,  ..., -0.3517,  0.6586, -3.1272],\n",
            "        [-0.4865, -7.1729, -3.5190,  ...,  6.3260,  0.4180, -3.9093]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1259, -1.8221, -2.6790,  ...,  0.5434,  0.6009, -1.4009],\n",
            "        [-1.5506,  4.2741,  4.8162,  ..., -0.4696, -0.1297, -0.9409],\n",
            "        [-3.1706,  3.4703, -0.6197,  ..., -2.7044,  1.8225, -2.7347],\n",
            "        ...,\n",
            "        [ 0.2098, -1.5015, -1.9238,  ...,  1.6888,  1.7069, -3.1177],\n",
            "        [ 2.0815, -3.0576, -3.5183,  ...,  0.7221, -3.4442, -4.5024],\n",
            "        [-1.8005, -1.5910,  1.2391,  ...,  0.4908,  0.0158, -2.2834]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5228, -1.8846, -3.5120,  ..., -0.7583, -2.7923, -3.2091],\n",
            "        [-4.3908,  1.7681, -0.6422,  ..., -0.4550,  0.8438, -0.6782],\n",
            "        [-3.0307, -2.4824, -3.2686,  ...,  4.7827,  2.2609, -0.9755],\n",
            "        ...,\n",
            "        [-0.1015, -2.5429,  2.3714,  ..., -0.4567,  2.9734, -2.0030],\n",
            "        [-3.2989,  2.6033,  2.7158,  ..., -2.0362,  1.5543, -2.5057],\n",
            "        [-2.6468, -0.7038,  0.7506,  ..., -1.1589, -0.9075, -2.0387]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6285, -2.7476, -0.4327,  ...,  0.3478,  1.6130, -1.9024],\n",
            "        [ 2.0692, -1.6345,  0.3395,  ...,  1.2032, -0.3083, -1.5523],\n",
            "        [-0.6925, -2.5291,  1.6224,  ...,  2.9461,  0.0538, -1.5199],\n",
            "        ...,\n",
            "        [-2.9083,  0.4513,  2.1765,  ..., -1.0585,  1.3316, -0.9444],\n",
            "        [-2.1516,  0.3719,  1.3113,  ..., -2.0853, -0.0447, -4.8452],\n",
            "        [ 0.1708, -1.5835, -3.9219,  ..., -0.1532, -1.8413, -4.4755]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.2683,  2.2185,  0.1369,  ..., -2.5891, -0.3935, -1.5215],\n",
            "        [ 3.1364, -3.9941, -0.4288,  ...,  3.3842, -0.2394, -4.0004],\n",
            "        [-3.2875,  6.7395,  0.3615,  ..., -0.0160,  1.5731, -1.0359],\n",
            "        ...,\n",
            "        [ 0.4150, -3.9081, -4.0047,  ...,  0.1032,  2.2678, -4.2581],\n",
            "        [-3.8427,  0.8804, -1.3528,  ...,  1.1857,  1.4293, -1.4208],\n",
            "        [-4.3672, -0.5912,  1.2267,  ..., -1.8437,  3.0863, -3.4350]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5859e+00, -7.3528e-01,  5.9391e-02,  ...,  2.0182e+00,\n",
            "          4.1772e-01, -3.1399e-01],\n",
            "        [-1.9138e+00, -3.6342e+00, -1.2465e+00,  ..., -1.4021e-01,\n",
            "          3.6548e-01, -2.4284e+00],\n",
            "        [-1.3653e+00, -1.1376e+00,  2.3905e+00,  ..., -1.4114e+00,\n",
            "          1.4201e+00, -2.2139e+00],\n",
            "        ...,\n",
            "        [ 2.5936e+00, -3.4495e+00, -3.2096e+00,  ...,  5.7793e+00,\n",
            "          3.4281e+00, -7.2104e-01],\n",
            "        [ 2.2170e+00, -1.3865e+00, -1.3814e+00,  ..., -2.3902e-01,\n",
            "          9.8938e-01, -2.5272e+00],\n",
            "        [-3.1378e+00, -5.3306e-02, -1.3073e+00,  ...,  3.8631e-03,\n",
            "          1.3963e-02, -1.7089e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8192,  1.2454, -1.2427,  ..., -1.0947,  1.4601, -2.2250],\n",
            "        [-1.9896,  2.9210,  2.9037,  ..., -2.1749,  1.5888, -1.7597],\n",
            "        [-4.1827, -1.2419, -1.6094,  ..., -1.1934,  2.7704, -3.9709],\n",
            "        ...,\n",
            "        [ 2.1532, -2.0476, -3.0885,  ...,  1.8055, -0.7105, -1.2251],\n",
            "        [-1.2124, -0.4184,  0.9988,  ..., -0.6908,  0.6053, -2.6784],\n",
            "        [-5.8547,  5.7923,  1.1755,  ...,  0.3660,  3.4338, -0.0084]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4279, -0.1782,  0.7105,  ...,  1.1014,  0.9177, -1.8858],\n",
            "        [-2.4213,  0.3539,  2.7385,  ...,  1.7940,  0.5913, -1.5617],\n",
            "        [-0.0842, -5.9306, -5.3240,  ...,  8.4526,  3.7179, -3.4683],\n",
            "        ...,\n",
            "        [-3.4735,  2.2186,  2.8716,  ..., -0.1052, -0.4455, -0.0446],\n",
            "        [ 3.9446, -5.2012, -2.7507,  ...,  1.4655,  0.3946, -3.9850],\n",
            "        [-4.0036,  0.5113,  0.9234,  ..., -0.2107,  2.2071, -0.4140]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3032, -2.7441, -1.1820,  ...,  1.5339, -0.0778, -0.2633],\n",
            "        [ 3.3790, -1.4612,  0.0982,  ..., -0.7117,  0.8283, -2.5739],\n",
            "        [-3.8607,  0.6093,  0.9955,  ...,  1.0711, -0.5316, -1.6246],\n",
            "        ...,\n",
            "        [-4.9571, -2.7742,  0.6929,  ..., -1.2110,  1.7667, -2.4370],\n",
            "        [-0.3273, -0.3017, -4.7298,  ...,  1.3560, -0.8019, -4.1549],\n",
            "        [-0.3105, -4.3693, -1.9157,  ...,  5.5183,  2.7595, -2.5392]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.5072e-03, -1.1658e+00, -4.0246e+00,  ...,  3.7728e+00,\n",
            "         -2.3528e+00, -1.9703e+00],\n",
            "        [-4.8085e+00,  1.9985e+00, -3.0333e+00,  ..., -1.9672e+00,\n",
            "          2.3719e+00, -3.2325e+00],\n",
            "        [-5.0559e+00,  3.0498e+00, -2.6479e-02,  ..., -1.6647e+00,\n",
            "          3.9423e+00, -2.5786e+00],\n",
            "        ...,\n",
            "        [ 7.0719e-01, -6.8907e-01, -1.9066e+00,  ...,  3.0987e+00,\n",
            "         -4.5528e-01, -2.5247e+00],\n",
            "        [-1.0675e+00,  4.1722e-01,  1.4854e+00,  ..., -3.3188e+00,\n",
            "          8.5711e-01, -3.3677e+00],\n",
            "        [ 4.7159e+00, -3.7987e+00,  1.5990e-01,  ...,  9.1406e-01,\n",
            "         -1.5607e-01, -1.1796e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6745e+00,  2.0295e+00, -3.7910e+00,  ..., -6.3247e-01,\n",
            "          1.7494e+00, -4.1131e-01],\n",
            "        [-1.9834e+00,  1.8622e+00,  1.4327e+00,  ..., -1.3661e+00,\n",
            "         -2.1314e-01, -2.5114e+00],\n",
            "        [-2.0694e+00,  2.2491e-04,  2.3984e+00,  ..., -1.5212e+00,\n",
            "          2.0326e-01, -4.5787e-01],\n",
            "        ...,\n",
            "        [ 4.2364e+00, -5.8673e+00,  8.9358e-01,  ..., -9.1621e-02,\n",
            "          4.1838e-01, -4.3215e+00],\n",
            "        [ 3.3994e+00, -4.1780e+00, -1.8343e+00,  ...,  3.9856e+00,\n",
            "          1.6453e+00, -1.4070e+00],\n",
            "        [-1.1138e+00,  1.9037e+00, -6.2309e-01,  ..., -2.1701e+00,\n",
            "          2.1290e+00, -2.1406e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2924, -0.5896, -1.8461,  ...,  0.8598,  0.2837, -1.6986],\n",
            "        [-6.0233,  4.7378, -0.1688,  ...,  1.3159,  4.5118, -0.9926],\n",
            "        [-0.6130, -5.5057,  1.3351,  ...,  0.6846,  1.0087, -3.2375],\n",
            "        ...,\n",
            "        [-3.2185, -0.7947,  2.9107,  ..., -1.8876,  0.5128,  0.6987],\n",
            "        [-1.2948, -0.1780, -3.0246,  ..., -1.9176,  1.8515, -2.8047],\n",
            "        [-3.1011, -2.4251, -3.4953,  ...,  3.9389, -0.9675, -3.5484]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1915, -0.8107, -4.9853,  ...,  2.1363,  0.3393, -2.5805],\n",
            "        [-0.8211, -3.3236,  0.4516,  ..., -0.4524,  1.2039, -1.7676],\n",
            "        [-1.2393, -4.1263,  0.5798,  ..., -1.3506,  2.2718, -3.5310],\n",
            "        ...,\n",
            "        [-4.7850, -0.9747, -1.8067,  ...,  1.9263,  1.5599, -3.2129],\n",
            "        [-0.4238, -3.3086,  2.8692,  ...,  2.0252,  1.4833, -2.5508],\n",
            "        [-1.8889, -2.8507, -1.8628,  ..., -0.1496, -0.9896, -1.8516]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7503, -2.3159, -0.5132,  ..., -1.4073,  0.6894, -3.4974],\n",
            "        [-3.2299,  4.1653,  0.6037,  ..., -1.6541, -0.1865, -2.3127],\n",
            "        [ 3.1124, -4.0228, -1.7680,  ...,  0.9890,  1.6402, -2.0804],\n",
            "        ...,\n",
            "        [ 3.0641, -3.6320, -0.3103,  ...,  2.3414, -3.0399, -2.9008],\n",
            "        [ 0.5308, -0.2002, -1.0502,  ..., -0.5903,  0.9721, -0.4682],\n",
            "        [-0.5923, -0.6237,  1.5582,  ...,  2.0510,  0.6934, -0.1035]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.8519, -0.4848,  0.1139,  ...,  0.3813, -1.6699, -2.5687],\n",
            "        [ 1.7648, -4.3373, -2.0612,  ..., -0.2994,  0.6252, -2.2216],\n",
            "        [-4.7765, -1.9762, -2.2457,  ...,  1.3063, -0.9145, -1.4453],\n",
            "        ...,\n",
            "        [-2.0442, -0.9629, -5.9314,  ...,  2.1940,  1.4889, -5.0886],\n",
            "        [-5.4169,  2.6131, -0.4943,  ..., -3.6959,  1.3254,  0.1431],\n",
            "        [-2.2111,  1.5709,  0.8398,  ..., -2.5466,  0.0429, -0.3323]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5388,  2.2339,  1.2590,  ..., -1.2507,  1.0281,  0.1167],\n",
            "        [-2.5893,  1.9019, -1.4123,  ..., -1.3674,  0.7886, -1.0021],\n",
            "        [-4.0987, -1.1199, -2.1501,  ...,  0.9638,  0.3251, -1.8092],\n",
            "        ...,\n",
            "        [-0.2638, -3.0715,  1.0716,  ..., -0.2005, -0.1155, -0.5106],\n",
            "        [-0.2315, -2.0780, -5.6048,  ..., -0.1987, -1.3533, -4.3473],\n",
            "        [-1.0589, -3.9680, -0.3884,  ..., -0.5452,  2.9083, -2.9952]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3825, -1.6437,  1.6382,  ..., -0.1452,  1.3278, -3.0515],\n",
            "        [-3.3872, -2.1555, -1.9060,  ..., -0.1761,  2.3885, -2.5869],\n",
            "        [ 0.3397, -0.4253,  2.1824,  ..., -0.2263,  0.2156, -1.4683],\n",
            "        ...,\n",
            "        [-2.2005, -0.3672,  1.3086,  ..., -0.3186, -0.3174, -0.5690],\n",
            "        [-1.1890, -5.2104, -1.8961,  ...,  2.1589,  0.9911, -4.5858],\n",
            "        [-3.0477, -3.1649,  0.1229,  ..., -1.1965, -0.7072, -1.7791]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1787, -4.8973, -1.6001,  ..., -0.9368,  1.6986, -3.4313],\n",
            "        [-1.5576,  0.4633,  3.2250,  ..., -2.7640,  2.2710, -0.2923],\n",
            "        [-2.4186, -2.4372, -1.3379,  ..., -0.1920, -0.3352, -3.3856],\n",
            "        ...,\n",
            "        [-2.6467,  1.2995, -1.8506,  ...,  0.0189,  1.7661, -2.2533],\n",
            "        [-1.4015, -2.4546, -4.4984,  ...,  4.9096,  2.4535, -1.9429],\n",
            "        [-0.5216, -3.9775, -2.7539,  ...,  2.6215, -0.1956, -2.2948]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.8156, -1.0948, -0.5030,  ...,  0.9284,  1.5367, -3.4558],\n",
            "        [ 0.3400, -3.0410, -0.3270,  ...,  0.3221,  0.9016, -1.3069],\n",
            "        [-1.1999, -1.5465, -1.8960,  ...,  0.2583,  2.0410, -2.7722],\n",
            "        ...,\n",
            "        [-2.4867, -0.2283, -0.9225,  ..., -0.6029,  0.5188, -0.9998],\n",
            "        [-0.9248, -0.8324, -0.1313,  ..., -2.5480,  0.6593, -0.7000],\n",
            "        [ 2.7988, -6.8846, -0.7149,  ...,  1.9357, -2.6581, -3.9410]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7327,  2.9022,  0.0574,  ..., -2.2701,  0.5054, -0.3171],\n",
            "        [-1.6266, -3.2593, -2.3662,  ..., -1.8824, -0.0256, -2.7159],\n",
            "        [-2.8710,  2.2092, -0.1538,  ..., -1.6111,  0.5348, -0.1669],\n",
            "        ...,\n",
            "        [-4.2454,  0.5505, -0.6833,  ..., -1.0155,  2.4768, -2.9992],\n",
            "        [-2.3873, -4.7208,  0.9721,  ..., -1.1958, -0.8194, -1.7708],\n",
            "        [-1.7175, -2.9733, -0.5700,  ...,  2.9842,  1.2501, -1.2541]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6844, -4.5547, -1.8309,  ...,  0.2043,  1.1812, -3.0113],\n",
            "        [-1.3575, -3.3755,  0.0819,  ...,  3.5896,  1.5883, -1.4754],\n",
            "        [-3.3219, -0.5757, -0.6316,  ..., -0.8829, -1.0386,  0.1200],\n",
            "        ...,\n",
            "        [-3.2691, -0.4723, -4.7785,  ...,  0.1695,  3.2173, -2.2591],\n",
            "        [ 2.1602, -5.6774, -0.9105,  ...,  0.3218, -0.0732, -3.5228],\n",
            "        [ 0.9139, -2.0329, -3.0894,  ...,  1.7346,  2.4102, -1.4063]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5194, -7.9679, -4.0508,  ...,  0.3448, -1.8605, -4.7193],\n",
            "        [-5.1757, -0.1693,  0.4475,  ..., -1.9777,  0.5163,  0.3579],\n",
            "        [ 1.3435, -2.2653,  1.6550,  ...,  2.4924,  1.5108, -1.8389],\n",
            "        ...,\n",
            "        [ 2.3247, -1.7965, -1.7124,  ...,  1.8930,  0.9370, -0.8315],\n",
            "        [-1.9270,  1.6798,  1.7080,  ..., -0.4675,  1.3946, -0.6857],\n",
            "        [-1.1363, -3.9302, -2.3399,  ...,  1.3690,  1.5486, -2.4140]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0641,  0.8939, -2.8312,  ..., -0.8066,  1.8003,  0.0973],\n",
            "        [ 0.1171, -3.2772,  0.3846,  ..., -0.0177,  0.7672, -0.6520],\n",
            "        [-0.8151, -3.7945, -1.2596,  ...,  2.0212, -0.4399, -4.4871],\n",
            "        ...,\n",
            "        [-4.9777,  1.3959, -5.2537,  ...,  0.5642,  3.5833, -3.4783],\n",
            "        [-4.3806, -6.3639, -4.2367,  ...,  2.5916,  0.2523, -1.9786],\n",
            "        [-1.5254, -1.1253, -0.2868,  ..., -1.1873,  0.9669, -2.6340]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8444,  1.7047,  2.2853,  ..., -0.4020,  1.6732, -0.5897],\n",
            "        [-0.0590, -0.1269, -2.0306,  ...,  1.1728,  1.5582, -0.2675],\n",
            "        [-4.3419,  2.8916, -0.3925,  ...,  0.6298,  0.2180,  0.1756],\n",
            "        ...,\n",
            "        [-5.0261,  3.2960,  1.0108,  ..., -1.0153,  1.5613, -0.0730],\n",
            "        [-2.3857,  2.6373,  2.0163,  ..., -2.0778,  1.0059, -1.4914],\n",
            "        [-5.1639, -2.6540, -0.1333,  ...,  2.3325,  2.2551, -2.0848]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8942, -2.6112, -2.9368,  ..., -0.4637,  0.3456, -1.9249],\n",
            "        [-1.0632, -2.3304,  0.5834,  ...,  1.1185,  0.8579, -1.3503],\n",
            "        [ 2.1992, -5.0088, -4.7807,  ...,  0.5510, -1.5325, -5.2175],\n",
            "        ...,\n",
            "        [ 1.9525, -5.0260, -1.4415,  ...,  1.3638,  1.6152, -4.4699],\n",
            "        [-1.2256,  0.8310,  0.3646,  ..., -2.7325,  0.4066, -0.7829],\n",
            "        [-0.7101, -2.1001, -6.2819,  ...,  2.1749, -0.5046, -3.6187]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9696, -2.9323,  0.5794,  ...,  1.7688, -0.0114, -0.7080],\n",
            "        [-2.0305, -0.2184,  1.4600,  ..., -0.2200,  0.6878, -1.5314],\n",
            "        [-1.2830, -5.1972, -1.1685,  ..., -0.8974,  0.3974, -2.2153],\n",
            "        ...,\n",
            "        [-1.2549,  1.7532,  3.5050,  ...,  0.0636,  0.6314, -0.5410],\n",
            "        [ 1.5208, -2.1636, -4.1586,  ..., -1.5339,  2.3479, -2.7482],\n",
            "        [-6.1896,  0.1731, -3.4936,  ..., -0.4600,  4.9531, -4.9557]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6260,  0.4876, -1.3727,  ...,  0.7830,  0.8274, -2.2225],\n",
            "        [-1.8420,  3.5618,  2.3222,  ..., -0.5649, -0.9381, -0.5826],\n",
            "        [-0.6676,  3.2193,  3.4719,  ..., -0.6121,  0.6370, -1.6632],\n",
            "        ...,\n",
            "        [ 1.3105, -5.2328, -0.2255,  ...,  1.8458,  1.7061, -4.5821],\n",
            "        [-3.3020,  0.1388, -1.3035,  ..., -0.0984,  1.8333,  0.4913],\n",
            "        [-3.5315,  1.1589, -2.8403,  ...,  0.0204,  1.7072, -0.9052]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2253e+00, -4.6188e+00, -3.4098e-01,  ..., -6.5703e-01,\n",
            "          1.7783e+00, -3.2923e+00],\n",
            "        [-1.3715e+00, -4.9731e+00, -2.0759e+00,  ..., -3.8925e+00,\n",
            "          1.5173e+00, -2.4554e+00],\n",
            "        [ 2.2159e+00, -2.2411e+00, -1.6094e+00,  ...,  9.2527e-01,\n",
            "          1.3185e+00, -3.0456e-03],\n",
            "        ...,\n",
            "        [-9.2136e-01, -4.2328e+00, -1.2834e+00,  ..., -6.4627e-03,\n",
            "          1.3532e+00, -3.7246e+00],\n",
            "        [-1.6679e+00, -2.1277e+00,  1.8716e+00,  ...,  4.6341e-01,\n",
            "          1.6864e-01, -1.8949e+00],\n",
            "        [-1.4734e+00, -3.7377e+00, -4.0426e+00,  ...,  4.9143e+00,\n",
            "          2.0954e+00, -3.9718e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7135, -3.9163, -4.1561,  ...,  1.4380, -0.9959, -2.9602],\n",
            "        [-0.2444, -3.4799, -0.5206,  ...,  1.4569,  1.0293, -2.7869],\n",
            "        [ 1.3157, -3.5649, -3.3090,  ...,  6.1651,  0.4444, -2.1937],\n",
            "        ...,\n",
            "        [-1.5639,  2.2919,  3.1425,  ...,  0.1730,  0.9217, -0.7521],\n",
            "        [-2.7933, -3.9803, -1.9590,  ...,  0.2085, -0.0569, -0.2348],\n",
            "        [-1.1269,  1.3318, -0.9804,  ...,  0.9627,  0.6499, -0.8922]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2124, -3.8427, -2.2697,  ..., -2.4262,  0.8855, -1.6670],\n",
            "        [-0.1759, -2.0900, -1.2000,  ..., -0.8831,  2.6694, -2.6890],\n",
            "        [ 3.4265, -7.1852, -2.7624,  ...,  1.9584, -1.5701, -4.5256],\n",
            "        ...,\n",
            "        [-2.7511, -0.6686, -0.4544,  ..., -2.0878, -0.1969,  0.0228],\n",
            "        [-0.9616, -2.9537, -0.9245,  ..., -1.7651,  2.2881, -3.5608],\n",
            "        [-1.6962,  0.9639, -2.0994,  ..., -2.5045,  2.6754, -2.1232]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3988, -4.7428, -1.8203,  ...,  0.0447,  2.2715, -2.8098],\n",
            "        [-2.2395, -2.1000, -1.6610,  ..., -1.2640,  1.1861, -2.1888],\n",
            "        [-4.0495,  1.0636, -4.4650,  ...,  0.6756,  1.2095, -2.9351],\n",
            "        ...,\n",
            "        [-1.3104, -3.1345, -1.1220,  ..., -0.1967,  0.1886, -1.0054],\n",
            "        [-2.4103, -2.2047, -0.5180,  ..., -1.9633,  3.2669, -4.5045],\n",
            "        [-1.0809,  0.4315, -0.0221,  ..., -2.8701,  0.5130, -0.9805]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9230,  2.0803, -1.9409,  ..., -3.1318,  3.2673,  0.3528],\n",
            "        [ 0.4438, -2.4318, -0.2158,  ..., -1.8545,  1.4813, -3.1807],\n",
            "        [ 3.5195, -4.0443, -1.2856,  ..., -0.3547,  1.2555, -1.5736],\n",
            "        ...,\n",
            "        [-0.5820, -3.7235, -2.7216,  ...,  1.5235,  0.6008, -3.1035],\n",
            "        [ 0.3257, -2.5451, -1.0353,  ...,  1.2416, -0.0518, -2.3235],\n",
            "        [-1.7106, -4.5397, -0.6354,  ..., -4.6486,  2.1524,  0.1218]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6930,  2.2016,  1.3932,  ..., -3.1857,  1.6198, -1.0881],\n",
            "        [-4.6155,  0.0759, -2.4715,  ..., -1.6095,  3.1502, -1.0092],\n",
            "        [-2.4615,  2.2450,  3.4050,  ..., -1.4436,  0.7521, -0.3687],\n",
            "        ...,\n",
            "        [-1.7969,  2.8058, -2.2221,  ..., -3.1277,  2.1791,  0.4616],\n",
            "        [-1.5479,  2.0206, -0.2349,  ..., -1.6772,  0.7737, -1.4626],\n",
            "        [ 0.0520, -3.9849, -2.7180,  ..., -2.5881,  2.4028, -1.6745]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.1310,  3.2636,  0.1689,  ...,  0.9095,  1.3259,  1.4178],\n",
            "        [-1.5468, -2.5585, -0.2760,  ..., -1.0509,  0.7014, -2.3027],\n",
            "        [-3.4854, -4.8755, -0.1544,  ..., -4.2558,  1.8016, -3.2445],\n",
            "        ...,\n",
            "        [-2.3620, -3.2538,  1.2691,  ..., -3.2447,  0.1624, -0.2710],\n",
            "        [-1.4030, -2.7076, -0.7942,  ..., -0.8009,  0.3299,  0.0084],\n",
            "        [ 0.8424, -4.1469, -0.1945,  ...,  3.6712,  0.3910, -3.0142]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1689,  1.4672,  0.3299,  ..., -0.4540,  0.2039, -0.5442],\n",
            "        [-1.5917,  2.2828,  3.5907,  ..., -1.4644,  1.0292, -0.4396],\n",
            "        [-1.0260, -1.9218, -2.4839,  ..., -0.4960,  0.6212, -0.2461],\n",
            "        ...,\n",
            "        [ 0.7033, -1.0327, -1.6360,  ..., -1.3495,  1.2489, -1.0566],\n",
            "        [-2.4205, -3.0658, -2.9565,  ...,  0.4760,  0.9951, -0.9326],\n",
            "        [-3.1880, -2.1405, -3.6085,  ...,  0.1973,  1.0896, -2.0705]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7370, -0.8884, -3.1469,  ..., -0.5519,  1.2200, -2.6272],\n",
            "        [-4.0162,  0.2091, -2.8258,  ..., -1.3678,  1.7828, -1.2683],\n",
            "        [ 0.1313, -2.0843, -0.5314,  ...,  4.5184, -0.4562, -1.7537],\n",
            "        ...,\n",
            "        [-1.8831, -1.2312, -0.6120,  ..., -0.5642,  1.2107, -1.8507],\n",
            "        [-1.2100,  2.4278,  2.9299,  ..., -1.2591,  0.9868, -0.2919],\n",
            "        [-2.4269, -4.7989, -4.5956,  ...,  1.9732,  1.0665, -3.3871]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5271, -1.3449, -4.2082,  ..., -0.5048,  1.8205, -2.2285],\n",
            "        [-1.4458, -3.0224, -1.2078,  ...,  0.0065,  2.2513,  0.5214],\n",
            "        [-3.7778, -1.5741, -0.2826,  ..., -1.2349,  0.4517,  0.0569],\n",
            "        ...,\n",
            "        [ 0.3283, -4.1483, -2.0851,  ...,  2.1637,  2.7841, -2.1507],\n",
            "        [-3.0184, -1.7406, -3.3105,  ..., -0.0814,  4.5068, -2.6626],\n",
            "        [-2.6100,  0.3599, -3.1078,  ..., -0.6246,  3.0563, -0.2559]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7840, -2.9820, -5.4714,  ...,  1.9069, -1.5092, -3.4434],\n",
            "        [-0.4246,  2.5503, -2.5291,  ..., -1.9127,  1.5660, -1.9095],\n",
            "        [-1.6667,  0.5445, -1.2318,  ..., -3.0087, -0.4566,  0.0267],\n",
            "        ...,\n",
            "        [-1.8451, -2.7988, -4.8785,  ..., -0.9398,  0.4489, -1.5080],\n",
            "        [-0.8149, -6.4423, -3.1749,  ...,  2.9318,  1.3830, -4.4404],\n",
            "        [-5.8751, -2.7949, -4.0620,  ...,  3.7611,  2.2528, -0.2745]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3381, -9.3227, -2.3207,  ...,  1.5649, -0.2373, -1.2194],\n",
            "        [ 0.2621, -1.9656, -2.0373,  ...,  0.2140,  1.4812,  0.7330],\n",
            "        [-0.6798, -3.3730,  1.0298,  ...,  0.7513,  0.3493, -1.3298],\n",
            "        ...,\n",
            "        [ 3.4295, -1.7230, -2.0821,  ...,  1.1320, -0.2939, -0.2551],\n",
            "        [-6.0894,  4.1795, -0.9106,  ..., -1.9407,  3.7862,  0.4251],\n",
            "        [ 0.0563,  1.0393, -2.5376,  ...,  1.1141,  3.5512,  0.4354]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7010, -3.1181, -0.4652,  ...,  4.9983,  1.0798, -2.2212],\n",
            "        [ 0.2016, -0.6571, -1.0489,  ..., -0.8214,  1.4965, -0.6691],\n",
            "        [-2.3224, -5.9142, -3.5718,  ..., -1.4132,  1.8070, -2.7528],\n",
            "        ...,\n",
            "        [ 0.0823, -2.8477, -4.9663,  ...,  5.0262,  4.1575,  0.2179],\n",
            "        [-4.0815, -1.2682, -1.5934,  ..., -1.1004,  1.8084, -2.7171],\n",
            "        [-4.3748, -0.5050, -2.8008,  ..., -2.1842,  1.4496, -1.4076]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.7438,  1.8127, -0.9454,  ..., -0.1748,  1.8665, -0.1373],\n",
            "        [-1.9623, -2.6508, -0.3524,  ..., -1.2673,  1.8760,  0.8540],\n",
            "        [-1.6735,  2.3674,  1.4697,  ..., -2.3132,  0.5380, -0.6860],\n",
            "        ...,\n",
            "        [-2.2119,  2.6633,  0.2169,  ..., -2.0759,  2.0470, -0.8676],\n",
            "        [-1.0121, -2.5179, -0.6186,  ...,  1.5487, -0.2242, -0.1527],\n",
            "        [ 2.0458, -4.8071, -1.9142,  ...,  4.3303, -0.5127, -1.7949]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2495,  0.4173, -2.9306,  ...,  0.8465,  2.6668,  0.5119],\n",
            "        [-0.7827, -3.3832,  0.6073,  ...,  2.0271, -1.0132,  0.9634],\n",
            "        [-1.1212, -3.2241, -3.7246,  ...,  0.5865, -0.3306, -1.0126],\n",
            "        ...,\n",
            "        [-2.6291,  0.7881, -3.3216,  ..., -0.6944,  3.6098, -0.7211],\n",
            "        [ 2.3892, -4.4790, -3.7627,  ..., -0.1541, -2.1331, -3.7383],\n",
            "        [-0.2415, -5.1315, -3.2800,  ...,  1.3493, -0.9042, -2.5814]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3987, -5.1777, -4.6800,  ..., -1.1596, -1.4997, -2.3748],\n",
            "        [-1.5094, -2.9886, -1.6601,  ..., -0.9304,  0.3380, -2.3850],\n",
            "        [ 1.5008, -1.5947, -1.1008,  ..., -0.5046,  0.5392, -1.6240],\n",
            "        ...,\n",
            "        [-0.3731, -1.9305, -0.4416,  ..., -0.5619,  0.6465, -0.8525],\n",
            "        [ 1.5764, -6.5856, -2.6862,  ...,  1.5840,  0.7959, -1.2168],\n",
            "        [-0.8069, -0.2731,  4.1211,  ..., -0.2261,  1.0842,  0.5024]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8424, -2.1051, -4.8733,  ..., -1.6365,  2.4072, -1.3102],\n",
            "        [-0.6935, -3.2079, -3.1415,  ...,  2.4498, -0.5626, -1.5169],\n",
            "        [-2.2561,  1.6467, -0.2038,  ..., -3.0154,  0.4088, -0.6921],\n",
            "        ...,\n",
            "        [-1.2222, -0.7311, -0.1815,  ...,  0.6396,  0.2849, -0.4490],\n",
            "        [-0.5511, -9.1348, -3.3136,  ...,  1.1124, -0.7649, -3.4218],\n",
            "        [-1.7254, -2.4304, -1.1728,  ..., -2.3679,  1.2178, -0.6797]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0346,  2.8510, -1.2002,  ..., -1.2757,  0.0527,  0.3084],\n",
            "        [ 0.4210, -3.8224, -4.6004,  ...,  2.7881, -0.1174, -2.2094],\n",
            "        [-1.0595,  2.2836,  1.0517,  ..., -1.1637,  0.0977,  0.3265],\n",
            "        ...,\n",
            "        [ 4.1598, -6.3201, -5.6076,  ...,  5.8242,  2.0018, -1.0850],\n",
            "        [-2.3296,  2.3631,  0.0318,  ..., -0.4412,  2.0906, -0.0070],\n",
            "        [-3.4000,  1.0194, -2.3443,  ..., -2.8155,  2.9681, -0.0518]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0459, -6.3330, -2.6135,  ...,  3.1054,  1.3668, -0.7233],\n",
            "        [-3.2795, -2.2476, -3.1934,  ..., -1.2084,  2.3343, -2.0186],\n",
            "        [-3.8544, -2.3196, -1.3193,  ..., -1.3645,  0.2975, -0.1831],\n",
            "        ...,\n",
            "        [-1.7312, -2.9931, -0.1449,  ..., -2.0951,  0.5503, -1.7915],\n",
            "        [-6.5663,  2.2676, -0.7399,  ..., -3.2447,  5.3206, -2.0962],\n",
            "        [-1.1825, -3.3599,  1.0489,  ...,  0.1096, -0.9397, -0.2644]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6971,  3.6670,  3.7235,  ...,  0.3020,  0.2609, -0.2274],\n",
            "        [-1.3072, -0.3938, -1.2190,  ..., -1.6664,  1.2213,  1.6093],\n",
            "        [-0.2779, -2.2230, -1.4019,  ...,  2.2383, -0.2680, -1.1256],\n",
            "        ...,\n",
            "        [-2.9776, -5.3991, -4.5432,  ...,  2.2759,  0.0687, -2.4298],\n",
            "        [ 2.7932, -2.7702, -2.5908,  ...,  1.8237,  0.5541, -0.6867],\n",
            "        [-1.7434, -1.3941, -5.8412,  ...,  0.9389,  0.4278, -1.6267]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5407e+00, -1.0709e+00, -5.7982e+00,  ...,  1.9870e+00,\n",
            "          2.1178e-01, -2.4933e+00],\n",
            "        [-1.5218e+00,  6.7631e-01,  6.4897e-01,  ...,  5.1837e-02,\n",
            "          1.4606e+00,  1.5832e+00],\n",
            "        [-2.3005e+00, -3.8131e-03, -3.6440e+00,  ..., -1.8139e+00,\n",
            "          1.7057e+00, -2.1461e+00],\n",
            "        ...,\n",
            "        [ 4.0076e+00, -7.3074e+00, -3.5002e+00,  ...,  3.2816e+00,\n",
            "          3.0727e+00, -3.8554e+00],\n",
            "        [-2.5644e+00, -1.2337e+00, -3.0512e+00,  ...,  2.3298e+00,\n",
            "          4.3536e-01,  6.5416e-01],\n",
            "        [-2.1955e+00, -2.2833e+00, -3.4016e+00,  ...,  2.0015e+00,\n",
            "         -8.3365e-01, -2.6187e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2079, -1.4937, -3.6401,  ..., -1.0401,  5.2993, -0.7900],\n",
            "        [-4.3938, -0.5593, -3.8915,  ..., -3.6462,  2.8739, -1.1861],\n",
            "        [-0.0768, -5.0133, -2.0770,  ...,  2.7138,  2.2493, -1.9673],\n",
            "        ...,\n",
            "        [-1.2446, -1.4237,  1.9325,  ...,  1.5291, -0.8233,  0.0687],\n",
            "        [-3.7070, -1.8546, -2.5767,  ..., -1.6705,  1.7801, -3.0750],\n",
            "        [-0.1341, -1.0173, -1.6604,  ..., -1.4404,  0.3397, -0.6238]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9150, -3.9167, -1.0511,  ..., -2.0928, -1.3662, -1.9855],\n",
            "        [ 0.8504, -4.7672, -2.2494,  ...,  1.8726,  0.9748, -2.5112],\n",
            "        [-3.6280,  0.7042, -1.8326,  ..., -1.8348,  3.1482, -0.0907],\n",
            "        ...,\n",
            "        [-0.7509, -3.6336, -1.0980,  ..., -1.7395,  2.2710, -3.4175],\n",
            "        [-3.6477, -1.7369, -4.5129,  ..., -0.5743,  2.8573, -1.9324],\n",
            "        [ 0.5699, -1.1642, -3.4562,  ...,  0.9844,  0.4687, -0.5520]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0145, -5.5830, -1.8963,  ...,  0.3237,  0.2242, -0.4937],\n",
            "        [-3.2006, -4.2121,  1.8489,  ..., -3.1433, -0.0685, -2.1848],\n",
            "        [-4.2736, -1.7103, -4.0566,  ..., -0.6244,  0.4471, -0.6779],\n",
            "        ...,\n",
            "        [-4.7093,  1.6682,  0.2569,  ..., -0.8778,  2.0221, -0.9601],\n",
            "        [-4.1119, -2.1563, -1.0880,  ..., -2.1297,  0.9398,  0.6738],\n",
            "        [-3.1425, -0.1769, -2.9157,  ..., -0.9833,  1.3906, -2.0883]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5794, -1.7694, -0.4996,  ...,  1.4363, -0.4721,  0.2499],\n",
            "        [-2.0898, -3.8615, -1.3306,  ..., -2.5797,  2.1512, -1.6999],\n",
            "        [-1.2722, -1.0495,  1.0904,  ..., -2.5948,  0.3944,  0.9960],\n",
            "        ...,\n",
            "        [-2.8023, -0.1358, -0.5459,  ..., -0.4207,  1.7720, -0.5883],\n",
            "        [-2.6619, -1.0448, -2.4538,  ...,  1.4949,  2.1855,  0.0995],\n",
            "        [-3.1078, -1.4168, -2.0606,  ..., -3.3628,  2.0991, -2.8815]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0131,  2.7869,  0.4652,  ..., -2.6955,  0.8892, -0.2036],\n",
            "        [-1.9956,  0.2907, -0.6694,  ..., -3.0485,  0.1782,  0.0231],\n",
            "        [-1.8186,  0.7707, -0.7795,  ..., -2.9854,  0.0436,  0.4905],\n",
            "        ...,\n",
            "        [ 1.0449, -5.8404, -6.8198,  ...,  0.5020,  1.2207, -5.2172],\n",
            "        [ 1.9415, -3.8855, -3.2836,  ...,  1.2271,  0.8845, -1.7305],\n",
            "        [-2.0595, -2.8461, -3.5523,  ..., -3.4704, -0.0201, -1.0513]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2748,  3.6040,  3.7346,  ..., -1.1925,  0.7747, -0.7371],\n",
            "        [-5.7828, -0.2967, -5.3535,  ...,  2.6947,  1.8247, -3.1488],\n",
            "        [-1.9564,  3.2221,  3.3496,  ..., -1.5772,  0.4967, -0.4698],\n",
            "        ...,\n",
            "        [-2.9769, -1.0188, -3.6228,  ..., -3.2020,  3.2453, -3.5326],\n",
            "        [-1.3969, -1.7041, -7.3592,  ...,  0.8443,  3.7813, -1.7108],\n",
            "        [-2.3377, -1.1849, -3.5093,  ..., -1.3432, -0.5032, -3.1804]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6590,  3.4861,  3.5905,  ..., -0.5640,  0.8655, -0.7205],\n",
            "        [ 0.5297, -1.8484, -1.1276,  ...,  1.3621,  1.0331, -1.6652],\n",
            "        [-4.4571,  1.3589, -3.6596,  ..., -1.8927,  5.5474, -0.8201],\n",
            "        ...,\n",
            "        [ 0.6410, -2.5997, -3.0502,  ..., -0.9161, -0.4181, -1.1750],\n",
            "        [-1.0082, -5.3383, -6.5239,  ...,  1.2990,  0.1940, -3.6354],\n",
            "        [ 2.7110, -7.9629, -1.5823,  ..., -0.0443,  0.1348, -3.5685]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7843,  1.5404, -0.5289,  ..., -0.5686,  0.0433, -0.0211],\n",
            "        [-1.8037, -3.1847, -1.1734,  ...,  0.2451,  0.7912,  0.9484],\n",
            "        [-1.9251,  1.4716, -1.8117,  ..., -1.1358,  0.0681,  0.2485],\n",
            "        ...,\n",
            "        [ 2.3298, -9.0788, -3.6573,  ..., -1.0145, -0.6580, -4.8567],\n",
            "        [-0.0784,  0.4443, -1.1011,  ..., -3.0525,  1.8426, -1.6343],\n",
            "        [-1.5407,  3.2957,  4.1164,  ..., -2.0581,  1.1048, -0.0357]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8571,  3.6924,  2.4968,  ..., -0.5527, -0.4151,  0.3150],\n",
            "        [-0.6112, -1.6675,  1.8828,  ...,  1.8263,  1.5239, -0.1675],\n",
            "        [ 3.5826, -8.1124,  0.2935,  ..., -1.4396,  1.3869, -2.1792],\n",
            "        ...,\n",
            "        [-0.8403, -2.7859, -2.0827,  ...,  0.2584,  0.0728, -1.0977],\n",
            "        [-3.4371, -2.1476, -3.0093,  ...,  0.5849,  1.8161, -2.0566],\n",
            "        [-1.2954, -2.2777, -2.5271,  ..., -0.1930,  2.5799, -1.5024]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6478,  0.8411, -2.6751,  ..., -0.1823,  3.0962, -1.5152],\n",
            "        [-1.9652, -1.2114,  0.6704,  ..., -2.1427, -0.1734,  0.4991],\n",
            "        [-4.6321,  1.2976, -2.2056,  ..., -2.8833,  0.5247,  0.9470],\n",
            "        ...,\n",
            "        [-2.3456, -4.2850, -4.4254,  ...,  1.1770,  0.7664, -2.4706],\n",
            "        [-3.4526,  4.0658,  1.7075,  ..., -3.4203,  1.3162,  0.8385],\n",
            "        [-3.4742, -0.4356,  1.2213,  ..., -0.0767, -0.0920, -0.5834]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7952, -2.2233, -1.4320,  ..., -1.0884,  0.8041, -0.6515],\n",
            "        [ 0.0669, -5.1621, -1.2988,  ...,  0.6821,  3.1093, -3.1521],\n",
            "        [-2.7529, -0.7050, -4.2051,  ..., -2.6087,  0.9206, -0.1579],\n",
            "        ...,\n",
            "        [-2.6520,  3.0046,  0.9149,  ..., -4.1674,  1.6580,  0.4087],\n",
            "        [-3.8303,  0.0480, -1.2429,  ..., -0.9085,  2.4176, -0.4386],\n",
            "        [-2.9171, -1.8607, -1.9675,  ..., -1.6028,  1.6739, -2.8049]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1981, -3.7352, -5.2368,  ...,  4.6101,  3.8195, -0.6909],\n",
            "        [-0.1453, -4.6213, -4.5012,  ..., -1.9213, -0.3824, -2.0392],\n",
            "        [-1.6676,  1.5001, -0.2301,  ..., -3.3606,  0.6762,  0.4069],\n",
            "        ...,\n",
            "        [-2.5711, -6.2466, -6.2719,  ...,  0.0135, -0.4653, -3.3204],\n",
            "        [ 0.3624, -2.5486, -1.5222,  ..., -2.3948,  1.5506, -0.4594],\n",
            "        [-5.0628, -1.2893, -3.2629,  ..., -0.2493,  0.6136, -1.5291]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1683, -4.7134, -0.9825,  ..., -1.8876,  1.8550,  0.0407],\n",
            "        [-1.6495, -0.1108, -4.1092,  ..., -0.7629,  2.8542, -1.5633],\n",
            "        [-1.2068, -2.5733, -3.3212,  ...,  1.1683,  0.2601, -0.6547],\n",
            "        ...,\n",
            "        [-2.4500, -0.5443, -2.0624,  ..., -2.4312,  1.8860, -2.2473],\n",
            "        [-0.8400, -6.3332, -3.2169,  ..., -2.0416, -0.4557, -1.4476],\n",
            "        [ 3.4889, -2.2748, -2.7341,  ...,  1.7076,  1.9538,  0.5515]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.8116,  2.4271, -2.4441,  ...,  0.2193,  1.1069, -1.8221],\n",
            "        [-2.4010, -4.9292, -3.2880,  ..., -2.4493,  2.9357, -1.1049],\n",
            "        [-0.5809, -1.1598, -2.5956,  ..., -0.1547,  0.0093, -2.1224],\n",
            "        ...,\n",
            "        [ 1.4521, -1.9752, -4.2016,  ...,  3.1442,  1.3821,  0.0761],\n",
            "        [-1.7875,  1.7019, -0.8739,  ..., -2.4676,  0.0835,  1.8349],\n",
            "        [-0.1390,  0.9204, -1.8459,  ...,  0.2819,  0.4602, -0.1106]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1929, -0.6744, -4.2532,  ..., -2.0383,  1.9895,  0.1031],\n",
            "        [-3.9737,  4.4091, -1.9973,  ..., -0.6524,  4.1490,  0.9534],\n",
            "        [ 0.9775, -0.4691, -0.8685,  ..., -1.6756, -0.1372,  1.2592],\n",
            "        ...,\n",
            "        [-3.4672, -2.0108, -3.9681,  ..., -1.5209,  1.3347, -0.7349],\n",
            "        [-1.0350, -1.5606, -2.4681,  ...,  0.1331, -0.8961, -1.5234],\n",
            "        [-3.6545,  2.4169,  1.2634,  ..., -0.1463,  1.1474,  1.9018]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.5160e+00, -1.7138e+00, -3.8679e+00,  ...,  1.3654e+00,\n",
            "          9.6703e-02, -2.2265e+00],\n",
            "        [-6.2020e-03, -4.9192e+00, -3.5269e+00,  ...,  3.1136e+00,\n",
            "          2.6613e+00, -7.5829e-01],\n",
            "        [-2.0979e+00, -3.2399e+00, -1.7699e+00,  ...,  2.3042e+00,\n",
            "          9.4119e-02,  7.9438e-02],\n",
            "        ...,\n",
            "        [ 4.5463e+00, -6.2383e+00, -5.8272e+00,  ...,  7.0445e+00,\n",
            "          2.2516e+00,  8.3177e-01],\n",
            "        [-1.9284e+00,  1.1477e+00, -6.5838e-01,  ..., -1.0017e+00,\n",
            "          1.9169e+00, -9.7088e-01],\n",
            "        [-2.5773e+00, -2.4264e+00, -1.7988e+00,  ...,  1.6279e+00,\n",
            "          1.0483e+00, -3.0403e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2063, -1.3217, -4.9100,  ..., -0.5702,  2.5345, -2.0570],\n",
            "        [-5.6797,  3.4306, -2.5399,  ..., -2.9829,  3.7120, -1.7058],\n",
            "        [-2.7228, -0.8772, -4.0864,  ..., -0.2764,  2.1403, -0.4633],\n",
            "        ...,\n",
            "        [-1.7370, -0.9184, -3.7166,  ..., -4.1341,  1.3226, -1.5900],\n",
            "        [-0.0210, -4.2544, -1.4846,  ...,  5.4939, -3.0077, -0.6957],\n",
            "        [-0.8547,  0.7037, -1.7994,  ...,  1.2407, -0.3548, -0.6769]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7742,  2.3692, -3.0155,  ..., -0.1938,  1.8932,  1.4130],\n",
            "        [-0.2870, -2.1769, -2.4790,  ..., -1.8905,  0.2191,  1.8945],\n",
            "        [-2.0200, -1.0947, -4.6790,  ..., -1.6635,  1.5330,  0.4446],\n",
            "        ...,\n",
            "        [ 0.3207, -3.6691, -1.9496,  ..., -0.0467,  1.6327,  0.9497],\n",
            "        [-0.2101, -5.1469, -7.8901,  ...,  6.4796, -0.3649, -1.0422],\n",
            "        [-0.4142, -2.9055, -3.2717,  ...,  2.1178,  3.0962, -0.9881]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4531,  0.7574, -2.2846,  ..., -1.4290, -1.1074, -1.2971],\n",
            "        [ 1.6523, -4.1121, -3.1726,  ...,  0.4593,  1.6676,  1.7451],\n",
            "        [-1.5722, -3.0348, -6.3915,  ...,  1.1435,  2.5647, -0.6678],\n",
            "        ...,\n",
            "        [-2.7055,  2.7379, -1.7607,  ..., -1.8212,  1.4592, -0.9051],\n",
            "        [-1.5428, -0.4309,  0.9881,  ..., -0.5685,  0.7455,  2.2820],\n",
            "        [-0.4974, -5.0007, -2.7900,  ...,  2.5492,  2.1964, -1.5252]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6088, -3.2065, -4.8750,  ..., -2.4309,  0.9590, -0.2986],\n",
            "        [-4.2288, -0.2666, -3.4931,  ..., -1.6524,  2.0958,  0.2868],\n",
            "        [-3.6149,  4.1120, -2.2295,  ..., -2.1279,  2.0444, -2.0913],\n",
            "        ...,\n",
            "        [-2.9603,  0.2370, -1.3091,  ..., -0.5990,  1.2327,  0.0223],\n",
            "        [-3.5441, -4.6982, -5.1681,  ..., -0.7656, -0.5741, -1.1585],\n",
            "        [-3.2010, -3.1655, -3.5750,  ...,  0.0761,  2.3281, -5.0147]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4555, -6.5474, -1.5720,  ...,  1.8065,  2.4100,  0.2177],\n",
            "        [ 3.9980, -5.3944, -4.8003,  ...,  0.5726, -1.2871, -2.6209],\n",
            "        [-1.9738, -0.5314, -2.6687,  ..., -1.5972,  1.9417,  2.7986],\n",
            "        ...,\n",
            "        [-1.6200,  0.2167, -1.7412,  ..., -2.0261,  1.1770,  2.1759],\n",
            "        [ 0.5318, -3.2545, -4.5804,  ...,  5.2921,  2.8269, -1.7353],\n",
            "        [-0.1726, -3.2002, -8.6437,  ...,  0.6929,  3.2575, -3.7607]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6570, -0.1382,  0.7702,  ..., -0.4756, -0.1367, -0.1330],\n",
            "        [-2.7902,  0.6156, -1.7761,  ..., -0.5133,  0.3051, -0.1322],\n",
            "        [-1.1333, -1.2155, -3.1233,  ..., -2.2518, -0.3340, -0.6245],\n",
            "        ...,\n",
            "        [-1.3630, -1.1191, -3.0167,  ..., -0.6048,  1.0836, -0.9785],\n",
            "        [-2.2930,  3.8031,  3.1946,  ..., -2.7625,  0.6994,  0.0818],\n",
            "        [-1.5510,  0.7901, -3.4689,  ..., -3.4090,  3.6026, -1.0984]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0027,  4.9216,  2.4180,  ..., -1.4933,  0.6542, -0.6506],\n",
            "        [-2.2708, -1.7626, -1.8438,  ..., -1.5421,  1.1301, -0.7470],\n",
            "        [-2.9243, -4.4959, -6.0649,  ...,  1.5579,  0.9499, -1.8959],\n",
            "        ...,\n",
            "        [-2.5944,  2.7590, -0.1660,  ..., -1.5484,  0.8084, -1.4583],\n",
            "        [ 3.1056, -3.3873, -4.1125,  ...,  0.1164, -1.7009, -1.0026],\n",
            "        [-0.0320, -2.8663, -1.7555,  ...,  1.4464, -0.6184,  0.4089]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3681, -2.6145, -2.5135,  ..., -3.2430, -0.9958, -2.1609],\n",
            "        [-0.2078, -3.5306, -2.0163,  ...,  5.5638,  1.0976, -2.5092],\n",
            "        [-0.3770, -5.0091, -6.9239,  ...,  0.7912, -0.6248, -4.1465],\n",
            "        ...,\n",
            "        [-2.4112,  3.2426,  1.2810,  ..., -3.0883,  1.0182, -0.6168],\n",
            "        [-2.6660,  0.1960, -5.4493,  ..., -1.9329,  0.6004, -1.8254],\n",
            "        [-2.2652, -7.4163, -4.4731,  ...,  5.0067,  1.5083, -1.0105]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.4916,  2.3726, -0.9667,  ...,  0.1625,  0.0109, -1.4697],\n",
            "        [-0.8025, -1.0970, -4.3856,  ...,  0.7208,  0.2518,  0.1230],\n",
            "        [ 0.9992, -4.7681, -4.8710,  ..., -1.7515,  2.2276, -2.3738],\n",
            "        ...,\n",
            "        [ 0.2759, -1.0645, -4.7387,  ...,  1.0297,  1.0949,  0.3307],\n",
            "        [-1.4687, -3.3334, -1.5324,  ..., -2.6971,  1.4047, -1.8049],\n",
            "        [-3.8532,  1.1675, -3.0026,  ..., -0.8704,  0.2236,  0.4294]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-6.1678,  1.8950, -2.0656,  ..., -1.0629,  0.3825, -0.3532],\n",
            "        [-3.7950,  3.4835, -1.9381,  ..., -1.0507,  4.0004, -0.0965],\n",
            "        [-1.4179,  1.8303, -0.6263,  ..., -0.9907,  0.6855,  1.5406],\n",
            "        ...,\n",
            "        [-2.4659, -2.2318, -1.1029,  ...,  2.1317,  1.0870,  0.5913],\n",
            "        [-1.5619,  2.9954,  1.9010,  ..., -0.6650,  1.5045,  0.0424],\n",
            "        [-2.2617, -1.6410, -2.5475,  ..., -3.7770,  2.2538, -2.4648]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0288,  0.5185, -2.8468,  ..., -1.6999,  2.2488, -0.8579],\n",
            "        [ 1.5096, -5.7244, -6.3171,  ..., -1.1921,  1.1195, -2.8735],\n",
            "        [-1.8336, -3.3928, -1.5645,  ...,  2.0886, -1.4144, -1.1921],\n",
            "        ...,\n",
            "        [-4.7625, -0.0459, -3.2306,  ..., -2.2335,  0.2089,  1.5214],\n",
            "        [-1.9357, -1.2026, -3.3891,  ..., -1.8274,  0.3722, -2.2012],\n",
            "        [-0.0477,  1.2254, -1.3448,  ..., -1.5166,  0.8370, -1.4141]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4746e+00, -3.0126e+00, -2.9740e+00,  ..., -1.1924e+00,\n",
            "          4.0033e+00, -2.5843e+00],\n",
            "        [-2.6289e+00,  2.9898e+00, -1.5632e+00,  ..., -3.1977e+00,\n",
            "          7.4503e-01,  1.5022e+00],\n",
            "        [-1.5383e+00, -1.3440e+00,  3.4583e+00,  ..., -9.8145e-01,\n",
            "          9.7553e-01, -6.5085e-04],\n",
            "        ...,\n",
            "        [ 1.7002e+00, -4.3491e+00, -5.1659e+00,  ..., -3.5966e-01,\n",
            "         -9.9931e-01, -2.3743e+00],\n",
            "        [-1.9628e+00,  2.3859e+00, -9.6916e-01,  ..., -1.0426e+00,\n",
            "          6.8009e-01,  1.4855e+00],\n",
            "        [-3.6771e+00, -1.7045e+00, -2.7874e+00,  ..., -2.2536e+00,\n",
            "         -2.2018e-01,  2.3161e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8256, -2.3928, -5.2124,  ..., -0.8983,  1.7017, -0.2720],\n",
            "        [-1.7417, -4.5442, -3.2668,  ..., -1.0247,  0.9539, -1.4871],\n",
            "        [-1.6216, -1.4649, -3.6477,  ..., -0.9168, -1.5544,  1.4938],\n",
            "        ...,\n",
            "        [-1.1239, -0.4661, -4.5035,  ..., -1.6323,  0.0774, -0.4688],\n",
            "        [ 0.6285, -1.0427, -1.8002,  ...,  0.3671,  0.8103,  1.1899],\n",
            "        [-2.2054, -3.6729, -4.0972,  ...,  1.3832,  1.3659,  0.2138]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8889, -2.1185, -1.7584,  ..., -3.0542,  1.1492,  0.1710],\n",
            "        [-3.7254,  1.8742,  4.8906,  ..., -1.3688, -0.2646, -0.4773],\n",
            "        [ 0.5376, -1.6579, -3.4413,  ...,  0.0934,  1.1392, -1.5360],\n",
            "        ...,\n",
            "        [-2.8346, -0.0349, -4.0475,  ..., -2.7788,  1.5176, -1.2400],\n",
            "        [ 1.7634, -6.4620, -6.7773,  ..., -3.2385, -1.6585, -4.2500],\n",
            "        [-1.7706, -1.6664, -2.7025,  ..., -0.3969,  1.5500,  2.2838]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8834, -4.3942, -1.8640,  ..., -1.7973, -2.4991,  1.6586],\n",
            "        [-3.5438,  0.9209, -1.4272,  ..., -0.1752,  0.3738, -1.2978],\n",
            "        [ 1.4825, -2.8191, -6.3781,  ...,  5.1115,  1.2513, -0.5858],\n",
            "        ...,\n",
            "        [-3.9360,  1.5820, -1.3814,  ..., -1.4673,  0.9755, -1.1329],\n",
            "        [-3.2159, -1.4279, -2.3322,  ..., -1.0182,  0.8070, -2.0440],\n",
            "        [-3.3643,  0.6668, -1.9756,  ..., -4.9430,  2.1977, -1.6379]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-6.5929,  0.6470, -2.0479,  ..., -0.7936,  1.2958, -2.3201],\n",
            "        [-3.7401, -0.9049,  1.1392,  ..., -3.7508,  2.1034,  1.2787],\n",
            "        [-1.6354, -7.5539, -4.6374,  ...,  3.2844,  0.5689, -1.1259],\n",
            "        ...,\n",
            "        [-3.1876, -1.2242, -3.7616,  ..., -2.5014,  1.6575,  0.1286],\n",
            "        [-1.5040, -1.0729,  0.5811,  ..., -0.0974,  0.1872, -0.1366],\n",
            "        [ 0.7111, -2.2075, -1.1797,  ..., -2.2563, -0.1928,  0.2937]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0771,  0.6071, -1.8913,  ..., -0.6670,  1.6438, -0.6784],\n",
            "        [-0.1591, -1.5631, -5.5187,  ...,  3.2450,  3.2281, -0.6199],\n",
            "        [-2.3691,  4.0341,  2.7202,  ..., -2.1095,  1.2345, -0.6070],\n",
            "        ...,\n",
            "        [-1.9466,  4.1743,  1.9196,  ..., -2.5644,  1.0364,  0.2236],\n",
            "        [-4.1628, -1.1560, -3.2915,  ..., -1.0187,  3.7288, -3.5374],\n",
            "        [-2.8366, -0.2661, -2.3974,  ..., -0.0907,  0.1934,  0.1434]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.5188, -0.3113, -5.6288,  ..., -3.0668,  1.6630, -0.3082],\n",
            "        [ 0.3879, -2.1287, -4.1101,  ...,  5.1193, -0.5796,  0.4323],\n",
            "        [ 1.3158, -4.4964, -3.8710,  ..., -0.0986, -2.2389, -0.9275],\n",
            "        ...,\n",
            "        [-2.6448,  1.0567, -1.0241,  ..., -1.8227,  2.8288, -2.0483],\n",
            "        [-0.7613, -2.4206, -3.4989,  ...,  1.8291,  1.3139,  0.0820],\n",
            "        [-3.1847,  1.1961, -0.5360,  ..., -4.5837,  2.3581,  0.3912]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3095, -1.8977, -3.8181,  ..., -1.5800,  1.8937, -2.4228],\n",
            "        [-2.6439,  1.7812, -2.4392,  ..., -0.6191,  1.3409, -0.9271],\n",
            "        [-1.7824, -2.1285, -4.9451,  ..., -0.8666,  0.6701,  1.2820],\n",
            "        ...,\n",
            "        [-1.7936,  1.7069, -1.1089,  ..., -2.8348,  0.8255,  0.0540],\n",
            "        [-2.4001,  2.3062, -1.7212,  ..., -2.8058,  0.7243,  0.9791],\n",
            "        [-2.6560, -0.3097, -1.4328,  ...,  1.2037, -0.6099,  0.4433]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3790,  1.9636, -0.9386,  ..., -1.3644,  2.5374,  0.7189],\n",
            "        [-0.2320, -1.7221, -4.2618,  ..., -1.1416,  0.8380,  0.2034],\n",
            "        [-0.9320, -1.4489, -4.0062,  ...,  3.9384,  1.1143, -0.6330],\n",
            "        ...,\n",
            "        [ 0.5900, -1.9492, -2.9314,  ..., -1.2842,  1.4473, -1.8666],\n",
            "        [-3.4998,  1.5703, -0.5275,  ..., -4.3258,  2.3551,  1.6459],\n",
            "        [-2.8631,  0.0583, -2.0029,  ...,  1.1126,  0.3082, -0.4150]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2625,  3.2337, -2.1173,  ..., -1.2046,  2.8501, -0.8261],\n",
            "        [ 3.6685, -4.1809, -3.1613,  ...,  0.8272, -2.1474, -2.5543],\n",
            "        [-1.8778, -0.8589,  1.8314,  ..., -0.3379,  1.5953,  0.4036],\n",
            "        ...,\n",
            "        [-0.4821, -2.6552, -6.6927,  ...,  3.8681,  1.5808, -4.3244],\n",
            "        [-1.9890,  0.0375, -2.6442,  ..., -2.1911,  0.0532,  0.6455],\n",
            "        [-1.6534,  0.8066, -5.6216,  ..., -0.8695,  0.1651, -0.1150]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2997,  4.2139,  2.9571,  ..., -1.9087,  0.8316, -1.1333],\n",
            "        [-1.0093, -2.5333, -7.4564,  ..., -0.1913,  3.9850, -3.2780],\n",
            "        [-2.8842, -4.4992, -2.8251,  ...,  0.8272, -0.2475,  1.2014],\n",
            "        ...,\n",
            "        [ 2.2160, -1.6919, -2.0039,  ...,  0.3463,  0.1262, -1.1704],\n",
            "        [-0.1692, -1.2137, -4.0778,  ...,  0.1138,  0.5144, -1.9277],\n",
            "        [-4.4498,  2.8919, -2.1453,  ..., -0.6814,  1.7653, -1.6125]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0474, -1.4973, -0.2646,  ..., -0.3604, -0.8087, -0.1437],\n",
            "        [-1.3830, -0.7971, -2.5635,  ...,  1.3759,  1.7110, -1.9886],\n",
            "        [-3.9402,  3.0654, -4.3922,  ..., -1.4634,  2.5493,  0.2632],\n",
            "        ...,\n",
            "        [-1.8657,  0.9848,  2.5791,  ..., -0.3992, -0.5067,  0.5546],\n",
            "        [-0.7461,  2.8638, -0.8091,  ..., -1.8330,  1.5105, -0.7249],\n",
            "        [-2.3340,  1.6644, -1.1064,  ..., -3.6076,  1.2508, -1.3499]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.0965,  2.7370, -3.2779,  ..., -1.8154,  4.7630, -0.7143],\n",
            "        [ 1.1290, -4.5900, -3.0632,  ..., -1.1162,  1.0635, -4.2498],\n",
            "        [-3.0196, -1.1314, -2.5400,  ..., -2.7136,  1.9726, -0.4174],\n",
            "        ...,\n",
            "        [-1.9225, -1.8115, -1.0253,  ..., -0.5219, -0.5529, -0.8461],\n",
            "        [-3.3066, -0.5810, -1.4000,  ...,  1.1838,  1.3157, -2.4995],\n",
            "        [-2.1172,  0.4316, -2.4067,  ...,  0.1344, -0.5871, -0.6854]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3733, -1.7936, -1.0005,  ..., -1.4234,  0.3550, -1.2814],\n",
            "        [-1.1339,  2.1644, -1.6412,  ..., -3.7770,  0.5265, -1.4954],\n",
            "        [-0.2009, -2.9601, -4.6951,  ..., -1.4992,  0.3087, -2.7665],\n",
            "        ...,\n",
            "        [-1.5849,  3.6385,  2.0113,  ..., -2.3619,  0.9431, -1.5901],\n",
            "        [-1.6374,  3.4684,  1.5977,  ..., -1.3774,  1.8776, -1.0467],\n",
            "        [-1.7443, -0.6984, -4.2920,  ..., -1.4232,  2.1404,  0.1562]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1110,  0.1811, -2.1017,  ..., -0.4271, -0.4552, -1.8833],\n",
            "        [-1.7528, -1.3395, -1.5993,  ...,  0.6300,  0.5808, -0.5594],\n",
            "        [-2.9339, -2.3958, -2.5660,  ..., -0.9114,  0.2286, -2.0127],\n",
            "        ...,\n",
            "        [-1.4683, -2.2476, -2.9437,  ..., -3.0202,  0.8363, -2.2120],\n",
            "        [-3.5472, -0.7019, -2.4007,  ..., -3.8399,  1.4496, -3.7609],\n",
            "        [-2.2409, -4.1644, -4.0752,  ...,  5.2154, -0.9123, -1.8292]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1517,  0.5975, -0.6041,  ..., -0.7333,  1.4085, -1.6876],\n",
            "        [-2.2162,  5.1606,  2.0728,  ..., -2.2494, -0.4138, -1.7619],\n",
            "        [-3.6746, -0.0199, -3.5165,  ...,  0.0794,  1.2173, -0.2640],\n",
            "        ...,\n",
            "        [-5.2512,  1.6090, -2.7952,  ..., -2.0531, -0.6284, -1.1999],\n",
            "        [-1.7455, -4.2443, -5.1445,  ...,  0.9375,  0.6896, -5.1641],\n",
            "        [-0.1193,  3.1602, -3.7677,  ..., -2.5024,  1.6314, -2.8340]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4628, -1.1656, -3.9433,  ...,  3.3271, -0.6162, -0.9448],\n",
            "        [-1.8024, -2.8859, -4.5535,  ..., -2.2886, -1.7111, -1.5699],\n",
            "        [-2.1224,  3.1169, -0.8833,  ..., -3.8374,  0.7965, -0.4116],\n",
            "        ...,\n",
            "        [-2.5522,  1.0265, -5.3426,  ...,  4.1140,  2.1859, -0.0880],\n",
            "        [-1.5293, -2.5881, -4.0947,  ...,  1.9271,  0.9866, -2.7405],\n",
            "        [-4.6812,  0.2271, -7.6987,  ..., -0.6938,  2.7087, -1.7539]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4677, -1.8563,  0.5119,  ...,  3.0287,  1.9722,  0.8033],\n",
            "        [-4.3232,  0.1233, -2.8893,  ..., -0.1436, -1.2756,  0.0593],\n",
            "        [-2.8410,  3.5883, -1.7549,  ..., -2.1287,  2.2611,  0.1601],\n",
            "        ...,\n",
            "        [-2.0935, -3.4234, -3.7138,  ...,  0.8334,  1.1635, -3.0837],\n",
            "        [ 2.4502, -3.1343, -5.1174,  ..., -2.0089, -1.4797, -1.5550],\n",
            "        [-2.5653,  5.0834,  1.4839,  ..., -1.8787,  1.1152, -1.2400]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3502, -0.9499, -1.1184,  ...,  4.5505, -0.5181, -1.3981],\n",
            "        [ 2.6958, -5.9735, -2.5275,  ..., -1.8980, -0.4850, -2.3643],\n",
            "        [-2.2313, -0.6317, -4.5327,  ..., -2.8127, -1.0917,  0.2308],\n",
            "        ...,\n",
            "        [-1.5343, -1.6560, -6.3461,  ...,  0.6164,  1.1233, -4.9551],\n",
            "        [-1.2155, -1.8870,  1.5250,  ..., -1.4129,  1.4064, -0.2963],\n",
            "        [-2.7725, -0.6419, -3.2631,  ...,  1.4956,  2.4739, -0.7930]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3752, -3.8202, -1.0864,  ..., -0.8083,  0.1204, -2.3154],\n",
            "        [-2.6234,  2.0121, -3.0194,  ...,  0.9422,  2.5696, -1.7523],\n",
            "        [-1.8416, -2.8485, -0.6731,  ..., -1.2935,  0.6275, -2.9769],\n",
            "        ...,\n",
            "        [ 0.8034, -0.1170, -2.0599,  ..., -2.2507,  0.1097, -3.2764],\n",
            "        [-2.3020,  2.0245, -2.6213,  ..., -0.7406, -0.1237, -1.3744],\n",
            "        [ 0.4043,  2.0231,  0.5794,  ..., -0.1568, -0.5104, -1.0230]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0873, -0.4128, -4.0745,  ..., -2.9016,  0.7165, -1.7870],\n",
            "        [ 3.6794, -6.5007, -5.1582,  ...,  2.0305,  0.2826, -3.6575],\n",
            "        [ 2.1870, -2.7872, -4.0020,  ...,  3.2746,  1.2089, -1.7263],\n",
            "        ...,\n",
            "        [ 0.5237, -3.9878, -0.7046,  ..., -0.7722,  0.4315, -2.6464],\n",
            "        [-2.0555, -0.8538, -0.9541,  ...,  3.8017,  0.6395,  0.3560],\n",
            "        [-2.6816, -2.8708, -1.6684,  ...,  3.3328,  1.4442, -1.2126]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4487, -7.4162, -7.3572,  ...,  5.6506,  2.2400, -2.4723],\n",
            "        [-1.9792, -1.9287, -2.5357,  ...,  0.0605, -0.5523, -1.6371],\n",
            "        [ 0.5238, -0.3119, -3.7721,  ...,  2.8675,  1.1978, -4.0154],\n",
            "        ...,\n",
            "        [-3.1193,  1.8946, -3.4331,  ...,  2.3963,  2.0692, -0.5873],\n",
            "        [-0.7294, -3.0173, -6.0269,  ...,  3.8763,  1.0069, -2.8834],\n",
            "        [ 1.9190, -3.2119, -5.0442,  ...,  3.6767,  1.3840, -2.3713]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5135, -0.4234, -5.2170,  ...,  0.3447,  2.8397, -0.2208],\n",
            "        [ 2.6310, -5.1349, -4.8847,  ...,  0.4896, -0.7882, -4.3688],\n",
            "        [ 0.8626, -5.2001, -2.7304,  ..., -0.5839,  1.5928, -2.9223],\n",
            "        ...,\n",
            "        [-2.5617, -1.8546, -3.7811,  ..., -5.3781,  0.0631, -3.8217],\n",
            "        [ 3.8161, -2.0086, -0.3437,  ..., -0.5165, -0.6359, -1.4047],\n",
            "        [-2.6557,  5.2813,  2.5437,  ..., -1.8546,  1.0145, -0.5200]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2627, -2.0402, -4.0609,  ..., -0.2807,  0.3543, -1.6386],\n",
            "        [-0.1593, -3.0328, -5.4572,  ...,  3.1568,  4.1336, -4.0831],\n",
            "        [-4.3360, -2.4504, -3.5903,  ...,  2.4122, -0.1010, -0.4030],\n",
            "        ...,\n",
            "        [ 2.5337, -5.9134, -5.7160,  ..., -0.1652, -3.1279, -2.6909],\n",
            "        [-0.5406, -4.8770, -2.0622,  ...,  6.9512,  2.0770, -1.3366],\n",
            "        [-1.6733, -1.1702, -2.4597,  ...,  2.5949,  1.6805, -0.4738]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4776, -0.9901, -2.5977,  ..., -1.4959,  1.7055, -2.9819],\n",
            "        [-4.7556,  2.9230, -4.6647,  ..., -1.4247,  4.9867,  0.6168],\n",
            "        [-1.9184,  3.9578,  1.7579,  ..., -1.8865,  1.0926, -0.9220],\n",
            "        ...,\n",
            "        [-2.6978, -0.2449, -2.5358,  ..., -2.9600, -0.2510, -2.0493],\n",
            "        [-2.3567,  0.0211, -1.8197,  ...,  1.2341,  0.7560, -1.8394],\n",
            "        [-4.4500,  0.9403, -0.5101,  ..., -1.8078,  3.2414, -0.4458]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6156,  0.2122, -2.5428,  ...,  2.8557,  0.2700, -0.7475],\n",
            "        [-1.9094, -2.7315, -0.5708,  ...,  1.8088,  1.6979, -1.6884],\n",
            "        [-2.4384,  0.4385, -1.3641,  ...,  1.1408, -0.0112, -3.2049],\n",
            "        ...,\n",
            "        [-1.1184, -0.6023, -4.2335,  ...,  2.4250,  1.9430, -2.6799],\n",
            "        [-0.5743, -1.6320, -2.5194,  ...,  2.1608,  0.9079, -2.0628],\n",
            "        [ 0.9623, -4.1878, -4.6726,  ...,  0.5099, -0.4890, -3.1990]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5227, -1.3871, -3.4358,  ...,  1.3154,  0.8035, -4.0805],\n",
            "        [-2.7296, -3.7018, -3.9304,  ..., -0.5073,  0.6956, -4.5820],\n",
            "        [-2.7711, -2.5497, -4.3874,  ..., -0.6884,  0.8685, -1.1267],\n",
            "        ...,\n",
            "        [-0.8979,  0.3516, -1.9103,  ..., -1.1723,  0.8821, -0.9008],\n",
            "        [-2.0300,  4.9940,  2.7476,  ..., -3.2950,  1.2011, -2.7083],\n",
            "        [-1.7011, -0.1530, -2.1147,  ..., -2.2338,  1.1419, -0.8848]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0978, -4.6009, -2.2702,  ..., -0.5076, -1.4430,  0.1047],\n",
            "        [-1.3844, -3.0673, -3.0798,  ...,  3.1531,  0.9966, -1.3497],\n",
            "        [-1.7102, -4.0478, -5.7959,  ...,  1.1934,  0.6202, -5.6412],\n",
            "        ...,\n",
            "        [-2.1634, -4.6567, -2.7897,  ..., -1.5247, -0.2130, -2.8069],\n",
            "        [ 1.2252, -1.4195, -3.2568,  ...,  1.0658,  2.2603, -3.5712],\n",
            "        [-1.2342, -0.4397, -2.9172,  ..., -0.4551,  1.7027, -4.5008]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0741,  6.2212,  0.5392,  ..., -2.7580,  3.4441, -3.6819],\n",
            "        [-3.3657,  2.1550, -2.1091,  ..., -3.1517,  4.1591, -3.0661],\n",
            "        [-5.1897,  5.6010, -6.0459,  ...,  0.1322,  3.1153, -0.4957],\n",
            "        ...,\n",
            "        [-1.1758, -1.4613,  3.2610,  ..., -1.1229,  0.2809, -1.6710],\n",
            "        [-3.7811, -0.6999, -3.7182,  ...,  0.8933,  1.1402, -1.6336],\n",
            "        [-3.7575, -4.3819, -4.7255,  ...,  2.5642, -0.6974,  0.9772]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9600,  0.9207, -0.7434,  ..., -4.0586,  1.6055, -3.4909],\n",
            "        [-2.4838,  3.4561,  0.1202,  ..., -2.2789,  1.4974, -4.0544],\n",
            "        [ 1.8947, -4.1241, -3.9509,  ...,  2.6999,  2.0907, -1.2975],\n",
            "        ...,\n",
            "        [ 1.8695, -0.5679, -2.1137,  ..., -0.7406,  2.1688, -2.9058],\n",
            "        [-3.3419, -2.2698, -4.0286,  ..., -0.6507,  3.2413, -3.4820],\n",
            "        [ 0.4599,  0.7169, -2.3711,  ..., -0.8547,  1.0264, -2.1408]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5218e+00,  1.0849e+00, -5.5237e+00,  ..., -7.8229e-01,\n",
            "          5.0763e-02, -2.4244e+00],\n",
            "        [-2.2307e+00,  2.7476e+00, -5.0598e-01,  ..., -2.1245e+00,\n",
            "          1.2146e+00, -3.2750e-01],\n",
            "        [-1.3570e+00, -2.3557e+00, -4.1139e+00,  ..., -9.3446e-01,\n",
            "          7.3789e-01, -3.4831e+00],\n",
            "        ...,\n",
            "        [ 1.1163e+00, -1.9563e+00,  1.5808e+00,  ..., -1.4762e+00,\n",
            "          1.5964e-03, -1.3803e+00],\n",
            "        [-3.0687e+00, -1.0959e+00, -5.3354e+00,  ..., -1.2570e+00,\n",
            "          9.5700e-01, -1.6340e+00],\n",
            "        [-9.2057e-01, -5.5255e-01,  5.3471e-01,  ..., -4.5248e-01,\n",
            "          1.8197e+00, -2.2520e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6634, -3.6631, -2.5904,  ..., -2.1196,  1.0121, -3.7741],\n",
            "        [-2.8890, -3.6742, -5.6710,  ..., -0.9865,  1.6030, -2.6639],\n",
            "        [-2.7932, -5.0453, -6.0973,  ..., -2.6810,  2.3773, -4.1111],\n",
            "        ...,\n",
            "        [-1.3442, -4.1921, -4.0817,  ..., -1.9455,  1.0184, -4.3795],\n",
            "        [-3.6626,  1.9857, -2.9982,  ...,  0.7890,  3.0834, -1.4793],\n",
            "        [-2.1100,  1.3668,  1.0903,  ..., -1.8077,  0.2479, -1.8869]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.3432,  5.1321, -1.9219,  ..., -1.2863,  3.5046, -2.5065],\n",
            "        [-6.4487,  3.5920, -2.2703,  ..., -0.0801,  5.7090, -1.2180],\n",
            "        [-1.6451, -1.1670, -0.6190,  ...,  1.1565, -1.6685, -3.4383],\n",
            "        ...,\n",
            "        [-3.5448, -0.3866, -4.4218,  ..., -1.7484,  1.8431, -3.5201],\n",
            "        [-0.9831, -1.1508, -1.7887,  ..., -0.4699,  2.0260, -4.0816],\n",
            "        [-0.5010, -6.6005, -3.7990,  ...,  2.1278,  1.7169, -4.0268]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.4439,  0.6926, -2.9032,  ..., -1.2157,  4.3802, -5.1261],\n",
            "        [-1.7631, -0.3199, -1.1650,  ..., -0.7853,  2.5645, -4.6926],\n",
            "        [-4.0584,  0.8388, -3.6640,  ..., -1.2434,  2.5643, -3.8134],\n",
            "        ...,\n",
            "        [-2.7504,  0.3220, -1.7070,  ..., -0.7461,  2.0603, -1.7221],\n",
            "        [ 2.5159, -1.1943, -0.0088,  ..., -0.3190,  2.0423, -2.0525],\n",
            "        [-0.2360, -0.2926, -1.5240,  ..., -0.1990,  1.7211, -3.3499]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6310, -0.6296, -3.1647,  ..., -3.4007,  0.7536, -2.1318],\n",
            "        [-3.1857, -1.8827, -3.4255,  ..., -0.8097,  1.5831, -2.7509],\n",
            "        [ 3.4932, -2.6698,  0.5712,  ...,  0.6388, -3.1999, -1.5387],\n",
            "        ...,\n",
            "        [ 2.9507, -9.6023, -6.9711,  ..., -1.1172, -3.1352, -3.9211],\n",
            "        [-0.6691,  1.2804, -1.3262,  ..., -3.5870,  2.1852, -3.2282],\n",
            "        [ 1.0040, -0.5908, -4.2421,  ...,  2.2153, -0.0372, -2.3472]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3946, -3.8274, -3.9397,  ..., -0.8483, -2.8619, -2.0119],\n",
            "        [ 2.2287, -3.5810, -3.1407,  ...,  2.0288,  1.5276, -1.7522],\n",
            "        [-0.4608, -4.3343, -5.2630,  ...,  3.9432,  2.3327, -2.3867],\n",
            "        ...,\n",
            "        [-2.0213, -1.3847, -3.4118,  ...,  2.0935,  1.1796, -1.3004],\n",
            "        [-4.6503, -4.8268, -7.1904,  ...,  1.4136, -1.4934, -3.4739],\n",
            "        [-2.4917,  3.5927,  3.5082,  ..., -0.4882,  1.4108, -1.5123]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5341,  2.5069, -0.6618,  ..., -3.8150,  0.7143, -1.1014],\n",
            "        [-4.0100, -2.2944, -2.3141,  ..., -2.1940,  1.9645, -0.7472],\n",
            "        [-0.9296, -6.0206, -4.6897,  ...,  2.3618,  0.1441, -2.8255],\n",
            "        ...,\n",
            "        [-3.4418, -2.0889,  0.0203,  ...,  2.4914,  0.8459, -0.6123],\n",
            "        [-1.6031,  0.3978, -1.1177,  ..., -0.3425,  2.4555, -0.5318],\n",
            "        [-1.1812,  2.4127,  0.8823,  ..., -2.4232,  0.9968, -1.8066]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6201, -1.5494, -0.8500,  ...,  0.3260,  0.3074, -1.1832],\n",
            "        [ 2.8903, -6.0293, -3.0594,  ...,  1.9412,  1.5113, -3.4396],\n",
            "        [-4.3872,  1.0815, -1.5262,  ..., -2.5307,  2.2624, -0.7886],\n",
            "        ...,\n",
            "        [-0.5290, -1.7697, -4.2464,  ...,  4.9076,  3.7560, -2.6712],\n",
            "        [-3.4487, -1.1939, -5.7310,  ..., -1.7260,  4.1815, -2.0208],\n",
            "        [-1.2949,  0.0645, -6.5515,  ...,  0.7699,  2.8118, -2.8454]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3420, -1.9343, -3.2646,  ..., -2.0410, -3.2238, -2.3806],\n",
            "        [-2.7593, -2.3658, -4.7726,  ...,  1.4557, -2.2879, -2.6589],\n",
            "        [-3.9611,  3.6998, -1.2032,  ..., -0.8427,  2.3021, -3.4700],\n",
            "        ...,\n",
            "        [ 0.4430, -1.4654, -3.5897,  ..., -1.2063,  0.9657, -3.6466],\n",
            "        [-0.6140, -0.2314, -3.0977,  ..., -1.5629,  3.5895, -3.2370],\n",
            "        [-2.0853, -1.8040, -2.0213,  ..., -0.0982,  0.2838,  0.2841]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0864,  2.7056, -0.4369,  ..., -1.6633,  0.7173, -2.1391],\n",
            "        [-3.0340, -0.7069, -0.9646,  ..., -2.6088,  0.2404, -3.2801],\n",
            "        [-0.5359, -3.0502, -1.6861,  ...,  1.9569,  2.6834, -2.6008],\n",
            "        ...,\n",
            "        [ 1.6730, -7.2294, -6.9344,  ..., -1.0376, -2.4203, -4.7651],\n",
            "        [-0.8256, -4.7509, -3.5498,  ...,  1.5035,  0.5694, -2.2609],\n",
            "        [-1.0904, -1.5170, -3.6907,  ...,  4.2454,  1.9304, -2.3142]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "826e171b8de24ae28ae08f07284cff68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5144, -2.7416, -2.2263,  ...,  1.0610,  0.5796, -0.5486],\n",
            "        [ 1.3817, -2.8949, -3.2656,  ..., -0.8984,  1.7492, -1.8232],\n",
            "        [-1.4215, -1.7580, -3.1262,  ..., -1.1466,  3.3759, -1.3490],\n",
            "        ...,\n",
            "        [-2.4284, -2.8582, -2.3655,  ..., -0.3573,  4.5322, -2.7178],\n",
            "        [-4.6788,  3.2510, -2.0306,  ..., -1.4704,  0.4308,  0.3163],\n",
            "        [-2.1413, -0.7277, -4.5637,  ...,  2.2866,  2.9118, -1.1668]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7671, -0.4559, -1.6202,  ...,  3.0284, -1.2079, -0.2395],\n",
            "        [ 1.3636, -4.6144, -4.1841,  ..., -1.0395, -0.9140, -2.7744],\n",
            "        [ 0.5835, -0.0848, -3.1430,  ..., -0.3005,  1.9202, -2.9604],\n",
            "        ...,\n",
            "        [ 0.4852, -1.8511, -4.6372,  ...,  1.0966,  0.2001, -1.7958],\n",
            "        [-2.8224,  1.2258, -0.7610,  ..., -1.0834,  1.2393, -2.8407],\n",
            "        [-3.2259, -1.4668, -1.8257,  ..., -2.4012,  1.1210, -2.1537]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8859, -3.5493, -5.3630,  ...,  4.4526,  2.7244, -2.2044],\n",
            "        [ 0.3781, -2.3315, -2.5531,  ...,  0.1921, -1.1924, -1.7150],\n",
            "        [-5.2963,  6.5154, -0.6995,  ..., -2.1258,  3.7882, -2.1975],\n",
            "        ...,\n",
            "        [-0.4924,  1.0591, -2.0905,  ..., -1.3097,  2.1470, -2.7423],\n",
            "        [-5.4764, -1.1864, -3.8446,  ...,  1.0154,  1.5443, -3.1027],\n",
            "        [-3.1010, -0.4436, -0.3892,  ..., -4.0309,  0.2403, -1.9662]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7918, -4.8676, -5.9660,  ..., -1.3043,  1.4152, -3.1374],\n",
            "        [-4.0327, -3.7616, -4.0607,  ...,  0.8785,  3.8391, -5.7487],\n",
            "        [-1.2529, -1.3592, -4.5880,  ...,  0.6109,  2.4798, -4.3907],\n",
            "        ...,\n",
            "        [-2.7604,  2.9015,  3.1611,  ..., -2.2428,  0.5443, -2.7657],\n",
            "        [-2.6714, -2.1902, -1.5504,  ...,  7.8339,  1.9103, -0.6135],\n",
            "        [-1.2386, -3.3124, -2.0840,  ...,  3.4426,  1.2192, -0.1944]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0024, -1.2975, -6.2485,  ..., -0.0915,  2.2456, -1.1450],\n",
            "        [ 4.8185, -6.6064, -1.5744,  ..., -0.7199,  1.4229, -4.4949],\n",
            "        [-2.2364, -0.7491, -1.4084,  ..., -2.2207,  0.4309, -1.2609],\n",
            "        ...,\n",
            "        [-2.2162,  3.8053,  4.1579,  ..., -1.7057,  0.9726, -1.7185],\n",
            "        [-4.4526,  1.6718, -0.7828,  ..., -0.7524,  1.4154, -4.4415],\n",
            "        [-0.7436, -2.7307, -6.4048,  ...,  1.3907,  1.9388, -3.4523]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1389, -6.4523, -3.0631,  ...,  0.1358,  0.5185, -2.2652],\n",
            "        [-1.7047,  2.7377,  1.5276,  ..., -1.2265,  0.5603, -2.1250],\n",
            "        [-2.0889,  3.2539, -0.3110,  ..., -1.9021,  1.0516, -2.1468],\n",
            "        ...,\n",
            "        [-2.9652,  2.0789, -3.2499,  ..., -0.6849,  2.4333,  0.1620],\n",
            "        [ 0.6040, -0.3221,  3.0155,  ...,  1.7211,  0.2766, -1.8693],\n",
            "        [ 2.5601, -6.4180, -2.2131,  ...,  2.8650, -0.9292, -3.1538]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.7504, -4.9447, -2.2242,  ..., -0.4896, -0.0496, -4.7588],\n",
            "        [ 1.0572, -4.5397, -2.1765,  ..., -2.5433,  4.7526, -5.1456],\n",
            "        [-2.8643, -1.6670,  0.4143,  ..., -2.1058,  1.4880, -0.2496],\n",
            "        ...,\n",
            "        [ 1.0915, -4.4123, -1.8474,  ..., -0.5528, -2.3140, -2.6542],\n",
            "        [-2.7305,  4.9287,  2.6673,  ..., -2.3401,  1.9541, -1.7160],\n",
            "        [-0.6082, -2.3971, -1.6639,  ..., -1.5812, -0.2512, -2.5591]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2465, -5.4145, -2.9352,  ...,  1.4113,  1.7956,  0.2979],\n",
            "        [-1.2610,  0.0993, -0.4095,  ..., -4.5218,  1.7278, -2.0189],\n",
            "        [ 3.7083, -5.3929, -4.4759,  ...,  3.1536,  1.5622, -2.9061],\n",
            "        ...,\n",
            "        [-4.9703, -0.1298,  0.4522,  ..., -1.9381, -0.2349, -1.6864],\n",
            "        [-2.6200,  1.1332, -1.3511,  ..., -0.6608, -1.1953, -0.3071],\n",
            "        [-1.2435, -4.1087, -2.9782,  ...,  0.6187,  0.4810, -3.1694]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3078, -1.7790, -0.6488,  ..., -0.6841,  0.8859, -1.1508],\n",
            "        [-3.2327,  0.3872, -0.0589,  ..., -1.7725,  2.8070, -0.5670],\n",
            "        [-4.3624, -5.1928, -3.7577,  ...,  0.1915,  0.9504, -3.4805],\n",
            "        ...,\n",
            "        [ 3.8062, -4.4372, -3.5686,  ...,  2.7339,  1.2792, -2.1838],\n",
            "        [ 1.4319, -2.5207,  0.5574,  ...,  2.2018, -0.4218, -2.3231],\n",
            "        [ 0.7382, -6.4414, -4.1174,  ...,  0.6227, -2.2672, -3.0354]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0548,  0.5297, -0.5036,  ..., -2.3451,  1.9819, -2.2066],\n",
            "        [-4.1557,  1.4512, -0.6190,  ...,  0.3554, -1.6768, -2.4935],\n",
            "        [-1.0725, -3.2260, -1.9256,  ...,  0.1665,  1.2460, -3.8201],\n",
            "        ...,\n",
            "        [-3.8483, -0.4243, -2.6684,  ...,  1.0712,  0.5184, -0.2323],\n",
            "        [ 6.6232, -6.6411, -2.4262,  ...,  6.3976,  0.5478,  0.0561],\n",
            "        [-7.6917,  2.1445, -3.2077,  ...,  0.0870,  2.1462, -1.1083]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6703, -2.4249, -5.7723,  ...,  4.0751,  3.0357, -2.9940],\n",
            "        [-1.7604,  4.2222,  3.5314,  ..., -0.6030,  1.5387, -1.9775],\n",
            "        [-1.3580, -3.6245, -0.3688,  ...,  1.4150, -0.9294, -2.2603],\n",
            "        ...,\n",
            "        [-2.3452,  1.4710,  1.9608,  ...,  0.5275, -0.9211, -0.5035],\n",
            "        [-6.6717,  2.0199, -1.5992,  ...,  0.2003, -1.0914,  0.7063],\n",
            "        [-1.3142, -3.8246, -0.7262,  ...,  5.8626,  1.9438, -0.3321]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9556e+00,  3.3137e+00, -7.9802e-01,  ..., -1.7100e+00,\n",
            "          2.2849e+00,  1.6002e-01],\n",
            "        [ 2.5860e+00, -5.6256e+00, -3.2875e+00,  ...,  7.2132e+00,\n",
            "          3.3407e+00,  1.3338e+00],\n",
            "        [-3.9594e-01,  9.9395e-01,  2.2393e-02,  ..., -1.5319e+00,\n",
            "          5.6432e-01, -2.7092e+00],\n",
            "        ...,\n",
            "        [-2.0234e+00,  1.0473e+00, -1.1853e+00,  ..., -1.7553e+00,\n",
            "         -1.1331e+00,  1.4862e+00],\n",
            "        [-7.6937e-01, -4.9807e+00, -2.4406e+00,  ..., -1.3617e+00,\n",
            "          2.5661e+00, -4.8893e+00],\n",
            "        [-2.0413e+00, -3.0226e+00, -3.9211e+00,  ...,  1.6793e+00,\n",
            "         -6.2950e-03, -3.7220e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6863, -2.4015, -1.3285,  ...,  3.4863, -0.7460, -1.0217],\n",
            "        [-1.5613, -1.4970, -2.0287,  ..., -0.6961,  0.8382, -1.1337],\n",
            "        [-3.3959, -2.7780, -0.0434,  ..., -0.8224, -0.2569, -4.2145],\n",
            "        ...,\n",
            "        [ 0.6542, -3.9484, -5.3351,  ...,  2.9184, -0.2988, -4.1558],\n",
            "        [-0.3803, -1.3119, -3.5339,  ...,  5.4561,  0.8593, -2.5279],\n",
            "        [-4.4219, -0.6695, -1.1103,  ...,  1.1969,  3.1694, -4.5526]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0504, -0.8470, -0.7747,  ...,  0.5461,  1.8716, -2.4167],\n",
            "        [ 1.0092, -0.3666, -2.9959,  ..., -0.2725,  0.5377, -0.9705],\n",
            "        [-1.4636, -3.6234, -4.4153,  ...,  0.4196, -0.0162, -3.2492],\n",
            "        ...,\n",
            "        [-1.6640, -4.8257, -0.3221,  ..., -0.8811,  0.1315, -1.9935],\n",
            "        [-1.6948,  0.2123, -2.0659,  ..., -3.0533,  0.3168, -1.5325],\n",
            "        [ 3.8069, -5.4179, -4.6030,  ...,  3.3273,  2.5182, -3.0727]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0937e+00,  3.0568e+00, -7.7390e-01,  ..., -1.6547e+00,\n",
            "          2.2099e+00, -2.5743e+00],\n",
            "        [-3.3077e+00,  3.9080e+00,  6.8047e-01,  ..., -2.0079e+00,\n",
            "          7.7617e-01, -3.1047e-01],\n",
            "        [-5.2311e+00, -2.6793e+00, -3.9154e+00,  ...,  5.6068e+00,\n",
            "          3.0685e+00,  2.1702e+00],\n",
            "        ...,\n",
            "        [-2.0282e+00,  2.1490e+00,  8.4913e-01,  ..., -3.2606e+00,\n",
            "         -2.0175e+00, -4.9170e-03],\n",
            "        [-8.7328e-01, -1.3388e+00, -5.3420e+00,  ..., -1.2889e+00,\n",
            "          2.8955e+00, -4.6407e+00],\n",
            "        [-1.2692e+00, -2.9051e+00,  3.7752e-01,  ..., -4.0765e-01,\n",
            "          2.5374e+00, -3.3494e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6019, -0.8000, -2.8061,  ..., -0.0292,  3.2185, -4.4503],\n",
            "        [-3.1000,  0.2088,  1.5548,  ..., -2.0220,  1.8641,  0.2477],\n",
            "        [-5.4042,  6.1342, -0.7862,  ..., -0.7117,  2.3491, -4.1154],\n",
            "        ...,\n",
            "        [-1.0870,  3.0082, -0.4669,  ..., -2.0823,  1.7816, -0.5088],\n",
            "        [-4.0689, -0.1984, -0.7440,  ...,  0.2135,  2.5695, -4.6731],\n",
            "        [ 0.6208, -3.2582, -0.3225,  ..., -1.3505,  0.6362, -3.6456]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8090, -2.6549, -4.1345,  ...,  0.2798,  0.7789, -1.8123],\n",
            "        [ 0.5360, -2.5447, -5.8607,  ...,  0.4268, -0.0477, -2.7342],\n",
            "        [ 0.1527, -2.2773, -5.3947,  ...,  0.8890, -0.8759, -3.8253],\n",
            "        ...,\n",
            "        [ 0.0376, -6.2436, -3.6647,  ..., -1.6523,  1.5693, -6.0396],\n",
            "        [-0.5540, -4.0210, -3.9408,  ...,  0.0697, -1.5011, -1.2808],\n",
            "        [-0.7028,  0.3736, -2.8909,  ..., -0.5473,  2.0036, -1.5335]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7861, -2.3948, -0.8917,  ..., -0.0343,  1.2938, -1.1255],\n",
            "        [-4.1236, -1.2914, -3.2108,  ...,  0.2992,  3.2164, -1.7423],\n",
            "        [-2.3232, -3.3880, -3.5674,  ..., -0.9509,  2.5600, -2.6508],\n",
            "        ...,\n",
            "        [ 2.7332, -6.9207, -6.0516,  ...,  0.5714, -0.5719, -5.5534],\n",
            "        [-1.3192, -0.8984,  4.1092,  ..., -1.9458,  0.5414, -0.1983],\n",
            "        [ 0.9666, -5.9319, -5.4238,  ...,  4.2487,  1.9063, -4.9513]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6594,  4.5070,  4.1391,  ...,  0.0983,  1.0079, -1.0359],\n",
            "        [ 1.3526, -1.0224, -1.7006,  ...,  0.6722,  2.5362, -2.2096],\n",
            "        [-4.3386,  0.5256, -2.8476,  ...,  0.5955,  3.5795, -4.4911],\n",
            "        ...,\n",
            "        [-1.9603, -1.1941, -2.8855,  ..., -0.8665,  2.6048, -3.3615],\n",
            "        [-1.6369,  3.5594,  4.2955,  ..., -1.2743,  1.4564, -1.5587],\n",
            "        [-3.6968, -0.5073, -0.2286,  ..., -1.6030,  2.2752, -3.6512]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8562e+00, -5.8861e-01, -6.4865e-01,  ...,  3.2104e+00,\n",
            "          2.1350e+00, -9.8665e-01],\n",
            "        [-6.1840e-01, -3.6897e-03,  2.0898e+00,  ..., -1.8002e+00,\n",
            "          2.3655e+00, -1.2820e+00],\n",
            "        [-2.0967e+00, -5.9268e+00, -5.9371e+00,  ...,  7.1452e-01,\n",
            "         -8.5278e-01, -2.9655e+00],\n",
            "        ...,\n",
            "        [ 2.2290e+00, -2.3422e+00, -2.9533e+00,  ..., -1.1135e+00,\n",
            "          2.5901e+00, -3.9987e+00],\n",
            "        [-3.1725e-01, -5.8044e+00, -4.7537e+00,  ..., -2.0829e-02,\n",
            "          1.3032e+00, -5.9333e+00],\n",
            "        [-2.3946e+00,  2.5379e+00,  2.2121e+00,  ..., -9.8111e-01,\n",
            "          8.9227e-01, -1.8605e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0971, -1.6468, -3.5497,  ..., -1.6487,  1.2797, -4.6982],\n",
            "        [-0.6562, -5.0455, -2.7315,  ...,  3.6228,  0.8424, -1.8824],\n",
            "        [-3.1841, -2.6326, -0.5471,  ..., -0.4631,  1.8680, -4.2252],\n",
            "        ...,\n",
            "        [-1.6021, -4.3791, -6.2811,  ...,  2.3929,  0.8182, -4.0764],\n",
            "        [-1.3099, -2.8884, -2.6052,  ..., -2.0616, -0.4114, -2.7204],\n",
            "        [-0.6752, -3.5163, -2.0405,  ...,  0.7564, -1.1858, -2.9083]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6558,  4.2785, -0.7104,  ..., -1.4367, -0.5503,  0.9209],\n",
            "        [-2.6824,  3.5709,  2.6184,  ..., -2.7339,  1.2790, -2.1238],\n",
            "        [-2.3920,  3.7491,  3.8499,  ..., -1.7952,  1.4092, -1.5282],\n",
            "        ...,\n",
            "        [ 0.5600, -3.7718, -3.6098,  ...,  0.3726,  1.6033, -5.1217],\n",
            "        [-0.9928, -2.3439, -4.9804,  ...,  3.5024, -0.7128, -4.0316],\n",
            "        [-2.0871, -0.2693, -0.9130,  ..., -0.5780,  0.2984, -1.9030]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7437, -1.5471, -4.7035,  ...,  1.4556,  3.1261, -4.6835],\n",
            "        [-3.4215,  0.1559, -0.5088,  ..., -2.3086,  1.3737, -0.7107],\n",
            "        [-0.5436, -2.2560,  1.2545,  ..., -2.8066,  2.7897, -2.8015],\n",
            "        ...,\n",
            "        [-0.4689, -1.0732,  1.0719,  ...,  1.4915,  0.0373, -1.1147],\n",
            "        [-2.6522,  4.3222,  4.8352,  ..., -2.7596,  1.2776, -1.8074],\n",
            "        [-3.8500,  0.4602, -0.1238,  ..., -0.6141,  3.3555,  0.8392]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4556, -3.0640, -2.1992,  ..., -1.9886,  0.3346, -3.4365],\n",
            "        [ 3.8997, -7.1493, -2.3685,  ...,  2.3750,  1.4217, -3.3107],\n",
            "        [-0.3492, -2.2171, -1.3718,  ..., -3.1096,  1.2562, -4.0810],\n",
            "        ...,\n",
            "        [-2.2157, -2.1247, -0.7524,  ..., -1.7001,  0.9149, -1.2179],\n",
            "        [-4.7591, -4.4255, -4.3213,  ...,  1.9573,  0.6954, -4.4883],\n",
            "        [-1.7086, -1.7804,  5.0120,  ..., -2.6060,  0.7525, -1.1816]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.4933e+00, -6.2838e-01, -9.5094e-01,  ..., -1.8695e+00,\n",
            "          1.8090e+00,  6.8231e-03],\n",
            "        [-3.6129e+00, -4.6272e+00, -2.4760e+00,  ..., -3.2882e-01,\n",
            "          6.8957e-02, -3.0679e+00],\n",
            "        [-5.1893e+00,  1.9301e+00, -3.8447e-01,  ...,  8.6090e-01,\n",
            "          1.2022e+00,  5.8625e-01],\n",
            "        ...,\n",
            "        [-2.1670e+00, -3.0121e+00, -3.1466e+00,  ...,  3.5937e-01,\n",
            "          1.0493e+00, -2.7300e+00],\n",
            "        [-3.3177e+00,  1.9372e+00, -1.6894e+00,  ..., -2.0479e+00,\n",
            "          1.7096e+00, -4.5476e-01],\n",
            "        [-2.0371e+00, -8.2914e+00, -2.5048e+00,  ...,  5.3885e+00,\n",
            "          1.7610e+00, -3.3767e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7000, -2.3280, -1.1323,  ...,  0.0469, -0.0889, -0.5185],\n",
            "        [ 0.6710, -0.9872, -1.8170,  ..., -1.2859,  4.1272, -1.1137],\n",
            "        [ 0.2949, -6.6099, -3.4177,  ..., -2.2602,  3.1622, -3.3552],\n",
            "        ...,\n",
            "        [-3.3456, -1.9343, -1.6958,  ..., -0.8079, -0.2570, -0.7783],\n",
            "        [-1.7944, -4.1000, -2.1814,  ...,  0.4591,  4.1849, -5.0568],\n",
            "        [-3.5757,  0.1799, -2.0411,  ..., -0.0373,  2.4333, -3.7285]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0028, -5.5483, -3.0773,  ...,  1.8525,  3.0628, -3.3906],\n",
            "        [ 3.4638, -6.0678, -4.2941,  ...,  2.1458,  3.3011, -3.7270],\n",
            "        [-2.7342, -1.4595, -2.4615,  ..., -0.4995,  0.3104, -0.3437],\n",
            "        ...,\n",
            "        [-1.2308, -2.0221, -2.0780,  ...,  0.1883,  0.3882, -2.3597],\n",
            "        [-2.2302, -2.5171, -1.9980,  ..., -0.9493, -1.6953, -1.2333],\n",
            "        [-1.7559, -1.2463, -2.8222,  ..., -0.3959,  1.9019, -3.2633]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0403, -2.8640, -3.5381,  ...,  1.9173,  3.3976, -2.2853],\n",
            "        [-2.7419, -4.4976, -2.3986,  ...,  5.8999,  3.3866, -1.1214],\n",
            "        [-3.3473,  0.2307, -3.5264,  ..., -1.6779,  1.5102, -0.8502],\n",
            "        ...,\n",
            "        [ 0.2028, -5.4765, -5.3063,  ...,  1.3432, -1.1006, -4.8540],\n",
            "        [ 0.6394, -2.8239, -3.7256,  ...,  1.0607,  2.5415, -2.6746],\n",
            "        [-3.4410,  0.1608, -2.2189,  ..., -2.1863,  0.7022, -3.3285]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1303, -3.9234, -5.6124,  ...,  4.3611,  1.6703, -2.4612],\n",
            "        [-2.4429,  3.5242,  3.1470,  ..., -1.5854,  1.8288, -0.6567],\n",
            "        [-3.6887,  0.8494, -0.9429,  ..., -2.0666,  2.6403, -0.9906],\n",
            "        ...,\n",
            "        [ 1.2207, -3.9333, -2.4999,  ..., -1.3715,  1.6481, -1.1234],\n",
            "        [ 0.4450, -2.7039, -0.7135,  ...,  0.7757,  1.6177, -1.5503],\n",
            "        [-2.6747, -3.4338, -2.4486,  ..., -0.6061,  0.2016, -0.2183]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9645,  1.5429,  0.9258,  ..., -1.4122, -0.1271, -1.3382],\n",
            "        [ 1.9612, -3.6447,  0.9864,  ..., -0.7316,  2.2544, -1.7889],\n",
            "        [-1.7748, -5.1358, -4.5139,  ..., -1.6287,  1.3533, -3.9411],\n",
            "        ...,\n",
            "        [-5.1381, -1.5916, -0.4693,  ..., -0.3863,  2.5946, -4.7686],\n",
            "        [-3.8344,  0.2608, -2.1371,  ...,  1.4785,  0.4326, -0.2101],\n",
            "        [-2.9106, -3.2111, -3.1609,  ...,  1.0017,  2.0855, -0.8875]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1472, -1.6071, -2.7197,  ..., -1.0538,  2.0114, -2.5090],\n",
            "        [-1.7343,  3.4796, -0.1373,  ...,  0.0205,  2.0244, -0.5872],\n",
            "        [-2.7258, -2.2088, -3.2666,  ...,  3.3958,  3.3063, -2.1265],\n",
            "        ...,\n",
            "        [-1.5628,  4.2521,  4.1575,  ..., -3.0126,  1.0004, -1.8392],\n",
            "        [-5.9012, -0.2440, -1.1607,  ..., -0.6394,  3.0704, -4.2634],\n",
            "        [-4.2781, -4.8888, -4.6090,  ...,  0.5119,  1.9987, -3.2657]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8537, -8.8377, -5.5304,  ...,  3.0000,  1.8285, -3.9358],\n",
            "        [-1.3477, -1.4186, -1.3345,  ..., -1.8035,  1.7358, -0.1369],\n",
            "        [-3.4485,  3.0801,  1.6029,  ..., -3.2021,  2.1925, -0.3459],\n",
            "        ...,\n",
            "        [-0.9930, -2.5374, -2.1086,  ..., -1.6016, -0.2191, -0.9675],\n",
            "        [-5.8791, -1.1708, -2.3105,  ...,  0.9258,  0.3277, -1.3193],\n",
            "        [-6.1902, -0.2549, -1.3011,  ..., -1.4636,  0.8387, -1.5701]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7108, -5.9627, -3.1659,  ..., -0.1217, -1.5343, -1.8056],\n",
            "        [ 1.9337, -0.1678, -1.9400,  ..., -3.2804,  1.6341, -3.5584],\n",
            "        [-0.6853, -7.0395, -0.9635,  ..., -0.4202,  0.4256, -0.6325],\n",
            "        ...,\n",
            "        [-2.6390, -1.2833, -5.6821,  ..., -0.3911, -0.6165, -1.1256],\n",
            "        [-0.0384, -1.3497, -2.2194,  ...,  1.7211,  1.2093, -1.8846],\n",
            "        [-3.4161,  0.0832, -5.2566,  ..., -0.2695,  3.3124, -1.5087]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5118, -4.6083, -4.6684,  ..., -0.3152,  0.5654, -4.6024],\n",
            "        [-4.8339,  4.2730, -0.1225,  ..., -0.5710,  2.1516, -1.4481],\n",
            "        [-1.9975,  3.4680,  3.4158,  ..., -0.1308,  1.5056, -0.8365],\n",
            "        ...,\n",
            "        [-3.7865,  1.5206,  2.1936,  ..., -4.0427,  2.2023, -1.7510],\n",
            "        [-3.1178,  3.5850,  0.3613,  ..., -2.9997,  1.5025,  0.1282],\n",
            "        [-3.0977,  0.8506,  0.3424,  ..., -3.0115,  0.9469, -0.2095]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7157,  1.2168,  0.9649,  ..., -1.2233,  1.7662, -2.6460],\n",
            "        [-1.3672, -3.1605, -7.2519,  ...,  3.3192,  2.0789, -1.7258],\n",
            "        [-2.5474,  1.5800, -2.5279,  ...,  0.2873,  5.4301, -0.6806],\n",
            "        ...,\n",
            "        [-2.4889,  3.2992,  4.4365,  ..., -3.9533,  1.8667, -1.0519],\n",
            "        [-3.2024, -4.4382, -2.5797,  ..., -3.9485,  1.3052, -4.6609],\n",
            "        [-0.5584, -1.5799, -1.7138,  ..., -2.1259,  2.9342, -0.7480]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7728, -6.0852, -1.3501,  ..., -0.8379,  1.7449, -3.2377],\n",
            "        [-3.7246, -4.2670, -1.6054,  ..., -0.2106,  1.6298, -3.6606],\n",
            "        [-0.7609, -1.7046,  0.4073,  ..., -2.8533,  1.4131, -1.4529],\n",
            "        ...,\n",
            "        [-6.7754,  6.0278, -0.8137,  ..., -0.0938,  3.0843,  0.6015],\n",
            "        [-4.3479, -2.3525,  1.7288,  ..., -5.2167, -0.3073, -0.9113],\n",
            "        [-4.6367,  1.2420, -0.2641,  ..., -3.6919,  5.1404, -6.0847]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0097, -0.6073, -0.9391,  ..., -1.9723,  2.2104, -0.9524],\n",
            "        [-2.3717, -1.5469, -2.9377,  ..., -0.8298,  2.5041, -2.2044],\n",
            "        [ 3.2369, -5.5065, -4.2474,  ...,  0.6366,  1.3579, -3.6545],\n",
            "        ...,\n",
            "        [-3.7689, -2.8122, -3.9545,  ...,  0.8413,  2.5619, -3.6874],\n",
            "        [-3.8943, -3.7812, -3.3930,  ..., -0.5117,  1.5715, -5.6686],\n",
            "        [ 1.9967, -6.3441, -3.6170,  ..., -1.3227, -2.7494, -1.4813]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.9517,  0.5460, -2.2470,  ...,  2.8124,  2.6000,  0.0293],\n",
            "        [ 2.3895, -1.6423, -2.2281,  ...,  1.6696,  1.5377, -0.7131],\n",
            "        [-0.7921, -5.6789, -1.5673,  ..., -1.1098,  4.0346, -3.6425],\n",
            "        ...,\n",
            "        [-0.3658, -9.6283, -3.4639,  ...,  7.4254, -0.3527, -2.5947],\n",
            "        [-1.6539,  1.1709, -0.2265,  ..., -3.0407,  0.9514, -0.0588],\n",
            "        [-2.8503,  2.1973,  1.1334,  ..., -3.5268,  1.9115, -1.8052]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1580, -3.3746, -2.3247,  ..., -2.6425,  3.6709, -0.6422],\n",
            "        [-2.6203, -0.0862, -0.4912,  ..., -1.7578,  2.5163,  0.3220],\n",
            "        [ 0.5999, -4.6742, -5.3678,  ...,  4.6132,  0.2758,  0.8495],\n",
            "        ...,\n",
            "        [-0.9243, -3.1961, -8.9714,  ...,  2.2667,  0.7765, -3.5672],\n",
            "        [-1.5747, -5.6261, -3.3777,  ...,  1.4086,  2.9468, -1.5518],\n",
            "        [-2.1694, -2.1467, -4.1857,  ..., -2.9431,  2.7441, -2.5539]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6132,  0.2940, -0.3219,  ...,  0.3781, -2.4136,  0.6740],\n",
            "        [ 2.9177, -8.4494, -4.0409,  ...,  1.4342,  2.7922, -3.3565],\n",
            "        [ 2.6500, -4.4814, -3.0715,  ...,  2.1191,  2.5875, -0.7849],\n",
            "        ...,\n",
            "        [-3.0115,  3.7596,  0.2998,  ..., -0.2094,  0.1093,  0.1853],\n",
            "        [-3.1629,  1.5430,  0.4770,  ..., -3.8126,  2.4293,  1.2917],\n",
            "        [-3.0459, -0.8114,  1.0983,  ..., -1.5471,  4.0778,  2.6254]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6004, -0.5270, -1.9174,  ..., -1.4175,  3.2612, -5.6961],\n",
            "        [-1.9772,  0.5211, -1.7978,  ..., -3.4841,  1.0737, -0.7339],\n",
            "        [ 2.5831, -5.3647, -3.1612,  ...,  0.7102,  0.3486, -3.2655],\n",
            "        ...,\n",
            "        [-3.0169,  0.0083, -1.9178,  ..., -0.5512,  2.4019, -2.3746],\n",
            "        [-0.6378, -5.1594, -4.8328,  ...,  1.1649,  3.6591, -3.8786],\n",
            "        [-2.0157,  0.8023, -1.2508,  ..., -3.0049,  0.9217, -0.8345]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-6.0323,  0.0220,  0.9665,  ...,  2.1243,  3.1283, -1.3286],\n",
            "        [ 0.6945, -3.7299, -1.7759,  ..., -0.2128, -0.6317, -3.0768],\n",
            "        [-3.4906, -2.6920, -3.4261,  ..., -1.0363,  1.2894,  1.9726],\n",
            "        ...,\n",
            "        [ 1.3088, -5.3093, -7.2221,  ..., -0.3824,  0.9487, -3.6602],\n",
            "        [-3.3881, -3.6571, -2.8308,  ..., -0.0462,  1.4279, -2.3229],\n",
            "        [-2.3273,  0.1034, -1.8514,  ..., -2.4124,  3.6025,  0.2406]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0814,  3.0032,  1.5878,  ..., -1.7413,  2.1330, -0.0962],\n",
            "        [ 3.9922, -6.6782, -1.2589,  ...,  0.5296,  0.2566, -4.1243],\n",
            "        [-1.5483,  4.7417,  3.8522,  ..., -1.8667,  0.9823, -0.7588],\n",
            "        ...,\n",
            "        [-3.0731, -1.4284, -1.2988,  ..., -1.4751,  3.3332, -3.3643],\n",
            "        [-1.0787, -4.4577, -0.0850,  ...,  0.7240, -0.0101, -0.6722],\n",
            "        [-4.5333, -3.1879, -1.0336,  ...,  0.7023,  0.6541,  0.0364]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.8111,  1.6006, -2.8339,  ..., -2.8364,  1.3169,  0.7489],\n",
            "        [-3.5490, -5.0887, -4.0420,  ...,  1.2391,  1.6678, -4.0597],\n",
            "        [-2.5391, -8.5689, -7.9969,  ...,  2.5328,  0.8754, -1.8287],\n",
            "        ...,\n",
            "        [ 0.1540, -5.1434, -3.2894,  ...,  0.8926,  1.2058,  0.1618],\n",
            "        [ 0.3148, -4.7746, -5.2699,  ...,  0.5448, -3.3628, -3.9819],\n",
            "        [-1.6657,  1.7907,  4.3777,  ...,  0.6435,  0.9541,  0.1503]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8825e+00, -1.4968e+00, -4.7111e+00,  ..., -2.3848e+00,\n",
            "          1.7154e+00, -1.9981e+00],\n",
            "        [ 2.9843e+00, -4.7141e+00, -4.8186e+00,  ...,  2.5191e-01,\n",
            "         -2.2930e+00, -6.5589e-01],\n",
            "        [-2.9273e+00, -1.1401e+00, -3.9836e-01,  ...,  2.4434e-03,\n",
            "         -2.9152e+00,  9.8768e-01],\n",
            "        ...,\n",
            "        [-3.7963e+00,  9.8432e-01, -3.1334e+00,  ..., -1.4573e-01,\n",
            "         -1.6047e-01, -1.7199e+00],\n",
            "        [-1.9830e+00,  1.6824e+00, -2.4319e+00,  ..., -1.5275e+00,\n",
            "          2.5843e+00, -6.7141e-01],\n",
            "        [-2.9898e+00,  1.2564e+00,  1.2262e+00,  ..., -2.2074e+00,\n",
            "         -3.8362e-02,  1.0272e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9748,  3.1667, -1.8762,  ..., -2.0144,  0.3860, -0.0351],\n",
            "        [-3.3435,  2.9682, -3.6311,  ..., -2.8817,  2.2427, -2.5714],\n",
            "        [-2.2478,  4.1714,  2.6623,  ..., -2.8083,  2.1685,  0.0626],\n",
            "        ...,\n",
            "        [-1.7785,  4.6086,  2.2540,  ..., -2.6934,  1.2718, -0.1805],\n",
            "        [-1.0965, -1.9963, -2.3720,  ...,  2.0865,  1.7284, -0.0244],\n",
            "        [-0.8717, -4.7597, -2.9245,  ..., -1.7063,  1.5808,  0.1318]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8850,  2.0979, -0.6024,  ..., -3.0125,  1.3926,  0.8249],\n",
            "        [ 1.8546, -4.6287, -5.4386,  ...,  0.7537,  0.8069, -3.7552],\n",
            "        [-0.7313, -4.4981, -6.0437,  ...,  1.6796, -3.0406, -4.2659],\n",
            "        ...,\n",
            "        [-0.5052, -4.6639, -3.6354,  ..., -0.3448,  3.1060, -1.6207],\n",
            "        [-3.4668,  0.0567,  0.2398,  ..., -3.7905,  0.8389, -1.2135],\n",
            "        [-0.7048,  0.4398, -3.5684,  ...,  4.0716,  1.8242, -0.7032]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5302, -0.2997,  0.8889,  ..., -0.6873, -0.1000,  0.2810],\n",
            "        [-5.5063,  1.7816, -2.0938,  ...,  0.1819,  2.1863, -2.0859],\n",
            "        [-4.0635, -1.0694, -3.7392,  ..., -1.1061,  1.8332, -0.4000],\n",
            "        ...,\n",
            "        [-3.0731,  4.0145,  3.9702,  ..., -2.6601,  1.8973, -0.2840],\n",
            "        [-4.1401,  3.7086,  0.0575,  ..., -2.5741,  1.8070,  0.5267],\n",
            "        [ 1.3946, -6.2248, -2.9758,  ..., -1.7228, -2.2813, -1.1679]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5875, -1.4014,  0.5932,  ...,  1.2339,  1.5542, -1.1057],\n",
            "        [-1.7611,  1.3029, -2.6685,  ..., -2.2544,  2.7364, -0.6628],\n",
            "        [-3.7969, -7.5378, -5.7011,  ...,  0.6185,  2.4066, -1.6483],\n",
            "        ...,\n",
            "        [-1.3534, -0.5256, -3.2112,  ...,  2.0899,  2.8734,  0.2633],\n",
            "        [ 0.3625, -3.6753, -1.4908,  ...,  0.7660,  1.8844, -2.1856],\n",
            "        [ 0.1792, -2.5493, -0.3196,  ...,  0.1626,  0.4069,  0.0803]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8217, -1.9595, -0.7464,  ..., -2.5484,  1.3279, -1.9253],\n",
            "        [-3.8088, -6.4417, -3.2504,  ..., -1.3672,  3.1264, -4.0921],\n",
            "        [ 1.3973, -2.8041, -4.2447,  ...,  1.4721,  2.3630, -0.2193],\n",
            "        ...,\n",
            "        [-3.3472, -0.6654, -4.0516,  ..., -1.5830, -0.5225, -0.3277],\n",
            "        [-3.0075, -1.0033, -3.8802,  ..., -0.5247,  0.3533,  0.5601],\n",
            "        [ 3.1746, -6.3448, -2.3077,  ...,  2.0446, -0.6133, -1.9711]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1538, -0.2755, -1.9967,  ...,  0.8051,  2.7417, -0.5677],\n",
            "        [-1.6341, -4.3891, -4.0241,  ...,  0.0228, -0.2043,  0.8113],\n",
            "        [-4.8909, -0.3231, -0.7062,  ..., -2.9962,  2.9200,  0.4219],\n",
            "        ...,\n",
            "        [-2.0923,  5.2653,  3.3696,  ..., -0.9462,  1.5091,  0.2075],\n",
            "        [ 0.0209, -1.6460, -3.2799,  ...,  0.8034,  0.0158,  0.1382],\n",
            "        [-1.8636, -2.2408, -2.6334,  ..., -3.9842,  2.2193, -2.7459]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5423,  4.3269, -1.2036,  ...,  0.4015,  2.0143, -1.4979],\n",
            "        [ 2.5377, -2.1861, -4.0357,  ..., -2.3993,  1.4842, -1.6565],\n",
            "        [-3.6107,  3.7655, -0.2819,  ..., -3.7370,  1.4952,  0.1958],\n",
            "        ...,\n",
            "        [-0.2331, -2.4349, -3.1806,  ..., -1.0293, -1.2724, -3.2413],\n",
            "        [-2.5570, -1.1774, -4.3022,  ...,  2.0318,  1.7780, -2.2342],\n",
            "        [-4.0072,  5.7486, -2.8449,  ...,  0.1074,  4.1052, -0.0447]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1319, -3.6305, -6.8196,  ...,  1.0766,  0.0511, -3.0194],\n",
            "        [-2.6467,  1.0833, -3.5760,  ..., -1.0382,  0.7386, -1.5355],\n",
            "        [-1.8812, -4.0800, -4.1652,  ...,  1.5622, -0.5028, -2.1083],\n",
            "        ...,\n",
            "        [-0.4989, -2.2341, -4.1197,  ..., -1.3324,  1.1142, -0.8976],\n",
            "        [-2.5872, -5.6337, -2.1276,  ...,  0.0797,  0.8635, -0.0507],\n",
            "        [-1.1101, -4.4086, -5.2614,  ...,  3.2585, -0.9903,  0.9117]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7365,  4.5758,  3.4523,  ..., -3.6981,  1.7144, -0.3507],\n",
            "        [-1.0924, -1.4475, -6.3453,  ..., -3.3442,  2.9281, -2.9847],\n",
            "        [-1.6376, -2.8015, -2.4292,  ...,  3.3691,  0.4315, -0.0230],\n",
            "        ...,\n",
            "        [-0.5990,  0.8878, -1.7582,  ..., -3.7938,  1.5544, -1.4484],\n",
            "        [ 3.0729, -6.1636, -5.3819,  ...,  6.1374,  2.6247, -1.3570],\n",
            "        [-3.5152,  3.4434, -0.2480,  ..., -1.1387,  2.8901, -0.7692]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.1415,  0.6376, -2.4596,  ..., -2.4520,  2.0140, -5.5386],\n",
            "        [ 2.1553, -2.2899,  0.9821,  ...,  0.8909,  0.7845, -0.1918],\n",
            "        [-1.8451, -1.7205, -2.7931,  ...,  1.3590,  2.3602, -2.6225],\n",
            "        ...,\n",
            "        [-2.7723,  0.3684, -4.6254,  ..., -0.7725,  0.4143, -1.5998],\n",
            "        [-2.0754,  1.7390, -3.6074,  ...,  3.2207,  0.5321, -2.6597],\n",
            "        [ 0.4857, -1.5949, -2.2502,  ..., -1.5457,  3.4107, -3.7777]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8722, -5.4763, -5.3506,  ...,  0.0540,  1.0944, -3.8811],\n",
            "        [-6.1849,  6.0592, -0.7068,  ..., -2.1777,  4.4024, -4.7918],\n",
            "        [-1.4417, -0.8506, -1.7936,  ..., -0.6150,  1.1366, -2.0245],\n",
            "        ...,\n",
            "        [-5.0337, -1.2906, -3.3236,  ..., -0.6590,  2.1945, -4.1500],\n",
            "        [-1.2891,  3.2363,  1.3327,  ..., -2.2312,  1.6970, -0.9907],\n",
            "        [-4.0713, -2.1788, -4.4194,  ..., -1.8949,  2.1602, -1.9391]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8475, -1.8259, -4.4181,  ..., -2.5637,  1.8275, -5.4057],\n",
            "        [-0.8232, -3.1304,  0.5901,  ..., -0.6342,  0.1359, -0.9337],\n",
            "        [ 0.9660, -8.8159, -7.7307,  ...,  3.6259,  4.2239, -4.5939],\n",
            "        ...,\n",
            "        [-3.2507,  0.8010, -0.0512,  ..., -3.8512,  1.0859, -3.6387],\n",
            "        [ 2.1272, -8.1157, -6.8421,  ..., -0.3703, -2.3036, -5.6309],\n",
            "        [-0.8937, -2.2206,  0.0221,  ..., -1.6463,  1.0191, -2.6418]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2530, -0.4151,  0.5683,  ..., -1.2331,  0.3749, -1.7584],\n",
            "        [ 3.0358, -5.4733, -4.3994,  ...,  1.9630,  2.7160, -2.1067],\n",
            "        [-0.8295,  1.7743, -1.6016,  ..., -3.1724,  4.3044, -0.8465],\n",
            "        ...,\n",
            "        [-4.7049, -0.4625, -0.4875,  ...,  1.8111,  2.0602, -2.7811],\n",
            "        [-3.1528, -0.6244, -0.6318,  ..., -1.8531,  0.1109, -2.1864],\n",
            "        [-1.1681, -6.1324, -5.9719,  ..., -0.5100,  0.4029, -1.3293]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9912, -1.1670, -0.4138,  ...,  1.8595, -1.5969, -1.5992],\n",
            "        [-1.6609, -3.8845,  0.4068,  ..., -1.7014,  1.4680, -1.9183],\n",
            "        [-2.5957,  3.8535,  3.2857,  ..., -3.8959,  2.6347, -1.6616],\n",
            "        ...,\n",
            "        [-1.1733, -2.8938,  0.5394,  ..., -1.0562,  0.9313, -1.2475],\n",
            "        [-0.6834, -8.7146, -4.6482,  ..., -1.7970,  1.1078, -3.2211],\n",
            "        [-0.3112, -4.2634, -1.2423,  ...,  2.5999,  1.0231, -2.8592]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4122, -1.2616, -0.8178,  ...,  0.3641, -1.5346, -2.5735],\n",
            "        [-3.0300,  4.1960,  1.7606,  ..., -2.8764,  1.9471, -0.3853],\n",
            "        [-2.8497, -0.0212, -0.5627,  ...,  0.0873,  1.0506,  0.6141],\n",
            "        ...,\n",
            "        [-5.8213, -0.5628, -0.7512,  ...,  1.4247,  4.7870, -0.8968],\n",
            "        [ 0.0839, -2.0042, -1.5486,  ...,  0.2403,  0.4390, -1.4535],\n",
            "        [-0.0620, -1.6618, -1.3873,  ...,  3.6305, -2.0020, -1.5986]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  6.3777, -10.2006,  -5.2475,  ...,   4.5275,   2.5786,  -3.6957],\n",
            "        [ -1.4444,  -2.3956,  -0.4826,  ...,  -2.2033,   1.4417,  -1.6110],\n",
            "        [ -2.8304,  -5.0217,  -3.0120,  ...,  -2.7131,   0.2207,  -2.7444],\n",
            "        ...,\n",
            "        [  2.6930,  -2.8159,  -4.4005,  ...,   0.0935,   0.6880,  -4.0359],\n",
            "        [ -0.9531,  -4.5014,  -4.9753,  ...,  -0.4937,   2.0410,  -2.7236],\n",
            "        [ -3.6383,  -0.1448,  -1.1194,  ...,  -2.4431,   0.8036,  -4.5320]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6415, -5.4122, -2.5505,  ..., -2.8873,  3.0441, -2.0515],\n",
            "        [-3.4624, -1.4296, -2.0300,  ...,  0.3233,  3.4062, -2.9597],\n",
            "        [ 0.4341,  1.7287, -1.1026,  ..., -2.3253,  0.4367, -2.8616],\n",
            "        ...,\n",
            "        [-3.0988, -1.6079, -1.6359,  ..., -3.1815,  3.2028, -5.5854],\n",
            "        [ 0.9684, -3.0995, -2.9086,  ..., -1.2922, -1.6412, -2.5753],\n",
            "        [-1.3410, -0.6277, -0.4842,  ...,  1.2426, -0.8476, -0.9437]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4655, -2.9645, -4.6333,  ...,  2.2551,  3.2060, -3.4815],\n",
            "        [-0.2389, -3.2552, -1.8961,  ..., -0.9748,  1.9382, -2.8166],\n",
            "        [-4.9316,  1.4665, -3.1619,  ..., -4.6884,  3.9605, -1.8117],\n",
            "        ...,\n",
            "        [-5.4936,  0.4077, -3.5270,  ...,  0.4996,  2.1963, -1.2700],\n",
            "        [ 0.5063, -4.4015, -4.3180,  ..., -1.5124,  3.9514, -2.4436],\n",
            "        [ 3.7401, -7.8951, -3.6887,  ..., -0.6743, -2.7467, -3.6998]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4858,  1.5565,  4.0139,  ..., -1.0241,  0.1075, -0.6313],\n",
            "        [-3.9471,  0.5978, -3.1121,  ..., -0.1945,  1.5674, -2.0451],\n",
            "        [-4.4854,  0.7413, -2.1040,  ..., -2.3132, -0.1133, -0.1051],\n",
            "        ...,\n",
            "        [-0.8716, -3.0197, -4.7196,  ..., -1.7811, -1.0270,  0.4058],\n",
            "        [ 3.3707, -3.0000, -1.9406,  ...,  2.4695,  1.9248, -0.5159],\n",
            "        [-3.4447, -2.8091, -0.4460,  ...,  1.2347,  5.1598, -3.5031]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1484, -2.6865, -2.1087,  ..., -1.2708,  1.5017, -3.7616],\n",
            "        [-3.0192, -0.3463, -3.9153,  ..., -1.5684,  0.3536, -1.0822],\n",
            "        [ 1.7873, -6.6490, -4.1250,  ..., -0.2993, -0.2077, -3.3179],\n",
            "        ...,\n",
            "        [-1.7253, -2.1370, -5.1099,  ..., -1.1671,  2.2254, -1.3426],\n",
            "        [-3.4801, -0.3009,  1.0570,  ..., -1.6699, -1.3118, -2.1824],\n",
            "        [-4.8882,  2.7659, -5.1583,  ..., -3.4524,  4.1886, -0.6159]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4031,  5.0001,  2.5511,  ..., -2.2820,  2.2558, -1.2743],\n",
            "        [ 0.7721, -1.3309, -4.1772,  ...,  3.5038,  0.0420, -1.5502],\n",
            "        [-3.1577, -1.3879, -2.2463,  ..., -1.4729,  2.2633,  0.1839],\n",
            "        ...,\n",
            "        [-1.9808,  3.6838, -2.4957,  ..., -3.7145,  2.1714, -0.0232],\n",
            "        [ 2.2569, -8.0377, -6.7176,  ...,  1.7684, -1.5861, -3.5044],\n",
            "        [ 0.2526,  0.7011, -1.5217,  ..., -3.2831,  1.0638, -2.1497]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8732, -2.6955, -2.0199,  ...,  0.1466,  0.9508,  3.0608],\n",
            "        [-1.7427,  3.8455,  3.9395,  ..., -3.1114,  0.6249, -0.5571],\n",
            "        [-3.1859, -0.4383, -3.5525,  ..., -0.7565,  2.6814, -0.9166],\n",
            "        ...,\n",
            "        [-3.4159, -0.5120, -0.8868,  ...,  0.3101,  3.2286, -2.4469],\n",
            "        [-0.5853, -0.7959,  5.0989,  ..., -2.3489,  1.1766, -0.5770],\n",
            "        [-4.9537,  4.9086, -0.5343,  ..., -2.1765,  0.2515,  1.5870]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8719, -5.5319, -6.8473,  ...,  0.7630,  0.7784, -0.7971],\n",
            "        [-2.7694,  1.4930,  0.0885,  ..., -4.7449,  1.9768, -0.3819],\n",
            "        [-0.8311, -4.2798, -4.0186,  ...,  1.5679,  0.8562, -3.6340],\n",
            "        ...,\n",
            "        [ 0.6907, -0.2285, -1.2097,  ..., -1.9088,  1.6840,  0.7495],\n",
            "        [ 0.1625, -5.9740, -2.8278,  ..., -0.9654,  0.3741, -2.4713],\n",
            "        [-3.5208, -3.1700, -2.4914,  ..., -1.9679,  0.6832, -4.1201]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5697,  4.7760,  3.8287,  ..., -2.4263,  1.6457, -1.4700],\n",
            "        [-0.1677, -3.6902, -4.3833,  ...,  2.4825, -1.7398, -3.7691],\n",
            "        [-4.9647, -1.8085, -1.8093,  ..., -3.1999,  2.7650, -2.4391],\n",
            "        ...,\n",
            "        [-4.7211, -0.2947, -2.7047,  ..., -0.3663,  1.7804, -1.9623],\n",
            "        [-3.9152,  0.2205, -3.6458,  ..., -2.5445,  1.1192, -3.0543],\n",
            "        [-2.2868, -1.9713, -4.9412,  ..., -3.7157, -0.3772, -2.4816]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.8809, -3.7737, -2.7056,  ..., -2.7366,  0.8396, -3.2074],\n",
            "        [ 2.6737, -7.6332, -5.5150,  ..., -0.7385,  0.2224, -4.2062],\n",
            "        [-2.1541, -0.3746, -2.8690,  ..., -2.3253,  1.1433, -0.8888],\n",
            "        ...,\n",
            "        [-0.5993, -1.9346, -4.9996,  ...,  2.3267,  1.3370, -3.0975],\n",
            "        [-6.4699, -0.3398, -1.2648,  ..., -0.5746,  2.6536, -4.8200],\n",
            "        [-0.0488, -1.5714,  0.1619,  ..., -1.9489,  1.5532, -2.1461]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8499,  3.5156, -0.1264,  ..., -3.3749,  0.4050, -1.8760],\n",
            "        [-3.6051, -0.6826, -7.0697,  ...,  0.2279,  3.8311,  0.2035],\n",
            "        [ 3.1821, -2.9511, -4.4375,  ..., -0.9214,  0.9310, -0.9200],\n",
            "        ...,\n",
            "        [-1.9248, -3.3112, -2.6613,  ..., -1.8797,  3.3826, -4.1863],\n",
            "        [-3.4084,  1.8775,  0.9309,  ..., -2.5118,  2.1220, -1.4937],\n",
            "        [ 1.1895, -2.9995, -3.4432,  ...,  1.2258,  1.0503, -3.5580]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3954, -1.2575, -5.3727,  ..., -0.1866,  1.2125, -0.7326],\n",
            "        [-0.8118,  0.6163,  0.3495,  ..., -2.2781,  0.7728, -1.4858],\n",
            "        [-4.2472, -1.0617, -2.6325,  ...,  0.3862,  0.4843, -3.9756],\n",
            "        ...,\n",
            "        [-0.3989, -0.3768, -2.9581,  ..., -1.8837,  0.2845, -2.1012],\n",
            "        [-3.2814,  4.7057,  5.3169,  ..., -2.5575, -0.8684, -2.3724],\n",
            "        [-2.0305,  0.1972,  1.2093,  ..., -1.1381, -0.1378,  0.9084]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1718, -5.8125, -3.4552,  ..., -1.7668, -1.1244,  0.3626],\n",
            "        [ 0.7226, -1.3876, -3.4478,  ..., -0.7794,  2.9154, -2.2125],\n",
            "        [-1.3565, -2.1151, -0.4355,  ..., -3.7137,  1.0627, -1.7945],\n",
            "        ...,\n",
            "        [-0.5113,  0.7498, -2.6120,  ..., -1.0961,  2.4955, -0.6172],\n",
            "        [-1.4696, -0.7692, -3.2409,  ..., -0.6251,  0.5215,  0.3443],\n",
            "        [-5.1228,  2.5595, -2.9384,  ..., -0.5632,  2.4611,  0.0453]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.5906,  3.3272, -0.8078,  ..., -1.7481, -0.2176, -0.6651],\n",
            "        [ 1.9164, -1.0954, -1.6830,  ..., -2.7093,  2.2341, -2.7261],\n",
            "        [-1.4225,  0.1534, -4.1812,  ..., -1.9801,  0.8249, -0.1308],\n",
            "        ...,\n",
            "        [ 3.1470, -6.0357, -8.6311,  ..., -0.2892, -2.8218, -2.4874],\n",
            "        [-1.0161, -0.5118, -3.5952,  ..., -0.4457,  2.9477, -3.0316],\n",
            "        [-3.4799,  2.4727, -1.7020,  ..., -1.5202,  1.0370,  0.6467]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7256,  3.5506,  1.7446,  ..., -3.8130,  1.4386, -0.2723],\n",
            "        [-1.7640,  3.8367,  2.8212,  ..., -2.5037,  0.2808, -1.0518],\n",
            "        [-2.5385,  4.7856,  0.7771,  ..., -3.2568,  0.9018, -0.1240],\n",
            "        ...,\n",
            "        [ 5.1567, -7.1222, -2.9354,  ...,  0.0644,  2.9569, -4.6833],\n",
            "        [-1.3242,  0.6505, -6.1940,  ..., -1.0277,  1.3689, -1.0912],\n",
            "        [-1.4724, -3.1784, -2.3322,  ...,  1.5335,  0.5134, -2.4845]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8780, -3.2497, -2.2020,  ..., -0.1846, -3.1721,  0.6042],\n",
            "        [-2.0279, -0.7332, -3.1438,  ..., -2.9160,  0.3527, -2.9412],\n",
            "        [-3.5713,  1.5875, -1.6580,  ..., -3.7179,  1.9962, -1.3804],\n",
            "        ...,\n",
            "        [-1.5651,  1.2328, -2.1413,  ..., -3.6966,  0.4481, -0.0765],\n",
            "        [-3.2466,  1.4882, -3.7482,  ...,  0.4940,  2.9100,  0.8235],\n",
            "        [ 2.3916, -4.4815, -5.0059,  ...,  0.0788, -1.4160, -2.9177]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9984, -3.0851, -3.2671,  ...,  0.8961,  2.5878, -2.0600],\n",
            "        [ 3.4212, -1.4203, -2.3819,  ...,  0.6905,  2.5055, -0.8123],\n",
            "        [ 0.6939, -5.3309, -3.3044,  ...,  0.1539,  1.7496, -2.9608],\n",
            "        ...,\n",
            "        [ 4.0802, -5.2122, -1.8178,  ..., -1.9051,  1.0207, -4.4208],\n",
            "        [-2.3663, -1.1973,  1.1553,  ..., -1.2464, -0.5925, -1.9793],\n",
            "        [-3.6562, -0.6160, -3.5025,  ..., -0.8309,  0.8643, -0.7314]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0966, -2.8100, -3.7744,  ...,  1.1727,  1.7995, -3.1820],\n",
            "        [-5.9077, -0.1590, -1.9430,  ..., -1.9593,  2.2303, -1.3232],\n",
            "        [-1.9254, -0.7032, -6.6878,  ...,  2.5986,  1.5122, -4.1186],\n",
            "        ...,\n",
            "        [-5.4074,  1.1854, -3.5750,  ..., -0.4882,  0.2544, -1.8968],\n",
            "        [-2.0319, -2.9336, -3.7393,  ...,  4.0381,  4.4667, -1.1699],\n",
            "        [ 3.7394, -3.5809, -4.5765,  ..., -0.5413,  2.2910, -2.9140]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1724, -6.5494, -6.3434,  ..., -0.2689,  0.1148, -2.4651],\n",
            "        [-1.2063, -1.1739, -0.6251,  ..., -0.2733, -0.7841, -0.8120],\n",
            "        [-3.6288,  0.4817, -1.9937,  ..., -3.8679,  0.8866, -4.5487],\n",
            "        ...,\n",
            "        [ 0.1529, -3.4919, -7.8993,  ...,  4.3467, -1.2655, -2.9909],\n",
            "        [ 1.6846, -1.3698, -1.6369,  ..., -3.1780,  1.4507, -3.3171],\n",
            "        [-5.5656, -4.8087, -6.3484,  ...,  3.4552, -0.3559, -1.2868]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5667,  0.4186, -5.1596,  ..., -0.4463,  0.0068, -0.6019],\n",
            "        [-2.0154, -6.0501, -4.4156,  ..., -0.5525,  2.4300, -3.4198],\n",
            "        [-2.7185, -0.5714, -0.9792,  ..., -2.0221,  1.6783, -3.0298],\n",
            "        ...,\n",
            "        [-6.4372, -0.4247, -1.8263,  ...,  3.2508,  2.4916, -2.2677],\n",
            "        [-1.5537,  1.3603, -0.7947,  ..., -4.7092,  0.4743, -1.0556],\n",
            "        [-3.0479,  3.8017,  2.6410,  ..., -3.9418,  1.7640, -0.9425]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5061,  3.4113,  2.3323,  ..., -3.3325,  1.1591, -0.9991],\n",
            "        [-1.4147,  1.3500, -1.1588,  ..., -4.0552,  2.4349, -3.0422],\n",
            "        [-0.9432, -2.0671, -4.7496,  ..., -2.5908,  3.6437, -2.1106],\n",
            "        ...,\n",
            "        [-2.8713, -0.6602, -0.7414,  ..., -3.4974, -0.4609, -1.5139],\n",
            "        [-2.7149, -0.5239, -3.0252,  ..., -4.2678,  1.2723, -1.9294],\n",
            "        [-4.6580, -0.3899, -5.3087,  ..., -0.9686,  3.5289, -0.2260]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0370,  4.3942,  3.9080,  ..., -3.2888,  1.4170, -1.3240],\n",
            "        [-3.0121, -1.8372, -2.0983,  ..., -2.2134,  0.7410, -2.3624],\n",
            "        [-2.7884,  3.9289,  3.1477,  ..., -3.5652,  1.8819, -0.8906],\n",
            "        ...,\n",
            "        [-2.3596, -2.4572, -2.4677,  ..., -2.8865,  0.9548, -2.9704],\n",
            "        [-4.0403, -1.2517, -2.3153,  ..., -1.5341,  1.9088,  0.5407],\n",
            "        [-2.4938, -0.7293, -1.1032,  ...,  0.7455,  2.1697, -3.1707]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3327,  0.0206, -5.9731,  ..., -0.9415,  0.6217, -2.7846],\n",
            "        [-2.9296, -1.5128, -2.3901,  ..., -3.0999, -0.3199, -3.8164],\n",
            "        [-3.0052, -1.6530, -2.5817,  ...,  2.7957,  1.9844, -1.2705],\n",
            "        ...,\n",
            "        [ 6.2759, -7.3008, -3.4178,  ..., -1.0232,  2.0247, -5.2420],\n",
            "        [-3.4101,  2.8813, -0.0724,  ..., -4.2877,  1.2016, -2.3763],\n",
            "        [-1.6339, -2.4621, -4.2689,  ..., -0.2194, -1.2782, -3.3279]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2457, -0.7948,  0.6312,  ...,  2.3065, -3.6264, -0.7827],\n",
            "        [-1.8529,  3.6914,  3.2566,  ..., -1.2787,  0.8910, -0.4708],\n",
            "        [-0.9003, -2.4650, -3.2226,  ...,  3.2223,  1.6515, -2.9846],\n",
            "        ...,\n",
            "        [-0.3129, -4.3349, -2.3180,  ..., -2.6440, -0.0915, -1.2402],\n",
            "        [ 1.1626, -2.0334, -0.7804,  ...,  1.0623, -0.7267, -1.3999],\n",
            "        [-2.2496,  2.5068, -2.6274,  ..., -3.0440,  1.6321, -1.1054]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2644, -4.6622, -4.6605,  ...,  1.0412,  0.3836, -4.0567],\n",
            "        [-2.9353, -0.6624, -2.3449,  ...,  0.1110, -0.9553, -3.4327],\n",
            "        [-3.5294,  1.8385, -6.2921,  ...,  0.6353,  2.9894, -0.4507],\n",
            "        ...,\n",
            "        [-5.4213, -3.2518, -0.6293,  ..., -0.7795, -3.1213,  0.1089],\n",
            "        [-2.5579,  3.3301, -0.9795,  ..., -3.0517,  0.5229,  0.0308],\n",
            "        [ 3.3195, -3.8519, -1.0747,  ..., -1.2209,  0.5122, -2.7209]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6914,  1.1562, -1.0575,  ..., -1.4629,  0.8674, -3.8280],\n",
            "        [-2.8499, -1.8501, -2.5567,  ..., -0.9609, -0.6687, -3.4037],\n",
            "        [-0.2011, -0.6964, -1.3448,  ...,  6.2132,  2.3883, -0.6040],\n",
            "        ...,\n",
            "        [ 1.3762, -2.2756, -2.1001,  ...,  0.7600,  0.1176, -2.9060],\n",
            "        [-1.4102, -2.1090, -8.3013,  ...,  1.2841,  0.7297, -2.0995],\n",
            "        [-2.3577, -0.6112, -1.5785,  ...,  0.2955, -0.1060, -0.8928]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6934e+00, -2.8771e+00, -7.2333e+00,  ..., -4.0365e-01,\n",
            "          2.9008e-01, -1.2012e+00],\n",
            "        [-4.4617e+00, -3.2125e-02, -3.2694e+00,  ..., -2.3194e+00,\n",
            "          1.2575e+00, -1.9182e+00],\n",
            "        [ 1.2657e+00, -9.2648e+00, -2.0013e+00,  ...,  2.4257e+00,\n",
            "         -9.6102e-01, -4.7632e+00],\n",
            "        ...,\n",
            "        [-2.7881e+00, -1.5060e+00,  4.5483e-03,  ..., -4.3386e+00,\n",
            "         -5.7362e-01, -1.0468e+00],\n",
            "        [-4.6184e+00,  2.1558e+00, -2.2391e+00,  ...,  1.0540e+00,\n",
            "          1.3267e+00, -2.5291e+00],\n",
            "        [-3.2950e+00,  2.5038e-01, -3.0484e+00,  ..., -1.8387e+00,\n",
            "          2.4032e+00, -1.6172e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6174,  0.0472, -1.8734,  ..., -2.1120,  0.8722,  0.6971],\n",
            "        [ 2.8231, -6.7307, -6.2291,  ...,  1.6323, -1.5741, -5.2353],\n",
            "        [-2.8437,  3.1324,  1.9807,  ..., -2.5767,  0.4838, -1.5876],\n",
            "        ...,\n",
            "        [-3.5318,  4.6251,  2.4071,  ..., -3.3667,  1.2262, -1.0727],\n",
            "        [-1.9661, -0.6176,  0.1812,  ..., -2.5032, -0.0497, -3.8120],\n",
            "        [-0.1997, -1.8256, -1.4437,  ...,  4.5017,  2.4842, -0.0448]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[  0.0551,  -2.8793,  -0.0751,  ...,   1.7232,  -2.1858,  -1.2243],\n",
            "        [  3.4365, -10.3110,  -7.6788,  ...,   5.2345,   1.2469,  -4.3437],\n",
            "        [  0.6841,  -2.7652,   0.1821,  ...,  -0.2847,  -1.9072,  -0.3038],\n",
            "        ...,\n",
            "        [  0.8917,  -4.3136,  -2.9222,  ...,  -0.4707,   0.9839,  -4.8245],\n",
            "        [ -1.5727,  -0.1996,  -0.1981,  ...,  -6.1073,  -0.7564,   0.6067],\n",
            "        [ -4.1105,   1.6557,  -0.8056,  ...,  -0.3512,  -1.5265,   0.2470]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7146,  1.2685,  0.2690,  ..., -3.2263, -0.7206, -1.7501],\n",
            "        [ 0.4812, -6.0798, -1.2686,  ...,  1.5624,  2.2783, -5.2134],\n",
            "        [-0.0319, -2.9527, -4.1551,  ..., -0.8149,  0.9510, -2.5523],\n",
            "        ...,\n",
            "        [-2.3964, -1.6637, -1.8466,  ..., -1.0402,  0.1155, -3.4339],\n",
            "        [ 0.0814, -1.0872, -4.8458,  ...,  1.0948,  0.5957, -3.8840],\n",
            "        [-4.8640,  0.0985, -4.1873,  ..., -2.6067,  1.8806, -2.0439]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5541, -1.2404, -0.8683,  ..., -1.6460, -0.4825,  1.4778],\n",
            "        [-1.9365, -0.8416,  1.6443,  ..., -0.1184, -1.9676, -0.3412],\n",
            "        [ 4.3951, -3.7645, -0.8388,  ...,  2.1150, -0.0600, -0.5168],\n",
            "        ...,\n",
            "        [ 0.7206, -1.4869, -7.4131,  ...,  1.8521,  0.8053, -5.6955],\n",
            "        [-2.0142,  0.1019, -4.8918,  ..., -0.6788, -0.2345, -2.6806],\n",
            "        [ 0.1469, -0.9863, -4.0724,  ..., -0.5440,  0.1913, -3.5326]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5180, -2.1445, -2.7899,  ...,  0.4720,  1.2305, -1.9248],\n",
            "        [ 1.6801, -0.4359,  0.5376,  ..., -1.6728, -1.2476, -3.0780],\n",
            "        [-0.9319, -3.8314, -1.4606,  ...,  0.9933, -1.5365, -1.6904],\n",
            "        ...,\n",
            "        [ 0.0956, -0.7406,  1.4739,  ...,  0.7565, -0.4343, -1.2579],\n",
            "        [-3.6066, -0.7536, -2.5049,  ..., -2.2162,  1.2223, -0.0298],\n",
            "        [-3.9442, -0.7959, -4.1610,  ..., -2.1685,  1.4172, -3.1879]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.7000, -1.1040, -3.4317,  ...,  0.9673, -0.1580, -3.1223],\n",
            "        [-0.5493, -5.4428, -3.0472,  ...,  5.1400, -0.6334, -0.7753],\n",
            "        [-2.7747,  1.3100, -1.5931,  ..., -1.7617,  1.3503, -0.4420],\n",
            "        ...,\n",
            "        [-5.5459, -0.7698, -0.9467,  ...,  0.3306,  2.6548, -5.0514],\n",
            "        [-1.0585,  0.5895, -2.4065,  ..., -1.0816,  0.8831, -3.5475],\n",
            "        [ 0.3531, -6.8338, -3.2382,  ...,  0.5029,  1.0079, -3.7377]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1486,  1.4043, -3.4841,  ..., -0.8529,  2.1970, -4.4297],\n",
            "        [-2.8998, -1.4943, -2.4105,  ..., -0.0696,  2.8991, -4.1851],\n",
            "        [-0.1161, -0.0708, -2.1290,  ...,  1.0120, -0.2469, -0.8583],\n",
            "        ...,\n",
            "        [-3.6397, -2.8486, -1.3589,  ..., -2.2122, -0.0382, -3.0277],\n",
            "        [-6.3180,  3.1628, -1.7430,  ..., -2.9190,  1.0175,  0.7442],\n",
            "        [-1.8839,  0.1252, -4.1150,  ..., -0.9285,  0.5522,  0.7281]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6370, -0.5831,  0.0771,  ..., -2.1306, -0.1434, -2.8670],\n",
            "        [-0.0848, -6.5092, -4.7134,  ..., -0.8632, -0.7457, -4.8546],\n",
            "        [ 1.8698, -2.6015, -3.6209,  ...,  0.9833,  0.7717, -2.8966],\n",
            "        ...,\n",
            "        [-1.0494, -0.4479, -0.8381,  ..., -4.9935,  1.0360,  0.5192],\n",
            "        [-4.7067, -3.8963, -1.1012,  ..., -0.7533, -0.1060, -2.6582],\n",
            "        [-2.9989, -3.7494, -2.8250,  ..., -1.6705, -0.7190, -0.3218]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3371, -7.1629, -3.4179,  ..., -3.1698, -0.4262, -1.1525],\n",
            "        [-1.4831, -1.2800, -2.6930,  ..., -0.2117, -0.3701, -1.8691],\n",
            "        [ 1.9273, -4.5212,  1.0572,  ...,  0.2485, -1.0105, -0.6275],\n",
            "        ...,\n",
            "        [-3.7999, -0.7314, -0.2993,  ..., -0.0435, -0.0239, -4.1607],\n",
            "        [ 0.4291, -1.4369, -3.9498,  ...,  2.9792,  2.8155, -3.0151],\n",
            "        [-1.5169,  0.4373, -2.3198,  ..., -4.1152, -0.0308, -1.0208]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7673, -1.9947,  0.8102,  ...,  0.1647, -1.7409, -1.4731],\n",
            "        [ 1.7677, -8.1687, -6.8458,  ...,  0.6024, -0.7891, -5.1606],\n",
            "        [-1.3107, -1.4902,  1.6252,  ...,  0.5768, -1.0364, -1.4254],\n",
            "        ...,\n",
            "        [ 1.7625, -2.8900, -5.4373,  ...,  2.9062, -0.9147, -3.9985],\n",
            "        [ 1.1280, -5.4414, -6.2517,  ...,  0.7916, -1.9982, -3.7336],\n",
            "        [-2.9305, -5.2018, -3.2648,  ..., -0.2556, -2.5461, -4.6818]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7220,  0.5236,  2.6724,  ...,  0.6802, -0.5023, -2.5779],\n",
            "        [-1.2437, -2.1843, -5.5649,  ...,  3.6067,  0.4716, -6.8966],\n",
            "        [-1.2193, -3.6293, -6.8336,  ...,  3.3936,  1.8037, -3.0199],\n",
            "        ...,\n",
            "        [-5.4498, -3.6175, -5.0025,  ...,  6.3412, -1.0690, -4.9176],\n",
            "        [-0.9203, -0.0287, -2.4097,  ..., -4.2096, -0.1497, -1.4619],\n",
            "        [-0.8218, -1.0249, -0.1916,  ..., -1.0175, -0.7710, -1.8148]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2243, -2.6664, -1.7020,  ...,  2.2277, -1.2019, -1.1508],\n",
            "        [ 0.2231, -6.9881, -4.1813,  ...,  0.6149,  0.4345, -3.0876],\n",
            "        [-3.1872,  0.0367, -2.4575,  ..., -3.3463, -0.8298,  1.8742],\n",
            "        ...,\n",
            "        [ 2.0169, -3.0914, -8.6383,  ...,  0.6133, -1.2412, -4.2361],\n",
            "        [-2.5622, -2.0967, -6.1696,  ..., -1.6755,  1.2539, -4.9341],\n",
            "        [ 2.5663, -5.9437, -2.0157,  ...,  1.8861,  0.5257, -5.9190]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8127,  2.5800, -0.1828,  ..., -2.3459,  0.2004, -1.2241],\n",
            "        [-1.1495, -0.5823,  0.0313,  ...,  0.4053, -0.4782, -2.1232],\n",
            "        [ 4.3421, -7.8016, -0.7357,  ...,  1.5255,  0.7691, -5.2981],\n",
            "        ...,\n",
            "        [-4.2812, -1.8551, -1.3383,  ...,  5.4082,  1.2690, -4.4043],\n",
            "        [-4.9594, -2.5977, -2.1597,  ..., -0.2942,  0.2957, -0.9977],\n",
            "        [-3.8356,  5.8078,  0.7066,  ..., -1.6934,  1.0698, -3.7426]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5679,  4.7921,  5.0214,  ..., -1.2219,  0.3555, -1.4288],\n",
            "        [-0.5575, -0.2210, -1.7435,  ..., -1.1654,  0.2039, -1.0343],\n",
            "        [-0.5956,  1.1605, -1.2994,  ..., -3.5143, -0.5559, -1.6289],\n",
            "        ...,\n",
            "        [-1.0330,  0.1616, -4.8195,  ..., -0.1692,  0.2005, -3.5191],\n",
            "        [-1.4357,  4.5961,  4.6839,  ..., -1.2729, -0.0990, -0.5695],\n",
            "        [-2.9688,  4.0636, -0.2733,  ..., -0.0149,  0.4637, -0.0051]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7829, -4.3981, -0.2530,  ..., -0.4770, -0.8007, -2.4499],\n",
            "        [-1.4104,  3.9417,  4.2701,  ..., -0.6613,  0.3156, -0.9919],\n",
            "        [-1.9210, -0.3607, -6.7623,  ..., -0.2480,  1.1907, -1.8025],\n",
            "        ...,\n",
            "        [-2.3093, -0.3086, -0.2964,  ..., -2.8622,  0.1294, -4.5910],\n",
            "        [-3.7223, -0.6187, -5.0655,  ...,  1.8646,  2.5059,  1.1164],\n",
            "        [-1.7417, -2.9088, -2.1763,  ..., -0.1674, -0.0907, -1.3338]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -1.1492,   0.9279,  -2.4717,  ...,   1.2954,   0.6183,  -1.7725],\n",
            "        [ -4.1980,   0.3050,  -0.3417,  ...,   1.0071,   2.9881,  -0.6586],\n",
            "        [ -2.9649,   0.8025,  -1.2588,  ...,   1.5553,   1.5835,  -4.8655],\n",
            "        ...,\n",
            "        [ -0.3740,  -5.2543,  -3.2333,  ...,  -1.5720,   1.2226,  -2.4854],\n",
            "        [ -1.2263,   0.7176,  -2.1313,  ...,  -3.8144,  -0.4898,  -0.7344],\n",
            "        [  1.6472, -10.7626,  -5.2428,  ...,   6.2122,  -3.1506,  -2.6560]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8180, -5.8410, -2.8856,  ...,  0.8402, -3.3010, -0.1308],\n",
            "        [-0.9472,  2.3103, -1.2545,  ...,  0.1222,  0.7746, -0.3310],\n",
            "        [ 0.6018, -3.6282, -4.0085,  ...,  1.1150, -0.0747, -1.5454],\n",
            "        ...,\n",
            "        [ 2.3369, -2.6065, -5.6253,  ...,  5.3245,  0.7821, -3.2291],\n",
            "        [-2.6602, -2.3436,  0.2801,  ..., -3.6100, -3.1237, -2.6525],\n",
            "        [ 2.4201, -3.0110, -3.9378,  ...,  1.3421,  0.6285, -2.9153]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.4730,  1.6605, -1.2609,  ..., -1.0328, -1.3690, -0.3110],\n",
            "        [-2.7184, -3.5919, -5.1296,  ..., -0.5391,  1.5860, -3.7191],\n",
            "        [-1.5980,  2.2892, -0.2525,  ..., -3.3665,  0.1055, -0.4850],\n",
            "        ...,\n",
            "        [-2.9974,  5.3496,  3.1578,  ..., -1.4156,  0.2408, -0.2829],\n",
            "        [-1.2019,  1.7802, -2.2529,  ..., -1.5698,  0.3799, -3.2104],\n",
            "        [-4.6530,  2.4236, -1.7305,  ..., -0.4667, -2.5119,  1.9229]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6877, -0.2951, -0.9349,  ..., -0.1534,  2.7427, -3.4489],\n",
            "        [ 2.5737, -4.7946, -3.4022,  ...,  1.4362, -0.6954, -3.0144],\n",
            "        [-0.7662,  0.8489, -1.6411,  ..., -1.0549, -0.0505, -2.1677],\n",
            "        ...,\n",
            "        [-5.1010,  1.2173, -3.1666,  ...,  1.4483,  0.8933, -3.7254],\n",
            "        [-2.2536,  3.8218,  4.5519,  ..., -1.5739,  0.5433, -0.5827],\n",
            "        [-0.2606, -2.4244, -1.9845,  ...,  1.1958,  0.9014, -3.8741]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5121, -0.9755, -2.2601,  ...,  0.4242,  1.1549,  1.1787],\n",
            "        [-1.6487,  1.0487, -1.5373,  ..., -2.9159, -0.0470, -0.7717],\n",
            "        [-1.4483, -3.0532, -2.0853,  ..., -2.0393,  1.1309, -0.7511],\n",
            "        ...,\n",
            "        [ 1.0221, -3.4274, -2.9368,  ...,  1.2295,  0.0798, -2.4434],\n",
            "        [-0.4181, -2.7161, -1.8380,  ..., -0.2307, -2.5888, -1.1127],\n",
            "        [-3.1508, -2.3668,  1.0758,  ..., -4.3569, -1.0769, -1.1672]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5452, -2.0365, -8.6450,  ...,  0.6074, -0.0911, -4.1953],\n",
            "        [ 4.0081, -6.9121, -5.0414,  ...,  4.3299,  2.7722, -2.3854],\n",
            "        [-0.1181, -6.1381, -3.5531,  ..., -2.3175, -3.0328,  1.0020],\n",
            "        ...,\n",
            "        [-1.8683,  4.6816,  4.5152,  ..., -1.9663,  0.4425,  0.0984],\n",
            "        [-2.1273, -1.0936, -1.6337,  ...,  0.3337,  2.0789, -0.2154],\n",
            "        [ 2.2288,  0.7039, -0.1146,  ...,  2.5385, -2.0530, -1.0897]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9867,  0.1333,  0.9890,  ..., -2.1144, -0.9542, -1.1238],\n",
            "        [-1.7011,  2.6470, -1.6449,  ..., -1.0363,  2.2367, -1.2001],\n",
            "        [-2.9815, -5.2691, -2.5672,  ..., -0.9281, -0.7917, -3.4148],\n",
            "        ...,\n",
            "        [-0.9993, -3.2082, -1.0180,  ..., -2.9286,  1.1791, -1.8664],\n",
            "        [-0.1146, -2.8353, -7.3495,  ...,  3.4199, -0.7484, -4.8229],\n",
            "        [-2.7362,  1.7324, -6.7653,  ..., -1.0189,  2.1809, -1.9768]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0258,  4.6455,  3.5993,  ..., -0.6899,  0.6872, -0.1617],\n",
            "        [ 4.7136, -7.9494, -7.6739,  ...,  0.4245, -2.9236, -6.9937],\n",
            "        [-1.9724,  3.5014,  4.8540,  ..., -0.8152,  0.3417, -0.8631],\n",
            "        ...,\n",
            "        [-0.7654,  2.3874, -0.5894,  ...,  1.7511,  0.9226, -1.2976],\n",
            "        [-0.4874, -1.2588, -4.8361,  ..., -1.1396, -0.4099, -1.8437],\n",
            "        [-2.1282,  0.4757, -5.9295,  ..., -2.7589,  0.4773, -2.0978]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5152, -2.0762, -1.9547,  ..., -0.8533, -4.3570, -0.9763],\n",
            "        [-1.4886, -5.2002, -2.8392,  ...,  5.9797, -1.5099, -2.8366],\n",
            "        [-2.6671, -0.8634, -3.5025,  ...,  2.9445,  1.9665, -0.5883],\n",
            "        ...,\n",
            "        [-1.4126,  0.9515,  1.3675,  ..., -1.1028, -0.7606, -2.0452],\n",
            "        [ 1.8788, -1.9452, -3.7136,  ..., -0.5472, -0.7167, -3.5070],\n",
            "        [ 1.6680, -4.1756, -4.7894,  ...,  0.1750, -1.2043, -6.3948]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4138, -5.5798, -2.8203,  ...,  1.5023,  0.7360, -4.5586],\n",
            "        [-4.1622, -2.0374, -4.5733,  ..., -2.0586,  0.1800, -1.9912],\n",
            "        [ 3.0707, -4.8258, -4.9498,  ..., -1.2649, -1.5054, -1.5888],\n",
            "        ...,\n",
            "        [ 3.1704, -5.5903, -5.7354,  ...,  0.3674,  1.5723, -4.6181],\n",
            "        [-4.2900,  1.3481, -3.4211,  ..., -2.2840,  1.3857, -1.3286],\n",
            "        [-4.6087,  0.1378,  0.9720,  ..., -0.0504,  0.3104, -0.8544]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7319,  0.0961, -1.5844,  ...,  1.6967,  1.0149, -3.2377],\n",
            "        [ 3.9794, -4.3028, -2.2073,  ...,  3.7955, -1.0223, -0.8023],\n",
            "        [-3.0731,  1.1745,  0.7287,  ..., -4.3241,  0.8578, -4.6793],\n",
            "        ...,\n",
            "        [-3.6373,  4.7795, -1.9385,  ..., -1.4612,  1.6056, -2.0546],\n",
            "        [ 1.2840, -2.7486, -2.9402,  ..., -0.1443,  1.3490, -0.5358],\n",
            "        [-2.8729,  4.3103,  5.2338,  ..., -3.0765,  0.0477, -0.3597]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-6.1741e+00, -2.8693e+00, -1.7856e+00,  ...,  1.7460e+00,\n",
            "          1.6134e+00, -5.2151e+00],\n",
            "        [-3.3016e+00, -6.0846e-01, -2.2092e+00,  ..., -2.4449e+00,\n",
            "         -7.2467e-01,  5.4987e-02],\n",
            "        [-1.8396e+00, -1.2560e-03,  2.1691e+00,  ..., -1.2956e+00,\n",
            "         -1.1750e+00, -1.0619e+00],\n",
            "        ...,\n",
            "        [ 9.9244e-01, -1.5968e+00, -9.0283e+00,  ...,  2.5859e+00,\n",
            "          1.1472e+00, -5.8640e+00],\n",
            "        [-1.6431e+00, -1.0526e+00, -2.0351e+00,  ...,  3.1068e-01,\n",
            "          3.4039e-01, -4.4525e+00],\n",
            "        [-2.4366e+00, -1.3488e+00,  3.9525e-01,  ..., -2.7395e+00,\n",
            "         -3.5570e-01, -3.5944e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6494, -0.3109, -3.6746,  ..., -3.3220,  0.0593, -1.9112],\n",
            "        [-5.5697, -0.0446, -1.8558,  ...,  2.4028,  1.0731, -2.0355],\n",
            "        [-1.3559, -2.2478, -4.1579,  ..., -0.8744,  0.1686, -0.1628],\n",
            "        ...,\n",
            "        [ 2.9901, -4.5943, -3.9811,  ...,  3.5031,  0.7232, -3.1754],\n",
            "        [-4.2943,  4.5064, -0.0870,  ..., -1.2422,  1.7165, -0.6130],\n",
            "        [-2.7773, -1.0630, -5.1278,  ...,  0.5329,  2.1243, -4.0636]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7281,  0.1189, -5.9417,  ...,  2.1659,  0.8758, -2.3098],\n",
            "        [-0.7734, -1.5924, -3.2017,  ...,  1.6033,  0.5465, -2.1147],\n",
            "        [ 2.3551, -4.6995, -4.0428,  ..., -2.9445, -3.8337, -0.1358],\n",
            "        ...,\n",
            "        [-0.7887, -1.3832, -3.0809,  ..., -2.2913,  2.1829, -5.3452],\n",
            "        [ 1.9153, -5.2286, -2.4695,  ...,  1.9269,  0.6789, -4.0589],\n",
            "        [ 3.9573, -3.9765, -3.2787,  ...,  0.4572, -2.7161, -2.5385]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6565, -1.6935,  0.1469,  ..., -2.0720,  2.8517, -4.1823],\n",
            "        [ 0.1940, -2.9814, -4.4354,  ..., -0.8026, -0.2921, -2.5334],\n",
            "        [-1.1384, -1.1592, -2.3977,  ..., -0.0993, -0.9987, -0.8224],\n",
            "        ...,\n",
            "        [-1.1759,  1.6858, -6.6921,  ..., -1.6835,  0.7463, -4.0196],\n",
            "        [-1.2192,  4.2474, -0.1094,  ...,  0.8692,  1.1569,  0.4611],\n",
            "        [ 1.1230,  0.9582,  1.0023,  ..., -1.3776, -0.9477, -1.9812]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0010, -0.9649, -2.2224,  ..., -1.2743,  0.1984, -0.7432],\n",
            "        [-0.9258, -6.6570, -2.9055,  ...,  3.4058,  1.3398, -2.3527],\n",
            "        [-0.8427, -1.1999, -7.6685,  ...,  0.1330,  1.6209, -5.0124],\n",
            "        ...,\n",
            "        [-0.6110, -0.7254, -1.7198,  ..., -1.5540, -1.6226,  1.1990],\n",
            "        [-6.1710, -3.4759, -0.6781,  ..., -2.3294,  0.9212, -2.2903],\n",
            "        [ 1.8136, -3.9228, -5.1964,  ..., -0.0865, -1.9272, -2.8028]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2878, -2.4687, -1.8733,  ..., -0.6345,  2.1815, -1.1973],\n",
            "        [-2.2284,  1.7465, -2.0277,  ..., -3.1507,  0.1426,  0.0981],\n",
            "        [-1.8307,  0.2064, -2.5535,  ...,  5.1805,  2.1329, -1.6175],\n",
            "        ...,\n",
            "        [-0.7566, -0.0269, -3.5259,  ...,  5.2210,  0.5156, -1.7701],\n",
            "        [-1.3813,  3.4890,  0.0654,  ..., -2.0093,  0.3613, -1.1329],\n",
            "        [-3.0523,  3.8880,  0.1689,  ..., -2.7069, -0.2230,  0.7021]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0713,  1.0232,  0.3942,  ...,  1.3618,  2.8025, -4.8425],\n",
            "        [-4.6336,  0.6487, -1.2811,  ..., -2.5466,  1.0177, -1.4512],\n",
            "        [-7.0840,  3.7179, -0.5646,  ..., -1.1898,  0.2008, -2.7903],\n",
            "        ...,\n",
            "        [-6.7364, -0.4627, -1.5412,  ..., -0.8169,  0.6909, -5.0656],\n",
            "        [-3.8854,  4.8446, -0.8239,  ..., -1.9786,  3.7482, -2.6189],\n",
            "        [-2.8323,  5.3051, -2.8091,  ..., -3.3680,  1.1912, -2.2497]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-6.1853, -1.1280, -1.8010,  ..., -0.5554, -3.0695,  0.5258],\n",
            "        [ 5.8051, -8.7800, -1.2651,  ...,  2.8193,  1.7971, -4.5625],\n",
            "        [-6.2136,  0.1936, -1.9886,  ...,  2.0849,  2.5263, -4.5450],\n",
            "        ...,\n",
            "        [-0.7261, -3.1972, -1.1568,  ..., -1.1842, -0.4399, -1.5057],\n",
            "        [-3.1950, -3.1559, -3.8093,  ..., -0.8232, -1.7006, -3.5436],\n",
            "        [-2.5836,  0.6315, -3.1765,  ...,  3.2833,  2.2503, -3.1967]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5495, -3.7319,  0.4382,  ..., -0.1471, -0.7000, -2.3364],\n",
            "        [ 0.1762, -0.8562, -1.4542,  ..., -1.4472, -0.0970, -0.4027],\n",
            "        [-2.8456,  0.8759,  1.1012,  ...,  0.3283,  3.1187, -2.4839],\n",
            "        ...,\n",
            "        [-0.6060,  2.4843, -0.3612,  ..., -1.4976,  1.2310, -1.4489],\n",
            "        [-2.1870, -0.2375, -0.5449,  ...,  2.0778,  0.5318, -0.8803],\n",
            "        [ 0.5228, -1.3707, -4.2070,  ..., -0.8990,  1.5847, -1.3304]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0316, -3.2460, -3.6092,  ..., -1.1263,  0.0675,  0.2539],\n",
            "        [ 1.5708, -5.2516, -2.6689,  ..., -0.9367, -3.4983, -1.6146],\n",
            "        [-4.2806, -0.2746, -4.4100,  ..., -0.2373,  0.8169, -2.3209],\n",
            "        ...,\n",
            "        [-3.1047,  3.3336, -0.5527,  ..., -1.9765, -0.2466,  1.0182],\n",
            "        [-0.4110, -1.2739, -2.6482,  ...,  0.1337,  2.1434, -1.4533],\n",
            "        [-5.6516, -0.6835, -1.2051,  ...,  0.4453,  1.1335, -3.2395]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9316, -7.2761, -1.3834,  ...,  1.9877, -0.9753, -4.2688],\n",
            "        [-3.9032,  2.7173,  1.5309,  ..., -3.3075, -0.8320,  1.3325],\n",
            "        [ 1.1345, -7.6740, -4.2051,  ...,  3.9368, -1.9888, -4.0569],\n",
            "        ...,\n",
            "        [-1.2986, -1.8791, -1.3302,  ..., -1.6974, -0.0928, -2.8082],\n",
            "        [-1.7678, -0.5123,  0.9469,  ...,  7.9189,  2.5232, -0.2585],\n",
            "        [-0.8150, -2.4987, -4.0748,  ...,  4.1368,  0.4941, -3.2461]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.6260,  5.5217,  3.1339,  ..., -2.7967,  1.3342,  2.0164],\n",
            "        [-4.1633,  2.2619, -3.5144,  ..., -2.6152,  2.2017, -0.0252],\n",
            "        [ 2.0258, -3.9600, -4.5178,  ...,  6.5775,  1.0615,  1.5443],\n",
            "        ...,\n",
            "        [-0.4528,  0.6221, -1.9226,  ...,  2.1685,  1.8443, -0.9054],\n",
            "        [-3.1163,  5.4886,  5.2594,  ..., -1.9030,  0.9732, -0.6868],\n",
            "        [-4.2025,  0.8997,  1.1950,  ..., -2.9730,  2.1378, -1.8609]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8136,  6.1326,  5.0262,  ..., -1.9149, -0.1789, -0.0868],\n",
            "        [-0.0288,  1.4637, -1.7056,  ..., -0.2873,  1.2869, -0.6442],\n",
            "        [-2.6104,  0.9760, -5.1740,  ..., -0.7605,  0.1702, -1.4795],\n",
            "        ...,\n",
            "        [-1.1240,  2.6393, -1.6325,  ..., -3.7842,  0.2955, -0.5995],\n",
            "        [-3.5917,  2.9786, -1.2016,  ...,  1.2752,  0.5864, -4.1878],\n",
            "        [-1.5900,  2.0391, -1.2473,  ..., -2.9733,  0.7683, -1.8516]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5440, -2.2580, -3.6592,  ...,  0.2958, -0.0206, -2.5894],\n",
            "        [-4.8162,  2.6197, -4.0113,  ..., -2.0636,  2.5538, -1.6830],\n",
            "        [-4.8496,  0.1591, -4.0166,  ..., -0.2660,  1.4811, -5.4928],\n",
            "        ...,\n",
            "        [-1.6316, -0.1516, -3.7951,  ..., -0.8960,  1.2873,  0.0335],\n",
            "        [ 4.8956, -8.9193, -2.2092,  ...,  4.1632, -2.8033, -2.3662],\n",
            "        [-4.4736,  5.2721,  1.6026,  ..., -4.5941, -0.1828, -0.1314]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3314, -3.5067, -1.4770,  ...,  0.7840, -1.6074,  0.6019],\n",
            "        [ 2.0570, -3.3118, -1.6237,  ..., -0.2857,  2.0332, -1.5015],\n",
            "        [-3.1962, -4.6321, -2.5066,  ...,  0.8313,  3.7620, -5.5588],\n",
            "        ...,\n",
            "        [ 1.4241, -1.1951, -3.8380,  ...,  3.5444,  0.6933, -3.0215],\n",
            "        [ 0.1402, -2.9831, -1.0483,  ...,  0.3592, -0.6937, -0.9599],\n",
            "        [ 4.4829, -7.0097, -5.3859,  ...,  2.5994, -0.2818, -3.3479]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1260,  0.6286, -3.9441,  ...,  5.3046,  2.6839, -0.5890],\n",
            "        [-2.6476,  0.8258, -2.6025,  ..., -0.6256, -1.1602, -1.4556],\n",
            "        [ 0.1186, -0.5630, -3.7811,  ...,  3.9044,  2.5591, -2.0543],\n",
            "        ...,\n",
            "        [-3.5383,  2.7160,  1.0268,  ...,  1.1494, -0.0458, -1.9392],\n",
            "        [-0.5914, -0.9331, -0.5477,  ..., -1.2469,  0.1209, -0.3151],\n",
            "        [ 1.5164, -3.5793, -4.8059,  ...,  1.3815, -3.1595, -3.1146]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0227, -2.8347, -6.3280,  ...,  2.5046, -2.3685, -3.7251],\n",
            "        [ 0.0752, -1.9166,  0.1638,  ..., -0.0834, -0.9838, -1.4138],\n",
            "        [-4.7864,  0.1927, -0.3063,  ..., -0.8761,  0.7691, -5.4661],\n",
            "        ...,\n",
            "        [-2.0140,  0.6468, -3.2759,  ...,  3.0143, -0.0180, -2.3357],\n",
            "        [ 0.3721, -3.8188, -5.1005,  ...,  4.6759,  0.0435, -5.2495],\n",
            "        [-4.3761,  6.4583,  2.6232,  ..., -3.3324,  0.3002,  0.3007]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2187, -4.7686, -3.6081,  ..., -0.0231, -0.0359, -4.1629],\n",
            "        [-4.0032,  2.1009,  1.8372,  ..., -1.5163, -0.8895, -0.8125],\n",
            "        [-2.5172, -2.0679, -4.6824,  ...,  0.9317,  1.2028,  0.3782],\n",
            "        ...,\n",
            "        [ 1.2613, -3.2433, -6.5784,  ...,  3.0650,  0.7184, -4.8191],\n",
            "        [-2.4283,  6.6003,  3.9869,  ..., -0.5288,  0.0748, -1.2689],\n",
            "        [-1.9166, -2.3123, -3.9976,  ...,  0.1648,  2.0305, -3.0106]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2960, -0.0586, -2.8065,  ...,  0.4669,  0.2928, -1.8345],\n",
            "        [-3.1930,  5.0713,  4.3823,  ..., -2.3334, -0.7799, -1.5897],\n",
            "        [-1.8541,  4.5366, -0.7045,  ..., -2.9533,  0.6633, -2.7865],\n",
            "        ...,\n",
            "        [-4.2902,  2.6555,  1.5591,  ..., -3.5164,  0.1222, -3.2255],\n",
            "        [-0.5167,  1.1203, -1.1304,  ..., -1.3903,  0.2372, -1.4824],\n",
            "        [-2.8878, -1.1087, -4.8973,  ..., -1.7575, -0.7006, -1.2097]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8227, -1.5644, -7.0818,  ...,  4.8326,  0.4916, -3.4498],\n",
            "        [-2.3815,  2.1575,  0.0319,  ...,  0.1009, -0.1311,  0.0179],\n",
            "        [ 3.9283, -6.5866, -0.9237,  ...,  2.6437, -0.2123, -2.0909],\n",
            "        ...,\n",
            "        [ 6.5493, -7.5189, -1.6989,  ...,  5.6016,  0.3026, -3.5032],\n",
            "        [-2.4087,  2.5771,  2.8026,  ..., -3.1324,  1.3534,  0.3025],\n",
            "        [-2.1337, -0.4864, -2.6834,  ..., -0.1628, -0.4328, -0.5663]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4164, -2.2871, -1.1281,  ...,  1.8822, -3.0165, -1.6372],\n",
            "        [ 2.8861, -2.6790, -4.1076,  ..., -0.3854, -2.8074, -2.2913],\n",
            "        [-2.5804, -2.8772, -4.2207,  ...,  5.9016,  1.7318, -2.5228],\n",
            "        ...,\n",
            "        [-5.2830,  1.7671, -0.5733,  ...,  0.7847,  1.0199, -3.7138],\n",
            "        [-3.3674,  0.1914,  1.3132,  ..., -1.7119, -1.6784, -1.4717],\n",
            "        [-1.2420,  0.7896, -2.1084,  ..., -0.4219, -1.5494, -3.0316]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-7.1823e-01, -7.7556e-01, -2.0001e+00,  ...,  2.9010e+00,\n",
            "          3.2808e-01, -2.0899e+00],\n",
            "        [-2.3694e+00,  1.4380e+00, -2.2028e+00,  ..., -3.6317e+00,\n",
            "         -6.5362e-01, -2.8907e+00],\n",
            "        [ 1.5151e+00, -3.5905e+00, -2.7726e+00,  ..., -7.1197e-01,\n",
            "         -4.9102e+00, -4.6039e+00],\n",
            "        ...,\n",
            "        [-3.4881e+00,  2.0541e+00,  1.0803e+00,  ..., -3.2305e+00,\n",
            "         -1.0594e+00, -1.2543e+00],\n",
            "        [-4.0900e+00,  1.6214e+00, -1.2497e+00,  ..., -2.5846e+00,\n",
            "          2.0070e+00,  3.8808e-03],\n",
            "        [-2.2558e+00,  8.3099e-01,  4.2011e+00,  ...,  9.4590e-01,\n",
            "         -1.4143e+00, -1.6981e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9151,  0.2745,  1.8181,  ..., -0.4665,  0.0865, -2.8533],\n",
            "        [-2.8529, -0.3974,  0.7719,  ...,  0.2019, -3.3340, -1.3886],\n",
            "        [ 0.5646, -3.4388, -0.8937,  ...,  5.1027, -0.8670, -0.2199],\n",
            "        ...,\n",
            "        [ 0.6392, -2.3327, -4.2203,  ..., -0.3411,  0.6846, -4.8442],\n",
            "        [-0.3171, -2.2007, -1.2819,  ...,  0.4700, -2.7007, -0.5253],\n",
            "        [-6.0246,  5.3622,  0.2973,  ...,  1.5704,  0.7599, -0.9104]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2944, -1.2950, -3.2594,  ..., -0.4631, -2.7823, -0.8284],\n",
            "        [-0.7761, -0.8656, -5.5980,  ..., -0.4396, -2.6966, -3.4584],\n",
            "        [-7.0574,  4.6936, -3.1770,  ...,  1.9570,  3.4467, -3.3692],\n",
            "        ...,\n",
            "        [ 2.9763, -6.5986, -4.4694,  ..., -2.3192, -3.1280, -5.0702],\n",
            "        [-4.6577,  1.4822, -0.5441,  ...,  0.0591,  0.6836, -2.9738],\n",
            "        [-5.5762, -0.3964, -3.4001,  ...,  3.2875,  1.6910, -6.4265]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3686, -1.9708, -0.2275,  ..., -1.3268, -2.4852, -0.7451],\n",
            "        [-7.0898,  7.0715, -1.4770,  ..., -4.2831,  1.6875, -5.1621],\n",
            "        [-1.9292, -0.5317,  0.9730,  ..., -0.4258,  0.0371, -2.6353],\n",
            "        ...,\n",
            "        [-1.1219, -1.1713, -4.6375,  ..., -2.2672, -0.7987, -3.7205],\n",
            "        [-1.4904,  0.4532, -2.6898,  ...,  7.2509, -2.4145, -4.0160],\n",
            "        [ 1.7202, -5.6841, -4.1547,  ...,  0.6506, -3.3186, -2.4335]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.0795,  1.3190,  2.2045,  ..., -1.9975,  1.6921,  1.7151],\n",
            "        [-4.4009,  1.2215, -0.1169,  ..., -1.0111,  2.7297, -6.5242],\n",
            "        [-3.8985,  5.1319,  4.5922,  ...,  0.2075, -0.7727, -1.9745],\n",
            "        ...,\n",
            "        [ 0.1228, -2.4327, -0.4686,  ...,  2.0350, -1.8179, -2.9812],\n",
            "        [-3.7334,  0.7866, -1.2165,  ..., -0.8933,  1.1451, -3.8168],\n",
            "        [-0.1554, -6.2111, -4.7063,  ...,  7.2708, -3.0244, -3.4625]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.8573,  0.6240, -2.3454,  ...,  0.7034,  0.7770, -5.2399],\n",
            "        [-4.1563, -3.3999, -4.7029,  ..., -0.7885,  3.7765, -3.9269],\n",
            "        [ 3.2693, -2.7129, -0.6127,  ...,  0.3110,  0.0841, -2.0052],\n",
            "        ...,\n",
            "        [-4.3022,  2.4523, -3.7281,  ..., -1.9025,  0.4082, -2.8695],\n",
            "        [ 0.7121, -0.8874, -0.2922,  ..., -0.3606, -2.2293, -2.4345],\n",
            "        [-2.5526, -1.8454, -4.5772,  ..., -0.6582, -0.1736, -2.0895]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.7372,  0.6053, -0.4580,  ...,  0.7564, -0.2195, -1.3916],\n",
            "        [-0.2286, -3.1015, -1.2975,  ...,  3.7682, -1.3354, -3.2343],\n",
            "        [-4.8461, -2.1060, -1.4584,  ..., -1.0572,  1.9258, -4.4025],\n",
            "        ...,\n",
            "        [-2.8318, -0.8499, -2.3987,  ..., -1.6661,  2.2500, -5.8532],\n",
            "        [-4.2234, -0.4514, -2.6754,  ..., -0.7634, -1.3515, -1.4926],\n",
            "        [-3.1765, -0.2861,  0.5217,  ...,  2.8760, -1.0336, -1.9440]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2850, -3.1681, -1.4306,  ...,  1.1087, -0.5370, -3.7805],\n",
            "        [-3.5752,  2.6920, -3.8663,  ...,  2.0641,  1.4110, -4.9720],\n",
            "        [-0.1511, -2.4416, -3.4891,  ...,  2.8766,  0.4135, -3.7491],\n",
            "        ...,\n",
            "        [-0.1816, -1.9509, -8.1564,  ...,  6.4697, -0.0122, -4.5860],\n",
            "        [-2.5688,  1.2804,  0.2964,  ...,  0.6083,  0.8521, -2.9402],\n",
            "        [-3.3177,  4.8750,  3.2163,  ..., -1.9541, -0.4179, -1.9645]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7502, -1.3311, -2.2858,  ...,  0.1468,  2.4129, -3.9900],\n",
            "        [-4.4438,  0.4716, -1.4633,  ..., -1.3420,  1.9403, -0.8871],\n",
            "        [-1.4538,  0.3256,  0.0910,  ...,  1.8523, -0.2414, -0.5105],\n",
            "        ...,\n",
            "        [-6.2006,  1.9644, -1.3246,  ..., -1.3859, -0.3775,  0.0293],\n",
            "        [-0.9046, -3.2863, -5.8660,  ..., -0.7965, -0.4334, -1.2506],\n",
            "        [ 4.8338, -2.1964, -0.6442,  ..., -1.4292,  0.7009, -2.7006]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4910,  4.9410,  4.0084,  ..., -3.1481, -1.1579, -1.6159],\n",
            "        [-5.0054,  1.4590, -2.2580,  ..., -2.2133, -2.5947, -1.2475],\n",
            "        [-4.9507,  2.8759, -3.5071,  ...,  1.0678, -1.9087, -3.5679],\n",
            "        ...,\n",
            "        [-2.3866,  0.5604, -0.4074,  ..., -3.0983, -0.6520, -2.9703],\n",
            "        [ 2.4316,  0.0922, -1.7207,  ...,  5.2832, -1.1113, -1.2611],\n",
            "        [-2.9860,  1.5591, -3.5547,  ...,  0.7598, -1.3821, -3.4005]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9568, -2.5111, -4.6271,  ...,  2.8748,  0.6101, -4.7146],\n",
            "        [-2.0870, -0.0154, -2.1957,  ..., -3.4702, -0.7410, -1.2232],\n",
            "        [-5.7748,  5.0661, -2.1980,  ..., -0.0449,  2.7889, -2.7921],\n",
            "        ...,\n",
            "        [-3.2528,  4.1649, -0.3204,  ..., -2.4047, -0.9716, -0.7300],\n",
            "        [-2.2516, -3.0864, -1.1026,  ...,  0.6628, -3.9089, -1.8931],\n",
            "        [-2.3289,  2.6556,  0.3130,  ..., -2.7436, -0.4359, -1.1952]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4176, -2.2489, -4.7516,  ..., -1.7870, -1.4616, -1.3547],\n",
            "        [-3.4309, -3.4186, -0.9352,  ...,  0.0796, -3.0813, -0.6534],\n",
            "        [-2.6651,  4.7242,  3.5514,  ..., -0.3808, -0.4002, -1.4328],\n",
            "        ...,\n",
            "        [ 2.8761, -2.6334, -2.8625,  ...,  2.5836, -0.2505, -1.4842],\n",
            "        [-2.9537,  0.7894, -1.3962,  ..., -0.8970, -0.6399, -1.0458],\n",
            "        [-0.1666, -2.3434, -6.7874,  ...,  1.7995, -1.0638, -4.2963]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5134, -3.6033, -2.9438,  ..., -0.7280,  0.1275, -4.6947],\n",
            "        [ 1.6056, -6.8139, -3.2099,  ..., -0.4566, -0.1325, -3.7229],\n",
            "        [-3.9824,  5.6754,  3.4218,  ..., -3.3238, -0.0835, -1.8961],\n",
            "        ...,\n",
            "        [-3.5423,  2.8070, -2.0950,  ..., -1.2764,  1.4686, -1.4614],\n",
            "        [-3.3309,  3.3203,  1.0648,  ..., -3.7305, -0.0298, -0.7094],\n",
            "        [-1.0860, -1.2635, -3.3806,  ...,  0.5326,  0.1936, -4.6665]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7841, -4.1927, -1.3325,  ..., -2.4581,  0.1596, -4.5639],\n",
            "        [ 3.0046, -3.5200, -2.4044,  ...,  1.3704, -3.0654, -3.6406],\n",
            "        [ 3.5204, -4.0864, -3.1512,  ..., -0.8527, -0.7740, -4.2529],\n",
            "        ...,\n",
            "        [ 3.4260, -0.4714, -3.0720,  ...,  2.9523,  0.9075, -2.4891],\n",
            "        [-0.0730, -2.1244, -5.0231,  ...,  3.2319, -0.8963, -2.6568],\n",
            "        [-1.8551,  3.6314,  3.9237,  ...,  0.2476, -0.6623, -1.3486]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.4758,  6.7854,  3.0822,  ..., -1.2074, -2.9505, -2.4115],\n",
            "        [-5.0080,  0.2874, -3.3512,  ..., -1.6584,  2.5437, -6.4564],\n",
            "        [-1.1266,  1.9459, -1.5656,  ..., -2.5080,  0.4020, -4.7074],\n",
            "        ...,\n",
            "        [-3.3477, -1.9982, -7.6391,  ..., -1.4775, -0.9986, -2.5153],\n",
            "        [-3.7243,  3.7085,  2.4059,  ..., -0.1060, -0.4788, -1.6216],\n",
            "        [-0.7718, -3.0002, -0.9361,  ...,  0.1755, -2.4086, -2.0877]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2869, -5.4477, -3.9029,  ..., -4.1746, -1.3292, -1.6964],\n",
            "        [-1.7542, -0.4458,  1.9647,  ..., -0.4798, -1.2369, -1.5529],\n",
            "        [ 0.4631,  0.3050, -1.5297,  ...,  0.0299, -0.6739, -1.7937],\n",
            "        ...,\n",
            "        [-4.2139, -1.5344, -3.0995,  ...,  1.2114,  1.2201, -3.1873],\n",
            "        [ 1.1161, -3.8782, -6.8483,  ...,  3.4774, -1.1616, -4.3245],\n",
            "        [ 2.7168, -6.5437, -7.0388,  ...,  2.1568, -3.1225, -4.8406]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4275,  6.0989,  4.2999,  ..., -2.8629, -1.0138, -2.0003],\n",
            "        [ 0.5213, -2.2302, -2.8846,  ...,  3.8926,  2.9415, -2.2992],\n",
            "        [ 2.4950, -4.5558, -5.3992,  ...,  0.8073, -0.2026, -2.3210],\n",
            "        ...,\n",
            "        [-3.3492,  1.2442, -2.3891,  ..., -0.8685,  0.0411, -0.6967],\n",
            "        [ 2.6478, -3.5518, -3.7537,  ..., -0.8915, -0.3200, -2.1628],\n",
            "        [-7.0898,  5.4624, -4.3003,  ..., -3.0211, -0.2383, -5.1755]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.3293,  5.0683,  2.1152,  ..., -2.9278,  0.0540, -1.7484],\n",
            "        [-1.2420, -1.3172, -0.3607,  ..., -2.9738, -1.3306, -1.2067],\n",
            "        [ 0.1792, -2.9447, -4.2604,  ...,  0.7591,  0.5065, -2.4240],\n",
            "        ...,\n",
            "        [-2.8277,  1.5443, -1.9546,  ..., -1.2647, -0.5204, -7.1885],\n",
            "        [-0.8504, -0.1157, -2.1098,  ..., -1.5475, -0.8634, -1.6809],\n",
            "        [-2.7860,  4.7957,  4.0534,  ..., -2.4077,  0.6928, -1.8430]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.5035,  4.5299,  2.3424,  ...,  0.5450, -2.0174, -1.2740],\n",
            "        [-0.1997, -4.7171, -6.4516,  ..., -1.6540, -0.9826, -1.8002],\n",
            "        [-2.7022, -0.3416, -6.0179,  ..., -2.5262,  0.7891, -2.0370],\n",
            "        ...,\n",
            "        [-1.4152, -3.6605, -2.5009,  ...,  6.7244, -1.0504, -3.2217],\n",
            "        [-1.0648, -2.6590, -1.3237,  ..., -1.5879, -0.5133, -1.1472],\n",
            "        [-3.9504,  1.1792, -1.7189,  ..., -0.0656, -0.0905, -4.9656]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -0.2584,   0.0862,  -2.1806,  ...,   0.3021,  -2.1241,  -2.6419],\n",
            "        [  3.9330, -10.9582,  -4.4667,  ...,   0.7284,  -2.0373,  -4.9435],\n",
            "        [ -3.3324,   4.7220,  -0.8733,  ...,  -2.2157,  -0.3528,  -0.9679],\n",
            "        ...,\n",
            "        [ -2.8781,   1.0400,  -0.8654,  ...,  -1.3699,   0.2651,  -1.9422],\n",
            "        [ -7.1452,   6.3858,   0.7698,  ...,  -3.2695,   0.9811,  -3.9224],\n",
            "        [  6.2590, -10.2721,  -2.7314,  ...,  -0.1930,   0.5385,  -3.9435]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.9396,  0.9061, -2.4364,  ...,  0.0873,  0.3723, -3.5057],\n",
            "        [-0.4861,  0.2493, -0.8121,  ...,  0.1913, -1.2248, -3.3161],\n",
            "        [-3.8743,  5.5017,  3.8652,  ..., -0.6838, -1.3873, -2.0823],\n",
            "        ...,\n",
            "        [-0.4257, -1.8579, -4.3535,  ...,  1.5138, -1.0363, -2.8489],\n",
            "        [-5.0266,  1.6427, -0.5197,  ...,  0.4973,  1.3194, -3.6037],\n",
            "        [-3.9589, -1.3135, -0.5344,  ..., -0.0628,  0.3746, -3.7131]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3865, -2.0796,  0.2979,  ..., -1.8901, -0.3956, -1.6605],\n",
            "        [ 2.9420, -5.2638, -4.4235,  ...,  1.0961,  0.4833, -3.3828],\n",
            "        [-5.6710,  5.9288, -1.1024,  ...,  0.4040,  2.5684, -4.1323],\n",
            "        ...,\n",
            "        [-2.9623, -1.1843, -1.4438,  ..., -2.2877, -0.7234, -3.3199],\n",
            "        [-1.5559, -5.4694, -4.0283,  ...,  2.8755,  0.5480, -4.4432],\n",
            "        [-3.9036,  2.1433,  2.1346,  ..., -3.8566, -1.8924, -1.1042]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3755, -4.9794, -3.0262,  ...,  4.4780, -1.7066, -1.7328],\n",
            "        [ 1.2527, -4.2533, -2.6869,  ...,  0.3455, -1.9549,  1.5144],\n",
            "        [-1.8882, -2.9422, -5.1610,  ...,  5.4712, -1.5517, -5.1714],\n",
            "        ...,\n",
            "        [-2.3316,  4.7694,  3.7005,  ..., -1.9344, -0.8570, -1.3888],\n",
            "        [ 5.3715, -3.1913, -1.2355,  ...,  2.9718,  0.9956, -0.9350],\n",
            "        [-3.3654,  0.4105, -3.1003,  ..., -1.0104,  2.6118, -4.7866]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1119, -0.8917, -1.8690,  ..., -0.9686,  0.6678, -3.4541],\n",
            "        [-5.5862,  3.3722, -4.5693,  ..., -0.4752,  4.2957, -0.8836],\n",
            "        [-2.2364,  4.4648,  3.0475,  ..., -1.3034, -0.3935, -0.9761],\n",
            "        ...,\n",
            "        [-2.9747, -0.2680, -1.5076,  ..., -2.5608, -2.4206, -2.3313],\n",
            "        [-2.4713, -0.0290, -1.4780,  ...,  2.3496, -0.5500, -2.8328],\n",
            "        [-4.8598,  0.8660,  0.4468,  ..., -1.1209,  1.7208, -1.1202]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1273,  0.1177, -0.5708,  ...,  3.6125, -0.9481, -0.7293],\n",
            "        [-1.9376, -2.8762, -0.3056,  ...,  2.6624,  0.2548, -2.1567],\n",
            "        [-2.0320,  0.2775, -0.7674,  ...,  2.0443, -1.6253, -4.1771],\n",
            "        ...,\n",
            "        [-1.6018, -0.5485, -3.8435,  ...,  3.5546,  0.4602, -4.0282],\n",
            "        [-0.8377, -2.3523, -1.7732,  ...,  2.8538,  0.8419, -3.3611],\n",
            "        [ 1.0193, -4.7483, -5.3726,  ...,  1.7400, -2.2467, -3.6280]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.4444, -0.9103, -2.3796,  ...,  2.5319, -0.8187, -5.2909],\n",
            "        [-3.0149, -3.9178, -3.6988,  ...,  0.6274, -1.3058, -4.8266],\n",
            "        [-2.6873, -2.8264, -4.0207,  ..., -0.2055, -0.6437, -1.0601],\n",
            "        ...,\n",
            "        [-0.9341,  0.3821, -2.0201,  ..., -0.6362, -0.4522, -1.5917],\n",
            "        [-2.8618,  5.9131,  4.9308,  ..., -2.7020, -0.3293, -2.6520],\n",
            "        [-1.8321, -0.3211, -2.2893,  ..., -1.8133, -0.3812, -1.5918]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7649, -5.7917, -1.6639,  ...,  0.4345, -3.3490,  0.4952],\n",
            "        [-1.6661, -3.4258, -2.8844,  ...,  4.3704, -0.0846, -2.7012],\n",
            "        [-1.4972, -4.4500, -5.4111,  ...,  2.8183, -0.8659, -7.3686],\n",
            "        ...,\n",
            "        [-2.2506, -5.0484, -2.2589,  ..., -0.8762, -1.9133, -3.1494],\n",
            "        [ 0.9611, -1.1593, -2.8646,  ...,  1.7381,  1.6388, -4.1059],\n",
            "        [-1.8523,  0.1659, -2.2855,  ...,  0.1398,  0.5046, -5.2025]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.1891,  6.9932,  2.5380,  ..., -2.0541,  1.8774, -4.2158],\n",
            "        [-4.2361,  2.8108, -1.0713,  ..., -2.6620,  2.8897, -2.8794],\n",
            "        [-5.9535,  6.1235, -4.6808,  ...,  1.1669,  2.0466, -1.9818],\n",
            "        ...,\n",
            "        [-0.5524, -2.3521,  4.2619,  ..., -0.4727, -1.6058, -2.2837],\n",
            "        [-3.7471, -0.5550, -3.1223,  ...,  2.0252, -0.2876, -3.4338],\n",
            "        [-3.8586, -5.1993, -4.6732,  ...,  3.4701, -1.8096, -0.3950]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2376,  1.6731,  0.0629,  ..., -3.8061,  0.1612, -3.6547],\n",
            "        [-3.1780,  4.6476,  1.8865,  ..., -1.7859, -0.0331, -4.4419],\n",
            "        [ 2.0608, -4.3956, -3.9504,  ...,  3.9511,  0.4043, -2.3733],\n",
            "        ...,\n",
            "        [ 2.1286, -0.5184, -1.7030,  ..., -0.3143,  1.3150, -3.8674],\n",
            "        [-3.7847, -2.1495, -2.9782,  ...,  0.3660,  1.8114, -4.6530],\n",
            "        [-0.1099,  1.1457, -1.7926,  ..., -0.1961,  0.0923, -2.6383]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4666,  1.4429, -5.2403,  ..., -0.6302, -1.0385, -2.7297],\n",
            "        [-2.5498,  3.2413,  0.4902,  ..., -1.4620, -0.1165, -0.5348],\n",
            "        [-0.7870, -2.5641, -3.5435,  ..., -0.1402, -0.4953, -3.9613],\n",
            "        ...,\n",
            "        [ 2.0968, -2.5174,  2.8154,  ..., -0.9398, -1.3062, -1.5760],\n",
            "        [-3.2605, -0.6533, -5.2178,  ..., -0.8318, -0.5908, -2.4358],\n",
            "        [-0.9241, -0.3615,  2.9427,  ...,  0.4015, -0.1353, -2.7747]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1755, -3.7710, -1.7821,  ..., -1.3892, -1.0800, -4.0456],\n",
            "        [-3.5622, -3.8841, -5.5879,  ..., -0.5586,  0.2807, -3.9878],\n",
            "        [-3.4409, -5.0529, -5.2654,  ..., -2.0416,  0.3619, -4.5768],\n",
            "        ...,\n",
            "        [-1.4286, -4.4905, -3.6624,  ..., -1.0422, -0.8070, -5.0616],\n",
            "        [-4.5259,  2.2528, -0.7852,  ...,  1.6892,  1.5273, -1.7246],\n",
            "        [-2.3066,  1.6090,  2.3101,  ..., -1.4253, -1.3806, -2.0610]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.2835,  5.9844, -1.0346,  ..., -0.6607,  2.4607, -3.4673],\n",
            "        [-7.5481,  4.2477, -0.7467,  ...,  0.8339,  4.7511, -2.3727],\n",
            "        [-1.1595, -1.6981, -0.1659,  ...,  1.8902, -3.1148, -4.7864],\n",
            "        ...,\n",
            "        [-3.7013,  0.0499, -3.7142,  ..., -1.0021,  0.6449, -4.9531],\n",
            "        [-1.4018, -1.2768, -0.6356,  ...,  0.3632,  0.4586, -4.9684],\n",
            "        [-0.3601, -6.8333, -3.9893,  ...,  3.1841, -0.0871, -4.7208]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.4811e+00,  1.0090e+00, -1.3567e+00,  ...,  5.5206e-04,\n",
            "          2.6309e+00, -6.0090e+00],\n",
            "        [-2.2076e+00,  3.1207e-01, -1.6359e-01,  ...,  1.8686e-01,\n",
            "          1.1947e+00, -5.5462e+00],\n",
            "        [-4.8556e+00,  9.8818e-01, -2.3208e+00,  ..., -3.0089e-01,\n",
            "          8.5484e-01, -4.3308e+00],\n",
            "        ...,\n",
            "        [-3.2899e+00,  5.1133e-01, -7.0424e-01,  ..., -2.6477e-01,\n",
            "          1.3549e+00, -3.1079e+00],\n",
            "        [ 2.9405e+00, -1.6407e+00,  5.2587e-01,  ...,  3.5593e-01,\n",
            "          7.8512e-01, -2.6591e+00],\n",
            "        [-4.4594e-01, -6.7550e-02, -9.4147e-01,  ...,  5.4851e-01,\n",
            "          2.7735e-01, -3.9871e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ -1.9170,  -0.3609,  -3.0486,  ...,  -3.1398,  -0.7598,  -2.4214],\n",
            "        [ -3.4836,  -1.6937,  -2.5273,  ...,   0.2806,  -0.3124,  -3.6808],\n",
            "        [  4.4777,  -3.2760,   1.1130,  ...,   1.0659,  -4.6307,  -1.4126],\n",
            "        ...,\n",
            "        [  3.8769, -11.0810,  -7.3143,  ...,  -0.6586,  -5.0989,  -4.0180],\n",
            "        [ -1.4166,   2.0206,   0.2362,  ...,  -3.4246,   0.7238,  -3.2551],\n",
            "        [  0.6400,   0.0138,  -3.7314,  ...,   2.6140,  -0.6698,  -2.8410]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9439, -4.9130, -4.0688,  ..., -0.0801, -4.5447, -1.3828],\n",
            "        [ 2.2424, -3.6207, -3.2552,  ...,  2.7065,  0.7121, -2.1808],\n",
            "        [-0.3077, -4.4433, -4.9516,  ...,  5.2068,  0.9664, -3.1323],\n",
            "        ...,\n",
            "        [-1.8976, -1.7674, -2.9407,  ...,  3.2613, -0.2916, -2.3979],\n",
            "        [-5.6908, -4.9501, -6.7880,  ...,  2.4801, -3.3641, -4.6846],\n",
            "        [-3.0067,  4.1051,  5.0319,  ...,  0.2793,  0.0984, -1.5854]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0237,  2.9735,  0.3367,  ..., -3.5588, -0.7288, -1.0733],\n",
            "        [-4.0795, -2.3534, -1.8004,  ..., -1.6268,  0.8173, -0.9365],\n",
            "        [-0.3785, -6.3336, -4.5095,  ...,  3.1593, -1.6754, -3.5782],\n",
            "        ...,\n",
            "        [-3.2514, -2.4045,  1.6566,  ...,  3.3274, -0.7094, -1.3601],\n",
            "        [-1.6237,  0.3752, -0.9074,  ...,  0.4893,  1.1822, -1.5280],\n",
            "        [-1.7234,  3.0337,  1.9742,  ..., -1.8901, -0.4996, -1.8090]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4320, -1.2114, -0.4283,  ...,  0.8945, -0.6885, -1.3990],\n",
            "        [ 3.1461, -6.5307, -2.9477,  ...,  2.8546, -0.0237, -3.6906],\n",
            "        [-5.0604,  1.3854, -0.9169,  ..., -1.8988,  1.0212, -1.0023],\n",
            "        ...,\n",
            "        [-0.6556, -1.6863, -3.6725,  ...,  6.1636,  2.8795, -3.6944],\n",
            "        [-4.2586, -0.9794, -4.4558,  ..., -1.1798,  3.7157, -3.3673],\n",
            "        [-1.5355,  0.0834, -6.0981,  ...,  1.9654,  1.7854, -4.6385]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7116, -2.7353, -2.7133,  ..., -1.8977, -4.6287, -2.0525],\n",
            "        [-2.9088, -2.7368, -5.1607,  ...,  2.8765, -4.0467, -3.7564],\n",
            "        [-4.9801,  4.7466,  0.8518,  ..., -0.0814,  1.0105, -3.7582],\n",
            "        ...,\n",
            "        [ 0.1142, -1.1851, -2.9566,  ..., -0.5257, -0.4520, -4.3660],\n",
            "        [-0.5348, -0.0666, -2.0729,  ..., -0.6645,  2.5915, -3.8674],\n",
            "        [-2.1235, -1.9476, -1.9435,  ...,  0.8279, -1.3668, -0.9386]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6730,  3.6025,  0.8628,  ..., -1.1059, -0.8352, -2.4983],\n",
            "        [-3.8033, -0.5688,  0.2153,  ..., -1.8113, -1.6911, -3.5593],\n",
            "        [-0.5368, -2.9058, -1.6011,  ...,  2.7403,  1.4650, -3.1566],\n",
            "        ...,\n",
            "        [ 2.3523, -8.2353, -7.0896,  ..., -0.3356, -4.5007, -5.0110],\n",
            "        [-0.5669, -6.0702, -2.8325,  ...,  2.2414, -0.9784, -2.8325],\n",
            "        [-1.1453, -1.4368, -2.9248,  ...,  5.5331,  0.9568, -3.3035]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        }
      ],
      "source": [
        "def train(args: SimpleMLPTrainingArgs) -> tuple[list[float], list[float], SimpleMLP]:\n",
        "    \"\"\"\n",
        "    Trains the model, using training parameters from the `args` object. Returns the model, and lists of loss & accuracy.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE - add a validation loop to the train function from above\n",
        "\n",
        "    epochs = args.epochs\n",
        "    learning_rate = args.learning_rate\n",
        "    batch_size = args.batch_size\n",
        "\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    train_loader = DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(mnist_testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      pbar = tqdm(train_loader)\n",
        "      for img, labels in train_loader:\n",
        "\n",
        "        img, labels = img.to(device), labels.to(device)\n",
        "\n",
        "        # 1. take batch and do forward pass\n",
        "        logits = model(img)\n",
        "        # 2. reset gradients\n",
        "        optimizer.zero_grad()\n",
        "        # 3. calculate loss on logits\n",
        "        loss = loss_function(logits, labels)\n",
        "        # 4. do backward pass\n",
        "        loss.backward()\n",
        "        # 5. use gradients to update parameters\n",
        "        optimizer.step()\n",
        "        # 6. continue\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "      # validate after each epoch:\n",
        "      with t.inference_mode(False):\n",
        "\n",
        "        # forward pass with val set\n",
        "        num_correct_classifications = 0\n",
        "        for img, labels in val_loader:\n",
        "          img, labels = img.to(device), labels.to(device)\n",
        "\n",
        "          logits = model(img)\n",
        "\n",
        "          # get pred classes\n",
        "          y_hat = t.argmax(logits, dim=1)\n",
        "          num_correct_classifications += (y_hat == labels).sum().item()\n",
        "\n",
        "      # Compute & log total accuracy\n",
        "      accuracy = num_correct_classifications / len(val_loader)\n",
        "      accuracy_list.append(accuracy)\n",
        "\n",
        "    return loss_list, accuracy_list, model\n",
        "\n",
        "\n",
        "args = SimpleMLPTrainingArgs()\n",
        "loss_list, accuracy_list, model = train(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_list)"
      ],
      "metadata": {
        "id": "_F0x_9h_G996",
        "outputId": "8f041305-a6f3-46e8-c538-314757d08d99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[57.1875, 57.125, 58.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o8M8odHlG7V0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XkofcnZKjBUO",
        "outputId": "e6515d1f-8da4-4ddd-db33-dc2bc350bffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"723ed606-c83d-4f3e-84bb-fb37382ad0d8\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"723ed606-c83d-4f3e-84bb-fb37382ad0d8\")) {                    Plotly.newPlot(                        \"723ed606-c83d-4f3e-84bb-fb37382ad0d8\",                        [{\"name\":\"Cross entropy loss\",\"x\":[0.0,63.829787234042556,127.65957446808511,191.48936170212767,255.31914893617022,319.1489361702128,382.97872340425533,446.8085106382979,510.63829787234044,574.468085106383,638.2978723404256,702.1276595744681,765.9574468085107,829.7872340425532,893.6170212765958,957.4468085106383,1021.2765957446809,1085.1063829787236,1148.936170212766,1212.7659574468084,1276.595744680851,1340.4255319148938,1404.2553191489362,1468.0851063829787,1531.9148936170213,1595.744680851064,1659.5744680851064,1723.404255319149,1787.2340425531916,1851.0638297872342,1914.8936170212767,1978.723404255319,2042.5531914893618,2106.3829787234044,2170.212765957447,2234.0425531914893,2297.872340425532,2361.7021276595747,2425.531914893617,2489.3617021276596,2553.191489361702,2617.021276595745,2680.8510638297876,2744.68085106383,2808.5106382978724,2872.340425531915,2936.1702127659573,3000.0,3063.8297872340427,3127.6595744680853,3191.489361702128,3255.31914893617,3319.148936170213,3382.9787234042556,3446.808510638298,3510.6382978723404,3574.468085106383,3638.297872340426,3702.1276595744685,3765.9574468085107,3829.7872340425533,3893.617021276596,3957.446808510638,4021.276595744681,4085.1063829787236,4148.936170212766,4212.765957446809,4276.595744680852,4340.425531914894,4404.255319148936,4468.085106382979,4531.914893617021,4595.744680851064,4659.574468085107,4723.404255319149,4787.234042553192,4851.063829787234,4914.893617021276,4978.723404255319,5042.553191489362,5106.382978723404,5170.212765957447,5234.04255319149,5297.8723404255325,5361.702127659575,5425.531914893617,5489.36170212766,5553.191489361702,5617.021276595745,5680.851063829788,5744.68085106383,5808.510638297873,5872.340425531915,5936.170212765957,6000.0,6063.829787234043,6127.659574468085,6191.489361702128,6255.319148936171,6319.148936170213,6382.978723404256,6446.808510638298,6510.63829787234,6574.468085106383,6638.297872340426,6702.127659574468,6765.957446808511,6829.787234042554,6893.617021276596,6957.446808510638,7021.276595744681,7085.106382978724,7148.936170212766,7212.765957446809,7276.595744680852,7340.425531914894,7404.255319148937,7468.085106382979,7531.914893617021,7595.744680851064,7659.574468085107,7723.404255319149,7787.234042553192,7851.063829787235,7914.893617021276,7978.723404255319,8042.553191489362,8106.382978723404,8170.212765957447,8234.04255319149,8297.872340425532,8361.702127659575,8425.531914893618,8489.36170212766,8553.191489361703,8617.021276595746,8680.851063829788,8744.68085106383,8808.510638297872,8872.340425531915,8936.170212765957,9000.0,9063.829787234043,9127.659574468085,9191.489361702128,9255.31914893617,9319.148936170213,9382.978723404256,9446.808510638299,9510.638297872341,9574.468085106384,9638.297872340427,9702.127659574468,9765.95744680851,9829.787234042553,9893.617021276596,9957.446808510638,10021.27659574468,10085.106382978724,10148.936170212766,10212.765957446809,10276.595744680852,10340.425531914894,10404.255319148937,10468.08510638298,10531.914893617022,10595.744680851065,10659.574468085108,10723.40425531915,10787.234042553191,10851.063829787234,10914.893617021276,10978.72340425532,11042.553191489362,11106.382978723404,11170.212765957447,11234.04255319149,11297.872340425532,11361.702127659575,11425.531914893618,11489.36170212766,11553.191489361703,11617.021276595746,11680.851063829788,11744.68085106383,11808.510638297872,11872.340425531915,11936.170212765957,12000.0,12063.829787234043,12127.659574468085,12191.489361702128,12255.31914893617,12319.148936170213,12382.978723404256,12446.808510638299,12510.638297872341,12574.468085106384,12638.297872340427,12702.12765957447,12765.957446808512,12829.787234042553,12893.617021276596,12957.446808510638,13021.27659574468,13085.106382978724,13148.936170212766,13212.765957446809,13276.595744680852,13340.425531914894,13404.255319148937,13468.08510638298,13531.914893617022,13595.744680851065,13659.574468085108,13723.40425531915,13787.234042553191,13851.063829787234,13914.893617021276,13978.72340425532,14042.553191489362,14106.382978723404,14170.212765957447,14234.04255319149,14297.872340425532,14361.702127659575,14425.531914893618,14489.36170212766,14553.191489361703,14617.021276595746,14680.851063829788,14744.680851063831,14808.510638297874,14872.340425531915,14936.170212765957,15000.0,15063.829787234043,15127.659574468085,15191.489361702128,15255.31914893617,15319.148936170213,15382.978723404256,15446.808510638299,15510.638297872341,15574.468085106384,15638.297872340427,15702.12765957447,15765.957446808512,15829.787234042553,15893.617021276596,15957.446808510638,16021.27659574468,16085.106382978724,16148.936170212766,16212.765957446809,16276.595744680852,16340.425531914894,16404.255319148935,16468.08510638298,16531.91489361702,16595.744680851065,16659.574468085106,16723.40425531915,16787.23404255319,16851.063829787236,16914.893617021276,16978.72340425532,17042.55319148936,17106.382978723406,17170.212765957447,17234.04255319149,17297.872340425532,17361.702127659577,17425.531914893618,17489.36170212766,17553.191489361703,17617.021276595744,17680.85106382979,17744.68085106383,17808.510638297874,17872.340425531915,17936.17021276596,18000.0,18063.829787234044,18127.659574468085,18191.48936170213,18255.31914893617,18319.148936170215,18382.978723404256,18446.808510638297,18510.63829787234,18574.468085106382,18638.297872340427,18702.127659574468,18765.957446808512,18829.787234042553,18893.617021276597,18957.44680851064,19021.276595744683,19085.106382978724,19148.936170212768,19212.76595744681,19276.595744680853,19340.425531914894,19404.255319148935,19468.08510638298,19531.91489361702,19595.744680851065,19659.574468085106,19723.40425531915,19787.23404255319,19851.063829787236,19914.893617021276,19978.72340425532,20042.55319148936,20106.382978723406,20170.212765957447,20234.04255319149,20297.872340425532,20361.702127659577,20425.531914893618,20489.36170212766,20553.191489361703,20617.021276595744,20680.85106382979,20744.68085106383,20808.510638297874,20872.340425531915,20936.17021276596,21000.0,21063.829787234044,21127.659574468085,21191.48936170213,21255.31914893617,21319.148936170215,21382.978723404256,21446.8085106383,21510.63829787234,21574.468085106382,21638.297872340427,21702.127659574468,21765.957446808512,21829.787234042553,21893.617021276597,21957.44680851064,22021.276595744683,22085.106382978724,22148.936170212768,22212.76595744681,22276.595744680853,22340.425531914894,22404.25531914894,22468.08510638298,22531.91489361702,22595.744680851065,22659.574468085106,22723.40425531915,22787.23404255319,22851.063829787236,22914.893617021276,22978.72340425532,23042.55319148936,23106.382978723406,23170.212765957447,23234.04255319149,23297.872340425532,23361.702127659577,23425.531914893618,23489.36170212766,23553.191489361703,23617.021276595744,23680.85106382979,23744.68085106383,23808.510638297874,23872.340425531915,23936.17021276596,24000.0,24063.829787234044,24127.659574468085,24191.48936170213,24255.31914893617,24319.148936170215,24382.978723404256,24446.8085106383,24510.63829787234,24574.468085106382,24638.297872340427,24702.127659574468,24765.957446808512,24829.787234042553,24893.617021276597,24957.44680851064,25021.276595744683,25085.106382978724,25148.936170212768,25212.76595744681,25276.595744680853,25340.425531914894,25404.25531914894,25468.08510638298,25531.914893617024,25595.744680851065,25659.574468085106,25723.40425531915,25787.23404255319,25851.063829787236,25914.893617021276,25978.72340425532,26042.55319148936,26106.382978723406,26170.212765957447,26234.04255319149,26297.872340425532,26361.702127659577,26425.531914893618,26489.361702127662,26553.191489361703,26617.021276595744,26680.85106382979,26744.68085106383,26808.510638297874,26872.340425531915,26936.17021276596,27000.0,27063.829787234044,27127.659574468085,27191.48936170213,27255.31914893617,27319.148936170215,27382.978723404256,27446.8085106383,27510.63829787234,27574.468085106382,27638.297872340427,27702.127659574468,27765.957446808512,27829.787234042553,27893.617021276597,27957.44680851064,28021.276595744683,28085.106382978724,28148.936170212768,28212.76595744681,28276.595744680853,28340.425531914894,28404.25531914894,28468.08510638298,28531.914893617024,28595.744680851065,28659.574468085106,28723.40425531915,28787.23404255319,28851.063829787236,28914.893617021276,28978.72340425532,29042.55319148936,29106.382978723406,29170.212765957447,29234.04255319149,29297.872340425532,29361.702127659577,29425.531914893618,29489.361702127662,29553.191489361703,29617.021276595748,29680.85106382979,29744.68085106383,29808.510638297874,29872.340425531915,29936.17021276596,30000.0],\"y\":[2.9183456897735596,2.5248680114746094,2.176180839538574,2.2776784896850586,1.8601657152175903,1.4974809885025024,1.6081256866455078,1.5425715446472168,1.3262672424316406,1.1358948945999146,1.013547658920288,1.2440634965896606,1.023200273513794,0.85304856300354,0.823371946811676,1.0671173334121704,0.7620373964309692,0.7476515173912048,0.5597168803215027,0.6152001023292542,0.5123674869537354,0.7319121956825256,0.8060936331748962,0.5512556433677673,0.5665282607078552,0.6729820966720581,0.6320918202400208,0.5794658660888672,0.508164644241333,0.6307913064956665,0.5133498311042786,0.45148009061813354,0.4821736216545105,0.7862743735313416,0.5918197631835938,0.35774603486061096,0.2164730727672577,0.41209495067596436,0.612002968788147,0.5506156086921692,0.6853291392326355,0.6059923768043518,0.36450421810150146,0.41578957438468933,0.5612345337867737,0.4439994990825653,0.3662181794643402,0.5159077048301697,0.49146533012390137,0.4726737439632416,0.42973995208740234,0.5389348268508911,0.42993462085723877,0.4343843162059784,0.5205205082893372,0.5062098503112793,0.436587393283844,0.2965557873249054,0.44182902574539185,0.4363943934440613,0.4686799645423889,0.50795978307724,0.3504219055175781,0.2844884693622589,0.46903401613235474,0.510057270526886,0.4638046622276306,0.5401068329811096,0.5668330192565918,0.39063674211502075,0.33316928148269653,0.4356374740600586,0.41542184352874756,0.32609862089157104,0.2719426453113556,0.49392634630203247,0.1731700748205185,0.3743639588356018,0.2085200846195221,0.24236613512039185,0.4884294271469116,0.3325022757053375,0.31952396035194397,0.440902441740036,0.2525251507759094,0.32457196712493896,0.4611268937587738,0.29139208793640137,0.587793231010437,0.3083969056606293,0.19588671624660492,0.32097116112709045,0.34709835052490234,0.2003130167722702,0.30039918422698975,0.3147086203098297,0.6188477277755737,0.3014826476573944,0.2850853502750397,0.2632963955402374,0.4971199929714203,0.34590446949005127,0.3423030376434326,0.354773610830307,0.32741114497184753,0.18072471022605896,0.37525928020477295,0.2398252785205841,0.24641123414039612,0.6118471622467041,0.23291726410388947,0.15997424721717834,0.2912060618400574,0.418539822101593,0.3227081596851349,0.31737270951271057,0.40250420570373535,0.2987653315067291,0.22432754933834076,0.41237643361091614,0.28047555685043335,0.13509583473205566,0.2977561950683594,0.26658210158348083,0.3419089615345001,0.2676352262496948,0.12086570262908936,0.289045125246048,0.3236772119998932,0.27658671140670776,0.3509920537471771,0.3900235593318939,0.4205036163330078,0.3386188745498657,0.32564470171928406,0.2314901053905487,0.16515810787677765,0.3865567743778229,0.36150631308555603,0.4004061818122864,0.13710322976112366,0.38345810770988464,0.22885359823703766,0.22896400094032288,0.4758477807044983,0.30567896366119385,0.20889833569526672,0.1893404722213745,0.2610262632369995,0.4532073736190796,0.25652334094047546,0.40487194061279297,0.23375721275806427,0.31620901823043823,0.15123213827610016,0.3797741234302521,0.17189660668373108,0.20419274270534515,0.14305168390274048,0.16859738528728485,0.13148631155490875,0.3105452358722687,0.2266695350408554,0.2350575029850006,0.2290899008512497,0.17063497006893158,0.14222490787506104,0.12470339238643646,0.1689910590648651,0.17806430160999298,0.16734355688095093,0.2944759428501129,0.21897384524345398,0.22659961879253387,0.1362805962562561,0.22496990859508514,0.35906782746315,0.3296273946762085,0.1948666274547577,0.2767138183116913,0.3211389183998108,0.1538538634777069,0.11004447191953659,0.11057299375534058,0.2716059386730194,0.2577308118343353,0.486788809299469,0.2656596004962921,0.32311657071113586,0.14856112003326416,0.14363785088062286,0.2595312297344208,0.2705720365047455,0.20543301105499268,0.2623346149921417,0.23949730396270752,0.29943838715553284,0.24289730191230774,0.12305611371994019,0.04341404139995575,0.31533750891685486,0.23932066559791565,0.10934354364871979,0.3542685806751251,0.3423132598400116,0.4031231701374054,0.3080463409423828,0.2554294764995575,0.1606179028749466,0.3088458776473999,0.2149023860692978,0.3285170793533325,0.18544918298721313,0.12557707726955414,0.39468318223953247,0.11083496361970901,0.2981099486351013,0.20951931178569794,0.2755202054977417,0.3161439895629883,0.2124590426683426,0.18307611346244812,0.2868374288082123,0.14502741396427155,0.2356448918581009,0.228481724858284,0.15043893456459045,0.2564367353916168,0.3067338168621063,0.21567986905574799,0.2371571660041809,0.20922285318374634,0.2852623760700226,0.2292206585407257,0.1256462037563324,0.1883365958929062,0.23145629465579987,0.18510234355926514,0.13407163321971893,0.19002212584018707,0.3182785212993622,0.2618075907230377,0.09233500808477402,0.27941983938217163,0.10224252939224243,0.15427622199058533,0.15184040367603302,0.10946295410394669,0.15554945170879364,0.17659853398799896,0.18127384781837463,0.20526468753814697,0.2166338711977005,0.3078136146068573,0.34737953543663025,0.12422122061252594,0.3058895766735077,0.18339189887046814,0.15597310662269592,0.2307102382183075,0.34240248799324036,0.15783308446407318,0.16603632271289825,0.11853145807981491,0.25596851110458374,0.12803255021572113,0.24968202412128448,0.2464994639158249,0.1590065062046051,0.17555274069309235,0.16805267333984375,0.16595222055912018,0.11092017590999603,0.27532896399497986,0.30037373304367065,0.27249762415885925,0.20577681064605713,0.1822068840265274,0.13657522201538086,0.286833256483078,0.23474963009357452,0.22173874080181122,0.29383385181427,0.16961988806724548,0.11220364272594452,0.19368211925029755,0.15559221804141998,0.11042580008506775,0.22466906905174255,0.15925705432891846,0.2072380632162094,0.13474179804325104,0.17055536806583405,0.15210597217082977,0.20442339777946472,0.12416081875562668,0.15720923244953156,0.33871766924858093,0.10337448120117188,0.13335153460502625,0.08633622527122498,0.23427996039390564,0.05489305779337883,0.14974650740623474,0.1409795731306076,0.0957561507821083,0.5283980369567871,0.2331826239824295,0.28256210684776306,0.11861968040466309,0.18957345187664032,0.19759462773799896,0.18658852577209473,0.22709950804710388,0.17102164030075073,0.14573431015014648,0.19773590564727783,0.06334611773490906,0.15956901013851166,0.14538422226905823,0.2162640541791916,0.21952462196350098,0.11903396248817444,0.18223679065704346,0.086748406291008,0.0919349268078804,0.3249640166759491,0.19500190019607544,0.09762078523635864,0.14694540202617645,0.20226983726024628,0.16458812355995178,0.1513892412185669,0.07959883660078049,0.21583569049835205,0.13789312541484833,0.12185133248567581,0.12434805929660797,0.2793043851852417,0.08485241234302521,0.41203421354293823,0.20728591084480286,0.14636950194835663,0.09236709028482437,0.14390510320663452,0.10265637934207916,0.20902001857757568,0.07744282484054565,0.279630184173584,0.10623955726623535,0.0777202919125557,0.124917171895504,0.14553770422935486,0.05565294995903969,0.20590505003929138,0.125243678689003,0.20712006092071533,0.10032437741756439,0.2182449996471405,0.10933821648359299,0.12258434295654297,0.19114230573177338,0.0725756511092186,0.19823357462882996,0.17954951524734497,0.17455154657363892,0.09862193465232849,0.08652681857347488,0.11802893877029419,0.09100793302059174,0.2059382051229477,0.16534528136253357,0.24861134588718414,0.17737939953804016,0.1121455505490303,0.12718245387077332,0.24432869255542755,0.11689814180135727,0.11163561046123505,0.26730918884277344,0.27020028233528137,0.1170930415391922,0.12779875099658966,0.09045903384685516,0.09701666980981827,0.23114104568958282,0.08651372045278549,0.07718420773744583,0.13129381835460663,0.31832945346832275,0.0956377312541008,0.1411421298980713,0.10607518255710602,0.09524662047624588,0.06882062554359436,0.15566036105155945,0.10357970744371414,0.17451824247837067,0.08635454624891281,0.14565514028072357,0.19894583523273468,0.11802073568105698,0.13102783262729645,0.14965340495109558,0.09326598048210144,0.07379024475812912,0.0730525553226471,0.15182261168956757,0.10109184682369232,0.09263275563716888,0.08645804226398468,0.0992705374956131,0.09103766828775406,0.24319639801979065,0.28524327278137207,0.07951118052005768,0.16406655311584473,0.24029001593589783,0.16656416654586792,0.12890450656414032,0.13305526971817017,0.22779549658298492,0.08521319180727005,0.1454734057188034,0.15776318311691284,0.17881177365779877,0.1450069546699524,0.09103894233703613,0.17097221314907074,0.10059905797243118,0.3937903940677643,0.1328704059123993,0.11120079457759857,0.0824182853102684,0.0991259515285492,0.27244794368743896,0.28810766339302063,0.12060429155826569,0.07791892439126968,0.07819854468107224,0.12391521781682968,0.045149583369493484,0.18424807488918304,0.1029326394200325,0.24788959324359894,0.23500372469425201,0.14509576559066772,0.2455236315727234,0.2112278938293457,0.06787870824337006,0.06865660101175308,0.10340040922164917,0.20351941883563995,0.28408437967300415,0.11862754821777344,0.28806573152542114,0.11610560864210129,0.05252886191010475,0.18767669796943665,0.15799188613891602,0.07353325188159943,0.047049518674612045,0.18888770043849945,0.16292276978492737,0.04840455204248428,0.2669745981693268,0.06996789574623108,0.09207582473754883,0.175800159573555,0.1625623106956482,0.010678534395992756],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Test Accuracy\",\"x\":[0.0,10000.0,20000.0,30000.0],\"y\":[0.1,57.1875,57.125,58.0],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Num examples seen\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Cross entropy loss\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Test Accuracy\"}},\"hovermode\":\"x unified\",\"title\":{\"text\":\"SimpleMLP training on MNIST\"},\"width\":800},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('723ed606-c83d-4f3e-84bb-fb37382ad0d8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "line(\n",
        "    y=[loss_list, [0.1] + accuracy_list],  # we start by assuming a uniform accuracy of 10%\n",
        "    use_secondary_yaxis=True,\n",
        "    x_max=args.epochs * len(mnist_trainset),\n",
        "    labels={\"x\": \"Num examples seen\", \"y1\": \"Cross entropy loss\", \"y2\": \"Test Accuracy\"},\n",
        "    title=\"SimpleMLP training on MNIST\",\n",
        "    width=800,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.signal import convolve2d\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Create a larger image (40x40) with structure (hollow rectangle)\n",
        "image_size = 40\n",
        "original_image = np.zeros((image_size, image_size), dtype=np.float32) # Black background\n",
        "\n",
        "# Define rectangle boundaries (adjust thickness by changing the range)\n",
        "top_row, bottom_row = 5, image_size - 6\n",
        "left_col, right_col = 5, image_size - 6\n",
        "thickness = 2 # Make lines thicker\n",
        "\n",
        "# Draw rectangle (set pixels to 1.0 for white)\n",
        "original_image[top_row:bottom_row+thickness, left_col:left_col+thickness] = 1.0 # Top-left corner area\n",
        "original_image[top_row:bottom_row+thickness, right_col:right_col+thickness] = 1.0 # Top-right corner area\n",
        "original_image[top_row:top_row+thickness, left_col:right_col+thickness] = 1.0 # Top edge area\n",
        "original_image[bottom_row:bottom_row+thickness, left_col:right_col+thickness] = 1.0 # Bottom edge area\n",
        "\n",
        "\n",
        "# 2. Define the 3x3 average pooling kernel (remains the same)\n",
        "kernel = np.ones((2, 2), dtype=np.float32) / 1.0\n",
        "\n",
        "kernel = t.tensor([0.5, 0.0, -0.5]).repeat((3, 1))\n",
        "\n",
        "print(kernel)\n",
        "\n",
        "# 3. Convolve the image with the kernel\n",
        "# 'valid' mode: output size will be (image_size - kernel_size + 1)\n",
        "convolved_image = convolve2d(original_image, kernel, mode='valid')\n",
        "\n",
        "# 4. Plot the original and convolved images\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5)) # Adjusted figure size\n",
        "\n",
        "# Plot Original Image\n",
        "axes[0].imshow(original_image, cmap='gray', vmin=0, vmax=1)\n",
        "axes[0].set_title(f'Original Image ({original_image.shape[0]}x{original_image.shape[1]})')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Plot Convolved Image\n",
        "axes[1].imshow(convolved_image, cmap='gray', vmin=0, vmax=1)\n",
        "axes[1].set_title(f'Convolved (Avg. Pooled) ({convolved_image.shape[0]}x{convolved_image.shape[1]})')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Original Image Shape:\", original_image.shape)\n",
        "print(\"Kernel Shape:\", kernel.shape)\n",
        "print(\"Convolved Image Shape:\", convolved_image.shape)\n",
        "# Optional: Print a small section if needed, full arrays are large\n",
        "# print(\"\\nOriginal Image Tensor (Top-Left Corner):\\n\", original_image[0:8, 0:8])\n",
        "# print(\"\\nConvolved Image Tensor (Top-Left Corner):\\n\", convolved_image[0:6, 0:6])"
      ],
      "metadata": {
        "id": "Y8jMffwWC9K7",
        "outputId": "e53c040a-65df-480b-ee13-dc5f36955d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5000,  0.0000, -0.5000],\n",
            "        [ 0.5000,  0.0000, -0.5000],\n",
            "        [ 0.5000,  0.0000, -0.5000]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Image Shape: (40, 40)\n",
            "Kernel Shape: torch.Size([3, 3])\n",
            "Convolved Image Shape: (38, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6xo0Kn9jBUO"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to measure correct classifications.</summary>\n",
        "\n",
        "You can take argmax of the output of your model, using `torch.argmax` (with the keyword argument `dim` to specify the dimension you want to take max over).\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I get <code>RuntimeError: expected scalar type Float but found Byte</code>.</summary>\n",
        "\n",
        "This is commonly because one of your operations is between tensors with the wrong datatypes (e.g. `int` and `float`). You can try adding assert or logging statements in your code, or alternatively if you're in VSCode then you can try navigating to the error line and checking your dtypes using VSCode's built-in debugger.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def train(args: SimpleMLPTrainingArgs) -> tuple[list[float], list[float], SimpleMLP]:\n",
        "    \"\"\"\n",
        "    Trains the model, using training parameters from the `args` object. Returns the model, and lists of loss & accuracy.\n",
        "    \"\"\"\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    mnist_trainset, mnist_testset = get_mnist()\n",
        "    mnist_trainloader = DataLoader(mnist_trainset, batch_size=args.batch_size, shuffle=True)\n",
        "    mnist_testloader = DataLoader(mnist_testset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "    accuracy = 0.0\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # Training loop\n",
        "        pbar = tqdm(mnist_trainloader)\n",
        "        for imgs, labels in pbar:\n",
        "            # Move data to device, perform forward pass\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            # Calculate loss, perform backward pass\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update logs & progress bar\n",
        "            loss_list.append(loss.item())\n",
        "            pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        num_correct_classifications = 0\n",
        "        for imgs, labels in mnist_testloader:\n",
        "            # Move data to device, perform forward pass in inference mode\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with t.inference_mode():\n",
        "                logits = model(imgs)\n",
        "\n",
        "            # Compute num correct by comparing argmaxed logits to true labels\n",
        "            predictions = t.argmax(logits, dim=1)\n",
        "            num_correct_classifications += (predictions == labels).sum().item()\n",
        "\n",
        "        # Compute & log total accuracy\n",
        "        accuracy = num_correct_classifications / len(mnist_testset)\n",
        "        accuracy_list.append(accuracy)\n",
        "\n",
        "    return loss_list, accuracy_list, model\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fefPyRdrjBUO"
      },
      "source": [
        "You should find that after the first epoch, the model is already doing much better than random chance (i.e. >80%), and it improves slightly in subsequent epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfzzybg8jBUO"
      },
      "source": [
        "# 3️⃣ Convolutions\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn how convolutions work, and why they are useful for vision models\n",
        "> * Implement your own convolutions, and maxpooling layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcNZO8ZjjBUO"
      },
      "source": [
        "_Note, this section is light on exercises, because it actually ends up being surprisingly hard to implement convolutional and linear operations from scratch (unlike the case for linear layers). It requires engaging with **strides**, an under-the-hood attribute of PyTorch tensors which we usually don't think about in regular work. For this reason, this section focuses more on understanding how convolutions work & giving you implementations of it, rather than asking you to implement it from scratch. There are implementation from scratch exercises in the bonus section at the end of today's material, if you get that far!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEE91TP1jBUO"
      },
      "source": [
        "## Reading\n",
        "\n",
        "We strongly recommend you at least watch the video in the first bullet point. The second article is recommended, but not essential. The third is more for interest (and will be more relevant next week, when we study interpretability).\n",
        "\n",
        "* [But what is a convolution?](https://www.youtube.com/watch?v=KuXjwB4LzSA) by 3Blue1Brown\n",
        "* [A Comprehensive Guide to Convolutional Neural Networks (Medium)](https://medium.com/towards-data-science/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)\n",
        "* [Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-MleGB0jBUO"
      },
      "source": [
        "## What are convolutions?\n",
        "\n",
        "A convolution is an operation which takes a kernel and slides it across the input, applying the kernel to each patch of the input. We can view it as a logical extension of the linear layer, except rather than having every output value being determined as a linear combination of every input value, we have a **prior of locality** - assuming that the input has some spatial structure, and each output value should only be determined by a small patch of the input. The kernel contains our learned weights, and we slide that kernel across our input, with each output value being computed by a sumproduct of the kernel values and the corresponding patch in the input. Note that we use all input channels when computing each output value, which means the sumproduct is over `kernel_length * in_channels` elements (or `kernel_width * kernel_height * in_channels` when, as is most often the case, we're using 2D kernels)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5dLKPJujBUO"
      },
      "source": [
        "### Mathematical definition\n",
        "\n",
        "Convolutions have 4 important parameters:\n",
        "\n",
        "- **Size** - the size of the kernel, i.e. the size of each patch of the input that the kernel is applied to when computing each output value.\n",
        "- **Stride** - the distance the kernel moves each time it is applied.\n",
        "- **Padding** - the number of pixels we pad around the input on each side.\n",
        "- **Output channels** - the number of separate kernels of shape `(in_channels, kernel_width, kernel_height)` we apply to the input. Each separate kernel has different learned weights, and will produce a separate output channel.\n",
        "\n",
        "Below is an illustration with `size=(3,3), stride=1, padding=1`, three input channels and a single output channel.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*ciDgQEjViWLnCbmX-EeSrA.gif\" width=\"800\">\n",
        "\n",
        "For width or height, we can compute the output dim size as a function of the input dim and convolution parameters:\n",
        "\n",
        "$$\n",
        "L_{\\text {out }}=\\left\\lfloor\\dfrac{L_{\\text {in }}+2 \\times \\text { padding }- \\text { kernel\\_size }}{\\text { stride }}+1\\right\\rfloor\n",
        "$$\n",
        "\n",
        "Notably, with our parameters `size=(3,3), stride=1, padding=1` this simplifies to $L_{\\text{out}} = \\left\\lfloor\\frac{L_{\\text{in}} + 2 - 3}{1} + 1\\right\\rfloor = L_{\\text{in}}$. We refer to this as a **shape-preserving convolution**, because the input & output dimensions for width/height are the same. This is quite useful because often when building neural networks we have to be careful to match the shapes of different tensors (otherwise skip connections will fail - we can't add together `x + conv(x)` if they're different shapes!).\n",
        "\n",
        "> A quick note on terminology - you might see docs and docstrings use `num_features`, sometimes use `channels` (sometimes abbreviated as $N_{in}$ or $C$ in PyTorch docs). When we're talking about convolutions specifically, these usually mean the same thing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJMslSkVjBUP"
      },
      "source": [
        "### What do convolutions learn?\n",
        "\n",
        "The terminology `num_features` hints at this, but often convolutions can be thought of as learning certain features from our data. For instance, there's evidence to suggest that early convolutional layers pick up on very simple low-level features such as edges, corners and curves, whereas later convolutional layers are able to combine these lower-level features hierarchically to form more complex representations.\n",
        "\n",
        "For more on this, we recommend the Distill post [Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/), which discusses various lines of evidence for interpreting the features learned by convolutional layers (and how they connect up to form circuits). Interestingly, this post philosophically underpins quite a lot of the current interpretability field - even though the focus has primarily shifted from vision models to language models, many of the underlying ideas remain the same.\n",
        "\n",
        "<img src=\"https://distill.pub/2020/circuits/zoom-in/images/curves.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPT61hsvjBUP"
      },
      "source": [
        "### Some questions about convolutions\n",
        "\n",
        "Here are some questions about convolutions to make sure you've understood the material. You should try and answer these questions without referring back to the article or video above.\n",
        "\n",
        "<details>\n",
        "<summary>Why would convolutional layers be less likely to overfit data than standard linear (fully connected) layers?</summary>\n",
        "\n",
        "Convolutional layers require significantly fewer weights to be learned. This is because the same kernel is applied all across the image, rather than every pair of `(input, output)` nodes requiring a different weight to be learned.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Suppose you fixed some random permutation of the pixels in an image, and applied this to all images in your dataset, before training a convolutional neural network for classifying images. Do you expect this to be less effective, or equally effective?</summary>\n",
        "\n",
        "It will be less effective, because CNNs work thanks to **spatial locality** - groups of pixels close together are more meaningful. For instance, CNNs will often learn convolutions at an early layer which recognise gradients or simple shapes. If you permute the pixels (even if you permute in the same way for every image), you destroy locality.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>If you have a 28x28 image, and you apply a 3x3 convolution with stride 2, padding 1, and 5 output channels, what shape will the output be?</summary>\n",
        "\n",
        "Applying the formula above, we get:\n",
        "\n",
        "$\n",
        "L_{\\text {out }}=\\left\\lfloor\\frac{L_{\\text {in }}+2 \\times \\text { padding }- \\text { kernel\\_size }}{\\text { stride }}+1\\right\\rfloor = \\left\\lfloor\\frac{28 + 2 \\times 1 - 3}{2} + 1\\right\\rfloor = 14\n",
        "$\n",
        "\n",
        "So our image has width & height 14. The shape will go from `(3, 28, 28)` to `(5, 14, 14)` (since the output dimensions are `out_channels, width, height`).\n",
        "\n",
        "As a general rule, a 3x3 convolution with padding 1, stride `stride` and input images with shape `(width, height)` will map to an output shape of `(width // stride, height // stride)`. This will be useful when we study GANs tomorrow, and we'll assemble a series of 3x3 convolutions with padding 1 and stride 2, which should each halve our input image size.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r5QjYtjjBUP"
      },
      "source": [
        "### Exercise - implement `Conv2d`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-20 minutes on this exercise.\n",
        "> This only requires you to create the conv weights - making your own fwd pass method is a bonus exercise later.\n",
        "> ```\n",
        "\n",
        "Rather than implementing the `conv2d` function from scratch, we'll allow you to use `t.nn.functional.conv2d`. In the exercise below, you should use this function to implement the `nn.Conv2d` layer. All you need to do is fill in the `__init__` method. Some guidance:\n",
        "\n",
        "- You should look at the PyTorch page for `nn.Conv2d` [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) (and review the discussion above) to understand what the shape of the weights should be.\n",
        "- We assume `bias=False`, so the only `nn.Parameter` object we need to define is `weight`.\n",
        "- You should use **uniform Kaiming initialization** like you have before, i.e. the bounds of the uniform distribution should be $\\pm 1/\\sqrt{N_{in}}$ where $N_{in}$ is the product of input channels and kernel height & width, as described at the bottom of the `nn.Conv2d` docs (the bullet points under the **Variables** header).\n",
        "\n",
        "<details>\n",
        "<summary>Question - why do you think we use the product of input channels and kernel height & width for our Kaiming initialization bounds?</summary>\n",
        "\n",
        "This is because each value in the output is computed by taking the product over `in_channels * kernel_height * kernel_width` elements, analogously to how each value in the linear layer is computed by taking the product over just `in_features` elements.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "gNDFqBv6jBUP",
        "outputId": "ca8155be-e9c2-4cf4-98f0-df06e7cf414d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_conv2d_module` passed!\n",
            "Manually verify that this is an informative repr: Conv2d(in_channels=24, out_channels=12, kernel_size=3, stride=2, padding=1)\n"
          ]
        }
      ],
      "source": [
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0):\n",
        "        \"\"\"\n",
        "        Same as torch.nn.Conv2d with bias=False.\n",
        "\n",
        "        Name your weight field `self.weight` for compatibility with the PyTorch version.\n",
        "\n",
        "        We assume kernel is square, with height = width = `kernel_size`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        # YOUR CODE HERE - define & initialize `self.weight`\n",
        "        kernel_height = kernel_width = kernel_size\n",
        "        sf = 1 / np.sqrt(in_channels * kernel_width * kernel_height)\n",
        "        self.weight = nn.Parameter(sf * (2 * t.rand(out_channels, in_channels, kernel_height, kernel_width) - 1))\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Apply the functional conv2d, which you can import.\"\"\"\n",
        "        return t.nn.functional.conv2d(x, self.weight, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "\n",
        "\n",
        "tests.test_conv2d_module(Conv2d)\n",
        "m = Conv2d(in_channels=24, out_channels=12, kernel_size=3, stride=2, padding=1)\n",
        "print(f\"Manually verify that this is an informative repr: {m}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtXz-fmKjBUP"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0):\n",
        "        \"\"\"\n",
        "        Same as torch.nn.Conv2d with bias=False.\n",
        "\n",
        "        Name your weight field `self.weight` for compatibility with the PyTorch version.\n",
        "\n",
        "        We assume kernel is square, with height = width = `kernel_size`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        kernel_height = kernel_width = kernel_size\n",
        "        sf = 1 / np.sqrt(in_channels * kernel_width * kernel_height)\n",
        "        self.weight = nn.Parameter(sf * (2 * t.rand(out_channels, in_channels, kernel_height, kernel_width) - 1))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Apply the functional conv2d, which you can import.\"\"\"\n",
        "        return t.nn.functional.conv2d(x, self.weight, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pL7QknMjBUP"
      },
      "source": [
        "### `MaxPool2d`\n",
        "\n",
        "We often add a maxpool layer after a convolutional layer. This layer is responsible for reducing the spatial size of the convolved feature. It works by taking the maximum value in each kernel-sized window, and outputting that value. For instance, if we have a 2x2 kernel, then we take the maximum of each 2x2 window in the input.\n",
        "\n",
        "Maxpool is useful for downsampling the image (reducing the total amount of data we're having to work with), as well as extracting dominant features in the image. For example, if we're training a model for classification, the model might find it useful to create a \"wheel detector\" to identify whether a wheel is present in the image - even if most chunks of the image don't contain a wheel, we care more about whether a wheel exists _somewhere_ in the image, and so we might only be interested in the largest values.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*uoWYsCV5vBU8SHFPAPao-w.gif\" width=\"360\">\n",
        "\n",
        "We've given you `MaxPool2d` below. This is a wrapper for the `max_pool2d` function (although in the bonus exercises later you can implement your own version of this)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5FDU_AqxjBUP"
      },
      "outputs": [],
      "source": [
        "class MaxPool2d(nn.Module):\n",
        "    def __init__(self, kernel_size: int, stride: int | None = None, padding: int = 1):\n",
        "        super().__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Call the functional version of maxpool2d.\"\"\"\n",
        "        return F.max_pool2d(x, kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        \"\"\"Add additional information to the string representation of this class.\"\"\"\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in [\"kernel_size\", \"stride\", \"padding\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfKdK3CsjBUP"
      },
      "source": [
        "# 4️⃣ ResNets\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn about skip connections, and how they help overcome the degradation problem\n",
        "> * Learn about batch normalization, and why it is used in training\n",
        "> * Assemble your own ResNet, and load in weights from PyTorch's ResNet implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTNY36KhjBUP"
      },
      "source": [
        "## Reading\n",
        "\n",
        "* [Batch Normalization in Convolutional Neural Networks](https://www.baeldung.com/cs/batch-normalization-cnn)\n",
        "* [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n",
        "\n",
        "You should move on once you can answer the following questions:\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\"Batch Normalization allows us to be less careful about initialization.\" Explain this statement.</summary>\n",
        "\n",
        "Weight initialisation methods like Xavier (which we encountered yesterday) are based on the idea of making sure the activations have approximately the same distribution across layers at initialisation. But batch normalisation ensures that this is the case as signals pass through the network.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Give three reasons why batch norm improves the performance of neural networks.</summary>\n",
        "\n",
        "The reasons given in the first linked document above are:\n",
        "\n",
        "* Normalising inputs speeds up computation\n",
        "* Internal covariate shift is reduced, i.e. the mean and standard deviation is kept constant across the layers.\n",
        "* Regularisation effect: noise internal to each minibatch is reduced\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>If you have an input tensor of size (batch, channels, width, height), and you apply a batchnorm layer, how many learned parameters will there be?</summary>\n",
        "\n",
        "A mean and standard deviation is calculated for each channel (i.e. each calculation is done across the batch, width, and height dimensions). So the number of learned params will be `2 * channels`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>In the paper, the diagram shows additive skip connections (i.e. F(x) + x). One can also form concatenated skip connections, by \"gluing together\" F(x) and x into a single tensor. Give one advantage and one disadvantage of these, relative to additive connections.</summary>\n",
        "\n",
        "One advantage of concatenation: the subsequent layers can re-use middle representations; maintaining more information which can lead to better performance. Also, this still works if the tensors aren't exactly the same shape. One disadvantage: less compact, so there may be more weights to learn in subsequent layers.\n",
        "\n",
        "Crucially, both the addition and concatenation methods have the property of preserving information, to at least some degree of fidelity. For instance, you can [use calculus to show](https://theaisummer.com/skip-connections/#:~:text=residual%20skip%20connections.-,ResNet%3A%20skip%20connections%C2%A0via%C2%A0addition,-The%20core%20idea) that both methods will fix the vanishing gradients problem.\n",
        "</details>\n",
        "\n",
        "\n",
        "In this section, we'll do a more advanced version of the exercise in part 1. Rather than building a relatively simple network in which computation can be easily represented by a sequence of simple layers, we're going to build a more complex architecture which requires us to define nested blocks.\n",
        "\n",
        "We'll start by defining a few more `nn.Module` objects, which we hadn't needed before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3UQwSkXjBUP"
      },
      "source": [
        "## Sequential\n",
        "\n",
        "Firstly, now that we're working with large and complex architectures, we should create a version of `nn.Sequential`. As the name suggests, when an `nn.Sequential` is fed an input, it sequentially applies each of its submodules to the input, with the output from one module feeding into the next one.\n",
        "\n",
        "The implementation is given to you below. A few notes:\n",
        "\n",
        "* In initalization, we add to the `_modules` dictionary.\n",
        "    * This is a special type of dict called an **ordered dictionary**, which preserves the order of elements that get added (although Python sort-of does this now by default).\n",
        "    * When we call `self.parameters()`, this recursively goes through all modules in `self._modules`, and returns the params in those modules. This means we can nest sequentials within sequentials!\n",
        "* The special `__getitem__` and `__setitem__` methods determine behaviour when we get and set modules within the sequential.\n",
        "* The `repr` of the base class `nn.Module` already recursively prints out the submodules, so we don't need to write anything in `extra_repr`.\n",
        "    * To see how this works in practice, try defining a `Sequential` which takes a sequence of modules that you've defined above, and see what it looks like when you print it.\n",
        "\n",
        "Don't worry about deeply understanding this code. The main takeaway is that `nn.Sequential` is a useful list-like object to store modules, and apply them all sequentially.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - initializing Sequential with an OrderedDict</summary>\n",
        "\n",
        "The actual `nn.Sequential` module can be initialized with an ordered dictionary, rather than a list of modules. For instance, rather than doing this:\n",
        "\n",
        "```python\n",
        "seq = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 30)\n",
        ")\n",
        "```\n",
        "\n",
        "we can do this:\n",
        "\n",
        "```python\n",
        "from collections import OrderedDict\n",
        "\n",
        "seq = nn.Sequential(OrderedDict([\n",
        "    (\"linear1\", nn.Linear(10, 20)),\n",
        "    (\"relu\", nn.ReLU()),\n",
        "    (\"linear2\", nn.Linear(20, 30))\n",
        "]))\n",
        "```\n",
        "\n",
        "This is handy if we want to give each module an descriptive name.\n",
        "\n",
        "The `Sequential` implementation below doesn't allow the input to be an OrderedDict. As a bonus exercise, can you rewrite the `__init__`, `__getitem__` and `__setitem__` methods to allow the input to be an OrderedDict? If you do this, you'll actually be able to match your eventual `ResNet` model names exactly to the PyTorch implementation.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "IMeB1It7jBUP"
      },
      "outputs": [],
      "source": [
        "class Sequential(nn.Module):\n",
        "    _modules: dict[str, nn.Module]\n",
        "\n",
        "    def __init__(self, *modules: nn.Module):\n",
        "        super().__init__()\n",
        "        for index, mod in enumerate(modules):\n",
        "            self._modules[str(index)] = mod\n",
        "\n",
        "    def __getitem__(self, index: int) -> nn.Module:\n",
        "        index %= len(self._modules)  # deal with negative indices\n",
        "        return self._modules[str(index)]\n",
        "\n",
        "    def __setitem__(self, index: int, module: nn.Module) -> None:\n",
        "        index %= len(self._modules)  # deal with negative indices\n",
        "        self._modules[str(index)] = module\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Chain each module together, with the output from one feeding into the next one.\"\"\"\n",
        "        for mod in self._modules.values():\n",
        "            x = mod(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiJjl23vjBUP"
      },
      "source": [
        "## BatchNorm2d\n",
        "\n",
        "Now, we'll implement our `BatchNorm2d`, the layer described in the reading material you hopefully read above. You'll be implementing it according to the [PyTorch docs](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) (with `affine=True` and `track_running_stats=True`).\n",
        "\n",
        "The primary function of batchnorm is to normalize the activations of each layer within the neural network during training. It normalizes each batch of input data to have a mean of 0 and std dev of 1. This normalization helps mitigate the **internal covariate shift** problem, which refers to the change in the distribution of layer inputs as the network trains. This becomes a particularly big problem as we build deeper networks, because there's more opportunity for the activation distribution to change over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1S4yU34jBUP"
      },
      "source": [
        "### Buffers\n",
        "\n",
        "A question that might have occurred to you as you read about batchnorm - how does averaging over input data work in inference mode, if you only have a single input rather than a batch? The answer is that during training mode we compute a running average of our data's mean and variance, and we use this running average in inference mode.\n",
        "\n",
        "How do we store these moving averages? We want them to be saved and loaded with the model (because we need these values in order to run our model), but we don't want to update them using gradient descent (so we don't want to use `nn.Parameter`). So instead, we use the Pytorch **buffers** feature. These are essentially tensors which are included in `model.state_dict()` (and so they're saved & loaded with the rest of the model) but not included in `model.parameters()`.\n",
        "\n",
        "You can create a buffer by calling [`self.register_buffer`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer) from inside a `nn.Module`. We've initialized the necessary buffers for you in the `__init__` method below - you'll need a running mean and variance, as well as a counter for the number of batches seen (technically this isn't strictly necessary because the running mean & variance are updated using an exponential moving average so the update rule is independent of the number of previous updates, but we're doing this so our state dict matches the PyTorch implementation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU_LYqcJjBUP"
      },
      "source": [
        "### Train and Eval Modes\n",
        "\n",
        "Okay so we have buffers, but how can we make them behave differently in different modes - i.e. updating the running mean & variance in training mode, and using the stored values in eval mode? The answer is that we use the `training` method of the `nn.Module` class, which is a boolean attribute that gets flipped when we call `self.eval()` or `self.train()`. In the case of batch norm, your code should look like this:\n",
        "\n",
        "```python\n",
        "if self.training:\n",
        "    # Use this data's mean & variance to normalize, then use it to update the buffers\n",
        "else:\n",
        "    # Use the buffer mean & variance to normalize\n",
        "```\n",
        "\n",
        "The other commonly used module which has different behaviour in training and eval modes is `Dropout` - in eval mode this module uses all its inputs, but in training it randomly selects some fraction `1 - p` of the input values to zero out and scales the remaining values by `1 / (1 - p)`.\n",
        "\n",
        "Note that other normalization modules we'll address later in this course like `LayerNorm` don't have different behaviour in training and eval modes, because these don't normalize over the batch dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHXorQkCjBUP"
      },
      "source": [
        "### Exercise - implement `BatchNorm2d`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-30 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `BatchNorm2d` according to the [PyTorch docs](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html). We're implementing it with `affine=True` and `track_running_stats=True`. All the parameters are defined for you in the `__init__` method, your job will be to fill in the `forward` and `extra_repr` methods.\n",
        "\n",
        "A few final tips:\n",
        "\n",
        "- Remember to use `weight` and `bias` in the fwd pass, after normalizing. You should multiply by `weight` and add `bias`.\n",
        "- All your tensors (`weight`, `bias`, `running_mean` and `running_var`) are vectors of length `num_features`, this should help you figure out what dimensions you're operating on.\n",
        "- Remember that the shape of `x` is `(batch, num_features, height, width)` which doesn't broadcast with `(num_features,)`. The easiest way to fix this is to reshape the latter to something like `(1, num_features, 1, 1)`, or optionally just `(num_features, 1, 1)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "N-PuyV34jBUP",
        "outputId": "3cfbcdf5-7d73-40a2-905c-347266f66b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_batchnorm2d_module` passed!\n",
            "All tests in `test_batchnorm2d_forward` passed!\n",
            "All tests in `test_batchnorm2d_running_mean` passed!\n"
          ]
        }
      ],
      "source": [
        "class BatchNorm2d(nn.Module):\n",
        "    # The type hints below aren't functional, they're just for documentation\n",
        "    running_mean: Float[Tensor, \"num_features\"]\n",
        "    running_var: Float[Tensor, \"num_features\"]\n",
        "    num_batches_tracked: Int[Tensor, \"\"]  # This is how we denote a scalar tensor\n",
        "\n",
        "    def __init__(self, num_features: int, eps=1e-05, momentum=0.1):\n",
        "        \"\"\"\n",
        "        Like nn.BatchNorm2d with track_running_stats=True and affine=True.\n",
        "\n",
        "        Name the learnable affine parameters `weight` and `bias` in that order.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.weight = nn.Parameter(t.ones(num_features))\n",
        "        self.bias = nn.Parameter(t.zeros(num_features))\n",
        "\n",
        "        self.register_buffer(\"running_mean\", t.zeros(num_features))\n",
        "        self.register_buffer(\"running_var\", t.ones(num_features))\n",
        "        self.register_buffer(\"num_batches_tracked\", t.tensor(0))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Normalize each channel.\n",
        "\n",
        "        Compute the variance using `torch.var(x, unbiased=False)`\n",
        "        Hint: you may also find it helpful to use the argument `keepdim`.\n",
        "\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels, height, width)\n",
        "        \"\"\"\n",
        "        if self.training:\n",
        "            mean = t.mean(x, dim=(0, 2, 3))\n",
        "            var = t.var(x, unbiased=False, dim=(0, 2, 3))\n",
        "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
        "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
        "            self.num_batches_tracked += 1\n",
        "        else:\n",
        "            mean = self.running_mean\n",
        "            var = self.running_var\n",
        "\n",
        "        mean_reshaped = einops.rearrange(mean, 'c -> 1 c 1 1')\n",
        "        var_reshaped = einops.rearrange(var, 'c -> 1 c 1 1')\n",
        "\n",
        "        rehape = lambda x: einops.rearrange(x, 'c -> 1 c 1 1')\n",
        "\n",
        "        x_normed = (x - rehape(mean)) / (t.sqrt(var_reshaped) + self.eps)\n",
        "\n",
        "        x_affine = x_normed * einops.rearrange(self.weight, 'c -> 1 c 1 1') + einops.rearrange(self.bias, 'c -> 1 c 1 1')\n",
        "        return x_affine\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_batchnorm2d_module(BatchNorm2d)\n",
        "tests.test_batchnorm2d_forward(BatchNorm2d)\n",
        "tests.test_batchnorm2d_running_mean(BatchNorm2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDElfgGRjBUP"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm stuck on this implementation, and need a template.</summary>\n",
        "\n",
        "The easiest way is to structure it like this (we've omitted the reshaping to make sure the mean & variance broadcasts correctly):\n",
        "\n",
        "```python\n",
        "if self.training:\n",
        "    mean = ... # mean of new data\n",
        "    var = ... # variance of new data\n",
        "    self.running_mean = ... # update running mean using exponential moving average\n",
        "    self.running_var = ... # update running variance using exponential moving average\n",
        "    self.num_batches_tracked += 1\n",
        "else:\n",
        "    mean = self.running_mean\n",
        "    var = self.running_var\n",
        "\n",
        "x_normed = ... # normalize x using `mean` and `var` (make sure `mean` and `var` are broadcastable with `x`)\n",
        "x_affine = ... # apply affine transformation from `self.weight` and `self.bias` (again, be careful of broadcasting)\n",
        "return x_affine\n",
        "```\n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def forward(self, x: Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Normalize each channel.\n",
        "\n",
        "    Compute the variance using `torch.var(x, unbiased=False)`\n",
        "    Hint: you may also find it helpful to use the argument `keepdim`.\n",
        "\n",
        "    x: shape (batch, channels, height, width)\n",
        "    Return: shape (batch, channels, height, width)\n",
        "    \"\"\"\n",
        "    # Calculating mean and var over all dims except for the channel dim\n",
        "    if self.training:\n",
        "        # Take mean over all dimensions except the feature dimension\n",
        "        mean = x.mean(dim=(0, 2, 3))\n",
        "        var = x.var(dim=(0, 2, 3), unbiased=False)\n",
        "        # Updating running mean and variance, in line with PyTorch documentation\n",
        "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
        "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
        "        self.num_batches_tracked += 1\n",
        "    else:\n",
        "        mean = self.running_mean\n",
        "        var = self.running_var\n",
        "\n",
        "    # Rearranging these so they can be broadcasted\n",
        "    reshape = lambda x: einops.rearrange(x, \"channels -> 1 channels 1 1\")\n",
        "\n",
        "    # Normalize, then apply affine transformation from self.weight & self.bias\n",
        "    x_normed = (x - reshape(mean)) / (reshape(var) + self.eps).sqrt()\n",
        "    x_affine = x_normed * reshape(self.weight) + reshape(self.bias)\n",
        "    return x_affine\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-zIkZUEjBUP"
      },
      "source": [
        "## AveragePool\n",
        "\n",
        "Let's end our collection of `nn.Module`s with an easy one 🙂\n",
        "\n",
        "The ResNet has a Linear layer with 1000 outputs at the end in order to produce classification logits for each of the 1000 classes. Any Linear needs to have a constant number of input features, but the ResNet is supposed to be compatible with arbitrary height and width, so we can't just do a pooling operation with a fixed kernel size and stride.\n",
        "\n",
        "Luckily, the simplest possible solution works decently: take the mean over the spatial dimensions. Intuitively, each position has an equal \"vote\" for what objects it can \"see\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYnKXRrfjBUP"
      },
      "source": [
        "### Exercise - implement `AveragePool`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴⚪⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 5-10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "This should be a pretty straightforward implementation; it doesn't have any weights or parameters of any kind, so you only need to implement the `forward` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPy0xaU9jBUP"
      },
      "outputs": [],
      "source": [
        "class AveragePool(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_averagepool(AveragePool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrMm9Hm8jBUP"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class AveragePool(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels)\n",
        "        \"\"\"\n",
        "        return t.mean(x, dim=(2, 3))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCgqtLlOjBUQ"
      },
      "source": [
        "## Building ResNet\n",
        "\n",
        "Now we have all the building blocks we need to start assembling your own ResNet! The following diagram describes the architecture of ResNet34 - the other versions are broadly similar.\n",
        "\n",
        "Note - unless otherwise noted, you should assume convolutions have `kernel_size=3, stride=1, padding=1` (this is a **shape preserving convolution** i.e. the width & height of the input and output will be the same). None of the convolutions have biases.\n",
        "\n",
        "You don't have to understand every detail in this diagram before proceeding; specific points will be clarified as we go through each exercise.\n",
        "\n",
        "<details>\n",
        "<summary>Question: why do we not care about including biases in the convolutional layers?</summary>\n",
        "\n",
        "Every convolution layer in this network is followed by a batch normalization layer. The first operation in the batch normalization layer is to subtract the mean of each output channel. But a convolutional bias just adds some scalar `b` to each output channel, increasing the mean by `b`. This means that for any `b` added, the batch normalization will subtract `b` to exactly negate the bias term.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm confused about how the nested subgraphs work.</summary>\n",
        "\n",
        "The right-most block in the diagram, `ResidualBlock`, is nested inside `BlockGroup` multiple times. When you see `ResidualBlock` in `BlockGroup`, you should visualise a copy of `ResidualBlock` sitting in that position.\n",
        "    \n",
        "Similarly, `BlockGroup` is nested multiple times (four to be precise) in the full `ResNet34` architecture.\n",
        "</details>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/resnet-fixed.svg\" width=\"900\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KC7tTKPjBUQ"
      },
      "source": [
        "### Exercise - implement `ResidualBlock`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 20-30 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `ResidualBlock` by referring to the diagram (i.e. the right-most of the three hierarchical diagrams above).\n",
        "\n",
        "The **left branch** starts with a strided convolution which changes the number of features from `in_feats` to `out_feats`. It has all conv parameters default i.e. `kernel_size=3, stride=1, padding=1` except for the stride which is instead given by `first_stride`. The second convolution has all default parameters, and maps from `out_feats` to `out_feats` (meaning it's fully shape preserving).\n",
        "\n",
        "As for the **right branch** - this is meant to essentially be a skip connection, the problem is we can't just use a skip connection because the shapes might not match up (and so we couldn't add them together at the end). The left branch is fully shape preserving if and only if `first_stride == 1` and `in_feats == out_feats`. If this is true then we do set the right branch to be the identity (that's what the \"OPTIONAL\" annotation refers to), but if this isn't true then we set the right branch to be a 1x1 convolution with stride `first_stride`, zero padding, and mapping from `in_feats` to `out_feats`, followed by a batchnorm layer. This is in a sense the simplest operation we can get which matches the left branch shape, since the convolution is basically just a downsampling operation (keeping pixels based on a `::first_stride` slice across the height and width dimensions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7B3MPn5jBUQ"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"\n",
        "        A single residual block with optional downsampling.\n",
        "\n",
        "        For compatibility with the pretrained model, declare the left side branch first using a `Sequential`.\n",
        "\n",
        "        If first_stride is > 1, this means the optional (conv + bn) should be present on the right branch. Declare it second using another `Sequential`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        is_shape_preserving = (first_stride == 1) and (in_feats == out_feats)  # determines if right branch is identity\n",
        "\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / stride, width / stride)\n",
        "\n",
        "        If no downsampling block is present, the addition should just add the left branch's output to the input.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_residual_block(ResidualBlock)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY4GJqgYjBUQ"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"\n",
        "        A single residual block with optional downsampling.\n",
        "\n",
        "        For compatibility with the pretrained model, declare the left side branch first using a `Sequential`.\n",
        "\n",
        "        If first_stride is > 1, this means the optional (conv + bn) should be present on the right branch. Declare it second using another `Sequential`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        is_shape_preserving = (first_stride == 1) and (in_feats == out_feats)  # determines if right branch is identity\n",
        "\n",
        "        self.left = Sequential(\n",
        "            Conv2d(in_feats, out_feats, kernel_size=3, stride=first_stride, padding=1),\n",
        "            BatchNorm2d(out_feats),\n",
        "            ReLU(),\n",
        "            Conv2d(out_feats, out_feats, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(out_feats),\n",
        "        )\n",
        "        self.right = (\n",
        "            nn.Identity()\n",
        "            if is_shape_preserving\n",
        "            else Sequential(Conv2d(in_feats, out_feats, kernel_size=1, stride=first_stride), BatchNorm2d(out_feats))\n",
        "        )\n",
        "        self.relu = ReLU()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / stride, width / stride)\n",
        "\n",
        "        If no downsampling block is present, the addition should just add the left branch's output to the input.\n",
        "        \"\"\"\n",
        "        x_left = self.left(x)\n",
        "        x_right = self.right(x)\n",
        "        return self.relu(x_left + x_right)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53nkd-GDjBUQ"
      },
      "source": [
        "### Exercise - implement `BlockGroup`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `BlockGroup` according to the diagram. There should be `n_blocks` total blocks in the group. Only the first block has the possibility of having a right branch (because we might have either `first_stride > 1` or `in_feats != out_feats`), but every subsequent block will have the identity instead of a right branch.\n",
        "\n",
        "<details>\n",
        "<summary>Help - I don't understand why all blocks after the first one won't have a right branch.</summary>\n",
        "\n",
        "- The `first_stride` argument only gets applied to the first block, definitionally (i.e. the purpose of the `BlockGroup` is to downsample the input by `first_stride` just once, not on every single block).\n",
        "- After we pass through the first block we can guarantee that the number of channels will be `out_feats`, so every subsequent block will have `out_feats` input channels and `out_feats` output channels.\n",
        "\n",
        "Combining these two facts, we see that every subsequent block will have a shape-preserving left branch, so it can have the identity as its right branch.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vxTirPmjBUQ"
      },
      "outputs": [],
      "source": [
        "class BlockGroup(nn.Module):\n",
        "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"An n_blocks-long sequence of ResidualBlock where only the first block uses the provided stride.\"\"\"\n",
        "        super().__init__()\n",
        "        # YOUR CODE HERE - define all components of block group\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / first_stride, width / first_stride)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_block_group(BlockGroup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRtj-5ukjBUQ"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class BlockGroup(nn.Module):\n",
        "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"An n_blocks-long sequence of ResidualBlock where only the first block uses the provided stride.\"\"\"\n",
        "        super().__init__()\n",
        "        self.blocks = Sequential(\n",
        "            ResidualBlock(in_feats, out_feats, first_stride),\n",
        "            *[ResidualBlock(out_feats, out_feats) for _ in range(n_blocks - 1)],\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / first_stride, width / first_stride)\n",
        "        \"\"\"\n",
        "        return self.blocks(x)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoeKPAlpjBUQ"
      },
      "source": [
        "### Exercise - implement `ResNet34`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 30-45 minutes on this exercise. This can sometimes involve a lot of fiddly debugging.\n",
        "> ```\n",
        "\n",
        "Last step! Assemble `ResNet34` using the diagram.\n",
        "\n",
        "To test your implementation, you can use the helper function `print_param_count` which prints out a stylized dataframe comparing your model's parameter count to the PyTorch implementation. Alternatively, you can use the following code to import your own `resnet34`, and inspect its architecture:\n",
        "\n",
        "```python\n",
        "resnet = models.resnet34()\n",
        "print(torchinfo.summary(resnet, input_size=(1, 3, 64, 64)))\n",
        "print(torchinfo.summary(my_resnet, input_size=(1, 3, 64, 64)))\n",
        "```\n",
        "\n",
        "Both will give you the shape & size of each of your model's parameters & buffers, and code is provided for both of these methods below.\n",
        "\n",
        "Note - in order to copy weights from the reference model to your implementation (which we'll do after this exercise), you'll need to have all the parameters defined in the same order as they are in the reference model - in other words, the rows from the two halves of the dataframe created via `print_param_count` should perfectly match up with each other. This can be a bit fiddly to get right, especially if the names of your parameters are different to the names in the PyTorch implementation. We recommend you look at the `__init__` methods of the solution if you're stuck (since it's the order that things are defined in for the various ResNet modules which determines the order of the rows in the dataframe).\n",
        "\n",
        "This 1-to-1 weight comparison won't always be possible during model replications, for example when we replicate GPT2-Small next week we'll be defining the attention weight matrices differently (in a way that's more condusive to interpretability research). In these cases, you'll need to resort to different debugging methods, like running the models on the same input and checking they give the same output. You can also break this down into smaller steps by running individual models, and by checking the shape before checking values. However in this case we don't need to resort to that, because our implementation is equivalent to the reference model's implementation.\n",
        "\n",
        "As a more general point, tweaking your model until all the layers match up might be a difficult and frustrating exercise at times, however it's a pretty good example of the kind of low-level model implementation and debugging that is important for your growth as ML engineers! So don't be disheartened if you find it hard to get exactly right (although we certainly recommend looking at the solutions and moving on if you're stuck on this particular exercise for more than ~45 minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f7NyxrEjBUQ"
      },
      "outputs": [],
      "source": [
        "class ResNet34(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_blocks_per_group=[3, 4, 6, 3],\n",
        "        out_features_per_group=[64, 128, 256, 512],\n",
        "        first_strides_per_group=[1, 2, 2, 2],\n",
        "        n_classes=1000,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        in_feats0 = 64\n",
        "        self.n_blocks_per_group = n_blocks_per_group\n",
        "        self.out_features_per_group = out_features_per_group\n",
        "        self.first_strides_per_group = first_strides_per_group\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # YOUR CODE HERE - define all components of resnet34\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, n_classes)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "my_resnet = ResNet34()\n",
        "\n",
        "# (1) Test via helper function `print_param_count`\n",
        "target_resnet = models.resnet34()  # without supplying a `weights` argument, we just initialize with random weights\n",
        "utils.print_param_count(my_resnet, target_resnet)\n",
        "\n",
        "# (2) Test via `torchinfo.summary`\n",
        "print(\"My model:\", torchinfo.summary(my_resnet, input_size=(1, 3, 64, 64)), sep=\"\\n\")\n",
        "print(\"\\nReference model:\", torchinfo.summary(target_resnet, input_size=(1, 3, 64, 64), depth=2), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf_bXp6hjBUQ"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to construct each of the BlockGroups.</summary>\n",
        "\n",
        "Each BlockGroup takes arguments `n_blocks`, `in_feats`, `out_feats` and `first_stride`. In the initialisation of `ResNet34` below, we're given a list of `n_blocks`, `out_feats` and `first_stride` for each of the BlockGroups. To find `in_feats` for each block, it suffices to note two things:\n",
        "    \n",
        "1. The first `in_feats` should be 64, because the input is coming from the convolutional layer with 64 output channels.\n",
        "2. The `out_feats` of each layer should be equal to the `in_feats` of the subsequent layer (because the BlockGroups are stacked one after the other; with no operations in between to change the shape).\n",
        "\n",
        "You can use these two facts to construct a list `in_features_per_group`, and then create your BlockGroups by zipping through all four lists.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm not sure how to construct the 7x7 conv at the very start.</summary>\n",
        "\n",
        "The stride, padding & output channels are givin in the diagram; the only thing not provided is `in_channels`. Recall that the input to this layer is an RGB image - can you deduce from this how many input channels your layer should have?\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm getting the right total parameter count, but my rows don't match up, and I'm not sure how to debug this.</summary>\n",
        "\n",
        "We'll use an example case to illustrate how to debug this. In the following case, our rows match up until the 21st row where we have our first discrepancy:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/row-diff.png\" width=\"1000\">\n",
        "\n",
        "We can see that the first discrepancy occurs at the first parameter from `residual_layers.1`, meaning something in the second `BlockGroup` in our sequential of blockgroups. We can see that the first blockgroup only had left branches but no right branches (this is because for the very first blockgroup we had `in_feats == out_feats == 64` and also `first_strides_per_group[0] == 1`, meaning this first blockgroup was shape-preserving and it didn't need a right branch). So it's the presence of a right branch that's causing the mismatch.\n",
        "\n",
        "Looking closer at the dataframe, we see that the left-hand parameter (from our model) has shape `(128, 64, 1, 1)` and has `right` in its name, so we deduce it's the 1x1 convolutional weight from the right branch. But the parameter from the PyTorch model has shape `(128, 64, 3, 3)`, i.e. it's a convolutional weight with a 3x3 kernel, so must be from the left branch (it also matches the naming convention for the left-branch convolutional weight from the first blockgroup - row index 3 in the dataframe). So we've now figured out what the problem is: **your implementation defines the right branch before the left branch in the the `ResidualBlock.__init__` method, and to match param orders with the PyTorch model you should swap them around.**\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ResNet34(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_blocks_per_group=[3, 4, 6, 3],\n",
        "        out_features_per_group=[64, 128, 256, 512],\n",
        "        first_strides_per_group=[1, 2, 2, 2],\n",
        "        n_classes=1000,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        in_feats0 = 64\n",
        "        self.n_blocks_per_group = n_blocks_per_group\n",
        "        self.out_features_per_group = out_features_per_group\n",
        "        self.first_strides_per_group = first_strides_per_group\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.in_layers = Sequential(\n",
        "            Conv2d(3, in_feats0, kernel_size=7, stride=2, padding=3),\n",
        "            BatchNorm2d(in_feats0),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "        residual_layers = []\n",
        "        for i in range(len(n_blocks_per_group)):\n",
        "            residual_layers.append(\n",
        "                BlockGroup(\n",
        "                    n_blocks=n_blocks_per_group[i],\n",
        "                    in_feats=[64, *self.out_features_per_group][i],\n",
        "                    out_feats=self.out_features_per_group[i],\n",
        "                    first_stride=self.first_strides_per_group[i],\n",
        "                )\n",
        "            )\n",
        "        self.residual_layers = Sequential(*residual_layers)\n",
        "\n",
        "        self.out_layers = Sequential(\n",
        "            AveragePool(),\n",
        "            Linear(out_features_per_group[-1], n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, n_classes)\n",
        "        \"\"\"\n",
        "        post_first_conv_block = self.in_layers(x)\n",
        "        post_block_groups = self.residual_layers(post_first_conv_block)\n",
        "        logits = self.out_layers(post_block_groups)\n",
        "        return logits\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGvDIe3UjBUQ"
      },
      "source": [
        "### Copying over weights\n",
        "\n",
        "Now that you've built your `ResNet34`, we'll copy weights over from PyTorch's pretrained resnet to yours. This is another good way to verify that you've designed the architecture correctly (although if you've passed all tests above and your parameter count order matches up, it's very likely that this code will also work)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoL_Jg8jjBUQ"
      },
      "outputs": [],
      "source": [
        "def copy_weights(my_resnet: ResNet34, pretrained_resnet: models.resnet.ResNet) -> ResNet34:\n",
        "    \"\"\"Copy over the weights of `pretrained_resnet` to your resnet.\"\"\"\n",
        "\n",
        "    # Get the state dictionaries for each model, check they have the same number of parameters & buffers\n",
        "    mydict = my_resnet.state_dict()\n",
        "    pretraineddict = pretrained_resnet.state_dict()\n",
        "    assert len(mydict) == len(pretraineddict), \"Mismatching state dictionaries.\"\n",
        "\n",
        "    # Define a dictionary mapping the names of your parameters / buffers to their values in the pretrained model\n",
        "    state_dict_to_load = {\n",
        "        mykey: pretrainedvalue\n",
        "        for (mykey, myvalue), (pretrainedkey, pretrainedvalue) in zip(mydict.items(), pretraineddict.items())\n",
        "    }\n",
        "\n",
        "    # Load in this dictionary to your model\n",
        "    my_resnet.load_state_dict(state_dict_to_load)\n",
        "\n",
        "    return my_resnet\n",
        "\n",
        "\n",
        "pretrained_resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1).to(device)\n",
        "my_resnet = copy_weights(my_resnet, pretrained_resnet).to(device)\n",
        "print(\"Weights copied successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTl0ji4bjBUQ"
      },
      "source": [
        "This function uses the `state_dict()` method, which returns an  `OrderedDict` (documentation [here](https://realpython.com/python-ordereddict/)) object containing all the parameter/buffer names and their values. State dicts can be extracted from models, saved to your filesystem (this is a common way to store the results of training a model), and can also be loaded back into a model using the `load_state_dict` method. (Note that you can also load weights using a regular Python `dict`, but since Python 3.7, the builtin `dict` is guaranteed to maintain items in the order they're inserted.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob6sea_yjBUQ"
      },
      "source": [
        "## Running Your Model\n",
        "\n",
        "We've provided you with some images for your model to classify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj_5PwZ9jBUQ"
      },
      "outputs": [],
      "source": [
        "IMAGE_FILENAMES = [\n",
        "    \"chimpanzee.jpg\",\n",
        "    \"golden_retriever.jpg\",\n",
        "    \"platypus.jpg\",\n",
        "    \"frogs.jpg\",\n",
        "    \"fireworks.jpg\",\n",
        "    \"astronaut.jpg\",\n",
        "    \"iguana.jpg\",\n",
        "    \"volcano.jpg\",\n",
        "    \"goofy.jpg\",\n",
        "    \"dragonfly.jpg\",\n",
        "]\n",
        "\n",
        "IMAGE_FOLDER = section_dir / \"resnet_inputs\"\n",
        "\n",
        "images = [Image.open(IMAGE_FOLDER / filename) for filename in IMAGE_FILENAMES]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6ZpFY0FjBUQ"
      },
      "source": [
        "Our `images` are of type `PIL.Image.Image`, so we can just call them in a cell to display them, or alternatively use a function like IPython's `display`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIw3-EK8jBUQ"
      },
      "outputs": [],
      "source": [
        "display(images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckcsww3hjBUQ"
      },
      "source": [
        "We now need to define a `transform` object like we did for MNIST. We will use the same transforms to convert the PIL image to a tensor, and to normalize it. But we also want to resize the images to `height=224, width=224`, because not all of them start out with this size and we need them to be consistent before passing them through our model.\n",
        "\n",
        "In the normalization step, we'll use a mean of `[0.485, 0.456, 0.406]`, and a standard deviation of `[0.229, 0.224, 0.225]` (these are the mean and std dev of images from [ImageNet](https://www.image-net.org/)). Note that the means and std devs have three elements, because ImageNet contains RGB rather than monochrome images, and we're normalising over each of the three RGB channels separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWkEk7fUjBUQ"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "IMAGENET_TRANSFORM = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prepared_images = t.stack([IMAGENET_TRANSFORM(img) for img in images], dim=0).to(device)\n",
        "assert prepared_images.shape == (len(images), 3, IMAGE_SIZE, IMAGE_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmZna3XejBUQ"
      },
      "source": [
        "### Exercise - verify your model's predictions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Lastly, you should run your model with these prepared images, and verify that your predictions are the same as the model's predictions.\n",
        "\n",
        "You can do this by filling in the `predict` function below, then running the code. We've also provided you with a file `imagenet_labels.json` which you can use to get the actual classnames of imagenet data, and see what your model's predictions actually are.\n",
        "\n",
        "When you run the code, you should find that your top prediction probabilities are within about 0.01% of the reference model's probabilities most (not all) of the time. This kind of error is not uncommon when you have slightly different orders of linear operations or small implementation details which differ between models, and which can introduce floating point errors that compound as we move through the model. As a bonus exercise (which may or may not break your sanity), you're welcome to try and work through our implementation, comparing it to the PyTorch model's implementation and find where the discrepancy comes from!\n",
        "\n",
        "*Tip - the torch method `torch.max` will return a tuple of (values, indices) if you supply a dimension argument `dim`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VHNYmPTjBUR"
      },
      "outputs": [],
      "source": [
        "@t.inference_mode()\n",
        "def predict(\n",
        "    model: nn.Module, images: Float[Tensor, \"batch rgb h w\"]\n",
        ") -> tuple[Float[Tensor, \"batch\"], Int[Tensor, \"batch\"]]:\n",
        "    \"\"\"\n",
        "    Returns the maximum probability and predicted class for each image, as a tensor of floats and ints respectively.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "with open(section_dir / \"imagenet_labels.json\") as f:\n",
        "    imagenet_labels = list(json.load(f).values())\n",
        "\n",
        "# Check your predictions match those of the pretrained model\n",
        "my_probs, my_predictions = predict(my_resnet, prepared_images)\n",
        "pretrained_probs, pretrained_predictions = predict(pretrained_resnet, prepared_images)\n",
        "assert (my_predictions == pretrained_predictions).all()\n",
        "t.testing.assert_close(my_probs, pretrained_probs, atol=5e-4, rtol=0)  # tolerance of 0.05%\n",
        "print(\"All predictions match!\")\n",
        "\n",
        "# Print out your predictions, next to the corresponding images\n",
        "for i, img in enumerate(images):\n",
        "    table = Table(\"Model\", \"Prediction\", \"Probability\")\n",
        "    table.add_row(\"My ResNet\", imagenet_labels[my_predictions[i]], f\"{my_probs[i]:.3%}\")\n",
        "    table.add_row(\"Reference Model\", imagenet_labels[pretrained_predictions[i]], f\"{pretrained_probs[i]:.3%}\")\n",
        "    rprint(table)\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqZ-CAOpjBUR"
      },
      "source": [
        "<details>\n",
        "<summary>Help! My model is predicting roughly the same percentage for every category!</summary>\n",
        "\n",
        "This can indicate that your model weights are randomly initialized, meaning the weight loading process didn't actually take. Or, you reinitialized your model by accident after loading the weights.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@t.inference_mode()\n",
        "def predict(\n",
        "    model: nn.Module, images: Float[Tensor, \"batch rgb h w\"]\n",
        ") -> tuple[Float[Tensor, \"batch\"], Int[Tensor, \"batch\"]]:\n",
        "    \"\"\"\n",
        "    Returns the maximum probability and predicted class for each image, as a tensor of floats and ints respectively.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    logits = model(images)\n",
        "    probabilities = logits.softmax(dim=-1)\n",
        "    return probabilities.max(dim=-1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkLlVXrdjBUR"
      },
      "source": [
        "If you've done everything correctly, your version should give the same classifications, and the percentages should match at least to a couple decimal places.\n",
        "\n",
        "If it does, congratulations, you've now run an entire ResNet, using barely any code from `torch.nn`! The only things we used were `nn.Module` and `nn.Parameter`.\n",
        "\n",
        "If it doesn't, you get to practice model debugging! Remember to use the `utils.print_param_count` function that was provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpA7i8hWjBUR"
      },
      "source": [
        "### Aside - hooks\n",
        "\n",
        "One problem you might have encountered is that your model outputs `NaN`s rather than actual numbers. When debugging this, it's useful to try and identify which module the error first appears in. This is a great use-case for **hooks**, which are something we'll be digging a lot more into during our mechanistic interpretability exercises later on.\n",
        "\n",
        "A hook is basically a function which you can attach to a particular `nn.Module`, which gets executed during your model's forward or backward passes. Here, we'll only consider forward hooks. A hook function's type signature is:\n",
        "\n",
        "```python\n",
        "def hook(module: nn.Module, inputs: list[t.Tensor], output: t.Tensor) -> None:\n",
        "    pass\n",
        "```\n",
        "\n",
        "The `inputs` argument is a list of the inputs to the module (often just one tensor), and the `output` argument is the output of the module. This hook gets registered to a module by calling `module.register_forward_hook(hook)`. During forward passes, the hook function will run.\n",
        "\n",
        "Here is some code which will check for `NaN`s in the output of each module, and raise a `ValueError` if it finds any. We've also given you an example tiny network which produces a `NaN` in the output of the second layer, to demonstrate it on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n4EvHKzjBUR"
      },
      "outputs": [],
      "source": [
        "class NanModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Define a module that always returns NaNs (we will use hooks to identify this error).\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return t.full_like(x, float(\"nan\"))\n",
        "\n",
        "\n",
        "def hook_check_for_nan_output(module: nn.Module, input: tuple[Tensor], output: Tensor) -> None:\n",
        "    \"\"\"\n",
        "    Hook function which detects when the output of a layer is NaN.\n",
        "    \"\"\"\n",
        "    if t.isnan(output).any():\n",
        "        raise ValueError(f\"NaN output from {module}\")\n",
        "\n",
        "\n",
        "def add_hook(module: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Register our hook function in a module.\n",
        "\n",
        "    Use model.apply(add_hook) to recursively apply the hook to model and all submodules.\n",
        "    \"\"\"\n",
        "    module.register_forward_hook(hook_check_for_nan_output)\n",
        "\n",
        "\n",
        "def remove_hooks(module: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Remove all hooks from module.\n",
        "\n",
        "    Use module.apply(remove_hooks) to do this recursively.\n",
        "    \"\"\"\n",
        "    module._backward_hooks.clear()\n",
        "    module._forward_hooks.clear()\n",
        "    module._forward_pre_hooks.clear()\n",
        "\n",
        "\n",
        "# Create our model with a NaN in the middle, and apply a hook function to it which checks for NaNs\n",
        "model = nn.Sequential(nn.Identity(), NanModule(), nn.Identity())\n",
        "model = model.apply(add_hook)\n",
        "\n",
        "# Run the model, and and our hook function should raise an error that gets caught by the try-except\n",
        "try:\n",
        "    input = t.randn(3)\n",
        "    output = model(input)\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "\n",
        "# Remove hooks at the end\n",
        "model = model.apply(remove_hooks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBg9yltzjBUR"
      },
      "source": [
        "When you run this code, you should find it raising an error at the `NanModule`.\n",
        "\n",
        "\n",
        "> Important - when you're working with PyTorch hooks, make sure you **remember to remove them at the end of each use**! This is a classic source of bugs, and one of the things that make PyTorch hooks so janky. When we study TransformerLens in the next chapter, we'll use a version of hooks that is essentially the same under the hood, but comes with quite a few quality of life improvements!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXL1UZH4jBUR"
      },
      "source": [
        "# ☆ Bonus - Feature Extraction\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand the difference between feature extraction and finetuning\n",
        "> * Perform feature extraction on a pre-trained ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XQ-NkXXjBUR"
      },
      "source": [
        "Now that you've seen how to build a modular training loop, and you've seen how ResNet works and is built, we're going to put these two things together to finetune a ResNet model on a new dataset.\n",
        "\n",
        "**Finetuning** can mean slightly different things in different contexts, but broadly speaking it means using the weights of an already trained network as the starting values for training a new network. Because training networks from scratch is very computationally expensive, this is a common practice in ML.\n",
        "\n",
        "The specific type of finetuning we'll be doing here is called **feature extraction**. This is when we freeze most layers of a model except the last few, and perform gradient descent on those. We call this feature extraction because the earlier layers of the model have already learned to identify important features of the data (and these features are also relevant for the new task), so all that we have to do is train a few final layers in the model to extract these features.\n",
        "\n",
        "*Terminology note - sometimes feature extraction and finetuning are defined differently, with finetuning referring to the training of all the weights in a pretrained model (usually with a small or decaying learning rate), and feature extraction referring to the freezing of some layers and training of others. To avoid confusion here, we'll use the term \"feature extraction\" rather than \"finetuning\".*\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/feature_extraction.png\" width=\"400\">\n",
        "\n",
        "How do we prepare a model for feature extraction? By **freezing layers** of our model.\n",
        "\n",
        "We'll discuss freezing layers & the backpropagation algorithm in much more detail tomorrow, but for now it's fine to just understand what's going on at a basic level. When we call `loss.backward()` in our training loop (or when this is implicitly called by our PyTorch Lightning trainer), this propagates gradients from our `loss` scalar back to all parameters in our model. If a parameter has its `requires_grad` attribute set to `False`, it means gradients won't be computed for this tensor during backpropagation. Thanks to PyTorch helpfully keeping track of the parameters which require gradients (using a structure called the **computational graph**), if we set `requires_grad = False` for the first few layers of parameters in our model, PyTorch will actually save us time and compute by not calculating gradients for these parameters at all.\n",
        "\n",
        "See the code below as an example of how gradient propagation stops at tensors with `requires_grad = False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NniVShj_jBUR"
      },
      "outputs": [],
      "source": [
        "layer0, layer1 = nn.Linear(3, 4), nn.Linear(4, 5)\n",
        "\n",
        "layer0.requires_grad_(False)  # generic code to set `param.requires_grad=False` recursively for a module / entire model\n",
        "\n",
        "x = t.randn(3)\n",
        "out = layer1(layer0(x)).sum()\n",
        "out.backward()\n",
        "\n",
        "assert layer0.weight.grad is None\n",
        "assert layer1.weight.grad is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihl5hAAIjBUR"
      },
      "source": [
        "### Exercise - prepare ResNet for feature extraction\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "First, you should complete the function below to do the following:\n",
        "\n",
        "* Instantiate a `ResNet34` model using your class, and copy in weights from a pretrained model (you can use code from earlier here)\n",
        "* Disable gradients for all layers\n",
        "* Replace the final linear layer with a new linear layer, which has the same number of `in_features`, but a different number of `out_features` (given by the `n_classes` argument)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9U-w8lejBUR"
      },
      "outputs": [],
      "source": [
        "def get_resnet_for_feature_extraction(n_classes: int) -> ResNet34:\n",
        "    \"\"\"\n",
        "    Creates a ResNet34 instance, replaces its final linear layer with a classifier for `n_classes` classes, and freezes\n",
        "    all weights except the ones in this layer.\n",
        "\n",
        "    Returns the ResNet model.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_get_resnet_for_feature_extraction(get_resnet_for_feature_extraction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmMmGjbfjBUR"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def get_resnet_for_feature_extraction(n_classes: int) -> ResNet34:\n",
        "    \"\"\"\n",
        "    Creates a ResNet34 instance, replaces its final linear layer with a classifier for `n_classes` classes, and freezes\n",
        "    all weights except the ones in this layer.\n",
        "\n",
        "    Returns the ResNet model.\n",
        "    \"\"\"\n",
        "    # Create a ResNet34 with the default number of classes\n",
        "    my_resnet = ResNet34()\n",
        "\n",
        "    # Load the pretrained weights\n",
        "    pretrained_resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # Copy the weights over\n",
        "    my_resnet = copy_weights(my_resnet, pretrained_resnet)\n",
        "\n",
        "    # Freeze gradients for all layers (note that when we redefine the last layer, it will be unfrozen)\n",
        "    my_resnet.requires_grad_(False)\n",
        "\n",
        "    # Redefine last layer\n",
        "    my_resnet.out_layers[-1] = Linear(my_resnet.out_features_per_group[-1], n_classes)\n",
        "\n",
        "    return my_resnet\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xFWfEyDjBUR"
      },
      "source": [
        "We'll now give you some boilerplate code to load in and transform your data (this is pretty similar to the MNIST code)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLaF_0mKjBUR"
      },
      "outputs": [],
      "source": [
        "def get_cifar() -> tuple[datasets.CIFAR10, datasets.CIFAR10]:\n",
        "    \"\"\"Returns CIFAR-10 train and test sets.\"\"\"\n",
        "    cifar_trainset = datasets.CIFAR10(exercises_dir / \"data\", train=True, download=True, transform=IMAGENET_TRANSFORM)\n",
        "    cifar_testset = datasets.CIFAR10(exercises_dir / \"data\", train=False, download=True, transform=IMAGENET_TRANSFORM)\n",
        "    return cifar_trainset, cifar_testset\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ResNetTrainingArgs:\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 5\n",
        "    learning_rate: float = 1e-3\n",
        "    n_classes: int = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9kgvI0UjBUR"
      },
      "source": [
        "The dataclass we've defined containing training arguments is basically the same as the one we had for the convnet, the main difference is that we're now using the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). This is the dataset we'll be training our model on. It consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. See the link for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9GO6tYjjBUR"
      },
      "source": [
        "### Exercise - write training loop for feature extraction\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "We now come to the final task - write a training loop for your ResNet model. This shouldn't be too difficult because most of the code can be directly taken from the exercise in section 2️⃣, however there are a few changes you should take note of:\n",
        "\n",
        "- Since all other parameters' gradients have been frozen, it doesn't really matter which parameters you pass to your optimizer. However, note that you have the option of passing just a subset of parameters using e.g. `AdamW(model.some_module.parameters(), ...)`.\n",
        "- Now that we're working with batchnorm, you'll have to call `model.train()` and `model.eval()` before your training and validation loops (recall that the behaviour of batchnorm changes between training and eval modes).\n",
        "- Make sure you're connected to GPU runtime rather than CPU, otherwise this training might take quite a while.\n",
        "- Also make sure you're logging progress within each epoch, since the epochs might each take a while (although we've given you the `get_cifar_subset` function which returns a subset of the CIFAR10 data, and we recommend using this function with default parameters so that each epoch is a bit faster)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz8BtxfujBUR"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "def get_cifar_subset(trainset_size: int = 10_000, testset_size: int = 1_000) -> tuple[Subset, Subset]:\n",
        "    \"\"\"Returns a subset of CIFAR-10 train and test sets (slicing the first examples from the datasets).\"\"\"\n",
        "    cifar_trainset, cifar_testset = get_cifar()\n",
        "    return Subset(cifar_trainset, range(trainset_size)), Subset(cifar_testset, range(testset_size))\n",
        "\n",
        "\n",
        "def train(args: ResNetTrainingArgs) -> tuple[list[float], list[float], ResNet34]:\n",
        "    \"\"\"\n",
        "    Performs feature extraction on ResNet, returning the model & lists of loss and accuracy.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE - write your train function for feature extraction\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "args = ResNetTrainingArgs()\n",
        "loss_list, accuracy_list, model = train(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsZIzFzzjBUR"
      },
      "outputs": [],
      "source": [
        "line(\n",
        "    y=[loss_list, [1 / args.n_classes] + accuracy_list],  # we start by assuming a uniform accuracy of 10%\n",
        "    use_secondary_yaxis=True,\n",
        "    x_max=args.epochs * 10_000,\n",
        "    labels={\"x\": \"Num examples seen\", \"y1\": \"Cross entropy loss\", \"y2\": \"Test Accuracy\"},\n",
        "    title=\"ResNet Feature Extraction\",\n",
        "    width=800,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw1WV4evjBUR"
      },
      "source": [
        "<details>\n",
        "<summary>Spoilers - what kind of results should you get?</summary>\n",
        "\n",
        "If you train the whole model rather than just the final layer, you should find accuracy increases very slowly, not getting very far above random chance. This reflects the fact that the model is trying to learn a new task (classifying images into 10 classes) from scratch, rather than just learning to extract features from images, and this takes a long time!\n",
        "\n",
        "If you train just the final layer, your accuracy should reach around 70-80% by the first epoch. This is because the model is already very good at extracting features from images, and it just needs to learn how to turn these features into predictions for this new set of classes.\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "def get_cifar_subset(trainset_size: int = 10_000, testset_size: int = 1_000) -> tuple[Subset, Subset]:\n",
        "    \"\"\"Returns a subset of CIFAR-10 train and test sets (slicing the first examples from the datasets).\"\"\"\n",
        "    cifar_trainset, cifar_testset = get_cifar()\n",
        "    return Subset(cifar_trainset, range(trainset_size)), Subset(cifar_testset, range(testset_size))\n",
        "\n",
        "\n",
        "def train(args: ResNetTrainingArgs) -> tuple[list[float], list[float], ResNet34]:\n",
        "    \"\"\"\n",
        "    Performs feature extraction on ResNet, returning the model & lists of loss and accuracy.\n",
        "    \"\"\"\n",
        "    model = get_resnet_for_feature_extraction(args.n_classes).to(device)\n",
        "\n",
        "    trainset, testset = get_cifar_subset()\n",
        "    trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
        "    testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.out_layers[-1].parameters(), lr=args.learning_rate)\n",
        "\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        for imgs, labels in (pbar := tqdm(trainloader)):\n",
        "            # Move data to device, perform forward pass\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            # Calculate loss, perform backward pass\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update logs & progress bar\n",
        "            loss_list.append(loss.item())\n",
        "            pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        num_correct_classifications = 0\n",
        "        for imgs, labels in testloader:\n",
        "            # Move data to device, perform forward pass in inference mode\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with t.inference_mode():\n",
        "                logits = model(imgs)\n",
        "\n",
        "            # Compute num correct by comparing argmaxed logits to true labels\n",
        "            predictions = t.argmax(logits, dim=1)\n",
        "            num_correct_classifications += (predictions == labels).sum().item()\n",
        "\n",
        "        # Compute & log total accuracy\n",
        "        accuracy = num_correct_classifications / len(mnist_testset)\n",
        "        accuracy_list.append(accuracy)\n",
        "\n",
        "    return loss_list, accuracy_list, model\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0Qbzi6hjBUR"
      },
      "source": [
        "# ☆ Bonus - Convolutions From Scratch\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand how array strides work, and why they're important for efficient linear operations\n",
        "> * Learn how to use `as_strided` to perform simple linear operations like trace and matrix multiplication\n",
        "> * Implement your own convolutions and maxpooling functions using stride-based methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKcm8AfIjBUR"
      },
      "source": [
        "This section is designed to get you familiar with the implementational details of layers like `Linear` and `Conv2d`. You'll be using libraries like `einops`, and functions like `torch.as_strided` to get a very low-level picture of how these operations work, which will help build up your overall understanding.\n",
        "\n",
        "Note that `torch.as_strided` isn't something which will come up explicitly in much of the rest of the course (unlike `einops`). The purpose of the stride exercises is more to give you an appreciation for what's going on under the hood, so that we can build layers of abstraction on top of that during the rest of this week (and by extension this course). I see this as analogous to how [many CS courses](https://cs50.harvard.edu/x/2023/) start by teaching you about languages like C and concepts like pointers and memory management before moving on to higher-level langauges like Python which abstract away these details. The hope is that when you get to the later sections of the course, you'll have the tools to understand them better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jei25WV9jBUR"
      },
      "source": [
        "## Reading\n",
        "\n",
        "* [Python NumPy, 6.1 - `as_strided()`](https://www.youtube.com/watch?v=VlkzN00P0Bc) explains what array strides are.\n",
        "* [`as_strided` and `sum` are all you need](https://jott.live/markdown/as_strided) gives an overview of how to use `as_strided` to perform array operations.\n",
        "* [Advanced NumPy: Master stride tricks with 25 illustrated exercises](https://towardsdatascience.com/advanced-numpy-master-stride-tricks-with-25-illustrated-exercises-923a9393ab20) provides several clear and intuitive examples of `as_strided` being used to construct arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-1QEmzWjBUR"
      },
      "source": [
        "## Basic stride exercises\n",
        "\n",
        "Array strides, and the `as_strided` method, are important to understand well because lots of linear operations are actually implementing something like `as_strided` under the hood.\n",
        "\n",
        "Run the following code, to define this tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR45lSoFjBUS"
      },
      "outputs": [],
      "source": [
        "test_input = t.tensor(\n",
        "    [\n",
        "        [0, 1, 2, 3, 4],\n",
        "        [5, 6, 7, 8, 9],\n",
        "        [10, 11, 12, 13, 14],\n",
        "        [15, 16, 17, 18, 19],\n",
        "    ],\n",
        "    dtype=t.float,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-iKkEfpjBUS"
      },
      "source": [
        "This tensor is stored in a contiguous block in computer memory.\n",
        "\n",
        "We can call the `stride` method to get the strides of this particular array. Running `test_input.stride()`, we get `(5, 1)`. This means that we need to skip over one element in the storage of this tensor to get to the next element in the row, and 5 elements to get the next element in the column (because you have to jump over all 5 elements in the row). Another way of phrasing this: the `n`th element in the stride is the number of elements we need to skip over to move one index position in the `n`th dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDrLYaxPjBUS"
      },
      "source": [
        "### Exercise - fill in the correct size and stride\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to ~30 minutes on these exercises collectively.\n",
        "> Strides can be confusing and fiddly, so you should be willing to look at the solution if you're stuck! They are not the most important part of the material today.\n",
        "> ```\n",
        "\n",
        "In the exercises below, we will work with the `test_input` tensor above. You should fill in the `size` and `stride` arguments so that calling `test_input.as_strided` with these arguments produces the desired output. When you run the cell, the `for` loop at the end will iterate through the test cases and print out whether the test passed or failed.\n",
        "\n",
        "We've already filled in the first two as an example, along with illustrations explaining what's going on:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/strides3c.png\" width=\"700\">\n",
        "\n",
        "By the end of these examples, hopefully you'll have a clear idea of what's going on. If you're still confused by some of these, then the dropdown below the codeblock contains some annotations to explain the answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tH7inLUjBUS"
      },
      "outputs": [],
      "source": [
        "TestCase = namedtuple(\"TestCase\", [\"output\", \"size\", \"stride\"])\n",
        "\n",
        "test_cases = [\n",
        "    # Example 1\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3]),\n",
        "        size=(4,),\n",
        "        stride=(1,),\n",
        "    ),\n",
        "    # Example 2\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 2], [5, 7]]),\n",
        "        size=(2, 2),\n",
        "        stride=(5, 2),\n",
        "    ),\n",
        "    # Start of exercises (you should fill in size & stride for all 6 of these):\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3, 4]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 5, 10, 15]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [5, 6, 7]]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [10, 11, 12]]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 0, 0], [11, 11, 11]]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 6, 12, 18]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "for i, test_case in enumerate(test_cases):\n",
        "    if (test_case.size is None) or (test_case.stride is None):\n",
        "        print(f\"Test {i} failed: attempt missing.\")\n",
        "    else:\n",
        "        actual = test_input.as_strided(size=test_case.size, stride=test_case.stride)\n",
        "        if (test_case.output != actual).any():\n",
        "            print(f\"Test {i} failed\\n  Expected: {test_case.output}\\n  Actual: {actual}\")\n",
        "        else:\n",
        "            print(f\"Test {i} passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKaHnmSEjBUS"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "test_cases = [\n",
        "    # Example 1\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3]),\n",
        "        size=(4,),\n",
        "        stride=(1,),\n",
        "    ),\n",
        "    # Example 2\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 2], [5, 7]]),\n",
        "        size=(2, 2),\n",
        "        stride=(5, 2),\n",
        "    ),\n",
        "    # Start of exercises (you should fill in size & stride for all 6 of these):\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3, 4]),\n",
        "        size=(5,),\n",
        "        stride=(1,),\n",
        "    ),\n",
        "    # # Explanation: the tensor is held in a contiguous memory block. When you get to the end of one row, a single\n",
        "    # # stride jumps to the start of the next row\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 5, 10, 15]),\n",
        "        size=(4,),\n",
        "        stride=(5,),\n",
        "    ),\n",
        "    # # Explanation: this is same as previous case, only now you're moving in colspace (i.e. skipping 5 elements) each\n",
        "    # # time you move one element across the output tensor. So stride is 5 rather than 1\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [5, 6, 7]]),\n",
        "        size=(2, 3),\n",
        "        stride=(5, 1),\n",
        "    ),\n",
        "    # # Explanation: as you move one column to the right in the output tensor, you want to jump one element in `test_input`\n",
        "    # # (since you're just going one column to the right). As you move one row down in the output tensor, you want to jump\n",
        "    # # down one row in `test_input` (which is equivalent to a stride of 5, because we're jumping 5 elements).\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [10, 11, 12]]),\n",
        "        size=(2, 3),\n",
        "        stride=(10, 1),\n",
        "    ),\n",
        "    # # Explanation: same as previous, except now we're jumping over 10 elements (2 rows of 5 elements) each time we\n",
        "    # # move down in the output tensor.\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 0, 0], [11, 11, 11]]),\n",
        "        size=(2, 3),\n",
        "        stride=(11, 0),\n",
        "    ),\n",
        "    # # Explanation: we're copying horizontally, i.e. we don't move in the original tensor when we step right in the\n",
        "    # # output tensor, so the stride is 0 (this is a very important case to understand for the later exercises, since\n",
        "    # # it's effectively our way of doing an einops.repeat operation!). As we move one row down, we're jumping over 11\n",
        "    # # elements in the original tensor (going from 0 to 11).\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 6, 12, 18]),\n",
        "        size=(4,),\n",
        "        stride=(6,),\n",
        "    ),\n",
        "    # Explanation: we're effectively taking the diagonal elements of the original tensor here, since we're creating a\n",
        "    # 1D tensor with stride equal to (row_stride + col_stride) of the original tensor.\n",
        "]\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxcpBvqJjBUS"
      },
      "source": [
        "## Intermediate stride exercises\n",
        "\n",
        "Now that you're comfortable with the basics, we'll dive a little deeper with `as_strided`. In the last few exercises of this section, you'll start to implement some more challenging stride functions: trace, matrix-vector and matrix-matrix multiplication, just like we did for `einsum` in the previous section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2KTSl8VjBUS"
      },
      "source": [
        "### Exercise - trace\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> Use the hint if you're stuck.\n",
        "> ```\n",
        "\n",
        "You might find the very last example in the previous section helpful for this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWEgP_XHjBUS"
      },
      "outputs": [],
      "source": [
        "def as_strided_trace(mat: Float[Tensor, \"i j\"]) -> Float[Tensor, \"\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.trace`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_trace(as_strided_trace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQRIlcRojBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "The trace is the sum of all the elements you get from starting at `[0, 0]` and then continually stepping down and right one element. Use strides to create a 1D array which contains these elements.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def as_strided_trace(mat: Float[Tensor, \"i j\"]) -> Float[Tensor, \"\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.trace`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    stride = mat.stride()\n",
        "\n",
        "    assert len(stride) == 2, f\"matrix should be 2D, not {len(stride)}\"\n",
        "    assert mat.size(0) == mat.size(1), \"matrix should be square\"\n",
        "\n",
        "    diag = mat.as_strided((mat.size(0),), (stride[0] + stride[1],))\n",
        "\n",
        "    return diag.sum()\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T00YeIh3jBUS"
      },
      "source": [
        "### Exercise - matrix-vector multiplication\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise.\n",
        "> The hints should be especially useful here if you're stuck. There are two hints available to you.\n",
        "> ```\n",
        "\n",
        "You should implement this using only `as_strided` and `sum` methods, and elementwise multiplication `*` - in other words, no matrix multiplication functions!\n",
        "\n",
        "You might find the second last example in the previous section helpful for this exercise (i.e. the one that involved a stride of zero)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v1OGj_LjBUS"
      },
      "outputs": [],
      "source": [
        "def as_strided_mv(mat: Float[Tensor, \"i j\"], vec: Float[Tensor, \"j\"]) -> Float[Tensor, \"i\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_mv(as_strided_mv)\n",
        "tests.test_mv2(as_strided_mv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpinaDvgjBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Hint 1</summary>\n",
        "\n",
        "You want your output array to be as follows:\n",
        "\n",
        "$$\n",
        "\\text{output}[i] = \\sum_j \\text{mat}[i, j] \\times \\text{vector}[j]\n",
        "$$\n",
        "\n",
        "so first try to create an array with:\n",
        "\n",
        "$$\n",
        "\\text{arr}[i, j] = \\text{mat}[i, j] \\times \\text{vector}[j]\n",
        "$$\n",
        "\n",
        "then you can calculate `output` by summing over the second dimension of `arr`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 2</summary>\n",
        "\n",
        "First try to use strides to create `vec_expanded` such that:\n",
        "\n",
        "$$\n",
        "\\text{vec\\_expanded}[i, j] = \\text{vec}[j]\n",
        "$$\n",
        "\n",
        "We can then compute:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{arr}[i, j] &= \\text{mat}[i, j] \\times \\text{vec\\_expanded}[i, j] \\\\\n",
        "\\text{output}[i] &= \\sum_j \\text{arr}[i, j]\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "with the first equation being a simple elementwise multiplication, and the second equation being a sum over the second dimension.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm passing the first test, but failing the second.</summary>\n",
        "\n",
        "It's possible that the input matrices you recieve could themselves be the output of an `as_strided` operation, so that they're represented in memory in a non-contiguous way. Make sure that your `as_strided `operation is using the strides from the original input arrays, i.e. it's not just assuming the last element in the `stride()` tuple is 1.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def as_strided_mv(mat: Float[Tensor, \"i j\"], vec: Float[Tensor, \"j\"]) -> Float[Tensor, \"i\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    sizeM = mat.shape\n",
        "    sizeV = vec.shape\n",
        "    strideV = vec.stride()\n",
        "\n",
        "    assert len(sizeM) == 2, f\"mat1 should be 2D, not {len(sizeM)}\"\n",
        "    assert sizeM[1] == sizeV[0], f\"mat{list(sizeM)}, vec{list(sizeV)} not compatible for multiplication\"\n",
        "\n",
        "    vec_expanded = vec.as_strided(mat.shape, (0, strideV[0]))\n",
        "\n",
        "    return (mat * vec_expanded).sum(dim=1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPLHf1Y0jBUS"
      },
      "source": [
        "### Exercise - matrix-matrix multiplication\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> The hints should be especially useful here if you're stuck. There are two hints available to you.\n",
        "> ```\n",
        "                \n",
        "Like the previous function, this should only involve `as_strided`, `sum`, and pointwise multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNmY5ncGjBUS"
      },
      "outputs": [],
      "source": [
        "def as_strided_mm(matA: Float[Tensor, \"i j\"], matB: Float[Tensor, \"j k\"]) -> Float[Tensor, \"i k\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_mm(as_strided_mm)\n",
        "tests.test_mm2(as_strided_mm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMIOVzNCjBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Hint 1</summary>\n",
        "\n",
        "If you did the first one, this isn't too dissimilar. We have:\n",
        "\n",
        "$$\n",
        "\\text{output}[i, k] = \\sum_j \\text{matA}[i, j] \\times \\text{matB}[j, k]\n",
        "$$\n",
        "\n",
        "\n",
        "so in this case, try to create an array with:\n",
        "\n",
        "$$\n",
        "\\text{arr}[i, j, k] = \\text{matA}[i, j] \\times \\text{matB}[j, k]\n",
        "$$\n",
        "\n",
        "then sum this array over `j` to get our output.\n",
        "\n",
        "We need to create expanded versions of both `matA` and `matB` in order to take this product.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 2</summary>\n",
        "\n",
        "We want to compute\n",
        "\n",
        "$$\n",
        "\\text{matA\\_expanded}[i, j, k] = \\text{matA}[i, j]\n",
        "$$\n",
        "\n",
        "so our stride for `matA` should be `(matA.stride(0), matA.stride(1), 0)` (because we're repeating over the last dimension but iterating over the first 2 dimensions just like for the 2D matrix `matA`).\n",
        "        \n",
        "A similar idea applies for `matB`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def as_strided_mm(matA: Float[Tensor, \"i j\"], matB: Float[Tensor, \"j k\"]) -> Float[Tensor, \"i k\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    assert len(matA.shape) == 2, f\"mat1 should be 2D, not {len(matA.shape)}\"\n",
        "    assert len(matB.shape) == 2, f\"mat2 should be 2D, not {len(matB.shape)}\"\n",
        "    assert matA.shape[1] == matB.shape[0], (\n",
        "        f\"mat1{list(matA.shape)}, mat2{list(matB.shape)} not compatible for multiplication\"\n",
        "    )\n",
        "\n",
        "    # Get the matrix strides, and matrix dims\n",
        "    sA0, sA1 = matA.stride()\n",
        "    dA0, dA1 = matA.shape\n",
        "    sB0, sB1 = matB.stride()\n",
        "    _, dB1 = matB.shape\n",
        "\n",
        "    # Get target size for matrices, as well as the strides necessary to create them\n",
        "    expanded_size = (dA0, dA1, dB1)\n",
        "    matA_expanded_stride = (sA0, sA1, 0)\n",
        "    matB_expanded_stride = (0, sB0, sB1)\n",
        "\n",
        "    # Create the strided matrices, and return their product summed over middle dimension\n",
        "    matA_expanded = matA.as_strided(expanded_size, matA_expanded_stride)\n",
        "    matB_expanded = matB.as_strided(expanded_size, matB_expanded_stride)\n",
        "    return (matA_expanded * matB_expanded).sum(dim=1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyD475YsjBUS"
      },
      "source": [
        "## conv1d minimal\n",
        "\n",
        "Here, we will implement the PyTorch `conv1d` function, which can be found [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html). We will start with a simple implementation where `stride=1` and `padding=0`, with the other arguments set to their default values.\n",
        "\n",
        "Firstly, some explanation of `conv1d` in PyTorch. The `1` in `1d` here refers to the number of dimensions along which we slide the weights (also called the kernel) when we convolve. Importantly, it does not refer to the number of dimensions of the tensors that are being used in our calculations. Typically the input and kernel are both 3D:\n",
        "\n",
        "* `input.shape = (batch, in_channels, width)`\n",
        "* `kernel.shape = (out_channels, in_channels, kernel_width)`\n",
        "\n",
        "A typical convolution operation is illustrated in the sketch below. Some notes on this sketch:\n",
        "\n",
        "* The `kernel_width` dimension of the kernel slides along the `width` dimension of the input. The `output_width` of the output is determined by the number of kernels that can be fit inside it; the formula can be seen in the right part of the sketch.\n",
        "* For each possible position of the kernel inside the model (i.e. each freezeframe position in the sketch), the operation happening is as follows:\n",
        "    * We take the product of the kernel values with the corresponding input values, and then take the sum\n",
        "    * This gives us a single value for each output channel\n",
        "    * These values are then passed into the output tensor\n",
        "* The sketch assumes a batch size of 1. To generalise to a larger batch number, we can just imagine this operation being repeated identically on every input.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-general.png\" width=950>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxAW8W4jBUS"
      },
      "source": [
        "### A note on `out_channels`\n",
        "\n",
        "The out_channels in a conv2d layer denotes the number of filters the layer uses. Each filter detects specific features in the input, producing an output with as many channels as filters.\n",
        "\n",
        "This number isn't tied to the input image's channels but is a design choice in the neural network architecture. Commonly, powers of 2 are chosen for computational efficiency, and deeper layers might have more channels to capture complex features. Additionally, this parameter is sometimes chosen based on the heuristic of wanting to balance the parameter count / compute for each layer - which is why you often see `out_channels` growing as the size of each feature map gets smaller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CTCD1yYjBUS"
      },
      "source": [
        "### Exercise - implement minimal 1D conv (part 1)\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> Use the diagram in the dropdown below, if you're stuck.\n",
        "> ```\n",
        "\n",
        "Below, you should implement `conv1d_minimal`. This is a function which works just like `conv1d`, but takes the default stride and padding values (these will be added back in later). You are allowed to use `as_strided` and `einsum`.\n",
        "\n",
        "Because this is a difficult exercise, we've given you a \"simplified\" function to implement first. This gets rid of the batch dimension, and input & output channel dimensions, so you only have to think about `x` and `weights` being one-dimensional tensors:\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-minimal.png\" width=650>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLxYfHY9jBUS"
      },
      "outputs": [],
      "source": [
        "def conv1d_minimal_simple(\n",
        "    x: Float[Tensor, \"width\"], weights: Float[Tensor, \"kernel_width\"]\n",
        ") -> Float[Tensor, \"output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "\n",
        "    Simplifications: batch = input channels = output channels = 1.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv1d_minimal_simple(conv1d_minimal_simple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCLG9IFfjBUS"
      },
      "source": [
        "<details>\n",
        "<summary>If you're stuck on <code>conv1d_minimal_simple</code>, click here to see a diagram which should help.</summary>\n",
        "\n",
        "This diagram illustrates the striding operation you'll need to perform on `x`. Once you do this, it's just a matter of using the right `einsum` operation to get the output.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-explained.png\" width=800>\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv1d_minimal_simple(\n",
        "    x: Float[Tensor, \"width\"], weights: Float[Tensor, \"kernel_width\"]\n",
        ") -> Float[Tensor, \"output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "\n",
        "    Simplifications: batch = input channels = output channels = 1.\n",
        "    \"\"\"\n",
        "    # Get output width, using formula\n",
        "    w = x.shape[0]\n",
        "    kw = weights.shape[0]\n",
        "    ow = w - kw + 1\n",
        "\n",
        "    # Get strides for x\n",
        "    s_w = x.stride(0)\n",
        "\n",
        "    # Get strided x (the new dimension has same stride as the original stride of x)\n",
        "    x_new_shape = (ow, kw)\n",
        "    x_new_stride = (s_w, s_w)\n",
        "    # Common error: s_w is always 1 if the tensor `x` wasn't itself created via striding, so if you put 1 here you won't\n",
        "    # spot your mistake until you try this with conv2d!\n",
        "    x_strided = x.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"ow kw, kw -> ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNGOcHejBUS"
      },
      "source": [
        "### Exercise - implement minimal 1D conv (part 2)\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Once you've implemented this function, you should now adapt it to make a \"full version\", which includes batch, in_channel and out_channel dimensions. If you're stuck, the dropdowns provide hints for how each of these new dimensions should be handled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Vimmc0ajBUS"
      },
      "outputs": [],
      "source": [
        "def conv1d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], weights: Float[Tensor, \"out_channels in_channels kernel_width\"]\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv1d_minimal(conv1d_minimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hmPFS18jBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm stuck on going from <code>conv1d_minimal_simple</code> to <code>conv1d_minimal</code>.</summary>\n",
        "\n",
        "The principle is the same as before. In your function, you should:\n",
        "\n",
        "* Create a strided version of `x` by adding a dimension of length `output_width` and with the same stride as the `width` stride of `x` (the purpose of which is to be able to do all the convolutions at once).\n",
        "* Perform an einsum between this strided version of `x` and `weights`, summing over the appropriate dimensions.\n",
        "\n",
        "The way each of the new dimensions `batch`, `out_channels` and `in_channels` are handled is as follows:\n",
        "\n",
        "* `batch` - this is an extra dimension for `x`, it is *not* summed over when creating `output`.\n",
        "* `out_channels` - this is an extra dimension for `weights`, it is *not* summed over when creating `output`.\n",
        "* `in_channels` - this is an extra dimension for `weights` *and* for `x`, it *is* summed over when creating `output`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv1d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], weights: Float[Tensor, \"out_channels in_channels kernel_width\"]\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    b, ic, w = x.shape\n",
        "    oc, ic2, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    # Get output width, using formula\n",
        "    ow = w - kw + 1\n",
        "\n",
        "    # Get strides for x\n",
        "    s_b, s_ic, s_w = x.stride()\n",
        "\n",
        "    # Get strided x (the new dimension has the same stride as the original width-stride of x)\n",
        "    x_new_shape = (b, ic, ow, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_w, s_w)\n",
        "    # Common error: xsWi is always 1, so if you put 1 here you won't spot your mistake until you try this with conv2d!\n",
        "    x_strided = x.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic ow kw, oc ic kw -> b oc ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgy48o8TjBUT"
      },
      "source": [
        "## conv2d minimal\n",
        "\n",
        "2D convolutions are conceptually similar to 1D. The only difference is in how you move the kernel across the tensor as you take your convolution. In this case, you will be moving the tensor across two dimensions:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv2d-general.png\" width=1050>\n",
        "\n",
        "For this reason, 1D convolutions tend to be used for signals (e.g. audio), 2D convolutions are used for images, and 3D convolutions are used for 3D scans (e.g. in medical applications)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p26FYremjBUT"
      },
      "source": [
        "### Exercise - implement 2D minimal convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        "> Use the diagram in the dropdown below, if you're stuck.\n",
        "> ```\n",
        "\n",
        "You should implement `conv2d` in a similar way to `conv1d`. Again, this is expected to be difficult and there are several hints you can go through. We've also provided a diagram to help you, like for the 1D case:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv2d-minimal.png\" width=900>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYIEJXr9jBUT"
      },
      "outputs": [],
      "source": [
        "def conv2d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        ") -> Float[Tensor, \"batch out_channels height_padding width_padding\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv2d_minimal(conv2d_minimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz3-F0JKjBUT"
      },
      "source": [
        "<details>\n",
        "<summary>Hint & diagram</summary>\n",
        "\n",
        "You should be doing the same thing that you did for the 1D version. The only difference is that you're introducing 2 new dimensions to your strided version of x, rather than 1 (their sizes should be `output_height` and `output_width`, and their strides should be the same as the original `height` and `width` strides of `x` respectively).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv2d-minimal-help.png\" width=700>\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv2d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        ") -> Float[Tensor, \"batch out_channels height_padding width_padding\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    b, ic, h, w = x.shape\n",
        "    oc, ic2, kh, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    ow = w - kw + 1\n",
        "    oh = h - kh + 1\n",
        "\n",
        "    s_b, s_ic, s_h, s_w = x.stride()\n",
        "\n",
        "    # Get strided x (the new height/width dims have the same stride as the original height/width-strides of x)\n",
        "    x_new_shape = (b, ic, oh, ow, kh, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_h, s_w, s_h, s_w)\n",
        "\n",
        "    x_strided = x.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic oh ow kh kw, oc ic kh kw -> b oc oh ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9ecETF0jBUT"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbXIYhvujBUT"
      },
      "source": [
        "For a full version of `conv`, and for `maxpool` (which will follow shortly), you'll need to implement `pad` helper functions. PyTorch has some very generic padding functions, but to keep things simple and build up gradually, we'll write 1D and 2D functions individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDcFkEyojBUT"
      },
      "source": [
        "### Exercise - implement padding\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise, and the next.\n",
        "> ```\n",
        "\n",
        "The `pad1d` function applies padding to the width dimension of a 1D tensor, i.e. we pad with `left` entries to the start of the last dimension of `x` and with `right` entries to the end of the last dimension of `x`.\n",
        "\n",
        "Tips:\n",
        "* Use the `new_full` method of the input tensor. This is a clean way to ensure that the output tensor is on the same device as the input, and has the same dtype.\n",
        "* You can use three dots to denote slicing over multiple dimensions. For instance, `x[..., 0]` will take the `0th` slice of `x` along its last dimension. This is equivalent to `x[:, 0]` for 2D, `x[:, :, 0]` for 3D, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAqi59injBUT"
      },
      "outputs": [],
      "source": [
        "def pad1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], left: int, right: int, pad_value: float\n",
        ") -> Float[Tensor, \"batch in_channels width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the edges.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_pad1d(pad1d)\n",
        "tests.test_pad1d_multi_channel(pad1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nb2FBTijBUT"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I get <code>RuntimeError: The expanded size of the tensor (0) must match ...</code></summary>\n",
        "\n",
        "This might be because you've indexed with `left : -right`. Think about what will happen here when `right` is zero.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def pad1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], left: int, right: int, pad_value: float\n",
        ") -> Float[Tensor, \"batch in_channels width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the edges.\"\"\"\n",
        "    B, C, W = x.shape\n",
        "    output = x.new_full(size=(B, C, left + W + right), fill_value=pad_value)\n",
        "    output[..., left : left + W] = x  # note we can't use `left:-right`, because `right` might be zero\n",
        "    return output\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQtx9KDOjBUT"
      },
      "source": [
        "Once you've passed the tests, you can implement the 2D version. The `left` and `right` padding arguments apply to the width dimension, and the `top` and `bottom` padding arguments apply to the height dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVwG4EvvjBUT"
      },
      "outputs": [],
      "source": [
        "def pad2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    left: int,\n",
        "    right: int,\n",
        "    top: int,\n",
        "    bottom: int,\n",
        "    pad_value: float,\n",
        ") -> Float[Tensor, \"batch in_channels height_padding width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the width & height dimensions.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_pad2d(pad2d)\n",
        "tests.test_pad2d_multi_channel(pad2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsNzMIWKjBUT"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def pad2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    left: int,\n",
        "    right: int,\n",
        "    top: int,\n",
        "    bottom: int,\n",
        "    pad_value: float,\n",
        ") -> Float[Tensor, \"batch in_channels height_padding width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the width & height dimensions.\"\"\"\n",
        "    B, C, H, W = x.shape\n",
        "    output = x.new_full(size=(B, C, top + H + bottom, left + W + right), fill_value=pad_value)\n",
        "    output[..., top : top + H, left : left + W] = x\n",
        "    return output\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ywkYQ6ZjBUT"
      },
      "source": [
        "## Full convolutions\n",
        "\n",
        "Now, you'll extend `conv1d` to handle the `stride` and `padding` arguments.\n",
        "\n",
        "`stride` is the number of input positions that the kernel slides at each step. `padding` is the number of zeros concatenated to each side of the input before the convolution.\n",
        "\n",
        "Output shape should be `(batch, output_channels, output_length)`, where output_length can be calculated as follows:\n",
        "\n",
        "$$\n",
        "\\text{output\\_length} = \\left\\lfloor\\frac{\\text{input\\_length} + 2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} \\right\\rfloor + 1\n",
        "$$\n",
        "\n",
        "Verify for yourself that the forumla above simplifies to the formula we used earlier when padding is 0 and stride is 1.\n",
        "\n",
        "Docs for pytorch's `conv1d` can be found [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2E-Io4YjBUT"
      },
      "source": [
        "### Exercise - implement 1D convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm9IJlj8jBUT"
      },
      "outputs": [],
      "source": [
        "def conv1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_width\"],\n",
        "    stride: int = 1,\n",
        "    padding: int = 0,\n",
        ") -> Float[Tensor, \"batch out_channels width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv1d(conv1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBSmgAEjjBUT"
      },
      "source": [
        "<details>\n",
        "<summary>Hint - dealing with padding</summary>\n",
        "\n",
        "As the first line of your function, replace `x` with the padded version of `x`. This way, you won't have to worry about accounting for padding in the rest of the function (e.g. in the formula for the output width).\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint - dealing with strides</summary>\n",
        "\n",
        "The following diagram shows how you should create the strided version of `x` differently, if you have a stride of 2 rather than the default stride of 1.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-help.png\" width=\"850\">\n",
        "\n",
        "Remember, you'll need a new formula for `output_width` (see formula in the  [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html) for help with this, or see if you can derive it without help).\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_width\"],\n",
        "    stride: int = 1,\n",
        "    padding: int = 0,\n",
        ") -> Float[Tensor, \"batch out_channels width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False.\n",
        "    \"\"\"\n",
        "    x_padded = pad1d(x, left=padding, right=padding, pad_value=0)\n",
        "\n",
        "    b, ic, w = x_padded.shape\n",
        "    oc, ic2, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    ow = 1 + (w - kw) // stride\n",
        "    # note, we assume padding is zero in the formula here, because we're working with input which has already been padded\n",
        "\n",
        "    s_b, s_ic, s_w = x_padded.stride()\n",
        "\n",
        "    # Get strided x (the new height/width dims have the same stride as the original height/width-strides of x,\n",
        "    # scaled by the stride (because we're \"skipping over\" x as we slide the kernel over it))\n",
        "    # See diagram in hints for more explanation.\n",
        "    x_new_shape = (b, ic, ow, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_w * stride, s_w)\n",
        "    x_strided = x_padded.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic ow kw, oc ic kw -> b oc ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rfXf1FyjBUT"
      },
      "source": [
        "### Exercise - implement 2D convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "A recurring pattern in these 2d functions is allowing the user to specify either an int or a pair of ints for an argument: examples are stride and padding. We've provided some type aliases and a helper function to simplify working with these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXVQGTOJjBUT"
      },
      "outputs": [],
      "source": [
        "IntOrPair = int | tuple[int, int]\n",
        "Pair = tuple[int, int]\n",
        "\n",
        "\n",
        "def force_pair(v: IntOrPair) -> Pair:\n",
        "    \"\"\"Convert v to a pair of int, if it isn't already.\"\"\"\n",
        "    if isinstance(v, tuple):\n",
        "        if len(v) != 2:\n",
        "            raise ValueError(v)\n",
        "        return (int(v[0]), int(v[1]))\n",
        "    elif isinstance(v, int):\n",
        "        return (v, v)\n",
        "    raise ValueError(v)\n",
        "\n",
        "\n",
        "# Examples of how this function can be used:\n",
        "for v in [(1, 2), 2, (1, 2, 3)]:\n",
        "    try:\n",
        "        print(f\"{v!r:9} -> {force_pair(v)!r}\")\n",
        "    except ValueError:\n",
        "        print(f\"{v!r:9} -> ValueError\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3x9bo6djBUT"
      },
      "source": [
        "Finally, you can implement a full version of `conv2d`. If you've done the full version of `conv1d`, and you've done `conv2d_minimal`, then you should be able to pull code from here to help you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYqsUhU-jBUT"
      },
      "outputs": [],
      "source": [
        "def conv2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        "    stride: IntOrPair = 1,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv2d(conv2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prEMdgDqjBUT"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        "    stride: IntOrPair = 1,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False.\n",
        "    \"\"\"\n",
        "    stride_h, stride_w = force_pair(stride)\n",
        "    padding_h, padding_w = force_pair(padding)\n",
        "\n",
        "    x_padded = pad2d(x, left=padding_w, right=padding_w, top=padding_h, bottom=padding_h, pad_value=0)\n",
        "\n",
        "    b, ic, h, w = x_padded.shape\n",
        "    oc, ic2, kh, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    ow = 1 + (w - kw) // stride_w\n",
        "    oh = 1 + (h - kh) // stride_h\n",
        "\n",
        "    s_b, s_ic, s_h, s_w = x_padded.stride()\n",
        "\n",
        "    # Get strided x (new height/width dims have same stride as original height/width-strides of x, scaled by stride)\n",
        "    x_new_shape = (b, ic, oh, ow, kh, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_h * stride_h, s_w * stride_w, s_h, s_w)\n",
        "    x_strided = x_padded.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic oh ow kh kw, oc ic kh kw -> b oc oh ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiY-d1FKjBUT"
      },
      "source": [
        "## Max pooling\n",
        "\n",
        "We have just one function left now - **max pooling**. You can review the [Medium post](https://medium.com/towards-data-science/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) from earlier to understand max pooling better.\n",
        "\n",
        "A \"max pooling\" layer is similar to a convolution in that you have a window sliding over some number of dimensions. The main difference is that there's no kernel: instead of multiplying by the kernel and adding, you just take the maximum.\n",
        "\n",
        "The way multiple channels work is also different. A convolution has some number of input and output channels, and each output channel is a function of all the input channels. There can be any number of output channels. In a pooling layer, the maximum operation is applied independently for each input channel, meaning the number of output channels is necessarily equal to the number of input channels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zfvV5G2jBUT"
      },
      "source": [
        "### Exercise - implement 2D max pooling\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `maxpool2d` using `torch.as_strided` and `torch.amax` (= max over axes) together. Your version should behave the same as the PyTorch version, but only the indicated arguments need to be supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17pBDSqOjBUT"
      },
      "outputs": [],
      "source": [
        "def maxpool2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    kernel_size: IntOrPair,\n",
        "    stride: IntOrPair | None = None,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like PyTorch's maxpool2d. If stride is None, should be equal to kernel size.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_maxpool2d(maxpool2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0OsLmyvjBUU"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Conceptually, this is similar to `conv2d`.\n",
        "    \n",
        "In `conv2d`, you had to use `as_strided` to turn the 4D tensor `x` into a 6D tensor `x_strided` (adding dimensions over which you would take the convolution), then multiply this tensor by the kernel and sum over these two new dimensions.\n",
        "\n",
        "`maxpool2d` is the same, except that you're simply taking max over those dimensions rather than a dot product with the kernel. So you should find yourself able to reuse a lot of code from your `conv2d` function.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm getting a small number of mismatched elements each time (e.g. between 0 and 5%).</summary>\n",
        "\n",
        "This is likely because you used an incorrect `pad_value`. In the convolution function, we set `pad_value=0` so these values wouldn't have any effect in the linear transformation. What pad value would make our padded elements \"invisible\" when we take the maximum?\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def maxpool2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    kernel_size: IntOrPair,\n",
        "    stride: IntOrPair | None = None,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like PyTorch's maxpool2d. If stride is None, should be equal to kernel size.\n",
        "    \"\"\"\n",
        "    # Set actual values for stride and padding, using force_pair function\n",
        "    if stride is None:\n",
        "        stride = kernel_size\n",
        "    stride_h, stride_w = force_pair(stride)\n",
        "    padding_h, padding_w = force_pair(padding)\n",
        "    kh, kw = force_pair(kernel_size)\n",
        "\n",
        "    # Get padded version of x\n",
        "    x_padded = pad2d(x, left=padding_w, right=padding_w, top=padding_h, bottom=padding_h, pad_value=-t.inf)\n",
        "\n",
        "    # Calculate output height and width for x\n",
        "    b, ic, h, w = x_padded.shape\n",
        "    ow = 1 + (w - kw) // stride_w\n",
        "    oh = 1 + (h - kh) // stride_h\n",
        "\n",
        "    # Get strided x\n",
        "    s_b, s_c, s_h, s_w = x_padded.stride()\n",
        "\n",
        "    x_new_shape = (b, ic, oh, ow, kh, kw)\n",
        "    x_new_stride = (s_b, s_c, s_h * stride_h, s_w * stride_w, s_h, s_w)\n",
        "    x_strided = x_padded.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    # Argmax over dimensions of the maxpool kernel\n",
        "    # (note these are the same dims that we multiply over in 2D convolutions)\n",
        "    return x_strided.amax(dim=(-1, -2))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd1rET04jBUU"
      },
      "source": [
        "Now, you're finished! You can go back to the ResNets exercises, and build your ResNet ***entirely using your own stride-based functions***."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5b7fbf28619435d9bcc7dbabcb904d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34803d116fa349648237375ed3cdece0",
              "IPY_MODEL_2348d3d1dc664563be768f1ecb08aff4",
              "IPY_MODEL_18f3efdad1374ee98e175e302b671a55"
            ],
            "layout": "IPY_MODEL_803f2380903641d998a15831e6cc00f8"
          }
        },
        "34803d116fa349648237375ed3cdece0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc5c751b33304309a5d7720b21e87eb1",
            "placeholder": "​",
            "style": "IPY_MODEL_fd4a65d086e74890937d91593b026872",
            "value": "100%"
          }
        },
        "2348d3d1dc664563be768f1ecb08aff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1b06c76e72440fab828f0901cc2eb4f",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_706ec976f17b4708869455a94b0a319f",
            "value": 6
          }
        },
        "18f3efdad1374ee98e175e302b671a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7390c41849ef489280a9dfeac2213aaa",
            "placeholder": "​",
            "style": "IPY_MODEL_47e6e294860146179d5a67a4c50bf800",
            "value": " 6/6 [00:06&lt;00:00,  1.00s/it, i=5, letter=!, time=6.010]"
          }
        },
        "803f2380903641d998a15831e6cc00f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5c751b33304309a5d7720b21e87eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd4a65d086e74890937d91593b026872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1b06c76e72440fab828f0901cc2eb4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "706ec976f17b4708869455a94b0a319f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7390c41849ef489280a9dfeac2213aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e6e294860146179d5a67a4c50bf800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5112daefd24543389dc3afc4fb3df1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7f7feee2d29400da204a03191f93a0c",
              "IPY_MODEL_f8043ee4b90544eeb85ae92a7f73a900",
              "IPY_MODEL_1e0027b45da2417fb8eca99b57e254e3"
            ],
            "layout": "IPY_MODEL_3bcec62be1e349a18ac33e5f38be85c0"
          }
        },
        "e7f7feee2d29400da204a03191f93a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca90ed4dcf0140ae9f0926d291bde5a1",
            "placeholder": "​",
            "style": "IPY_MODEL_3f4dde5dc1fb4e77b4fd895f59505377",
            "value": "100%"
          }
        },
        "f8043ee4b90544eeb85ae92a7f73a900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219b1c9f59434430b4f8cff57d49c8c6",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cce3256a17d48dc9c012f4591bbd24c",
            "value": 79
          }
        },
        "1e0027b45da2417fb8eca99b57e254e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5d9d365756b4ec39b148fd7fd568d7a",
            "placeholder": "​",
            "style": "IPY_MODEL_6a769a7d9fd2451d886ce0bb4876604a",
            "value": " 79/79 [00:04&lt;00:00, 29.76it/s, epoch=1/3, loss=0.552]"
          }
        },
        "3bcec62be1e349a18ac33e5f38be85c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca90ed4dcf0140ae9f0926d291bde5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f4dde5dc1fb4e77b4fd895f59505377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "219b1c9f59434430b4f8cff57d49c8c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cce3256a17d48dc9c012f4591bbd24c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5d9d365756b4ec39b148fd7fd568d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a769a7d9fd2451d886ce0bb4876604a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edf0a3235d17423fb311df540fbd49ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c7b82d910e243bcbccf1447f3c07156",
              "IPY_MODEL_2f941c123af24d33bfc0db450405320d",
              "IPY_MODEL_f49193d1bef247fa98e31b7348ec0399"
            ],
            "layout": "IPY_MODEL_ae7bf005a1fc4082948ce336455317a8"
          }
        },
        "7c7b82d910e243bcbccf1447f3c07156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db9b0d87a34f4995910daa77e93cbdd6",
            "placeholder": "​",
            "style": "IPY_MODEL_e05ae5faaa4d453da5866be06126f59e",
            "value": "100%"
          }
        },
        "2f941c123af24d33bfc0db450405320d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98cd4f3ae37844ff9b2aa299b78c3637",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c8a02f96798418a95e70c5141912c09",
            "value": 79
          }
        },
        "f49193d1bef247fa98e31b7348ec0399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90ca6e8b91084595a875dc08835d2dbd",
            "placeholder": "​",
            "style": "IPY_MODEL_d22ba470df344a2e87717f68c83f8727",
            "value": " 79/79 [00:02&lt;00:00, 27.64it/s, epoch=2/3, loss=0.138]"
          }
        },
        "ae7bf005a1fc4082948ce336455317a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db9b0d87a34f4995910daa77e93cbdd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05ae5faaa4d453da5866be06126f59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98cd4f3ae37844ff9b2aa299b78c3637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c8a02f96798418a95e70c5141912c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90ca6e8b91084595a875dc08835d2dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22ba470df344a2e87717f68c83f8727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07dab8cca5c346c180a6df0da4e27c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40ffa7641c8e433ca63acdee7262018e",
              "IPY_MODEL_879aaf6eea614ce59d04ee592c124532",
              "IPY_MODEL_3c904e6d821e4e5995a2503f732bbbbb"
            ],
            "layout": "IPY_MODEL_d2b1bea5d48b4fc487084c79e152af2c"
          }
        },
        "40ffa7641c8e433ca63acdee7262018e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9cb617eba934b8c906fa852d39c4197",
            "placeholder": "​",
            "style": "IPY_MODEL_0308028381de467da056c15d4b77c926",
            "value": "100%"
          }
        },
        "879aaf6eea614ce59d04ee592c124532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5502d5c16fa14e499710d7c41b388c26",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d07d041f846546afaecb20d06515262b",
            "value": 79
          }
        },
        "3c904e6d821e4e5995a2503f732bbbbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29d5cf65a5b840f5b584387ec660bebe",
            "placeholder": "​",
            "style": "IPY_MODEL_b321abf3bcdb48f1b4626e6151609a5e",
            "value": " 79/79 [00:02&lt;00:00, 32.64it/s, epoch=3/3, loss=0.365]"
          }
        },
        "d2b1bea5d48b4fc487084c79e152af2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9cb617eba934b8c906fa852d39c4197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0308028381de467da056c15d4b77c926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5502d5c16fa14e499710d7c41b388c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d07d041f846546afaecb20d06515262b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29d5cf65a5b840f5b584387ec660bebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b321abf3bcdb48f1b4626e6151609a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b38b3fae2f54652a7c703f49470a8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f535714ebb9464d9cc6990f0c60d238",
              "IPY_MODEL_5a9c5458c7be4ce28b8eec194f2966d5",
              "IPY_MODEL_2d00aa6729d143afbdf074590cca9848"
            ],
            "layout": "IPY_MODEL_97f5ebf3cc414449bb5f858d282b2984"
          }
        },
        "0f535714ebb9464d9cc6990f0c60d238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_591dae181ebb46459f927b7997cdfcff",
            "placeholder": "​",
            "style": "IPY_MODEL_63d275a5af9c4c288381bd47da9b407e",
            "value": "100%"
          }
        },
        "5a9c5458c7be4ce28b8eec194f2966d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea5e11fabad4aacb6071b487459237f",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12eabe16d264417aa5d70fd1bf8ac5aa",
            "value": 157
          }
        },
        "2d00aa6729d143afbdf074590cca9848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6f27f3907624673a54bf7f19049efd8",
            "placeholder": "​",
            "style": "IPY_MODEL_c515d6ca91fa4a65a1a4a5b8a623eb40",
            "value": " 157/157 [00:02&lt;00:00, 53.90it/s, epoch=1/3, loss=0.183]"
          }
        },
        "97f5ebf3cc414449bb5f858d282b2984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "591dae181ebb46459f927b7997cdfcff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d275a5af9c4c288381bd47da9b407e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ea5e11fabad4aacb6071b487459237f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12eabe16d264417aa5d70fd1bf8ac5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6f27f3907624673a54bf7f19049efd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c515d6ca91fa4a65a1a4a5b8a623eb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2debff0803204027bff3c57eb38d8f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79ca56223d9d4eaba484a80673038b42",
              "IPY_MODEL_fa88248ca696491ba23cdba48139a251",
              "IPY_MODEL_8f2448256cfd491ebc28784b40f06866"
            ],
            "layout": "IPY_MODEL_5144345cbf15422d86d321e9dee6c4e1"
          }
        },
        "79ca56223d9d4eaba484a80673038b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78965ab5dade4ee7adab76a9434da30c",
            "placeholder": "​",
            "style": "IPY_MODEL_570da9e26b2b495a9c7730bdc51421e3",
            "value": "100%"
          }
        },
        "fa88248ca696491ba23cdba48139a251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0810ab1db0a44d1b2376e2cb5761dcb",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de5027064b704c01adb1971603793531",
            "value": 157
          }
        },
        "8f2448256cfd491ebc28784b40f06866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db3f3aca813405686a5b788a9025620",
            "placeholder": "​",
            "style": "IPY_MODEL_2ff76fe9988a4bb4ae448e4f150f3048",
            "value": " 157/157 [00:02&lt;00:00, 52.78it/s, epoch=2/3, loss=0.274]"
          }
        },
        "5144345cbf15422d86d321e9dee6c4e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78965ab5dade4ee7adab76a9434da30c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570da9e26b2b495a9c7730bdc51421e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0810ab1db0a44d1b2376e2cb5761dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de5027064b704c01adb1971603793531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4db3f3aca813405686a5b788a9025620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff76fe9988a4bb4ae448e4f150f3048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9654d83d4e6641f9b701e26deedc49e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_134a1d2cc29c4c8b92ef7d7a4baaf8f6",
              "IPY_MODEL_5d089a36f60f406faa8319d17d334451",
              "IPY_MODEL_f9840bf9ea5e4735b1368d7527f8ac6a"
            ],
            "layout": "IPY_MODEL_525ed5c645a84937bb6fdf74f0b46393"
          }
        },
        "134a1d2cc29c4c8b92ef7d7a4baaf8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b137652c8626431cacf32b8aedf11b5a",
            "placeholder": "​",
            "style": "IPY_MODEL_e7a1dc53602b4d3fbcd4947d83308677",
            "value": "100%"
          }
        },
        "5d089a36f60f406faa8319d17d334451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4fee3f17874ff1850dcca4d9ef060d",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f4de19481a148f984a2fa89d4b70603",
            "value": 157
          }
        },
        "f9840bf9ea5e4735b1368d7527f8ac6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e9f53a627f8482db87b132fd0efcb3c",
            "placeholder": "​",
            "style": "IPY_MODEL_ec445910df0d441689f36d6a244fbd11",
            "value": " 157/157 [00:02&lt;00:00, 51.04it/s, epoch=3/3, loss=0.104]"
          }
        },
        "525ed5c645a84937bb6fdf74f0b46393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b137652c8626431cacf32b8aedf11b5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a1dc53602b4d3fbcd4947d83308677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de4fee3f17874ff1850dcca4d9ef060d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4de19481a148f984a2fa89d4b70603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e9f53a627f8482db87b132fd0efcb3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec445910df0d441689f36d6a244fbd11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f58fe3314854471db7278d95a76e721a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51d6e74fbdbe472f8649d06f04c5e784",
              "IPY_MODEL_9c8b382c1517407eb521cf5b1b159e56",
              "IPY_MODEL_b9c49f2e93ce45198f95c4218f15d283"
            ],
            "layout": "IPY_MODEL_c4c0c6fe49e6406eaa3eead1dae65b83"
          }
        },
        "51d6e74fbdbe472f8649d06f04c5e784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8738c061e2a4193867113e812c4947f",
            "placeholder": "​",
            "style": "IPY_MODEL_97ba1fec96814367affa199bba528174",
            "value": "  0%"
          }
        },
        "9c8b382c1517407eb521cf5b1b159e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17dd6fffddcb42b190363655d27dd507",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa39c26a08bb4d0ab6d2733c1de7f1d3",
            "value": 0
          }
        },
        "b9c49f2e93ce45198f95c4218f15d283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b726cbd76e149478cbf9862e7e7460e",
            "placeholder": "​",
            "style": "IPY_MODEL_b691a363e9ee44aca69a6d441ed22226",
            "value": " 0/157 [00:03&lt;?, ?it/s]"
          }
        },
        "c4c0c6fe49e6406eaa3eead1dae65b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8738c061e2a4193867113e812c4947f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ba1fec96814367affa199bba528174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17dd6fffddcb42b190363655d27dd507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa39c26a08bb4d0ab6d2733c1de7f1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b726cbd76e149478cbf9862e7e7460e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b691a363e9ee44aca69a6d441ed22226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50a2da2f02ef42ae9d8c40dc9e381685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12027d4027a04a3389b5c5c0be2b998c",
              "IPY_MODEL_f7e5d1a5dce645a1820c5abd61dd392a",
              "IPY_MODEL_bfdb353281e34fefae43eb03d7315c1f"
            ],
            "layout": "IPY_MODEL_0665b7343ed34e42bdf31e11d5d3d615"
          }
        },
        "12027d4027a04a3389b5c5c0be2b998c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_203cbe3f70cf4e8db4430ff1661122ea",
            "placeholder": "​",
            "style": "IPY_MODEL_35a045ecfa494907a24a708d4d93306f",
            "value": "  0%"
          }
        },
        "f7e5d1a5dce645a1820c5abd61dd392a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8469e99a99dd4f37beb8cdf3c4f0e8a8",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6edc847aab7d497b94d16f114dbf269b",
            "value": 0
          }
        },
        "bfdb353281e34fefae43eb03d7315c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78245a0f5a624778944a36f010979056",
            "placeholder": "​",
            "style": "IPY_MODEL_637f3ab4b3d1480591543fde6c3a5b93",
            "value": " 0/157 [00:05&lt;?, ?it/s]"
          }
        },
        "0665b7343ed34e42bdf31e11d5d3d615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "203cbe3f70cf4e8db4430ff1661122ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a045ecfa494907a24a708d4d93306f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8469e99a99dd4f37beb8cdf3c4f0e8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6edc847aab7d497b94d16f114dbf269b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78245a0f5a624778944a36f010979056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "637f3ab4b3d1480591543fde6c3a5b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "826e171b8de24ae28ae08f07284cff68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b38d4a570e34ea88f6b96377cae3499",
              "IPY_MODEL_6352d3fc81754747ba0dc557bf5bc3a9",
              "IPY_MODEL_401051a3f83e43c6b96cb11e370c7a12"
            ],
            "layout": "IPY_MODEL_b7c10368a74a40e0937ff10df97798cf"
          }
        },
        "8b38d4a570e34ea88f6b96377cae3499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b2cbf8a16fc41f7b5a87609fe2149d6",
            "placeholder": "​",
            "style": "IPY_MODEL_75dfd3d784fd4a028b21d3ea30dacbf3",
            "value": "  0%"
          }
        },
        "6352d3fc81754747ba0dc557bf5bc3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d06be3dc4c764701beddc338074c6e63",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8f54e31a750473491485ae8918b20df",
            "value": 0
          }
        },
        "401051a3f83e43c6b96cb11e370c7a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a070e145f9eb4f79b1e1949ca2baff06",
            "placeholder": "​",
            "style": "IPY_MODEL_17a8bf7aa2b24666941d8377e8fa92e8",
            "value": " 0/157 [00:02&lt;?, ?it/s]"
          }
        },
        "b7c10368a74a40e0937ff10df97798cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b2cbf8a16fc41f7b5a87609fe2149d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75dfd3d784fd4a028b21d3ea30dacbf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d06be3dc4c764701beddc338074c6e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f54e31a750473491485ae8918b20df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a070e145f9eb4f79b1e1949ca2baff06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a8bf7aa2b24666941d8377e8fa92e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}