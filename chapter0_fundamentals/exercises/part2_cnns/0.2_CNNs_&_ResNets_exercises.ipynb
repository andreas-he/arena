{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_iswa50jBUB"
      },
      "source": [
        "# [0.2] - CNNs & ResNets (exercises)\n",
        "\n",
        "> **ARENA [Streamlit Page](https://arena-chapter0-fundamentals.streamlit.app/02_[0.2]_CNNs_&_ResNets)**\n",
        ">\n",
        "> **Colab: [exercises](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_exercises.ipynb?t=20250316) | [solutions](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_solutions.ipynb?t=20250316)**\n",
        "\n",
        "Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-2zick19fl-6GY1yoGaoUozyM3wObwmnQ), and ask any questions on the dedicated channels for this chapter of material.\n",
        "\n",
        "You can collapse each section so only the headers are visible, by clicking the arrow symbol on the left hand side of the markdown header cells.\n",
        "\n",
        "Links to all other chapters: [(0) Fundamentals](https://arena-chapter0-fundamentals.streamlit.app/), [(1) Transformer Interpretability](https://arena-chapter1-transformer-interp.streamlit.app/), [(2) RL](https://arena-chapter2-rl.streamlit.app/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KReTy3YXjBUD"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/headers/header-02.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjDs7AnnjBUD"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IteXpvwkjBUE"
      },
      "source": [
        "This section is designed to get you familiar with basic neural networks: how they are structured, the basic operations like linear layers and convolutions which go into making them, and why they work as well as they do. You'll start by making very simple neural networks, and by the end of today you'll build up to assembling ResNet34, a comparatively much more complicated architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ56L21GjBUE"
      },
      "source": [
        "## Content & Learning Objectives\n",
        "\n",
        "### 1️⃣ Making your own modules\n",
        "\n",
        "In the first set of exercises, we'll cover the general structure of modules in PyTorch. You'll also implement your own basic modules, including for ReLU and Linear layers. You'll finish by assembling a very simple neural network.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn how to create your own modules in PyTorch, by inheriting from `nn.Module`\n",
        "> - Assemble the pieces together to create a simple fully-connected network, to classify MNIST digits\n",
        "\n",
        "### 2️⃣ Training Neural Networks\n",
        "\n",
        "Here, you'll learn how to write a training loop in PyTorch. We'll keep it simple for today (and later on we'll experiment with more modular and extensible designs).\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand how to work with transforms, datasets and dataloaders\n",
        "> - Understand the basic structure of a training loop\n",
        "> - Learn how to write your own validation loop\n",
        "\n",
        "### 3️⃣ Convolutions\n",
        "\n",
        "In this section, you'll read about convolutions, and implement them as an `nn.Module` (not from scratch; we leave that to the bonus exercises). You'll also learn about maxpooling, and implement that as well.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn how convolutions work, and why they are useful for vision models\n",
        "> * Implement your own convolutions, and maxpooling layers\n",
        "\n",
        "### 4️⃣ ResNets\n",
        "\n",
        "Here, you'll combine all the pieces you've learned so far to assemble ResNet34, a much more complex architecture used for image classification.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn about skip connections, and how they help overcome the degradation problem\n",
        "> * Learn about batch normalization, and why it is used in training\n",
        "> * Assemble your own ResNet, and load in weights from PyTorch's ResNet implementation\n",
        "\n",
        "### ☆ Bonus - Feature Extraction\n",
        "\n",
        "In this section, you'll learn how to repurpose your ResNet to perform a different task than it was designed for, using feature extraction.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand the difference between feature extraction and finetuning\n",
        "> * Perform feature extraction on a pre-trained ResNet\n",
        "\n",
        "### ☆ Bonus - Convolutions From Scratch\n",
        "\n",
        "This section takes you through the low-level details of how to actually implement convolutions. It's not necessary to understand this section to complete the exercises, but it's a good way to get a deeper understanding of how convolutions work.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand how array strides work, and why they're important for efficient linear operations\n",
        "> * Learn how to use `as_strided` to perform simple linear operations like trace and matrix multiplication\n",
        "> * Implement your own convolutions and maxpooling functions using stride-based methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xpzt7ZBjBUE"
      },
      "source": [
        "## Setup code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3SaGqsSjBUE",
        "outputId": "83163de9-d4c6-4ef8-f458-a606e7bbee50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.3.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping)\n",
            "  Downloading wadler_lindig-0.1.4-py3-none-any.whl.metadata (17 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading jaxtyping-0.3.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.4-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, torchinfo, jaxtyping\n",
            "Successfully installed jaxtyping-0.3.1 torchinfo-1.8.0 wadler-lindig-0.1.4\n",
            "--2025-04-10 18:50:27--  https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main [following]\n",
            "--2025-04-10 18:50:28--  https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 20.205.243.165\n",
            "Connecting to codeload.github.com (codeload.github.com)|20.205.243.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/content/main.zip’\n",
            "\n",
            "main.zip                [         <=>        ]  21.08M  9.06MB/s    in 2.3s    \n",
            "\n",
            "2025-04-10 18:50:30 (9.06 MB/s) - ‘/content/main.zip’ saved [22109910]\n",
            "\n",
            "Archive:  /content/main.zip\n",
            "c17a514d83a19a404b9f041821fc05c491461012\n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/\n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/0.0_Prerequisites_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/0.0_Prerequisites_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/numbers.npy  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/0.1_Ray_Tracing_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/0.1_Ray_Tracing_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/pikachu.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/pikachu.stl  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/test_with_pytest.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/imagenet_labels.json  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/astronaut.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/chimpanzee.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/dragonfly.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/fireworks.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/frogs.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/golden_retriever.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/goofy.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/hourglass.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/iguana.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/platypus.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/volcano.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/0.3_Optimization_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/0.3_Optimization_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/0.4_Backprop_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/0.4_Backprop_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/utils.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/plotly_utils.py  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "repo = \"ARENA_3.0\"\n",
        "branch = \"main\"\n",
        "\n",
        "# Install dependencies\n",
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    %pip install torchinfo jaxtyping\n",
        "\n",
        "# Get root directory, handling 3 different cases: (1) Colab, (2) notebook not in ARENA repo, (3) notebook in ARENA repo\n",
        "root = (\n",
        "    \"/content\"\n",
        "    if IN_COLAB\n",
        "    else \"/root\"\n",
        "    if repo not in os.getcwd()\n",
        "    else str(next(p for p in Path.cwd().parents if p.name == repo))\n",
        ")\n",
        "\n",
        "if Path(root).exists() and not Path(f\"{root}/{chapter}\").exists():\n",
        "    if not IN_COLAB:\n",
        "        !sudo apt-get install unzip\n",
        "        %pip install jupyter ipython --upgrade\n",
        "\n",
        "    if not os.path.exists(f\"{root}/{chapter}\"):\n",
        "        !wget -P {root} https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/{branch}.zip\n",
        "        !unzip {root}/{branch}.zip '{repo}-{branch}/{chapter}/exercises/*' -d {root}\n",
        "        !mv {root}/{repo}-{branch}/{chapter} {root}/{chapter}\n",
        "        !rm {root}/{branch}.zip\n",
        "        !rmdir {root}/{repo}-{branch}\n",
        "\n",
        "\n",
        "if f\"{root}/{chapter}/exercises\" not in sys.path:\n",
        "    sys.path.append(f\"{root}/{chapter}/exercises\")\n",
        "\n",
        "os.chdir(f\"{root}/{chapter}/exercises\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J760KjlEjBUF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "from collections import namedtuple\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import einops\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchinfo\n",
        "from IPython.display import display\n",
        "from jaxtyping import Float, Int\n",
        "from PIL import Image\n",
        "from rich import print as rprint\n",
        "from rich.table import Table\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Make sure exercises are in the path\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "section = \"part2_cnns\"\n",
        "root_dir = next(p for p in Path.cwd().parents if (p / chapter).exists())\n",
        "exercises_dir = root_dir / chapter / \"exercises\"\n",
        "section_dir = exercises_dir / section\n",
        "if str(exercises_dir) not in sys.path:\n",
        "    sys.path.append(str(exercises_dir))\n",
        "\n",
        "\n",
        "import part2_cnns.tests as tests\n",
        "import part2_cnns.utils as utils\n",
        "from plotly_utils import line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt1-bUz3jBUF"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I get a NumPy-related error</summary>\n",
        "\n",
        "This is an annoying colab-related issue which I haven't been able to find a satisfying fix for. If you restart runtime (but don't delete runtime), and run just the imports cell above again (but not the `%pip install` cell), the problem should go away.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlzN3uFYjBUF"
      },
      "source": [
        "# 1️⃣ Making your own modules\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn how to create your own modules in PyTorch, by inheriting from `nn.Module`\n",
        "> - Assemble the pieces together to create a simple fully-connected network, to classify MNIST digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amANK1ZwjBUF"
      },
      "source": [
        "Note - from this point on we'll start referring to the PyTorch documentation pages quite a lot. We will also include a lot of content within this material if we want to highlight it for you, however it's also an important skill to be able to use documentation pages to find answers to specific questions & assist you in debugging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u7TDJr8jBUF"
      },
      "source": [
        "## Subclassing `nn.Module`\n",
        "\n",
        "One of the most basic parts of PyTorch that you will see over and over is the `nn.Module` class. All types of neural net components inherit from it, from the simplest `nn.Relu` to the most complex `nn.Transformer`. Often, a complex `nn.Module` will have sub-`Module`s which implement smaller pieces of its functionality.\n",
        "\n",
        "Other common `Module`s  you'll see include\n",
        "\n",
        "- `nn.Linear`, for fully-connected layers with or without a bias\n",
        "- `nn.Conv2d`, for a two-dimensional convolution (we'll see more of these in a future section)\n",
        "- `nn.Softmax`, which implements the [softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) function\n",
        "\n",
        "The list goes on, including activation functions, normalizations, pooling, attention, and more. You can see all the `Module`s that PyTorch provides [here](https://pytorch.org/docs/stable/nn.html). You can also create your own `Module`s, as we will do often!\n",
        "\n",
        "The `Module` class provides a lot of functionality, but we'll only cover a little bit of it here.\n",
        "\n",
        "In this section, we'll add another layer of abstraction to all the linear operations we've done in previous sections, by packaging them inside `nn.Module` objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd35tEeHjBUF"
      },
      "source": [
        "### `__init__` and `forward`\n",
        "\n",
        "A subclass of `nn.Module` usually looks something like this:\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, arg1, arg2, ...):\n",
        "        super().__init__()\n",
        "        # Initialization code\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        # Forward pass code\n",
        "```\n",
        "\n",
        "The initialization sets up attributes that will be used for the life of the `Module`, like its parameters, hyperparameters, or other sub-`Module`s it might need to use. These are usually added to the instance with something like `self.attribute = attr`, where `attr` might be provided as an argument. Some modules are simple enough that they don't need any persistent attributes, and in this case you can skip the `__init__`.\n",
        "\n",
        "The `forward` method is called on each forward pass of the `Module`, possibly using the attributes that were set up in the `__init__`. It should take in the input, do whatever it's supposed to do, and return the result. Subclassing `nn.Module` automatically makes instances of your class callable, so you can do `model(x)` on an input `x` to invoke the `forward` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR3NHdlijBUF"
      },
      "source": [
        "### The `nn.Parameter` class\n",
        "\n",
        "A `nn.Parameter` is a special type of `Tensor`. Basically, this is the class that torch has provided for storing the weights and biases of a `Module`. It has some special properties for doing this:\n",
        "\n",
        "- If a `Parameter` is set as an attribute of a `Module`, it will be auto-detected by torch and returned when you call `module.parameters()` (along with all the other `Parameters` associated with the `Module`, or any of the `Module`'s sub-modules!).\n",
        "- This makes it easy to pass all the parameters of a model into an optimizer and update them all at once.\n",
        "\n",
        "When you create a `Module` that has weights or biases, be sure to wrap them in `nn.Parameter` so that torch can detect and update them appropriately:\n",
        "\n",
        "```python\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, weights: t.Tensor, biases: t.Tensor):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(weights) # wrapping a tensor in nn.Parameter\n",
        "        self.biases = nn.Parameter(biases)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygSJWmByjBUF"
      },
      "source": [
        "### Printing information with `extra_repr`\n",
        "\n",
        "Another useful method is called `extra_repr`. This allows you to format the string representation of your `Module` in a way that's more informative than the default. For example, the following:\n",
        "\n",
        "```python\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, arg1, arg2, ...):\n",
        "        super().__init__()\n",
        "        # Initialization code\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"arg1={self.arg1}, arg2={self.arg2}, ...\"\n",
        "```\n",
        "\n",
        "will result in the output `\"MyModule(arg1=arg1, arg2=arg2, ...)\"` when you print an instance of this module. You might want to take this opportunity to print out useful invariant information about the module. The Python built-in function `getattr` might be helpful here (it can be used e.g. as `getattr(self, \"arg1\")`, which returns the same as `self.arg1` would). For simple modules, it's fine not to implement `extra_repr`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Tq7dwBjBUF"
      },
      "source": [
        "## ReLU\n",
        "\n",
        "The first module you should implement is `ReLU`. This will relatively simple, since it doesn't involve any argument (so we only need to implement `forward`). Make sure you look at the PyTorch documentation page for [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) so that you're comfortable with how they work.\n",
        "\n",
        "ReLU is defined as the element-wise maximum between the input and a tensor of zeros. It's one of the simplest types of **nonlinear activation functions**. These are essential because linear operations compose to make more linear operations, which is very limiting. On the other hand, the **universal approximation theorem** tells us that we can approximate any continuous function using a sufficiently large neural network, if we use nonlinear activation functions. It's worth emphasizing that the theory of the UAT and what networks look like in practice are very different - in particular, many versions of the UAT are based on a shallow but extremely wide neural network, on the other hand most of the power of modern neural networks comes from their ability to compose between layers: feeding the output of one layer into the input of another, and create increasingly expressive functions. We'll explore this idea more when we study circuits in next week's interpretability material."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmarEv11jBUF"
      },
      "source": [
        "### Exercise - implement `ReLU`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should fill in the `forward` method of the `ReLU` class below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9sfqUqfjBUF",
        "outputId": "08cdd873-3ac5-4425-d80c-88ba262fdf65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.2400, -1.7748, -0.3785, -1.3589, -0.6364,  0.2321, -0.2603, -0.4081,\n",
            "         0.0577,  0.4146])\n",
            "All tests in `test_relu` passed!\n"
          ]
        }
      ],
      "source": [
        "class ReLU(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "      print(x)\n",
        "      return t.max(t.tensor(0.0), x)\n",
        "\n",
        "\n",
        "tests.test_relu(ReLU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHxhtlaRjBUF"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ReLU(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return t.maximum(x, t.tensor(0.0))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNQObgqGjBUF"
      },
      "source": [
        "## Linear\n",
        "\n",
        "Now implement your own `Linear` module. This applies a simple linear transformation, with a weight matrix and optional bias vector. The PyTorch documentation page is [here](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html). Note that this is the first `Module` you'll implement that has learnable weights and biases.\n",
        "\n",
        "<details>\n",
        "<summary>Question - what type do you think these variables should be?</summary>\n",
        "\n",
        "They have to be `torch.Tensor` objects wrapped in `nn.Parameter` in order for `nn.Module` to recognize them. If you forget to do this, `module.parameters()` won't include your `Parameter`, which prevents an optimizer from being able to modify it during training.\n",
        "        \n",
        "Also, in tomorrow's exercises we'll be building a ResNet and loading in weights from a pretrained model, and this is hard to do if you haven't registered all your parameters!\n",
        "</details>\n",
        "\n",
        "For any layer, initialization is very important for the stability of training: with a bad initialization, your model will take much longer to converge or may completely fail to learn anything. The default PyTorch behavior isn't necessarily optimal and you can often improve performance by using something more custom, but we'll follow it for today because it's simple and works decently well.\n",
        "\n",
        "Each float in the weight and bias tensors are drawn independently from the uniform distribution on the interval:\n",
        "\n",
        "$$\n",
        "\\bigg[-\\frac{1}{\\sqrt{N_{in}}}, \\frac{1}{\\sqrt{N_{in}}}\\bigg]\n",
        "$$\n",
        "\n",
        "where $N_{in}$ is the number of inputs contributing to each output value. The rough intuition for this is that it keeps the variance of the activations at each layer constant, since each one is calculated by taking the sum over $N_{in}$ inputs multiplied by the weights (and standard deviation of the sum of independent random variables scales as the square root of number of variables).\n",
        "\n",
        "This initialization technique is called **uniform Kaiming initialization**. A few last notes on initialization methods:\n",
        "\n",
        "- Kaiming often has a different constant in the numerator depending on what the target variance is, also there are uniform & normal variants of it (we'll only be using the uniform variant)\n",
        "- **Xavier initialization** is the other well-known technique, and differs in that it uses $N_{in} + N_{out}$ in the denominator (this makes sense when also considering variance scaling of backward passes as well as forward passes - see the next dropdown for technical details)\n",
        "\n",
        "<details>\n",
        "<summary>Technical details (derivation of distribution)</summary>\n",
        "\n",
        "The key intuition behind Kaiming initialisation (and others like it) is that we want the variance of our activations to be the same through all layers of the model when we initialize. Suppose $x$ and $y$ are activations from two adjacent layers, and $w$ are the weights connecting them (so we have $y_i = \\sum_j w_{ij} x_j + b_i$, where $b$ is the bias). With $N_{x}$ as the number of neurons in layer $x$, we have:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\operatorname{Var}\\left(y_i\\right)=\\sigma_x^2 & =\\operatorname{Var}\\left(\\sum_j w_{i j} x_j\\right) \\\\\n",
        "& =\\sum_j \\operatorname{Var}\\left(w_{i j} x_j\\right) \\quad \\text { Inputs and weights are independent of each other } \\\\\n",
        "& =\\sum_j \\operatorname{Var}\\left(w_{i j}\\right) \\cdot \\operatorname{Var}\\left(x_j\\right) \\quad \\text { Variance of product of independent RVs with zero mean is product of variances } \\\\\n",
        "& = N_x \\cdot \\sigma_x^2 \\cdot \\operatorname{Var}\\left(w_{i j}\\right) \\quad \\text { Variance equal for all } N_x \\text { neurons, call this value } \\sigma_x^2\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "For this to be the same as $\\sigma_x^2$, we need $\\operatorname{Var}(w_{ij}) = \\frac{1}{N_x}$, so the standard deviation is $\\frac{1}{\\sqrt{N_x}}$.\n",
        "\n",
        "This is not exactly the case for the Kaiming uniform distribution (which has variance $\\frac{12}{(2 \\sqrt{N_x})^2} = \\frac{3}{N_x}$), and as far as I'm aware there's no principled reason why PyTorch does this. But the most important thing is that the variance scales as $O(1 / N_x)$, rather than what the exact scaling constant is.\n",
        "\n",
        "There are other initializations with some theoretical justification. For instance, **Xavier initialization** has a uniform distribution in the interval:\n",
        "\n",
        "$$\n",
        "\\bigg[-\\frac{\\sqrt{6}}{\\sqrt{N_{in} + N_{out} + 1}}, \\frac{\\sqrt{6}}{\\sqrt{N_{in} + N_{out} + 1}}\\bigg]\n",
        "$$\n",
        "\n",
        "which is motivated by the idea of both keeping the variance of activations constant and keeping the ***gradients*** constant when we backpropagate.\n",
        "\n",
        "However, you don't need to worry about any of this here, just implement Kaiming He uniform with a bound of $\\frac{1}{\\sqrt{N_{in}}}$!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sayc08FRjBUG"
      },
      "source": [
        "### Exercise - implement `Linear`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Remember, you should define the weights (and bias, if `bias=True`) in the `__init__` block. Also, make sure not to mix up `bias` (which is the boolean parameter to `__init__`) and `self.bias` (which should either be the actual bias tensor, or `None` if `bias` is false).\n",
        "\n",
        "You should also fill in `forward` (which will multiply the input by the weight matrix and add the bias, if present).\n",
        "\n",
        "Lastly, you should fill in `extra_repr` to give a string representation of the `Linear` module. There are no tests for this method, you should just make sure it's suitably informative (this will help when printing out your model later on)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_XQjEHcjBUG",
        "outputId": "b8a8544c-662a-4670-ff16-44b3128ca8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_linear_parameters` passed!\n",
            "All tests in `test_linear_parameters` passed!\n",
            "All tests in `test_linear_forward` passed!\n",
            "All tests in `test_linear_forward` passed!\n"
          ]
        }
      ],
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
        "        \"\"\"\n",
        "        A simple linear (technically, affine) transformation.\n",
        "\n",
        "        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n",
        "        If `bias` is False, set `self.bias` to None.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.bias = bias\n",
        "        self.weight = nn.Parameter(nn.init.kaiming_uniform_(t.empty(out_features, in_features)))\n",
        "        if bias:\n",
        "          self.bias = nn.Parameter(t.zeros(out_features))\n",
        "        else:\n",
        "          self.bias = None\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (*, in_features)\n",
        "        Return: shape (*, out_features)\n",
        "        \"\"\"\n",
        "        x = einops.einsum(x, self.weight, 'batch input, output input -> batch output')\n",
        "        if self.bias is not None:\n",
        "            x += self.bias  # Add the bias if it exists\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"input_shape={self.in_features}, output_shape={self.out_features}\"\n",
        "\n",
        "\n",
        "tests.test_linear_parameters(Linear, bias=False)\n",
        "tests.test_linear_parameters(Linear, bias=True)\n",
        "tests.test_linear_forward(Linear, bias=False)\n",
        "tests.test_linear_forward(Linear, bias=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTo8VirAjBUG"
      },
      "source": [
        "<details>\n",
        "<summary>Help - when I print my Linear module, it also prints a large tensor.</summary>\n",
        "\n",
        "This is because you've (correctly) defined `self.bias` as either `torch.Tensor` or `None`, rather than set it to the boolean value of `bias` used in initialisation.\n",
        "        \n",
        "To fix this, you will need to change `extra_repr` so that it prints the boolean value of `bias` rather than the value of `self.bias`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
        "        \"\"\"\n",
        "        A simple linear (technically, affine) transformation.\n",
        "\n",
        "        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n",
        "        If `bias` is False, set `self.bias` to None.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.bias = bias\n",
        "\n",
        "        sf = 1 / np.sqrt(in_features)\n",
        "\n",
        "        weight = sf * (2 * t.rand(out_features, in_features) - 1)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "\n",
        "        if bias:\n",
        "            bias = sf * (2 * t.rand(out_features) - 1)\n",
        "            self.bias = nn.Parameter(bias)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (*, in_features)\n",
        "        Return: shape (*, out_features)\n",
        "        \"\"\"\n",
        "        x = einops.einsum(x, self.weight, \"... in_feats, out_feats in_feats -> ... out_feats\")\n",
        "        if self.bias is not None:\n",
        "            x += self.bias\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        # note, we need to use `self.bias is not None`, because `self.bias` is either a tensor or None, not bool\n",
        "        return f\"in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}\"\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GmLM-WkjBUG"
      },
      "source": [
        "## Flatten\n",
        "\n",
        "Lastly, we've given you the `Flatten` module rather than including it as an exercise (because it's simple but quite finnicky to implement). This is a standardised way to rearrange our tensors so that they can be fed into a linear layer. It's a bit like `einops.rearrange`, but more specialised and less flexible (it flattens over some contiguous range of dimensions, rather than allowing for general reshape operations). By default we use `Flatten(start_dim=1, end_dim=-1)` which means flattening over the dimensions from `input.shape[1:]`, in other words over all except the batch dimension.\n",
        "\n",
        "Make sure you understand what this module is doing before moving on.\n",
        "\n",
        "<!-- <details>\n",
        "<summary>Help - I can't figure out what shape the output should be in Flatten.</summary>\n",
        "\n",
        "If `input.shape = (n0, n1, ..., nk)`, and the `Flatten` module has `start_dim=i, end_dim=j`, then the new shape should be `(n0, n1, ..., ni*...*nj, ..., nk)`. This is because we're **flattening** over the dimensions `(ni, ..., nj)`.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I can't see why my Flatten module is failing the tests.</summary>\n",
        "\n",
        "The most common reason is failing to correctly handle indices. Make sure that:\n",
        "* You're indexing up to **and including** `end_dim`.\n",
        "* You're correctly managing the times when `end_dim` is negative (e.g. if `input` is an nD tensor, and `end_dim=-1`, this should be interpreted as `end_dim=n-1`).\n",
        "</details> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kJ8_fjZ3jBUG"
      },
      "outputs": [],
      "source": [
        "class Flatten(nn.Module):\n",
        "    def __init__(self, start_dim: int = 1, end_dim: int = -1) -> None:\n",
        "        super().__init__()\n",
        "        self.start_dim = start_dim\n",
        "        self.end_dim = end_dim\n",
        "\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Flatten out dimensions from start_dim to end_dim, inclusive of both.\n",
        "        \"\"\"\n",
        "        shape = input.shape\n",
        "\n",
        "        # Get start & end dims, handling negative indexing for end dim\n",
        "        start_dim = self.start_dim\n",
        "        end_dim = self.end_dim if self.end_dim >= 0 else len(shape) + self.end_dim\n",
        "\n",
        "        # Get the shapes to the left / right of flattened dims, as well as the size of the flattened middle\n",
        "        shape_left = shape[:start_dim]\n",
        "        shape_right = shape[end_dim + 1 :]\n",
        "        shape_middle = t.prod(t.tensor(shape[start_dim : end_dim + 1])).item()\n",
        "\n",
        "        return t.reshape(input, shape_left + (shape_middle,) + shape_right)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in [\"start_dim\", \"end_dim\"]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = t.rand((2,3,4))\n",
        "print(test.shape)\n",
        "test_flat = Flatten(0, 1)(test)\n",
        "print(test_flat.shape)"
      ],
      "metadata": {
        "id": "dsCF-TbI1GfW",
        "outputId": "c527597e-b65a-4754-d9e3-058604c22b3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n",
            "torch.Size([6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVmSiz4CjBUG"
      },
      "source": [
        "## Simple Multi-Layer Perceptron\n",
        "\n",
        "Now, we can put together these two modules to create a neural network. We'll create one of the simplest networks which can be used to separate data that is non-linearly separable: a single linear layer, followed by a nonlinear function (ReLU), followed by another linear layer. This type of architecture (alternating linear layers and nonlinear functions) is often called a **multi-layer perceptron** (MLP).\n",
        "\n",
        "The output of this network will have 10 dimensions, corresponding to the 10 classes of MNIST digits. We can then use the **softmax function** $x_i \\to \\frac{e^{x_i}}{\\sum_i e^{x_i}}$ to turn these values into probabilities. However, it's common practice for the output of a neural network to be the values before we take softmax, rather than after. We call these pre-softmax values the **logits**.\n",
        "\n",
        "<details>\n",
        "<summary>Question - can you see what makes logits non-unique (i.e. why any given set of probabilities might correspond to several different possible sets of logits)?</summary>\n",
        "\n",
        "Logits are **translation invariant**. If you add some constant $c$ to all logits $x_i$, then the new probabilities are:\n",
        "\n",
        "$$\n",
        "p_i' = \\frac{e^{x_i + c}}{\\sum_j e^{x_j + c}} = \\frac{e^{x_i}}{\\sum_j e^{x_j}} = p_i\n",
        "$$\n",
        "\n",
        "in other words, the probabilities don't change.\n",
        "\n",
        "We can define **logprobs** as the log of the probabilities, i.e. $y_i = \\log p_i$. Unlike logits, these are uniquely defined.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKzRBaB8jBUG"
      },
      "source": [
        "### Exercise - implement the simple MLP\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to ~20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "The diagram below shows what your MLP should look like:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mlp-mermaid.svg\" width=\"170\">\n",
        "\n",
        "Please ask a TA (or message the Slack group) if any part of this diagram is unclear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-Iaj1re_jBUG",
        "outputId": "53481769-10c5-42a1-8aae-9a2b49b7a73b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleMLP(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Linear(input_shape=784, output_shape=100)\n",
            "  (relu): ReLU()\n",
            "  (linear2): Linear(input_shape=100, output_shape=10)\n",
            ")\n",
            "All tests in `test_mlp_module` passed!\n",
            "tensor([[-3.7860e-01, -4.0041e-01, -4.6514e-01, -5.6859e-01,  1.5606e-01,\n",
            "         -3.2386e-01,  1.9988e-01, -8.7318e-02,  2.4950e-01, -1.9612e-02,\n",
            "          2.9075e-01,  1.3408e-01,  2.1187e-01, -7.4279e-02,  2.4120e-01,\n",
            "          2.9852e-01, -4.6853e-02, -2.0130e-01, -1.3496e-01, -1.2569e-02,\n",
            "          1.6985e-01, -3.2386e-03,  5.7354e-02, -3.3241e-02, -1.4853e-01,\n",
            "         -3.2649e-01, -1.1171e-01,  5.5196e-01, -6.9258e-01,  3.7233e-02,\n",
            "         -2.3516e-01,  1.6713e-01, -5.8222e-01,  4.0312e-01, -2.2733e-02,\n",
            "          6.9659e-02,  4.2750e-02, -7.4978e-02, -6.4216e-02,  7.4385e-01,\n",
            "          3.1862e-01,  8.6645e-02, -1.3815e-01, -1.1356e-01, -6.9103e-02,\n",
            "         -3.4474e-02,  1.8475e-01, -4.7635e-02, -5.4342e-01, -5.3139e-02,\n",
            "         -3.1477e-02, -2.8004e-01,  1.1239e-01, -1.9696e-01, -2.8998e-01,\n",
            "         -1.7181e-01, -2.7185e-01, -8.9590e-02, -3.6764e-01,  3.4836e-02,\n",
            "         -2.3897e-01,  1.8262e-01, -4.2003e-01, -4.7158e-02,  1.6489e-01,\n",
            "          6.0310e-02, -2.7243e-01,  1.7878e-01,  3.3452e-01, -1.7471e-01,\n",
            "          5.0709e-02, -3.0204e-01, -2.1793e-01, -2.3705e-01,  8.3081e-02,\n",
            "          9.8870e-02, -2.9274e-01, -3.2052e-01,  4.9156e-02, -4.9642e-01,\n",
            "         -1.4386e-01,  9.7240e-02, -1.9431e-01, -8.9607e-02, -1.1913e-01,\n",
            "          2.1852e-01,  7.7463e-02, -1.6123e-01, -3.5769e-01,  4.7076e-01,\n",
            "          4.3403e-01, -4.1247e-01, -1.4477e-01,  1.4386e-01, -1.6339e-01,\n",
            "          3.7388e-01, -1.2247e-01,  5.3481e-01, -2.8413e-02, -6.1629e-01],\n",
            "        [-8.8252e-02, -3.2950e-01, -3.0573e-01, -5.6349e-01,  9.4692e-02,\n",
            "         -6.8104e-01,  1.8043e-01,  3.8521e-01,  5.1384e-01,  1.0559e-01,\n",
            "          2.9356e-01, -6.7041e-02,  3.2615e-01, -5.1158e-01,  5.5636e-01,\n",
            "          4.7744e-01, -1.5381e-01,  1.7001e-01, -2.6492e-01,  1.4091e-01,\n",
            "          3.7142e-01, -1.5683e-01,  1.6832e-01,  1.5847e-01,  1.5805e-02,\n",
            "         -4.9473e-01, -6.4385e-02,  5.2703e-01, -5.1404e-01,  1.7025e-01,\n",
            "          1.6241e-01,  1.5194e-01, -4.7778e-01,  7.9519e-02, -2.0509e-01,\n",
            "         -4.8041e-01,  2.0340e-01, -4.1440e-02,  1.0617e-01,  9.0205e-01,\n",
            "          1.3527e-01,  7.1024e-01,  4.4719e-02,  4.4466e-02,  1.9325e-01,\n",
            "         -2.0922e-01,  7.3021e-02, -3.7530e-01, -3.4880e-01, -5.3063e-02,\n",
            "         -7.4740e-02, -2.8864e-01, -1.5396e-02,  1.9150e-01, -2.4197e-02,\n",
            "         -3.4065e-01, -5.4721e-02, -2.2080e-01, -3.4599e-01, -3.3933e-01,\n",
            "          5.9030e-02,  5.0374e-02, -2.9386e-01, -5.6614e-02,  3.3170e-02,\n",
            "          4.2369e-02, -1.1307e-01,  3.5997e-01,  2.5989e-01, -2.1405e-01,\n",
            "         -4.2890e-02, -3.0193e-01, -8.7376e-02, -2.9051e-01,  3.4371e-01,\n",
            "         -2.5745e-01, -3.8549e-01,  1.7309e-01,  8.2158e-02, -4.3158e-01,\n",
            "          6.4320e-03,  3.3930e-01, -6.0291e-01,  8.6882e-03, -2.3025e-01,\n",
            "          8.9358e-02,  3.2215e-01, -1.9642e-01, -2.8595e-01,  4.3320e-01,\n",
            "          2.0610e-01, -3.3021e-01, -1.7722e-01,  2.1596e-01, -9.4722e-02,\n",
            "          1.5683e-01,  1.4555e-02,  2.1744e-01, -8.8374e-02, -6.5815e-01],\n",
            "        [-2.6653e-01, -5.0101e-01, -1.1765e-01, -3.9881e-01,  1.4957e-01,\n",
            "         -5.3447e-01,  2.4547e-01,  1.5175e-01,  6.6853e-01,  2.6823e-01,\n",
            "          2.5798e-01,  3.2571e-01,  1.9576e-01, -2.4772e-01,  2.1293e-01,\n",
            "          2.5638e-01, -4.3521e-01,  3.2544e-01, -3.4609e-01, -3.8474e-01,\n",
            "          2.1134e-01,  5.1634e-03,  3.0358e-02, -2.8461e-01,  2.4570e-01,\n",
            "         -6.4474e-02, -2.4216e-01,  5.6170e-01, -5.3112e-01,  4.2859e-02,\n",
            "         -2.4450e-01,  3.2759e-01, -3.3057e-01,  5.5160e-02, -4.5755e-02,\n",
            "         -4.3170e-02,  2.1806e-01, -2.2420e-02,  1.3062e-01,  5.8688e-01,\n",
            "          2.7929e-01,  5.3946e-01, -2.4798e-01,  3.9877e-02,  1.7523e-01,\n",
            "          3.3288e-02,  4.6558e-01, -3.9665e-01, -3.3574e-01,  2.4225e-01,\n",
            "         -7.8086e-02, -2.1012e-01,  1.2117e-03,  6.2715e-01, -2.8277e-01,\n",
            "         -2.6481e-01, -3.7847e-01, -4.8156e-01, -2.2242e-01, -4.8990e-01,\n",
            "         -5.7711e-02,  1.4826e-01, -2.2298e-01,  1.1109e-01,  8.5765e-02,\n",
            "          4.7541e-01, -8.8168e-02,  4.3405e-01,  5.2313e-01,  1.8737e-02,\n",
            "          1.3209e-01, -3.8489e-01, -4.8220e-01, -2.0026e-01,  1.0933e-01,\n",
            "         -4.8325e-01, -1.2952e-01, -1.8308e-01, -1.7452e-01, -6.6250e-01,\n",
            "         -6.5421e-02,  4.9227e-01, -1.6358e-01, -8.2618e-02, -1.9117e-01,\n",
            "          1.0578e-01, -2.1153e-02, -4.9573e-01, -4.4570e-01,  4.6953e-01,\n",
            "          4.6583e-01, -6.3150e-01, -2.4879e-01, -1.2849e-01, -1.6649e-01,\n",
            "          1.7195e-02,  3.5172e-02,  1.6195e-01, -3.1413e-01, -2.6412e-01],\n",
            "        [-1.3238e-01, -5.1099e-01, -1.6345e-01, -4.7979e-01, -1.0321e-02,\n",
            "         -5.6931e-01,  6.3932e-01,  2.0719e-01,  6.7529e-01,  1.3886e-01,\n",
            "          1.7542e-01,  1.0132e-01,  1.6951e-01, -3.5035e-01,  2.1436e-01,\n",
            "          3.1612e-01, -1.9772e-01,  3.1987e-02, -1.9285e-01, -2.2361e-01,\n",
            "          2.8703e-01, -7.8699e-02,  3.0821e-02, -1.2673e-01,  2.4112e-02,\n",
            "         -3.1600e-01, -3.2302e-01,  4.0806e-01, -5.4113e-01,  1.9326e-02,\n",
            "          1.8087e-01,  3.0208e-01, -2.5956e-01,  8.0600e-02,  9.8833e-02,\n",
            "         -2.7623e-01,  1.3680e-01, -3.1992e-01, -3.1115e-02,  3.6075e-01,\n",
            "          1.5447e-01,  1.1889e-01, -2.9468e-01,  2.2262e-02,  3.5081e-02,\n",
            "          6.8071e-02,  4.8629e-02, -3.0008e-01, -2.0028e-01, -7.7486e-03,\n",
            "         -1.9410e-01, -1.0915e-01, -1.4445e-01,  2.4401e-02, -1.2912e-01,\n",
            "         -3.2660e-01, -3.9971e-01, -1.8893e-01, -3.2878e-01, -3.8254e-01,\n",
            "          4.7164e-02,  4.2530e-01, -1.3366e-01,  8.9412e-02,  3.4095e-02,\n",
            "          1.9584e-01, -2.4940e-01,  1.9581e-01,  5.2208e-01,  1.8020e-02,\n",
            "          1.3990e-01, -5.2891e-01, -3.2645e-02,  7.4739e-03,  8.5981e-02,\n",
            "         -2.5030e-01, -2.6126e-01,  1.9506e-01, -4.8531e-02, -5.2638e-01,\n",
            "         -2.8967e-01,  3.4107e-01, -1.6491e-02, -2.7507e-01, -1.3534e-01,\n",
            "          1.8293e-01, -2.3906e-02, -6.5652e-02, -1.2075e-01,  4.4410e-01,\n",
            "          1.8930e-01, -7.4000e-01, -1.6406e-01, -1.2218e-01,  1.2215e-01,\n",
            "          1.9561e-01, -3.4390e-01,  4.1712e-01, -2.0201e-01, -4.7906e-01],\n",
            "        [-3.0182e-01, -5.5711e-01, -2.3908e-01, -5.2646e-01,  2.5529e-01,\n",
            "         -6.7558e-01,  1.3197e-01,  2.8407e-03,  5.8870e-01,  3.0385e-01,\n",
            "         -2.1008e-01, -9.1115e-02, -9.8777e-03, -2.3537e-02,  4.2497e-01,\n",
            "          3.5980e-01, -5.7653e-02,  2.3548e-01, -2.1098e-01, -2.8795e-01,\n",
            "         -7.7025e-02,  2.5513e-01,  1.1599e-01, -2.0156e-01,  3.3234e-01,\n",
            "         -4.0387e-01, -1.6405e-01,  5.2575e-01, -6.3509e-01, -1.6351e-01,\n",
            "         -1.0847e-01,  2.5236e-01, -5.2680e-01, -1.3346e-02, -1.0400e-02,\n",
            "         -3.3861e-01,  1.7314e-01, -2.5534e-01,  7.8013e-02,  7.5641e-01,\n",
            "          3.8462e-01,  2.1766e-01, -2.9392e-01,  3.2854e-02,  1.1184e-01,\n",
            "         -6.0330e-02, -1.3375e-01, -2.0052e-01, -6.3524e-01,  4.3458e-01,\n",
            "         -1.8057e-01, -1.5439e-01, -1.0570e-01,  1.0462e-01, -2.3569e-02,\n",
            "         -3.2559e-01, -3.8647e-01,  2.1644e-02, -2.5213e-01, -4.3200e-01,\n",
            "         -4.5571e-02,  2.5154e-01, -3.9563e-01, -3.4344e-02, -1.6261e-01,\n",
            "         -8.7606e-02, -5.8329e-02,  2.7352e-01,  4.5891e-01, -1.4809e-01,\n",
            "          1.4042e-01, -3.8083e-01, -1.8163e-02,  3.3301e-02, -2.8733e-02,\n",
            "         -3.9799e-01, -3.0760e-01, -5.8964e-02, -1.7943e-01, -3.5731e-01,\n",
            "         -3.3377e-01,  5.5454e-02, -1.6520e-01, -2.5769e-01, -2.8100e-01,\n",
            "          8.9758e-02, -1.2656e-01, -1.7574e-01, -1.5029e-01,  5.0419e-01,\n",
            "          2.2958e-01, -7.5364e-01, -2.9976e-02,  2.0356e-01, -2.1329e-02,\n",
            "          1.9955e-01,  2.2049e-01,  6.3111e-01, -1.5113e-01, -7.2387e-01],\n",
            "        [-2.6227e-01, -7.6710e-01, -6.1665e-01, -6.7701e-01,  1.0645e-01,\n",
            "         -5.2756e-01,  5.2669e-01, -1.6371e-01,  4.5475e-01,  2.4250e-01,\n",
            "          1.2431e-01,  2.6054e-01,  3.2481e-01, -1.9764e-02,  4.2986e-01,\n",
            "          5.2040e-01, -6.7199e-03, -1.1479e-01, -2.7469e-01, -1.5552e-01,\n",
            "          6.5227e-02,  2.1336e-02,  1.3526e-01, -4.1824e-01,  2.5346e-01,\n",
            "         -1.8659e-01, -3.4285e-01,  6.9132e-01, -6.0130e-01, -1.7293e-02,\n",
            "         -5.0420e-02,  7.2074e-02, -2.4387e-01,  2.9045e-01, -1.9956e-01,\n",
            "         -2.1148e-01,  2.3687e-01, -7.3860e-02, -5.9556e-02,  4.7291e-01,\n",
            "          2.4798e-01,  4.3385e-01, -2.9173e-01,  4.1629e-01,  3.6693e-01,\n",
            "         -1.0234e-01,  6.8407e-01, -3.9829e-01, -2.8169e-01, -5.9303e-03,\n",
            "          1.6623e-01, -3.2722e-01,  1.0540e-01, -6.0509e-02, -3.6268e-01,\n",
            "         -2.4872e-01, -2.2314e-01, -2.2483e-01, -1.4422e-01, -2.6373e-01,\n",
            "         -1.6838e-01,  4.9084e-01, -4.0814e-01, -8.6763e-03,  2.8322e-01,\n",
            "          5.7446e-02, -6.3254e-02,  6.8518e-02,  3.8707e-01, -1.5972e-02,\n",
            "          5.1506e-01, -6.4662e-01, -1.0040e-01, -1.0138e-01,  2.7317e-01,\n",
            "         -2.3999e-01, -3.7736e-01, -2.5259e-01, -2.5322e-01, -3.7969e-01,\n",
            "         -5.7609e-02,  3.2675e-01, -2.0240e-01, -2.7286e-02, -2.2961e-03,\n",
            "          6.2611e-02,  2.3728e-01, -2.3586e-01, -3.4157e-01,  3.4492e-01,\n",
            "          2.4796e-01, -6.5061e-01,  1.1882e-01,  3.1575e-01,  5.1504e-02,\n",
            "         -1.7174e-01, -6.5522e-02,  1.9224e-01, -3.9494e-02, -3.6994e-01],\n",
            "        [ 1.9504e-01, -5.0041e-01, -2.3672e-01, -6.3531e-01,  9.6097e-02,\n",
            "         -7.1767e-01,  2.1739e-01, -2.9403e-02,  5.8735e-01,  1.8002e-01,\n",
            "          2.5052e-01,  3.5119e-02,  1.7053e-01, -9.0333e-02,  1.6483e-01,\n",
            "          1.9758e-01,  1.4416e-02,  4.8488e-01, -2.1918e-01, -1.0155e-01,\n",
            "          4.4348e-01,  7.1062e-02, -2.0818e-01, -2.7856e-01,  1.6713e-01,\n",
            "         -4.3420e-01, -1.5879e-01,  6.5854e-01, -5.3568e-01,  1.1663e-01,\n",
            "         -2.8657e-01,  1.7443e-01, -4.4768e-01,  3.7824e-01,  2.9444e-02,\n",
            "         -5.7791e-01,  6.5743e-02, -1.0474e-01, -7.6978e-02,  5.5601e-01,\n",
            "          4.6672e-01,  2.8244e-01, -1.5017e-01,  1.7377e-03,  1.3396e-03,\n",
            "         -2.9470e-01, -2.6278e-01, -4.6784e-01, -3.1432e-01,  3.5131e-01,\n",
            "         -2.0603e-01, -5.0585e-03,  1.3762e-01,  2.8003e-01, -3.3005e-01,\n",
            "         -2.6667e-01, -3.1060e-01, -3.6737e-01, -5.4304e-01, -8.1762e-02,\n",
            "          1.3610e-01, -2.3352e-02, -2.8896e-01,  8.9335e-02,  1.1803e-01,\n",
            "          2.4140e-02, -4.7204e-02,  1.3365e-01,  6.1853e-01, -4.3287e-01,\n",
            "          7.4092e-02, -6.5147e-01, -1.8191e-01, -7.8350e-02,  1.2381e-01,\n",
            "         -1.1808e-01, -1.8465e-01, -1.1733e-01, -1.4946e-01, -4.4018e-01,\n",
            "         -1.3173e-01,  8.2862e-02, -7.9964e-02,  9.4406e-02, -1.8820e-01,\n",
            "          1.3037e-01,  2.6558e-01, -3.0866e-01, -2.0606e-01,  4.0767e-01,\n",
            "          6.4013e-01, -4.2280e-01, -1.7602e-01,  1.9798e-01,  7.7810e-02,\n",
            "          4.2328e-01, -2.6082e-02,  4.9109e-01, -1.4578e-01, -3.2301e-01],\n",
            "        [ 1.1728e-01, -4.1497e-01, -5.7474e-01, -4.1527e-01,  1.4739e-01,\n",
            "         -7.9791e-01,  1.9775e-01,  1.5428e-01,  5.7138e-01,  4.1063e-01,\n",
            "          2.1655e-01,  2.9744e-01,  1.2566e-02, -1.0456e-02,  4.2778e-01,\n",
            "          2.7277e-01, -4.7512e-01,  4.4376e-02, -3.9523e-02, -1.6478e-01,\n",
            "         -2.6536e-01,  1.3111e-01, -2.4524e-01, -1.1462e-01, -1.6039e-01,\n",
            "         -1.8199e-01, -2.4880e-01,  4.3173e-01, -3.4507e-01, -4.4556e-02,\n",
            "         -6.7342e-02,  3.7997e-01, -6.0663e-01,  4.1633e-02,  1.0035e-01,\n",
            "          1.0573e-01,  1.0606e-01, -2.2503e-02, -4.5676e-02,  8.9318e-01,\n",
            "         -3.6959e-02,  4.1201e-01, -1.4567e-01,  1.7618e-01, -1.4222e-01,\n",
            "         -6.7592e-03,  8.7906e-02, -3.4972e-01, -3.9818e-01,  4.5647e-01,\n",
            "         -2.1279e-02, -3.5253e-01,  1.5091e-01,  2.0028e-01, -1.6236e-01,\n",
            "         -3.9815e-01, -5.1734e-01, -1.8590e-01, -2.4826e-01, -1.3343e-01,\n",
            "         -4.6545e-02, -1.9849e-02, -3.3990e-01, -7.3489e-02,  5.8743e-02,\n",
            "          2.5268e-02, -4.2420e-01,  3.7981e-01,  3.6654e-01,  5.4894e-04,\n",
            "          3.0543e-02, -5.2514e-01, -7.7228e-01,  6.7905e-02,  3.7235e-01,\n",
            "         -3.3040e-01, -1.7147e-01, -2.8532e-01,  8.6000e-02, -5.1777e-01,\n",
            "         -2.6831e-01,  3.7650e-01, -4.0509e-02, -5.0699e-01, -3.4780e-01,\n",
            "         -7.1097e-02, -4.6853e-02, -2.4096e-01, -2.6830e-03,  4.9126e-01,\n",
            "          5.4433e-02, -4.8780e-01, -1.2962e-01,  2.1156e-01,  1.0522e-01,\n",
            "          3.4290e-01, -2.9535e-02,  2.5824e-01, -3.8214e-01, -7.2559e-01],\n",
            "        [ 2.5873e-02, -3.1203e-01, -4.2514e-01, -3.9047e-01,  2.0005e-01,\n",
            "         -8.5511e-01,  3.6264e-01,  1.0616e-01,  7.0519e-01,  4.0347e-01,\n",
            "          2.4499e-01,  2.7746e-01,  1.1658e-01, -6.1432e-03,  6.9906e-01,\n",
            "          1.4487e-01, -5.7001e-02, -1.5001e-02, -2.2823e-01, -3.5933e-02,\n",
            "          4.9443e-01,  1.3872e-01, -2.4401e-01, -1.8924e-01, -1.3746e-01,\n",
            "         -3.4767e-01,  3.2219e-03,  5.2926e-01, -4.9064e-01,  2.1266e-01,\n",
            "         -1.3997e-01,  4.0962e-01, -2.7934e-01,  2.3182e-01, -1.6161e-01,\n",
            "         -1.4002e-01,  2.4190e-02, -4.3566e-02,  2.4476e-02,  4.4804e-01,\n",
            "          2.9523e-01,  1.9412e-01, -1.1965e-01,  1.7567e-01,  2.2962e-01,\n",
            "         -3.8089e-02,  1.7924e-01, -2.9665e-01, -2.5951e-01, -1.1130e-01,\n",
            "         -8.8187e-02, -3.5353e-01,  1.9226e-01, -4.3648e-02, -2.0453e-02,\n",
            "         -2.0819e-01, -4.2825e-01, -3.0294e-01, -3.9796e-01, -2.5042e-01,\n",
            "          3.3853e-01,  1.6071e-01, -1.9497e-01, -3.7380e-02,  3.1592e-01,\n",
            "         -3.3487e-01, -5.3918e-01,  2.6395e-01,  4.7139e-01, -3.2527e-01,\n",
            "          1.3226e-01, -6.1616e-01, -2.8725e-01, -4.7773e-03,  2.9369e-01,\n",
            "         -4.4561e-01, -3.3232e-01, -1.5540e-02, -1.0082e-01, -2.2081e-01,\n",
            "          2.7516e-02,  1.0668e-01, -6.7595e-02, -3.3625e-01, -2.3269e-01,\n",
            "          4.5039e-01, -6.5999e-02, -6.5659e-01, -2.6125e-01,  1.9524e-01,\n",
            "          3.8425e-01, -6.6141e-01,  8.5093e-02,  5.1215e-02,  7.5648e-02,\n",
            "          1.0719e-01,  6.7710e-02,  2.5977e-01, -3.4197e-01, -1.7511e-01],\n",
            "        [ 1.9968e-01, -5.6638e-01, -7.2040e-01, -4.2451e-01,  1.6145e-01,\n",
            "         -4.1544e-01,  1.1744e-01, -2.0569e-01,  5.9851e-01,  1.7054e-01,\n",
            "          3.4521e-01, -1.8129e-01,  2.7555e-01,  2.0538e-01,  3.2762e-01,\n",
            "          1.5232e-01, -1.5408e-01, -1.3290e-01, -3.1315e-01, -2.7627e-01,\n",
            "         -1.1146e-01,  6.9709e-02,  8.2686e-02, -2.9743e-01, -1.4712e-01,\n",
            "         -4.3698e-01,  4.7206e-02,  4.8941e-01, -4.3708e-01,  1.6433e-02,\n",
            "         -6.2399e-02,  3.4511e-01, -4.7259e-01,  1.7990e-01,  7.3562e-02,\n",
            "         -1.7000e-01,  2.2042e-01, -2.5882e-01,  2.7749e-01,  6.8930e-01,\n",
            "          1.9125e-01,  2.5469e-01, -4.0424e-01,  1.2466e-01,  2.0471e-01,\n",
            "          1.4966e-01,  2.4787e-01, -6.4107e-01, -2.0706e-01,  3.6549e-01,\n",
            "         -4.5712e-02, -7.9126e-02,  1.1056e-01, -4.7327e-02, -5.6612e-02,\n",
            "         -1.9788e-01, -4.9624e-02, -1.4753e-01, -4.8848e-01, -5.2541e-01,\n",
            "         -1.4549e-01, -4.3227e-02, -1.9393e-01, -1.0221e-01, -9.7464e-02,\n",
            "          1.1103e-02, -1.6692e-01, -9.8410e-03,  4.4066e-01, -3.9770e-02,\n",
            "          8.4037e-02, -4.3476e-01, -3.6694e-01, -2.5657e-01,  1.3774e-01,\n",
            "         -4.4053e-01, -3.0512e-01, -1.8689e-02, -2.5352e-01, -7.0957e-01,\n",
            "         -3.3163e-01,  4.5282e-01, -3.2844e-01, -1.4378e-01, -2.1683e-01,\n",
            "         -6.5774e-02, -1.6112e-01, -4.1272e-01, -1.3354e-01,  3.8731e-01,\n",
            "          2.6849e-01, -4.5865e-01,  3.4438e-01,  1.2917e-01, -1.3446e-01,\n",
            "          2.3989e-01, -5.8972e-02,  4.6791e-01, -2.4409e-01, -5.1315e-01]],\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "All tests in `test_mlp_forward` passed!\n"
          ]
        }
      ],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = Flatten()\n",
        "        self.linear1 = Linear(in_features=28**2, out_features=100)\n",
        "        self.relu = ReLU()\n",
        "        self.linear2 = Linear(in_features=100, out_features=10)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        logits = self.linear2(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = SimpleMLP()\n",
        "print(model)\n",
        "tests.test_mlp_module(SimpleMLP)\n",
        "tests.test_mlp_forward(SimpleMLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wFEVgZWjBUG"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = Flatten()\n",
        "        self.linear1 = Linear(in_features=28 * 28, out_features=100)\n",
        "        self.relu = ReLU()\n",
        "        self.linear2 = Linear(in_features=100, out_features=10)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.linear2(self.relu(self.linear1(self.flatten(x))))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUsPcuGNjBUG"
      },
      "source": [
        "In the next section, we'll learn how to train and evaluate our model on real data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pual9hHjBUG"
      },
      "source": [
        "# 2️⃣ Training Neural Networks\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand how to work with transforms, datasets and dataloaders\n",
        "> - Understand the basic structure of a training loop\n",
        "> - Learn how to write your own validation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgkKLYK2jBUG"
      },
      "source": [
        "## Transforms, Datasets & DataLoaders\n",
        "\n",
        "Before we use this model to make any predictions, we first need to think about our input data. Below is a block of code to fetch and process MNIST data. We will go through it line by line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EG9SNl8UjBUG",
        "outputId": "08763975-8e8e-40c3-b601-94d07cdcfb2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.63MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.28MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.60MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_batch.shape=torch.Size([64, 1, 28, 28])\n",
            "label_batch.shape=torch.Size([64])\n",
            "\n",
            "img.shape=torch.Size([1, 28, 28])\n",
            "label=7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "MNIST_TRANSFORM = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(0.1307, 0.3081),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def get_mnist(trainset_size: int = 10_000, testset_size: int = 1_000) -> tuple[Subset, Subset]:\n",
        "    \"\"\"Returns a subset of MNIST training data.\"\"\"\n",
        "\n",
        "    # Get original datasets, which are downloaded to \"chapter0_fundamentals/exercises/data\" for future use\n",
        "    mnist_trainset = datasets.MNIST(exercises_dir / \"data\", train=True, download=True, transform=MNIST_TRANSFORM)\n",
        "    mnist_testset = datasets.MNIST(exercises_dir / \"data\", train=False, download=True, transform=MNIST_TRANSFORM)\n",
        "\n",
        "    # # Return a subset of the original datasets\n",
        "    mnist_trainset = Subset(mnist_trainset, indices=range(trainset_size))\n",
        "    mnist_testset = Subset(mnist_testset, indices=range(testset_size))\n",
        "\n",
        "    return mnist_trainset, mnist_testset\n",
        "\n",
        "\n",
        "mnist_trainset, mnist_testset = get_mnist()\n",
        "mnist_trainloader = DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
        "mnist_testloader = DataLoader(mnist_testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Get the first batch of test data, by starting to iterate over `mnist_testloader`\n",
        "for img_batch, label_batch in mnist_testloader:\n",
        "    print(f\"{img_batch.shape=}\\n{label_batch.shape=}\\n\")\n",
        "    break\n",
        "\n",
        "# Get the first datapoint in the test set, by starting to iterate over `mnist_testset`\n",
        "for img, label in mnist_testset:\n",
        "    print(f\"{img.shape=}\\n{label=}\\n\")\n",
        "    break\n",
        "\n",
        "t.testing.assert_close(img, img_batch[0])\n",
        "assert label == label_batch[0].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZPruRoVjBUG"
      },
      "source": [
        "The `torchvision` package consists of popular datasets, model architectures, and common image transformations for computer vision, and `torchvision.transforms` provides access to a suite of functions for preprocessing data. We define a transform for the MNIST data (which is applied to each image in the dataset) by composing `ToTensor` (which converts a `PIL.Image` object into a PyTorch tensor) and `Normalize` (which takes arguments for the mean and standard deviation, and performs the linear transformation `x -> (x - mean) / std`). For the latter, we use `0.1307` and `0.3081` which are the empirical mean & std of the raw data (so after this transformation, the data will have mean 0 and variance 1).\n",
        "\n",
        "Next, we define our datasets using `torchvision.datasets`. The first argument tells us where to save our data to (so that when we run this in the future we won't have to re-save it), and `transform=MNIST_TRANSFORM` tells us that we should apply our previously defined `transform` to each element in our dataset. We also use `Subset` which allows us to return a slice of the dataset rather than the whole thing (because our model won't need much data to train!).\n",
        "\n",
        "Finally, since our dataset only allows for iteration over individual datapoints, we wrap it in `DataLoader` which enables iteration over **batches**. It also provides useful arguments like `shuffle`, which determine whether we randomize the order after each epoch. The code above demonstrates iteration over the dataset & dataloader respectively, showing how the first element in the dataloader's first batch equals the first element in the dataset (note that this wouldn't be true for the training set, because we've shuffled it).\n",
        "\n",
        "<details>\n",
        "<summary>Aside - why batch sizes are often powers of 2</summary>\n",
        "\n",
        "It's common to see batch sizes which are powers of two. The motivation is for efficient GPU utilisation, since processor architectures are normally organised around powers of 2, and computational efficiency is often increased by having the items in each batch split across processors. Or at least, that's the idea. The truth is a bit more complicated, and some studies dispute whether it actually saves time, so at this point it's more of a standard convention than a hard rule which will always lead to more efficient training.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScJ71Ki8jBUG"
      },
      "source": [
        "Before proceeding, try and answer the following questions:\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Question - can you explain why we include a data normalization function in <code>torchvision.transforms</code> ?</summary>\n",
        "\n",
        "One consequence of unnormalized data is that you might find yourself stuck in a very flat region of the domain, and gradient descent may take much longer to converge.\n",
        "\n",
        "Normalization isn't strictly necessary for this reason, because any rescaling of an input vector can be effectively undone by the network learning different weights and biases. But in practice, it does usually help speed up convergence.\n",
        "\n",
        "Normalization also helps avoid numerical issues.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Question - what is the benefit of using <code>shuffle=True</code> when defining our dataloaders? What might the problem be if we didn't do this?</summary>\n",
        "\n",
        "Shuffling is done during the training to make sure we aren't exposing our model to the same cycle (order) of data in every epoch. It is basically done to ensure the model isn't adapting its learning to any kind of spurious pattern.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iTKJ-PCjBUG"
      },
      "source": [
        "### Aside - `tqdm`\n",
        "\n",
        "You might have seen some blue progress bars running when you first downloaded your MNIST data. These were generated using a library called `tqdm`, which is also a really useful tool when training models or running any process that takes a long period of time.\n",
        "\n",
        "The `tqdm` function wraps around an iterable, and displays a progress bar as you iterate through it. The code below shows a minimal example:\n",
        "\n",
        "```python\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "for i in tqdm(range(100)):\n",
        "    time.sleep(0.1)\n",
        "```\n",
        "\n",
        "There are some more advanced features of `tqdm` too, for example:\n",
        "\n",
        "- If you define the progress bar `pbar = tqdm(...)` before your iteration, then you have the option of adding extra information to it using `pbar.set_description` or `pbar.set_postfix`\n",
        "- You can specify the total number of iterations with `tqdm(iterable, total=...)`; this is actually very important when the iterable is something like `enumerate(...)` which doesn't have a length attribute, since tqdm will usually try and infer the total from calling `len` on the iterable you pass it.\n",
        "\n",
        "Here's some code that demonstrates these extra features:\n",
        "\n",
        "```python\n",
        "word = \"hello!\"\n",
        "pbar = tqdm(enumerate(word), total=len(word))\n",
        "t0 = time.time()\n",
        "\n",
        "for i, letter in pbar:\n",
        "    time.sleep(1.0)\n",
        "    pbar.set_postfix(i=i, letter=letter, time=f\"{time.time()-t0:.3f}\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "word = \"hello!\"\n",
        "pbar = tqdm(enumerate(word), total=len(word))\n",
        "t0 = time.time()\n",
        "\n",
        "for i, letter in pbar:\n",
        "    time.sleep(1.0)\n",
        "    pbar.set_postfix(i=i, letter=letter, time=f\"{time.time()-t0:.3f}\")"
      ],
      "metadata": {
        "id": "Ym7-7RaEHc19",
        "outputId": "f36459f5-3ed1-4134-fba6-780722ff0fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "77162a2448d442a59363324f157fe36d",
            "478b2c56e5944279b6ef825d6f443ad6",
            "b30709540a5c4d748bf8d7caf4d0125c",
            "9050ad61b91c492bb37a674af22b50aa",
            "d92b8e4aac7547768ba104029f1a761f",
            "0d3361af45b6444484a08e9adfbcef2b",
            "1418a29a52c54fe0b1b1bee87ddfd5ec",
            "cab4601db1964758b5062edd87add959",
            "09a7a810e4ec4f47a8c3adc7f810e538",
            "c0e4536783554072b17bb90297b4cf17",
            "3d49dea8d431403d896f1cd906fad468"
          ]
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77162a2448d442a59363324f157fe36d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfRC2yXljBUG"
      },
      "source": [
        "### Aside - `device`\n",
        "\n",
        "One last thing to discuss before we move onto training our model: **GPUs**. We'll discuss this in more detail in later exercises. For now, [this page](https://wandb.ai/wandb/common-ml-errors/reports/How-To-Use-GPU-with-PyTorch---VmlldzozMzAxMDk) should provide a basic overview of how to use your GPU. A few things to be aware of here:\n",
        "\n",
        "* The `to` method is really useful here - it can move objects between different devices (i.e. CPU and GPU) *as well as* changing a tensor's datatype.\n",
        "    * Note that `to` is never inplace for tensors (i.e. you have to call `x = x.to(device)`), but when working with models, calling `model = model.to(device)` or `model.to(device)` are both perfectly valid.\n",
        "* Errors from having one tensor on cpu and another on cuda are very common. Some useful practices to avoid this:\n",
        "    * Throw in assert statements, to make sure tensors are on the same device\n",
        "    * Remember that when you initialise an array (e.g. with `t.zeros` or `t.arange`), it will be on CPU by default.\n",
        "    * Tensor methods like [`new_zeros`](https://pytorch.org/docs/stable/generated/torch.Tensor.new_zeros.html) or [`new_full`](https://pytorch.org/docs/stable/generated/torch.Tensor.new_full.html) are useful, because they'll create tensors which match the device and dtype of the base tensor.\n",
        "\n",
        "It's common practice to put a line like this at the top of your file, defining a global variable which you can use in subsequent modules and functions (excluding the print statement):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pEYxzx0HjBUG",
        "outputId": "c7255f7e-9ed9-479d-b98b-6a3ab6e65e2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# If this is CPU, we recommend figuring out how to get cuda access (or MPS if you're on a Mac).\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMTdW3bGjBUG"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Below is a very simple training loop, which you can run to train your model.\n",
        "\n",
        "In later exercises, we'll try to **modularize** our training loops. This will involve things like creating a `Trainer` class which wraps around our model, and giving it methods like `training_step` and `validation_step` which correspond to different parts of the training loop. This will make it easier to add features like logging and validation, and will also make our code more readable and easier to refactor. However, for now we've kept things simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TaV3wfVgjBUO",
        "collapsed": true,
        "outputId": "6eafa638-75fd-432d-adf6-4624962ed0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a4577d1c5fe4446c87d3990a611a6146",
            "9346283fd9034263a918609148ce1b88",
            "127aadd55c5a433bb2f201d6a7378c9b",
            "39ac96a8871d4cf18aaacab654617b77",
            "7769ce496e4d4b8a9b5c0ebedd487712",
            "78b4cf1eb9d34b1f9244b157587e1b51",
            "0a446dc2131349799dfe2901ee3f7595",
            "83584efaae0a4e5f9f9b4c70f48584d1",
            "8309741998cb42eeafae743694a6fe91",
            "5d82f9a29c14475ab8a3364dd1092650",
            "4b5e634373d847aa81cec36ba02f7457",
            "3ae5150dd2d349a7a719afe1e9a13be1",
            "fb13817ea09c443d90db066ebd308873",
            "229c77768f754f3581a447d112fc5f36",
            "3fd6cbab68ca415583b1e7e8a0221aa7",
            "203f698177e846bdbdec273a8730bf32",
            "f8234920c2ab48499682646a9fc91b5d",
            "cbf5788569fc42589dbb00cf5ca625e5",
            "bb4626491c134718a521e373983752d2",
            "bc91b034f94d4533b70472db277b4482",
            "bc7ada51b84d428e91b42daae6f64203",
            "d832ac9f97074155812d80f94df2cef4",
            "572a2dc5793140acaa6781550b31dc9a",
            "d4cb6b2710b847d19af832d3610554bf",
            "df3dc34015ca4018a747fe47607b8bb5",
            "3d7e9c7faad64020b55784499d14331b",
            "0d1973e1a1514176be398d8c88ce6dab",
            "23d293a4d5e04af498c3275ec139b7a9",
            "0341b20508824c3e8299cba2ba133ec6",
            "c17cc49c50aa4d1b994887c612a44c30",
            "f85b81cbf490424283e84fe186fb1a93",
            "96ce32df5d9a4020afd636621395513e",
            "8a1feb4718404a85a7304af227676bee"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4577d1c5fe4446c87d3990a611a6146"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0057, -1.4391, -2.4262,  ..., -2.1918,  0.8880,  2.4801],\n",
            "        [-0.3143,  1.0619,  0.1870,  ..., -0.9576,  0.7155,  1.4318],\n",
            "        [-0.2549,  0.1239,  1.5891,  ..., -0.5643, -1.0971, -0.4323],\n",
            "        ...,\n",
            "        [ 0.2308, -0.4195,  1.0875,  ...,  2.5151, -0.1414, -0.6783],\n",
            "        [-2.0864, -1.4235, -2.1317,  ..., -3.3276,  2.4852,  1.2951],\n",
            "        [-1.9505,  0.2538,  0.8327,  ..., -0.8191,  0.3279,  2.4715]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3049,  0.6036,  1.3615,  ..., -0.5035,  1.4844, -1.7911],\n",
            "        [ 0.9595, -0.7644,  0.4201,  ..., -1.5450, -1.9419, -1.0340],\n",
            "        [-2.5815, -0.1497, -0.9823,  ..., -1.2742,  1.7161,  2.1180],\n",
            "        ...,\n",
            "        [ 0.8360, -1.5818,  0.4200,  ...,  0.2365, -1.1959, -0.7402],\n",
            "        [-2.2668, -1.7777,  1.0789,  ...,  1.9561, -1.3117,  1.3996],\n",
            "        [-0.2255, -0.9934, -0.9986,  ..., -1.3772,  0.6352,  1.2712]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2769, -1.2132, -1.6186,  ..., -1.7832,  0.0398,  1.4543],\n",
            "        [-1.3022, -0.8734, -0.7431,  ..., -3.2491, -0.5845,  2.2562],\n",
            "        [-2.4166,  0.7747, -1.6242,  ..., -0.4597,  1.5589,  1.7702],\n",
            "        ...,\n",
            "        [ 0.3948,  0.2815, -1.2523,  ..., -1.0392, -0.4424,  1.6201],\n",
            "        [-3.0047,  1.1596,  0.5301,  ..., -0.4308,  2.0805,  2.2176],\n",
            "        [-0.6192,  1.7021, -2.4017,  ..., -3.8543,  1.1271, -0.2168]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8622,  2.9855, -1.9503,  ...,  0.1996, -1.5359,  2.0148],\n",
            "        [-0.7520,  0.8606, -1.1490,  ..., -0.5993,  1.7938,  1.2943],\n",
            "        [ 1.2827, -0.6305, -2.5418,  ..., -0.2447, -1.4846,  0.0141],\n",
            "        ...,\n",
            "        [ 0.3583,  1.9696, -1.3709,  ..., -0.1305,  0.5835, -0.9322],\n",
            "        [ 1.0243, -0.1283, -1.7915,  ..., -0.2711,  0.7317,  1.0422],\n",
            "        [-0.4108, -0.8870, -0.3443,  ..., -0.9533,  2.4074,  0.4752]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8947,  1.2179,  0.8374,  ..., -0.3494,  0.9028,  0.2698],\n",
            "        [ 2.4467, -0.5828,  0.0255,  ..., -1.3000, -3.7236,  1.9725],\n",
            "        [-0.3379,  0.1882, -0.9983,  ...,  0.9320,  0.2713, -0.3136],\n",
            "        ...,\n",
            "        [ 0.1327,  0.4388, -0.6734,  ..., -2.0826,  1.2054,  0.6383],\n",
            "        [-1.1500,  0.7943, -1.2619,  ..., -2.8387,  0.4374,  1.6192],\n",
            "        [ 0.9091,  1.3942,  0.2469,  ..., -2.7088, -2.3046,  1.4086]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2402, -2.5435, -1.8399,  ..., -2.8809,  0.5137,  2.0320],\n",
            "        [ 1.4544, -1.8313, -0.8444,  ..., -0.5348, -0.2026,  1.1092],\n",
            "        [ 0.4929,  0.0581,  1.7691,  ..., -0.6964, -1.7489,  1.6902],\n",
            "        ...,\n",
            "        [ 0.4103,  0.8045, -0.0050,  ..., -2.7079, -2.6584,  2.6136],\n",
            "        [ 0.9667, -0.0861,  0.8567,  ...,  1.7110, -2.6667,  0.6386],\n",
            "        [ 1.3229,  0.3458,  0.1002,  ...,  0.5307,  1.1945,  0.6455]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1005,  1.6397, -1.8258,  ..., -1.1800, -0.8980,  3.8387],\n",
            "        [-1.2946,  0.6987,  1.4911,  ..., -0.8484, -1.9217, -2.6231],\n",
            "        [ 0.5130,  1.8410, -1.4551,  ..., -3.2229, -1.3719,  3.1793],\n",
            "        ...,\n",
            "        [-0.0605, -0.1544, -1.3699,  ..., -1.3255,  0.4001, -0.1807],\n",
            "        [-0.2490, -1.1695,  0.8866,  ...,  2.2293, -1.3991,  0.6867],\n",
            "        [-1.8392, -2.9215,  1.0846,  ...,  2.9385, -0.3995,  2.2819]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0678,  0.1450, -1.6296,  ..., -0.3309,  0.5262,  1.7363],\n",
            "        [-0.4080, -2.4669,  0.4855,  ...,  1.7221, -0.5427,  0.5514],\n",
            "        [ 1.6994,  1.7297,  0.2843,  ..., -1.1266, -2.5985,  1.6702],\n",
            "        ...,\n",
            "        [ 1.4965, -0.5707, -0.5111,  ...,  1.3338, -2.2557, -1.7223],\n",
            "        [ 0.3918, -0.6183, -1.2922,  ..., -2.7147, -0.4917,  0.6597],\n",
            "        [ 0.2762,  1.0368,  0.6383,  ..., -0.4756, -0.2067,  0.3584]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0368,  0.8613, -1.3350,  ..., -2.6102,  0.6810, -0.6213],\n",
            "        [-1.1695, -1.4037,  0.6046,  ..., -2.1221,  1.0394,  0.2931],\n",
            "        [ 0.4366, -2.2713, -0.8842,  ..., -0.6459,  0.7194,  1.3597],\n",
            "        ...,\n",
            "        [ 1.0917,  0.0668, -0.2301,  ..., -1.9997, -0.0381,  0.1824],\n",
            "        [ 0.0465,  0.2441,  0.6067,  ..., -2.9596, -1.9439,  1.7772],\n",
            "        [ 1.5497, -0.4585,  0.4120,  ..., -0.5646, -2.3616,  1.3149]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2854, -0.2042,  0.5305,  ..., -0.9007, -0.9695, -0.7952],\n",
            "        [ 1.3062,  1.9833,  0.1153,  ...,  2.0306, -2.0750,  1.8172],\n",
            "        [ 0.6430, -0.2553, -1.3346,  ...,  0.3273,  0.4860,  3.2514],\n",
            "        ...,\n",
            "        [-0.3959,  0.4025, -0.2250,  ..., -0.0302, -1.5260,  2.0657],\n",
            "        [ 1.7843, -0.4734, -2.6243,  ..., -1.2218, -0.8291,  0.7588],\n",
            "        [ 2.5960,  0.6064, -1.6876,  ..., -0.8493,  0.3160, -0.4014]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4352e-01,  5.5873e-01, -8.4948e-01,  ..., -3.4395e+00,\n",
            "         -2.1723e+00,  4.3355e-01],\n",
            "        [ 9.4175e-01,  2.0278e+00,  1.5575e+00,  ...,  2.2215e-02,\n",
            "         -1.5816e+00,  1.0253e+00],\n",
            "        [-1.8471e-01, -3.1915e+00,  4.8153e-01,  ..., -2.7041e+00,\n",
            "          3.2490e-01,  5.6705e-01],\n",
            "        ...,\n",
            "        [ 6.2683e-01, -1.3548e+00, -3.3593e-03,  ..., -1.9295e+00,\n",
            "         -7.8924e-01,  6.2623e-01],\n",
            "        [ 3.0554e+00, -2.6820e+00,  2.5884e+00,  ..., -7.2359e-01,\n",
            "         -2.1904e+00, -1.1130e+00],\n",
            "        [ 4.1484e+00, -7.4771e-02, -1.8674e+00,  ..., -3.0296e+00,\n",
            "         -2.0553e+00,  3.3885e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8496, -2.1089,  2.1920,  ..., -1.0345, -3.0486, -0.9653],\n",
            "        [ 0.8415,  1.3383, -1.9010,  ..., -3.6607,  0.5582, -0.3715],\n",
            "        [ 0.3400, -0.1840,  1.0627,  ..., -2.6011,  0.5071,  1.0331],\n",
            "        ...,\n",
            "        [ 0.6958, -1.1000, -1.8562,  ..., -2.2233, -1.5590,  1.2008],\n",
            "        [ 2.3100, -3.8924,  0.2207,  ..., -0.6572, -0.8835, -0.5063],\n",
            "        [ 0.8881,  0.2681, -0.7250,  ..., -0.1314, -0.6849,  0.8857]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8161,  2.8065,  0.2989,  ..., -1.4328, -1.6767,  3.2477],\n",
            "        [ 0.1285,  1.5546, -2.7221,  ..., -2.9183, -0.0984,  2.7912],\n",
            "        [ 0.1035, -0.3547, -1.7857,  ..., -1.3048, -2.2616,  1.4455],\n",
            "        ...,\n",
            "        [ 1.1319,  0.4122,  0.2129,  ..., -1.8199, -1.8519,  2.9087],\n",
            "        [ 1.2220,  0.6352, -3.1885,  ..., -1.8092,  3.0647,  0.9058],\n",
            "        [ 0.5710, -0.4402, -0.1834,  ..., -2.0345, -0.6137,  0.9615]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6031, -0.4944, -0.2574,  ..., -3.8881, -3.0940,  2.0576],\n",
            "        [ 1.3016, -1.3586, -2.1057,  ..., -1.8733, -1.1814,  0.9113],\n",
            "        [ 0.7114,  0.0692,  0.4088,  ..., -2.2692,  1.9197,  0.3689],\n",
            "        ...,\n",
            "        [-0.4887, -1.7635, -2.7343,  ..., -2.5600,  0.6649,  2.0917],\n",
            "        [ 2.1870, -2.3372, -0.1280,  ..., -0.2809, -1.0231,  0.6399],\n",
            "        [ 2.1708, -0.7285, -1.2995,  ...,  0.2279, -2.9000,  0.3637]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0317,  1.1679, -2.0309,  ...,  0.3246, -0.9300,  2.8138],\n",
            "        [ 2.6525, -1.0281, -0.8796,  ...,  0.4512, -2.4438,  0.9141],\n",
            "        [-0.1582, -1.0829,  2.3537,  ..., -2.3313,  1.6448, -0.3438],\n",
            "        ...,\n",
            "        [ 2.3467,  0.4561, -1.1545,  ...,  0.2407, -0.5860,  1.7147],\n",
            "        [-0.3191,  1.3258, -2.7512,  ..., -2.5745,  2.6730,  0.2797],\n",
            "        [-0.2677,  0.8051, -1.2047,  ..., -2.0349, -2.8827,  2.6907]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1503,  1.5889, -1.9608,  ..., -1.8992, -2.1453,  2.2220],\n",
            "        [-0.8147, -0.4946, -1.2039,  ..., -0.9680, -0.5246, -0.4310],\n",
            "        [-2.3130,  0.1808, -0.4882,  ..., -2.4396, -1.1353,  1.5393],\n",
            "        ...,\n",
            "        [ 0.6064,  1.9967, -1.0589,  ...,  4.0922, -2.9984,  0.1807],\n",
            "        [ 1.2625,  3.1531,  1.2053,  ..., -2.3108, -1.1354,  2.5337],\n",
            "        [ 2.0013,  0.9075, -1.2119,  ..., -2.5366, -2.4608,  0.2554]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1186,  0.0715,  0.2409,  ..., -0.8433,  0.2419,  1.2396],\n",
            "        [-1.4655,  0.3333, -2.2859,  ..., -0.9839,  1.8860,  1.1102],\n",
            "        [ 2.0645, -1.4368, -0.1384,  ...,  0.9382, -4.6554,  1.1613],\n",
            "        ...,\n",
            "        [ 0.2139,  0.8305, -1.4721,  ..., -0.8714,  1.3651,  1.0264],\n",
            "        [-0.6028,  1.8148, -2.3465,  ..., -2.7153, -0.1036,  3.2347],\n",
            "        [-2.1207,  2.0966,  0.2737,  ...,  1.2787, -2.2927,  3.2537]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0938, -0.0365, -1.5107,  ..., -1.8499, -2.0948,  0.9546],\n",
            "        [ 1.5466,  0.9257,  1.1528,  ..., -2.0002, -1.5951,  1.7139],\n",
            "        [ 0.6482,  0.6126,  2.1146,  ...,  0.4069, -1.2721,  1.9443],\n",
            "        ...,\n",
            "        [-1.8461,  0.9043, -3.0406,  ...,  0.1037, -1.6889,  1.7246],\n",
            "        [ 1.1092,  1.6053, -2.7466,  ...,  1.1018, -3.2140,  0.2645],\n",
            "        [ 1.0088, -0.0685, -0.4998,  ..., -3.0050, -0.3679,  0.3116]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2349,  3.8808, -1.6048,  ..., -1.2929, -1.5129,  2.2562],\n",
            "        [-1.0432,  3.1409, -2.9929,  ..., -2.0222, -0.6514,  3.4385],\n",
            "        [-0.0780,  1.6385,  0.1760,  ..., -0.6901, -0.0742,  0.4495],\n",
            "        ...,\n",
            "        [ 2.5010,  5.6247, -2.4938,  ..., -0.3008, -2.5522,  3.4628],\n",
            "        [-0.2620,  0.9284,  0.8957,  ..., -0.7767, -0.1984,  1.4853],\n",
            "        [-1.0203,  2.6635,  0.0413,  ..., -1.0865,  0.0081,  2.5984]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6846,  1.0858, -0.6477,  ..., -2.6041,  1.2303,  1.8765],\n",
            "        [ 1.3783,  0.7141, -1.0176,  ..., -0.8353, -1.5147,  2.1130],\n",
            "        [-0.4268,  2.1295, -0.8882,  ..., -1.4013,  0.9065,  0.6677],\n",
            "        ...,\n",
            "        [-1.7509,  0.3946,  0.1665,  ...,  0.0287, -3.0942,  4.2776],\n",
            "        [-0.8509, -0.3443,  0.0748,  ..., -1.9814, -1.4991,  0.9600],\n",
            "        [-0.3934,  2.3758, -1.4509,  ..., -1.1704, -0.9821,  4.2054]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7285,  2.1482, -0.0571,  ...,  2.8746, -2.1907,  1.8820],\n",
            "        [ 1.5552,  3.3873, -1.0611,  ..., -1.3832, -2.2167,  0.8740],\n",
            "        [-0.5087,  3.5223,  0.8622,  ..., -0.1365, -1.6971,  2.9007],\n",
            "        ...,\n",
            "        [ 0.0797,  0.6258, -1.5494,  ..., -1.2776, -1.0911,  4.0303],\n",
            "        [ 0.3768, -1.5386, -0.0202,  ..., -1.3177, -2.7941,  0.7415],\n",
            "        [ 0.9583,  7.0548, -3.2389,  ..., -2.1633, -2.8087,  3.2154]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4070,  3.6085, -0.8057,  ..., -2.3160, -1.6187,  3.1138],\n",
            "        [-0.8261,  0.4376,  0.1647,  ..., -2.0287,  0.2176,  0.3716],\n",
            "        [-1.4248,  1.4361, -0.9783,  ..., -1.7600, -1.1524,  2.6480],\n",
            "        ...,\n",
            "        [ 0.9098,  0.7207, -2.0570,  ..., -0.3582, -1.4327,  3.0875],\n",
            "        [-0.6697,  1.6713, -1.7717,  ..., -0.7146, -1.1104,  2.2902],\n",
            "        [-0.8724,  0.1305,  0.6150,  ..., -2.0105, -1.8221,  3.0056]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6838,  2.6647,  1.4591,  ..., -2.7739, -0.4427,  2.0305],\n",
            "        [ 0.7169,  3.6834,  1.2176,  ..., -2.2823, -2.5783,  0.7099],\n",
            "        [ 1.7788, -1.5842,  0.9252,  ..., -1.8461, -0.4409, -0.6998],\n",
            "        ...,\n",
            "        [-0.3455,  1.7587, -1.0317,  ...,  0.8336, -1.8369,  3.8739],\n",
            "        [ 0.9302,  4.2651, -0.8117,  ...,  1.7480, -2.2079,  3.3442],\n",
            "        [-2.5801,  1.3878, -3.4546,  ..., -1.6099, -1.9009,  3.0919]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1367,  3.4216, -0.3339,  ...,  0.0386, -2.1861,  6.9414],\n",
            "        [ 0.0213,  0.9223, -0.1310,  ..., -2.0455, -1.1104,  4.8123],\n",
            "        [-2.0042,  1.6029,  0.3432,  ..., -1.5565,  0.9650,  0.6389],\n",
            "        ...,\n",
            "        [-0.9909,  4.4085,  1.0193,  ...,  2.6156, -2.5930,  3.6551],\n",
            "        [-1.7774,  4.5091,  0.8631,  ...,  0.5901, -2.9398,  2.9338],\n",
            "        [ 0.2787,  1.6613, -2.1238,  ...,  0.5913, -1.1090,  2.8020]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3367,  0.3845, -1.0298,  ..., -1.3830, -0.0775,  0.9869],\n",
            "        [-0.2790,  0.5596, -0.5191,  ..., -1.5844, -0.9084,  2.9633],\n",
            "        [ 0.1178,  1.5240,  0.0609,  ..., -2.2630, -2.4403,  1.2982],\n",
            "        ...,\n",
            "        [-1.7120,  0.1133,  3.0072,  ..., -1.0993, -0.2428,  0.0945],\n",
            "        [-2.7161, -0.8688,  3.1682,  ...,  0.0680,  0.4874,  0.5667],\n",
            "        [-0.2967,  0.1283, -1.1913,  ..., -1.7238, -0.4896,  0.8527]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8783, -1.2784,  3.3986,  ..., -1.8330, -0.8527,  0.0471],\n",
            "        [-0.9072,  2.7213,  0.2739,  ..., -2.1001,  0.2342,  0.3492],\n",
            "        [ 0.3738, -0.0250,  2.8708,  ..., -2.5343, -0.1027, -0.0116],\n",
            "        ...,\n",
            "        [ 0.9380,  0.2639, -0.4893,  ..., -3.7853, -3.5206,  1.5707],\n",
            "        [-1.0492,  1.6643, -3.0093,  ...,  0.0218, -1.7562,  4.2680],\n",
            "        [ 1.4508,  0.9125,  0.3409,  ..., -1.5239, -1.9275,  0.9258]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2416, -2.3562,  2.1288,  ...,  1.8696, -3.1941,  0.6132],\n",
            "        [-0.7246,  1.8903, -2.3316,  ..., -1.1978, -1.0936,  3.7077],\n",
            "        [ 0.1905,  0.4840,  1.7762,  ...,  4.7679, -2.2385,  1.6958],\n",
            "        ...,\n",
            "        [ 0.3888,  0.0357, -1.6445,  ...,  0.3458, -2.2344,  2.9128],\n",
            "        [ 0.3512,  0.9559,  0.4861,  ..., -0.9995, -3.7664,  3.2183],\n",
            "        [ 2.2729, -0.9142,  0.7441,  ..., -1.4466, -3.2616,  0.6456]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4886,  0.3100, -2.4734,  ..., -2.2080, -0.0616,  2.8108],\n",
            "        [ 1.8704,  1.7528, -2.9206,  ..., -2.3885, -1.8522,  1.7519],\n",
            "        [-0.8120,  1.2538, -0.6808,  ..., -2.2846, -1.2714,  2.8950],\n",
            "        ...,\n",
            "        [-0.0557,  0.1066,  1.6183,  ..., -1.8571,  0.2317,  0.3495],\n",
            "        [ 0.2117, -0.4150, -0.2392,  ..., -0.7808, -2.5364,  4.1391],\n",
            "        [-1.0455,  1.0613,  3.3778,  ...,  1.2721, -1.1815,  3.7753]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6813,  0.0946, -0.3559,  ..., -2.6493, -0.4018,  3.5391],\n",
            "        [ 0.7788,  2.0248, -0.0584,  ..., -2.5502, -0.4242,  1.6260],\n",
            "        [ 1.1088, -0.9900,  0.0084,  ..., -1.9818, -0.7250,  3.4514],\n",
            "        ...,\n",
            "        [-1.2047,  2.9844,  1.8275,  ...,  0.1210, -1.8443,  2.5154],\n",
            "        [ 1.1031,  0.7777, -0.6433,  ..., -3.8824, -2.5713,  1.6939],\n",
            "        [-0.7672,  3.2333,  0.3902,  ..., -2.2913,  0.9833,  0.9821]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8556,  2.3443, -1.3963,  ..., -0.5901, -2.3477,  4.6084],\n",
            "        [ 0.0198,  1.8423, -0.3550,  ..., -0.6985,  0.4291,  1.4711],\n",
            "        [ 0.1616,  1.4621, -1.2943,  ..., -1.0532,  0.0824,  2.5662],\n",
            "        ...,\n",
            "        [-0.5349,  2.3830,  0.9702,  ..., -1.4166,  0.3639,  1.5625],\n",
            "        [ 0.5463, -1.0073,  0.2409,  ..., -0.8305, -1.1541,  0.5907],\n",
            "        [-0.8319, -1.0936,  3.1733,  ..., -0.5524, -1.8430,  1.5554]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0768,  1.8454, -2.4165,  ..., -1.4474, -1.6997,  3.6736],\n",
            "        [ 0.7618,  0.9637,  0.9342,  ..., -1.4193, -0.1226,  1.9547],\n",
            "        [-1.0034,  1.6885,  0.9786,  ..., -2.4759, -1.0134,  2.5740],\n",
            "        ...,\n",
            "        [-3.0555,  0.1405, -0.2037,  ...,  2.0949, -4.3513,  7.4381],\n",
            "        [-1.3132,  2.7263, -2.3433,  ..., -1.3775, -1.1841,  2.2535],\n",
            "        [-0.4285, -0.5994,  3.1145,  ...,  0.4202, -2.7019,  2.5882]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2181,  2.3626, -0.7367,  ..., -2.6157,  1.0922,  3.4284],\n",
            "        [ 1.1825,  2.5875,  1.5005,  ..., -3.3850,  0.1725,  2.1171],\n",
            "        [-0.5021,  0.0362,  2.5926,  ..., -1.9835, -1.7619,  2.1951],\n",
            "        ...,\n",
            "        [ 0.7269,  1.0425,  1.3667,  ..., -1.6522, -2.6191,  2.2915],\n",
            "        [-0.2827,  0.3384, -1.2348,  ..., -1.9845, -0.8331,  3.5448],\n",
            "        [ 0.6770,  1.4248, -1.7330,  ..., -0.3231, -1.8555,  3.8399]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1523,  0.5392,  2.0890,  ..., -1.9436, -3.4652,  2.8933],\n",
            "        [-0.9937, -0.1485,  3.9156,  ..., -2.2104, -0.8105,  1.0511],\n",
            "        [-0.8929, -0.9385,  2.4086,  ..., -1.1601, -0.5529,  2.3227],\n",
            "        ...,\n",
            "        [-0.8281,  1.2918, -2.0529,  ..., -2.6535,  1.5510,  0.5280],\n",
            "        [ 2.4386,  0.5132,  1.3185,  ..., -2.5167, -4.3074,  0.5906],\n",
            "        [-0.3160,  0.8449, -0.2382,  ..., -2.4170,  0.5401,  0.1697]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2547,  1.3630,  0.1640,  ..., -3.4984, -1.6154,  1.2654],\n",
            "        [-0.9581,  1.7347,  1.3278,  ...,  2.1971, -1.4464,  2.4324],\n",
            "        [ 2.1620,  5.0916, -0.2355,  ..., -2.6509, -3.2787,  2.0902],\n",
            "        ...,\n",
            "        [-1.2710, -0.7325,  2.2113,  ..., -2.3315, -0.7073,  3.6644],\n",
            "        [-0.5316,  0.8561,  1.2420,  ..., -1.5511,  0.0068,  2.5186],\n",
            "        [-0.5131,  2.2494,  3.8366,  ...,  4.0715, -1.1108,  3.6546]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0085, -1.1007, -1.3824,  ..., -2.4953,  0.9279,  2.1181],\n",
            "        [-1.9657,  0.5220, -0.0436,  ..., -2.1345,  1.2898,  0.8765],\n",
            "        [ 0.0919,  1.5252, -0.6043,  ..., -1.0072,  0.2594,  1.8860],\n",
            "        ...,\n",
            "        [-2.4286, -0.3585,  2.8430,  ..., -3.0337, -1.0220,  0.9426],\n",
            "        [ 1.4115,  3.6244, -1.6164,  ..., -2.1272, -0.0098,  0.7348],\n",
            "        [-0.0815,  0.3775,  3.8567,  ..., -1.6027, -2.7767,  1.7274]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2627, -0.3361,  2.1113,  ..., -0.6341, -0.7029,  1.1518],\n",
            "        [ 0.8845,  1.6384,  2.0820,  ..., -0.3737, -4.3710,  2.2301],\n",
            "        [-0.9576,  2.8343,  1.5189,  ..., -1.5774, -2.1424,  4.0917],\n",
            "        ...,\n",
            "        [-0.3202,  1.9537,  0.7520,  ..., -0.5821,  0.9263,  1.3621],\n",
            "        [-2.0024,  3.1852,  0.1670,  ..., -0.2383,  0.1509,  3.1103],\n",
            "        [-0.0080,  0.9312,  1.5774,  ..., -1.3877,  0.7834,  2.5185]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8843,  1.8463,  0.8712,  ..., -2.2658,  2.0422,  0.0977],\n",
            "        [-0.9934,  1.1532,  4.5367,  ...,  5.3722, -2.7523,  2.7037],\n",
            "        [-1.0484,  3.5597, -0.2695,  ...,  3.1704, -1.5528,  1.1517],\n",
            "        ...,\n",
            "        [-0.2272,  1.4487,  1.0144,  ..., -0.0430, -0.4739,  4.4348],\n",
            "        [-0.8248,  2.9051, -0.9867,  ..., -3.6169,  0.9737,  2.5199],\n",
            "        [-0.9533,  2.3359, -1.9248,  ..., -0.2336, -0.8945,  1.7828]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5135,  1.4172, -0.9968,  ..., -1.4163, -0.3482,  1.2974],\n",
            "        [ 1.3198, -2.0635,  0.6137,  ..., -1.4337, -3.1111,  0.9487],\n",
            "        [ 0.4215,  1.0239, -1.9569,  ..., -3.4341,  0.3155,  0.5092],\n",
            "        ...,\n",
            "        [-0.0723,  2.5116, -1.7347,  ..., -1.4673,  0.0324,  2.1629],\n",
            "        [-1.3097, -0.8840,  3.7110,  ..., -0.6136, -1.7729, -0.8729],\n",
            "        [-2.1579,  1.3759,  1.2732,  ...,  3.8189, -2.4997,  2.2678]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1375,  4.7909, -0.6889,  ...,  1.8919, -4.9366,  5.6921],\n",
            "        [ 0.7709,  5.1569,  2.6263,  ...,  0.3567, -3.4837,  5.4679],\n",
            "        [-2.3217,  2.0332,  2.9252,  ...,  3.6333, -0.8803,  4.1572],\n",
            "        ...,\n",
            "        [ 0.8791,  2.5361,  2.3888,  ...,  1.6456, -4.1630,  3.9783],\n",
            "        [ 0.7812,  2.7503,  0.3222,  ...,  2.8579, -2.6873,  0.8698],\n",
            "        [-2.8861,  2.1249,  0.0662,  ..., -0.5306, -1.2179,  5.6063]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8916,  4.7228,  1.9640,  ...,  1.2769, -2.7858,  3.5872],\n",
            "        [-1.1220, -0.5433, -0.6236,  ..., -2.6509,  1.4594, -0.5423],\n",
            "        [-1.4793,  1.4434,  1.1136,  ...,  2.9632, -1.9294,  0.2658],\n",
            "        ...,\n",
            "        [-0.3798,  1.5145,  0.8602,  ..., -0.8324, -1.5364,  1.4313],\n",
            "        [ 3.3229,  3.6511, -0.3583,  ..., -2.0137, -0.0542,  2.4519],\n",
            "        [-0.0541,  1.7214, -2.7731,  ..., -2.0705,  0.6029,  2.5633]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8867,  1.6657,  2.1063,  ...,  2.6396, -2.1959,  1.2847],\n",
            "        [-0.1221,  3.8450, -0.6602,  ..., -0.6129, -0.8773,  4.4487],\n",
            "        [-1.8482,  3.0481,  1.8625,  ..., -1.5914,  1.3527,  1.8895],\n",
            "        ...,\n",
            "        [ 3.1178, -1.5125,  2.5442,  ..., -2.8323, -3.4590, -2.2081],\n",
            "        [-0.6614,  7.0102, -0.1042,  ...,  2.8817, -3.2787,  5.1908],\n",
            "        [-0.4590,  0.5568,  0.6708,  ..., -0.6452, -0.7355,  2.1989]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3235,  2.2968, -0.0088,  ..., -1.7227, -0.7210,  2.4652],\n",
            "        [-1.2754, -1.9445,  3.2236,  ...,  1.8658, -1.7793,  2.5879],\n",
            "        [ 1.3503,  1.8412, -0.1775,  ..., -2.5217, -0.1242,  1.0229],\n",
            "        ...,\n",
            "        [ 0.2305,  0.0447,  1.3412,  ..., -1.2427,  1.0283,  0.8635],\n",
            "        [-0.5376,  1.7744,  3.6330,  ..., -1.3219, -0.0191,  1.9286],\n",
            "        [-0.3609,  0.2169,  3.5475,  ..., -1.8188,  0.0448, -0.2682]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9873,  4.7248,  3.4736,  ..., -0.9419, -2.6983,  5.5766],\n",
            "        [-0.8235,  1.3165, -0.2879,  ..., -1.8313, -2.0989,  3.9138],\n",
            "        [-0.9321,  1.3808,  2.4142,  ..., -2.2847, -1.2419,  3.0731],\n",
            "        ...,\n",
            "        [-1.2724,  1.4872,  2.3894,  ...,  0.4276,  1.5301,  0.0519],\n",
            "        [-3.2303,  2.0523,  1.1667,  ...,  0.5500, -1.6576,  4.8194],\n",
            "        [-1.0434,  4.2313,  2.3001,  ..., -2.9529, -2.2370,  4.6762]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3436e+00,  2.3319e+00,  9.8797e-01,  ..., -4.6745e-02,\n",
            "         -9.0549e-01,  1.8859e-01],\n",
            "        [-6.0524e-01,  7.9768e+00, -4.9506e+00,  ..., -2.3938e+00,\n",
            "         -2.7924e+00,  2.1127e+00],\n",
            "        [ 2.1845e+00,  2.8931e+00, -7.0653e-04,  ...,  3.0859e-01,\n",
            "         -3.0586e+00,  1.7009e-01],\n",
            "        ...,\n",
            "        [ 4.8808e-01,  8.2438e-01,  4.4810e+00,  ..., -2.6620e+00,\n",
            "         -7.8001e-01, -1.0767e+00],\n",
            "        [-2.5328e-01,  2.5586e+00, -1.0759e+00,  ..., -8.2062e-01,\n",
            "         -1.6318e+00,  4.7565e+00],\n",
            "        [ 6.6135e-02,  8.2296e-01,  3.0300e+00,  ..., -1.2223e+00,\n",
            "         -1.4165e+00,  9.0139e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0259,  3.3619, -1.5922,  ..., -3.1635, -0.5309,  1.3903],\n",
            "        [ 0.2923,  4.2723, -0.7865,  ..., -2.9007, -1.5673,  1.6429],\n",
            "        [ 0.4099,  1.0059, -0.7233,  ..., -2.4030, -1.7166,  3.0300],\n",
            "        ...,\n",
            "        [-0.1719, -0.4934,  0.2049,  ..., -2.4123, -0.2462,  3.0716],\n",
            "        [ 0.7384,  4.4825,  3.5401,  ...,  1.2668, -0.0204,  1.2700],\n",
            "        [-0.8760,  1.3188, -0.5158,  ...,  0.7301, -0.9890,  2.0860]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1284,  2.4923,  0.9489,  ..., -2.9150,  1.5593,  4.3158],\n",
            "        [-1.5329,  2.8945,  1.1164,  ..., -0.6294,  1.7232,  0.7469],\n",
            "        [ 1.6112,  3.7125, -2.4693,  ..., -4.2982,  0.5385,  1.5972],\n",
            "        ...,\n",
            "        [ 2.1108,  0.5465,  0.9981,  ..., -2.3497, -4.6761,  1.5391],\n",
            "        [-1.1019,  2.8856,  2.0008,  ...,  1.9100, -1.9424,  2.3633],\n",
            "        [ 1.5644,  3.5213,  2.4300,  ..., -1.3443, -2.5328,  3.3862]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7255,  5.0345,  0.8340,  ...,  0.1300, -3.2846,  7.2212],\n",
            "        [ 0.2172,  0.9195,  3.2742,  ..., -1.7017,  1.0883,  1.1567],\n",
            "        [ 1.6279,  1.3102,  0.2777,  ...,  1.2319, -1.4139,  0.5039],\n",
            "        ...,\n",
            "        [-0.1284,  0.3655,  1.0095,  ..., -1.0611, -0.8486, -0.2652],\n",
            "        [ 1.0844,  0.4755,  3.5134,  ..., -2.0490,  0.1590, -0.2533],\n",
            "        [ 0.0739,  3.9049,  1.4991,  ...,  2.1000, -2.9823,  2.0984]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8827,  1.2929,  4.4732,  ...,  1.2315, -2.3740,  4.9487],\n",
            "        [ 0.2091,  0.5016, -2.4603,  ..., -3.2799, -1.5414,  3.1140],\n",
            "        [ 0.9868,  3.4812, -1.1722,  ..., -2.2823, -1.2948,  0.9962],\n",
            "        ...,\n",
            "        [-0.5298,  3.9278, -0.9702,  ..., -2.0683, -2.3609,  3.8631],\n",
            "        [ 0.4010,  1.8026, -1.4732,  ..., -2.3880, -2.6420,  1.2685],\n",
            "        [-0.3883,  3.9173,  1.3354,  ..., -1.4885, -3.7722,  3.6330]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3100,  3.4150,  2.5918,  ..., -0.0947, -1.6995,  4.0405],\n",
            "        [-1.0164,  1.7196,  1.5574,  ..., -0.6478, -0.8827,  3.7171],\n",
            "        [ 0.0050,  3.7519,  0.2543,  ..., -2.3630,  0.3840,  1.1002],\n",
            "        ...,\n",
            "        [ 0.0997,  4.1556,  0.1692,  ..., -2.0526, -0.7416,  2.3080],\n",
            "        [-1.2418,  3.0529,  1.2361,  ..., -2.3678, -0.6918,  1.6523],\n",
            "        [-1.2931,  2.4934, -0.7290,  ..., -0.4629, -0.0729,  1.9832]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1071,  1.6352, -2.3495,  ..., -2.1839, -0.8597,  0.5402],\n",
            "        [ 1.3701, -1.5598,  3.5416,  ..., -1.1283, -2.6717,  0.1350],\n",
            "        [-0.0449,  0.6106,  2.7425,  ..., -1.3800, -2.5515,  2.7471],\n",
            "        ...,\n",
            "        [ 2.5210, -0.3429, -1.5274,  ..., -1.0470, -2.5694,  1.1280],\n",
            "        [-1.2615,  3.3057,  0.0120,  ..., -2.6371,  1.0380,  0.9477],\n",
            "        [ 1.7419,  1.8632, -0.5829,  ..., -4.6998, -0.6606, -0.0815]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1773,  2.2930,  0.1247,  ..., -2.1033,  0.2865,  0.7789],\n",
            "        [ 0.5097,  3.5942, -1.3677,  ..., -2.7201, -1.1546,  2.7169],\n",
            "        [ 0.8536,  0.2650,  0.2595,  ..., -0.3954, -2.7525,  2.9723],\n",
            "        ...,\n",
            "        [-0.5111,  3.6922,  2.1182,  ...,  4.0031, -2.1714,  1.5724],\n",
            "        [ 0.2983,  3.3053,  0.4354,  ..., -2.9699, -1.1340,  2.6122],\n",
            "        [ 2.5390,  4.5291, -1.4667,  ..., -3.2846, -0.2012,  2.6632]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1857,  3.3586,  0.4311,  ..., -1.5925, -3.2615,  3.1906],\n",
            "        [ 0.3547,  1.2828,  1.2637,  ..., -2.8826, -0.8770,  2.0827],\n",
            "        [ 0.2274,  3.0011, -0.5732,  ..., -1.3244, -0.6883,  2.2415],\n",
            "        ...,\n",
            "        [-0.0736,  6.2409, -2.0370,  ..., -3.3967, -2.7638,  2.6045],\n",
            "        [ 0.3811,  3.6288,  0.2661,  ...,  0.2211, -2.7559,  3.2254],\n",
            "        [-0.7529,  4.1531, -0.6953,  ..., -1.5818,  0.8647,  2.1862]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1867,  4.7723,  2.0853,  ..., -0.7740, -3.1990,  6.6652],\n",
            "        [ 0.9808,  4.1196,  2.6734,  ...,  1.5780, -1.9821,  2.0654],\n",
            "        [ 2.2312,  2.5016,  0.3852,  ...,  2.0402, -3.4951,  2.9774],\n",
            "        ...,\n",
            "        [-0.4475,  1.8239, -1.0212,  ..., -2.6247, -0.0855,  3.5046],\n",
            "        [ 1.2859,  1.7769,  1.5701,  ..., -2.7686, -0.4842,  3.4658],\n",
            "        [ 0.5749,  2.3730,  0.8221,  ..., -1.9751, -1.2386,  1.2121]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9332,  2.7296, -0.7459,  ...,  0.6966, -1.9496,  2.9500],\n",
            "        [-0.5223,  1.2167, -1.1342,  ..., -1.3441, -1.3963,  1.2967],\n",
            "        [-1.1071,  1.0280,  1.7205,  ...,  0.0611, -3.1477,  0.2104],\n",
            "        ...,\n",
            "        [ 0.1334,  4.9766,  0.0206,  ..., -0.4420, -1.5020,  2.7243],\n",
            "        [ 0.8697,  1.1405,  2.9490,  ...,  0.1337, -3.2171,  4.4479],\n",
            "        [-0.9930,  2.0840,  1.4050,  ..., -1.7159, -2.4837,  3.0252]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5774,  4.3993,  2.0379,  ...,  1.0931, -1.0440,  1.3404],\n",
            "        [ 0.4243,  1.9501,  1.7123,  ..., -1.6408, -0.3526,  1.6805],\n",
            "        [ 1.3130,  4.9129, -2.2848,  ..., -1.6783, -3.4112,  2.1309],\n",
            "        ...,\n",
            "        [ 1.1999, -0.3594, -0.2819,  ..., -2.9180, -3.2550,  1.8116],\n",
            "        [-1.2450,  3.1261, -0.4106,  ...,  2.7451, -1.9313,  0.9540],\n",
            "        [-0.0390,  1.7768, -0.1573,  ..., -1.4483,  0.2275,  0.5960]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4959,  2.3563, -0.2584,  ..., -1.2016, -1.4964,  4.1938],\n",
            "        [ 2.2793, -0.7311,  1.8851,  ..., -0.9583, -2.0474, -0.4608],\n",
            "        [-0.1564,  0.2313,  3.9868,  ...,  0.3580, -4.2337,  1.3751],\n",
            "        ...,\n",
            "        [ 0.2576,  4.3417,  0.2144,  ..., -4.3254,  1.1397,  3.0021],\n",
            "        [-0.8054,  4.0627,  0.4138,  ..., -1.0248,  0.5941,  2.8237],\n",
            "        [ 0.5652,  4.0148, -0.2014,  ..., -2.3544, -1.0653,  2.4902]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4256,  2.9177,  2.3105,  ..., -1.9304, -1.0874,  4.0786],\n",
            "        [ 1.1624,  3.1826, -0.6581,  ..., -2.8483, -1.8616,  2.4326],\n",
            "        [-0.8733,  3.4069, -2.3625,  ..., -3.7720, -0.5683,  2.6539],\n",
            "        ...,\n",
            "        [-0.0203,  9.7958, -0.5986,  ...,  0.1099, -3.5428,  5.4107],\n",
            "        [ 3.0168,  1.4096,  0.1226,  ..., -0.7963, -5.0961,  3.6943],\n",
            "        [ 0.0388,  3.2284,  0.9456,  ..., -1.2728, -0.2731,  2.2837]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1208,  7.7037,  0.0559,  ..., -1.0934, -2.6911,  4.4870],\n",
            "        [-2.2995,  4.8498, -1.2719,  ..., -0.6957, -1.1757,  3.1709],\n",
            "        [ 1.7508, -0.6100,  2.8714,  ..., -1.0729, -1.8625, -1.9217],\n",
            "        ...,\n",
            "        [ 1.5315,  2.3426,  0.4276,  ..., -2.8957, -0.6239,  0.9600],\n",
            "        [-1.0902,  2.6128, -0.1201,  ..., -0.2557, -3.2561,  5.0032],\n",
            "        [-0.0548,  0.4535,  7.4524,  ..., -0.7475, -2.0496, -2.2463]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8622, -1.6190,  1.4914,  ...,  0.1590, -3.2249,  0.3418],\n",
            "        [ 0.0350,  2.5136, -0.1640,  ..., -1.8049,  0.3385,  3.7113],\n",
            "        [ 0.0191,  4.6708, -1.1350,  ..., -1.7012, -0.6194,  2.3987],\n",
            "        ...,\n",
            "        [ 0.7494,  0.1671,  1.2832,  ..., -0.5028, -1.8587,  1.2345],\n",
            "        [-0.8105, -0.7861,  6.0407,  ...,  2.0103, -1.3125, -2.2516],\n",
            "        [ 0.5133,  1.5315,  0.5546,  ..., -1.8370, -0.0835,  0.0617]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0683,  4.8207,  1.1286,  ..., -0.4289, -1.8405,  3.8532],\n",
            "        [-1.5546,  4.6531, -2.4701,  ..., -2.1759, -0.6372,  2.8263],\n",
            "        [-1.6584,  1.6701,  1.9395,  ..., -2.9368,  0.1118,  1.5481],\n",
            "        ...,\n",
            "        [-1.7662,  6.7703,  0.8006,  ...,  1.6319, -0.7114,  4.3566],\n",
            "        [ 3.2437,  1.2313, -1.0291,  ..., -1.5567, -4.6106,  0.6047],\n",
            "        [ 0.3233,  1.4297,  1.4109,  ..., -0.8660, -0.6134,  0.7645]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2523,  2.2238, -2.0046,  ..., -1.5001, -2.0408,  2.0839],\n",
            "        [ 0.7289,  3.6835, -0.1684,  ..., -1.2569, -2.0239,  3.1731],\n",
            "        [-1.1569,  4.8125,  0.4731,  ..., -1.1875, -2.2743,  5.5808],\n",
            "        ...,\n",
            "        [-0.8015, -0.3637,  1.2430,  ..., -0.4755, -0.8043,  2.2997],\n",
            "        [ 0.1797,  1.4474,  0.2391,  ...,  0.3594,  0.2911,  1.1870],\n",
            "        [ 0.5385,  5.1436, -4.8023,  ..., -3.0167, -2.1243,  4.0231]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5574,  1.0189,  2.3391,  ..., -0.9525, -1.2722,  1.8466],\n",
            "        [ 1.1575, -0.1853,  3.2836,  ..., -1.8191, -2.1966,  2.8993],\n",
            "        [-1.2197,  2.1471,  2.8269,  ..., -1.4664, -2.6609,  3.3245],\n",
            "        ...,\n",
            "        [ 1.3522,  0.0466,  4.5031,  ..., -1.9585, -3.1742, -0.4177],\n",
            "        [-0.3759,  1.5034,  0.5697,  ..., -1.7093,  0.6369,  1.1265],\n",
            "        [ 3.0013,  3.5674, -0.2973,  ...,  0.5921, -0.7385,  3.3372]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9137,  2.2569, -2.0780,  ..., -1.9370, -1.4485,  3.2762],\n",
            "        [ 0.2365,  1.9568, -0.7657,  ..., -0.4107,  0.3528,  2.2854],\n",
            "        [ 0.2165,  0.2078,  0.6364,  ..., -1.8178,  0.4758,  2.1338],\n",
            "        ...,\n",
            "        [ 0.6087,  2.0015,  0.4319,  ..., -1.0756, -0.0510,  1.4404],\n",
            "        [ 0.2753,  3.7303,  2.0077,  ...,  1.9660, -5.0766,  2.6287],\n",
            "        [ 3.1970,  3.1147, -2.2674,  ..., -2.9302, -0.5323,  1.5311]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1098,  2.8955,  1.3243,  ..., -1.8731, -0.6780,  3.3988],\n",
            "        [-0.3253,  1.0442,  1.1549,  ..., -3.4344, -2.1130,  1.3431],\n",
            "        [-1.0612,  4.4945, -0.8262,  ..., -1.0668, -2.7903,  5.1309],\n",
            "        ...,\n",
            "        [-0.3587,  2.4021,  0.9644,  ...,  0.7654, -2.7139,  2.0511],\n",
            "        [-1.5704,  4.4630,  1.1937,  ..., -2.4151, -1.3833,  7.5977],\n",
            "        [ 0.9148,  0.1893, -0.2439,  ..., -3.5184, -0.3000,  1.7734]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8853,  6.4043, -0.6429,  ..., -0.9628, -0.2906,  1.8669],\n",
            "        [-1.7128,  4.4649,  0.8192,  ..., -1.8588, -2.6244,  6.7216],\n",
            "        [ 2.9025,  4.4485,  0.3295,  ..., -2.5707,  2.1569,  0.4287],\n",
            "        ...,\n",
            "        [-0.3579,  0.8814, -0.3337,  ..., -0.1016, -2.1233,  1.6492],\n",
            "        [-1.5662,  3.0255, -3.0000,  ..., -2.0744, -1.9609,  2.4961],\n",
            "        [ 1.0436,  6.4828, -1.4496,  ...,  0.5741, -3.7196,  3.6217]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1515,  1.2034, -1.1058,  ..., -2.8547,  2.1294,  2.1138],\n",
            "        [-2.2625,  8.0638,  2.5702,  ...,  1.1508, -0.4169,  8.3278],\n",
            "        [-1.3414,  5.0700, -0.3297,  ..., -3.0418, -2.1971,  5.8287],\n",
            "        ...,\n",
            "        [-0.5368,  5.5376, -0.9577,  ...,  1.5658,  0.7172,  3.0560],\n",
            "        [-1.5501,  2.8761,  2.5153,  ...,  0.3269, -3.4171,  2.6392],\n",
            "        [ 0.9492,  0.7822, -1.0956,  ..., -1.6460, -2.1969,  2.2116]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0766, -0.1681,  2.8607,  ...,  1.5103, -3.7770,  0.6547],\n",
            "        [-0.7901,  6.3742, -2.4770,  ..., -1.4379, -1.7441,  4.6026],\n",
            "        [-0.8717,  4.6031,  1.0229,  ..., -0.2106, -3.0184,  6.4621],\n",
            "        ...,\n",
            "        [ 2.1762,  3.2670, -1.2033,  ..., -0.0404, -3.1558,  2.6442],\n",
            "        [-0.8495,  2.9986, -3.4998,  ...,  1.7747, -2.8532,  4.1722],\n",
            "        [ 0.0301,  2.0781,  0.8830,  ..., -0.2217, -3.0854,  3.0676]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9151,  0.8274,  1.7468,  ..., -1.7202, -2.1015,  3.6089],\n",
            "        [ 0.0684,  3.2545,  0.8805,  ..., -0.4550, -3.4731,  2.2340],\n",
            "        [ 0.4342,  3.2212,  2.6235,  ..., -2.0921, -2.2773,  3.1529],\n",
            "        ...,\n",
            "        [ 3.1183, -0.1621, -1.8108,  ..., -4.4890, -0.3477,  1.0510],\n",
            "        [ 1.2545,  0.0238,  5.7216,  ..., -4.1723, -1.6409,  0.1659],\n",
            "        [ 0.6507,  2.1629,  1.4971,  ..., -1.6479, -2.6202,  5.5723]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1005,  2.3385,  2.0509,  ..., -2.5776, -2.0514,  5.7002],\n",
            "        [ 0.0531,  1.3793,  2.6790,  ..., -0.9555, -2.5418,  2.7422],\n",
            "        [ 1.3228,  0.5507,  2.4550,  ...,  0.1259, -3.1934,  1.4344],\n",
            "        ...,\n",
            "        [ 0.4683,  2.0024, -2.1313,  ..., -1.4942, -3.2734,  1.4468],\n",
            "        [ 1.7838, -0.3782,  1.0597,  ..., -2.1084, -3.0830,  1.9022],\n",
            "        [ 1.8248,  1.7526,  2.1109,  ...,  3.0379, -3.1151,  2.1144]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5181,  0.7599,  4.2469,  ..., -2.2596,  0.2727,  0.1254],\n",
            "        [ 0.6736,  1.9523,  0.1181,  ..., -0.0637, -2.3688,  2.0061],\n",
            "        [-0.0439,  8.0395, -3.8051,  ..., -1.8118, -4.4322,  5.8973],\n",
            "        ...,\n",
            "        [-0.5157,  0.7282,  0.3943,  ..., -2.5427, -0.5105,  2.2172],\n",
            "        [ 0.6203,  2.1719,  1.5116,  ..., -2.7650, -1.1467,  4.4448],\n",
            "        [ 0.2754,  2.5445, -1.9614,  ..., -1.0243, -3.1529,  2.4343]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4558,  1.6749,  5.8568,  ..., -1.1560, -2.4159,  1.1435],\n",
            "        [ 0.5110,  2.2603,  2.3978,  ...,  0.4431, -0.3861,  1.6597],\n",
            "        [ 2.7592,  3.5037,  0.6960,  ..., -2.3155, -1.8850,  2.5072],\n",
            "        ...,\n",
            "        [ 0.5854,  2.8724, -1.3390,  ..., -2.1405, -0.6611,  3.5514],\n",
            "        [-0.3094,  7.1536,  1.5849,  ...,  0.0555, -3.4170,  2.9376],\n",
            "        [ 0.4272,  0.1867,  1.7668,  ..., -2.3563, -0.0098,  2.0373]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2424,  5.0536, -0.4563,  ...,  1.4141,  0.1941,  4.9313],\n",
            "        [-1.8079,  4.6727,  0.3536,  ..., -0.4829, -3.1989,  8.0618],\n",
            "        [-0.6864,  2.9327,  0.4276,  ..., -2.9525,  1.0724,  0.9110],\n",
            "        ...,\n",
            "        [ 3.1218,  0.1216,  3.6575,  ..., -3.2716, -3.3277,  0.7601],\n",
            "        [ 0.8672,  1.4580,  2.8671,  ...,  1.7477, -5.7906,  2.6386],\n",
            "        [ 4.0223,  3.6051, -1.3944,  ..., -2.7843, -1.3174,  2.3893]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3134, -0.3391,  1.8129,  ...,  0.2843, -1.5272,  2.1366],\n",
            "        [-0.8701,  9.3198, -1.1949,  ..., -0.8071, -1.3135,  6.1193],\n",
            "        [ 1.7341,  6.2071,  1.7562,  ..., -1.1162, -1.0306,  1.3992],\n",
            "        ...,\n",
            "        [-0.5873,  1.9947,  2.7122,  ...,  2.4334, -4.0273,  3.5329],\n",
            "        [-0.1211,  2.7915, -1.5038,  ..., -2.3014, -1.7913,  2.3390],\n",
            "        [-0.5494,  0.9922,  4.7202,  ...,  1.6390, -2.3758,  2.7543]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2292, -1.9052,  1.6120,  ..., -1.1838, -3.8850,  0.6110],\n",
            "        [ 2.0783,  6.1994, -0.2298,  ..., -1.8001,  0.3189,  2.0964],\n",
            "        [ 0.5299,  2.2793, -0.7345,  ..., -1.7540, -1.8107,  4.6947],\n",
            "        ...,\n",
            "        [-1.1179,  4.8749,  0.4908,  ..., -2.2390, -1.6073,  3.9691],\n",
            "        [ 0.5511,  7.2797, -2.0131,  ...,  0.2841, -2.5856,  5.7123],\n",
            "        [ 2.2292, -1.5325,  2.4522,  ..., -3.8948, -2.9265,  0.6575]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7120, -0.4019,  4.2542,  ..., -0.5169, -2.4877, -2.0375],\n",
            "        [-0.0636,  2.9625,  2.9896,  ..., -2.2071, -2.4472,  4.8118],\n",
            "        [-0.2628,  2.2044,  1.7156,  ..., -1.0049,  0.5692,  2.9201],\n",
            "        ...,\n",
            "        [-3.1561,  4.6453, -1.2405,  ..., -1.4291,  0.9887,  2.3715],\n",
            "        [ 1.0183,  0.0237,  0.4075,  ..., -3.1652, -0.8379,  1.3062],\n",
            "        [-0.3811,  3.3997,  0.8146,  ..., -1.8903,  1.0505,  3.8923]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6832,  2.5739, -0.4753,  ..., -1.3351,  0.8143,  1.6894],\n",
            "        [ 2.4175, -1.5322,  2.6059,  ..., -1.9800, -4.0332, -1.2596],\n",
            "        [-2.6702,  2.4097, -0.0372,  ..., -0.9195, -0.5720,  2.6250],\n",
            "        ...,\n",
            "        [-0.7016,  1.1217,  3.8580,  ..., -0.6414, -0.4339, -0.7206],\n",
            "        [ 1.4836,  4.6855,  2.9671,  ...,  4.4965, -2.7680,  2.2218],\n",
            "        [ 1.5780,  3.9053, -0.3885,  ..., -2.3050, -1.7583,  5.7464]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5715,  0.6493, -2.4653,  ..., -3.9050, -0.0356,  3.0162],\n",
            "        [ 1.4136,  4.5896,  0.2126,  ...,  2.4193, -3.5959,  2.8059],\n",
            "        [ 0.1048,  1.0924, -1.7718,  ..., -1.1103, -1.8192,  2.4651],\n",
            "        ...,\n",
            "        [ 0.6724, -0.9081,  2.5736,  ..., -3.4402,  0.1052,  0.2138],\n",
            "        [-1.8032,  5.5890,  1.6859,  ..., -0.6542, -2.9550,  6.7226],\n",
            "        [ 1.5276,  0.2433,  0.9583,  ..., -1.6676, -1.1640,  1.3689]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5270,  6.3392, -0.0170,  ..., -4.1022, -1.2733,  6.1640],\n",
            "        [-1.7911,  1.0909,  2.7320,  ...,  4.1485, -1.5718,  1.9126],\n",
            "        [-0.3218,  0.6980,  5.5214,  ..., -2.0329,  0.1763, -0.0873],\n",
            "        ...,\n",
            "        [-2.8433,  6.6922,  0.3097,  ..., -0.9075, -0.5733,  5.0918],\n",
            "        [-1.2445,  1.4315,  4.7007,  ..., -1.1165, -0.2560, -1.1970],\n",
            "        [ 1.8627,  0.0802, -1.0968,  ..., -3.5713, -1.5858,  1.5753]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6693,  2.0133, -0.4044,  ..., -1.9923, -0.5556,  1.5437],\n",
            "        [ 1.9208,  0.7151,  0.6098,  ..., -2.8153, -2.7294,  2.6604],\n",
            "        [ 0.0931,  5.1503,  0.9965,  ..., -1.7438,  0.5782,  2.0427],\n",
            "        ...,\n",
            "        [-1.7284,  3.8949,  1.3372,  ..., -1.6877, -2.4732,  7.0608],\n",
            "        [ 0.4083,  4.0181,  0.1223,  ..., -2.0280, -0.9905,  2.9522],\n",
            "        [ 0.6124, -0.7298,  4.4341,  ..., -2.4678, -3.4107, -0.3646]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ae5150dd2d349a7a719afe1e9a13be1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.2018, -0.3723,  5.4484,  ...,  3.5637, -2.5487,  0.3547],\n",
            "        [-1.2748,  6.0983, -2.0380,  ...,  0.0209, -1.6081,  3.7502],\n",
            "        [ 1.3987, -0.0599, -0.7541,  ..., -2.3294, -1.0232,  0.4877],\n",
            "        ...,\n",
            "        [ 0.1575, -1.4456,  0.7701,  ..., -4.5413, -0.3340,  1.2213],\n",
            "        [ 4.4342,  4.0018, -0.5442,  ..., -2.7373, -1.9606,  2.8869],\n",
            "        [-0.0873,  3.2530, -1.8593,  ..., -2.3642, -0.9024,  1.5669]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8293,  3.7957, -0.7504,  ...,  2.2915, -1.8183,  1.6646],\n",
            "        [ 0.9844, -0.5229,  2.9952,  ..., -2.9270, -0.6970, -0.9759],\n",
            "        [-0.7946, -0.4657, -1.7391,  ..., -2.5317, -0.0746,  2.4765],\n",
            "        ...,\n",
            "        [-0.8092,  0.5402,  5.0177,  ..., -0.7119, -0.6493,  1.5135],\n",
            "        [-0.8184,  0.8732, -0.7411,  ..., -0.6576, -0.9661,  3.3016],\n",
            "        [-1.8240,  4.0590,  0.8619,  ...,  0.9611, -0.7597,  1.6446]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6133,  3.8879,  2.7193,  ...,  2.5315, -0.7326,  2.7345],\n",
            "        [ 1.5471,  1.9610, -2.9027,  ..., -3.5655, -1.5885,  4.1247],\n",
            "        [-0.5930, -0.2915,  0.2678,  ..., -1.3638, -0.6427,  2.1030],\n",
            "        ...,\n",
            "        [-0.1522,  2.1729, -1.5026,  ..., -0.9181, -0.2509,  1.8009],\n",
            "        [-1.5465,  3.2630,  3.0443,  ...,  0.9155, -2.8680,  5.5933],\n",
            "        [-1.5433,  3.2216,  2.3009,  ...,  4.1631, -0.9169,  3.6286]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2719, -1.4008,  6.5977,  ...,  0.7451, -2.2836, -0.3059],\n",
            "        [-2.9224,  5.8733, -1.2388,  ..., -0.8852, -0.6501,  3.2643],\n",
            "        [-0.5521,  1.2080, -1.1500,  ..., -1.0531, -1.6087,  4.0528],\n",
            "        ...,\n",
            "        [-1.2518,  0.7060,  5.3508,  ...,  0.5204, -2.6669, -0.4291],\n",
            "        [-1.6022,  2.0568, -0.4574,  ..., -2.2291,  0.1243,  2.7082],\n",
            "        [-0.9197,  2.0894,  4.3372,  ...,  2.1186, -3.6571,  4.0891]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8425,  2.8434, -1.5751,  ..., -0.8929, -0.7083,  6.0893],\n",
            "        [ 0.1652,  2.8417, -0.4923,  ..., -2.7903, -0.3363,  3.0459],\n",
            "        [-1.8151,  1.3887,  0.5093,  ..., -4.1342,  0.1110,  1.5782],\n",
            "        ...,\n",
            "        [-1.2063,  2.4874, -0.0624,  ..., -1.7384, -2.2015,  4.8298],\n",
            "        [ 0.9232,  2.7111, -0.1536,  ..., -3.5133, -0.1827,  3.1259],\n",
            "        [ 0.3085,  0.8720,  0.6528,  ..., -2.6795, -2.2445,  2.4442]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9448,  2.7254,  4.9190,  ...,  1.5527, -1.9382,  4.0336],\n",
            "        [-2.1208,  0.4539,  2.6142,  ..., -2.3015,  1.3336,  0.0244],\n",
            "        [-0.2051, -0.1561,  1.6862,  ..., -2.4760, -1.1512,  3.3158],\n",
            "        ...,\n",
            "        [ 4.3598,  3.3313,  0.3510,  ..., -1.8980, -0.0810,  1.7117],\n",
            "        [-1.8018,  3.7064,  0.4540,  ..., -0.3084, -0.6945,  3.8927],\n",
            "        [-3.0878,  2.8444, -0.6028,  ..., -1.1564,  0.7302,  0.9835]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2937,  4.6978,  2.2572,  ...,  1.5402, -2.5580,  1.3345],\n",
            "        [ 0.4196,  6.6508,  0.3374,  ...,  0.9316, -3.4882,  4.7445],\n",
            "        [-1.1706,  1.2239,  4.4259,  ..., -1.5314,  0.7575, -0.3739],\n",
            "        ...,\n",
            "        [-0.9857,  1.3995,  0.5851,  ..., -1.7539,  0.5221,  3.6603],\n",
            "        [-0.7850,  1.5625, -1.6010,  ..., -1.7262,  0.5801,  3.8570],\n",
            "        [ 0.9210,  1.0655,  4.2056,  ..., -2.8185, -2.0285, -1.6789]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2306e+00,  7.4653e+00, -2.8070e+00,  ..., -1.4154e+00,\n",
            "         -3.5363e+00,  3.3681e+00],\n",
            "        [-1.0323e+00,  6.5035e-03,  2.4161e+00,  ..., -2.8630e+00,\n",
            "          9.3167e-01, -3.0111e-01],\n",
            "        [-1.8902e+00,  4.1119e+00, -4.6283e-01,  ..., -4.7920e+00,\n",
            "         -5.2234e-02,  4.4245e+00],\n",
            "        ...,\n",
            "        [-2.0402e+00, -2.2066e-01,  3.2926e+00,  ..., -1.1097e+00,\n",
            "         -1.3815e+00,  2.1544e+00],\n",
            "        [-7.1648e-01,  2.4284e+00,  1.0398e+00,  ..., -7.2262e-01,\n",
            "         -3.4677e-01,  5.5016e+00],\n",
            "        [ 1.6580e-01,  6.2714e-01,  2.4012e+00,  ..., -4.5984e-01,\n",
            "         -2.1846e+00,  4.5297e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9189e-01,  3.0923e-03,  3.5188e+00,  ..., -3.2275e+00,\n",
            "         -9.4898e-01, -3.6613e-01],\n",
            "        [ 1.2607e-01,  4.8435e+00, -2.0547e+00,  ..., -5.9113e-01,\n",
            "         -5.6033e-01,  3.0640e+00],\n",
            "        [-1.1208e+00,  3.8883e+00, -5.8159e-01,  ..., -3.9411e+00,\n",
            "         -9.5183e-01,  2.1771e+00],\n",
            "        ...,\n",
            "        [-2.2898e+00,  3.8181e+00, -2.7634e+00,  ..., -3.8419e+00,\n",
            "          7.8833e-01,  1.0031e+00],\n",
            "        [-1.6027e+00,  4.9757e+00, -1.2055e+00,  ...,  1.7090e+00,\n",
            "         -2.0490e+00,  3.0719e+00],\n",
            "        [ 1.7223e+00, -7.0308e-01, -4.1639e-01,  ..., -3.8480e+00,\n",
            "         -2.3337e+00,  9.3248e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1286, -0.2466,  1.5482,  ..., -1.5984,  1.2923,  1.1535],\n",
            "        [ 0.2857,  2.2715, -3.1336,  ..., -2.7749, -0.2342,  4.0175],\n",
            "        [ 1.4639,  1.7479,  0.6274,  ..., -2.5405, -0.6834,  0.8286],\n",
            "        ...,\n",
            "        [ 1.1356,  2.8027, -0.0934,  ..., -0.4594, -3.6382,  3.4429],\n",
            "        [ 0.1815,  4.1745, -0.7164,  ..., -3.5505, -1.2624,  3.4710],\n",
            "        [-0.7971,  2.7553,  3.4973,  ..., -1.7953, -1.8931,  5.1982]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.8161,  6.0265, -0.5669,  ...,  0.0840,  0.5388,  5.3443],\n",
            "        [-0.0096,  2.9572, -1.3444,  ..., -0.9792,  0.1759,  2.3481],\n",
            "        [ 1.0896,  3.5722,  0.9886,  ...,  1.0408, -1.8438,  2.0418],\n",
            "        ...,\n",
            "        [ 0.1365,  3.0657,  2.1109,  ..., -3.1942,  1.2747,  1.1372],\n",
            "        [-0.9588,  0.1627, -0.2007,  ..., -0.2393, -1.0635,  2.1375],\n",
            "        [-2.6402,  3.0535,  1.3694,  ..., -1.7834, -1.9994,  5.1171]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3436,  0.8825,  1.0456,  ..., -2.9246, -1.9930,  2.0704],\n",
            "        [ 0.2740, -1.7461,  1.9536,  ..., -3.7902, -1.6301,  0.9101],\n",
            "        [-1.1305,  3.6984,  3.3367,  ...,  1.6638, -0.0761,  3.9076],\n",
            "        ...,\n",
            "        [-0.6833,  3.8028,  1.8233,  ...,  0.7493, -2.4775,  1.1318],\n",
            "        [ 1.0873,  3.0687,  0.0285,  ..., -2.5687,  0.0962,  2.1765],\n",
            "        [ 0.1964,  4.3015,  0.8504,  ...,  0.5261, -2.8340,  0.6530]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7776e-01,  1.9153e+00, -1.5425e+00,  ..., -1.7622e+00,\n",
            "         -1.8346e+00,  4.5983e+00],\n",
            "        [ 2.6416e+00, -3.7112e-01,  4.9900e-02,  ..., -3.2353e+00,\n",
            "         -3.1346e+00,  3.6880e-02],\n",
            "        [ 2.0021e-01,  1.2198e+00,  1.8809e+00,  ..., -1.3825e+00,\n",
            "          4.1277e-01,  1.1050e+00],\n",
            "        ...,\n",
            "        [ 1.8893e+00,  6.8838e+00, -1.2877e+00,  ..., -1.3816e+00,\n",
            "         -2.2296e+00,  4.7809e+00],\n",
            "        [ 2.0136e+00,  2.5979e-03, -2.8285e-02,  ..., -1.1528e+00,\n",
            "         -4.4183e+00,  2.2316e+00],\n",
            "        [ 1.6725e+00,  6.2334e+00, -1.6056e-01,  ..., -8.5743e-01,\n",
            "         -4.3939e+00,  4.9143e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3912,  1.6633, -0.7766,  ..., -2.1412, -2.0955,  2.2711],\n",
            "        [ 0.4833,  0.6495,  0.8904,  ...,  0.8005, -4.8115,  3.0160],\n",
            "        [ 0.8560,  2.8230, -0.2985,  ..., -1.7321, -1.8652,  2.7588],\n",
            "        ...,\n",
            "        [-1.9821,  1.1984,  0.4258,  ...,  0.0202, -1.8996,  4.3430],\n",
            "        [ 0.9415,  3.3874, -0.5412,  ..., -3.3978, -1.4202,  2.7311],\n",
            "        [-3.4177,  3.2694,  0.8902,  ...,  1.3963, -3.2086,  4.9223]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6832,  3.9898,  0.3929,  ..., -2.3265, -2.3733,  6.7572],\n",
            "        [-1.1034,  1.5154, -1.2166,  ..., -1.4082, -0.7180,  2.8097],\n",
            "        [ 0.7801,  0.0329, -1.8951,  ..., -4.1345,  1.2286,  1.7577],\n",
            "        ...,\n",
            "        [ 0.1539,  3.2056, -0.7530,  ..., -1.8618, -0.3815,  1.2049],\n",
            "        [-0.6827,  6.0942,  4.2121,  ...,  1.0769, -1.7916,  5.6876],\n",
            "        [-0.0787,  0.2162,  3.0940,  ..., -3.5870,  0.2461,  2.1013]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4158,  1.8832,  3.6108,  ..., -1.2128, -2.9703,  3.5388],\n",
            "        [ 0.2803,  0.7690, -3.2937,  ..., -4.1873,  0.0528,  1.9942],\n",
            "        [-1.3300,  4.7959,  1.3146,  ..., -1.6076, -2.4431,  5.6375],\n",
            "        ...,\n",
            "        [-0.8192,  1.0976,  1.0394,  ..., -4.3137, -1.7389,  1.6060],\n",
            "        [ 0.2780,  2.0496,  0.0653,  ..., -0.2655, -2.2495,  2.0816],\n",
            "        [-0.3726,  3.9103,  0.4695,  ..., -2.4323, -0.0906,  0.8293]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6561,  1.7232,  2.5921,  ..., -2.7782, -2.7782,  3.2699],\n",
            "        [-0.8810,  2.7311, -1.5118,  ..., -2.8094,  1.4207,  3.9161],\n",
            "        [-2.1094,  3.1271, -0.3608,  ..., -2.3645, -2.0478,  4.6943],\n",
            "        ...,\n",
            "        [-2.0869, -0.6916,  2.2041,  ..., -4.6107, -0.0580,  2.5555],\n",
            "        [-1.6005,  1.7630,  2.1998,  ..., -2.1894, -0.5566,  1.1224],\n",
            "        [-2.3869,  3.8278, -0.8180,  ..., -0.7718,  0.3218,  3.9093]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4218, -0.6122,  3.5194,  ..., -3.3869, -2.6433,  0.5093],\n",
            "        [ 0.4888,  4.2833,  1.3222,  ..., -1.3844, -0.8503,  6.7999],\n",
            "        [-0.8491,  3.3641,  1.7567,  ...,  2.8177, -4.0783,  1.4153],\n",
            "        ...,\n",
            "        [ 0.8237,  2.5186,  2.1411,  ..., -3.9221,  0.8510,  2.3200],\n",
            "        [ 0.8782,  3.3850,  2.7174,  ...,  2.9341, -0.0373,  1.6970],\n",
            "        [ 0.9929,  0.9458, -0.8798,  ..., -1.8281, -0.8352,  3.6293]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3696,  2.3772, -0.2810,  ..., -3.6613, -2.8437,  4.6643],\n",
            "        [ 3.0139,  5.2618,  1.1924,  ..., -1.7216, -3.3222,  4.4768],\n",
            "        [ 1.5627,  1.7721, -0.8217,  ..., -3.1027, -1.9746,  0.9615],\n",
            "        ...,\n",
            "        [ 1.2194,  1.4749, -1.9408,  ..., -6.2308, -0.3713,  4.0433],\n",
            "        [ 1.2850,  0.2820,  2.0191,  ..., -1.4647, -2.3964,  4.1238],\n",
            "        [ 0.4713,  3.2327, -0.6071,  ..., -1.9435, -1.0515,  2.3855]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0844,  3.3053,  2.0866,  ...,  1.9662, -2.9018,  4.5365],\n",
            "        [-0.5239,  2.0693,  3.2261,  ..., -0.7438, -2.3770,  5.1832],\n",
            "        [-1.5225,  0.9821,  0.9170,  ..., -1.9131, -2.3357,  3.3639],\n",
            "        ...,\n",
            "        [ 3.1508,  3.4050, -0.1370,  ..., -2.9848, -2.3504,  3.7736],\n",
            "        [-2.4316,  5.1845,  3.7265,  ...,  3.0944, -1.4312,  3.9034],\n",
            "        [-0.8464,  1.7996, -0.6397,  ..., -1.9643,  0.8613,  1.0329]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4033,  0.4795,  0.2847,  ..., -2.5365,  1.5356,  2.7685],\n",
            "        [-1.5280,  3.8805,  1.9992,  ..., -2.5616, -1.5450,  6.5004],\n",
            "        [ 1.3911,  0.9596, -2.7272,  ..., -4.4882,  0.2060,  0.1561],\n",
            "        ...,\n",
            "        [-1.4652,  3.8073,  0.5899,  ..., -1.3282,  1.8080,  2.3448],\n",
            "        [-1.6989,  2.5151, -0.9598,  ..., -1.5077, -1.0161,  3.0021],\n",
            "        [-0.2991,  3.1804, -2.0342,  ..., -1.4930, -1.1836,  3.4096]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8157,  7.4351, -1.0051,  ...,  0.5406, -1.0207,  6.1533],\n",
            "        [ 2.0821,  0.6789,  0.3325,  ..., -3.4225, -2.5393,  2.8253],\n",
            "        [-2.1104,  4.2704,  0.5408,  ..., -0.1594, -2.2146,  3.7536],\n",
            "        ...,\n",
            "        [ 1.1123,  3.7983,  6.2728,  ...,  5.8251, -2.2772,  0.8331],\n",
            "        [ 0.0756,  2.9677, -1.6104,  ..., -1.1126,  0.3329,  2.7610],\n",
            "        [-0.3387,  2.5575,  0.2748,  ...,  2.6158, -2.2819,  0.9590]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4011,  3.4113, -0.7181,  ..., -2.5435,  1.2870,  1.7478],\n",
            "        [-0.3159,  2.8579,  2.8451,  ..., -2.7790, -1.7540,  4.9029],\n",
            "        [-0.9859,  4.1695,  0.0454,  ..., -1.1665, -2.2485,  4.1869],\n",
            "        ...,\n",
            "        [ 0.2826,  5.0781, -1.1759,  ..., -2.4793,  1.1259,  2.6866],\n",
            "        [-1.2295,  3.7622,  1.3916,  ..., -4.2073,  0.0993,  5.7644],\n",
            "        [ 0.0191,  0.3492,  3.5210,  ..., -1.6886, -2.8979,  0.5898]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1272,  4.0177,  2.0206,  ...,  3.4088, -1.3816,  1.8290],\n",
            "        [-0.3918,  0.4765,  4.0222,  ...,  0.1339, -1.3097,  1.4095],\n",
            "        [-0.2177,  0.6397,  2.1353,  ..., -3.4317, -0.0079,  0.2707],\n",
            "        ...,\n",
            "        [ 0.3134,  2.2572, -1.4427,  ..., -1.0549,  0.9842,  1.6002],\n",
            "        [-0.7764,  2.9827,  2.3480,  ...,  1.2379, -1.2966,  0.8578],\n",
            "        [ 1.3784, -1.4960,  4.5019,  ..., -3.0248, -4.0289,  0.1633]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4124,  2.7482,  0.8541,  ..., -2.8057, -1.5108,  2.5800],\n",
            "        [-0.1137,  5.2890, -1.4286,  ..., -2.1842,  0.5505,  2.5509],\n",
            "        [-1.0646,  2.4757,  1.5539,  ..., -1.7273,  0.3766,  2.0100],\n",
            "        ...,\n",
            "        [ 1.6467, -1.3755,  5.2030,  ..., -3.6242, -1.2680, -0.7395],\n",
            "        [ 0.7703,  2.9630, -1.9927,  ..., -1.8236, -2.5604,  2.2851],\n",
            "        [-1.1721,  0.7738,  3.8937,  ..., -1.4894, -4.3158,  5.9012]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3532,  0.7571,  5.1168,  ..., -1.9754, -0.0286, -0.0870],\n",
            "        [-0.4620,  1.7945, -0.5070,  ..., -3.4603, -0.2093,  1.4749],\n",
            "        [ 0.7061,  5.6790, -2.4539,  ..., -2.1264, -0.2342,  3.2800],\n",
            "        ...,\n",
            "        [ 1.5925, -1.1510,  1.0972,  ..., -2.9262, -2.2876,  0.8465],\n",
            "        [-1.6653,  1.9084, -0.1917,  ..., -1.0523, -3.0142,  3.7693],\n",
            "        [-0.7010,  2.7991,  0.8522,  ..., -2.6986, -1.7841,  1.6083]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5205,  1.9028, -3.4004,  ..., -3.6051,  2.2733,  2.2773],\n",
            "        [-2.1710,  5.6057, -2.1008,  ...,  0.2837, -1.2236,  4.1187],\n",
            "        [ 1.0236,  0.8461,  2.6980,  ..., -1.4600, -1.1088,  0.6202],\n",
            "        ...,\n",
            "        [-0.3168,  5.3033, -1.1317,  ...,  1.1834, -1.0544,  2.4941],\n",
            "        [-0.1589,  1.3099,  2.0393,  ..., -1.5286, -0.8988, -1.0820],\n",
            "        [ 2.4060,  5.7261,  1.4812,  ..., -0.8639, -0.8599,  3.4199]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1948, -0.2251,  1.9106,  ..., -0.8938, -0.8589,  2.1040],\n",
            "        [-3.8429,  4.4596, -1.6462,  ..., -3.0186, -1.7043,  6.2251],\n",
            "        [ 2.2116,  6.9113, -1.6007,  ..., -2.6204, -2.3537,  4.6189],\n",
            "        ...,\n",
            "        [-2.3252,  2.3124,  3.8573,  ...,  4.1104, -1.6715,  1.7729],\n",
            "        [ 2.1058, -0.2606,  1.7936,  ..., -2.3775, -1.5325,  1.1351],\n",
            "        [ 1.0548,  3.4246,  2.8283,  ...,  1.6493, -2.8046,  2.9590]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8262,  3.9871, -2.3756,  ..., -2.3490, -0.7822,  4.8968],\n",
            "        [-0.8965,  1.0976, -3.6185,  ..., -5.3012,  0.3510,  1.2957],\n",
            "        [-0.9382,  1.7297,  0.5402,  ..., -0.2420, -2.5481,  2.5237],\n",
            "        ...,\n",
            "        [-0.6458, -0.1554,  2.8210,  ...,  0.6027, -2.3322,  0.3099],\n",
            "        [-0.7714,  0.2824,  2.5007,  ...,  1.5821, -3.4968,  1.7791],\n",
            "        [-1.2595,  3.7751,  3.2725,  ..., -3.1529, -0.8717,  6.6868]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3341,  5.1621, -1.5534,  ..., -0.8404,  0.4065,  4.6348],\n",
            "        [ 1.3113,  6.4496,  1.5563,  ...,  0.2941, -2.5518,  5.2402],\n",
            "        [ 1.5259,  2.6402, -1.3412,  ..., -1.9640,  0.4264,  1.9491],\n",
            "        ...,\n",
            "        [ 0.6897,  6.2541, -0.4897,  ..., -0.0854, -0.7313,  3.5150],\n",
            "        [-1.7353,  5.7370, -1.2577,  ...,  1.1672,  1.3957,  4.4899],\n",
            "        [ 1.4917, -1.1807,  0.5169,  ..., -2.3738, -1.7563,  0.9159]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2256,  2.5987, -1.5331,  ..., -2.1991,  0.1116,  2.7932],\n",
            "        [ 0.4453,  5.9197,  1.0618,  ...,  4.0643, -2.7313,  1.5246],\n",
            "        [-0.0528, -0.1471,  3.0816,  ..., -3.5122, -1.7594, -0.9640],\n",
            "        ...,\n",
            "        [ 1.2307,  5.5235, -3.8572,  ..., -1.2281,  1.0494,  3.4779],\n",
            "        [ 2.0443,  6.3183, -4.2642,  ..., -2.3352, -2.3904,  2.4577],\n",
            "        [ 1.5099, -0.9251,  3.6808,  ..., -0.8090, -4.5505, -0.1920]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5008,  1.4209,  0.6804,  ..., -0.8635,  0.4006,  1.8823],\n",
            "        [ 2.8053, -0.7287,  0.2247,  ..., -1.9137, -3.9200,  2.7462],\n",
            "        [ 0.2184,  1.5974,  1.0552,  ..., -1.9987,  0.9875,  0.5114],\n",
            "        ...,\n",
            "        [ 3.4577,  1.4069, -1.2642,  ..., -2.1320, -2.7122,  1.6070],\n",
            "        [ 0.3070,  4.1125, -1.6721,  ..., -2.0590, -0.4631,  2.8041],\n",
            "        [ 0.3025,  0.9210,  0.0953,  ..., -2.7370,  1.0226,  1.5626]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.1790,  3.5565, -0.3034,  ...,  0.3601, -2.3627,  2.3631],\n",
            "        [-2.0207,  5.5316, -1.3660,  ...,  1.1184, -3.3071,  6.7138],\n",
            "        [ 2.0932,  3.2442,  0.7116,  ..., -3.4327, -0.1922,  2.5659],\n",
            "        ...,\n",
            "        [ 1.5424,  0.0838,  1.3777,  ..., -2.3471, -2.3673,  0.5045],\n",
            "        [-1.8001,  5.4417, -0.3621,  ..., -3.4274, -1.5067,  4.5776],\n",
            "        [-0.1384,  2.9666,  0.5344,  ..., -0.9828,  1.6761,  1.3968]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8709, -1.7116, -0.7236,  ..., -2.3288, -2.9099,  3.6568],\n",
            "        [ 0.3296,  2.4771, -1.7198,  ..., -3.9121, -1.4309,  2.4463],\n",
            "        [ 1.0464,  4.6074, -0.7347,  ...,  0.3691, -2.3653,  2.8429],\n",
            "        ...,\n",
            "        [-0.2659,  2.7351, -0.3669,  ..., -0.0248, -1.3933,  3.9475],\n",
            "        [-1.2609,  0.4524,  2.0824,  ..., -1.7338, -1.4123,  0.4120],\n",
            "        [-0.0285,  1.7823, -2.5951,  ..., -1.2725, -1.5427,  2.2306]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5320e-01,  5.8201e-01,  6.6807e+00,  ..., -1.4392e+00,\n",
            "         -2.6761e+00, -2.2830e+00],\n",
            "        [ 4.7292e+00,  2.3065e+00, -9.4164e-01,  ..., -2.0267e+00,\n",
            "         -2.0842e+00,  3.5709e+00],\n",
            "        [-1.9586e-01,  4.6735e+00,  4.2677e-01,  ..., -2.9133e+00,\n",
            "          1.9617e-01,  3.5561e+00],\n",
            "        ...,\n",
            "        [ 1.7198e+00,  2.5035e+00, -2.3469e+00,  ..., -4.7367e+00,\n",
            "          6.8178e-01,  3.5264e+00],\n",
            "        [ 4.0062e-01,  3.3670e-01,  3.6507e+00,  ..., -3.8124e-01,\n",
            "          2.1961e-02,  1.3126e+00],\n",
            "        [ 5.3578e-03,  5.6683e-01,  1.5394e+00,  ..., -1.9428e+00,\n",
            "          2.3580e-01,  3.5624e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1210,  2.5449,  1.5491,  ...,  1.6697, -2.9186,  2.0270],\n",
            "        [ 1.5819,  2.6400, -0.7049,  ..., -2.1783, -0.4546,  1.0658],\n",
            "        [ 0.4118, -0.1337,  2.0257,  ...,  3.3197, -1.2518,  0.8000],\n",
            "        ...,\n",
            "        [ 0.7748,  1.8815, -1.8611,  ..., -2.4893, -1.9797,  1.0173],\n",
            "        [ 1.9027, -0.0353,  0.3450,  ..., -3.6798, -2.1614,  1.8569],\n",
            "        [-0.9183,  1.7997,  0.1517,  ..., -1.2217, -1.4482,  2.1422]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5225,  1.4228,  2.3487,  ...,  0.0565, -0.9867,  2.3486],\n",
            "        [-0.3165,  3.0969,  1.0389,  ...,  1.6768, -1.0087,  1.7629],\n",
            "        [-0.8604,  1.1867, -0.2259,  ..., -0.3740, -0.5170,  1.9539],\n",
            "        ...,\n",
            "        [ 1.9048,  4.2819, -1.5917,  ...,  2.4337, -3.1187,  3.6722],\n",
            "        [ 1.4130, -1.0922,  4.5809,  ..., -4.0301,  0.7136,  0.3772],\n",
            "        [-0.9435,  0.1612,  4.5443,  ..., -1.0518, -1.0466,  2.7669]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6282,  4.4981,  0.6674,  ...,  0.0891, -3.1092,  2.9209],\n",
            "        [ 1.1555, -0.1563,  2.3359,  ..., -0.1110, -3.2598,  2.7267],\n",
            "        [-0.5174,  3.2791, -3.5438,  ..., -2.9953,  1.3139,  3.8589],\n",
            "        ...,\n",
            "        [ 1.5436, -1.9992,  0.2620,  ..., -3.2298, -1.9420,  1.2080],\n",
            "        [ 1.3726,  2.7885, -0.2122,  ..., -0.2793, -1.9266,  2.8427],\n",
            "        [-2.4222,  4.0165, -2.1166,  ...,  0.9245, -0.5421,  4.1114]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0268,  1.4376, -0.4472,  ...,  0.3996,  1.2460,  1.1345],\n",
            "        [ 0.0752,  5.7506,  0.8531,  ...,  4.5015, -0.4106,  2.6176],\n",
            "        [ 2.7836,  0.1701,  0.0089,  ..., -1.7956, -3.0581,  2.2550],\n",
            "        ...,\n",
            "        [-1.3151,  5.2795, -1.1584,  ..., -1.2675,  0.4253,  2.6845],\n",
            "        [-1.1603,  2.6944, -0.0208,  ..., -2.8704,  2.2031,  1.2494],\n",
            "        [-1.1415,  0.2796,  3.0591,  ..., -3.1627, -1.4684,  1.1037]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1595,  3.0000, -0.2156,  ..., -2.7531,  1.8461,  1.1729],\n",
            "        [-0.6636,  1.9432,  0.8553,  ..., -1.3368, -1.5047,  4.5154],\n",
            "        [ 0.4315,  2.2354, -3.3790,  ..., -0.0922, -1.8823,  2.3757],\n",
            "        ...,\n",
            "        [ 1.0006,  1.6727,  0.0118,  ..., -2.1090, -0.3311,  1.1343],\n",
            "        [-1.5563,  1.3270,  2.4594,  ..., -0.2038,  0.8563,  0.4668],\n",
            "        [-1.3354, -0.5214, -1.2197,  ..., -3.3807,  0.1567,  2.2846]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3821,  3.1656, -0.1179,  ..., -2.8875,  1.2968,  1.9754],\n",
            "        [-2.6675, -0.6923,  2.0018,  ...,  0.8784, -0.8007,  2.7539],\n",
            "        [ 0.7707, -0.2851, -2.7116,  ..., -3.9097,  1.4289,  2.5449],\n",
            "        ...,\n",
            "        [-2.3223,  5.7131, -0.5174,  ...,  0.8957,  2.9087,  6.9481],\n",
            "        [-1.3677,  5.6947,  2.6638,  ...,  3.8696, -5.0508,  3.4567],\n",
            "        [-0.5639,  0.7546,  0.1862,  ..., -0.7730,  0.2047,  0.6568]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2213,  4.2772, -1.4666,  ..., -3.2511, -0.7846,  3.4994],\n",
            "        [ 0.3670, -0.3149,  2.6207,  ..., -0.4192,  0.0716,  2.1785],\n",
            "        [-5.2824,  2.8872,  0.4388,  ...,  0.3648,  0.6255,  4.5316],\n",
            "        ...,\n",
            "        [-0.4644, -0.1497,  1.4830,  ..., -0.9213, -3.5867,  3.7578],\n",
            "        [ 1.8650,  1.4192,  4.5036,  ...,  1.7725, -4.3428,  0.5931],\n",
            "        [-1.5745,  2.7301,  2.5217,  ..., -1.6684, -1.7455,  8.0334]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2702,  1.9157,  0.2733,  ..., -1.6945,  1.6708,  0.9380],\n",
            "        [-0.7712,  1.8634, -0.2807,  ...,  0.4474, -0.4987,  2.7705],\n",
            "        [-0.8550,  3.3531, -1.8052,  ..., -1.5355,  1.9391,  2.7189],\n",
            "        ...,\n",
            "        [-0.3961,  3.6836,  0.8244,  ..., -0.9794,  2.1202,  1.6699],\n",
            "        [ 1.1898,  1.3667, -1.6378,  ..., -1.9024,  0.6131,  1.1090],\n",
            "        [ 0.8930, -0.6732,  0.2237,  ..., -3.3124, -3.2199,  2.1322]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1636,  1.6271,  0.1970,  ..., -3.5963, -3.0188,  1.2611],\n",
            "        [-2.9915,  0.6099,  2.0119,  ..., -0.3991, -0.1213,  4.2327],\n",
            "        [-1.1636,  3.2218,  1.4319,  ...,  2.3984, -4.2411,  5.7218],\n",
            "        ...,\n",
            "        [ 3.3035, -2.3850,  2.1640,  ..., -1.9586, -3.4482,  0.1170],\n",
            "        [ 0.5465,  2.5214, -2.7513,  ..., -0.7770, -2.0471,  2.5377],\n",
            "        [ 2.9851,  3.7208, -0.8688,  ..., -2.4993,  0.0850,  2.2603]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5417,  0.1890,  2.1422,  ...,  2.3856, -5.7659,  2.7388],\n",
            "        [ 0.0121,  4.8196, -0.3238,  ...,  3.5400, -1.8124,  2.6815],\n",
            "        [ 1.5723, -0.4729,  0.2131,  ..., -1.0735, -2.6066,  1.2190],\n",
            "        ...,\n",
            "        [ 1.7405,  1.0109, -0.0226,  ..., -1.8946,  0.6361,  0.7765],\n",
            "        [-0.8698,  1.2342,  0.8090,  ..., -1.7965, -3.2226,  3.9951],\n",
            "        [-0.8053,  1.5420,  1.3513,  ..., -0.3847, -0.1785,  2.6788]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6718,  5.9849, -1.4668,  ..., -1.4126, -0.7670,  4.8836],\n",
            "        [-0.2060,  5.8209, -0.6655,  ..., -0.9111, -1.5264,  7.0633],\n",
            "        [-1.9608,  2.6906,  0.4925,  ..., -2.2839,  2.0353,  1.8932],\n",
            "        ...,\n",
            "        [-2.3255,  6.9292, -1.9294,  ...,  1.4740,  0.9054,  5.3293],\n",
            "        [ 3.4337, -0.8928,  1.6489,  ..., -1.1168, -4.3837,  0.5266],\n",
            "        [ 0.2283,  0.4404,  1.3185,  ..., -1.8264,  0.0378,  2.2413]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5518,  0.2253,  0.4033,  ...,  0.2383, -0.0785,  0.6924],\n",
            "        [ 1.5527,  0.4540, -0.5191,  ..., -1.6693, -2.8671,  1.4915],\n",
            "        [-0.3498,  1.3332,  3.1356,  ..., -0.7375, -0.4766,  2.7284],\n",
            "        ...,\n",
            "        [ 0.2804,  1.3128, -0.1887,  ..., -1.7979, -1.9952,  4.6841],\n",
            "        [-2.5149,  3.1485,  0.5595,  ...,  2.4991, -1.7993,  1.7065],\n",
            "        [-0.0693,  5.8220, -3.4345,  ..., -1.7739, -0.3213,  4.4936]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.2788,  4.5730, -0.3619,  ...,  3.0459,  0.6446,  5.3690],\n",
            "        [-0.4131,  3.0320,  1.8423,  ...,  0.2340, -2.8032,  4.0852],\n",
            "        [-0.9907,  1.1553, -2.0377,  ..., -3.8867, -0.4245,  3.4802],\n",
            "        ...,\n",
            "        [-1.7305,  7.5768, -0.9592,  ...,  1.1623, -0.1587,  7.5753],\n",
            "        [ 0.4522, -0.7150,  4.4504,  ...,  1.7453, -3.6936,  0.9697],\n",
            "        [-0.5639,  4.5350, -0.1778,  ..., -1.8293, -0.3570,  4.4842]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1796,  2.6091, -2.0709,  ..., -0.1399, -0.1739,  2.9146],\n",
            "        [-0.1828,  1.2975,  1.1946,  ..., -0.2826, -1.9320,  3.3290],\n",
            "        [-0.5604,  3.7307,  0.6454,  ..., -2.9083,  0.8354,  1.6286],\n",
            "        ...,\n",
            "        [ 0.8596,  0.3460,  1.9500,  ..., -0.1575,  1.2163, -0.1026],\n",
            "        [ 0.8229,  0.5061,  0.6236,  ..., -4.9962, -1.2003, -0.2690],\n",
            "        [-1.4284,  2.1433,  0.8858,  ..., -2.4485,  2.2990,  0.4052]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4269,  5.2577, -0.3573,  ...,  3.2107, -2.0507,  6.9575],\n",
            "        [ 2.2503, -0.0083,  2.0326,  ..., -0.4480, -4.7134,  0.7546],\n",
            "        [ 1.0557,  1.3580, -0.4092,  ..., -2.7334, -2.0592,  0.7024],\n",
            "        ...,\n",
            "        [-1.7219,  0.2283, -0.0659,  ..., -0.6967,  0.9750,  2.2700],\n",
            "        [ 2.6211, -1.5276,  2.9108,  ...,  0.7977, -4.3330,  4.9909],\n",
            "        [ 2.7080, -0.4703,  1.8577,  ...,  0.6130, -4.0278,  1.7232]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0703e-01,  2.0445e+00, -6.7980e-03,  ..., -1.4651e+00,\n",
            "         -2.7854e+00,  3.2120e+00],\n",
            "        [ 1.6969e-01,  7.0293e+00, -9.4964e-01,  ...,  7.3674e-01,\n",
            "         -4.2368e-01,  4.0101e+00],\n",
            "        [ 2.5786e-01,  3.2770e+00, -2.3806e+00,  ..., -1.4112e+00,\n",
            "         -9.5726e-02,  2.5593e+00],\n",
            "        ...,\n",
            "        [ 7.4691e-01,  3.6761e+00, -9.6148e-01,  ..., -2.2448e+00,\n",
            "          2.6061e-01,  2.2310e+00],\n",
            "        [ 2.6103e+00, -1.0092e+00,  1.1416e-02,  ..., -2.4804e+00,\n",
            "         -3.7737e+00,  1.0086e+00],\n",
            "        [ 8.2976e-01,  4.5281e-01,  1.4904e+00,  ..., -9.3602e-01,\n",
            "          1.8377e+00,  5.5827e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8040,  3.4148, -2.0954,  ..., -1.9859,  0.5257,  2.5511],\n",
            "        [-0.7605, -0.7828,  6.4528,  ...,  1.0889, -2.3917, -2.5589],\n",
            "        [-0.4510,  6.0366,  0.6823,  ...,  3.5522,  0.0857,  3.9998],\n",
            "        ...,\n",
            "        [-0.4448,  3.6943, -4.4751,  ..., -2.4131,  0.3509,  2.5946],\n",
            "        [-0.0106,  4.6571, -1.3094,  ..., -0.7091,  3.0713,  2.8669],\n",
            "        [ 1.1723,  0.3259,  0.5389,  ..., -2.1630,  0.3969,  2.1909]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6414,  1.2146, -0.2119,  ..., -2.0282,  3.0652,  1.1786],\n",
            "        [-1.2639,  3.0093,  3.8170,  ...,  1.7945, -4.8895,  7.8245],\n",
            "        [ 1.2856,  2.4547, -1.1110,  ..., -2.5457, -0.4187,  1.6323],\n",
            "        ...,\n",
            "        [ 0.6814,  1.6835,  2.2151,  ..., -2.2223, -1.5290,  4.7061],\n",
            "        [ 0.2248,  2.6394, -0.2218,  ..., -1.1766,  0.3505,  1.8130],\n",
            "        [ 1.8542,  5.5481,  0.5477,  ..., -2.5734,  1.5333,  3.8162]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6051,  2.3294, -2.6264,  ..., -1.5398, -1.6608,  1.1509],\n",
            "        [-0.3787,  1.0042,  4.6261,  ..., -2.1583, -0.9733,  1.3936],\n",
            "        [-0.6994,  2.2167,  0.2207,  ...,  1.0347, -0.9763,  0.3742],\n",
            "        ...,\n",
            "        [-0.0332,  4.0347,  1.3892,  ..., -2.1305,  1.1080,  2.7324],\n",
            "        [ 0.4950,  1.6261,  1.5282,  ...,  5.5930, -0.4212,  1.5492],\n",
            "        [-2.1162,  2.2150,  2.0312,  ...,  3.6683, -3.4569,  2.9094]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1730,  6.3967,  1.8136,  ...,  0.2976, -0.6518,  1.8562],\n",
            "        [ 1.5951, -0.7988,  1.0288,  ..., -2.1129, -1.8278, -0.3206],\n",
            "        [ 2.7244,  6.8297, -1.9301,  ..., -2.6868, -1.2076,  2.8943],\n",
            "        ...,\n",
            "        [-1.8360,  9.1452, -1.1693,  ..., -1.8924, -0.5171,  5.0699],\n",
            "        [-0.9767,  3.8544,  0.6763,  ..., -2.3062,  2.0842,  2.8434],\n",
            "        [-1.6690,  2.2008,  2.9431,  ...,  2.1245, -2.2754,  3.0769]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4110,  6.3749, -2.8138,  ..., -0.9394, -2.0340,  5.5925],\n",
            "        [ 1.0342,  1.5362,  0.7960,  ..., -2.0210,  0.2897,  0.9451],\n",
            "        [-0.8873,  5.2158,  0.7762,  ..., -3.0636,  2.3822,  3.6042],\n",
            "        ...,\n",
            "        [-1.2519,  0.3254,  1.1679,  ..., -3.5782,  0.0301,  3.7038],\n",
            "        [ 0.4584,  3.8519,  3.6715,  ...,  3.1053, -1.2409,  3.8403],\n",
            "        [ 1.9079,  2.3018, -0.5701,  ..., -0.4059, -1.3362,  3.0320]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7068,  6.0115,  2.2064,  ...,  2.9643, -1.2244,  4.0516],\n",
            "        [-1.9128,  0.5230,  1.9989,  ..., -1.9973, -0.3395,  3.1674],\n",
            "        [ 0.4745,  2.5211, -2.6806,  ..., -2.1984, -0.4162,  1.8474],\n",
            "        ...,\n",
            "        [ 0.2783,  2.6954, -1.6689,  ..., -2.5703, -0.7434,  1.6292],\n",
            "        [ 0.0683,  5.0924, -0.8897,  ..., -1.6256,  1.7996,  1.6951],\n",
            "        [-0.9257,  4.3748,  1.9194,  ...,  5.8040, -1.6423,  3.2742]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0007,  3.5444,  0.4424,  ..., -0.3008, -0.3589,  6.1421],\n",
            "        [-1.0979,  1.6215,  5.0025,  ...,  4.3164, -2.5062,  0.6410],\n",
            "        [-2.0636,  0.9681, -2.5633,  ...,  0.2431,  0.5392,  4.9402],\n",
            "        ...,\n",
            "        [ 0.5162,  3.5388, -2.8796,  ..., -2.0514,  0.0339,  3.1985],\n",
            "        [ 0.2983,  3.0033, -1.2841,  ..., -2.5327, -1.5292,  3.9721],\n",
            "        [-2.4224,  1.6377,  1.3883,  ..., -2.4076,  2.5982,  1.2384]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4870,  6.2743, -2.5018,  ..., -0.7458, -1.4254,  4.1571],\n",
            "        [-2.9673,  6.5696, -2.3601,  ..., -0.9490,  1.1639,  5.1043],\n",
            "        [ 0.9847,  6.8798,  0.1268,  ...,  2.4760, -0.1865,  4.2153],\n",
            "        ...,\n",
            "        [-0.8295,  3.5955,  1.1713,  ..., -0.2278,  1.7410,  6.2433],\n",
            "        [ 0.0512,  1.8482,  2.6986,  ..., -0.9730,  0.7772,  1.1548],\n",
            "        [ 1.5717,  2.1489, -1.0579,  ..., -2.9533, -1.0961,  2.0922]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0352,  3.8022,  0.7320,  ..., -1.0405, -1.4558,  2.3157],\n",
            "        [-2.0601,  5.4153,  1.1530,  ..., -0.5887, -0.6348,  6.6623],\n",
            "        [ 0.8382,  3.9343,  2.1768,  ...,  2.9946,  0.5602,  1.3325],\n",
            "        ...,\n",
            "        [-2.8136,  3.1571, -3.6516,  ..., -4.0068, -1.1466,  5.1654],\n",
            "        [ 0.4003,  1.5874,  0.3425,  ...,  0.8841, -1.5945,  2.4964],\n",
            "        [ 1.1062,  0.5331, -1.7300,  ..., -1.2783,  0.2729,  0.9839]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0514,  4.3948, -2.6000,  ..., -2.8673,  0.1626,  6.0461],\n",
            "        [-1.0839,  4.6340, -0.1333,  ..., -0.9481,  2.7053,  2.8977],\n",
            "        [-1.3391,  1.5157,  1.9585,  ..., -2.1372,  1.8628,  0.0865],\n",
            "        ...,\n",
            "        [ 0.9583,  0.1263,  4.6866,  ...,  0.3242, -1.5404, -0.7144],\n",
            "        [ 1.2250,  5.6170,  2.1142,  ..., -2.9641, -0.2792,  7.2361],\n",
            "        [-0.6982,  1.0010,  1.7493,  ..., -4.5613,  0.1904,  2.5881]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6398,  2.9981, -1.1305,  ..., -2.9890,  0.5502,  2.2693],\n",
            "        [ 0.0782,  6.6911, -0.5155,  ..., -1.8333, -0.1885,  3.3381],\n",
            "        [ 0.8583,  1.7460,  3.5014,  ..., -2.5806,  0.1707,  0.4186],\n",
            "        ...,\n",
            "        [ 0.0765,  4.6235, -1.0568,  ..., -2.5559,  2.3687,  2.0050],\n",
            "        [ 0.3347,  5.4711, -0.4158,  ..., -0.3074,  0.3430,  4.8859],\n",
            "        [ 0.2161,  3.5408, -3.4917,  ...,  0.2861, -1.1483,  4.5115]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1393,  2.4327,  0.7949,  ..., -0.7536,  2.1056,  0.8147],\n",
            "        [ 0.3842,  1.7866,  6.7518,  ..., -3.0901, -0.3677,  0.4229],\n",
            "        [ 2.7968,  4.1924, -1.9235,  ..., -2.6910,  0.3539,  3.9875],\n",
            "        ...,\n",
            "        [-0.1596,  1.4504,  2.4156,  ..., -2.0846,  2.6856,  1.2210],\n",
            "        [ 0.5858,  4.4266,  3.2325,  ...,  5.5755,  0.0929,  4.4268],\n",
            "        [ 0.4342,  5.2176, -1.0837,  ..., -1.3923,  1.0331,  2.8074]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3882,  3.4617,  1.2170,  ..., -2.1770,  1.1228,  2.8000],\n",
            "        [ 1.4193,  4.3716, -1.0609,  ...,  0.9104, -1.0125,  5.1347],\n",
            "        [ 0.6469,  0.8015,  0.5440,  ..., -3.0766, -0.7643,  1.7514],\n",
            "        ...,\n",
            "        [ 0.4317,  3.7266, -0.6430,  ..., -2.3195,  2.0196,  1.6107],\n",
            "        [-1.8694,  2.4907,  1.7249,  ...,  1.7643, -2.5322,  5.4414],\n",
            "        [ 0.0165,  4.1272, -0.5004,  ..., -1.9051,  2.1652,  1.6609]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9232,  7.7384,  0.4729,  ..., -1.4484, -0.9503,  8.4157],\n",
            "        [-0.5171,  4.2276,  2.5302,  ...,  4.0074, -1.9466,  4.1980],\n",
            "        [-0.4933,  1.8671,  6.0802,  ..., -1.0609, -1.0645,  2.0211],\n",
            "        ...,\n",
            "        [-0.9501,  5.6934, -1.8577,  ...,  0.0409,  0.9820,  4.0915],\n",
            "        [ 0.6046, -0.6527,  1.7735,  ..., -2.6092, -0.9104,  0.5827],\n",
            "        [-1.0733,  3.9766, -0.9834,  ...,  1.1892,  0.9389,  4.8315]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4746,  6.6538,  2.8925,  ...,  3.3605, -3.8924,  2.2489],\n",
            "        [ 0.8274,  1.0812,  0.6665,  ..., -4.6510, -1.2487,  2.3373],\n",
            "        [-1.9693,  4.5004,  1.0879,  ...,  4.3083, -1.2958,  1.9582],\n",
            "        ...,\n",
            "        [ 1.2728,  3.9927, -1.4506,  ..., -2.3697, -0.4592,  2.1465],\n",
            "        [-1.2295,  1.7020,  1.8784,  ..., -2.8968, -0.1397,  1.1192],\n",
            "        [ 4.0641,  8.3949, -1.6274,  ...,  0.6358, -2.9935,  5.8516]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3668,  1.9176, -2.5229,  ..., -1.0775, -0.7510,  2.9200],\n",
            "        [ 1.0675,  3.9671, -0.1924,  ..., -1.8561,  1.2364,  2.2932],\n",
            "        [-0.7869,  1.1034,  0.5678,  ..., -2.1453,  0.1604,  1.5519],\n",
            "        ...,\n",
            "        [-1.0438,  3.8339,  0.5670,  ..., -2.9065,  1.7164,  2.0294],\n",
            "        [-3.4115,  3.4044, -0.5761,  ...,  0.4175,  1.3267,  4.3384],\n",
            "        [ 0.5460,  2.2577,  1.7874,  ..., -1.8417,  1.1171,  1.9770]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5757, -1.2180,  2.4652,  ...,  1.4666, -3.9742,  2.8520],\n",
            "        [-1.3895,  2.1606,  1.8243,  ..., -1.5550, -0.8464,  3.7511],\n",
            "        [ 1.2201,  0.9221,  1.1534,  ..., -3.1680, -0.9849,  4.4033],\n",
            "        ...,\n",
            "        [ 0.0958,  2.0147, -1.0020,  ..., -3.0572,  3.3483,  2.5951],\n",
            "        [-2.9460,  2.9826, -1.0572,  ..., -2.6640,  2.0237,  2.8097],\n",
            "        [-1.6366,  3.6879,  1.6817,  ..., -2.6538,  2.6435,  2.8350]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3274,  2.2535, -1.0908,  ..., -3.9727, -1.2483,  1.7032],\n",
            "        [ 1.5881,  3.4155,  0.1164,  ..., -3.4105,  0.9325,  2.8227],\n",
            "        [-0.8807,  7.0823,  0.2526,  ..., -1.1089,  0.6485,  3.1361],\n",
            "        ...,\n",
            "        [-0.7159,  4.8728,  1.9220,  ..., -2.9092, -0.8775,  2.8426],\n",
            "        [-1.5899,  4.6105,  2.6933,  ..., -2.1993,  1.1336,  6.2648],\n",
            "        [-0.7114,  3.4566, -0.5254,  ..., -1.1903,  3.1745,  1.3304]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2033,  4.5537, -0.2830,  ..., -2.1620,  0.9444,  1.9871],\n",
            "        [-0.0380,  6.4493, -0.1775,  ...,  0.7805, -0.1411,  7.3666],\n",
            "        [ 1.8950, -0.2429,  0.5492,  ..., -1.4637,  0.0877,  1.2728],\n",
            "        ...,\n",
            "        [ 2.6761,  3.3761,  1.9216,  ..., -0.3685, -2.2849,  3.1767],\n",
            "        [-0.0282,  0.6527,  1.0467,  ..., -3.2177,  0.9660,  2.4315],\n",
            "        [-2.0311,  3.2959,  0.4099,  ..., -3.7902,  1.6652,  3.2590]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0104,  4.3639, -1.4314,  ...,  1.3933, -3.4386,  2.7612],\n",
            "        [ 1.7808,  5.0075, -0.9137,  ..., -0.2880, -1.7783,  3.9873],\n",
            "        [-0.3347,  3.5084, -3.4551,  ..., -0.8852, -1.3946,  2.6682],\n",
            "        ...,\n",
            "        [-1.6877,  1.1850,  3.1280,  ..., -0.5323, -0.0595,  0.9416],\n",
            "        [-0.4992,  4.1784,  2.7334,  ..., -2.2628,  0.2217,  5.5831],\n",
            "        [ 0.2876,  2.7299, -2.9863,  ..., -1.6279,  0.6430,  2.7832]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6375,  5.9113,  2.5238,  ...,  7.9801, -2.8601,  1.6919],\n",
            "        [-1.0159,  7.3775,  2.3851,  ...,  2.2157,  1.7945,  1.1436],\n",
            "        [ 2.5024,  6.0317,  2.5629,  ...,  3.3115, -0.8884,  5.3818],\n",
            "        ...,\n",
            "        [ 0.1050,  2.6150, -0.4108,  ..., -1.8226,  1.6151,  1.8141],\n",
            "        [-0.1033,  4.0292, -1.1295,  ..., -0.6687,  1.4943,  5.3600],\n",
            "        [-0.2709,  6.6924,  3.2708,  ...,  0.1250, -0.8011,  4.4222]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7401,  0.2522,  0.5689,  ..., -3.8131, -1.5576,  1.8050],\n",
            "        [ 2.2828,  1.6078,  2.9554,  ..., -0.4715, -2.0799,  4.7986],\n",
            "        [-0.6106,  6.9073,  2.0262,  ...,  0.6537, -1.0569,  9.9136],\n",
            "        ...,\n",
            "        [-2.7196,  6.7942, -2.5175,  ..., -0.1429,  1.6731,  2.4444],\n",
            "        [-1.3934,  4.5360, -0.8398,  ..., -1.5744,  1.6882,  4.6215],\n",
            "        [ 2.6958,  3.2062, -0.1935,  ..., -1.5076,  1.1379,  2.4424]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3398,  2.6825,  0.2768,  ..., -2.0195, -1.4743,  2.9165],\n",
            "        [ 0.1281,  4.9485, -1.8393,  ...,  0.8693,  1.4494,  2.1387],\n",
            "        [ 0.3987,  2.6451, -0.2038,  ..., -1.8113,  0.6246,  0.8427],\n",
            "        ...,\n",
            "        [-2.7772, -0.2305,  3.2016,  ...,  5.1495, -1.9644,  1.8347],\n",
            "        [-0.0615,  6.1050,  3.2173,  ...,  1.0392, -0.1773,  4.7008],\n",
            "        [ 0.0115,  0.1018,  5.7072,  ..., -0.5428, -0.5690, -0.3733]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8868,  5.3232,  0.5410,  ..., -2.4614,  2.0736,  4.1202],\n",
            "        [-0.6175,  1.2108,  5.6631,  ...,  1.4451,  1.2088, -1.1432],\n",
            "        [ 0.4810,  2.7656, -0.0832,  ..., -1.7081,  1.4187,  3.0425],\n",
            "        ...,\n",
            "        [-0.0376,  1.2143,  0.8314,  ..., -2.3950,  1.0530,  2.3902],\n",
            "        [-0.9353,  4.3216, -1.6362,  ..., -1.4799,  2.0665,  3.5722],\n",
            "        [ 0.6609,  0.7222,  1.4403,  ..., -0.7614, -2.1074,  1.6113]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0498,  1.5123,  2.8214,  ..., -3.0163,  3.4477,  1.5794],\n",
            "        [-1.5840,  2.6506, -0.3500,  ..., -0.5896, -1.2478,  4.0148],\n",
            "        [ 0.4134,  2.5797,  3.3033,  ...,  1.5470,  1.2130,  1.4360],\n",
            "        ...,\n",
            "        [ 1.2270,  1.2025,  3.5155,  ..., -1.1951, -1.9481, -0.6402],\n",
            "        [-0.1972,  2.5861,  0.0707,  ..., -2.6833,  2.0857,  1.2524],\n",
            "        [ 1.4113,  4.7977,  1.0330,  ..., -1.8436,  3.4264,  4.1821]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4961,  1.6422, -2.1252,  ..., -1.7550, -0.8010,  0.1910],\n",
            "        [-1.0577,  3.8161,  1.3328,  ..., -1.1709, -2.4980,  0.9365],\n",
            "        [ 1.2922,  4.0985, -1.1724,  ...,  0.9265, -0.9303,  5.9007],\n",
            "        ...,\n",
            "        [-0.6877,  3.0931,  0.1406,  ..., -3.3194,  2.5579,  1.9289],\n",
            "        [ 0.8440,  3.6898, -0.9247,  ...,  1.5132, -0.7856,  4.3361],\n",
            "        [-1.6704,  2.0566, -1.5108,  ..., -2.8781,  3.5362,  2.7374]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3382,  2.5996,  2.6308,  ..., -0.4065,  1.5864,  5.4148],\n",
            "        [-1.3508,  4.4985,  0.7296,  ..., -2.3808,  0.3196,  5.7285],\n",
            "        [-1.1713,  2.1228,  1.0408,  ..., -0.8789,  2.1234,  2.8917],\n",
            "        ...,\n",
            "        [-0.8470,  7.0176, -0.5982,  ...,  0.7437,  3.4264,  1.9777],\n",
            "        [ 1.3390,  0.6607, -0.8937,  ..., -0.4741,  0.1204,  1.2715],\n",
            "        [-1.9539,  6.9647,  3.6482,  ...,  5.8835, -1.2393,  4.3980]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3500,  3.0398, -1.4052,  ..., -2.5386,  0.5777,  0.5702],\n",
            "        [ 0.4308,  0.2978,  8.0703,  ..., -1.2589, -1.2741, -2.7332],\n",
            "        [ 1.0238,  1.9514, -0.1194,  ..., -1.4396, -0.3313,  2.9022],\n",
            "        ...,\n",
            "        [-0.5167,  1.9718,  5.4646,  ..., -0.3705, -0.4465,  0.8327],\n",
            "        [-1.7802,  3.0374, -1.0564,  ...,  3.3517,  0.3491,  1.5025],\n",
            "        [-0.3058,  6.6860,  3.0059,  ...,  4.4422, -0.0157,  2.8642]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "572a2dc5793140acaa6781550b31dc9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.7971,  4.0788, -0.6770,  ..., -2.1617,  3.2180,  2.8151],\n",
            "        [ 4.1673,  4.9034, -0.9478,  ..., -2.3225,  2.2913,  3.0909],\n",
            "        [ 0.2457,  0.8286,  2.1197,  ..., -0.7517, -0.6926,  1.3262],\n",
            "        ...,\n",
            "        [ 2.5340,  4.4938, -0.9602,  ..., -3.3195,  0.6476,  4.0210],\n",
            "        [ 0.3579,  4.8273, -1.3471,  ..., -1.5062,  2.4525,  3.9696],\n",
            "        [ 0.3392,  1.3715,  2.0672,  ..., -0.8612, -0.7946,  2.5701]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1949,  3.0770,  0.0474,  ..., -2.7722,  0.4309,  3.3361],\n",
            "        [-1.5560,  2.7760, -0.2232,  ..., -2.9861,  1.8967,  2.3437],\n",
            "        [-0.9959,  1.4688, -1.0730,  ..., -3.2777, -0.3303,  5.0038],\n",
            "        ...,\n",
            "        [ 0.6080,  0.6078,  2.1699,  ..., -0.7280, -0.5878,  3.6241],\n",
            "        [ 0.1010,  1.0943,  1.1169,  ..., -1.1822, -1.4042,  0.8806],\n",
            "        [-0.0138,  1.5887,  5.2488,  ...,  4.5146, -3.6158,  0.8987]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4886,  3.9684,  0.5913,  ..., -1.4189,  1.2216,  1.8058],\n",
            "        [-1.7200,  3.2972,  0.6741,  ..., -1.2878,  0.2300,  6.1018],\n",
            "        [ 0.6840,  6.5518, -0.9257,  ...,  0.3727, -0.2260,  3.5671],\n",
            "        ...,\n",
            "        [-0.4526,  4.8491, -0.8003,  ..., -1.6862,  0.2520,  4.5283],\n",
            "        [-0.6387,  3.4353,  4.5791,  ...,  2.2067, -2.2848,  6.4138],\n",
            "        [ 0.9022,  2.4208,  2.0908,  ...,  3.9820, -0.8961,  3.0782]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7490,  2.8990,  1.1440,  ...,  2.9296, -0.5242,  3.0801],\n",
            "        [ 0.6129, -0.8572,  2.6304,  ...,  1.3643, -2.8652,  2.5624],\n",
            "        [-1.0919,  1.0893,  1.2960,  ..., -2.6065,  2.2918,  2.8317],\n",
            "        ...,\n",
            "        [ 0.3093,  2.9826, -1.9055,  ..., -0.8317,  0.9585,  3.2512],\n",
            "        [-0.3687,  1.3554,  6.1990,  ...,  0.6744, -2.1801, -1.4887],\n",
            "        [-2.5728,  3.4872,  0.3637,  ...,  1.1142, -0.6912,  2.4061]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.8254e+00,  6.7611e+00, -2.6779e+00,  ...,  3.6229e-01,\n",
            "          2.2137e+00,  3.8887e+00],\n",
            "        [-1.1926e+00,  5.6737e+00, -2.1828e+00,  ..., -1.4619e+00,\n",
            "          4.8500e-01,  5.5564e+00],\n",
            "        [ 4.3956e-02,  4.9023e+00,  2.2110e+00,  ..., -1.5330e+00,\n",
            "         -3.3381e-01,  4.9396e+00],\n",
            "        ...,\n",
            "        [ 1.9132e+00, -4.8910e-01,  3.4987e+00,  ..., -2.3996e+00,\n",
            "         -1.4319e+00, -1.2337e+00],\n",
            "        [-3.2787e-03,  3.7423e-01,  3.2365e+00,  ..., -1.2651e+00,\n",
            "          9.9567e-01,  1.4369e-01],\n",
            "        [ 2.3737e+00,  1.0455e+00,  2.3875e+00,  ..., -2.5400e-01,\n",
            "         -9.7563e-01,  2.9046e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3214,  1.0705,  0.8417,  ..., -0.1721,  1.0136,  4.0896],\n",
            "        [ 1.9409,  3.3221,  0.9708,  ...,  2.0817, -0.7897,  1.2571],\n",
            "        [-0.7353, -0.3270,  4.3008,  ...,  2.5304,  0.3089, -0.5531],\n",
            "        ...,\n",
            "        [ 1.5246,  6.5870,  1.6742,  ...,  1.9196, -0.5841,  3.9351],\n",
            "        [ 0.4569,  0.2498,  4.0796,  ..., -3.6518,  2.3280,  0.6867],\n",
            "        [ 0.5118,  1.7449, -2.8063,  ..., -1.6867, -0.7147,  1.2403]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8453e+00,  1.6833e-01, -4.4318e-01,  ..., -2.9741e+00,\n",
            "         -8.8853e-01,  1.9835e+00],\n",
            "        [-4.3985e-01,  3.7275e+00, -1.5651e+00,  ..., -9.8185e-01,\n",
            "          2.1494e+00,  2.8563e+00],\n",
            "        [-7.4558e-01,  4.4263e+00,  1.6755e+00,  ..., -1.1709e+00,\n",
            "          2.5378e-01,  6.7440e+00],\n",
            "        ...,\n",
            "        [ 1.8878e+00,  1.8188e+00,  4.3586e+00,  ...,  2.1168e+00,\n",
            "         -2.5582e+00,  4.9654e+00],\n",
            "        [ 4.0909e-01,  2.6498e+00, -5.0811e-03,  ..., -9.8513e-01,\n",
            "          3.0783e-01,  1.7810e+00],\n",
            "        [ 2.3771e+00, -5.4764e-01,  8.2331e-02,  ..., -1.0630e+00,\n",
            "         -8.6459e-02,  1.5950e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6153,  6.5604, -1.7187,  ..., -1.4997,  1.8140,  3.6987],\n",
            "        [ 2.0404,  3.7559, -0.0911,  ..., -1.9668,  1.9614,  4.0129],\n",
            "        [ 2.0353,  2.4404,  3.5575,  ...,  2.6838, -1.4303,  3.5713],\n",
            "        ...,\n",
            "        [ 0.7994,  2.6831, -1.6067,  ..., -1.3186,  1.1296,  2.4748],\n",
            "        [-0.3851,  7.2864,  1.4203,  ...,  1.8212, -0.4375,  4.2227],\n",
            "        [ 0.9427,  4.3163,  0.1893,  ..., -2.4932,  3.4314,  4.4645]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2311,  5.0086,  0.5157,  ...,  0.2092,  0.0272,  1.7558],\n",
            "        [-0.0998,  2.6834, -2.5741,  ..., -0.6943, -0.6173,  2.6975],\n",
            "        [ 1.6680,  2.7212, -0.5851,  ..., -3.0056,  0.5750,  2.7947],\n",
            "        ...,\n",
            "        [ 0.0502,  2.4787, -1.8722,  ...,  0.1477, -1.5549,  5.0826],\n",
            "        [ 0.6308,  2.3126, -1.5912,  ..., -4.4114,  4.5352,  3.2607],\n",
            "        [ 2.8208,  5.9728, -1.0804,  ..., -1.2919,  2.1709,  2.2790]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1702,  1.9704, -1.3464,  ..., -0.6145,  3.0267,  0.7949],\n",
            "        [ 0.5412,  1.8268, -1.1439,  ..., -1.7929, -0.2411,  1.2683],\n",
            "        [ 2.1789,  0.5178,  4.4499,  ...,  0.8672, -3.8754,  2.7222],\n",
            "        ...,\n",
            "        [ 0.3626,  3.3192,  2.8094,  ...,  1.2813, -2.3828,  0.6796],\n",
            "        [-0.1673,  0.2125,  0.9845,  ...,  0.7187, -0.1568,  1.4496],\n",
            "        [ 0.3893,  2.7223, -3.5306,  ..., -2.4874, -1.7889,  3.6346]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4177,  6.7261,  0.6736,  ..., -0.1784, -1.0966,  4.9140],\n",
            "        [ 0.1785,  3.1964,  1.5323,  ...,  3.0385, -0.8997,  2.4024],\n",
            "        [ 1.2615,  3.9669, -1.3748,  ..., -3.5095,  1.3838,  2.8605],\n",
            "        ...,\n",
            "        [ 1.1142,  5.0698,  3.3326,  ...,  2.3148, -1.6974,  9.5486],\n",
            "        [ 1.6607, -1.2102,  2.6465,  ...,  0.2242, -3.2004, -1.3676],\n",
            "        [ 1.5240,  2.1391, -1.1530,  ..., -1.3710, -0.0107,  2.6381]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2164,  3.6597,  5.3278,  ...,  4.7966,  0.3657,  4.2171],\n",
            "        [ 0.4574,  4.0072,  0.2473,  ...,  2.6672,  1.2463,  5.1596],\n",
            "        [-1.2106,  1.2557,  2.2401,  ...,  1.5733,  0.5376,  0.1781],\n",
            "        ...,\n",
            "        [-2.8582,  4.3433, -0.8484,  ..., -1.4853,  3.7500,  4.5058],\n",
            "        [-0.5617,  3.1501, -0.0427,  ..., -2.7788,  2.7981,  2.4419],\n",
            "        [-1.0115,  1.0858,  4.7374,  ...,  1.0993, -0.9804, -0.5290]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3207,  4.8780, -1.2513,  ..., -0.8604,  2.8299,  2.7186],\n",
            "        [ 1.9445,  3.1946,  5.5084,  ...,  2.9335, -0.6951,  3.9852],\n",
            "        [ 2.4639,  2.1613,  2.3396,  ..., -0.2272, -4.6509,  2.9779],\n",
            "        ...,\n",
            "        [-1.5335,  4.5849,  2.2479,  ...,  5.6796,  0.2404,  2.6329],\n",
            "        [-2.0008,  4.3936,  1.8273,  ...,  1.4070, -2.7969,  6.1517],\n",
            "        [-0.8817,  3.0799, -4.2494,  ...,  1.3482, -3.1076,  4.8430]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6443,  2.9306, -0.2235,  ..., -1.6833,  2.6154,  1.7823],\n",
            "        [ 0.6574,  0.0306,  3.4217,  ...,  4.7806, -3.5252,  4.0361],\n",
            "        [ 0.5913,  3.4267, -3.0432,  ..., -1.9644,  1.0978,  5.4319],\n",
            "        ...,\n",
            "        [-0.1076,  3.1841,  1.1267,  ..., -2.4969,  2.2145,  5.4263],\n",
            "        [ 0.1504,  1.8095, -1.3495,  ..., -3.6863,  0.5104,  2.4426],\n",
            "        [ 0.7870,  3.8373, -2.3381,  ..., -0.1573, -0.8182,  3.6503]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2309,  6.2435, -2.6988,  ..., -1.3759,  0.6823,  2.7278],\n",
            "        [-2.6443,  3.4522,  1.5809,  ...,  0.8793,  0.8471,  3.6526],\n",
            "        [-0.9824,  5.4063, -2.2900,  ..., -2.9186,  0.5675,  2.2486],\n",
            "        ...,\n",
            "        [-1.2287,  1.9736,  0.8381,  ...,  2.0625, -0.6508,  4.5167],\n",
            "        [-2.0899,  0.1195,  1.5075,  ..., -1.2841,  0.7681,  1.2192],\n",
            "        [-2.8563,  5.6223, -1.6989,  ...,  2.0360,  0.5344,  7.2464]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5645,  0.4209,  1.3822,  ..., -3.0258, -0.6681,  1.3091],\n",
            "        [-0.5139,  1.2907,  2.9187,  ..., -0.8477, -2.8893,  1.8823],\n",
            "        [-0.8487,  4.1395, -1.4802,  ..., -3.1396,  0.2905,  3.3107],\n",
            "        ...,\n",
            "        [-1.5600,  6.4883, -0.0425,  ...,  0.5160,  2.6430,  6.6551],\n",
            "        [-1.6615,  4.5283, -0.2748,  ..., -0.1304,  0.0096,  4.9524],\n",
            "        [ 0.8731,  0.2438, -1.0530,  ..., -2.6243,  0.6901,  2.1431]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8956,  4.2316, -0.3353,  ..., -2.0173,  2.1806,  1.8883],\n",
            "        [ 2.5734, -1.8942,  1.5240,  ..., -1.5167, -1.5571,  0.8659],\n",
            "        [ 2.0597,  1.4503, -0.2185,  ..., -2.2379, -0.8446,  1.7351],\n",
            "        ...,\n",
            "        [-0.5585,  4.4193, -3.6696,  ..., -0.2087,  1.2891,  2.8025],\n",
            "        [-2.4337,  1.8594,  1.6014,  ..., -2.9037,  2.8224,  3.0529],\n",
            "        [-0.6861,  1.8920,  4.1768,  ..., -1.3713,  1.2993,  2.3878]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4314,  7.0401, -1.5809,  ..., -1.1107,  0.4243,  5.7328],\n",
            "        [-0.7207,  2.6556,  1.1198,  ...,  1.0240, -0.0643,  3.7933],\n",
            "        [-0.3567,  5.3022,  1.0072,  ...,  5.8209,  0.5906,  1.8844],\n",
            "        ...,\n",
            "        [-0.3378,  4.6890, -0.6240,  ...,  1.0117,  2.0260,  2.9562],\n",
            "        [ 0.4651,  5.0806, -1.2362,  ..., -1.0482,  2.3694,  3.2023],\n",
            "        [ 1.0292,  5.1737, -1.1589,  ..., -2.1361,  1.3896,  1.9608]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0157,  3.9998, -1.7492,  ...,  0.5707,  2.1971,  6.4494],\n",
            "        [-1.2195, -0.0877,  7.5165,  ...,  2.3522, -2.1823, -1.1121],\n",
            "        [ 0.2571,  7.9995, -3.5738,  ..., -1.8851, -0.9902,  3.2957],\n",
            "        ...,\n",
            "        [ 1.7999,  1.0003, -0.8429,  ..., -2.6348, -1.8962,  1.2006],\n",
            "        [ 1.0730,  8.8093, -0.0830,  ..., -0.1982,  0.3641,  4.0099],\n",
            "        [ 0.0835,  0.6235,  1.1400,  ..., -5.1057,  0.8414,  2.1901]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0151e+00,  6.3913e-01,  1.3594e+00,  ..., -1.8862e+00,\n",
            "          7.1157e-02,  1.0306e+00],\n",
            "        [ 2.0598e-02,  3.7237e+00, -1.6350e+00,  ..., -1.4657e+00,\n",
            "          1.3607e+00,  2.7090e+00],\n",
            "        [-9.4055e-01,  4.2861e+00, -6.0674e-01,  ...,  4.4097e-03,\n",
            "         -2.1274e-01,  6.9962e+00],\n",
            "        ...,\n",
            "        [-3.0324e-02,  1.7401e+00, -2.9410e+00,  ...,  2.1316e-01,\n",
            "         -4.8214e-01,  7.3016e-01],\n",
            "        [-1.8976e+00,  5.1464e+00,  4.4692e+00,  ...,  4.9842e-01,\n",
            "         -2.6091e+00,  4.3793e+00],\n",
            "        [ 1.5232e+00,  7.4347e+00, -2.7204e-01,  ..., -1.1720e+00,\n",
            "         -1.3384e-02,  4.0034e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0393,  0.5335,  2.9194,  ...,  6.7775, -6.4884,  3.3050],\n",
            "        [ 2.3935,  0.6911,  1.5014,  ..., -0.2223, -3.5498,  1.1449],\n",
            "        [-1.7733,  2.5060,  1.0471,  ..., -1.8320,  3.3968,  2.9755],\n",
            "        ...,\n",
            "        [-0.2607,  3.2220, -4.0778,  ..., -1.2650, -0.2126,  3.1266],\n",
            "        [-0.2494,  0.8494,  0.6533,  ..., -2.1707,  1.7085,  2.5013],\n",
            "        [-1.0331,  4.8138,  1.9085,  ..., -1.4401,  0.6484,  4.3452]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6846,  3.2535, -1.8406,  ..., -3.7823,  1.5605,  4.1364],\n",
            "        [-1.7368,  0.9249, -1.5390,  ..., -2.7666,  3.2561,  2.5385],\n",
            "        [-0.8285,  2.3776,  0.2883,  ...,  1.5370, -1.4166,  3.4359],\n",
            "        ...,\n",
            "        [-0.8166,  5.4517, -1.9662,  ..., -3.6145,  2.2186,  4.4970],\n",
            "        [-1.4243,  2.9643,  2.8524,  ...,  3.0672,  1.8093,  3.9799],\n",
            "        [-0.0927,  1.2056,  0.1092,  ...,  2.0200, -0.9385,  3.7908]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.1902e-01, -4.6301e-01,  3.0511e-01,  ..., -2.2050e+00,\n",
            "         -2.0193e+00,  1.6590e+00],\n",
            "        [-7.0759e-01,  5.0621e+00,  2.5918e+00,  ...,  5.6742e-01,\n",
            "         -1.4634e+00,  4.3979e+00],\n",
            "        [-1.2847e+00,  4.2158e+00, -6.9700e-01,  ..., -1.4336e+00,\n",
            "          9.4839e-01,  5.9671e+00],\n",
            "        ...,\n",
            "        [ 2.4562e-01,  4.9671e+00,  1.7109e-01,  ...,  9.3832e-01,\n",
            "          1.1165e+00,  3.0711e+00],\n",
            "        [ 9.0554e-01,  4.9110e+00, -1.3601e+00,  ..., -2.5171e+00,\n",
            "         -1.7926e-04,  3.2258e+00],\n",
            "        [-9.1087e-01,  7.1233e-01,  3.1819e-01,  ..., -1.8486e+00,\n",
            "          1.1738e+00,  1.3008e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6645,  0.9066,  3.4320,  ...,  0.4646,  0.1368, -0.6130],\n",
            "        [-2.4495,  7.0352,  0.4728,  ..., -0.0311,  0.3773,  4.5201],\n",
            "        [-0.3530,  0.2058,  4.2137,  ..., -2.3112,  2.4765,  0.6812],\n",
            "        ...,\n",
            "        [ 0.1429,  2.7268, -1.5142,  ..., -1.3956, -0.2663,  5.2608],\n",
            "        [ 2.0405, -0.3781,  5.0217,  ...,  1.3192, -1.8643,  0.8393],\n",
            "        [-1.3605,  3.1609, -0.3204,  ..., -2.2445,  2.3756,  1.4109]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6542,  4.4955, -0.1113,  ..., -0.6364,  2.2248,  4.3569],\n",
            "        [ 0.2789,  3.0641, -0.0421,  ..., -0.8007,  0.7305,  3.6665],\n",
            "        [ 0.5344, -0.8172,  2.0052,  ...,  1.4099, -2.4706,  1.5370],\n",
            "        ...,\n",
            "        [-0.8939,  2.1489, -0.9783,  ..., -1.2362,  2.1354,  2.3506],\n",
            "        [-0.6544,  3.6161, -1.4598,  ..., -1.9811,  2.4884,  1.9962],\n",
            "        [-0.5264,  4.4914, -1.0312,  ..., -4.6371,  2.4076,  2.5227]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6623,  2.1688,  0.1431,  ..., -1.0374,  0.0419,  5.6776],\n",
            "        [-3.0169,  1.0225, -0.7786,  ..., -1.3554,  4.3250,  3.2283],\n",
            "        [ 1.3673,  0.2932,  1.5968,  ...,  0.3433, -1.2403,  2.5141],\n",
            "        ...,\n",
            "        [-1.1905,  2.5455, -2.8073,  ...,  1.1152,  2.2925,  3.8454],\n",
            "        [ 0.0460,  4.3519, -1.3126,  ..., -1.8286,  0.6618,  2.4938],\n",
            "        [-1.6039,  3.4133, -0.7776,  ..., -1.9152,  0.3439,  5.8416]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-7.5358e-02,  1.7632e+00,  1.8842e+00,  ..., -6.7637e-01,\n",
            "          7.3139e-01,  4.6277e+00],\n",
            "        [-1.8518e+00,  5.2172e+00, -1.4510e+00,  ..., -1.4852e-01,\n",
            "         -1.2123e+00,  6.6535e+00],\n",
            "        [ 7.3479e-01,  3.4164e+00, -3.9850e-01,  ..., -1.9684e+00,\n",
            "          1.5651e-03,  3.1137e+00],\n",
            "        ...,\n",
            "        [ 3.1691e-01,  6.2048e+00, -5.5236e+00,  ..., -3.5635e+00,\n",
            "         -4.0613e-01,  4.3876e+00],\n",
            "        [-2.8847e+00,  6.5582e+00, -1.7493e+00,  ...,  3.4370e+00,\n",
            "          1.5065e+00,  7.3409e+00],\n",
            "        [-1.3854e+00,  7.6565e+00,  1.1513e-02,  ...,  3.2714e+00,\n",
            "         -1.4514e+00,  8.5541e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1254,  4.4791,  3.3962,  ...,  4.7429, -1.2465,  6.0992],\n",
            "        [ 0.3434,  2.9825,  0.3513,  ..., -1.9342, -1.2844,  1.1361],\n",
            "        [-1.3483,  4.2929,  0.8606,  ..., -1.3527,  0.5871,  6.5728],\n",
            "        ...,\n",
            "        [-0.8736,  6.2043, -0.8767,  ...,  2.6441,  2.1505,  3.6186],\n",
            "        [ 0.6404,  2.6567,  1.4049,  ..., -0.2288, -1.1782,  2.4857],\n",
            "        [-0.6123,  2.9438,  0.0626,  ...,  0.2749, -0.2013,  0.8145]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6649,  4.6845,  0.1578,  ...,  1.7220,  3.1146,  5.9399],\n",
            "        [-2.0054,  1.8460,  4.6133,  ...,  2.1071, -1.7615,  4.1057],\n",
            "        [ 2.1729,  3.5374, -2.3583,  ..., -2.5526,  0.7613,  1.2488],\n",
            "        ...,\n",
            "        [-0.1116,  0.7867,  2.2086,  ..., -0.8400,  1.1926, -0.0850],\n",
            "        [-1.1905,  0.7278,  2.6169,  ...,  3.9469, -4.6456,  2.1349],\n",
            "        [-0.2430,  4.4931,  1.3538,  ...,  0.6686, -0.2447,  1.9511]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5375,  0.5679,  0.4516,  ...,  1.1638, -1.1877,  5.0431],\n",
            "        [ 1.8916,  4.3527, -0.4093,  ...,  0.6859, -2.3940,  6.0763],\n",
            "        [ 2.8823,  0.9847,  2.3767,  ..., -1.3264, -3.1798,  0.6256],\n",
            "        ...,\n",
            "        [ 0.5553,  0.9010,  0.3905,  ..., -3.9721,  0.1491,  1.4593],\n",
            "        [-1.0927,  0.3466,  0.2878,  ..., -2.0919,  0.6703,  4.4126],\n",
            "        [-1.8472,  1.7495, -0.9928,  ..., -3.1340,  1.8787,  4.1431]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3682,  1.9736,  2.1566,  ...,  0.6369,  1.9122,  0.7601],\n",
            "        [-0.4172,  4.5701,  1.3052,  ..., -2.4492,  0.3895,  6.0884],\n",
            "        [ 0.1200,  5.4684, -0.8675,  ..., -1.9609,  0.8168,  2.9485],\n",
            "        ...,\n",
            "        [ 0.6026,  5.6531,  2.9076,  ...,  4.3804, -0.1217,  3.9333],\n",
            "        [ 0.3673,  3.3617, -1.5111,  ..., -2.1058,  2.6513,  1.1599],\n",
            "        [-3.0088,  4.5891,  1.0286,  ...,  5.2459, -0.6025,  2.6893]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9136,  1.3099,  1.9863,  ...,  0.9552,  2.1965,  1.2078],\n",
            "        [-0.6390,  5.5586, -1.3678,  ...,  0.1511,  2.6832,  2.7719],\n",
            "        [ 0.1305,  4.1685,  3.7977,  ...,  2.4637,  2.1288,  3.5595],\n",
            "        ...,\n",
            "        [-0.5605,  5.6669,  0.1681,  ..., -3.1780,  0.7680,  3.3927],\n",
            "        [-1.0532,  4.3391, -1.7896,  ..., -1.3605,  3.9839,  4.3979],\n",
            "        [ 1.0747,  3.3652,  4.2145,  ...,  3.4911, -0.7265,  3.0772]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9061,  5.2045, -4.0950,  ...,  0.2304, -0.1820,  2.5139],\n",
            "        [ 1.5540,  3.0123, -3.4216,  ..., -3.0967, -0.0978,  1.8709],\n",
            "        [-0.1748,  2.1714, -2.3527,  ..., -1.6812, -1.5097,  0.9561],\n",
            "        ...,\n",
            "        [ 0.2239,  0.4582,  0.2814,  ..., -0.5861,  0.2876,  2.7898],\n",
            "        [-1.1650,  4.0863,  0.2727,  ...,  0.3853,  0.3477,  6.6188],\n",
            "        [-2.6239,  7.0812, -2.7372,  ...,  2.7471,  0.4613,  6.4450]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8689, 10.1691, -1.1139,  ...,  0.3928,  3.5257,  7.2192],\n",
            "        [-1.3042,  2.8689, -1.0786,  ...,  0.5010,  1.1480,  4.1952],\n",
            "        [-0.1443,  5.5094,  1.9246,  ...,  0.1545, -0.2921,  6.5401],\n",
            "        ...,\n",
            "        [ 1.8642,  1.4892,  0.6045,  ...,  0.3349, -2.6967,  4.1714],\n",
            "        [-0.7656, -0.9018,  1.2688,  ..., -3.2210,  0.6533,  1.1088],\n",
            "        [-0.5391,  4.9357, -1.7166,  ..., -0.5126, -1.6422,  5.9067]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5011,  3.1988, -0.1728,  ..., -2.0981,  1.6246,  1.8459],\n",
            "        [-0.8587,  3.8455, -1.1492,  ..., -1.6000,  1.9769,  2.4903],\n",
            "        [ 0.8191,  0.2054,  0.2554,  ..., -3.9348, -1.9723,  2.2976],\n",
            "        ...,\n",
            "        [ 0.1426,  0.8230, -0.0786,  ..., -5.7420,  0.8442,  2.7200],\n",
            "        [-1.7717, 10.4536,  2.6608,  ...,  5.9113, -0.0571,  6.5794],\n",
            "        [ 2.3318,  1.7578,  4.6551,  ..., -3.4012, -3.0771,  1.2662]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3005,  3.2475,  1.0475,  ..., -0.2095,  1.4229,  1.6765],\n",
            "        [-1.5739,  1.1520,  0.0134,  ...,  1.3115,  0.5762,  3.6305],\n",
            "        [ 1.8325,  1.2334, -1.2860,  ..., -1.2221, -1.3170,  0.9704],\n",
            "        ...,\n",
            "        [ 2.0203,  5.8389, -0.7039,  ..., -2.1245, -1.0822,  3.4147],\n",
            "        [ 4.1444,  4.4214, -0.7297,  ..., -2.7238,  1.1812,  2.8241],\n",
            "        [-0.6348,  3.8606, -1.0219,  ..., -1.8593, -0.6664,  4.3793]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0218,  2.7827,  1.1169,  ...,  1.4019, -1.3158,  2.9802],\n",
            "        [-0.7976,  1.1348, -2.5155,  ..., -5.7383, -0.2456,  2.1583],\n",
            "        [-1.0277,  4.2967,  0.0735,  ..., -0.5182,  2.5598,  1.5841],\n",
            "        ...,\n",
            "        [ 0.5061,  5.0530, -1.6602,  ..., -1.4295,  0.2610,  3.0281],\n",
            "        [-2.5691,  5.6270, -0.0844,  ...,  0.2343,  1.5863,  4.0249],\n",
            "        [ 1.1335, -1.8613, -0.0481,  ..., -3.1748, -2.2100,  3.6550]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2922,  1.4546,  2.2877,  ..., -1.2102, -1.4887,  5.3402],\n",
            "        [ 0.2217,  1.2812,  4.6120,  ..., -4.4224,  1.9287,  1.8374],\n",
            "        [ 1.7346,  1.5255,  1.5814,  ...,  0.7954, -2.6103,  3.5724],\n",
            "        ...,\n",
            "        [-0.0451,  0.6155,  0.2230,  ...,  1.2088, -1.9476,  1.9466],\n",
            "        [-1.2166,  2.2621, -1.1508,  ..., -4.0974,  3.3832,  4.1079],\n",
            "        [-2.0796,  8.7605, -1.0444,  ..., -2.2656,  0.8092,  5.1528]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3368,  0.9267,  3.6232,  ...,  0.8090, -3.5254,  1.8019],\n",
            "        [-3.6542,  6.4574, -0.6800,  ...,  1.0534,  1.4310,  3.0025],\n",
            "        [-0.0773,  2.2733,  1.3571,  ..., -0.7284,  2.4079,  1.2974],\n",
            "        ...,\n",
            "        [ 0.1673,  2.9120,  1.3639,  ..., -3.1063, -1.8163,  3.2829],\n",
            "        [ 1.1064,  2.1493, -0.4980,  ..., -2.2130,  0.4131,  0.2708],\n",
            "        [-0.3302,  2.8138,  0.1881,  ..., -1.3650,  1.4897,  1.1509]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7528,  2.9591,  1.6736,  ..., -3.0560,  1.7173,  1.9982],\n",
            "        [-0.1412, -2.0753,  2.8703,  ..., -3.2505, -0.2905,  2.0348],\n",
            "        [ 0.5194,  0.7644,  3.5302,  ..., -2.7892, -0.7647,  1.8651],\n",
            "        ...,\n",
            "        [-0.6110,  4.1591,  4.3907,  ...,  1.1798, -0.3944,  2.8095],\n",
            "        [-0.0140,  4.1778, -1.8277,  ..., -0.5306,  1.4356,  1.8913],\n",
            "        [ 1.4331, -0.4407,  1.9424,  ...,  2.6063, -7.1460,  5.4967]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2014,  5.7306, -0.8258,  ..., -3.5909,  0.7247,  1.4491],\n",
            "        [ 4.2261,  4.4660, -0.4122,  ..., -3.1407, -0.2212,  3.6908],\n",
            "        [-1.5483,  4.0265, -1.0889,  ..., -0.7889, -1.0792,  4.6713],\n",
            "        ...,\n",
            "        [-2.3826, -0.0095,  2.3333,  ..., -4.1551,  1.4156,  1.6205],\n",
            "        [ 0.8918,  7.3957,  2.2254,  ...,  2.2056, -0.8979,  6.5321],\n",
            "        [-2.4106,  3.1093,  1.5565,  ..., -2.4291,  3.1454,  3.4996]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.4338,  3.8173,  1.0692,  ..., -0.8049, -0.3554,  3.1060],\n",
            "        [-0.1066,  5.0286, -2.1944,  ..., -2.6521,  1.6285,  4.6399],\n",
            "        [-0.4579,  2.8345, -3.1858,  ...,  0.8971,  0.0322,  2.6792],\n",
            "        ...,\n",
            "        [-4.3108,  6.2634, -0.9821,  ..., -0.2298,  1.5490,  5.0102],\n",
            "        [ 1.2642,  0.6595,  2.1911,  ..., -2.3985, -2.7227,  2.2034],\n",
            "        [ 2.4989, -0.0242,  5.4398,  ..., -4.6731, -4.2484,  3.4385]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0440,  1.0974,  1.2012,  ..., -3.9859,  2.4397,  2.1053],\n",
            "        [-1.6178,  5.7455, -1.2794,  ..., -3.7776,  0.5835,  6.0573],\n",
            "        [-0.9852,  6.0760,  0.5659,  ..., -1.1677,  1.5562,  2.5760],\n",
            "        ...,\n",
            "        [ 0.4454,  6.2378, -0.1725,  ..., -1.9048,  0.5046,  2.8634],\n",
            "        [-0.7209,  4.5542, -1.5727,  ..., -1.6005,  1.4270,  1.2796],\n",
            "        [-0.9253,  1.2916,  5.4683,  ...,  1.3326,  1.3170, -0.9021]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3050,  3.0516, -0.7417,  ..., -1.2663,  1.9440,  1.8004],\n",
            "        [ 2.6924,  0.0895,  4.9801,  ...,  0.2577, -3.1469,  3.4970],\n",
            "        [ 2.2937,  8.8796,  0.0449,  ...,  2.6530, -1.6372,  6.0397],\n",
            "        ...,\n",
            "        [ 0.1828, -0.3813,  0.6039,  ..., -3.4733, -1.6444,  1.9949],\n",
            "        [-4.0540,  3.0484,  0.9029,  ..., -1.9778,  1.9544,  4.2274],\n",
            "        [ 1.2257,  3.5928,  0.1247,  ..., -2.3631,  2.5328,  2.0835]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1280, -0.2504,  4.9188,  ..., -3.1914,  0.1923, -0.0145],\n",
            "        [ 1.1999,  4.2040,  4.0538,  ...,  3.6181, -1.3360,  1.5184],\n",
            "        [-0.9264,  1.6068,  4.9493,  ..., -0.3773,  3.2740,  0.2496],\n",
            "        ...,\n",
            "        [ 0.1072,  2.9787,  2.7733,  ...,  4.7146, -0.9379,  3.8393],\n",
            "        [-1.7546,  6.9012,  4.2934,  ...,  6.3138,  2.0821,  5.1591],\n",
            "        [ 2.9899, -0.8420,  1.4548,  ..., -0.8052, -3.8622,  1.8986]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0536,  7.2457,  0.8800,  ..., -0.8189,  0.3826,  4.6775],\n",
            "        [-1.7116,  2.9859,  1.4314,  ..., -2.3362,  1.2601,  2.9627],\n",
            "        [-3.3935,  7.4462,  0.0083,  ...,  0.0232,  0.4404,  7.3795],\n",
            "        ...,\n",
            "        [ 1.4151,  3.0718, -0.0701,  ..., -0.2989, -2.6860,  3.0922],\n",
            "        [-1.9155,  1.0537,  0.2384,  ...,  0.0402, -1.0333,  3.3262],\n",
            "        [-2.1409,  4.5183,  0.1771,  ..., -1.5920,  2.3196,  3.5270]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5790e-01,  1.4838e-01, -1.8668e+00,  ..., -2.2648e+00,\n",
            "          8.3153e-01,  1.0058e+00],\n",
            "        [ 1.1410e+00,  4.6093e+00, -1.0904e-01,  ..., -3.6931e+00,\n",
            "         -3.1086e-01,  2.7128e+00],\n",
            "        [-1.3153e+00,  1.9097e+00,  2.5908e+00,  ..., -3.3572e+00,\n",
            "          1.4405e+00,  1.2763e+00],\n",
            "        ...,\n",
            "        [ 1.5572e-01, -7.7719e-01, -3.2803e-02,  ..., -1.4932e+00,\n",
            "         -2.9237e+00,  1.8169e+00],\n",
            "        [-7.2443e-01,  2.3955e+00, -1.5489e+00,  ...,  1.9200e+00,\n",
            "         -3.5732e-03,  1.8689e+00],\n",
            "        [ 1.5008e+00,  7.0829e+00,  2.7133e+00,  ...,  5.8714e-01,\n",
            "          2.9466e+00,  2.1293e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9990,  1.9960, -1.1422,  ..., -0.9864,  1.2927,  3.1675],\n",
            "        [ 0.7672,  2.1790, -1.8720,  ..., -1.1065, -0.7866,  2.9482],\n",
            "        [ 0.0316,  2.1598, -2.6785,  ..., -1.9404, -2.3711,  1.2224],\n",
            "        ...,\n",
            "        [-0.8052,  3.3578, -1.0060,  ..., -2.2519,  1.7362,  1.6647],\n",
            "        [-2.0042,  5.4606,  1.0906,  ..., -3.8512,  1.6904,  8.7425],\n",
            "        [-0.5611,  6.8043, -0.6716,  ..., -3.2856,  1.9544,  3.8968]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4280,  4.2533, -1.9096,  ..., -3.4741,  1.2710,  5.1241],\n",
            "        [-0.6102,  5.9363,  1.0973,  ..., -2.8613,  2.8470,  3.5684],\n",
            "        [-0.8834,  4.3352, -0.8134,  ..., -2.0798, -1.5042,  4.5153],\n",
            "        ...,\n",
            "        [-0.6913,  9.7573,  1.6996,  ...,  0.3518,  1.7641,  3.0645],\n",
            "        [ 0.4089,  5.7544,  0.3731,  ...,  1.4962, -3.6921,  3.1490],\n",
            "        [-0.0877,  5.0248,  0.1828,  ..., -1.4865, -0.2705,  5.6371]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2430,  5.7546, -3.0503,  ..., -3.5379,  1.2574,  2.4464],\n",
            "        [-0.0761,  2.6329, -0.3917,  ..., -4.3866, -1.3839,  1.6796],\n",
            "        [ 0.3855,  3.1904,  2.5117,  ...,  4.0246, -1.1784,  0.8827],\n",
            "        ...,\n",
            "        [-0.4862,  4.3849, -2.9490,  ..., -1.0481, -1.2540,  6.2169],\n",
            "        [ 0.4902,  1.4855,  1.6362,  ..., -1.7223,  1.3242,  1.4780],\n",
            "        [-0.2750,  4.6704,  4.8509,  ..., -0.7473,  0.0427,  4.6416]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1715,  3.4443, -1.6259,  ..., -3.8919,  2.5960,  0.2700],\n",
            "        [-0.7267,  1.9734,  4.9518,  ...,  0.0915, -2.0942, -0.9232],\n",
            "        [ 1.1745,  0.2388,  2.3536,  ..., -0.8745, -3.4981, -0.5627],\n",
            "        ...,\n",
            "        [ 2.9219,  3.8470,  2.1497,  ..., -0.3860, -2.0586,  3.2331],\n",
            "        [-0.0858,  7.7404,  4.8656,  ...,  3.1517, -0.0944,  4.1365],\n",
            "        [-1.2909,  6.6600, -0.3215,  ..., -1.7143, -0.5846,  4.2738]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7146, -0.0399, -0.6204,  ..., -2.8993,  0.5302,  3.5618],\n",
            "        [-0.3701,  3.5152,  0.1335,  ..., -0.8865,  1.3831,  5.2754],\n",
            "        [ 0.8022,  1.7296,  2.2031,  ..., -1.0296, -2.1664,  2.4143],\n",
            "        ...,\n",
            "        [ 0.4578,  0.8174,  2.1898,  ..., -4.4048,  0.2508,  2.9474],\n",
            "        [-0.1948,  1.5667, -0.8448,  ..., -0.2365, -3.2611,  3.8721],\n",
            "        [ 0.2796,  3.7686, -2.5580,  ..., -3.1855, -0.6846,  4.0102]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1807,  0.5707,  4.6973,  ..., -2.8964,  0.0438, -0.5698],\n",
            "        [ 0.7541, -0.3090,  2.5132,  ...,  0.4959, -4.2967,  2.7728],\n",
            "        [ 0.1943,  2.3247, -2.2911,  ..., -2.3446, -2.3643,  0.7459],\n",
            "        ...,\n",
            "        [ 1.3725,  7.3770,  2.6933,  ...,  2.8120,  2.4674,  1.7075],\n",
            "        [ 0.4091,  2.0582,  0.1696,  ..., -3.4667, -0.8600,  2.2379],\n",
            "        [ 1.0151,  1.5996,  2.4776,  ...,  1.3282, -1.1534,  3.8295]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7642,  3.7092,  2.5641,  ..., -2.3037,  1.8258,  6.4258],\n",
            "        [-1.4268,  0.0802,  0.8117,  ..., -4.0503,  1.5141,  2.1112],\n",
            "        [ 0.5354,  5.7353, -0.8216,  ..., -0.6956,  1.8600,  2.4615],\n",
            "        ...,\n",
            "        [-1.3393,  2.1045,  1.5957,  ..., -2.4274,  1.6401,  1.3841],\n",
            "        [ 0.8441,  2.7778, -0.3880,  ..., -1.5985, -0.2285,  1.8969],\n",
            "        [-0.6356,  1.1993,  2.8986,  ...,  0.6690, -2.6831,  3.8005]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4602,  4.7938,  4.8822,  ...,  6.1547, -1.8372,  1.4571],\n",
            "        [-1.4738,  3.4557,  1.2954,  ...,  0.0236, -0.2478,  3.9655],\n",
            "        [ 1.9400,  7.0575, -1.1268,  ..., -0.2597,  1.1745,  4.2028],\n",
            "        ...,\n",
            "        [ 1.3892, -1.4272,  3.3664,  ..., -1.4119, -2.7296, -0.9827],\n",
            "        [ 0.7615,  2.7044,  1.6988,  ..., -1.6999, -0.2324,  6.2544],\n",
            "        [-1.0836,  5.3185,  0.0644,  ..., -1.8217,  1.9074,  3.1208]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5446,  2.9179, -0.3895,  ...,  0.0844,  1.9924,  3.1237],\n",
            "        [ 0.2228,  2.6149,  2.1603,  ...,  3.7607, -1.8306,  0.1241],\n",
            "        [-0.6549,  3.6344,  1.2663,  ..., -2.9322,  2.2474,  2.8671],\n",
            "        ...,\n",
            "        [-0.9384,  1.4525,  2.7077,  ..., -3.3059,  2.9019,  2.0048],\n",
            "        [ 0.3583,  2.7610,  0.7458,  ..., -1.4972, -1.1249,  2.0238],\n",
            "        [ 1.4123,  3.0344, -0.4542,  ..., -2.4562, -0.0371,  3.0379]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3977, -0.7426,  4.7142,  ..., -2.0493, -2.7469, -1.0572],\n",
            "        [-0.1500,  3.4022,  0.6538,  ..., -5.0550,  2.2796,  2.2535],\n",
            "        [ 1.1397,  4.8476,  1.0858,  ...,  2.4305,  1.3867,  4.9252],\n",
            "        ...,\n",
            "        [ 3.1123,  5.4935, -0.1003,  ..., -3.0169,  0.4257,  1.2954],\n",
            "        [ 0.9251,  1.1114,  2.6132,  ..., -0.5909, -0.7937,  2.2541],\n",
            "        [ 0.3835,  0.1930,  5.2336,  ..., -4.4145, -0.3503,  1.7855]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6688,  1.7968,  3.8201,  ..., -0.7364,  0.0331,  0.9491],\n",
            "        [ 0.3248,  3.9572,  2.8126,  ...,  4.6245, -0.1663,  2.9443],\n",
            "        [ 1.9386,  0.2726,  0.8067,  ..., -3.3248, -1.7541,  2.7951],\n",
            "        ...,\n",
            "        [ 0.9229,  2.5941, -0.7603,  ..., -4.3048,  2.7436,  1.8972],\n",
            "        [ 4.2043,  0.6199,  0.6310,  ...,  0.2035, -2.9167,  2.2393],\n",
            "        [ 1.5754,  3.6529,  2.0685,  ...,  3.0190, -1.6827,  1.6758]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9791,  0.5327,  0.3628,  ..., -4.5525, -1.3281,  1.1609],\n",
            "        [-0.4874,  0.0788,  1.3971,  ..., -3.0528,  0.0634,  2.6589],\n",
            "        [ 0.0566,  4.2188, -1.2844,  ..., -1.1238,  0.8513,  3.5634],\n",
            "        ...,\n",
            "        [-0.8191,  6.2570, -1.5756,  ..., -1.9428,  0.4328,  5.6992],\n",
            "        [-0.3415,  5.4819,  6.3574,  ...,  4.3974, -2.0711,  4.2619],\n",
            "        [ 0.0791,  3.3418, -1.8659,  ..., -1.5603, -1.9973,  5.0357]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3648e+00,  5.2812e+00, -8.8027e-01,  ..., -2.4857e+00,\n",
            "          9.7502e-01,  7.0165e+00],\n",
            "        [-7.2249e-04,  1.8552e+00,  2.7362e+00,  ...,  7.4330e-01,\n",
            "          2.0676e+00,  1.4677e+00],\n",
            "        [ 2.3510e+00,  4.2809e-01, -1.7352e+00,  ..., -9.0850e-01,\n",
            "         -1.7030e+00,  1.2308e+00],\n",
            "        ...,\n",
            "        [ 6.0994e-01,  3.0173e+00,  6.8581e-01,  ...,  2.7067e-01,\n",
            "          1.5831e+00,  3.3501e+00],\n",
            "        [-3.3372e-01,  3.0523e+00, -2.4252e-01,  ..., -2.1089e+00,\n",
            "          1.5508e+00,  2.0469e+00],\n",
            "        [-2.6361e+00,  5.0991e+00,  1.3079e+00,  ...,  6.6498e+00,\n",
            "         -7.7724e-01,  2.9425e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0791, -1.3343,  4.9581,  ..., -2.0118, -1.3960,  3.2254],\n",
            "        [ 0.0353,  2.9976,  2.3912,  ...,  1.2618, -3.7093,  5.3344],\n",
            "        [ 1.0033, -1.4091,  2.5660,  ..., -5.1516, -0.3408,  0.6493],\n",
            "        ...,\n",
            "        [ 1.2355,  3.4457, -1.7246,  ..., -1.3891,  1.1369,  5.5207],\n",
            "        [ 0.0925,  0.5792,  2.2296,  ...,  0.5525, -2.0213,  3.0467],\n",
            "        [ 1.5255,  1.1629,  0.6470,  ...,  0.9243, -4.1054,  1.4390]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1112,  4.7651, -2.7221,  ..., -1.7466,  0.5592,  4.9102],\n",
            "        [ 1.1107,  0.6707,  0.9330,  ..., -3.4505, -1.3163,  3.2357],\n",
            "        [ 0.0200,  4.2218,  0.0710,  ..., -1.3519,  1.3363,  2.0369],\n",
            "        ...,\n",
            "        [ 1.7771, -1.0698,  5.3399,  ...,  1.4397, -2.0580,  2.4582],\n",
            "        [ 3.3057,  3.9331,  0.4491,  ..., -0.0908,  1.5638,  1.6794],\n",
            "        [ 1.7167,  0.3122,  3.1453,  ..., -0.6380, -2.6646,  3.5465]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3601,  1.6805, -1.7268,  ..., -3.7939,  2.4420,  1.5180],\n",
            "        [ 0.0173, -0.3045,  1.2606,  ..., -4.9575,  0.5640,  2.1185],\n",
            "        [-1.0946,  1.6994, -0.0762,  ..., -1.5519,  1.6691,  0.9688],\n",
            "        ...,\n",
            "        [ 1.1646,  2.9855,  0.5103,  ..., -1.6257,  1.7584,  2.1304],\n",
            "        [ 0.5110,  2.0498,  0.4750,  ..., -1.1072,  0.7420,  2.4904],\n",
            "        [ 0.3338,  4.5084,  2.1465,  ...,  5.0854, -4.4970,  1.4337]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8159,  1.5593,  4.7323,  ..., -0.9502,  2.2608, -0.3259],\n",
            "        [-0.7503,  3.1276,  4.5227,  ...,  4.0839, -6.0690,  1.9148],\n",
            "        [-0.4980,  3.9184,  0.7798,  ..., -2.0346,  2.6946,  5.4346],\n",
            "        ...,\n",
            "        [ 3.0169,  3.7516,  0.5345,  ...,  0.1987,  0.3893,  3.8656],\n",
            "        [-1.0730,  2.3317,  2.0511,  ..., -1.0349,  2.1121,  3.8147],\n",
            "        [-0.3951,  6.1298, -1.1586,  ..., -2.4556,  3.1000,  3.5455]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9537,  1.6182, -1.2832,  ..., -3.7269,  1.2530,  0.7838],\n",
            "        [-0.9263,  4.0162, -1.2874,  ..., -1.4600,  0.7348,  2.1858],\n",
            "        [ 0.1850,  1.2369,  0.2696,  ..., -1.7047,  1.6896,  3.9562],\n",
            "        ...,\n",
            "        [-0.4758,  7.3780,  6.0246,  ..., 10.1047,  0.3521,  4.4419],\n",
            "        [-0.7922,  0.0370, -0.9137,  ...,  1.2464,  1.4043,  1.4741],\n",
            "        [-1.1480,  1.2898,  2.2008,  ...,  0.8954, -1.8768,  3.1937]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9406,  8.3380, -0.5209,  ...,  1.5625,  1.6107,  7.8401],\n",
            "        [ 1.7522,  0.9289,  4.6397,  ..., -4.3980, -0.4751,  2.1236],\n",
            "        [-0.9373,  3.8966,  1.2215,  ...,  4.1706,  0.2074,  0.8183],\n",
            "        ...,\n",
            "        [-1.8442,  2.7215,  1.1747,  ..., -1.0151, -1.6192,  2.8569],\n",
            "        [-0.7518,  7.0671,  0.4956,  ...,  0.0957,  1.5649,  3.3279],\n",
            "        [-0.9064,  5.6916,  2.2950,  ...,  2.5627, -0.0290,  2.8368]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9022,  2.9929,  3.9446,  ...,  2.4972,  1.2773,  1.2344],\n",
            "        [ 3.4193,  3.4031,  0.9206,  ...,  0.2400, -0.4634,  4.1733],\n",
            "        [-1.2029,  2.4427, -1.0419,  ..., -0.6755, -0.6718,  4.7167],\n",
            "        ...,\n",
            "        [ 2.2883,  3.8439, -0.1619,  ...,  0.3691, -0.6410,  5.3914],\n",
            "        [-0.9321,  2.3717, -0.3634,  ...,  0.0394,  1.7296,  4.3093],\n",
            "        [ 0.5612,  4.7435, -0.8866,  ...,  0.5603,  1.1353,  2.3572]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7103,  1.6336,  3.3502,  ..., -0.4604, -0.4593,  2.5091],\n",
            "        [ 1.9243,  3.9920, -1.2463,  ..., -1.1583,  0.0089,  2.2843],\n",
            "        [-1.0310,  5.9792,  3.0453,  ...,  3.4802, -2.2908,  6.1576],\n",
            "        ...,\n",
            "        [-1.0213,  4.1859,  1.6146,  ..., -1.0136,  4.7492,  6.7902],\n",
            "        [-1.1032,  2.8855, -0.3771,  ..., -0.9413,  1.8811,  2.5008],\n",
            "        [-1.2264,  1.2825,  2.4940,  ...,  0.7903,  0.8051, -0.7387]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4115,  2.4454, -3.1263,  ..., -2.6577,  1.0331,  2.6905],\n",
            "        [ 0.5926,  1.8629,  3.5820,  ..., -0.0848, -0.5607,  2.9552],\n",
            "        [ 0.3334,  2.4564,  0.1065,  ..., -2.3239,  2.0139,  1.2358],\n",
            "        ...,\n",
            "        [ 0.8003,  1.2480,  2.4994,  ..., -2.0357, -1.3970,  2.7525],\n",
            "        [ 1.2360, -0.9751,  3.8610,  ..., -1.5701, -2.4108,  2.0939],\n",
            "        [-0.4074,  4.1354,  0.8376,  ..., -0.8984, -2.5127,  2.4273]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0151,  4.5828,  2.4890,  ...,  1.4079, -1.1136,  6.2110],\n",
            "        [ 2.1648, -1.7450,  0.0739,  ..., -1.7441, -2.6526,  3.8306],\n",
            "        [ 0.4528,  1.7702,  0.8149,  ..., -1.3758,  1.7501,  3.2876],\n",
            "        ...,\n",
            "        [ 1.2353,  0.7879, -1.1727,  ..., -2.2539, -1.8058,  1.3364],\n",
            "        [ 3.6785,  3.6362,  2.0394,  ...,  1.0672, -1.1036, -0.2534],\n",
            "        [ 0.1260,  7.2451,  7.4288,  ...,  9.0420,  0.1931,  4.2257]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6181,  4.9095, -0.9110,  ...,  1.7841,  0.1403,  4.8812],\n",
            "        [-0.5964,  6.9139, -0.3308,  ..., -1.9923,  0.9952,  3.3259],\n",
            "        [ 0.0484,  1.1734, -0.1229,  ..., -3.7779,  0.6191,  1.3903],\n",
            "        ...,\n",
            "        [-0.0278,  1.4532, -1.0697,  ..., -1.5037, -0.9794,  0.9715],\n",
            "        [ 0.7495,  5.8830,  0.7491,  ..., -4.4234,  2.9307,  5.5036],\n",
            "        [-0.4504,  5.4052,  1.1777,  ...,  3.8653, -0.8567,  1.1883]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9144,  2.5852, -0.2070,  ..., -0.9329, -3.1646,  3.1773],\n",
            "        [ 0.7392,  2.3341, -1.2611,  ..., -1.9750,  0.8378,  2.8196],\n",
            "        [ 1.5589,  4.8676,  1.4889,  ...,  0.3776,  2.5127,  2.0579],\n",
            "        ...,\n",
            "        [ 1.8500,  2.6537,  0.0408,  ..., -1.6773,  0.8003,  3.3129],\n",
            "        [-0.2442,  1.4119,  3.6327,  ..., -0.0681,  1.4292,  1.5920],\n",
            "        [-0.0643,  4.6861,  1.5031,  ..., -2.5432,  1.1438,  5.5692]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2630,  9.0084, -2.5131,  ..., -1.4556, -1.4948,  5.9959],\n",
            "        [ 1.9829,  5.4027,  1.5869,  ..., -0.1483,  0.9615,  5.5181],\n",
            "        [ 2.7360,  1.6825, -0.4958,  ..., -2.7495, -0.6320,  1.1324],\n",
            "        ...,\n",
            "        [-0.0600,  3.0306, -0.7689,  ..., -1.6463, -2.7526,  3.3121],\n",
            "        [ 0.3884,  0.2672, -0.0498,  ..., -3.0876, -3.9675,  2.1742],\n",
            "        [ 1.0820,  2.4601, -2.5359,  ..., -2.5574, -1.2359,  2.4751]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3739,  3.8502, -2.8520,  ..., -2.1536, -0.8504,  3.2617],\n",
            "        [ 3.8847,  5.3197,  0.3557,  ..., -2.8573,  3.7438,  2.7641],\n",
            "        [ 4.3305,  0.6188,  4.0495,  ...,  0.4148, -3.0239,  2.3058],\n",
            "        ...,\n",
            "        [-1.5713,  6.9288,  0.5267,  ...,  0.9644, -1.8549,  3.3679],\n",
            "        [-0.0512,  3.7464, -0.3773,  ..., -2.3805,  0.8936,  5.2109],\n",
            "        [ 1.2981,  2.0648, -0.7704,  ..., -1.9884,  2.3855,  3.3140]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2315,  4.1572, -1.3459,  ..., -2.1367,  2.2218,  7.2207],\n",
            "        [ 2.4343,  3.7654,  3.2740,  ...,  4.8920, -0.7565,  1.5689],\n",
            "        [ 0.0558,  3.2087,  0.5042,  ..., -2.9447,  1.4515,  1.0228],\n",
            "        ...,\n",
            "        [-1.0584,  4.8758,  2.7845,  ...,  6.8330, -0.6820,  2.7020],\n",
            "        [ 0.6275,  3.4175,  0.9384,  ..., -2.2105,  2.4079,  1.6918],\n",
            "        [-0.0570,  3.5546,  0.2687,  ..., -2.3873,  2.9488,  3.6168]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3944,  2.2771, -0.0291,  ..., -1.8035,  4.1508,  1.8029],\n",
            "        [ 0.8954,  0.1672,  0.1228,  ..., -4.3499, -0.7203,  2.7341],\n",
            "        [ 0.1316,  4.7174,  0.1348,  ...,  0.1656,  0.2666,  2.9697],\n",
            "        ...,\n",
            "        [ 2.2918,  1.0285, -0.4983,  ..., -5.6051,  0.0626,  2.7229],\n",
            "        [-0.2184, -0.8725,  2.4298,  ..., -1.2196, -2.1333,  0.8048],\n",
            "        [ 1.1181,  3.5409, -1.6653,  ..., -2.1360,  0.2984,  3.4658]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.0701,  4.2730,  1.0134,  ..., -3.0409,  2.3395,  1.8528],\n",
            "        [ 1.1747, -0.1425, -0.7401,  ..., -3.0930, -2.4806,  1.5854],\n",
            "        [ 1.0583,  3.8837,  0.7329,  ...,  0.7570, -3.3118,  3.6402],\n",
            "        ...,\n",
            "        [ 0.9840,  5.3799,  1.7786,  ..., -2.3843,  0.6037,  5.8464],\n",
            "        [-0.2360,  5.2973, -1.8478,  ..., -0.5581, -0.3610,  7.5417],\n",
            "        [ 1.9401,  1.9747,  3.0893,  ...,  2.2405, -5.1504,  4.4342]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6280,  1.7418,  4.1253,  ...,  3.4630, -6.5870,  2.8595],\n",
            "        [ 3.4846,  7.1800,  0.7465,  ..., -1.9346,  1.6389,  3.6255],\n",
            "        [-0.3556,  1.1447,  1.0891,  ..., -3.9235,  1.6977,  1.2418],\n",
            "        ...,\n",
            "        [ 0.6807,  5.7015,  2.0194,  ...,  1.6167, -1.1961,  1.5148],\n",
            "        [ 0.4407,  3.3319,  6.7153,  ...,  5.3139, -4.5677,  4.2725],\n",
            "        [ 3.7740,  0.2362,  3.7488,  ..., -2.6715, -4.0679,  2.7919]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2596,  3.2547,  3.7089,  ...,  1.6288,  0.2886,  0.8066],\n",
            "        [-2.5524,  2.6624, -1.3673,  ..., -1.8312,  0.4638,  5.1100],\n",
            "        [-2.1610,  6.7511, -0.5954,  ..., -2.7317, -0.6412,  4.9604],\n",
            "        ...,\n",
            "        [ 2.8132, 10.7118, -4.2652,  ..., -1.6321, -0.8501,  4.0192],\n",
            "        [ 3.5262,  4.7404,  0.7268,  ..., -1.5470,  0.0706,  2.5572],\n",
            "        [-0.8322,  4.7427, -0.9780,  ..., -0.9763,  4.0675,  2.5555]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = SimpleMLP().to(device)\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 3\n",
        "\n",
        "mnist_trainset, _ = get_mnist()\n",
        "mnist_trainloader = DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "optimizer = t.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    pbar = tqdm(mnist_trainloader)\n",
        "\n",
        "    for imgs, labels in pbar:\n",
        "        # Move data to device, perform forward pass\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        logits = model(imgs)\n",
        "\n",
        "        # Calculate loss, perform backward pass\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Update logs & progress bar\n",
        "        loss_list.append(loss.item())\n",
        "        pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VkiH-f3sjBUO",
        "outputId": "8101f5bd-b69d-4b30-e7d9-f42533a6c791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c71a6584-22a3-49ca-8f5e-16630a793282\" class=\"plotly-graph-div\" style=\"height:525px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c71a6584-22a3-49ca-8f5e-16630a793282\")) {                    Plotly.newPlot(                        \"c71a6584-22a3-49ca-8f5e-16630a793282\",                        [{\"hovertemplate\":\"Examples seen=%{x}\\u003cbr\\u003eCross entropy loss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,127.11864406779661,254.23728813559322,381.35593220338984,508.47457627118644,635.5932203389831,762.7118644067797,889.8305084745763,1016.9491525423729,1144.0677966101696,1271.1864406779662,1398.3050847457628,1525.4237288135594,1652.542372881356,1779.6610169491526,1906.7796610169491,2033.8983050847457,2161.0169491525426,2288.135593220339,2415.2542372881358,2542.3728813559323,2669.491525423729,2796.6101694915255,2923.728813559322,3050.8474576271187,3177.9661016949153,3305.084745762712,3432.2033898305085,3559.322033898305,3686.4406779661017,3813.5593220338983,3940.677966101695,4067.7966101694915,4194.9152542372885,4322.033898305085,4449.152542372882,4576.271186440678,4703.389830508475,4830.5084745762715,4957.627118644068,5084.745762711865,5211.864406779661,5338.983050847458,5466.1016949152545,5593.220338983051,5720.338983050848,5847.457627118644,5974.576271186441,6101.6949152542375,6228.813559322034,6355.932203389831,6483.050847457627,6610.169491525424,6737.28813559322,6864.406779661017,6991.525423728814,7118.64406779661,7245.762711864407,7372.881355932203,7500.0,7627.118644067797,7754.237288135593,7881.35593220339,8008.474576271186,8135.593220338983,8262.71186440678,8389.830508474577,8516.949152542373,8644.06779661017,8771.186440677966,8898.305084745763,9025.42372881356,9152.542372881357,9279.661016949152,9406.77966101695,9533.898305084746,9661.016949152543,9788.135593220339,9915.254237288136,10042.372881355932,10169.49152542373,10296.610169491525,10423.728813559323,10550.847457627118,10677.966101694916,10805.084745762711,10932.203389830509,11059.322033898305,11186.440677966102,11313.559322033898,11440.677966101695,11567.796610169491,11694.915254237289,11822.033898305084,11949.152542372882,12076.271186440677,12203.389830508475,12330.50847457627,12457.627118644068,12584.745762711864,12711.864406779661,12838.983050847457,12966.101694915254,13093.22033898305,13220.338983050848,13347.457627118643,13474.57627118644,13601.694915254237,13728.813559322034,13855.93220338983,13983.050847457627,14110.169491525423,14237.28813559322,14364.406779661016,14491.525423728814,14618.64406779661,14745.762711864407,14872.881355932202,15000.0,15127.118644067796,15254.237288135593,15381.355932203389,15508.474576271186,15635.593220338982,15762.71186440678,15889.830508474575,16016.949152542373,16144.067796610168,16271.186440677966,16398.305084745763,16525.42372881356,16652.542372881355,16779.661016949154,16906.77966101695,17033.898305084746,17161.01694915254,17288.13559322034,17415.254237288136,17542.372881355932,17669.491525423728,17796.610169491527,17923.728813559323,18050.84745762712,18177.966101694914,18305.084745762713,18432.20338983051,18559.322033898305,18686.4406779661,18813.5593220339,18940.677966101695,19067.79661016949,19194.915254237287,19322.033898305086,19449.15254237288,19576.271186440677,19703.389830508473,19830.508474576272,19957.627118644068,20084.745762711864,20211.86440677966,20338.98305084746,20466.101694915254,20593.22033898305,20720.338983050846,20847.457627118645,20974.57627118644,21101.694915254237,21228.813559322032,21355.93220338983,21483.050847457627,21610.169491525423,21737.28813559322,21864.406779661018,21991.525423728814,22118.64406779661,22245.762711864405,22372.881355932204,22500.0,22627.118644067796,22754.23728813559,22881.35593220339,23008.474576271186,23135.593220338982,23262.711864406778,23389.830508474577,23516.949152542373,23644.06779661017,23771.186440677964,23898.305084745763,24025.42372881356,24152.542372881355,24279.66101694915,24406.77966101695,24533.898305084746,24661.01694915254,24788.13559322034,24915.254237288136,25042.372881355932,25169.491525423728,25296.610169491527,25423.728813559323,25550.84745762712,25677.966101694914,25805.084745762713,25932.20338983051,26059.322033898305,26186.4406779661,26313.5593220339,26440.677966101695,26567.79661016949,26694.915254237287,26822.033898305086,26949.15254237288,27076.271186440677,27203.389830508473,27330.508474576272,27457.627118644068,27584.745762711864,27711.86440677966,27838.98305084746,27966.101694915254,28093.22033898305,28220.338983050846,28347.457627118645,28474.57627118644,28601.694915254237,28728.813559322032,28855.93220338983,28983.050847457627,29110.169491525423,29237.28813559322,29364.406779661018,29491.525423728814,29618.64406779661,29745.762711864405,29872.881355932204,30000.0],\"xaxis\":\"x\",\"y\":[2.885082960128784,2.441380023956299,2.024500846862793,1.896558165550232,1.5850807428359985,1.580270528793335,1.4084022045135498,1.2025951147079468,1.1522367000579834,1.0841845273971558,1.0506900548934937,0.8458306789398193,0.8743636608123779,0.8770246505737305,0.7376503944396973,0.7085584402084351,0.6630614995956421,0.6842001676559448,0.6712715029716492,0.7088185548782349,0.605094850063324,0.7181717753410339,0.44283002614974976,0.5975950956344604,0.5405097603797913,0.6397785544395447,0.5173091888427734,0.4689013659954071,0.6495338082313538,0.4048527777194977,0.4187172055244446,0.4889773726463318,0.3755047917366028,0.40193262696266174,0.5438520312309265,0.39727434515953064,0.44927626848220825,0.34591782093048096,0.451994925737381,0.351627916097641,0.37701138854026794,0.4072224497795105,0.3784414827823639,0.4563562273979187,0.3689350485801697,0.3525962233543396,0.3561248481273651,0.46511921286582947,0.3955734074115753,0.5422254800796509,0.3858304023742676,0.4360654950141907,0.4742775559425354,0.48214083909988403,0.39565110206604004,0.2703203558921814,0.48153507709503174,0.33202701807022095,0.36043742299079895,0.33594170212745667,0.26236915588378906,0.4385654926300049,0.30067354440689087,0.32970479130744934,0.23336447775363922,0.47054779529571533,0.4134453237056732,0.2887212336063385,0.2784316837787628,0.29547038674354553,0.40456822514533997,0.2715508043766022,0.42288485169410706,0.21887093782424927,0.34073543548583984,0.39804667234420776,0.26023244857788086,0.29740628600120544,0.3313659429550171,0.43129631876945496,0.2764691710472107,0.322712779045105,0.2703775465488434,0.42114177346229553,0.263558566570282,0.25257083773612976,0.30363279581069946,0.3048020601272583,0.21512065827846527,0.21563145518302917,0.42451807856559753,0.3536457419395447,0.21456095576286316,0.46600160002708435,0.22453054785728455,0.2765038311481476,0.2642959952354431,0.2662716507911682,0.21904274821281433,0.24558761715888977,0.24759063124656677,0.1866977959871292,0.2421235740184784,0.2755505442619324,0.40056663751602173,0.20030789077281952,0.46343109011650085,0.21568189561367035,0.18788589537143707,0.21774181723594666,0.22236216068267822,0.2900710105895996,0.20752480626106262,0.35897645354270935,0.22050464153289795,0.27921774983406067,0.29492273926734924,0.2838204801082611,0.306723028421402,0.2660110294818878,0.2733917534351349,0.22671496868133545,0.23675936460494995,0.30799242854118347,0.18340373039245605,0.19992557168006897,0.2706913650035858,0.17076918482780457,0.2106289118528366,0.15995976328849792,0.2875269055366516,0.24617119133472443,0.20366260409355164,0.2852512300014496,0.1936541050672531,0.28993892669677734,0.32835057377815247,0.27143368124961853,0.209850013256073,0.1718723177909851,0.19799849390983582,0.12459861487150192,0.30653709173202515,0.3206965923309326,0.19316424429416656,0.23402288556098938,0.2681378722190857,0.2161787748336792,0.17235861718654633,0.24764716625213623,0.15193766355514526,0.35113224387168884,0.2223861664533615,0.2116449624300003,0.2546796500682831,0.19177581369876862,0.19592493772506714,0.15695436298847198,0.10341588407754898,0.19138368964195251,0.19165858626365662,0.19022884964942932,0.22647686302661896,0.16909079253673553,0.148786723613739,0.25271329283714294,0.17365948855876923,0.18556779623031616,0.15331026911735535,0.20425426959991455,0.13884873688220978,0.13167265057563782,0.18839092552661896,0.14872591197490692,0.17190107703208923,0.2950371503829956,0.2717271149158478,0.3039308190345764,0.15555322170257568,0.16630299389362335,0.20221756398677826,0.17744360864162445,0.16323786973953247,0.22570262849330902,0.24336758255958557,0.21932853758335114,0.13064132630825043,0.2201741635799408,0.13056722283363342,0.19814422726631165,0.24183326959609985,0.2198237180709839,0.2155107855796814,0.19379214942455292,0.18133951723575592,0.3085770905017853,0.190871462225914,0.1469935178756714,0.13857302069664001,0.12320290505886078,0.18505987524986267,0.12978698313236237,0.2300969362258911,0.13291721045970917,0.19703803956508636,0.17100714147090912,0.1700468212366104,0.09299392998218536,0.23159196972846985,0.2850492298603058,0.11320580542087555,0.20603814721107483,0.16244342923164368,0.2732688784599304,0.1755095273256302,0.2575209438800812,0.21852682530879974,0.13707289099693298,0.11472052335739136,0.19817161560058594,0.24339954555034637,0.17825302481651306,0.25563085079193115,0.15878604352474213,0.25965097546577454,0.11829004436731339,0.1445312798023224,0.13827966153621674,0.17185822129249573,0.19014406204223633,0.18795247375965118,0.2686363458633423,0.12809838354587555,0.1084282323718071,0.20545348525047302,0.24318856000900269,0.03866942971944809],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Examples seen\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Cross entropy loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"SimpleMLP training on MNIST\"},\"width\":700,\"hovermode\":\"x unified\"},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c71a6584-22a3-49ca-8f5e-16630a793282');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "line(\n",
        "    loss_list,\n",
        "    x_max=epochs * len(mnist_trainset),\n",
        "    labels={\"x\": \"Examples seen\", \"y\": \"Cross entropy loss\"},\n",
        "    title=\"SimpleMLP training on MNIST\",\n",
        "    width=700,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViY0EL5jjBUO"
      },
      "source": [
        "Let's break down the important parts of this code.\n",
        "\n",
        "The batch size is the number of samples in each batch (i.e. the number of samples we feed into the model at once). While training our model, we differentiate with respect to the average loss over all samples in the batch (so a smaller batch usually means the loss is more noisy). However, if you're working with large models, then often having a batch size too large will result in a memory error. This will be relevant for models later on in the course, but for now we're working with very small models so this isn't an issue.\n",
        "\n",
        "Next, we get our training set, via the helper function `get_mnist`. This helper function used `torchvision.datasets.MNIST` to load in data, and then (optionally) the `torch.utils.data.Subset` function to return a subset of this data. Don't worry about the details of this function, it's not the kind of thing you'll need to know by heart.\n",
        "\n",
        "We then define our optimizer, using `torch.optim.Adam`. The `torch.optim` module gives a wide variety of modules, such as Adam, SGD, and RMSProp. Adam is generally the most popular and seen as the most effective in the majority of cases. We'll discuss optimizers in more detail tomorrow, but for now it's enough to understand that the optimizer calculates the amount to update parameters by (as a function of those parameters' gradients, and sometimes other inputs), and performs this update step. The first argument passed to our optimizer is the parameters of our model (because these are the values that will be updated via gradient descent), and you can also pass keyword arguments to the optimizer which change its behaviour (e.g. the learning rate).\n",
        "\n",
        "Lastly, we have the actual training loop. We iterate through our training data, and for each batch we:\n",
        "\n",
        "1. Evaluate our model on the batch of data, to get the logits for our class predictions,\n",
        "2. Calculate the loss between our logits and the true class labels,\n",
        "3. Backpropagate the loss through our model (this step accumulates gradients in our model parameters),\n",
        "4. Step our optimizer, which is what actually updates the model parameters,\n",
        "5. Zero the gradients of our optimizer, ready for the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUesBrjkjBUO"
      },
      "source": [
        "### Cross entropy loss\n",
        "\n",
        "The formula for cross entropy loss over a batch of size $N$ is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "l &= \\frac{1}{N} \\sum_{n=1}^{N} l_n \\\\\n",
        "l_n &=-\\log p_{n, y_{n}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $p_{n, c}$ is the probability the model assigns to class $c$ for sample $n$, and $y_{n}$ is the true label for this sample.\n",
        "\n",
        "<details>\n",
        "<summary>See this dropdown, if you're still confused about this formula, and how this relates to the information-theoretic general formula for cross entropy.</summary>\n",
        "\n",
        "The cross entropy of a distribution $p$ relate to a distribution $q$ is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "H(q, p) &= -\\sum_{n} q(n) \\log p(n)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "In our case, $q$ is the true distribution (i.e. the one-hot encoded labels, which equals one for $n = y_n$, zero otherwise), and $p$ is our model's output. With these subsitutions, this formula becomes equivalent to the formula for $l$ given above.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>See this dropdown, if you're confused about how this is the same as the <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\">PyTorch definition</a>.</summary>\n",
        "\n",
        "The PyTorch definition of cross entropy loss is:\n",
        "\n",
        "$$\n",
        "\\ell(x, y)=\\frac{1}{N}\\sum_{n=1}^{N} l_n, \\quad l_n=-\\sum_{c=1}^C w_c \\log \\frac{\\exp \\left(x_{n, c}\\right)}{\\sum_{i=1}^C \\exp \\left(x_{n, i}\\right)} y_{n, c}\n",
        "$$\n",
        "\n",
        "$w_c$ are the weights (which all equal one by default), $p_{n, c} = \\frac{\\exp \\left(x_{n, c}\\right)}{\\sum_{i=1}^C \\exp \\left(x_{n, i}\\right)}$ are the probabilities, and $y_{n, c}$ are the true labels (which are one-hot encoded, i.e. their value is one at the correct label $c$ and zero everywhere else). With this, the formula for $l_n$ reduces to the one we see above (i.e. the mean of the negative log probabilities).\n",
        "\n",
        "</details>\n",
        "\n",
        "The function `torch.functional.cross_entropy` expects the **unnormalized logits** as its first input, rather than probabilities. We get probabilities from logits by applying the softmax function:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p_{n, c} &= \\frac{\\exp(x_{n, c})}{\\sum_{c'=1}^{C} \\exp(x_{n, c'})}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $x_{n, c}$ is the model's output for class $c$ and sample $n$, and $C$ is the number of classes (in the case of MNIST, $C = 10$).\n",
        "\n",
        "Some terminology notes:\n",
        "\n",
        "* When we say **logits**, we mean the output of the model before applying softmax. We can uniquely define a distribution with a set of logits, just like we can define a distribution with a set of probabilities (and sometimes it's easier to think of a distribution in terms of logits, as we'll see later in the course).\n",
        "\n",
        "* When we say **unnormalized**, we mean the denominator term $\\sum_{c'} \\exp(x_{n, c'})$ isn't necessarily equal to 1. We can add a constant value onto all the logits which makes this term 1 without changing any of the actual probabilities, then we have the relation $p_{n, c} = \\exp(-l_{n, c})$. Here, we call $-l_{n, c}$ the **log probabilities** (or log probs), since $-l_{n, c} = \\log p_{n, c}$.\n",
        "\n",
        "If you're interested in the intuition behind cross entropy as a loss function, see [this post on KL divergence](https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence) (note that KL divergence and cross entropy differ by an amount which is independent of our model's predictions, so minimizing cross entropy is equivalent to minimizing KL divergence). Also see these two videos:\n",
        "\n",
        "* [Intuitively Understanding the Cross Entropy Loss](https://www.youtube.com/watch?v=Pwgpl9mKars&amp;ab_channel=AdianLiusie)\n",
        "* [Intuitively Understanding the KL Divergence](https://www.youtube.com/watch?v=SxGYPqCgJWM&amp;ab_channel=AdianLiusie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nld1gt2XjBUO"
      },
      "source": [
        "### Aside - `dataclasses`\n",
        "\n",
        "Sometimes, when we have a lot of different input parameters to our model, it can be helpful to use dataclasses to keep track of them all. Dataclasses are a special kind of class which come with built-in methods for initialising and printing (i.e. no need to define an `__init__` or `__repr__`). Another advantage of using them is autocompletion: when you type in `args.` in VSCode, you'll get a dropdown of all your different dataclass attributes, which can be useful when you've forgotten what you called a variable!\n",
        "\n",
        "Here's an example of how we might rewrite our training code above using dataclasses. We've wrapped all the training code inside a single argument called `train`, which takes a `SimpleMLPTrainingArgs` object as its only argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Cffn85qGjBUO",
        "outputId": "b52d8d67-a11d-4abb-e7e6-bbc9084ec89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b6b3cea04d7149cc8d76a7742dcb79ab",
            "4093ce5092d5456ab61d9e025211e648",
            "34a73d0af37b4fe5bf68e239dc442057",
            "c1f9a90153ca4757926401a294a873bd",
            "f174e621c3fa40edae051ff300ff472f",
            "3aed0d77436347c3ba3c62d5c3360890",
            "53064e728e0f4b2881b79df6a9512713",
            "59c37fb9f03a4aad91041ed52aa0e9a4",
            "ea988373fda445f396df57bdf540ef5e",
            "6da9d75a028648298a5e327c99b81825",
            "b7cb420ee6ac484d877e2df16067b73a",
            "80e6ce9f696d45cba8d8b511735df32b",
            "85fe95e3f4a54e3fbed06ccf3ca100c5",
            "cd43db5ffed548798b6f521cfd7d5a93",
            "75c849775e654441a3fcf8e742f4eb6d",
            "5091ad8d8a6e4c65b5eb4dc405f9ed7d",
            "ac8cbf3e425041709f9155244adf3d0a",
            "32cb214483dc4d2d90ad4bffc25b7d2e",
            "f5d47a0eb0644a068c0d0815440789ad",
            "720a7be4da2f408b9df2ac25a45fa157",
            "73d3615ab1454afc9586e4c0f024b8f5",
            "a50846783b4e449c8280ed15b5b8117c",
            "405480958f624cf4bb8b59568f15fa93",
            "44ec736e0b3c437baffc6d6975f7b526",
            "d3880c1e183f486cb636c6573cf5c3f0",
            "e3ca8ddb810848e6b341ec682cc6b07e",
            "b01b713a09554286a692309dead8b9e4",
            "71671a2f9779466286478637ac831222",
            "af82bb4655ef4de28420b5386d6ac934",
            "5f8222fb1e034b709730a79da64c224e",
            "23cdf7663286480a9d7e98af2e5f5ad7",
            "f0c2478672a94658a8e2d978a595672c",
            "c856ba2d6b07453db2032129036411a7"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6b3cea04d7149cc8d76a7742dcb79ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0572, -1.3818, -1.1423,  ...,  1.7724, -2.1819,  0.7147],\n",
            "        [ 1.3784,  2.7375,  2.8131,  ..., -1.0676,  0.2629, -0.1453],\n",
            "        [ 1.3687, -0.2370, -0.2302,  ..., -0.6927, -1.4379, -0.3624],\n",
            "        ...,\n",
            "        [ 0.9755,  0.5227, -0.3410,  ...,  1.5624, -1.4180,  0.3068],\n",
            "        [ 1.3731,  0.7905,  0.6160,  ...,  1.7614,  0.5897,  0.1548],\n",
            "        [ 1.7394, -0.0605, -2.3507,  ...,  1.5345, -2.8080, -0.3985]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2167,  0.3264, -0.7679,  ...,  1.3672, -0.6860,  0.8703],\n",
            "        [ 1.8347,  2.1972, -1.0968,  ..., -0.9249,  0.5954,  1.8194],\n",
            "        [-1.8140,  1.1252,  0.1395,  ..., -1.1176,  0.1900,  0.1520],\n",
            "        ...,\n",
            "        [ 0.2224, -0.2225, -1.0565,  ...,  1.2091, -1.9903,  0.3927],\n",
            "        [ 2.2808, -1.3064, -1.4499,  ...,  0.4135, -0.9533,  1.3649],\n",
            "        [-1.0217, -0.0107, -1.0219,  ...,  1.1886,  0.6373,  1.2557]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4354, -0.4781, -0.9904,  ...,  2.2599, -0.4245, -0.6763],\n",
            "        [ 1.2462,  0.5765,  1.8546,  ..., -0.9359,  1.2081, -0.9796],\n",
            "        [ 2.8619,  1.7319, -2.2772,  ...,  1.8666, -1.4232, -0.4047],\n",
            "        ...,\n",
            "        [ 0.5180,  0.6878, -0.6034,  ...,  1.3853,  0.5069,  2.0194],\n",
            "        [ 2.8053, -0.9380, -1.2928,  ...,  3.7282,  2.2848, -0.0318],\n",
            "        [ 1.2736,  0.2541, -0.5832,  ...,  0.5032, -0.6053, -0.7620]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.3457e-01, -7.0150e-02, -1.3100e+00,  ...,  1.7644e-01,\n",
            "         -7.8223e-01, -3.7123e-01],\n",
            "        [ 2.7647e+00,  9.9569e-01,  1.1463e+00,  ...,  2.2545e+00,\n",
            "         -2.2321e-03,  2.0772e+00],\n",
            "        [ 1.0684e+00,  1.8882e+00,  2.1455e+00,  ...,  1.7537e+00,\n",
            "          2.9989e-02,  1.1512e-01],\n",
            "        ...,\n",
            "        [ 2.9417e+00, -1.0982e+00, -1.6038e+00,  ...,  1.5051e+00,\n",
            "         -2.0567e+00,  2.4452e-01],\n",
            "        [ 4.1943e+00,  1.7684e+00, -1.2563e+00,  ...,  3.0357e+00,\n",
            "          2.4513e-01,  1.7769e+00],\n",
            "        [ 1.3739e+00,  9.3287e-01, -1.1332e+00,  ...,  1.3376e+00,\n",
            "          3.7922e-01, -1.0198e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2219,  1.8766,  0.5795,  ..., -0.2317,  0.4829,  1.3421],\n",
            "        [ 2.4354,  1.8227, -1.0449,  ...,  0.7812, -1.2956, -0.0615],\n",
            "        [ 1.0837,  0.6344,  1.1220,  ...,  2.4630, -1.2108, -1.2944],\n",
            "        ...,\n",
            "        [ 0.3761,  0.3132,  0.6321,  ...,  2.6203,  0.2367, -0.0204],\n",
            "        [ 1.4847,  1.1681, -0.0061,  ...,  1.7050, -1.2372, -0.1187],\n",
            "        [ 1.7428,  2.0499, -1.6385,  ...,  3.6723,  0.2050,  0.5833]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7451,  1.6628,  0.1824,  ...,  2.4102,  2.3832,  2.1906],\n",
            "        [ 1.4344, -0.9983,  2.3870,  ...,  1.6627,  1.0220, -0.0938],\n",
            "        [ 1.2371,  1.9745, -0.0216,  ...,  1.2887,  0.4114,  0.9396],\n",
            "        ...,\n",
            "        [ 0.6927,  3.6628,  0.7528,  ...,  0.1948,  2.6638,  0.0780],\n",
            "        [ 4.1602,  2.2563,  0.0178,  ...,  2.0349,  0.2785,  2.0391],\n",
            "        [ 2.6144,  0.4986, -0.6244,  ...,  0.8181, -0.9162,  0.0453]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7257,  1.6020,  2.0609,  ...,  2.0978,  0.9482,  1.7610],\n",
            "        [ 1.5077,  0.8234,  0.0994,  ...,  2.5682, -0.5502, -0.4025],\n",
            "        [ 3.3220,  3.0044,  0.4912,  ...,  2.6933,  1.5882,  0.1826],\n",
            "        ...,\n",
            "        [ 1.3229,  0.8811, -1.2797,  ...,  2.0476, -2.8574, -0.9858],\n",
            "        [ 2.2870,  1.1758, -0.3608,  ...,  1.8849, -0.0387,  1.6295],\n",
            "        [-0.2322,  1.6475,  4.1165,  ...,  0.3617,  2.5980,  0.1961]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1776,  1.9550,  2.5666,  ...,  1.7195,  1.8758,  1.5525],\n",
            "        [ 1.4232, -0.2599,  0.0112,  ...,  1.7011,  0.9533, -0.5154],\n",
            "        [ 1.7454,  1.8759, -0.8954,  ...,  2.1262, -0.4961, -1.2097],\n",
            "        ...,\n",
            "        [ 2.9730,  1.6607, -0.2389,  ...,  0.0518,  2.0715,  1.2348],\n",
            "        [ 0.7165,  3.4123,  2.2601,  ...,  1.5938,  2.0600,  1.6302],\n",
            "        [-0.8124,  2.6820,  0.2356,  ...,  0.6673,  0.8456, -0.6239]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0628,  1.6077,  1.7018,  ...,  2.3769,  0.1707, -0.4185],\n",
            "        [ 1.6292,  2.3944,  0.8862,  ...,  1.2570,  0.8596, -0.4048],\n",
            "        [ 2.7513,  4.0869,  1.4666,  ...,  1.9664,  0.3608,  1.7311],\n",
            "        ...,\n",
            "        [ 3.4470,  2.6250, -1.4609,  ...,  1.7183, -0.7655, -1.0156],\n",
            "        [ 1.8173,  3.4948, -0.4659,  ...,  1.4250,  1.1854,  1.2511],\n",
            "        [ 0.5456,  4.0383,  1.9759,  ...,  0.6463,  1.2249, -1.0303]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2292,  3.5132,  4.3359,  ...,  0.2084, -0.2206,  1.4852],\n",
            "        [ 1.4152,  1.6687,  1.4899,  ...,  0.7243,  1.3744, -0.4527],\n",
            "        [ 1.9503,  0.3865,  2.1311,  ..., -0.0448,  1.7413, -1.3862],\n",
            "        ...,\n",
            "        [-0.6452,  3.5640,  1.8944,  ...,  0.7719, -0.7421, -0.0880],\n",
            "        [ 0.4202,  2.7111, -0.9405,  ...,  0.5455, -1.0311,  0.4659],\n",
            "        [ 2.9011,  5.3367, -1.1979,  ...,  0.0219, -0.3133, -1.8256]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0745,  4.7653,  2.2669,  ...,  1.6507,  3.3259,  0.3213],\n",
            "        [ 3.0826,  0.6071, -0.2565,  ...,  0.4831, -1.5302,  0.6245],\n",
            "        [ 3.0280,  3.5599, -0.5782,  ...,  2.0626, -0.3102, -0.2019],\n",
            "        ...,\n",
            "        [ 1.0842,  0.8190,  0.3378,  ...,  3.0188,  1.7662, -0.2590],\n",
            "        [ 2.5107,  2.9797, -0.9414,  ...,  1.7785, -0.6764, -1.4812],\n",
            "        [ 2.9742,  4.3845,  2.5074,  ..., -1.4817,  2.9987,  2.8555]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5027,  1.4905,  0.7812,  ...,  1.9302, -0.8814, -0.1289],\n",
            "        [ 1.1126,  3.6854,  3.8510,  ..., -0.2105,  3.2722, -0.4607],\n",
            "        [ 3.2871,  6.1291,  0.4790,  ...,  0.3968, -0.3855, -1.3832],\n",
            "        ...,\n",
            "        [ 1.2844,  2.6578,  1.1524,  ..., -1.2281, -0.7644, -0.4345],\n",
            "        [ 1.3148,  1.6313,  0.7177,  ...,  1.8811, -0.0754, -0.2570],\n",
            "        [ 1.2895,  2.2930,  1.1421,  ..., -1.0405,  0.7004,  0.5051]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9410e+00,  7.1460e-01,  2.1001e+00,  ...,  1.3933e+00,\n",
            "          5.9470e-01, -1.6264e-03],\n",
            "        [ 9.3106e-01,  3.8548e-01,  2.4836e+00,  ...,  1.2173e+00,\n",
            "          2.1724e+00, -5.5767e-01],\n",
            "        [ 1.1731e+00,  3.2042e+00,  3.4802e+00,  ...,  9.4370e-01,\n",
            "          2.8023e+00, -2.5683e-02],\n",
            "        ...,\n",
            "        [ 4.6315e-01, -1.3084e-01,  2.7434e+00,  ...,  1.6150e+00,\n",
            "          2.1397e+00, -8.2770e-01],\n",
            "        [ 1.3844e+00,  3.5226e-01,  2.5392e+00,  ...,  1.1113e+00,\n",
            "          2.3448e+00, -4.3984e-01],\n",
            "        [ 5.9374e-01,  8.7580e-01,  3.1931e+00,  ...,  4.5586e-01,\n",
            "          5.3842e-01,  1.2562e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5459,  1.9425,  1.0961,  ...,  1.4933,  1.2380, -0.2217],\n",
            "        [ 3.2996,  2.5946, -0.7475,  ..., -0.0874, -0.4018, -0.8657],\n",
            "        [ 1.9670,  4.0073,  0.2509,  ...,  0.9056,  2.3395,  0.0051],\n",
            "        ...,\n",
            "        [ 1.8180,  1.6847,  2.4679,  ...,  0.6248,  0.7959, -0.7835],\n",
            "        [ 1.1699,  1.0935,  1.9638,  ...,  2.0171,  1.4377, -0.6841],\n",
            "        [ 2.3161,  3.5469,  0.8636,  ...,  1.2091,  1.0901,  0.5080]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1242,  3.5728,  2.9435,  ...,  2.6626,  2.8137, -1.0508],\n",
            "        [ 1.8809,  1.1607,  2.8020,  ..., -2.3722,  4.5380,  3.8271],\n",
            "        [ 0.8133,  1.1740,  0.8494,  ...,  2.7815,  1.7532, -1.5680],\n",
            "        ...,\n",
            "        [ 3.3765,  2.9559, -1.5700,  ..., -0.3042,  0.5174, -0.6724],\n",
            "        [ 0.7853,  0.7989,  2.6996,  ...,  2.0521,  1.8298, -1.5079],\n",
            "        [ 4.0479,  1.4419,  0.9866,  ...,  1.0077,  2.6251,  4.5853]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0274,  2.2343,  0.1434,  ...,  1.7459,  1.3384, -0.4897],\n",
            "        [ 3.4712,  2.7779,  1.5689,  ...,  1.8220,  0.1744, -2.4733],\n",
            "        [ 1.5263,  3.8180,  2.3385,  ..., -1.4260,  7.4891,  2.9590],\n",
            "        ...,\n",
            "        [ 2.6248,  2.1607,  2.5002,  ...,  1.2416,  2.9346, -1.3827],\n",
            "        [ 1.8697,  0.6257,  2.9720,  ...,  0.8904,  1.5948,  0.1252],\n",
            "        [ 1.8572,  3.0868,  0.9615,  ...,  0.9089,  1.9757, -1.5217]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1326,  0.9819,  0.5937,  ...,  2.2469,  2.4287, -0.5196],\n",
            "        [ 2.5997,  1.2237,  3.1978,  ...,  2.2840,  2.9812,  0.1947],\n",
            "        [ 0.5079,  3.7311,  2.1008,  ...,  0.1646,  1.9649, -0.1366],\n",
            "        ...,\n",
            "        [ 3.6110,  2.9184,  2.2411,  ...,  0.2296,  1.3469,  0.2240],\n",
            "        [ 2.2601,  3.2210,  2.2084,  ..., -0.1419,  1.1850, -0.3869],\n",
            "        [ 1.1482,  0.3361,  1.8827,  ...,  2.0653,  1.7484, -1.0928]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9288e+00,  2.9546e+00,  2.2716e+00,  ...,  1.4639e+00,\n",
            "          1.3029e+00, -1.5970e+00],\n",
            "        [ 1.6060e+00,  3.3332e+00,  2.1110e+00,  ...,  7.3062e-03,\n",
            "          1.5798e+00, -2.1512e-01],\n",
            "        [ 1.0487e+00,  9.6083e-01,  4.0334e+00,  ...,  2.1724e+00,\n",
            "          1.1244e+00, -1.1656e+00],\n",
            "        ...,\n",
            "        [ 3.1777e+00,  2.1054e+00,  2.4765e+00,  ...,  1.9059e+00,\n",
            "          4.2590e+00,  1.7677e-01],\n",
            "        [ 2.4341e+00,  2.6684e+00,  1.6956e+00,  ...,  6.7568e-01,\n",
            "          9.7812e-01, -2.3882e+00],\n",
            "        [ 1.8564e+00,  4.0344e+00,  2.5791e+00,  ..., -3.0262e-01,\n",
            "          7.3347e+00,  3.6286e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0229,  4.1408,  3.8148,  ..., -0.9472,  2.8490,  3.5695],\n",
            "        [ 1.7923,  2.1227,  0.7015,  ...,  2.9872,  2.7738, -1.0045],\n",
            "        [ 0.8055,  0.7943,  2.5855,  ...,  2.0984,  3.0280, -0.9927],\n",
            "        ...,\n",
            "        [-0.0529,  1.1924,  2.2344,  ...,  2.1124,  0.9487, -0.2511],\n",
            "        [ 0.3295,  0.8993,  3.2098,  ...,  1.9715,  2.9265, -1.0532],\n",
            "        [ 3.5037,  1.6997,  1.7977,  ...,  0.8223,  2.4680,  0.8444]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2530,  2.4448,  2.1444,  ...,  1.9849,  1.4008, -0.2316],\n",
            "        [ 1.0422,  3.9039,  0.2357,  ..., -0.3376,  1.7218,  4.0622],\n",
            "        [ 1.4323,  2.7499,  3.8327,  ...,  0.1550,  4.3271,  0.9369],\n",
            "        ...,\n",
            "        [ 1.6249,  4.9700,  1.9495,  ..., -2.1417,  2.0464,  1.6002],\n",
            "        [ 2.3646,  4.2075,  4.0211,  ..., -3.3298,  7.3344,  3.7220],\n",
            "        [ 1.5776,  0.4434,  2.9739,  ...,  2.4550,  3.7375,  1.1867]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1567,  2.4911,  0.9502,  ..., -0.9529,  1.0218, -1.6163],\n",
            "        [ 1.5965,  0.3854,  1.9687,  ...,  1.5827,  1.7032,  0.4431],\n",
            "        [ 1.6118,  6.8589,  4.5296,  ...,  0.1785,  2.2083, -0.4158],\n",
            "        ...,\n",
            "        [ 3.1912,  2.2273,  1.3979,  ...,  0.4057,  1.2651,  0.2275],\n",
            "        [ 0.0775,  1.3856,  1.3625,  ...,  2.6171,  2.9348, -0.3288],\n",
            "        [ 3.1707,  2.6419,  4.2409,  ...,  0.6545,  3.4212,  2.0961]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6406,  0.2064,  2.1336,  ...,  1.9477,  0.7246, -0.5450],\n",
            "        [ 0.4550,  2.8110,  2.4375,  ...,  0.7713,  2.9230,  1.1251],\n",
            "        [ 3.5845,  5.0499,  2.0423,  ...,  2.1519,  7.3473,  2.9149],\n",
            "        ...,\n",
            "        [ 3.0737,  3.0079, -0.1090,  ...,  1.9234,  0.9107, -1.7960],\n",
            "        [ 1.4814,  1.2990,  3.2858,  ...,  1.8732,  3.6821,  0.2911],\n",
            "        [ 1.1754,  1.6771,  2.9053,  ...,  2.5840,  2.5763, -1.1301]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5403,  1.5272,  3.9843,  ...,  2.0193,  3.3232,  0.3791],\n",
            "        [ 2.9903,  3.5409,  0.8279,  ...,  1.3120,  1.4427, -0.1509],\n",
            "        [ 1.5816,  0.5956,  1.9036,  ...,  0.9877,  2.7367, -0.1754],\n",
            "        ...,\n",
            "        [ 1.2158,  4.8247,  3.6332,  ..., -1.3381,  4.8575,  2.8638],\n",
            "        [ 2.2867,  3.3131,  3.6828,  ..., -1.7053,  1.3312,  0.8374],\n",
            "        [ 0.6254,  4.6845,  2.3706,  ...,  1.2441,  2.9881,  1.9522]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2869,  2.6104,  3.1039,  ...,  0.8104,  0.1693,  1.3008],\n",
            "        [ 1.4397,  4.7985,  4.5195,  ...,  2.9519,  4.2977, -0.1433],\n",
            "        [ 3.8534,  3.9515,  1.8583,  ...,  0.5751,  0.8767, -0.2379],\n",
            "        ...,\n",
            "        [ 1.5837,  1.7930,  2.4946,  ...,  0.8463,  0.7777, -0.8464],\n",
            "        [ 1.4659,  1.5383, -0.2564,  ...,  1.8755,  2.8612, -2.1710],\n",
            "        [ 0.4568,  4.0975,  1.7969,  ..., -0.5756,  2.3787,  4.4583]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2616,  5.0624,  2.5544,  ...,  0.9156,  0.7275, -2.0249],\n",
            "        [ 2.0834,  5.5150,  1.6903,  ..., -1.5049,  3.3007,  5.6291],\n",
            "        [ 2.7983,  5.8729, -2.4444,  ...,  1.2378,  4.0966,  0.5188],\n",
            "        ...,\n",
            "        [ 1.5631,  3.7173,  2.9704,  ...,  0.2107,  0.9294, -1.6905],\n",
            "        [ 0.8542,  6.3870,  4.0879,  ...,  0.2482,  8.7907,  5.6560],\n",
            "        [ 1.0278,  4.8232,  1.9638,  ...,  1.1656,  9.5191,  3.1171]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6970,  5.9815,  4.2436,  ...,  0.6124,  4.0242, -0.2467],\n",
            "        [ 3.9894,  4.2942,  2.2066,  ...,  0.6579, -0.0969, -0.0185],\n",
            "        [ 1.2947,  5.4081,  2.7894,  ...,  0.9107,  0.4446,  0.2230],\n",
            "        ...,\n",
            "        [ 0.7207,  5.6985,  3.0791,  ..., -0.2939,  2.4109,  2.5998],\n",
            "        [ 2.9486,  3.6669, -0.2155,  ...,  2.0110,  2.0080, -1.5748],\n",
            "        [ 2.8166,  4.7151,  4.1476,  ..., -0.6769,  6.1781,  3.0028]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8716,  3.7032,  0.1004,  ...,  1.4092, -0.5353, -0.5824],\n",
            "        [ 1.8247,  4.0743,  2.6958,  ...,  1.4621,  2.1082, -0.6719],\n",
            "        [ 2.4138,  1.5316,  3.9538,  ...,  2.2325,  3.0592, -1.2280],\n",
            "        ...,\n",
            "        [ 1.4925,  5.7411, -0.0404,  ...,  1.2965,  2.4997,  1.5028],\n",
            "        [ 0.5073,  2.3984,  5.0134,  ...,  1.0499,  2.4311,  0.8825],\n",
            "        [ 2.2918,  2.4078,  0.2076,  ...,  2.6722,  1.1596, -1.6825]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4985,  2.8399,  1.3588,  ...,  0.4469,  0.6875,  0.1197],\n",
            "        [ 1.4294,  7.1963,  5.6509,  ...,  1.0308,  2.7181, -1.6482],\n",
            "        [ 3.1456,  4.6922,  2.3894,  ..., -0.2606,  2.4494,  0.6301],\n",
            "        ...,\n",
            "        [ 2.0461,  3.9022,  4.3982,  ...,  1.4904,  3.7050,  0.4974],\n",
            "        [ 1.6939,  2.5160,  2.4534,  ...,  2.2048,  3.5035, -2.0457],\n",
            "        [ 1.4095,  2.5375,  2.4091,  ...,  0.3062,  0.5562,  1.1601]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4078,  4.9095,  1.1272,  ..., -0.3318,  5.3512,  0.5008],\n",
            "        [-0.7426,  4.1735,  1.0129,  ...,  0.5528,  2.3153,  3.1018],\n",
            "        [-1.1206,  4.5063,  2.1363,  ...,  2.1563,  0.8976,  1.4236],\n",
            "        ...,\n",
            "        [ 3.9343,  4.0511, -1.5394,  ...,  1.9870,  2.3082, -2.4676],\n",
            "        [ 0.2254,  5.5125,  3.9129,  ...,  1.5356,  3.0227,  0.5951],\n",
            "        [ 2.5139,  5.0053, -0.2789,  ...,  2.8820,  4.1738,  2.1070]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2642,  3.2877,  2.4646,  ..., -0.1287,  1.4749, -0.7165],\n",
            "        [ 0.9016,  3.0440,  2.3093,  ...,  1.4191,  3.0554,  0.1924],\n",
            "        [ 1.2327,  1.7685,  4.1839,  ...,  1.3123,  3.7028,  0.0486],\n",
            "        ...,\n",
            "        [ 3.5001,  6.3880,  2.3622,  ...,  1.6013,  0.5417, -2.5958],\n",
            "        [ 2.2972,  1.7118,  5.9084,  ...,  0.0099,  4.8465,  2.8126],\n",
            "        [ 3.9151,  2.2769,  1.7427,  ...,  2.7314,  5.2917,  3.6750]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5511,  5.3987,  3.5487,  ...,  3.5905,  2.8796, -0.3533],\n",
            "        [ 1.3859,  1.6369,  3.0097,  ...,  2.3577,  3.7822,  0.1024],\n",
            "        [ 2.5499,  2.3590,  1.9538,  ...,  1.6873, -1.2966, -1.6618],\n",
            "        ...,\n",
            "        [ 1.3973,  1.6974,  0.0414,  ...,  1.4705, -1.0633,  0.7565],\n",
            "        [ 1.7891,  2.4448, -0.6985,  ...,  0.7756,  1.7827, -0.3480],\n",
            "        [ 0.2672,  3.8149,  4.3555,  ...,  1.1944,  1.0618,  1.6979]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8849,  6.7458, -1.2372,  ...,  1.6210,  0.6129,  2.5948],\n",
            "        [ 0.6417,  1.5914,  5.0931,  ...,  1.3127,  3.2815,  2.6541],\n",
            "        [ 0.1540,  1.9748,  4.4593,  ...,  1.9983,  2.3269, -1.0619],\n",
            "        ...,\n",
            "        [ 0.6915,  3.1912,  3.6349,  ..., -0.9060,  1.3521, -0.1424],\n",
            "        [ 2.4106,  1.7958,  1.4211,  ...,  2.5457, -0.1602, -1.2844],\n",
            "        [ 1.8752,  1.7602,  3.6976,  ...,  1.6786,  3.5817, -0.3488]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1297,  2.9229,  3.7994,  ...,  0.5968,  4.0828,  0.9798],\n",
            "        [-0.6285,  6.6720, -0.3472,  ..., -1.9576,  2.9536,  5.0577],\n",
            "        [ 2.2377,  5.0875,  1.4160,  ...,  0.2110,  1.4845, -0.3571],\n",
            "        ...,\n",
            "        [ 1.3401,  4.2068,  3.2496,  ...,  0.4625, -1.7432,  2.1464],\n",
            "        [ 2.7687,  4.5737,  2.6647,  ...,  2.8103,  3.1604,  0.3270],\n",
            "        [ 3.3532,  5.1567,  1.9127,  ..., -1.1802,  2.6984,  6.2698]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9890,  1.0208,  2.3269,  ...,  3.2488,  1.3073, -0.2272],\n",
            "        [ 0.8419,  4.5550,  1.4937,  ...,  0.6134,  1.9718,  5.0144],\n",
            "        [ 0.7024,  2.0123,  2.7707,  ...,  2.9639,  2.2558, -0.6034],\n",
            "        ...,\n",
            "        [ 2.3567,  5.0120,  1.5843,  ..., -2.1854, -0.6305,  4.2692],\n",
            "        [ 1.1470,  3.2713,  3.1138,  ...,  3.2083,  2.0209,  1.7191],\n",
            "        [ 0.5499,  2.9953,  1.3456,  ...,  0.8114,  1.3450,  1.6111]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6934e+00,  1.8104e+00,  1.4419e+00,  ...,  1.0601e+00,\n",
            "          1.5862e+00, -1.5246e+00],\n",
            "        [-1.1128e-03,  6.0670e+00,  5.1465e+00,  ..., -2.5392e+00,\n",
            "          5.5799e+00,  1.0972e+00],\n",
            "        [ 3.2659e+00,  7.5933e+00,  2.1718e+00,  ...,  1.6621e+00,\n",
            "          4.1033e-01,  1.4340e+00],\n",
            "        ...,\n",
            "        [ 1.5349e+00,  3.8879e+00,  3.3595e+00,  ...,  4.1495e-01,\n",
            "          5.7791e+00,  2.5940e+00],\n",
            "        [ 3.3996e+00,  4.0844e+00,  1.8415e+00,  ...,  1.1625e+00,\n",
            "          7.4146e+00,  4.3927e+00],\n",
            "        [ 2.9306e+00,  6.2681e+00,  2.2092e+00,  ..., -7.1624e-01,\n",
            "          3.9594e+00,  5.8667e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9048,  2.1360,  4.0269,  ...,  3.0929,  2.2248, -0.2488],\n",
            "        [-0.0616,  1.3656,  4.6261,  ...,  1.8765,  3.6852,  0.7456],\n",
            "        [ 3.9919,  3.2938, -0.2121,  ...,  1.6094,  1.6681,  0.6163],\n",
            "        ...,\n",
            "        [ 0.5740,  3.5797,  5.0564,  ...,  0.0907,  3.1637,  0.7404],\n",
            "        [ 3.9655,  3.8080, -0.4938,  ...,  0.1251,  1.9120,  0.0436],\n",
            "        [ 1.6379,  1.7375,  2.6773,  ..., -1.1930,  1.7184, -1.2103]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4064e+00,  2.5681e+00,  4.2516e+00,  ...,  5.8304e-01,\n",
            "          2.6237e+00,  2.2773e+00],\n",
            "        [ 1.8991e+00,  3.8967e+00,  5.8008e+00,  ..., -3.9461e+00,\n",
            "          6.1378e+00,  6.9701e+00],\n",
            "        [ 3.8726e+00,  2.8055e+00, -1.4525e-01,  ...,  1.3620e+00,\n",
            "          1.3214e+00,  6.7657e-01],\n",
            "        ...,\n",
            "        [ 3.0921e+00,  6.8689e+00,  7.3546e-01,  ...,  3.5823e+00,\n",
            "          4.0932e+00,  8.3367e-01],\n",
            "        [ 8.7977e-01,  4.7729e+00,  3.3624e-01,  ..., -7.7494e-01,\n",
            "          1.6070e+00,  3.0045e+00],\n",
            "        [ 2.4910e+00,  5.3505e+00,  1.9127e+00,  ..., -2.3201e-03,\n",
            "          4.5675e+00,  3.8114e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8254,  5.7160,  4.3903,  ...,  2.1032,  3.6794,  0.5085],\n",
            "        [ 0.3512,  1.7783,  1.3926,  ...,  1.8814,  1.0357, -1.7363],\n",
            "        [ 0.1450,  6.0501,  4.2134,  ...,  0.9005,  2.2830,  4.6665],\n",
            "        ...,\n",
            "        [ 1.1877,  2.4119,  4.4649,  ...,  1.1959,  1.6186,  0.8537],\n",
            "        [ 1.3511,  5.4055,  5.7524,  ..., -2.8306,  5.7901,  3.6028],\n",
            "        [ 1.7781,  6.3587,  2.8308,  ...,  1.6210,  2.6185,  4.0154]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4791,  6.3083,  3.6631,  ...,  0.6447,  5.3675,  1.1550],\n",
            "        [ 0.2570,  2.7877,  3.8315,  ...,  2.3538,  2.6971,  0.3584],\n",
            "        [ 1.6365,  1.8282,  2.2595,  ..., -2.1396,  0.5350,  0.9817],\n",
            "        ...,\n",
            "        [ 2.3846,  4.2921,  2.1682,  ..., -2.8525,  3.1392,  2.8511],\n",
            "        [ 0.8176,  2.9040,  4.3248,  ...,  1.6815,  2.9024,  1.3422],\n",
            "        [ 1.5278,  3.3763,  1.7596,  ...,  0.3108, -1.7409,  0.9188]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1608,  6.4728,  1.9762,  ..., -0.2825,  9.6011,  4.8887],\n",
            "        [ 0.5602,  0.9355,  4.3724,  ..., -2.1302, -0.0137,  1.6863],\n",
            "        [-0.2612,  6.5180,  3.7589,  ..., -0.5435,  5.3520,  3.2806],\n",
            "        ...,\n",
            "        [ 1.2951,  2.1311,  1.9831,  ...,  2.8275,  2.7311, -0.6171],\n",
            "        [ 1.4048,  3.2373,  3.1322,  ..., -0.6439,  3.0457,  1.6200],\n",
            "        [ 1.9736,  6.5551,  3.9478,  ...,  0.2928,  4.6853,  1.8906]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6876,  2.3737,  3.1216,  ...,  0.5591,  2.1053,  4.5279],\n",
            "        [ 3.7648,  2.9778,  3.5457,  ..., -1.0041,  4.7723,  3.7247],\n",
            "        [ 1.6965,  3.7012,  6.6414,  ..., -2.1729,  1.6085,  2.6558],\n",
            "        ...,\n",
            "        [ 1.9575,  0.8845,  1.2095,  ..., -0.7715,  3.2539,  1.5340],\n",
            "        [ 3.9996,  4.7489,  2.2315,  ...,  0.3105,  2.7368,  7.0850],\n",
            "        [-0.3462,  3.8512,  3.1185,  ...,  0.6462,  2.6449,  1.7021]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9247,  2.7644,  0.7837,  ...,  1.3969,  2.1008,  2.0971],\n",
            "        [ 1.5645,  2.8969,  3.5563,  ..., -1.4492,  3.5779,  2.3003],\n",
            "        [ 1.2151,  2.1428,  4.9970,  ...,  1.7549,  3.8147,  0.6608],\n",
            "        ...,\n",
            "        [ 2.6055,  4.3265,  2.9612,  ...,  0.8739,  1.9075,  4.7163],\n",
            "        [ 2.1519,  5.1405,  3.3781,  ...,  0.9978,  3.5947,  4.2684],\n",
            "        [ 0.3255,  5.5669,  3.0128,  ..., -0.3803,  1.4289,  1.3182]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[4.8621, 8.2173, 0.2202,  ..., 3.0113, 4.4622, 2.4417],\n",
            "        [0.7805, 3.1210, 4.5887,  ..., 2.0205, 2.7823, 0.1767],\n",
            "        [0.2236, 3.4542, 2.7733,  ..., 0.1677, 1.2944, 1.4354],\n",
            "        ...,\n",
            "        [2.2920, 3.1007, 3.9409,  ..., 1.2606, 3.7706, 0.9242],\n",
            "        [2.5198, 6.3759, 2.3654,  ..., 0.9559, 3.3760, 1.6855],\n",
            "        [3.5367, 2.5015, 2.7343,  ..., 0.1542, 6.7273, 3.9985]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.9976,  5.7913,  2.0944,  ..., -0.4584,  0.3718, -0.4977],\n",
            "        [ 1.6243,  2.7890,  5.0611,  ...,  0.5382,  3.6129,  0.7036],\n",
            "        [ 1.3252,  3.9741,  1.5361,  ...,  1.4009,  1.1051,  2.9935],\n",
            "        ...,\n",
            "        [ 3.2302,  1.3192,  1.0593,  ...,  1.3705,  3.9784,  1.0635],\n",
            "        [ 0.2149,  2.6748,  2.9752,  ...,  2.1065,  2.8629,  0.8688],\n",
            "        [-0.9031,  2.4887,  5.3582,  ..., -1.4053,  2.2829,  1.2124]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6642,  5.5709,  1.7907,  ..., -0.1143,  2.0800,  2.8446],\n",
            "        [ 3.1682,  5.5973,  3.4897,  ...,  1.7930,  7.9920,  4.5750],\n",
            "        [ 1.6599,  5.9495,  5.4574,  ...,  0.6279,  3.1194,  2.6792],\n",
            "        ...,\n",
            "        [ 2.6171,  3.9986,  4.9662,  ...,  0.4690,  0.3978, -0.9594],\n",
            "        [ 1.7659,  3.7311,  3.9639,  ...,  0.6357,  1.9996,  2.4578],\n",
            "        [ 0.6131,  5.5769,  4.1811,  ..., -2.5763,  1.0542,  0.6345]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2311,  2.1955,  4.1678,  ...,  1.6248,  2.9547,  0.5351],\n",
            "        [ 1.4541,  3.5433,  4.3319,  ...,  2.2957,  0.0226, -1.4686],\n",
            "        [ 4.3925,  7.3565,  2.8243,  ..., -1.6430, -0.8491, -0.8973],\n",
            "        ...,\n",
            "        [ 2.2470,  3.0126,  1.3638,  ...,  2.0963, -0.6202,  0.7349],\n",
            "        [ 5.0400,  7.3609,  1.3689,  ..., -0.3562,  5.1191,  9.0065],\n",
            "        [-0.0188,  3.2555,  4.1665,  ...,  1.4709,  0.9575,  2.1682]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7257,  4.5488,  5.7664,  ...,  0.2298,  1.6731,  5.3050],\n",
            "        [ 1.2133,  3.2889,  2.8316,  ..., -2.1534,  5.8880,  0.1104],\n",
            "        [ 3.4518,  3.5237,  2.2800,  ..., -0.0779,  0.0250, -0.5742],\n",
            "        ...,\n",
            "        [ 0.3569,  0.8374,  5.6605,  ..., -2.3593,  6.0746,  2.5330],\n",
            "        [ 0.6721,  3.3460,  4.5114,  ...,  2.0281,  2.1212,  0.6654],\n",
            "        [ 1.7754,  4.2905,  2.6561,  ...,  0.9993,  0.3670, -0.8415]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5311,  2.4994,  5.6340,  ...,  0.1704,  3.9604,  1.8320],\n",
            "        [ 1.2783,  2.7878,  2.7666,  ...,  0.9663,  2.7599,  1.7802],\n",
            "        [ 3.2850,  5.3260,  3.8160,  ..., -0.5065,  1.5456,  7.4730],\n",
            "        ...,\n",
            "        [ 0.8704,  4.0651,  2.7713,  ...,  2.6412,  3.5467,  2.7090],\n",
            "        [ 1.2180,  5.5740,  2.1132,  ...,  2.8942,  2.9324,  3.7241],\n",
            "        [ 1.7140,  5.4073,  1.9174,  ...,  0.5675,  2.8222,  2.1913]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2203,  4.3864,  5.4697,  ...,  1.3726,  3.4927,  1.6105],\n",
            "        [ 2.7284,  6.5027,  1.8372,  ...,  2.5729,  5.9377,  2.7469],\n",
            "        [ 1.0508,  2.4289,  1.3215,  ...,  1.1356,  0.9587,  0.7971],\n",
            "        ...,\n",
            "        [ 0.0546,  6.3216, -0.0447,  ..., -1.6045,  0.7820,  5.8378],\n",
            "        [ 1.1205,  6.1301,  1.4291,  ...,  2.2827,  2.8969,  3.2251],\n",
            "        [ 1.5038,  4.1699,  3.5255,  ...,  3.0203, -1.0443, -0.4831]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.3481,  5.5075,  2.3567,  ...,  0.8343, -0.0607,  2.1383],\n",
            "        [ 5.7504,  5.3499,  2.4758,  ...,  1.0440,  2.5992,  6.4550],\n",
            "        [ 0.7559,  4.3075,  0.0329,  ..., -0.5684,  0.3395,  6.1664],\n",
            "        ...,\n",
            "        [ 1.6565,  3.3984,  2.8549,  ...,  2.9385,  1.9131,  1.2526],\n",
            "        [ 0.3810,  2.4784,  5.8055,  ...,  0.1237,  4.5753,  5.0752],\n",
            "        [ 1.5831,  7.9465,  2.8754,  ...,  2.4064, -0.3245,  1.4010]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6060,  4.3136,  4.0709,  ..., -3.3714,  6.6754,  3.3286],\n",
            "        [ 2.4683,  3.1329,  0.1250,  ...,  0.6433,  1.1199,  0.2570],\n",
            "        [ 3.9773,  2.8219,  1.7771,  ...,  0.9008,  0.0852,  1.7682],\n",
            "        ...,\n",
            "        [ 2.1125,  4.8349,  3.8030,  ..., -0.1788,  1.0888,  0.7330],\n",
            "        [ 1.1416,  3.1243,  6.3355,  ...,  0.7081,  1.9732,  1.5635],\n",
            "        [ 0.9716,  4.4996,  2.6999,  ...,  1.2259,  2.7211, -0.1183]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1844,  1.9128,  4.2061,  ...,  0.1811,  1.0309,  2.1796],\n",
            "        [ 0.5766,  3.3706,  3.6684,  ..., -3.3240,  4.9392,  8.7131],\n",
            "        [-1.4556,  1.5970,  4.1015,  ..., -0.6542,  0.8999,  0.5697],\n",
            "        ...,\n",
            "        [ 4.5326,  4.0674, -0.9121,  ...,  2.3349,  2.3911,  0.2387],\n",
            "        [ 3.8762,  3.3477,  1.4269,  ...,  1.8268,  1.5950,  0.3404],\n",
            "        [ 1.5331,  4.2150,  0.2344,  ..., -0.2055,  0.3322,  5.8605]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8023,  2.9544,  2.1967,  ...,  1.4892,  6.2733,  5.0362],\n",
            "        [ 1.5837,  5.6561,  0.3575,  ...,  4.2122,  2.0428,  3.7447],\n",
            "        [ 2.3459,  2.1146,  2.7771,  ...,  3.2791,  0.6826,  1.4281],\n",
            "        ...,\n",
            "        [ 1.4818,  5.3645,  1.7957,  ...,  3.0426,  3.8169,  4.7152],\n",
            "        [ 4.1819,  4.9252,  2.8518,  ...,  1.0781,  3.3149,  1.3382],\n",
            "        [ 2.5120,  2.9585,  4.7719,  ..., -1.3549,  5.0271,  9.1269]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9124,  3.9062,  2.6114,  ...,  1.4851, -0.6605,  2.5959],\n",
            "        [ 1.4533, -0.3612,  3.3338,  ...,  1.1579,  0.1086,  1.9066],\n",
            "        [ 3.5918,  6.3188,  1.7831,  ..., -1.1206,  6.8750,  7.4894],\n",
            "        ...,\n",
            "        [ 0.6759,  3.9309,  2.4980,  ...,  2.3832,  1.3299,  2.3380],\n",
            "        [ 2.1716,  5.4787,  1.6382,  ...,  3.3731, -1.0766,  2.3336],\n",
            "        [ 3.8621,  6.4303,  4.0803,  ..., -0.6328,  2.3659,  0.4603]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2909,  3.1548,  2.3010,  ...,  1.1500, -1.5847,  0.2251],\n",
            "        [ 0.9405,  4.5751,  3.4711,  ...,  0.9305,  1.9538,  2.7574],\n",
            "        [ 0.1320,  3.1312,  1.7422,  ...,  1.0382,  2.2952,  1.0894],\n",
            "        ...,\n",
            "        [ 4.4416,  8.2052,  3.8604,  ...,  2.2369,  1.2602,  2.0059],\n",
            "        [ 2.1438,  4.6737,  1.0988,  ..., -3.1767,  2.5020,  5.0862],\n",
            "        [ 0.2090,  2.4634,  3.9138,  ..., -1.5876,  0.0163,  2.8614]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9217,  1.7644,  1.6568,  ...,  2.8583, -0.1277,  0.0773],\n",
            "        [ 1.8936,  8.0477, -1.3095,  ..., -2.1257,  1.5339,  3.4998],\n",
            "        [ 3.8396,  3.2244, -0.3221,  ..., -0.0407, -0.3286,  1.7297],\n",
            "        ...,\n",
            "        [ 1.3959,  2.3569,  2.2565,  ...,  2.4384,  3.0113,  3.2495],\n",
            "        [ 1.8953,  4.5639,  1.8007,  ...,  3.6716,  2.5243,  5.9358],\n",
            "        [ 4.4391,  5.3318,  0.0776,  ...,  2.1257,  2.7347,  0.2021]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7850,  4.5402,  1.1592,  ...,  0.8839, -2.7657,  0.9138],\n",
            "        [ 0.8167,  4.2148,  3.7517,  ...,  1.2849,  4.4459,  4.0302],\n",
            "        [ 1.0675,  4.8714,  3.6570,  ...,  2.1962,  1.3989, -0.4616],\n",
            "        ...,\n",
            "        [ 1.6827,  7.0113,  0.9727,  ...,  1.4377,  1.6358, -0.1342],\n",
            "        [ 0.6724,  4.3430,  2.9157,  ..., -0.5185, -1.2697,  0.6148],\n",
            "        [ 1.4383,  4.3281,  3.7392,  ...,  3.6307,  1.3259,  0.3265]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0838,  7.5252,  0.4765,  ..., -2.6110,  7.9081,  9.5429],\n",
            "        [ 1.6262,  6.2798,  3.7497,  ...,  1.2275,  5.5997,  2.6929],\n",
            "        [ 1.6018,  0.9969,  4.7163,  ...,  1.1917,  2.1443,  2.2323],\n",
            "        ...,\n",
            "        [ 1.7004,  1.9606,  2.4269,  ...,  1.8440,  4.5502,  2.5950],\n",
            "        [ 0.9391,  2.6075,  3.0155,  ..., -0.5289,  1.9177,  1.1630],\n",
            "        [ 2.9741,  1.7691,  1.2426,  ...,  0.1182,  0.7226,  1.2740]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9390,  4.1803,  3.8006,  ..., -1.0613,  5.5140,  4.9340],\n",
            "        [ 1.4713,  6.3355,  1.3584,  ..., -0.5007,  2.2663,  5.2573],\n",
            "        [ 4.7467,  3.7619, -0.9853,  ...,  1.3898,  2.0558,  1.0103],\n",
            "        ...,\n",
            "        [ 1.6751,  3.9167,  2.0789,  ...,  0.1917,  4.2245,  6.5581],\n",
            "        [ 0.6360,  4.5348,  5.0116,  ...,  1.0691,  3.3302,  5.1005],\n",
            "        [ 2.1155,  4.4687,  5.0222,  ...,  1.0148,  3.8538,  2.2554]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7364,  2.9458,  1.6254,  ...,  2.1535, -0.4011,  2.1065],\n",
            "        [ 2.2401,  4.9361,  6.0578,  ...,  0.8351,  1.4999,  0.3091],\n",
            "        [ 0.0782,  3.0113,  4.2609,  ...,  0.6413,  1.3250,  3.1925],\n",
            "        ...,\n",
            "        [ 2.0156,  5.3223, -0.2026,  ...,  1.8955,  6.3912,  2.2720],\n",
            "        [ 1.4273,  6.0530,  3.3755,  ...,  2.0317, -0.2576,  2.8394],\n",
            "        [ 2.9965,  3.6560,  6.9911,  ..., -0.1652,  3.8207,  5.5009]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4153,  3.4058,  4.0582,  ..., -1.5470,  5.2328,  4.6199],\n",
            "        [ 4.3602,  2.2899,  3.0090,  ...,  3.0484,  2.4422,  1.7026],\n",
            "        [ 4.1121,  7.7854,  5.0190,  ...,  0.2586,  1.8729,  2.2146],\n",
            "        ...,\n",
            "        [ 4.4016,  9.0024,  0.6276,  ...,  1.2659,  7.8151,  4.7237],\n",
            "        [ 1.5201,  4.0464,  6.3950,  ...,  0.9828,  3.7553,  4.3290],\n",
            "        [ 2.3696,  5.0272,  0.5536,  ...,  3.9367,  5.0015,  6.1606]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[3.9334, 8.6816, 3.2427,  ..., 0.3976, 1.2033, 8.3049],\n",
            "        [1.2089, 4.9629, 2.3947,  ..., 1.9312, 2.2454, 1.1534],\n",
            "        [2.6256, 1.9662, 0.7432,  ..., 0.3285, 3.4286, 2.5887],\n",
            "        ...,\n",
            "        [3.4446, 3.8274, 3.0707,  ..., 0.7401, 3.1310, 2.9345],\n",
            "        [1.0854, 5.0614, 4.2755,  ..., 2.0870, 3.4561, 3.4368],\n",
            "        [1.0074, 3.6015, 2.8299,  ..., 2.2263, 1.8872, 3.8514]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8611,  4.7373,  4.8463,  ...,  1.9042,  1.0453,  1.8731],\n",
            "        [ 1.6973,  1.9002,  6.5757,  ..., -0.6183,  2.2183,  0.9494],\n",
            "        [ 4.9880,  9.8981,  4.4500,  ...,  0.9090,  3.8836,  2.5015],\n",
            "        ...,\n",
            "        [ 2.9668,  3.1333,  0.7813,  ...,  1.7630,  0.1897,  1.0106],\n",
            "        [ 1.1720,  2.1401,  3.2367,  ..., -0.9324,  4.1982,  6.9455],\n",
            "        [ 0.4230,  2.0605,  2.4379,  ...,  3.1175,  1.5214,  2.8465]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0381,  2.9814,  4.3081,  ..., -1.1274,  3.0468,  5.1950],\n",
            "        [ 1.5555,  4.4346,  2.4414,  ...,  1.7825,  3.7341,  1.4414],\n",
            "        [ 1.4979,  4.1454,  3.3991,  ...,  3.1893,  1.8659,  1.5324],\n",
            "        ...,\n",
            "        [ 2.2258,  4.6337,  5.7238,  ..., -3.8539,  3.5651,  1.0729],\n",
            "        [ 2.9223,  6.2159,  2.5384,  ...,  0.6787,  5.9741,  4.1182],\n",
            "        [ 1.6069,  2.9746,  2.8757,  ...,  2.3569,  3.2611,  1.9867]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4428,  2.6304,  6.0040,  ...,  0.6850,  1.9376,  2.0296],\n",
            "        [ 4.2152,  4.9272,  2.0695,  ..., -0.5780,  0.5610,  1.2139],\n",
            "        [ 3.1682,  7.6034,  2.9491,  ...,  1.1491, -1.1094,  3.4276],\n",
            "        ...,\n",
            "        [ 1.1751,  2.9075,  2.7529,  ...,  0.5312,  5.5392,  3.5699],\n",
            "        [ 1.6243,  4.3420,  2.7335,  ...,  2.6277,  2.0963,  0.6230],\n",
            "        [ 3.0671,  7.1711,  1.1953,  ..., -2.4969,  6.2327,  6.8904]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6092,  8.0466, -0.7428,  ..., -2.0309,  2.4349,  4.3266],\n",
            "        [ 1.9218,  5.6497,  4.5303,  ...,  2.0821,  4.0528,  1.5420],\n",
            "        [-0.1043,  6.2545,  4.0200,  ..., -1.7932,  2.6292,  1.1282],\n",
            "        ...,\n",
            "        [ 0.7219,  9.3511, -0.0721,  ..., -1.7344,  3.6251,  5.3487],\n",
            "        [-0.2550,  2.0163,  3.9659,  ...,  2.1463,  3.0151,  1.6996],\n",
            "        [ 3.4257,  2.1207,  3.6275,  ...,  1.6624,  3.2189,  0.7031]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8730,  1.3277,  4.8674,  ...,  0.9861,  0.6759, -0.3693],\n",
            "        [ 0.0115,  7.1985,  0.2404,  ..., -0.1439, -1.1406,  6.5860],\n",
            "        [ 0.4931,  2.1446,  4.6287,  ...,  2.2613,  3.0159,  2.1483],\n",
            "        ...,\n",
            "        [ 1.5075,  6.2781,  2.2310,  ...,  0.1664,  3.7392,  1.6536],\n",
            "        [ 3.0144,  3.2765,  4.7412,  ...,  0.8826,  4.3404,  1.3346],\n",
            "        [ 2.0414,  3.7539,  4.6810,  ..., -0.6010,  1.3863,  0.4002]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2390,  4.7235,  2.5280,  ...,  3.9387,  4.9267,  4.4105],\n",
            "        [ 2.3465,  2.4286,  1.6651,  ...,  2.2227,  0.9186,  1.8349],\n",
            "        [ 5.1574,  3.9786,  1.8408,  ...,  1.7882,  2.6862,  6.8887],\n",
            "        ...,\n",
            "        [ 2.6764,  2.3783,  1.3888,  ...,  1.7867, -0.4424,  1.7538],\n",
            "        [ 1.1746,  3.0109,  3.8297,  ...,  3.4180,  2.9898,  1.9038],\n",
            "        [ 1.5780,  1.4273,  5.9757,  ...,  1.0876,  3.3034,  3.6724]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.3296,  5.5137,  0.7624,  ..., -0.5621,  0.3616,  1.2012],\n",
            "        [ 1.6850,  5.4205,  3.5135,  ...,  1.4980,  4.1196,  3.2937],\n",
            "        [ 0.3510,  3.4869,  5.4273,  ...,  0.1883,  2.6983,  6.0690],\n",
            "        ...,\n",
            "        [ 2.0715,  4.8118,  4.2042,  ...,  0.8057,  3.7793,  0.9094],\n",
            "        [ 2.1227,  3.6028,  4.7185,  ..., -0.4717,  1.3237,  1.5952],\n",
            "        [ 1.1307,  5.1449, -0.8400,  ..., -1.2483,  1.2918,  3.8283]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3729,  3.6565,  5.2032,  ...,  0.7261,  3.1127,  0.4253],\n",
            "        [ 0.0259,  2.2872,  4.9108,  ...,  0.4471,  2.8068,  1.5796],\n",
            "        [ 1.9984,  1.9345,  3.2633,  ...,  1.9781,  3.6587,  1.8214],\n",
            "        ...,\n",
            "        [ 0.5382,  3.6589,  2.9303,  ...,  0.1727,  2.4662,  1.3039],\n",
            "        [ 1.4235,  2.4590,  4.8809,  ...,  1.1809,  2.6054,  4.6585],\n",
            "        [ 0.8930,  2.7056,  4.6372,  ...,  1.7354,  3.2469,  1.2567]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6672,  2.9145,  1.1831,  ...,  0.9489,  5.5382,  1.7780],\n",
            "        [ 0.2636,  2.1149,  2.6125,  ...,  0.9090,  0.0976,  2.6059],\n",
            "        [-0.6683,  4.6420,  4.3249,  ...,  0.3680,  3.4952,  3.0765],\n",
            "        ...,\n",
            "        [ 1.6137,  1.9114,  2.4787,  ...,  2.4831,  1.0086,  0.3137],\n",
            "        [ 0.4064,  8.2189,  1.4086,  ...,  3.3819,  3.5872,  3.7732],\n",
            "        [ 1.7711,  2.9095,  3.2791,  ...,  2.4410,  0.9795,  0.8630]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4442,  6.1351,  2.4867,  ..., -2.6374,  3.1555,  9.8596],\n",
            "        [ 3.3356,  6.0048,  2.2278,  ...,  2.0652,  3.1223,  1.9862],\n",
            "        [-0.4485,  2.0661,  4.2270,  ...,  0.0874,  3.5483,  4.6189],\n",
            "        ...,\n",
            "        [ 0.1421,  2.7355,  4.0592,  ...,  0.9093,  1.0560,  3.9384],\n",
            "        [ 2.0393,  3.6655,  1.3370,  ...,  2.3519,  1.3550,  3.2225],\n",
            "        [ 0.9661,  2.3017,  4.4085,  ...,  1.7968,  3.5715,  1.1778]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9235,  5.4454,  2.0752,  ...,  1.5953,  4.3144,  8.8633],\n",
            "        [ 3.2758,  5.5610,  3.9587,  ..., -2.8792,  4.3527,  5.0351],\n",
            "        [ 3.0941,  2.9413,  1.9306,  ...,  0.7044,  0.3038,  1.4227],\n",
            "        ...,\n",
            "        [ 1.7676,  2.9356,  2.6896,  ...,  0.1410,  3.2524,  4.6761],\n",
            "        [ 2.3107,  1.3291,  1.1609,  ...,  1.4149,  0.4631,  1.3657],\n",
            "        [ 0.9665,  2.6114,  2.4904,  ...,  1.5553,  1.2448,  0.9308]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3729,  4.2860,  4.6531,  ..., -1.7654, -1.0851, -1.0884],\n",
            "        [ 2.4909,  4.2345,  4.7840,  ...,  1.8235,  0.8175, -0.4002],\n",
            "        [ 1.4305,  3.3694,  5.9927,  ..., -1.9056,  5.0534,  8.0974],\n",
            "        ...,\n",
            "        [ 0.2377,  1.8321,  4.4536,  ...,  2.7953,  2.7594,  2.6178],\n",
            "        [ 0.7983,  5.3511,  6.1376,  ...,  1.5448,  1.1832,  1.3847],\n",
            "        [ 0.8912,  0.3541,  5.7868,  ...,  0.1497,  1.3957,  2.3223]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7530,  4.6986,  4.6373,  ...,  1.1987, -0.5026, -2.5514],\n",
            "        [ 1.3070,  1.9723,  3.1889,  ...,  1.1014,  3.2358,  2.8597],\n",
            "        [ 2.8088,  3.6278,  2.4888,  ...,  1.0510,  2.5789,  8.5412],\n",
            "        ...,\n",
            "        [ 1.0793,  3.7947,  1.1191,  ...,  2.9367,  1.7224,  2.0113],\n",
            "        [ 0.4211,  6.8389,  0.0925,  ...,  0.9392,  0.3568,  3.5018],\n",
            "        [-0.1811,  4.5015,  5.6739,  ..., -2.0914,  3.3848,  3.6631]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7432,  2.6124,  4.7447,  ...,  2.1916,  4.2427,  0.9457],\n",
            "        [-0.0088,  2.7271,  3.9411,  ...,  1.8187,  2.2253,  2.4431],\n",
            "        [ 2.4306,  3.1915,  4.4422,  ...,  2.0161,  4.9208,  1.0093],\n",
            "        ...,\n",
            "        [ 1.6071,  1.7890,  4.2008,  ...,  1.5803,  4.3904,  1.8636],\n",
            "        [ 2.0451,  3.3735,  1.3613,  ..., -0.9585,  3.0847,  0.5953],\n",
            "        [ 1.0734,  4.9133,  6.2196,  ..., -4.2816,  5.5448,  7.1471]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4309,  6.6220,  2.4401,  ...,  1.3834,  3.7072,  3.6889],\n",
            "        [ 1.8095,  2.8312,  4.9420,  ...,  0.4314,  3.7172,  7.3041],\n",
            "        [ 3.0636,  4.6662,  5.0393,  ...,  0.4976,  2.5786,  6.8984],\n",
            "        ...,\n",
            "        [ 1.0903,  3.0356,  3.4714,  ...,  0.8136,  1.9853,  2.3063],\n",
            "        [ 2.3924,  2.5644,  3.0577,  ...,  1.5234,  0.9426,  0.9683],\n",
            "        [ 1.2398,  3.4006,  1.0264,  ..., -1.9037,  5.2773,  2.7883]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2869,  2.2456,  3.4583,  ...,  1.1019,  1.0890,  2.4512],\n",
            "        [ 3.1223,  6.3424,  4.2924,  ..., -3.0051,  0.6884,  1.2466],\n",
            "        [ 3.2562,  4.1498,  2.1486,  ...,  1.2544,  0.1436,  2.2303],\n",
            "        ...,\n",
            "        [ 2.4776,  4.5995,  2.8351,  ...,  0.4165,  1.4535,  4.3553],\n",
            "        [ 2.4355,  3.4929,  1.0920,  ..., -0.0243,  2.5587,  9.0636],\n",
            "        [ 2.1104,  5.0875,  1.9632,  ...,  1.7389,  4.4226,  2.1415]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3505,  3.0995,  4.3997,  ..., -1.8927,  2.2229,  0.8742],\n",
            "        [ 0.8766,  3.2375,  4.9025,  ...,  2.9677,  2.2278,  2.0550],\n",
            "        [ 4.1173,  4.7412,  1.8002,  ..., -0.9344,  0.5877,  2.0133],\n",
            "        ...,\n",
            "        [ 3.1498, 10.2130,  2.6529,  ...,  1.5279,  1.3398,  2.6486],\n",
            "        [ 4.2676,  4.6686,  1.8964,  ..., -0.9846,  0.8062,  3.9307],\n",
            "        [-0.3004,  5.2101,  0.7494,  ..., -0.0168,  2.0218,  7.0879]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9136,  5.9417,  1.1331,  ...,  0.6599,  6.6165,  5.2485],\n",
            "        [ 4.7959,  7.6910,  3.5822,  ...,  2.3691,  3.1679,  2.1600],\n",
            "        [ 1.1495,  3.5227,  2.9281,  ..., -0.9289,  2.0963,  1.7537],\n",
            "        ...,\n",
            "        [ 1.9981,  4.2450,  2.0426,  ...,  0.3386,  1.2005,  8.9164],\n",
            "        [ 2.4718,  7.1987,  2.4951,  ..., -0.0593,  5.4035,  3.2172],\n",
            "        [ 1.6233,  3.0013,  5.3716,  ..., -0.3676,  2.8270,  2.0364]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2818,  7.3972,  1.7526,  ...,  2.6298,  2.3559,  5.3105],\n",
            "        [ 1.6199,  3.4825,  5.8275,  ...,  0.2732,  1.2331,  2.4409],\n",
            "        [ 1.6200,  3.0998,  4.7489,  ...,  3.2976,  2.0032,  1.9986],\n",
            "        ...,\n",
            "        [ 1.3284,  5.0417, -0.2275,  ...,  0.8889,  8.3618,  6.4981],\n",
            "        [ 3.2308,  3.6649,  1.8457,  ...,  0.6144,  0.3863,  1.2412],\n",
            "        [ 0.3895,  5.8075,  0.9166,  ..., -2.6986,  3.7085,  4.3705]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7923,  4.4735,  0.1757,  ..., -2.1462,  8.6763,  5.7127],\n",
            "        [ 0.7431,  2.2442,  3.7492,  ...,  2.7798,  2.9652,  1.9469],\n",
            "        [ 1.7548,  2.7959,  2.8575,  ...,  3.1254,  3.3589,  3.7344],\n",
            "        ...,\n",
            "        [ 1.4238,  3.6263,  1.8431,  ...,  2.8865,  2.3892,  2.2485],\n",
            "        [ 4.5274,  4.9252, -0.2495,  ...,  0.4528,  0.4353,  0.3363],\n",
            "        [ 0.9856,  3.4760,  5.7196,  ...,  0.2812,  2.5826,  4.7512]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5926,  3.8481,  3.8158,  ...,  3.5457,  5.1282,  0.3964],\n",
            "        [ 2.1042,  2.2571,  1.4494,  ...,  1.1143,  5.4115,  3.0786],\n",
            "        [ 1.4371,  3.8279,  3.5714,  ..., -0.9559,  4.1647,  3.9764],\n",
            "        ...,\n",
            "        [ 0.1375,  4.1375,  6.0053,  ..., -2.4375, -0.0626,  1.2234],\n",
            "        [ 1.0293,  3.8113,  4.6577,  ...,  0.1679,  3.6838,  3.2033],\n",
            "        [ 1.9915,  3.4795,  4.0866,  ...,  3.5032,  1.0441,  1.0297]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4255,  6.3298,  3.8776,  ...,  0.6919,  5.3592,  4.7243],\n",
            "        [ 1.8233,  4.8642,  2.6194,  ..., -0.0416, -1.9456,  1.0816],\n",
            "        [ 3.1608,  9.7516,  3.6995,  ..., -1.6462,  3.5008,  2.9537],\n",
            "        ...,\n",
            "        [ 5.2410,  9.3738,  2.0576,  ...,  0.5883,  2.4474,  4.0284],\n",
            "        [ 0.8182,  2.4875,  5.9393,  ...,  1.0502,  3.0340,  3.7315],\n",
            "        [-0.5088,  3.5386,  4.3020,  ..., -0.6252,  0.5191,  1.8911]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9591,  5.6646,  3.1341,  ...,  1.6107,  1.9869,  2.0198],\n",
            "        [ 1.7191,  3.4914,  4.6200,  ...,  1.3138,  4.3674,  1.4690],\n",
            "        [ 2.1765,  7.0226,  0.0902,  ...,  1.2238,  2.6724,  5.6878],\n",
            "        ...,\n",
            "        [ 1.9852,  3.6616,  4.5294,  ..., -1.5532,  5.7500,  8.4377],\n",
            "        [ 2.1442,  2.2188,  0.8454,  ...,  1.9274,  4.8783,  4.8332],\n",
            "        [ 0.2489,  3.5455,  4.5996,  ..., -2.1382, -1.7715,  2.4484]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5397e+00,  3.0887e+00,  1.6143e+00,  ...,  3.0021e-01,\n",
            "          1.6620e+00,  2.6792e+00],\n",
            "        [ 5.5504e+00,  6.6067e+00,  1.0107e+00,  ...,  3.7597e+00,\n",
            "          3.7685e+00,  4.7480e+00],\n",
            "        [ 2.3571e-01,  3.1333e+00,  2.4723e+00,  ..., -2.7506e-03,\n",
            "          3.2672e+00,  2.2077e+00],\n",
            "        ...,\n",
            "        [-1.4684e-01,  1.8415e+00,  4.5284e+00,  ...,  4.8320e-01,\n",
            "          2.6168e+00,  7.4037e-01],\n",
            "        [ 3.3761e+00,  4.7123e+00,  2.8536e+00,  ...,  2.9210e+00,\n",
            "          3.5441e-01,  5.4399e-01],\n",
            "        [ 5.3251e+00,  7.2883e+00,  2.0168e+00,  ...,  2.6496e+00,\n",
            "          5.1170e+00,  4.9508e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9107,  4.9935,  0.1828,  ..., -0.7000,  4.0729,  4.0651],\n",
            "        [ 1.4017,  8.6375,  0.0591,  ..., -0.1352,  6.8667,  3.8382],\n",
            "        [-0.2633,  3.5950,  2.3602,  ..., -3.3979,  1.1818,  2.8153],\n",
            "        ...,\n",
            "        [ 2.2464,  4.4635,  6.0082,  ...,  0.8598,  4.3420,  3.8084],\n",
            "        [ 2.7421,  4.7489,  1.4859,  ...,  3.8633,  3.3714,  3.3091],\n",
            "        [ 2.4884,  4.5185,  3.3577,  ...,  1.7799,  2.5517,  2.9273]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3853,  3.5285,  3.4962,  ...,  3.3638,  2.5245,  1.8180],\n",
            "        [ 2.9362,  6.8589,  3.1049,  ..., -0.2542,  1.4537, -0.0158],\n",
            "        [ 5.2641,  9.9280,  3.2662,  ...,  1.0607,  1.4850,  1.2444],\n",
            "        ...,\n",
            "        [ 0.8184,  4.2641,  4.2251,  ..., -0.7730, -2.5089,  2.0286],\n",
            "        [ 4.6378,  4.1759,  2.1141,  ...,  0.2752, -0.9510,  0.3449],\n",
            "        [ 3.7710,  2.3414,  5.2454,  ..., -0.0759,  2.0788,  0.9325]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9854,  3.7750,  5.1433,  ...,  2.2889,  2.3978,  2.2833],\n",
            "        [ 5.0065,  4.5791,  3.5674,  ...,  0.9174,  0.2586,  2.5537],\n",
            "        [ 1.0092,  2.9124,  1.9462,  ..., -0.0388,  4.7618,  4.2736],\n",
            "        ...,\n",
            "        [ 2.8185,  4.5740,  4.1225,  ..., -1.6867, -0.4789,  2.4285],\n",
            "        [ 3.6508,  3.1153,  0.4521,  ...,  0.2685,  2.1788,  2.9442],\n",
            "        [ 3.2234,  4.9027,  4.0425,  ...,  2.0911,  3.3604,  2.6622]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2669,  9.6278,  2.3787,  ..., -0.6313, 10.0734,  4.6417],\n",
            "        [ 4.8572,  9.7155,  0.3510,  ...,  3.3438,  6.4781,  2.4015],\n",
            "        [ 0.3736,  3.0953,  1.7583,  ...,  1.0930,  4.9696,  2.7420],\n",
            "        ...,\n",
            "        [ 2.9283,  5.6708,  1.2561,  ..., -1.7286,  3.9886,  3.9289],\n",
            "        [-0.4217,  9.6310,  3.8770,  ..., -1.2271,  7.5983,  6.0743],\n",
            "        [ 2.1830,  2.9391,  3.3237,  ...,  2.8681,  3.4382,  2.1230]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9630,  4.8868,  3.3560,  ..., -1.3013, -2.1156,  1.7395],\n",
            "        [ 2.7525,  8.3911,  2.7511,  ..., -0.3250,  3.2526,  2.0241],\n",
            "        [ 2.8375,  5.3275,  3.1524,  ...,  2.6665,  2.5898,  2.7003],\n",
            "        ...,\n",
            "        [ 3.5487,  6.7661,  2.8196,  ..., -1.7260,  2.1510,  5.9617],\n",
            "        [ 3.8963,  2.8820, -0.1897,  ...,  0.8806,  2.2937,  2.6393],\n",
            "        [ 0.5602,  5.4715,  2.5616,  ...,  3.0637,  3.9197,  5.1965]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1045,  4.4602,  2.7412,  ..., -1.9695,  1.7695,  5.2788],\n",
            "        [ 1.4486,  4.7744,  5.7532,  ..., -3.8556,  7.8886,  3.4680],\n",
            "        [ 4.4048,  2.1823, -1.0332,  ...,  1.2718,  5.2465,  2.4188],\n",
            "        ...,\n",
            "        [ 4.0940,  2.4698, -0.4918,  ...,  0.7714,  3.5305,  2.7025],\n",
            "        [ 0.6259,  4.0316,  1.0015,  ...,  1.6961,  1.9525,  2.3286],\n",
            "        [ 1.7849,  7.3701,  3.1588,  ...,  3.9505,  0.3778,  1.4024]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.9383,  4.4974,  1.8609,  ...,  0.8684,  4.8212,  2.4997],\n",
            "        [ 5.0215,  5.5578,  3.7187,  ..., -0.2999,  4.3930,  8.0780],\n",
            "        [ 0.3391,  3.8458,  5.0363,  ...,  3.1445,  2.4438,  1.7677],\n",
            "        ...,\n",
            "        [ 2.3834,  3.2180, -0.3438,  ..., -1.2167,  3.5478,  4.4780],\n",
            "        [ 0.2868,  6.4710,  5.7514,  ..., -0.9672,  4.0544,  3.2314],\n",
            "        [ 3.5079,  5.1415,  0.8079,  ...,  1.3699,  2.8106,  2.4133]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6876,  4.6608,  4.7855,  ..., -2.4049,  2.9127,  5.9619],\n",
            "        [ 1.4999,  5.7916,  5.3456,  ...,  0.2298,  3.1682,  1.5682],\n",
            "        [ 2.3760,  5.8515,  5.1586,  ...,  0.8281,  4.5721,  5.1659],\n",
            "        ...,\n",
            "        [ 2.3258,  6.4695,  2.3012,  ...,  0.7546,  4.2796,  1.4886],\n",
            "        [ 4.5556,  6.5862,  2.8080,  ...,  0.5066,  2.4484,  9.8942],\n",
            "        [ 3.0754,  5.2851,  1.1655,  ...,  3.4535,  1.3799, -0.4574]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0650,  6.8778, -1.0665,  ...,  4.0329,  4.3037,  2.3885],\n",
            "        [ 1.0054,  4.3402,  4.1976,  ...,  0.5687,  5.4208,  1.2883],\n",
            "        [ 4.4149,  7.0558,  2.6296,  ..., -0.9571,  1.4068,  2.9322],\n",
            "        ...,\n",
            "        [ 0.9705,  8.0958,  3.7981,  ..., -1.0391,  0.1285,  1.7701],\n",
            "        [ 3.6946,  5.7087,  1.3921,  ..., -1.8530,  0.7323,  3.2741],\n",
            "        [ 1.1884,  3.7029,  2.9379,  ...,  0.4568,  1.6770,  2.9588]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8781,  8.0365,  7.6654,  ..., -0.4127,  3.8381,  4.8173],\n",
            "        [ 2.9088,  1.7235,  0.7505,  ...,  0.9724,  1.5848,  1.0523],\n",
            "        [ 1.1612,  6.3790,  1.3287,  ...,  2.5097,  2.9332,  1.3585],\n",
            "        ...,\n",
            "        [ 3.8655, 10.2141,  1.8106,  ...,  2.0548,  0.9535,  2.5905],\n",
            "        [ 1.5312,  6.0521,  2.5596,  ...,  2.7693,  4.2929,  5.3150],\n",
            "        [ 2.5210,  2.2754,  2.7282,  ..., -0.8325,  3.2904,  5.3906]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4852,  3.9269,  0.4881,  ...,  2.1236,  2.9652,  0.7974],\n",
            "        [ 2.6523,  5.1939,  4.7742,  ..., -0.4420,  3.6367,  4.0602],\n",
            "        [ 3.1125,  8.3453,  2.4552,  ..., -1.6125,  1.7082,  9.4174],\n",
            "        ...,\n",
            "        [ 0.7663,  3.5174,  3.9281,  ...,  3.5558,  2.8595,  2.0445],\n",
            "        [ 2.8137,  3.8598,  3.4611,  ...,  0.2707,  0.7911,  2.7051],\n",
            "        [ 0.3640,  3.1123,  6.0793,  ...,  0.4471,  2.0089,  2.6913]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1082,  4.4515,  4.0561,  ...,  2.4174,  2.3073,  2.0249],\n",
            "        [ 0.5734,  8.0642,  0.1651,  ..., -2.6624,  0.7905,  8.6173],\n",
            "        [ 0.5331,  3.4637,  4.4957,  ...,  3.1351,  1.8215,  2.3003],\n",
            "        ...,\n",
            "        [ 1.0032,  2.1774,  3.9326,  ...,  3.4527,  2.1161,  2.1338],\n",
            "        [ 0.5143,  3.2937,  3.8928,  ...,  3.2154,  2.5425,  1.9674],\n",
            "        [ 2.3620,  5.2644,  4.7664,  ...,  2.4593,  2.4014,  1.1894]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9128,  3.2981,  1.0077,  ...,  0.7663,  2.5007,  3.6570],\n",
            "        [ 0.4937,  4.5088,  5.1220,  ...,  0.9537,  1.5571,  5.7702],\n",
            "        [ 1.6295,  5.8757,  4.4863,  ...,  2.9884,  1.4971,  2.0827],\n",
            "        ...,\n",
            "        [ 0.4035,  6.4743, -0.0645,  ..., -3.4259,  3.1670,  3.3149],\n",
            "        [ 1.0230,  4.2259,  3.7126,  ...,  3.2788,  1.9716,  1.8934],\n",
            "        [ 7.4737,  5.0025, -1.2444,  ...,  2.4127,  1.4019,  0.1374]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6849,  6.8738, -0.8619,  ..., -0.5718,  1.0841,  3.9378],\n",
            "        [ 5.5247,  5.4751,  2.7518,  ...,  2.8944,  3.7889,  7.0536],\n",
            "        [ 1.0734,  2.2790,  0.9776,  ...,  3.1414,  1.4929,  1.7565],\n",
            "        ...,\n",
            "        [ 1.2095,  2.9845,  4.7335,  ...,  3.4232,  2.1945,  1.2729],\n",
            "        [ 2.6807,  6.7923,  2.2753,  ..., -0.2505, -0.4835,  3.2884],\n",
            "        [ 0.3763,  5.6773,  1.6025,  ...,  0.2359,  2.8221,  5.7412]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.5128,  3.8555,  0.3040,  ..., -0.7033,  2.2196,  1.9599],\n",
            "        [ 2.4085,  5.6031,  2.1489,  ..., -0.8307,  3.5435,  4.5274],\n",
            "        [ 1.7312,  7.0469,  3.0918,  ..., -0.5447,  1.9049,  3.8485],\n",
            "        ...,\n",
            "        [ 1.3777,  1.7963,  1.2180,  ...,  1.7785, -1.0188,  0.9479],\n",
            "        [ 2.1347,  5.8848,  4.4275,  ...,  0.9750,  4.2383,  0.3339],\n",
            "        [ 1.1409,  5.6030,  6.9976,  ...,  1.8426,  2.9521,  5.6353]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4449,  4.6204,  4.0010,  ...,  1.2843,  4.0839,  0.1880],\n",
            "        [ 2.8805,  2.4666, -0.1403,  ...,  1.6951,  3.6274,  2.8046],\n",
            "        [ 3.7701,  5.4986,  0.5934,  ...,  2.7055,  2.4919,  1.5880],\n",
            "        ...,\n",
            "        [ 5.0152,  6.7656,  3.0979,  ...,  1.4637, -0.6071,  1.5657],\n",
            "        [ 0.9236,  0.5597,  5.2526,  ...,  1.2466,  3.5155,  1.1597],\n",
            "        [ 0.1751,  1.8505,  3.1297,  ...,  0.6417,  3.2469,  2.8051]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1365,  3.9628,  5.9851,  ...,  0.1279,  2.0832,  7.2835],\n",
            "        [ 1.3655,  6.0619,  4.0384,  ...,  1.3769,  0.7804,  3.8583],\n",
            "        [ 1.6667,  6.9717,  4.8573,  ..., -3.4121,  1.9003, -0.1466],\n",
            "        ...,\n",
            "        [-0.1683,  2.4997,  4.1834,  ..., -0.1043, -0.7333,  3.0330],\n",
            "        [ 2.1504,  6.6401,  0.1975,  ..., -0.8068,  1.7779,  7.5211],\n",
            "        [ 2.6272,  6.5834,  2.7063,  ...,  1.9766,  0.3779,  2.0744]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0531,  5.6371,  5.3172,  ..., -1.3020,  2.8445,  5.2954],\n",
            "        [ 0.1722,  1.7521,  4.6187,  ...,  2.5103,  3.4832,  0.7766],\n",
            "        [ 2.5253,  4.1186,  3.5709,  ..., -1.1748,  4.3645,  3.7614],\n",
            "        ...,\n",
            "        [ 2.3088,  9.1061,  0.4771,  ..., -2.8109,  1.3057,  6.1674],\n",
            "        [ 1.4129,  0.7008,  4.5292,  ...,  2.4309,  3.9017,  4.5013],\n",
            "        [ 2.0492,  1.6905,  3.5556,  ...,  2.7389,  3.9160,  1.1749]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9422,  6.4321,  1.5221,  ..., -0.2630,  5.1322,  5.5715],\n",
            "        [ 2.4705, 11.1684,  4.0783,  ...,  0.8066,  0.2922,  2.7646],\n",
            "        [ 2.8721,  4.5820,  5.0442,  ...,  1.1476,  4.4117,  2.8355],\n",
            "        ...,\n",
            "        [ 2.1283,  5.7840,  2.0862,  ...,  2.5415,  2.4805,  2.9839],\n",
            "        [ 3.8075,  3.9745,  3.1109,  ..., -0.7943,  0.8331,  1.9310],\n",
            "        [ 1.2460,  2.8449,  3.5361,  ...,  0.1852,  0.7810,  1.5039]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8888,  5.6079,  2.3691,  ...,  4.0677,  3.7142,  2.0044],\n",
            "        [ 0.4583,  3.9721,  5.7653,  ...,  0.8415, -1.0179,  5.0114],\n",
            "        [ 5.5439,  8.8831,  5.1450,  ...,  1.1708,  0.8207,  2.6526],\n",
            "        ...,\n",
            "        [ 2.4609,  2.3983,  3.3653,  ...,  1.6138,  3.2925,  1.7002],\n",
            "        [ 0.8511,  3.9416,  5.3301,  ...,  2.7478,  2.1920,  1.1965],\n",
            "        [ 1.1062,  1.6774,  5.5794,  ...,  1.3168,  1.7184,  3.1574]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.2100,  4.2877,  2.2273,  ...,  3.0357, -0.4131,  2.2310],\n",
            "        [-0.0409,  6.3656,  7.0375,  ..., -5.2038,  6.2353,  8.2171],\n",
            "        [ 4.9415,  2.7907,  3.0207,  ..., -0.4364,  0.4818,  0.9098],\n",
            "        ...,\n",
            "        [-0.8466,  5.7356, -0.2522,  ...,  0.9373, -0.8111,  7.1270],\n",
            "        [ 0.1905,  5.7933,  3.1843,  ..., -2.6798, -1.5693,  5.6493],\n",
            "        [ 2.7402,  2.2743,  1.4373,  ..., -0.9092,  1.8355,  2.1733]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7173,  3.5037,  4.6831,  ...,  0.3509,  3.5063,  1.1678],\n",
            "        [ 1.5715,  6.4780,  4.6845,  ..., -3.3143,  2.8867,  2.5043],\n",
            "        [ 3.0885,  2.0695,  3.9138,  ...,  4.8016, -0.3973,  0.0177],\n",
            "        ...,\n",
            "        [ 1.1159,  1.1347,  2.9267,  ...,  1.3194,  2.3992,  0.5188],\n",
            "        [ 1.8064,  6.7571,  4.5740,  ..., -0.2980,  5.6552,  5.3779],\n",
            "        [ 2.3415,  7.5175,  6.3749,  ...,  0.8320,  4.7133,  3.7032]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6772,  3.8733,  5.0055,  ...,  0.8387,  3.2667,  4.0326],\n",
            "        [ 1.9136,  6.2985,  2.5983,  ..., -2.8533,  4.1609,  6.4783],\n",
            "        [ 1.6821,  4.4470,  1.6608,  ...,  2.5899, -1.5616, -0.7183],\n",
            "        ...,\n",
            "        [ 1.5959,  2.0900,  3.7988,  ...,  1.6332,  3.5641,  0.9591],\n",
            "        [-0.0673,  3.0512,  2.1479,  ...,  2.4863, -0.1072,  3.5473],\n",
            "        [ 3.8848,  3.4853,  1.7725,  ...,  0.8151,  0.6821,  2.0459]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8526,  6.3703,  1.9040,  ..., -2.3745,  3.0313,  6.1071],\n",
            "        [-0.2502,  2.3573,  3.7779,  ...,  0.4733,  2.1993,  2.0077],\n",
            "        [ 0.7884,  6.4426,  2.8116,  ..., -2.8404,  3.2285,  4.9758],\n",
            "        ...,\n",
            "        [ 2.6381,  8.3054,  2.3057,  ...,  2.0725,  0.6148,  2.4715],\n",
            "        [ 3.5554,  2.2389, -0.4963,  ...,  1.3046,  4.6852,  2.9951],\n",
            "        [-0.0431,  7.8131,  2.0798,  ..., -0.1333,  6.8101,  5.2599]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5684e+00,  5.8707e+00,  1.9982e+00,  ...,  2.8678e+00,\n",
            "          1.4088e+00,  1.9861e+00],\n",
            "        [ 2.4554e+00,  3.5851e+00,  2.8112e+00,  ...,  2.1099e+00,\n",
            "          2.4028e+00,  1.2687e+00],\n",
            "        [ 1.7173e+00,  2.9589e+00,  4.4307e+00,  ...,  1.1813e+00,\n",
            "          5.0355e-02, -1.7469e+00],\n",
            "        ...,\n",
            "        [ 1.7733e+00,  6.9542e+00,  9.7526e-01,  ...,  1.8125e+00,\n",
            "          1.2025e+01,  5.3849e+00],\n",
            "        [ 4.7651e+00,  2.9584e+00,  3.1102e+00,  ...,  2.4057e+00,\n",
            "         -1.6201e+00, -2.2469e-03],\n",
            "        [ 4.3254e+00,  3.8929e+00,  1.3919e+00,  ...,  1.0295e+00,\n",
            "          3.7847e+00,  1.3115e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.5147e+00,  4.3213e+00, -7.0304e-01,  ..., -1.5927e-01,\n",
            "          6.0096e-02,  1.8703e+00],\n",
            "        [ 3.8652e+00,  5.7092e+00,  2.8911e+00,  ..., -8.2578e-01,\n",
            "         -1.9330e-01,  3.2704e+00],\n",
            "        [ 4.1003e-01,  3.5150e+00,  2.9946e+00,  ...,  4.2477e-01,\n",
            "          5.7125e-01,  3.2590e+00],\n",
            "        ...,\n",
            "        [ 1.2883e+00,  2.9979e+00,  4.5084e+00,  ...,  2.0619e+00,\n",
            "          3.6566e+00,  1.9970e+00],\n",
            "        [ 4.3190e+00,  2.4131e+00, -5.1365e-03,  ...,  2.6726e+00,\n",
            "          4.0455e+00,  1.1191e+00],\n",
            "        [ 2.9693e+00,  3.7417e+00,  3.1136e+00,  ...,  2.4050e-01,\n",
            "          2.9752e-01,  2.5160e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7362,  7.7418,  3.3467,  ...,  1.6613,  4.3281, -0.1194],\n",
            "        [ 1.0044,  2.2565,  4.0082,  ..., -0.1046,  3.1758,  1.3528],\n",
            "        [ 3.5363,  2.5550,  0.5753,  ..., -1.3637,  1.0493,  2.7445],\n",
            "        ...,\n",
            "        [-0.1292,  2.8137,  2.1245,  ...,  2.5108,  2.8143,  1.7959],\n",
            "        [ 2.3789,  4.9584,  3.1583,  ..., -0.4758,  1.1611, -0.1879],\n",
            "        [ 6.7958,  7.2247,  3.4121,  ...,  0.7941,  4.4687,  7.0676]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3013,  5.7156,  2.4894,  ...,  1.1687,  6.0587,  3.7857],\n",
            "        [ 1.4035,  7.5347, -0.0231,  ...,  1.6907,  0.5414,  4.5166],\n",
            "        [ 1.6852,  3.0110,  3.5574,  ...,  0.8134,  3.2552,  2.6057],\n",
            "        ...,\n",
            "        [ 1.5176,  5.1890,  5.1110,  ...,  2.5132,  3.2743,  2.2461],\n",
            "        [ 0.6566,  2.3286,  3.2632,  ...,  2.9507,  2.7553,  0.7657],\n",
            "        [ 1.4849,  6.2884,  2.1083,  ...,  0.1570, -1.0085,  2.5167]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0532,  3.4236,  0.2703,  ...,  2.2354,  0.9036,  0.7621],\n",
            "        [ 3.6014,  9.8722,  0.9763,  ...,  0.1885,  9.9638,  6.5171],\n",
            "        [ 3.2464,  5.5418,  2.6006,  ..., -3.3903,  1.8372,  3.3438],\n",
            "        ...,\n",
            "        [ 1.6258,  5.0894,  3.4756,  ..., -0.6365,  1.6958,  1.8654],\n",
            "        [ 3.7011,  6.6110,  1.9791,  ...,  2.9223,  3.8312,  1.8536],\n",
            "        [ 3.5408,  6.1356,  1.4790,  ...,  3.8031,  3.5837,  4.6337]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9863,  6.7052, -0.0596,  ..., -0.8085,  1.2968,  6.8427],\n",
            "        [ 2.7264,  3.1363,  0.7383,  ...,  2.3319,  2.1483, -0.2959],\n",
            "        [ 2.3467,  5.0562,  3.5131,  ..., -0.6151, -1.6344,  1.0300],\n",
            "        ...,\n",
            "        [ 2.9674,  5.0751,  2.8382,  ...,  3.0632, -0.0144,  0.8918],\n",
            "        [ 1.2938,  5.0404,  4.2008,  ..., -0.0634,  2.6874,  8.0438],\n",
            "        [ 0.8938,  4.6011,  4.7866,  ...,  2.3581,  3.6733,  1.6336]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6350,  4.7102,  4.5930,  ...,  1.7986,  0.9184,  4.0269],\n",
            "        [ 2.8599,  8.9011,  2.7455,  ...,  3.2751,  6.3376,  3.5532],\n",
            "        [ 1.1571,  5.8562,  2.1701,  ...,  1.2770, 10.7510,  6.9514],\n",
            "        ...,\n",
            "        [ 1.7527,  3.5239,  3.2303,  ..., -4.8031,  3.4969,  7.0277],\n",
            "        [ 2.8948,  3.8238,  3.1191,  ..., -0.4461,  1.5662, -0.3049],\n",
            "        [ 1.7219,  3.0109,  2.4769,  ...,  2.1685,  1.1849,  2.6408]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3837,  2.5495,  5.5364,  ...,  1.4511,  2.1019,  3.9434],\n",
            "        [ 0.9493,  3.1894,  6.8223,  ..., -1.2717,  3.7091,  7.1286],\n",
            "        [ 7.0356,  6.0363,  2.0824,  ...,  0.0994,  0.6069, -0.0247],\n",
            "        ...,\n",
            "        [ 1.5363,  3.4068,  4.3313,  ...,  2.0686,  0.9985, -1.1557],\n",
            "        [ 4.3921,  5.3412,  1.5483,  ...,  1.0381,  5.2833,  4.2259],\n",
            "        [ 4.6344,  7.1805,  1.7433,  ...,  2.6575,  1.3260,  2.5855]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5138,  6.9445,  1.5609,  ...,  0.6533,  0.5852,  4.1196],\n",
            "        [ 0.4871,  7.0657,  7.4995,  ..., -2.4978,  6.1451,  7.0590],\n",
            "        [ 0.2072,  3.8063,  4.4873,  ...,  0.5229,  3.5792,  4.7968],\n",
            "        ...,\n",
            "        [ 2.9999,  6.3744,  0.1554,  ..., -4.9349,  2.0243,  5.0081],\n",
            "        [ 3.0964,  6.8017,  3.3523,  ..., -1.4531,  1.6792,  5.9426],\n",
            "        [ 3.8760,  5.4367,  0.9555,  ...,  3.5916,  3.8392,  3.0751]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3323,  3.3028,  3.6930,  ...,  1.7835,  1.2237,  1.3189],\n",
            "        [ 2.2144,  8.4261,  1.5348,  ...,  1.4801,  7.9271,  3.0268],\n",
            "        [ 5.0301,  5.6847,  0.5209,  ...,  0.2710,  1.7068,  1.2982],\n",
            "        ...,\n",
            "        [ 0.7681,  4.0092,  4.1933,  ..., -0.1279,  7.7352,  5.5610],\n",
            "        [ 0.2479,  6.8746,  4.1642,  ...,  0.0730, -0.7315,  3.1909],\n",
            "        [ 2.0837,  7.8379,  3.6077,  ...,  1.9277,  3.9823,  3.2043]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8337,  5.3066, -0.4853,  ...,  3.5775,  4.6112,  5.1181],\n",
            "        [ 3.4534,  6.0036,  2.6047,  ..., -0.8489,  0.2508,  1.8944],\n",
            "        [ 3.1258,  4.9031,  2.3553,  ...,  0.4634,  2.3280,  1.2017],\n",
            "        ...,\n",
            "        [ 4.4371,  7.8826, -0.8000,  ..., -1.0244,  5.2211,  5.8874],\n",
            "        [ 1.0716,  4.2421,  4.0448,  ...,  2.1994,  3.0865,  1.7570],\n",
            "        [ 4.9556,  2.7817,  1.1787,  ...,  1.5224,  1.1956,  1.0370]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0127,  2.7516, -0.3235,  ...,  0.6680,  3.2847,  2.7500],\n",
            "        [ 5.0155,  9.5038,  1.9306,  ...,  1.5096,  3.8976,  2.7995],\n",
            "        [ 2.9849,  9.6668,  3.7823,  ...,  3.2598,  0.1241,  1.9993],\n",
            "        ...,\n",
            "        [ 1.9531,  3.5654,  3.8177,  ...,  0.1377,  1.5400,  7.6680],\n",
            "        [ 0.2036,  3.5281,  2.4624,  ...,  1.3765,  7.0190,  4.5084],\n",
            "        [ 5.3451,  9.4510,  5.0575,  ..., -0.8353,  4.2562,  6.6673]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.5364,  5.7476,  3.4064,  ...,  1.9006,  2.1906,  2.4790],\n",
            "        [-0.0162,  5.3959,  4.2374,  ...,  0.8384,  2.3922,  2.6206],\n",
            "        [ 1.5077,  7.1501, -1.9748,  ...,  0.6891, -0.5700,  3.4867],\n",
            "        ...,\n",
            "        [ 1.3283,  2.8932,  5.1909,  ...,  1.5028,  4.8231,  2.3410],\n",
            "        [ 2.8359,  3.0575,  1.8350,  ...,  1.9286,  3.9115,  1.3087],\n",
            "        [ 1.0264,  5.7130,  1.5482,  ...,  1.5353, -1.0592,  2.0537]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5150,  4.1981,  4.0860,  ...,  1.1663,  3.3688,  2.8001],\n",
            "        [ 4.1899,  2.9000, -1.0797,  ...,  1.2354,  3.5293,  0.7206],\n",
            "        [ 3.1870,  7.0687,  4.8942,  ...,  1.7336,  2.9310,  6.7375],\n",
            "        ...,\n",
            "        [ 2.5478,  5.0694,  2.4079,  ...,  2.3465,  1.9536,  5.0603],\n",
            "        [ 0.4316,  5.2759,  5.8281,  ..., -0.7862,  1.5461,  5.5742],\n",
            "        [ 2.2861,  6.3044, -0.0302,  ..., -3.5118,  1.3836,  4.5434]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0554,  4.2774,  3.0127,  ...,  1.8668,  1.0171,  2.3404],\n",
            "        [ 1.9981,  5.0163,  0.3340,  ...,  2.9560,  2.7802, -0.4521],\n",
            "        [ 3.2405,  3.6924,  3.3540,  ...,  4.8796,  4.9873,  5.1974],\n",
            "        ...,\n",
            "        [ 2.7702,  7.8306,  3.7967,  ...,  1.7120,  1.0557,  2.0724],\n",
            "        [ 4.0220,  2.5025,  0.6179,  ...,  0.6212,  1.7472,  2.6280],\n",
            "        [ 2.4804,  3.8981,  4.6838,  ...,  1.7001,  1.5781,  2.6446]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0929,  5.2468,  0.3303,  ..., -0.2861,  1.6634, -0.2962],\n",
            "        [ 1.4379,  3.4969,  7.4277,  ...,  1.3890,  2.1212,  2.1874],\n",
            "        [ 1.8106,  3.4183,  3.0600,  ...,  0.8996,  1.5590,  2.8711],\n",
            "        ...,\n",
            "        [ 3.5268,  5.4456,  3.3945,  ...,  0.7506,  0.7683,  1.0160],\n",
            "        [ 4.2662,  8.0229,  5.3733,  ..., -1.4818,  5.2110,  3.1458],\n",
            "        [-0.2499,  4.9594,  2.3739,  ...,  0.2471, -1.1388,  8.5071]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1294,  3.8516,  4.6656,  ...,  2.7846,  1.4487,  1.3153],\n",
            "        [ 5.0958,  5.0757,  4.1205,  ...,  0.9767,  1.2484,  1.0327],\n",
            "        [ 1.3828,  2.5694,  4.4462,  ...,  2.8652,  4.1075,  1.8186],\n",
            "        ...,\n",
            "        [ 3.1410,  5.7145,  2.1537,  ...,  2.1957,  3.4744,  0.3843],\n",
            "        [ 1.7153,  2.4207,  1.3538,  ...,  3.2834,  1.2451,  0.6739],\n",
            "        [ 0.0553,  4.6509,  2.0626,  ..., -1.4020, -0.3597, -0.1103]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7844,  4.6171,  1.3401,  ...,  4.7459,  3.6601,  1.5861],\n",
            "        [ 1.4814,  7.3972,  4.8591,  ..., -1.7183,  2.6011,  6.0483],\n",
            "        [ 4.5065,  8.0741,  0.3569,  ..., -0.9373,  3.0645,  0.6006],\n",
            "        ...,\n",
            "        [ 1.7818,  4.7999,  3.6754,  ...,  0.2583,  2.7471,  2.7408],\n",
            "        [ 6.6822,  7.6257,  2.1127,  ...,  0.9382,  2.5996,  5.9625],\n",
            "        [ 0.3922,  2.2236, -0.0662,  ..., -3.3327,  3.2464,  2.4584]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4082,  5.6548,  3.0063,  ...,  0.7679,  0.4530,  2.5949],\n",
            "        [ 2.7007,  6.2597, -0.7678,  ...,  0.0656,  8.8905,  4.3298],\n",
            "        [ 1.8655,  2.9065,  7.4522,  ..., -1.0929,  3.8812,  6.6569],\n",
            "        ...,\n",
            "        [ 2.6188,  4.8449,  5.3469,  ...,  0.0570,  3.7300,  5.7385],\n",
            "        [ 1.5226,  3.3473,  1.9805,  ...,  2.0930,  0.4025,  1.3336],\n",
            "        [ 1.3326,  5.4891,  4.3264,  ..., -0.5307,  0.9121,  4.1618]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1718,  6.1565,  5.9697,  ...,  0.5103,  3.1615,  4.0579],\n",
            "        [ 1.0341,  4.4115,  4.7418,  ...,  0.9236,  2.2583,  5.9640],\n",
            "        [-1.3656,  3.8224,  5.7227,  ..., -2.8351,  7.0934,  3.4237],\n",
            "        ...,\n",
            "        [ 1.3525,  5.0177,  4.0098,  ...,  0.4922,  2.2136,  1.9204],\n",
            "        [ 4.6404,  3.6377,  1.0692,  ...,  3.5374,  1.8626,  0.3727],\n",
            "        [ 3.3511,  4.0407,  2.5784,  ...,  4.5953,  4.1410,  5.1652]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6157,  7.9610,  5.0503,  ..., -1.1259,  3.6770,  7.2729],\n",
            "        [ 2.0581,  5.0125,  5.6302,  ...,  0.3316,  3.7588,  4.6054],\n",
            "        [-0.6783,  1.8559,  5.7911,  ..., -0.5941,  0.8919,  0.8323],\n",
            "        ...,\n",
            "        [-0.2200,  5.3036,  3.8744,  ...,  1.8800,  3.9782,  6.0310],\n",
            "        [ 2.9163,  5.1456,  2.8463,  ...,  1.6112,  2.9708,  2.6060],\n",
            "        [ 2.8977,  4.6964,  2.5648,  ...,  2.5042,  0.0795, -0.0598]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5402,  4.2183,  3.3008,  ...,  2.2106,  3.2950,  4.6366],\n",
            "        [ 1.3583,  3.5405,  4.9438,  ..., -0.1570,  4.0000, 10.2640],\n",
            "        [ 1.9790,  3.8081,  3.9517,  ...,  1.5695,  0.8141, -0.3668],\n",
            "        ...,\n",
            "        [ 2.1522,  4.8274,  3.3667,  ...,  1.6329,  7.5184,  6.0367],\n",
            "        [-0.8650,  1.5274,  4.5390,  ..., -1.4943,  6.7800,  3.8258],\n",
            "        [ 3.2901,  2.3616,  2.9083,  ...,  1.9699,  4.5306,  5.2014]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4712,  4.2993,  7.0275,  ...,  0.2319,  3.6803,  6.4149],\n",
            "        [ 1.8830,  6.9527,  1.7581,  ...,  1.8654,  3.2507,  0.2204],\n",
            "        [-0.9923,  5.5240,  7.3039,  ..., -3.4129,  7.7120,  3.4601],\n",
            "        ...,\n",
            "        [ 0.7714,  3.3967,  2.6368,  ...,  0.5400,  3.2025,  1.6803],\n",
            "        [ 0.5568,  7.7932,  1.6504,  ..., -0.2248,  2.4658,  5.4419],\n",
            "        [ 2.4841,  3.3196,  4.0229,  ...,  1.8675,  3.7161,  2.3943]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.0682,  5.4393,  3.5132,  ..., -0.0808,  1.7059,  2.7650],\n",
            "        [-0.0472,  4.1724,  6.4968,  ..., -0.6630,  5.4383,  2.3479],\n",
            "        [ 2.1843,  3.2474,  4.5594,  ...,  2.7852,  1.9209,  1.8025],\n",
            "        ...,\n",
            "        [ 1.2426,  4.9652,  3.2851,  ...,  2.0369, -0.4195,  1.2758],\n",
            "        [ 5.3514,  8.6729,  4.6627,  ...,  0.4187,  2.4458,  0.4712],\n",
            "        [ 1.2764,  8.1238,  3.1894,  ...,  2.5264,  6.7997,  4.6322]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1358,  8.5671,  2.0768,  ..., -3.4954,  0.6862,  6.9841],\n",
            "        [ 1.2180,  6.7957,  3.4016,  ...,  2.8433,  0.3433,  3.1543],\n",
            "        [ 0.8567,  2.7242,  4.2294,  ...,  2.0317,  3.5444,  2.1829],\n",
            "        ...,\n",
            "        [ 1.1509,  2.8291,  3.3121,  ...,  1.2120,  3.7072,  1.9872],\n",
            "        [ 2.5837,  2.8117,  1.0506,  ...,  1.8473,  0.5942,  2.0032],\n",
            "        [ 0.0261,  3.2953,  5.6233,  ...,  1.5030,  4.3649,  5.4633]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.5501,  4.8701,  3.5522,  ..., -1.3746,  1.1253,  4.0714],\n",
            "        [ 3.5685,  6.0814,  2.0877,  ...,  2.9934,  1.9574,  4.2645],\n",
            "        [ 0.5829,  3.5821,  3.1342,  ...,  3.5332,  2.0705,  2.9279],\n",
            "        ...,\n",
            "        [ 4.8599,  3.3881,  0.6006,  ...,  3.0060, -0.5549,  2.6338],\n",
            "        [ 1.6135,  2.7301,  1.3784,  ...,  1.4266, -2.6717,  0.6818],\n",
            "        [ 1.0083,  4.5849,  5.8990,  ..., -1.8313,  4.0997,  2.4947]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1527,  5.4489,  6.6147,  ..., -3.1943,  4.6674,  7.6130],\n",
            "        [ 7.0098,  9.3160,  0.8423,  ...,  4.8526,  4.5232, -0.6473],\n",
            "        [ 3.5437,  2.8885,  1.1678,  ...,  3.9764,  2.8941,  3.7071],\n",
            "        ...,\n",
            "        [ 3.3462,  2.7906,  1.3923,  ...,  3.4628,  0.5192,  2.9085],\n",
            "        [ 0.8212,  3.9107,  6.4137,  ...,  1.2922,  3.7292,  4.4424],\n",
            "        [ 2.7764,  3.8623,  5.5518,  ...,  3.2162,  3.1560,  1.8204]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9775e-01,  2.8156e+00,  4.7945e+00,  ...,  7.6078e-01,\n",
            "          3.8688e+00,  3.1300e+00],\n",
            "        [-5.9163e-01,  7.7693e+00,  3.4556e+00,  ...,  6.1487e-01,\n",
            "          6.8853e+00,  5.0564e+00],\n",
            "        [ 3.7134e+00,  7.1314e+00,  4.4793e-01,  ..., -9.1298e-03,\n",
            "          2.1132e+00,  9.4896e+00],\n",
            "        ...,\n",
            "        [ 2.9258e+00,  3.2036e+00, -6.6017e-01,  ...,  3.2132e+00,\n",
            "          1.3403e+00,  1.8289e+00],\n",
            "        [ 3.7569e-01,  4.0240e+00,  6.4393e-02,  ...,  1.0974e+00,\n",
            "          2.1639e+00,  3.2151e-01],\n",
            "        [ 2.9184e+00,  3.7045e+00,  2.9002e+00,  ...,  5.5300e-01,\n",
            "          5.3409e-01, -1.1330e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3998,  6.3884,  1.4672,  ..., -0.5477, -0.5421,  2.9521],\n",
            "        [ 3.2907,  5.7364,  0.5438,  ...,  1.4297,  3.1229,  0.4586],\n",
            "        [ 2.9559,  1.7110,  4.8652,  ...,  0.3467,  5.0020,  7.6045],\n",
            "        ...,\n",
            "        [ 6.6998,  4.1668, -0.3813,  ...,  2.4954,  3.2185,  1.3622],\n",
            "        [ 2.8605,  3.5260,  4.8090,  ...,  1.0550,  1.7978,  5.2800],\n",
            "        [ 0.5335,  5.2044,  0.4422,  ...,  0.7137, -0.3892,  7.6211]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0408, 10.4637,  3.0016,  ...,  2.3780,  2.3038,  3.5499],\n",
            "        [ 2.7999,  4.8421,  4.2452,  ...,  1.3553,  3.6253,  0.1881],\n",
            "        [ 4.3608,  4.2437,  0.9201,  ...,  5.2872,  1.3124,  1.2189],\n",
            "        ...,\n",
            "        [ 0.3708,  5.7979,  4.5539,  ..., -0.1554,  0.2645,  4.5256],\n",
            "        [ 1.8169,  5.2316,  4.5950,  ...,  1.8934,  2.0122,  2.5812],\n",
            "        [ 2.6228,  4.8677,  1.4147,  ...,  1.5826,  2.5514,  1.3986]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8936,  2.0760,  4.6031,  ...,  0.0587,  3.9858,  6.0673],\n",
            "        [ 2.1218,  5.6699,  1.4015,  ...,  4.6176,  1.5224,  4.3820],\n",
            "        [ 2.8099,  8.7377,  4.3195,  ...,  0.6389,  6.2499,  6.8990],\n",
            "        ...,\n",
            "        [ 6.4174,  8.1438,  2.4854,  ..., -0.6981,  4.9465,  3.2159],\n",
            "        [ 2.0521,  6.0975,  1.5344,  ...,  0.3623,  5.0362,  3.1048],\n",
            "        [ 1.9269,  5.5567,  4.2627,  ...,  0.5867, -0.6324,  4.4990]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6968,  2.8671,  6.2118,  ..., -1.0366,  1.4142,  2.4444],\n",
            "        [ 4.9086,  4.3523,  1.2901,  ...,  1.2340,  0.6433,  2.5617],\n",
            "        [ 2.6863,  6.0093,  1.6081,  ...,  4.0394,  2.9213,  1.0035],\n",
            "        ...,\n",
            "        [ 1.6794,  3.5896,  1.9055,  ...,  1.2569, -0.7271,  3.9298],\n",
            "        [ 0.8778,  4.3408,  3.6529,  ...,  0.2066,  0.3143,  1.4259],\n",
            "        [ 0.7703,  2.0364,  3.9539,  ...,  1.1357, -1.7432,  0.4086]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5827,  5.1816,  3.8209,  ...,  1.2658,  3.8028,  6.4767],\n",
            "        [ 1.8385,  5.0387,  3.8331,  ..., -0.6081,  9.5348,  6.0580],\n",
            "        [ 4.5348,  3.5339,  0.1235,  ...,  1.7570,  1.3350,  1.9432],\n",
            "        ...,\n",
            "        [ 4.5422,  5.3580,  1.7942,  ...,  0.3588,  2.9784,  5.3275],\n",
            "        [ 1.1023,  8.4999,  6.8270,  ...,  0.5130, -0.3596, -0.3135],\n",
            "        [ 4.8797,  6.6819,  2.7051,  ..., -0.3572,  7.0171,  5.6090]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4712,  3.2592,  6.1746,  ...,  0.0390,  5.5027,  4.7201],\n",
            "        [ 2.5436,  9.6612,  1.1276,  ...,  0.8892,  5.5647,  3.1411],\n",
            "        [ 3.9594, 10.6668,  2.7355,  ...,  2.8643,  1.1928,  1.4718],\n",
            "        ...,\n",
            "        [-0.0717,  5.8005,  5.7599,  ..., -0.8139, -1.9552,  0.7959],\n",
            "        [ 2.3438,  5.2673,  1.9984,  ..., -0.7870,  7.5362,  3.0417],\n",
            "        [ 3.2918,  3.9309,  2.9069,  ...,  1.1251, -1.2387,  1.0132]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9439,  9.3294,  5.9581,  ...,  2.3935,  0.9709,  0.5691],\n",
            "        [ 2.8338,  7.4803,  3.8005,  ...,  0.2700,  9.0098,  7.2166],\n",
            "        [ 3.0698,  4.3655,  2.6780,  ...,  1.4454,  5.2604,  6.9895],\n",
            "        ...,\n",
            "        [ 1.9187,  3.9075,  7.0680,  ..., -1.3065,  0.6431,  0.9552],\n",
            "        [ 3.8871,  4.8875,  3.2741,  ...,  1.8281,  4.7110,  3.1103],\n",
            "        [-0.3433,  2.7711,  3.4024,  ..., -0.7754,  1.0951,  3.2426]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5472,  4.2333,  3.3586,  ...,  0.0423,  1.7140,  1.6399],\n",
            "        [ 1.7707, -0.0384,  2.0756,  ...,  2.7084,  2.2497,  1.6460],\n",
            "        [-0.8245,  2.0048,  2.3504,  ..., -0.4980,  1.5010,  5.1353],\n",
            "        ...,\n",
            "        [ 1.5044,  5.0171,  3.2103,  ...,  1.3526, -2.1012, -1.3929],\n",
            "        [ 3.6367,  5.4515,  2.3885,  ...,  3.6504,  2.3833,  1.6743],\n",
            "        [ 1.3155,  2.8851,  4.0274,  ...,  4.0579,  2.6117,  1.7987]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.5524,  7.0113,  2.2109,  ...,  5.8605,  1.6345,  0.3939],\n",
            "        [ 2.7918,  3.7126,  6.4300,  ..., -0.6141,  4.7269,  6.6423],\n",
            "        [ 2.2505,  4.7577,  3.8122,  ...,  2.9030,  0.6156,  3.4258],\n",
            "        ...,\n",
            "        [ 3.4153,  1.5170,  0.1713,  ...,  1.2140,  4.1914,  2.1739],\n",
            "        [ 0.8619,  4.9506,  4.4814,  ..., -2.4435,  2.3863,  4.4796],\n",
            "        [ 3.5539,  2.5578,  1.3078,  ...,  1.3468,  0.0259,  1.3239]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6881,  8.1833, -0.1748,  ...,  5.4752,  4.6532,  2.5324],\n",
            "        [ 4.8150,  3.3212,  1.8275,  ...,  2.2986, -0.2244,  0.9236],\n",
            "        [ 2.6109,  4.4749,  4.0200,  ...,  3.6205,  4.1395,  1.8179],\n",
            "        ...,\n",
            "        [ 1.6366,  4.9186,  2.4789,  ...,  1.5918,  6.2892,  5.6542],\n",
            "        [ 4.3552,  5.5816,  2.7389,  ...,  2.3065,  4.5014,  2.1859],\n",
            "        [ 3.9634,  9.0701,  4.4888,  ...,  2.4878,  0.9096,  2.2854]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.8779,  5.0170,  0.2055,  ...,  0.6889, -1.1541,  0.4174],\n",
            "        [ 3.9576,  2.7236,  2.1512,  ...,  1.1783,  3.8868,  2.2682],\n",
            "        [ 4.9895,  6.9878,  2.0004,  ...,  3.6770,  3.7980,  0.4924],\n",
            "        ...,\n",
            "        [ 2.2472,  5.5465,  4.2781,  ...,  1.1589,  6.7879,  3.7481],\n",
            "        [ 0.8939,  1.1106,  1.8175,  ...,  2.6104, -1.6211,  1.5138],\n",
            "        [ 2.5008,  3.7684,  6.4423,  ..., -0.9554,  4.4481,  5.5772]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3590, 10.2385, -1.2844,  ..., -1.6028,  0.7022,  4.8612],\n",
            "        [ 6.3719,  6.9998,  3.6779,  ...,  2.1132,  0.5822,  0.2200],\n",
            "        [ 0.7893,  6.9605,  3.8941,  ...,  1.4126, -1.1003,  3.8404],\n",
            "        ...,\n",
            "        [ 0.1303,  4.3802,  1.2791,  ...,  0.5505,  3.2052, -1.5912],\n",
            "        [ 2.3454,  4.6695,  5.9065,  ..., -0.8399,  5.6809,  6.8136],\n",
            "        [-1.8311,  2.1371,  4.7798,  ..., -0.7009,  0.1278,  2.7541]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5358,  4.2353,  2.5632,  ..., -3.9926,  4.7299,  3.6850],\n",
            "        [ 2.6450,  3.8423,  3.0419,  ...,  1.4851,  0.5077,  1.4037],\n",
            "        [ 0.5163,  3.6018,  4.4521,  ...,  3.3510,  3.0431,  1.6515],\n",
            "        ...,\n",
            "        [ 7.6963, 10.6731,  4.7875,  ...,  1.6959,  2.0711, -0.2747],\n",
            "        [ 1.3838,  4.0807,  3.1599,  ...,  3.3910,  0.1890,  1.9290],\n",
            "        [ 0.1085,  6.5871,  3.8198,  ...,  3.2137,  1.9353,  4.3389]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1559,  2.4123,  3.5841,  ...,  4.5842,  1.7943,  1.8894],\n",
            "        [ 4.2926,  2.6895,  2.2216,  ...,  3.1825, -0.7327, -0.6529],\n",
            "        [ 3.6911,  7.2885,  0.5889,  ..., -0.1764,  4.0782,  9.1750],\n",
            "        ...,\n",
            "        [ 0.0640,  5.4029,  5.6501,  ..., -2.8700,  0.4202,  1.7716],\n",
            "        [ 1.2148,  6.7507,  5.8877,  ...,  0.4923,  2.5831,  2.8615],\n",
            "        [ 4.4892,  2.6763,  0.1682,  ...,  0.0697,  0.9266,  2.2881]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.4058,  8.1210, -1.8520,  ..., -0.4539,  8.6394,  6.8016],\n",
            "        [ 1.7473,  4.1845,  7.1994,  ..., -0.8277,  6.0023,  5.6439],\n",
            "        [ 0.6102,  2.7967,  3.0210,  ...,  3.0316,  2.0481,  1.9763],\n",
            "        ...,\n",
            "        [ 4.3375,  6.7366,  3.4928,  ..., -2.6283,  1.6115,  3.7000],\n",
            "        [ 0.7567,  4.0408,  1.8982,  ...,  3.2701,  3.6614,  1.2643],\n",
            "        [ 2.4043,  4.0102,  3.2353,  ...,  2.2744,  2.2188,  2.7488]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[1.7043, 4.0449, 3.5369,  ..., 2.0718, 0.2834, 1.0676],\n",
            "        [2.3749, 5.2786, 4.5381,  ..., 2.2242, 3.6804, 1.6542],\n",
            "        [1.5553, 3.5589, 3.9681,  ..., 2.7236, 4.5132, 0.8868],\n",
            "        ...,\n",
            "        [1.4652, 2.4417, 3.2158,  ..., 3.6468, 3.0114, 0.5427],\n",
            "        [3.4338, 4.5503, 4.0721,  ..., 1.9595, 3.7697, 4.5600],\n",
            "        [4.4698, 6.5359, 1.9876,  ..., 4.0532, 2.5415, 2.3200]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 8.3552,  7.7230,  2.8258,  ...,  2.8773,  2.0540,  5.1290],\n",
            "        [ 3.6719,  6.4996,  3.4728,  ..., -1.0357,  6.0686,  4.9563],\n",
            "        [ 4.5148,  9.8771,  1.1750,  ...,  0.5793, 10.2106,  2.3668],\n",
            "        ...,\n",
            "        [ 3.3184,  8.3025,  3.0617,  ...,  2.1570,  0.2477,  3.5784],\n",
            "        [ 2.0964,  4.1693,  4.5692,  ...,  1.6835,  4.2187,  1.0770],\n",
            "        [ 0.3889,  6.7783,  3.5154,  ...,  2.6882,  0.3359,  3.8932]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7706,  5.6223,  2.7850,  ...,  0.6220,  1.5578,  2.2087],\n",
            "        [ 0.2774,  4.1549,  3.8784,  ...,  1.4140,  0.4373,  1.1087],\n",
            "        [ 3.7233,  9.1182,  0.3969,  ..., -3.5753,  3.4022,  6.9981],\n",
            "        ...,\n",
            "        [-0.1799,  5.3743,  2.8042,  ...,  0.8628,  0.0636,  5.0332],\n",
            "        [ 3.9903,  7.5232,  1.8063,  ...,  5.5538,  4.3131,  1.6789],\n",
            "        [ 3.3917,  5.2828,  2.5793,  ...,  4.7082,  1.1139,  4.5130]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3436,  5.1922,  4.1606,  ..., -0.1453,  2.7496,  6.5095],\n",
            "        [ 1.8077,  2.9998,  3.6088,  ...,  3.7388,  2.8290,  1.0452],\n",
            "        [ 1.3013,  3.1902,  2.7074,  ...,  1.8645, -0.8462,  2.7758],\n",
            "        ...,\n",
            "        [ 2.4578,  3.8995, -0.3120,  ..., -1.9367,  2.7521,  3.8916],\n",
            "        [ 2.2513,  6.2749,  2.2722,  ...,  0.1054,  5.9065,  2.3219],\n",
            "        [ 7.0953, 10.0667,  0.3451,  ...,  2.5465, 12.0958,  8.0649]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80e6ce9f696d45cba8d8b511735df32b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.8724,  6.3080,  1.8550,  ...,  3.4286,  2.6106,  1.1610],\n",
            "        [ 1.0919,  3.5363,  1.1407,  ..., -2.4410,  3.6451,  4.5476],\n",
            "        [ 5.4229,  3.4684, -0.6859,  ...,  2.3523,  1.9231,  0.3131],\n",
            "        ...,\n",
            "        [ 0.5811,  4.0373,  6.0117,  ...,  0.6584,  2.0746,  6.0839],\n",
            "        [-0.3128,  5.3639,  5.8535,  ..., -4.1646,  2.6708,  3.5589],\n",
            "        [ 4.4888,  5.8769,  2.0039,  ...,  5.9833,  4.3420,  3.7018]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4065,  8.8041, -1.9283,  ..., -0.3372, -0.6581,  6.4022],\n",
            "        [ 4.5662,  7.6366,  2.2195,  ...,  5.3035,  6.0725,  2.4631],\n",
            "        [ 3.2066,  7.0385,  3.1963,  ...,  3.7274,  3.0102,  3.4829],\n",
            "        ...,\n",
            "        [ 2.0955,  7.6004,  1.2590,  ...,  1.1583, -0.2721,  4.8927],\n",
            "        [ 4.2242,  3.2486,  2.4144,  ..., -0.5574,  1.3258,  1.6971],\n",
            "        [ 3.2032,  4.8850,  1.9946,  ...,  2.1216,  2.2110,  8.4296]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7929,  5.5170,  3.8987,  ...,  0.0947,  1.6637,  2.7127],\n",
            "        [ 3.5498,  3.9767, -0.4910,  ...,  2.1344,  1.3463,  1.7275],\n",
            "        [ 2.9268,  5.7365, -0.1291,  ...,  1.1521,  0.1419,  8.0938],\n",
            "        ...,\n",
            "        [ 5.6659,  5.1621,  0.3454,  ...,  0.9854,  4.0388,  2.2199],\n",
            "        [ 2.2138,  4.4199,  3.1587,  ...,  3.6308,  2.3091,  3.9279],\n",
            "        [ 2.7180,  6.6296,  2.1452,  ...,  1.9192,  6.3962,  2.8220]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.7261,  8.0532,  3.6506,  ...,  2.6342,  1.8256,  1.4962],\n",
            "        [ 2.4841,  4.6351,  5.9399,  ..., -1.0946,  2.4193,  1.5619],\n",
            "        [ 2.3350,  4.2246,  5.0105,  ...,  1.0611,  3.4297,  1.3752],\n",
            "        ...,\n",
            "        [ 4.6539,  4.7573,  2.1394,  ...,  2.1226,  1.4962,  2.2538],\n",
            "        [ 0.7081,  4.4731,  3.6374,  ...,  0.1616,  1.9333,  1.1919],\n",
            "        [ 4.6480,  9.5959,  2.9751,  ..., -2.2110,  2.4298,  4.9161]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1446,  4.0371,  5.3327,  ...,  2.0922,  2.5503,  2.3217],\n",
            "        [ 2.4805,  5.7184,  1.1998,  ...,  0.5998,  1.4245,  9.8871],\n",
            "        [ 1.6568,  2.9152,  2.0246,  ...,  2.4738, -0.4779,  0.6983],\n",
            "        ...,\n",
            "        [ 3.4638,  6.7435,  1.5163,  ...,  0.7017,  6.6543,  4.9122],\n",
            "        [ 3.6047,  7.3809,  1.4376,  ..., -2.8221,  4.6782,  3.5988],\n",
            "        [ 1.0360,  8.7638,  4.8620,  ..., -0.6853,  0.4597,  5.2916]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7278,  3.6291,  4.8901,  ...,  1.6475,  3.2857,  3.0561],\n",
            "        [ 0.9413,  8.9264,  0.1185,  ..., -2.7809, -1.5418,  5.2523],\n",
            "        [ 4.0139,  6.4268,  4.7630,  ...,  1.9958,  5.6655,  4.7516],\n",
            "        ...,\n",
            "        [ 0.6362,  2.9264,  4.3904,  ...,  2.2639,  2.7107,  1.6722],\n",
            "        [ 1.9187,  6.1071,  3.9540,  ...,  1.0917,  2.4312,  3.8045],\n",
            "        [ 3.3440,  7.5751,  3.4108,  ...,  2.6028,  1.5534,  3.6669]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1864,  5.7388,  5.0157,  ...,  0.0643,  0.1395,  3.5452],\n",
            "        [ 2.0263,  2.9063,  1.6596,  ..., -0.1058,  1.1761,  2.5984],\n",
            "        [-0.7882,  3.3374,  6.3049,  ..., -3.8196,  5.7535,  6.2345],\n",
            "        ...,\n",
            "        [ 2.7796,  7.7199,  2.6622,  ..., -1.7178,  0.7948, 11.3275],\n",
            "        [ 5.3623,  4.3105,  2.2573,  ...,  2.2258,  1.2632,  7.3653],\n",
            "        [ 1.3402,  4.3159,  3.6950,  ...,  3.5668,  2.3827,  3.3636]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4006,  6.1204,  3.2812,  ...,  0.0285,  8.9209,  3.2470],\n",
            "        [ 3.9474,  6.1948,  3.2341,  ...,  0.8552,  6.1017,  5.8967],\n",
            "        [ 1.0471,  5.8962,  5.2860,  ...,  0.7053, -0.3573,  6.1267],\n",
            "        ...,\n",
            "        [ 0.8809,  1.9696,  4.1120,  ...,  2.0096,  3.3533,  1.2988],\n",
            "        [ 3.3071, 11.4665,  1.3213,  ..., -1.3900,  7.5579,  5.3157],\n",
            "        [ 0.8505,  5.7355,  1.9328,  ..., -1.7816,  2.2119,  4.6259]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8548,  5.9012,  1.8268,  ...,  0.0506,  4.7757,  3.4285],\n",
            "        [ 1.6466,  8.5841,  3.2083,  ..., -0.8581, 10.4313,  6.8328],\n",
            "        [ 3.0919,  2.9507,  2.3300,  ...,  0.0192,  0.7634,  3.1609],\n",
            "        ...,\n",
            "        [ 2.7507,  9.2991,  3.3194,  ..., -1.4855, -1.2288,  3.3479],\n",
            "        [ 4.1794,  3.8017,  2.5901,  ...,  2.1931,  1.6107,  6.7769],\n",
            "        [ 5.4069, 10.7814,  3.1319,  ...,  0.5994,  2.2681,  3.7581]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9653,  3.9311,  6.4463,  ...,  0.6020,  2.2603,  4.6601],\n",
            "        [ 3.0983, 10.0929,  3.6281,  ...,  0.5885,  1.6569,  1.9741],\n",
            "        [ 0.5454,  2.1072,  4.2484,  ...,  2.3644,  2.9665,  1.5331],\n",
            "        ...,\n",
            "        [ 2.5580,  6.0837,  1.9716,  ...,  3.5162,  2.6262,  1.4181],\n",
            "        [ 4.2299,  4.9042,  2.4439,  ...,  2.1388, -1.4810,  0.8616],\n",
            "        [ 3.2103,  4.2172,  3.5937,  ...,  2.7391,  1.5949,  7.2200]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5590,  6.5366,  3.4606,  ...,  2.4906,  1.9497,  3.4314],\n",
            "        [ 3.9849,  5.8122,  4.1075,  ...,  2.2943,  0.6455,  3.1399],\n",
            "        [-0.6903,  4.2460,  3.1596,  ...,  0.8232,  3.0119,  7.6337],\n",
            "        ...,\n",
            "        [ 0.1719,  1.4813,  1.3583,  ...,  0.8275,  0.7177,  4.5350],\n",
            "        [ 5.0947,  9.7208,  1.8982,  ...,  4.1613,  3.1015,  2.5896],\n",
            "        [ 4.8924,  5.1137,  1.6902,  ...,  5.0042,  0.6213,  5.1074]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5018e+00,  4.0887e+00,  2.9172e+00,  ...,  9.7394e-01,\n",
            "          8.8179e-01,  4.0928e+00],\n",
            "        [ 4.4356e+00,  8.3477e+00,  4.2563e+00,  ...,  2.1842e-01,\n",
            "          1.6323e+00,  2.7141e+00],\n",
            "        [ 8.3418e-01,  1.8052e+00,  3.2865e+00,  ..., -3.6763e-01,\n",
            "         -1.3355e+00,  3.2368e+00],\n",
            "        ...,\n",
            "        [ 3.3250e+00,  8.8086e+00,  2.0157e+00,  ...,  1.8782e+00,\n",
            "          6.7756e+00,  6.0281e+00],\n",
            "        [ 4.9405e+00,  5.1678e+00,  3.1758e+00,  ...,  5.6452e-01,\n",
            "          1.6894e+00,  3.5979e+00],\n",
            "        [ 4.2601e+00,  1.3085e+01,  1.2042e-02,  ...,  3.2743e+00,\n",
            "          2.8815e+00,  4.2174e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5862,  5.0054,  3.9979,  ...,  0.6471,  7.6634,  4.8872],\n",
            "        [-0.0779,  7.1735,  3.9428,  ..., -0.5174,  2.9472,  4.3817],\n",
            "        [ 2.4675,  7.3025,  6.4014,  ..., -2.8802,  2.5494,  4.8990],\n",
            "        ...,\n",
            "        [ 0.8807,  3.2862,  4.5126,  ...,  1.9506,  1.9936,  3.7040],\n",
            "        [ 2.8331,  4.6127,  3.7929,  ..., -0.0730,  0.6398,  1.0498],\n",
            "        [ 3.0225,  5.6914,  4.8356,  ..., -0.0453,  0.6429,  1.5971]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6963,  3.4804,  4.5286,  ...,  4.0245,  2.3575,  1.5167],\n",
            "        [ 0.6896,  2.6557,  4.1473,  ...,  1.3290,  3.2757,  2.1196],\n",
            "        [ 1.1177,  5.3805,  4.4136,  ...,  0.7487, -0.3835,  6.2259],\n",
            "        ...,\n",
            "        [-0.5025,  3.8322,  3.7110,  ...,  0.7625,  2.9889,  5.9452],\n",
            "        [ 3.9940,  3.2319,  1.6408,  ...,  2.6495,  4.2557,  2.1679],\n",
            "        [ 4.2192,  5.4417, -1.6277,  ...,  3.0558,  1.4047,  5.5949]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.4315,  8.0543,  5.1804,  ..., -2.3918,  1.5774,  4.0853],\n",
            "        [ 4.7508,  2.4623,  1.1466,  ...,  1.3555,  2.1530,  1.0192],\n",
            "        [ 5.4021,  5.9206,  1.8558,  ...,  0.6807,  1.9042,  8.5344],\n",
            "        ...,\n",
            "        [ 5.1829,  9.7103,  3.3932,  ..., -0.2328,  7.7893,  4.8823],\n",
            "        [ 1.1476,  2.3720,  3.2628,  ...,  2.2107,  3.9547,  4.4683],\n",
            "        [ 3.9550,  3.9565, -0.5031,  ...,  2.5085,  0.7016,  0.9243]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5938,  3.6643,  2.9811,  ...,  4.2797,  2.1339,  1.3596],\n",
            "        [ 3.4806,  3.3642,  5.0928,  ...,  2.9764, -1.2425, -0.4266],\n",
            "        [ 4.1882,  8.2383, -0.6972,  ...,  0.9827,  1.5932,  7.7808],\n",
            "        ...,\n",
            "        [ 2.0587,  4.2755,  5.4288,  ...,  0.4650,  0.9978,  1.7381],\n",
            "        [ 2.1716,  3.3341,  1.0611,  ...,  3.5851,  3.9078,  1.1233],\n",
            "        [ 0.8639,  4.4784,  1.3756,  ..., -1.2406,  1.5685,  4.3280]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.7372,  6.5211,  3.2051,  ...,  3.5418,  2.7353,  1.4831],\n",
            "        [ 5.5504,  9.9331,  0.6972,  ...,  5.1873,  5.2338,  3.2763],\n",
            "        [-1.1260,  5.2628,  5.9193,  ...,  1.3999,  2.8842,  5.8084],\n",
            "        ...,\n",
            "        [ 2.6121,  4.5419,  3.2120,  ..., -0.1036,  2.3364,  0.3359],\n",
            "        [ 2.0849,  4.4936,  3.1551,  ...,  1.0567,  7.6106,  6.1412],\n",
            "        [ 0.5227,  6.7431,  6.3975,  ..., -0.6950,  3.4786,  3.3929]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6642,  4.2352,  1.3120,  ...,  1.3028,  1.6622, -1.1816],\n",
            "        [ 3.1360,  4.4559,  4.3234,  ...,  3.1802,  1.2326,  3.4469],\n",
            "        [ 4.0635,  8.1092,  4.6361,  ..., -2.3733,  1.0505,  0.7864],\n",
            "        ...,\n",
            "        [-0.9410,  3.5001,  2.4755,  ...,  2.3725,  1.6089,  0.6548],\n",
            "        [ 1.1224,  6.7639,  4.9381,  ...,  1.6481,  1.0678,  5.1252],\n",
            "        [-1.0937,  1.7129,  5.7040,  ..., -0.4903,  0.4365,  0.0611]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1055,  5.2785,  1.7008,  ...,  2.7126,  7.3224,  1.0082],\n",
            "        [ 4.2025,  7.2233,  0.5517,  ..., -1.6107,  0.8433,  5.6885],\n",
            "        [ 1.2363,  2.7111,  3.2544,  ...,  3.6857,  2.3047,  1.0734],\n",
            "        ...,\n",
            "        [ 3.9896,  2.2886,  1.5014,  ...,  1.5285,  2.0838,  0.8472],\n",
            "        [ 4.1164,  3.5210,  0.0161,  ...,  2.2545,  6.1764,  3.3028],\n",
            "        [ 2.1379,  3.8964,  4.6879,  ...,  4.0667,  0.7503,  1.2028]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1304,  3.5070,  4.2643,  ...,  0.3496,  4.7700,  3.5179],\n",
            "        [ 1.3417,  6.8670,  6.2450,  ...,  2.2070,  2.1546,  1.3205],\n",
            "        [ 0.3171,  2.3717,  2.3083,  ...,  2.0632,  1.6424,  2.8089],\n",
            "        ...,\n",
            "        [ 6.5537,  6.8392,  0.1690,  ...,  2.5270,  7.4729,  2.8882],\n",
            "        [ 3.4083,  7.8233,  5.9534,  ...,  0.4602, -0.5855,  3.7978],\n",
            "        [ 0.8024,  1.2849,  3.1825,  ...,  1.8046,  0.3255,  4.0393]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9342,  3.5799, -1.7701,  ...,  1.7066,  0.2254,  2.5002],\n",
            "        [ 0.7449,  4.9436,  2.3801,  ..., -0.9106, -0.1427,  1.6503],\n",
            "        [ 2.8294,  9.4757,  0.0395,  ...,  4.4881,  4.5650,  3.2088],\n",
            "        ...,\n",
            "        [ 5.0380,  7.1594,  1.6650,  ...,  6.0647,  1.6680,  0.6949],\n",
            "        [ 6.0590,  6.7612,  2.6535,  ...,  3.9356,  1.3173,  1.5585],\n",
            "        [ 2.2056,  3.1201,  4.8986,  ...,  0.1824,  2.2770,  2.5289]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3220,  3.9383,  4.6476,  ...,  3.2548,  2.5079,  1.3687],\n",
            "        [ 6.2195,  6.4164, -0.2715,  ...,  3.1307,  3.6689,  2.6367],\n",
            "        [ 3.3232,  6.2914,  2.6456,  ...,  3.1428,  3.2854,  3.1926],\n",
            "        ...,\n",
            "        [ 3.4331,  6.2789,  5.8996,  ..., -1.1251,  3.9075,  2.9693],\n",
            "        [ 6.8733,  4.0052,  0.5422,  ...,  3.7100,  0.1249,  1.8722],\n",
            "        [ 5.3646,  3.4542,  3.8412,  ...,  1.9194,  2.6708,  1.8521]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5301,  4.6645,  1.7036,  ...,  0.0943,  1.8630,  2.2165],\n",
            "        [ 2.0365,  4.4437,  4.8090,  ...,  1.7979,  4.1364,  3.1532],\n",
            "        [ 0.6298,  8.2089,  0.5253,  ..., -2.3383,  2.3610,  6.3012],\n",
            "        ...,\n",
            "        [ 0.3157,  5.1530,  1.8373,  ..., -3.2876,  5.2069,  2.8292],\n",
            "        [ 0.8804,  5.2497,  4.9534,  ..., -0.3315, -0.5234,  4.6957],\n",
            "        [ 1.8446,  6.8622,  1.3008,  ..., -1.6558,  0.6776,  7.9841]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5364,  8.1386,  4.4177,  ..., -0.4090,  2.2986,  3.2046],\n",
            "        [ 3.9495,  3.4969,  1.3859,  ...,  2.8600, -1.2194, -0.5394],\n",
            "        [ 3.2944,  5.5007,  3.2451,  ...,  4.0352,  2.5338,  2.7379],\n",
            "        ...,\n",
            "        [ 3.6306,  4.8302,  1.9558,  ...,  2.6032, -0.6054,  2.0590],\n",
            "        [ 1.2192,  3.9981,  5.2831,  ...,  2.0828,  3.9069,  1.6790],\n",
            "        [ 2.7858,  4.8846,  6.8508,  ..., -1.5438,  1.9797, -0.2742]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[1.5266, 2.7892, 5.6859,  ..., 1.5582, 1.8592, 4.6700],\n",
            "        [3.4286, 3.3404, 3.5291,  ..., 2.0670, 5.0387, 2.5880],\n",
            "        [0.4536, 2.6436, 3.5216,  ..., 1.4521, 2.7636, 2.1956],\n",
            "        ...,\n",
            "        [2.9713, 4.6307, 2.2801,  ..., 0.6002, 2.4939, 8.0759],\n",
            "        [1.7336, 2.6696, 4.1381,  ..., 2.2382, 4.0484, 1.3037],\n",
            "        [0.9234, 2.5413, 3.2774,  ..., 3.0777, 2.2945, 2.1491]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7352,  3.6281,  3.1741,  ...,  0.8278,  0.9308,  4.4393],\n",
            "        [ 2.5622,  8.0927,  4.5539,  ...,  0.3232,  4.4675,  3.8460],\n",
            "        [-0.7579,  8.0041,  1.5087,  ..., -4.1819,  0.3932,  8.3495],\n",
            "        ...,\n",
            "        [ 0.5780,  8.9434, -1.6244,  ..., -2.8540, -0.7859,  4.0498],\n",
            "        [ 2.7766,  4.7569,  3.5128,  ...,  0.9171, -1.5538,  0.8014],\n",
            "        [ 4.3341,  5.2097, -1.2136,  ...,  4.1461,  4.3861,  1.0085]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.6044,  6.6450,  3.2243,  ...,  1.1289,  0.0912,  0.4412],\n",
            "        [ 2.8462,  4.0802,  4.5380,  ...,  0.9590,  4.5210,  2.0956],\n",
            "        [ 6.1005,  8.3247,  0.9489,  ...,  3.8550,  4.1308,  5.9706],\n",
            "        ...,\n",
            "        [ 3.1368,  3.2874,  2.4577,  ..., -0.9660,  0.2998,  1.9969],\n",
            "        [ 0.4175,  3.2050,  5.1425,  ...,  1.5301,  2.5584,  1.8945],\n",
            "        [-0.7587,  6.9977,  6.2875,  ..., -3.4150,  4.6770,  3.8230]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9731,  1.4732,  3.1086,  ..., -1.9560,  1.2254,  1.7201],\n",
            "        [ 6.6668,  5.1439, -0.9790,  ...,  1.1816,  1.2425,  0.5747],\n",
            "        [ 0.8298,  6.9988,  3.4197,  ..., -4.1735,  3.1293,  2.0377],\n",
            "        ...,\n",
            "        [ 0.8608,  4.5198,  4.7365,  ...,  3.3419,  2.5825,  2.2361],\n",
            "        [ 0.5809,  0.6254,  2.2450,  ...,  0.4260,  0.7151, -0.0436],\n",
            "        [ 3.6368,  5.3405,  3.8306,  ...,  1.9168,  1.1903,  5.6905]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3879,  1.3587,  4.5606,  ..., -0.7524,  3.6408,  7.0228],\n",
            "        [ 3.9061,  2.0133,  0.5349,  ...,  1.6955,  3.8300,  2.7765],\n",
            "        [ 0.3098,  5.5312,  1.8588,  ..., -0.2927,  1.5525,  4.1947],\n",
            "        ...,\n",
            "        [ 2.7497,  4.5518,  3.1831,  ...,  3.6091,  2.9542,  0.8029],\n",
            "        [-0.2917,  6.0128,  3.8724,  ..., -3.2243, -3.0335,  6.7602],\n",
            "        [ 1.5483,  4.1048,  4.0188,  ...,  1.7260,  1.1372,  1.5185]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1453,  3.4994,  2.3145,  ...,  2.2998,  1.3630,  4.6761],\n",
            "        [ 3.9659,  5.6634,  1.5650,  ...,  3.5493,  3.4117,  0.9134],\n",
            "        [ 3.2829, 13.3951,  3.7242,  ..., -1.6390, -0.4721,  2.9018],\n",
            "        ...,\n",
            "        [ 2.1430,  6.3568,  5.8608,  ...,  0.8082,  1.5386,  2.4762],\n",
            "        [ 3.0048,  2.2613,  6.5501,  ..., -0.1535, -1.1639,  1.7158],\n",
            "        [ 1.8950,  2.7360,  2.0107,  ...,  2.6679,  1.3781, -0.4779]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.4027,  8.7137,  0.2403,  ...,  1.2590, 10.7659,  9.5320],\n",
            "        [ 2.3087,  3.2864,  5.0423,  ..., -1.1786,  1.6479,  0.1422],\n",
            "        [ 4.1332,  6.9884, -1.0614,  ...,  3.4251,  5.0849,  2.2587],\n",
            "        ...,\n",
            "        [ 1.9576,  1.9294,  6.6199,  ..., -0.1827, -0.0914,  1.5069],\n",
            "        [ 4.9078, 13.8637,  1.5381,  ...,  2.3048,  7.9022,  7.0752],\n",
            "        [ 2.5049,  5.6877,  1.4210,  ...,  1.4199,  6.2519,  3.0482]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9716,  3.9985,  3.4611,  ...,  3.1559,  2.3287,  1.7595],\n",
            "        [ 2.1907,  8.1498,  2.8785,  ...,  0.4796,  6.2422,  1.4740],\n",
            "        [ 2.4516,  5.0615,  5.1899,  ...,  1.3259,  4.8653,  1.8170],\n",
            "        ...,\n",
            "        [ 2.2885,  6.1131,  8.1952,  ..., -0.7658,  1.7692,  7.6715],\n",
            "        [ 1.4580,  5.8856,  3.9336,  ...,  0.9528,  3.2777,  2.0753],\n",
            "        [ 2.8139,  7.3248,  3.0354,  ...,  3.1257,  2.6420,  3.9033]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1482,  2.7088,  3.4213,  ...,  2.9227,  2.7737,  3.8547],\n",
            "        [ 0.2775,  3.6925,  2.7744,  ...,  0.9828,  6.6837,  4.7553],\n",
            "        [ 1.8122,  4.9930,  4.7622,  ..., -1.6705,  0.9674,  1.7390],\n",
            "        ...,\n",
            "        [ 2.0861,  3.7289,  3.5194,  ..., -0.7098,  0.2317,  2.6727],\n",
            "        [ 1.7617,  6.2558, -0.9224,  ...,  0.3998, -1.6063,  7.0940],\n",
            "        [ 2.8952,  8.1906,  3.3128,  ...,  2.0118, -1.6145,  3.0053]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6081,  3.9763,  2.6311,  ...,  1.9036,  0.9293,  0.3100],\n",
            "        [ 2.5155,  3.0031,  4.7506,  ...,  1.1563,  1.4591,  5.8253],\n",
            "        [ 2.5647,  7.6036,  2.4245,  ..., -2.1473, -1.5633,  1.0811],\n",
            "        ...,\n",
            "        [ 2.0752,  7.4239,  2.7827,  ...,  0.8944,  0.6243,  6.3317],\n",
            "        [ 1.5668,  6.4805,  5.0580,  ..., -0.8614,  0.4514,  1.5207],\n",
            "        [ 1.8197,  5.6197,  6.0313,  ...,  1.9742,  1.2267,  4.0713]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4543,  3.2233,  1.6267,  ...,  1.4389, -0.1390, -1.5298],\n",
            "        [-1.0691,  5.5326,  4.7889,  ..., -0.5518,  2.1737,  2.4357],\n",
            "        [ 7.4688,  5.1775, -0.3139,  ...,  1.3021,  1.5953, -0.6840],\n",
            "        ...,\n",
            "        [ 1.6612,  4.0092,  5.6988,  ...,  0.0843,  1.0747,  2.4738],\n",
            "        [ 5.0637,  8.0226,  1.7196,  ..., -2.3413,  2.5410,  7.3007],\n",
            "        [ 1.1145,  9.2999,  4.3458,  ...,  0.2378,  0.9673,  5.9231]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7418,  4.5926,  7.6678,  ...,  0.6404,  4.3414,  5.9908],\n",
            "        [ 3.1981,  4.3861,  2.6678,  ...,  0.5772,  0.3715,  2.9527],\n",
            "        [ 1.8370,  2.0012,  2.7486,  ...,  0.2879,  1.6321, -0.2571],\n",
            "        ...,\n",
            "        [ 4.7583,  2.7072,  3.2749,  ...,  2.0166,  2.2491, -0.2217],\n",
            "        [ 0.9365,  7.0188,  3.4240,  ...,  2.2738,  3.7696,  0.2789],\n",
            "        [ 3.4634,  8.8378,  4.0934,  ...,  0.0683,  0.2661,  2.1869]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4631,  5.1741,  5.1615,  ...,  1.6681,  3.6447,  2.1409],\n",
            "        [ 2.2747,  7.4438,  4.0127,  ..., -0.4077,  0.2613,  0.4674],\n",
            "        [ 5.7964, 10.1856,  3.2578,  ...,  0.7569, -0.4456,  4.2562],\n",
            "        ...,\n",
            "        [ 3.0398,  2.3285,  4.2307,  ...,  0.7694,  0.4345,  1.5210],\n",
            "        [ 6.1080,  7.5872,  2.0517,  ..., -0.6534, -0.1519,  2.2030],\n",
            "        [ 3.6697,  7.7613,  4.9434,  ..., -1.2149,  1.7752,  2.3871]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4187,  7.3223,  4.9420,  ...,  3.3226,  0.7531,  2.7181],\n",
            "        [ 1.3905,  4.1558,  0.8776,  ..., -1.0997,  0.4724,  7.2972],\n",
            "        [ 4.2055,  7.0339,  2.2962,  ...,  1.5404,  0.3627,  8.5967],\n",
            "        ...,\n",
            "        [ 3.8343,  5.2302,  3.2105,  ..., -0.4494, -1.3820,  4.3381],\n",
            "        [ 2.5224,  7.1365,  2.7941,  ..., -0.5317,  7.6383,  5.1214],\n",
            "        [ 1.2004,  4.2616,  3.8673,  ..., -2.2028,  5.3615,  0.6477]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3502,  8.2457,  5.1934,  ..., -0.3762,  2.5053,  2.9911],\n",
            "        [ 2.9070,  8.6226, -0.2003,  ...,  4.1657,  7.3316,  6.2874],\n",
            "        [ 1.3257,  3.3423,  4.8516,  ...,  1.9085,  3.4517,  2.6745],\n",
            "        ...,\n",
            "        [ 2.5474,  5.1175,  4.1982,  ...,  1.9877,  4.9011,  0.9858],\n",
            "        [ 2.9920,  4.4933,  3.7786,  ...,  2.1124, -0.6427,  1.4188],\n",
            "        [ 1.5242,  4.5494,  6.3940,  ...,  2.5002,  1.2909,  1.5711]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2408e-01,  2.3237e+00,  6.7709e+00,  ...,  6.2365e-01,\n",
            "          4.6492e+00,  4.2350e+00],\n",
            "        [ 1.9145e+00,  4.9545e+00,  5.3309e+00,  ...,  2.2614e-01,\n",
            "         -1.9690e-01, -2.3291e-03],\n",
            "        [ 5.5803e-01,  2.1933e+00,  3.6923e+00,  ..., -1.0581e+00,\n",
            "          2.7324e+00,  6.1953e+00],\n",
            "        ...,\n",
            "        [ 6.1514e+00,  1.0846e+01,  1.2310e+00,  ...,  5.1059e+00,\n",
            "          2.8949e+00,  5.9477e-02],\n",
            "        [ 5.5892e+00,  2.9733e+00, -5.8446e-01,  ...,  6.9691e+00,\n",
            "          7.0177e+00,  2.1833e+00],\n",
            "        [ 8.6437e-02,  2.3912e+00,  2.6800e+00,  ...,  1.6607e+00,\n",
            "          3.6588e-01,  2.7372e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4536, 10.8857,  2.5182,  ...,  1.9852,  2.2700,  0.5772],\n",
            "        [-0.6886,  4.4753,  3.8617,  ...,  2.6276,  2.0311,  5.6621],\n",
            "        [-1.0487,  3.8936,  5.7053,  ..., -1.4561,  0.7800,  6.7634],\n",
            "        ...,\n",
            "        [ 1.8145,  4.2899,  4.6845,  ...,  1.5032,  4.2685,  1.5869],\n",
            "        [ 2.2731,  7.7506,  5.1974,  ...,  3.6956,  2.8742,  3.9010],\n",
            "        [ 3.5964,  7.9205,  0.5156,  ...,  1.4213,  6.1713,  2.6084]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0239,  2.9329,  0.4416,  ...,  1.1165,  0.4575,  2.6064],\n",
            "        [ 7.6997,  5.5924,  1.5555,  ...,  2.5800, -1.0244, -1.0981],\n",
            "        [ 4.3612,  3.6883,  2.3256,  ...,  1.6469,  0.8762,  3.1942],\n",
            "        ...,\n",
            "        [ 2.2601,  7.1946,  4.0766,  ...,  0.0982, -1.0768,  0.9413],\n",
            "        [ 4.7086,  6.8560,  3.2074,  ..., -0.4684,  4.9891,  5.3124],\n",
            "        [ 2.1286,  5.2377,  2.3767,  ...,  2.4941, -1.6457, -0.0642]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0693,  5.8217,  6.9880,  ..., -3.6528,  4.9250,  6.7337],\n",
            "        [ 4.4363,  6.5877,  4.5730,  ..., -1.7899,  2.3195,  0.2460],\n",
            "        [ 5.2125,  6.7256,  2.0468,  ...,  3.8458,  1.6945,  4.4176],\n",
            "        ...,\n",
            "        [ 5.3554,  4.7316, -0.6626,  ...,  3.5571,  2.3883,  0.9845],\n",
            "        [ 0.1912,  4.2818,  5.3064,  ..., -3.2819,  5.3910,  3.5613],\n",
            "        [ 1.1908,  3.7566,  4.2700,  ...,  3.5878,  3.0067,  1.5782]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0765,  1.6068,  5.6531,  ..., -0.2292,  1.1046,  2.8351],\n",
            "        [ 2.4578,  5.1129,  2.8860,  ...,  4.1134,  3.6944,  3.3639],\n",
            "        [ 1.8420,  4.2169,  3.0450,  ..., -1.2946, -0.7179,  3.7810],\n",
            "        ...,\n",
            "        [ 0.7302,  3.0797,  2.3492,  ...,  2.1954,  0.1200,  3.5410],\n",
            "        [ 1.4730,  2.4842,  4.2386,  ...,  2.8473,  0.3123,  2.5794],\n",
            "        [ 1.8566,  4.8336,  5.0332,  ...,  1.1063,  1.1646, -1.1336]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8395,  6.7908,  4.3313,  ...,  2.1511,  0.2815,  3.5537],\n",
            "        [ 0.3391,  5.6835,  4.5116,  ..., -3.1736,  5.3141,  4.2075],\n",
            "        [ 4.2484,  6.9345,  4.6940,  ...,  3.4250,  2.9429,  4.2221],\n",
            "        ...,\n",
            "        [ 3.4601,  4.0367,  4.9153,  ...,  2.1192,  4.0608,  1.0228],\n",
            "        [ 3.2450,  4.7249,  8.0432,  ..., -1.0747,  3.6392,  6.0180],\n",
            "        [ 2.2221,  7.2832,  4.7249,  ...,  0.0921,  0.9596,  4.3230]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2949,  5.8183,  4.0707,  ..., -0.6181,  5.4685,  5.6723],\n",
            "        [ 4.4720,  5.0165,  3.1006,  ...,  2.6908,  2.0331,  7.4521],\n",
            "        [ 2.6540,  1.8691,  2.2662,  ...,  2.0099,  3.5256,  1.4534],\n",
            "        ...,\n",
            "        [ 3.7267,  7.5098,  4.5683,  ..., -4.1565,  3.6656,  5.4889],\n",
            "        [ 2.4199,  3.8237,  1.8833,  ...,  3.3877,  2.1708,  1.3882],\n",
            "        [ 1.9113,  7.4639,  3.7457,  ...,  2.7552, -0.1360,  3.4147]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5629,  4.6296,  3.8377,  ...,  0.0758,  0.5908,  0.6995],\n",
            "        [ 2.1125,  3.2991,  6.4817,  ...,  0.5579,  0.3326,  0.1868],\n",
            "        [ 0.5179,  1.9940,  5.0365,  ...,  0.5532, -0.0386,  0.3820],\n",
            "        ...,\n",
            "        [ 5.6634,  5.0581, -1.8408,  ...,  1.9494,  3.0618,  2.0730],\n",
            "        [ 2.9291,  3.4043,  4.3299,  ...,  6.0246,  4.9661,  2.8570],\n",
            "        [ 0.9727,  4.5168,  7.6833,  ...,  0.5997,  3.3973,  6.5433]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7639,  5.1720,  3.6092,  ..., -1.4418,  5.0389,  1.4587],\n",
            "        [ 2.8012, 10.2164,  3.2566,  ...,  2.2915,  0.5485,  3.8318],\n",
            "        [ 4.9538,  3.7528,  0.3733,  ...,  1.3226,  2.1732,  2.1127],\n",
            "        ...,\n",
            "        [ 1.2976,  4.8019,  2.8961,  ...,  1.4990,  2.1952,  1.2250],\n",
            "        [ 2.5003,  3.8826,  4.3059,  ...,  0.2996,  2.1948,  3.4546],\n",
            "        [ 4.9987, 11.3327,  1.8702,  ...,  4.2599,  2.3680,  1.3012]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.7038,  8.8981,  4.0887,  ...,  1.6129,  9.2424,  5.3296],\n",
            "        [ 1.3157,  8.8498,  4.3839,  ...,  0.1673,  0.8010,  0.7534],\n",
            "        [ 0.4292,  7.7374,  5.5033,  ..., -1.6494, -1.9727,  5.8325],\n",
            "        ...,\n",
            "        [ 1.5361,  5.2188,  4.2560,  ...,  3.4093,  2.7998,  1.6608],\n",
            "        [ 2.1066,  7.0379,  7.7623,  ..., -0.7169,  1.0100,  2.1003],\n",
            "        [ 0.7129,  2.1377,  4.4638,  ..., -2.9328,  3.2459,  6.3830]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2272, 13.2988,  4.5796,  ...,  1.1224,  0.1903,  3.0139],\n",
            "        [ 4.2120,  8.1033,  3.6596,  ...,  2.7002,  8.8382,  4.0903],\n",
            "        [ 4.2299,  5.3489,  2.0850,  ...,  1.0884, -0.1314,  0.9654],\n",
            "        ...,\n",
            "        [ 1.3358,  3.3506,  3.7741,  ...,  1.5966,  2.8630,  2.5601],\n",
            "        [ 1.4503,  6.7513,  8.3143,  ..., -1.1436,  6.2224,  2.7138],\n",
            "        [ 2.3255,  7.6416,  1.4428,  ..., -0.5725,  1.5132,  6.2580]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1793,  6.3821,  3.9037,  ..., -0.2241, -0.4498,  0.5684],\n",
            "        [ 2.4803,  5.6170,  0.1711,  ...,  2.7171,  7.0154,  1.9916],\n",
            "        [ 3.7626,  7.8152,  1.0361,  ...,  5.4779,  3.1337,  1.2962],\n",
            "        ...,\n",
            "        [ 1.7026,  6.2872,  4.4181,  ...,  4.4466,  2.1196,  0.4290],\n",
            "        [ 2.9249,  5.2387,  0.7292,  ...,  5.2187,  4.4275,  6.1615],\n",
            "        [ 0.5872,  2.3641,  3.1017,  ...,  2.8855,  2.7724,  1.0401]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8018,  6.9430,  1.8690,  ...,  1.2848, -0.3741,  0.8321],\n",
            "        [ 1.8903,  9.1681,  3.6609,  ...,  3.0330,  5.0960,  3.6497],\n",
            "        [ 3.8792,  5.3388,  3.2902,  ...,  1.6899,  0.2790,  1.8121],\n",
            "        ...,\n",
            "        [ 0.1572,  5.2184,  4.8158,  ..., -1.5128, -0.4809,  3.5249],\n",
            "        [ 1.5641,  5.5996,  2.0215,  ...,  2.0985,  1.8631,  0.9653],\n",
            "        [ 2.6557,  3.5359,  2.2021,  ...,  2.6276, -0.5366,  0.9862]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.6208,  8.0770,  3.3107,  ..., -1.6544,  1.5651,  6.5881],\n",
            "        [ 3.2864,  5.5795,  5.3137,  ..., -0.4232,  0.0606, -0.5297],\n",
            "        [ 0.9601,  3.3369,  4.7958,  ...,  2.2962,  3.7761,  2.5626],\n",
            "        ...,\n",
            "        [ 3.7134,  4.4664,  1.6124,  ...,  2.4493,  2.5683,  2.3190],\n",
            "        [ 4.1444,  4.7542,  3.8207,  ...,  1.4530,  1.6705, -0.2152],\n",
            "        [ 3.8911,  3.3962,  0.4524,  ...,  2.9242,  2.5782,  0.6741]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7046,  5.0988,  3.4828,  ...,  2.2673,  0.0892,  2.3653],\n",
            "        [ 4.7254,  5.4564,  1.6707,  ...,  1.3411, -0.6751,  0.8798],\n",
            "        [ 2.3065,  6.9570,  3.4360,  ...,  3.8483,  5.5085,  0.4039],\n",
            "        ...,\n",
            "        [ 4.0240,  5.4436,  5.5640,  ...,  2.8158,  3.8283,  2.1000],\n",
            "        [ 7.0515,  6.6055,  0.8383,  ...,  1.3501,  1.7414,  6.8744],\n",
            "        [ 1.0166,  5.7963,  6.1518,  ..., -1.0642,  4.1698,  5.5352]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5412,  2.5278, -0.1819,  ...,  3.5495,  3.5142,  2.1616],\n",
            "        [ 2.8141,  2.2899,  1.1407,  ...,  1.6953,  0.7824,  2.0220],\n",
            "        [ 1.5973,  5.9880,  5.8921,  ...,  0.4086,  4.0900,  4.7961],\n",
            "        ...,\n",
            "        [ 0.0575,  5.5389,  5.9070,  ...,  0.2150,  2.0256,  3.8671],\n",
            "        [ 2.0497,  7.1704,  5.1716,  ...,  1.5693,  6.8659,  4.9293],\n",
            "        [ 5.6905,  3.5719,  3.8277,  ..., -1.2712, -0.7795,  2.3239]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4145,  4.1056,  4.6544,  ...,  4.0733,  2.2060,  1.7162],\n",
            "        [-0.4265,  7.4758,  8.1363,  ..., -5.9399,  5.8425,  8.0255],\n",
            "        [ 6.6773,  5.3609,  2.6025,  ...,  0.7654,  0.4485,  1.5915],\n",
            "        ...,\n",
            "        [ 4.8780,  5.9286,  2.4999,  ...,  1.7483,  0.4587,  3.0400],\n",
            "        [ 5.4172,  3.1286,  1.7866,  ...,  1.1915, -0.0732, -0.4071],\n",
            "        [ 4.4229,  4.9435, -0.7357,  ...,  2.0694,  1.1013,  2.3460]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4040,  2.0479,  4.4466,  ...,  1.0509,  0.5358,  1.1514],\n",
            "        [ 4.8986,  7.3044,  4.1541,  ...,  1.3202,  2.5324, -0.2152],\n",
            "        [-0.1537,  4.1247,  5.9563,  ..., -1.3915,  2.0434,  0.6319],\n",
            "        ...,\n",
            "        [ 3.3268,  6.7407,  0.2953,  ..., -1.0670,  0.8852,  4.5586],\n",
            "        [-0.2427,  2.5383,  5.1976,  ..., -0.2765,  1.0651,  2.6662],\n",
            "        [ 4.2414,  5.7253,  1.0189,  ...,  1.9972,  0.1449,  1.2612]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4637,  4.6249,  1.3441,  ...,  3.5559,  2.1833,  2.7004],\n",
            "        [ 3.3051,  5.0680,  5.7345,  ...,  2.6416,  3.2523,  3.3018],\n",
            "        [ 2.6636,  4.6817,  3.6192,  ...,  2.0397,  0.0401,  3.6715],\n",
            "        ...,\n",
            "        [ 1.6398,  4.6324,  4.4278,  ...,  1.1495, -0.1116,  4.7118],\n",
            "        [ 3.8258,  3.4424,  0.5561,  ...,  2.8931, -0.0426, -0.3713],\n",
            "        [ 1.8377,  6.2098,  2.8150,  ...,  1.4875,  3.0641,  2.0336]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.0519,  9.8432, -0.4620,  ...,  0.0285,  8.7429,  6.8435],\n",
            "        [ 3.1265,  6.4634,  3.3176,  ...,  2.6202,  1.4729,  1.5727],\n",
            "        [ 2.5144,  5.5792,  2.1854,  ..., -1.7338,  2.1469,  4.3036],\n",
            "        ...,\n",
            "        [ 3.4710,  3.2094,  3.5202,  ...,  2.0105,  2.9033,  7.4665],\n",
            "        [ 2.0702,  4.4070,  5.0648,  ..., -1.2762,  2.7428,  3.3804],\n",
            "        [ 4.7421,  6.1486,  1.4807,  ...,  0.1307, -0.8780,  1.2607]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2110,  4.8656,  4.2109,  ...,  0.2669, -0.4741,  2.8693],\n",
            "        [ 4.5824,  3.2267, -0.0885,  ...,  2.1816,  4.1006,  2.0614],\n",
            "        [ 1.3733,  1.6038,  7.0038,  ...,  0.3297,  4.5337,  5.3834],\n",
            "        ...,\n",
            "        [ 3.9116,  4.4137,  1.7589,  ...,  3.4779,  2.3802,  0.7200],\n",
            "        [ 3.6821,  5.5433,  4.6944,  ...,  0.9721,  4.6263,  1.5216],\n",
            "        [-1.6046,  6.0993,  3.7725,  ...,  0.9156, -0.6444,  3.2721]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4314e+00,  5.1059e+00,  3.0978e+00,  ...,  1.9857e+00,\n",
            "          2.5944e+00,  3.3727e+00],\n",
            "        [ 2.1006e+00,  6.3206e+00,  9.8229e-01,  ...,  2.2939e+00,\n",
            "          5.0233e+00,  7.2545e+00],\n",
            "        [ 2.7723e+00,  3.3910e+00,  4.4508e+00,  ...,  9.0574e-03,\n",
            "         -1.4512e+00,  1.3906e+00],\n",
            "        ...,\n",
            "        [ 5.4025e+00,  8.9724e+00,  1.3110e+00,  ..., -1.3986e+00,\n",
            "          7.3915e-01,  9.3477e+00],\n",
            "        [ 1.4155e+00,  4.3672e+00,  4.4950e+00,  ...,  3.5443e+00,\n",
            "          2.1511e+00,  2.0149e+00],\n",
            "        [ 6.1391e-01,  5.5536e+00,  4.1865e+00,  ...,  1.3316e+00,\n",
            "          3.1283e+00,  3.8811e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3249,  3.1385,  3.0386,  ...,  2.2094,  0.1158,  2.3281],\n",
            "        [-0.5000,  9.0662,  2.0126,  ..., -4.0868, -3.7840,  5.6643],\n",
            "        [ 1.6719,  4.4046,  2.1988,  ...,  1.0569,  1.5984,  3.0618],\n",
            "        ...,\n",
            "        [ 4.1929,  3.5581,  2.1960,  ...,  0.4359,  0.6429,  1.6761],\n",
            "        [ 1.4356,  3.8266,  3.7715,  ...,  0.6672,  2.2015,  2.2580],\n",
            "        [ 2.0418,  3.0539,  5.0834,  ...,  1.3610,  4.4312,  1.5996]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0336,  7.6226,  3.7801,  ...,  0.8577,  3.9749,  3.6007],\n",
            "        [ 2.4320,  3.7352,  0.2148,  ...,  1.5672,  5.3303,  2.8881],\n",
            "        [ 4.4727,  8.7446,  5.2590,  ...,  1.5683,  1.4041,  4.8626],\n",
            "        ...,\n",
            "        [ 1.2735,  4.6095,  3.9747,  ...,  2.8838,  2.7288,  2.3234],\n",
            "        [ 6.1707, 10.9320,  2.7910,  ...,  1.7339,  7.6779,  4.9961],\n",
            "        [ 0.9060,  2.0541,  5.2210,  ..., -0.6598,  3.6394,  4.9458]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3531,  9.2009,  4.7782,  ..., -0.7888,  7.8381,  6.6343],\n",
            "        [ 4.7283,  3.3709,  0.1091,  ...,  1.2709,  2.4945,  2.7528],\n",
            "        [ 3.8699,  8.7588,  3.6245,  ..., -2.4241,  2.2670,  9.6058],\n",
            "        ...,\n",
            "        [ 1.8663,  7.3548,  4.0577,  ...,  1.0056, -1.2656,  4.0448],\n",
            "        [ 2.9809,  7.9638,  3.2577,  ...,  1.4012,  3.6248,  2.3435],\n",
            "        [ 4.2964,  9.0582,  0.6323,  ...,  1.9371,  5.6372,  4.1016]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4509,  2.3458,  6.3130,  ..., -1.6025,  3.6364,  6.6895],\n",
            "        [ 3.2076,  8.4457,  2.5385,  ...,  2.7752,  3.6138,  5.9446],\n",
            "        [ 3.3539,  1.9491,  2.2719,  ...,  2.9632,  0.1923,  1.0340],\n",
            "        ...,\n",
            "        [ 0.1301,  7.0515,  7.2041,  ..., -0.2816,  5.6369,  4.7569],\n",
            "        [-0.8813,  7.9202,  5.8210,  ..., -1.0270,  3.6874,  5.1151],\n",
            "        [ 1.2437,  4.0486,  5.5468,  ...,  1.7473,  2.9007,  4.0323]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8936e+00,  5.0696e+00,  2.9484e+00,  ...,  3.4357e+00,\n",
            "          1.3601e+00,  4.3537e+00],\n",
            "        [ 1.7769e+00,  6.8067e+00,  2.4452e+00,  ...,  2.5213e+00,\n",
            "          2.7944e+00,  5.8253e+00],\n",
            "        [ 4.1820e+00,  2.7345e+00,  3.9458e+00,  ...,  1.7137e+00,\n",
            "          3.0215e-03,  1.2479e-01],\n",
            "        ...,\n",
            "        [-5.6950e-01,  6.9157e+00,  6.0839e+00,  ..., -5.7050e-01,\n",
            "          3.2236e+00,  5.3035e+00],\n",
            "        [ 2.2048e+00,  3.8383e+00,  3.7275e+00,  ...,  2.2295e+00,\n",
            "          2.8335e+00,  4.4860e+00],\n",
            "        [-6.1138e-01,  7.4461e+00,  5.9898e+00,  ..., -2.0086e+00,\n",
            "          3.4606e+00,  4.6726e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6247,  4.7567,  5.3317,  ..., -1.1904,  2.4293,  0.0784],\n",
            "        [ 0.7926,  4.6683,  2.4172,  ...,  2.5603,  3.4055,  2.0074],\n",
            "        [ 0.7553,  4.4916,  4.5175,  ..., -0.0387,  0.3913,  3.7479],\n",
            "        ...,\n",
            "        [ 5.0669,  3.5833,  1.5953,  ...,  2.5535, -0.3595,  3.0189],\n",
            "        [ 1.8642,  3.1801,  4.8355,  ...,  2.0928,  4.4882,  1.6356],\n",
            "        [ 0.8492,  3.2211,  2.7378,  ...,  1.8797,  1.1331,  3.0092]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.9549,  2.6184,  1.8210,  ...,  0.8111,  2.2474,  1.7912],\n",
            "        [ 2.3800,  7.5355,  2.5335,  ...,  2.0191,  1.1961,  1.5950],\n",
            "        [ 1.8275,  1.3988,  6.5120,  ..., -1.5147,  4.0786,  7.4925],\n",
            "        ...,\n",
            "        [ 0.7467,  3.7364,  3.2892,  ...,  1.9060,  1.5396,  2.6108],\n",
            "        [ 2.8821,  3.1681,  4.4232,  ...,  1.3765,  3.9446,  2.1416],\n",
            "        [ 3.4868,  7.2476,  5.4294,  ...,  0.1499,  2.7324,  2.2918]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7973,  4.3519,  4.8556,  ...,  2.6899,  3.5521,  1.2157],\n",
            "        [ 5.1026,  8.2162,  6.5073,  ..., -2.0175, -0.0595,  1.1746],\n",
            "        [ 3.5226,  5.8704,  6.4542,  ..., -1.4698, -0.7725,  0.7961],\n",
            "        ...,\n",
            "        [ 0.8703,  5.6843,  8.7290,  ...,  1.7896,  4.2173,  3.5153],\n",
            "        [ 1.6969,  4.0865,  2.3338,  ...,  0.7238, -0.8771,  4.4448],\n",
            "        [ 5.2660, 11.9876,  3.1106,  ...,  2.5467, 10.4451,  6.4562]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4674,  4.3348,  4.1709,  ...,  0.4183,  3.9197,  4.1012],\n",
            "        [ 4.4413,  6.0430,  1.3828,  ...,  5.0090,  4.8481,  4.1794],\n",
            "        [ 4.3984,  7.9111, -0.1972,  ...,  2.6512,  5.1332,  4.2451],\n",
            "        ...,\n",
            "        [-3.2102,  6.4446,  6.4152,  ..., -3.7341, -3.4389,  6.9911],\n",
            "        [ 2.7709,  4.6425,  2.9830,  ...,  0.7200,  3.0236,  4.1244],\n",
            "        [ 3.4741,  6.9938,  0.9743,  ...,  4.1802,  1.3665,  1.5011]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6291,  3.8725,  5.4768,  ..., -0.7298,  3.4566,  7.6327],\n",
            "        [ 4.8971, 10.0534,  2.1100,  ...,  0.2968,  6.4887,  3.7675],\n",
            "        [ 3.9826,  5.1222,  2.5463,  ...,  1.4383,  0.4108,  1.0292],\n",
            "        ...,\n",
            "        [ 3.6971,  3.8887, -0.2092,  ...,  2.0332,  0.6456,  1.2893],\n",
            "        [-0.7815,  3.5301,  1.7151,  ...,  0.3035,  7.5285,  4.3532],\n",
            "        [ 4.0751,  3.7100, -0.8993,  ...,  4.3825,  0.9898,  0.3408]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2914,  2.9047,  3.8347,  ...,  1.2185,  2.8347,  2.8806],\n",
            "        [ 3.3884,  5.2228,  3.8954,  ...,  2.7593, -1.0848, -0.6976],\n",
            "        [ 0.8765,  3.0080,  4.3736,  ...,  2.9845,  2.6424,  2.5187],\n",
            "        ...,\n",
            "        [ 4.5402,  9.3794,  4.7412,  ..., -0.0319,  2.7399,  1.5320],\n",
            "        [ 1.0562,  4.3599,  5.6814,  ..., -0.8068, -0.3898,  6.5613],\n",
            "        [ 4.4383,  7.7929,  4.8540,  ...,  0.1008,  3.2826,  0.4314]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8573,  4.1628,  4.4361,  ...,  3.5569,  2.6135,  2.9434],\n",
            "        [ 1.1848,  4.4598,  2.1944,  ..., -1.2803,  3.2949,  1.5217],\n",
            "        [ 3.9907,  9.8400,  2.7235,  ...,  1.2277,  7.5839,  7.9409],\n",
            "        ...,\n",
            "        [ 2.6796,  7.0484, -1.7374,  ..., -1.6396,  4.0933,  5.7308],\n",
            "        [ 1.3731,  3.8493,  7.8545,  ..., -2.9169,  3.9453,  7.2520],\n",
            "        [ 4.4540,  4.1844,  1.6800,  ...,  2.7067,  2.7821,  1.4128]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3216,  5.3987,  4.6634,  ...,  3.2017,  1.5694,  2.1395],\n",
            "        [ 1.2608,  2.7230,  1.5996,  ...,  2.5192,  2.4494,  1.0304],\n",
            "        [ 4.9297,  4.5280,  4.6529,  ...,  0.3068,  2.2619,  1.7115],\n",
            "        ...,\n",
            "        [ 4.2012,  5.4355,  2.0955,  ..., -1.3301,  0.7271,  4.8262],\n",
            "        [ 0.0957,  9.3891,  3.0405,  ..., -1.2717, -4.4709,  7.0561],\n",
            "        [ 2.3639,  6.7671,  7.6818,  ...,  0.1075,  3.3729,  0.4139]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.0462,  7.8769,  3.1763,  ..., -0.8246,  1.0613,  2.9257],\n",
            "        [ 3.7952,  6.3551,  2.2458,  ...,  2.1620,  7.8514,  5.3706],\n",
            "        [ 3.0949,  5.6088,  8.2087,  ..., -3.0636,  0.4764,  3.0800],\n",
            "        ...,\n",
            "        [ 2.2439,  5.0223,  6.1107,  ..., -2.3447,  0.7884,  5.7982],\n",
            "        [ 0.5338,  3.9497,  4.5938,  ...,  1.7458,  2.3067,  2.9001],\n",
            "        [ 3.5397,  5.0176,  2.5585,  ...,  1.1142,  1.7906,  1.4860]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9222,  7.4507,  5.3277,  ..., -0.1358, -0.2602,  2.6144],\n",
            "        [ 2.2576,  5.0332,  4.0034,  ...,  3.7175,  2.5322,  1.5824],\n",
            "        [ 3.7711,  4.9125,  4.8497,  ...,  3.8591,  2.0801,  1.4452],\n",
            "        ...,\n",
            "        [ 3.4998,  2.0119,  2.5885,  ...,  2.4478,  2.6358,  2.1181],\n",
            "        [ 3.9060,  6.9151,  5.4694,  ..., -4.5449,  6.3460,  3.7419],\n",
            "        [ 2.8729,  5.6155,  6.6993,  ...,  0.5683,  3.7056,  5.4618]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8033,  6.9500,  1.3842,  ...,  2.7213,  2.1533,  2.7954],\n",
            "        [ 3.6239,  8.2209,  1.7155,  ...,  2.1821,  7.3236,  2.7481],\n",
            "        [ 4.2429,  2.3299, -0.3900,  ...,  2.8632, -1.2525,  2.6374],\n",
            "        ...,\n",
            "        [ 4.6440,  3.3192,  0.5329,  ...,  1.2308,  0.7420,  0.2713],\n",
            "        [ 1.9290,  7.1320,  6.0768,  ..., -1.7822,  6.8954,  7.9764],\n",
            "        [ 0.3333,  3.5668,  4.1767,  ...,  2.2287,  1.0837,  1.6078]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4237,  8.5921,  2.9136,  ...,  1.1164,  6.4361,  5.4330],\n",
            "        [ 3.4029,  4.6988,  4.8008,  ...,  2.4912,  5.9901,  2.1296],\n",
            "        [ 5.8051,  5.7181,  1.5869,  ...,  2.0187,  1.0252,  2.3852],\n",
            "        ...,\n",
            "        [ 0.4620,  3.5994,  6.6486,  ..., -0.7774,  2.7052,  5.1666],\n",
            "        [ 4.5296, 10.3095, -0.6679,  ...,  3.6516, -0.1549,  4.4248],\n",
            "        [ 4.7499,  3.1335, -0.0305,  ...,  3.2807, -0.3830,  4.3230]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1997,  9.6343,  6.5893,  ..., -2.2139,  1.5649,  8.0536],\n",
            "        [ 3.6273,  6.0456,  3.1751,  ...,  1.6417,  2.0540,  0.5384],\n",
            "        [ 3.8099,  5.9908, -1.1406,  ...,  0.1333,  6.3665,  4.4716],\n",
            "        ...,\n",
            "        [ 1.8073,  4.5824,  3.4909,  ..., -0.0615,  0.9161,  2.3159],\n",
            "        [ 2.1184,  7.4439,  4.4945,  ...,  0.7280,  0.2213,  1.1999],\n",
            "        [ 0.3194,  4.5919,  5.9149,  ...,  2.5218,  1.4990,  2.5775]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1523,  9.6176,  3.3875,  ...,  1.3699,  5.4959,  4.9558],\n",
            "        [ 4.2565,  6.9993,  1.4580,  ...,  3.7364,  1.8271, -1.5284],\n",
            "        [ 4.9756,  6.8868,  0.7738,  ...,  2.1555,  6.6157,  4.3189],\n",
            "        ...,\n",
            "        [ 1.3831,  5.7782,  4.9758,  ..., -0.2708,  1.3727,  6.9291],\n",
            "        [ 0.2007,  5.5079,  4.9881,  ..., -0.6267,  2.3568,  7.2429],\n",
            "        [ 3.8014,  7.4469,  3.3823,  ..., -0.5002,  6.3824,  3.9938]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6885, 12.7205,  5.5390,  ...,  0.3280,  0.7518,  2.4814],\n",
            "        [ 0.4211,  4.9355,  5.6014,  ..., -1.5940, -1.6045,  5.6665],\n",
            "        [ 2.4007,  6.1743,  1.5666,  ...,  3.4428,  0.7714,  4.1782],\n",
            "        ...,\n",
            "        [ 2.0839,  6.3178,  2.1196,  ..., -1.7591,  0.3204,  9.6577],\n",
            "        [ 4.2404, 10.0463, -0.2734,  ..., -2.8131,  3.4468,  7.1541],\n",
            "        [ 4.6735,  5.5991,  0.9575,  ...,  4.3327,  0.5437,  0.6433]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1089,  3.5134,  4.2981,  ...,  2.5158,  3.1093,  1.8035],\n",
            "        [ 1.9144,  5.7889,  5.3860,  ..., -0.2178,  1.6274, -0.7600],\n",
            "        [ 4.8258,  5.6014,  1.9926,  ...,  2.4113, -0.2124,  1.8431],\n",
            "        ...,\n",
            "        [ 2.7175,  6.7184,  7.4181,  ..., -1.3801, -1.6048, -2.9123],\n",
            "        [ 5.8076, 10.4096,  3.7600,  ...,  2.1526,  0.1535,  1.0438],\n",
            "        [ 2.5539,  1.7812,  4.5177,  ..., -0.4172,  2.0078,  0.0515]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0213,  4.3002,  1.6447,  ...,  0.3033,  2.4377,  5.7760],\n",
            "        [-0.1794,  3.9654,  6.3414,  ..., -0.7822,  1.2244,  7.2337],\n",
            "        [ 3.3485,  6.4289,  7.5310,  ...,  0.5784,  1.5239,  5.2439],\n",
            "        ...,\n",
            "        [ 6.5020,  6.1150,  2.3805,  ...,  2.2675,  1.7005,  7.9689],\n",
            "        [ 3.4467,  5.2464, -0.9316,  ...,  5.0826,  1.8800,  1.8340],\n",
            "        [ 1.7912,  5.8164,  4.0118,  ..., -1.0966, -1.6501, -0.7049]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.9318,  3.6461, -0.9616,  ...,  2.6890,  3.9958,  1.9578],\n",
            "        [-0.9890,  3.1216,  4.4427,  ...,  1.8588,  2.0774,  5.7157],\n",
            "        [ 5.3867,  6.5273,  2.0551,  ...,  3.2964,  5.1080,  3.7805],\n",
            "        ...,\n",
            "        [ 1.6297,  2.7765,  5.5175,  ..., -1.0664,  3.6123,  9.0425],\n",
            "        [-0.2468,  3.2077,  2.9705,  ...,  3.3885, -0.2778,  3.2908],\n",
            "        [ 1.9064,  3.6214,  7.1764,  ..., -0.4987,  3.4156,  6.9197]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0436,  5.2604,  5.5615,  ...,  4.0009,  2.0011,  1.8065],\n",
            "        [-0.6032,  3.8033,  6.1677,  ...,  2.7176,  0.4260,  2.0080],\n",
            "        [ 3.4685,  4.7582, -2.0284,  ...,  4.0201,  1.7709, -1.7996],\n",
            "        ...,\n",
            "        [-0.1261,  5.7679,  4.1683,  ...,  1.7229,  5.3750,  4.7710],\n",
            "        [ 3.1108,  4.3293,  2.6060,  ...,  1.7682,  5.5121,  5.1928],\n",
            "        [ 0.9200,  3.1536,  4.3792,  ...,  2.7359,  3.1942,  2.0502]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1296, 10.2086,  3.0588,  ..., -0.1202,  9.8126,  7.9656],\n",
            "        [ 1.2805,  4.5574,  3.8605,  ..., -3.7755,  3.4401,  6.7466],\n",
            "        [ 1.6888,  0.7109,  5.2179,  ..., -1.2769,  3.0458,  7.8726],\n",
            "        ...,\n",
            "        [ 0.9282,  4.5466,  3.8929,  ...,  4.1182,  2.3586,  1.6781],\n",
            "        [-0.1341,  3.4769,  4.0939,  ...,  2.3041,  0.2629,  4.9847],\n",
            "        [ 1.7551,  4.1874,  5.4398,  ...,  1.5286,  3.7717,  1.6982]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7844,  6.4668,  1.3248,  ..., -0.0853, -1.2574,  4.7180],\n",
            "        [ 3.8965,  4.8680,  3.8238,  ...,  1.9718, -0.2326,  2.3585],\n",
            "        [ 3.2663,  9.1858,  3.5100,  ..., -2.1456,  0.4801,  8.7424],\n",
            "        ...,\n",
            "        [ 0.7296,  5.7607,  1.8430,  ..., -0.3658, -1.3237,  1.0257],\n",
            "        [ 2.3833,  6.0211,  5.5005,  ...,  1.5310,  2.2335,  4.4150],\n",
            "        [ 1.0034,  3.6819,  5.0708,  ..., -0.4884,  3.5138, 10.3541]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[2.3214, 5.9792, 5.3240,  ..., 1.3882, 1.9046, 3.4776],\n",
            "        [0.5505, 2.7888, 5.7824,  ..., 1.7742, 1.9777, 1.0549],\n",
            "        [1.2464, 3.1109, 3.9031,  ..., 3.8950, 2.6483, 4.1199],\n",
            "        ...,\n",
            "        [3.1667, 3.4471, 1.0987,  ..., 1.4740, 0.4087, 2.9957],\n",
            "        [1.9985, 3.2669, 3.0669,  ..., 0.9779, 6.6058, 5.7644],\n",
            "        [6.7765, 4.2260, 1.1124,  ..., 0.8096, 3.3817, 2.7823]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3523e+00,  3.9681e+00,  2.2440e+00,  ..., -5.0321e-01,\n",
            "         -3.2516e-02,  1.1371e+00],\n",
            "        [-2.3393e-01,  6.3071e+00,  4.2012e+00,  ..., -4.2029e+00,\n",
            "          5.0738e+00,  6.6203e+00],\n",
            "        [ 6.6422e-01,  3.0926e+00,  3.4637e+00,  ..., -9.6859e-02,\n",
            "          3.2443e+00,  6.4769e+00],\n",
            "        ...,\n",
            "        [ 1.7544e+00,  4.4696e+00,  2.1085e+00,  ...,  1.9603e+00,\n",
            "         -8.8795e-03,  8.0323e+00],\n",
            "        [ 9.4871e-01,  9.1414e+00,  7.5000e+00,  ..., -1.7612e-01,\n",
            "         -3.7551e-01,  1.5201e-01],\n",
            "        [ 5.2662e+00,  8.5768e+00,  9.0840e-01,  ...,  6.0159e+00,\n",
            "          1.8648e+00,  2.3593e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3256,  8.2663,  1.1461,  ...,  0.0363, -2.9240,  7.6933],\n",
            "        [ 1.7790,  3.9660,  3.4779,  ..., -0.3447,  1.4947, -0.0312],\n",
            "        [ 4.8167,  7.7289,  2.4710,  ...,  3.2520,  3.8312,  2.4199],\n",
            "        ...,\n",
            "        [ 1.6614,  4.1036,  4.0935,  ...,  4.0522,  2.4974,  1.4557],\n",
            "        [ 6.0973,  8.5746,  3.2927,  ...,  0.7619,  3.0962,  2.1438],\n",
            "        [ 2.2037,  5.7048,  3.2658,  ...,  4.4205,  2.3555,  3.1601]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5567,  4.5301,  0.4098,  ...,  0.8800,  2.1336,  0.4568],\n",
            "        [ 0.8236,  2.0545,  3.9693,  ..., -0.6271, -0.0767,  1.0813],\n",
            "        [ 3.3002,  6.7966,  5.1511,  ...,  1.0150,  1.0160,  5.0464],\n",
            "        ...,\n",
            "        [ 4.0847,  3.5221, -0.1719,  ...,  5.3418,  3.4465,  0.7995],\n",
            "        [ 2.3024,  2.6373,  3.6098,  ..., -0.6487, -1.6846,  2.9199],\n",
            "        [ 1.9056,  4.0895,  2.6619,  ...,  0.0131, -3.6008,  1.5069]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0466,  6.5054,  3.7897,  ...,  1.6896,  2.3635,  1.5282],\n",
            "        [ 0.4600,  4.8061,  2.9512,  ...,  1.2576,  5.7674,  5.8616],\n",
            "        [ 0.6695,  3.3983,  3.6780,  ...,  0.8162,  1.2969,  2.7341],\n",
            "        ...,\n",
            "        [ 2.6846,  5.8484,  1.1112,  ..., -0.1841,  1.4979,  3.4328],\n",
            "        [ 2.6758,  6.9273,  1.9412,  ...,  1.4862,  5.7910,  4.7945],\n",
            "        [ 4.2152,  4.8650,  0.4636,  ...,  0.3737,  2.8440,  3.1471]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3173,  5.1392,  4.5826,  ...,  0.8786,  1.1024,  0.0771],\n",
            "        [ 1.9657,  6.5956,  2.7145,  ...,  4.2839,  1.8299,  5.6402],\n",
            "        [-0.0569,  2.7550,  5.6950,  ..., -0.5772,  1.3528,  0.6569],\n",
            "        ...,\n",
            "        [ 1.3463,  2.6288,  1.9263,  ...,  3.5401,  0.8821, -0.0729],\n",
            "        [ 2.6838,  3.7531,  3.7329,  ...,  0.5850,  1.5495,  2.9120],\n",
            "        [ 1.8617,  3.4007,  6.4046,  ..., -1.0726,  5.0962,  7.1411]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2214e+00,  2.3664e+00,  2.9853e+00,  ...,  1.0723e+00,\n",
            "          7.7637e-01, -6.1086e-01],\n",
            "        [ 4.4181e+00,  3.5059e+00,  1.9662e+00,  ...,  3.1326e+00,\n",
            "         -3.5118e-01, -1.4025e+00],\n",
            "        [ 2.0820e+00,  6.4622e+00,  3.3209e+00,  ...,  2.9942e+00,\n",
            "          2.4450e+00,  1.7933e+00],\n",
            "        ...,\n",
            "        [ 9.3104e-01,  5.6736e+00,  5.2537e+00,  ...,  9.5880e-01,\n",
            "         -4.0755e-03,  3.7047e+00],\n",
            "        [ 4.0506e+00,  6.2484e+00,  2.1666e+00,  ...,  1.3259e+00,\n",
            "         -1.0849e+00, -1.9598e+00],\n",
            "        [ 1.6858e+00,  3.7093e+00,  3.5956e+00,  ...,  2.7541e-01,\n",
            "          4.5793e+00,  5.2054e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2993,  5.8289,  6.1933,  ..., -1.4345,  1.7022,  7.6761],\n",
            "        [ 2.3822,  7.3275,  3.1505,  ...,  3.8008,  2.6181,  3.6934],\n",
            "        [ 6.5365, 11.2420,  3.9749,  ..., -0.3926,  2.5623,  1.9865],\n",
            "        ...,\n",
            "        [-0.5726,  6.4699,  1.2185,  ...,  2.3404, -1.1697,  8.1732],\n",
            "        [ 3.0781,  2.9256, -0.3133,  ...,  2.4621,  3.1794,  2.6932],\n",
            "        [ 0.3522,  1.9962,  2.7572,  ...,  2.9363,  2.3538,  1.7174]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1221,  6.8044,  1.4868,  ...,  4.8819,  2.8651,  2.2313],\n",
            "        [ 5.1521,  3.6407,  3.1439,  ...,  1.2352,  3.3303,  1.5371],\n",
            "        [ 2.0841,  5.4700,  1.0582,  ...,  3.9827,  2.8080,  4.6245],\n",
            "        ...,\n",
            "        [ 4.6195,  4.1373,  1.8958,  ...,  2.4174, -0.1761,  0.5450],\n",
            "        [ 1.0341,  3.4761,  3.9005,  ...,  2.2578,  3.1198,  1.7279],\n",
            "        [ 1.8567,  7.1650,  0.0668,  ...,  3.4287,  0.8560,  3.7730]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4902,  7.5055,  5.2897,  ...,  0.3493,  0.7454,  5.0711],\n",
            "        [ 3.5679,  7.8275,  1.9540,  ...,  3.4144,  3.4529,  1.7361],\n",
            "        [ 6.7194,  4.6214, -0.7667,  ...,  1.7563,  0.4998,  2.1287],\n",
            "        ...,\n",
            "        [ 1.7278,  4.1435,  5.2010,  ..., -0.6721,  2.0384,  5.8503],\n",
            "        [ 2.8716,  8.5046,  5.3897,  ...,  1.8000,  1.7112,  3.5575],\n",
            "        [ 4.5894,  5.3103, -0.4595,  ...,  3.0277,  0.6736,  1.8193]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9121,  5.3899,  4.2050,  ...,  1.8290,  0.2743,  4.4514],\n",
            "        [ 4.6344,  6.6254,  4.1869,  ...,  2.7561,  5.4710,  2.5399],\n",
            "        [ 3.9482, 10.1862, -1.3963,  ...,  0.7874,  2.5282,  6.7638],\n",
            "        ...,\n",
            "        [ 2.8287,  7.2792,  3.7236,  ...,  1.6635,  1.7655,  1.7259],\n",
            "        [ 2.3873,  4.1720,  1.8373,  ...,  2.0852,  2.9753,  1.1666],\n",
            "        [ 2.2102,  7.8521,  2.4490,  ...,  2.5754, 10.3372,  7.1821]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1497,  6.9455,  5.8561,  ..., -2.9124,  6.3446,  2.4888],\n",
            "        [ 1.2564,  2.9675,  5.4763,  ...,  1.4934,  2.6238,  2.6099],\n",
            "        [ 3.9148,  6.8181,  2.8166,  ..., -0.3474, -0.8586,  2.4306],\n",
            "        ...,\n",
            "        [ 3.3195,  8.1976,  2.4193,  ..., -0.5834,  1.8431,  6.6538],\n",
            "        [ 3.0929,  2.3292,  1.7427,  ...,  0.7817,  1.5804,  1.6124],\n",
            "        [ 5.1977,  6.5194,  2.8650,  ...,  6.2881,  2.9293,  4.3326]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6401,  4.2517,  2.8589,  ...,  0.0315,  6.9570,  5.7346],\n",
            "        [ 1.3975,  5.0117,  2.8458,  ...,  2.7548, -0.3411,  4.0396],\n",
            "        [ 1.1302,  5.4134,  4.7701,  ...,  3.9771,  1.9782,  2.5278],\n",
            "        ...,\n",
            "        [-1.0950,  5.9815,  3.4307,  ..., -0.9103, -0.5523,  4.0272],\n",
            "        [ 4.8908,  6.5578,  2.0994,  ...,  0.4091,  0.2478,  1.0600],\n",
            "        [-1.2951,  5.8750,  1.5263,  ..., -1.5206, -1.6676,  8.9392]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3190,  8.4989,  1.4282,  ..., -1.3782,  0.0546,  8.4918],\n",
            "        [ 2.3194,  4.2745,  4.0662,  ...,  0.6705,  2.9318,  2.6975],\n",
            "        [ 3.5609,  2.9718,  1.8190,  ...,  3.4170,  0.6253,  1.6550],\n",
            "        ...,\n",
            "        [ 1.9996,  6.5757,  2.5085,  ...,  1.5599,  1.8753,  4.1099],\n",
            "        [ 2.1445,  7.3700,  5.9489,  ...,  0.9613,  2.7594,  4.0872],\n",
            "        [-0.8347,  2.9272,  4.1288,  ..., -1.2443, -0.2477,  4.0831]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6556,  3.0373,  3.4608,  ...,  2.0058,  2.0953,  1.1694],\n",
            "        [ 0.1280,  3.6937,  4.8212,  ...,  2.6853,  2.0483,  2.9390],\n",
            "        [ 1.5864,  4.3883,  2.2515,  ...,  1.7943, -0.4517,  2.6204],\n",
            "        ...,\n",
            "        [ 6.1184, 12.2209,  4.6832,  ..., -1.1111,  2.2800,  2.4520],\n",
            "        [ 1.5385,  6.9727,  3.5869,  ..., -0.6325,  2.7578,  4.7539],\n",
            "        [ 1.3346,  2.5597,  3.1712,  ...,  1.0503,  0.0237,  3.7746]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3605,  5.4154,  5.2622,  ..., -0.9436,  1.8065,  1.7581],\n",
            "        [ 0.6614,  5.8185,  3.1848,  ...,  0.9483,  0.3940,  0.0561],\n",
            "        [ 2.0573,  7.8406,  7.7373,  ..., -1.0685,  4.3806,  5.6818],\n",
            "        ...,\n",
            "        [ 2.7263,  3.8983,  3.3979,  ..., -0.3139,  0.2436,  0.2978],\n",
            "        [ 5.8460, 10.3860,  5.3455,  ..., -0.5535, -0.5189,  0.7689],\n",
            "        [ 2.2599,  2.9567,  2.8084,  ...,  0.8917,  1.5442,  4.9213]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5662,  7.9160,  4.0465,  ...,  1.4124,  4.2869,  0.6369],\n",
            "        [ 4.2812,  8.4446,  3.4733,  ...,  0.9341, -2.8683,  5.3193],\n",
            "        [ 2.9970,  6.2521,  3.8764,  ...,  3.6054,  1.2488,  3.0494],\n",
            "        ...,\n",
            "        [ 1.6418,  6.1806,  3.5047,  ...,  1.8181,  1.4359,  2.5755],\n",
            "        [ 0.3395,  3.5241,  4.8032,  ...,  2.8455,  1.1900,  3.4608],\n",
            "        [ 5.3791,  4.9853,  0.1730,  ...,  3.7146,  1.9134,  5.6532]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.7090,  5.0395,  1.0130,  ...,  2.8222,  1.6175,  1.3329],\n",
            "        [-0.3855,  3.8343,  7.0350,  ...,  0.8858, -0.9906,  2.6254],\n",
            "        [ 2.8252,  5.2402,  5.6061,  ..., -1.1735,  3.6029,  5.2010],\n",
            "        ...,\n",
            "        [ 1.5926,  3.6543,  3.5817,  ...,  3.1383,  2.6032,  1.4964],\n",
            "        [ 1.2204,  2.8643,  4.5036,  ...,  3.1451, -0.5017,  1.3975],\n",
            "        [ 3.8118,  6.0282,  3.4227,  ...,  3.0870,  4.2815,  3.8371]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.3291,  4.0963,  1.0403,  ...,  0.8102,  2.8186,  3.4364],\n",
            "        [ 0.4615,  4.7072,  5.5255,  ...,  2.5105,  2.3850,  2.5021],\n",
            "        [ 4.4877,  8.8444,  2.0110,  ..., -1.4504,  7.2114,  4.2726],\n",
            "        ...,\n",
            "        [ 0.9554,  5.5518,  6.6566,  ...,  1.8483,  1.8987,  1.7486],\n",
            "        [ 3.9049, 11.7647,  1.5057,  ..., -4.4109,  3.7287,  9.9771],\n",
            "        [ 0.7546,  4.8421,  4.3076,  ...,  0.0497,  1.4217, -0.7170]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.3824,  6.2149,  4.4164,  ...,  1.1602,  0.0827,  2.5710],\n",
            "        [ 0.9395,  6.3153,  6.7189,  ..., -1.2867,  0.8345,  5.8675],\n",
            "        [ 2.8855,  7.2795,  3.0603,  ...,  3.3260,  3.5192,  3.5870],\n",
            "        ...,\n",
            "        [ 2.1770,  3.5846, -0.2852,  ..., -0.2696,  2.2689,  4.8218],\n",
            "        [ 2.9080,  3.2383,  3.6305,  ...,  2.4443,  4.2252,  1.3419],\n",
            "        [ 0.7659,  3.5836,  4.2637,  ...,  3.4066,  1.5399,  3.5999]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.1969, 11.4482,  0.4021,  ...,  1.1723,  0.4258,  4.4592],\n",
            "        [ 3.9950,  5.3246,  2.5108,  ...,  1.8726,  0.1081,  1.9635],\n",
            "        [ 2.9932,  4.1935,  3.5663,  ...,  1.5249,  4.2988,  3.1386],\n",
            "        ...,\n",
            "        [ 2.5832,  2.1242,  0.3108,  ...,  2.2735,  3.1780,  2.8655],\n",
            "        [ 1.6347,  4.3523,  5.4086,  ...,  2.3212,  3.4032,  3.6894],\n",
            "        [ 1.5491,  5.6595,  2.9637,  ..., -0.3052, -1.2745, -0.4777]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6287,  7.1034,  2.6102,  ..., -0.6161, -0.0461,  0.3748],\n",
            "        [ 3.2220,  4.5096,  3.4225,  ...,  2.4299, -2.4013, -2.0424],\n",
            "        [ 4.4585, 12.5559,  4.3564,  ...,  0.0729,  1.3774,  2.6950],\n",
            "        ...,\n",
            "        [ 1.9975,  4.1398,  1.1706,  ...,  3.1690,  1.4977,  2.3186],\n",
            "        [ 3.1421,  5.7141, -2.3290,  ..., -0.8577,  2.3532,  3.5467],\n",
            "        [ 5.3367,  4.5841,  2.6988,  ...,  1.0164, -0.4523,  2.4586]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7322,  5.5290,  3.3405,  ..., -0.3497,  2.0254,  9.3081],\n",
            "        [ 3.3373, 10.0396,  8.4935,  ..., -0.3588,  1.3351,  4.1555],\n",
            "        [ 3.0606,  6.0865,  0.7059,  ...,  1.3864, -2.0460, -0.4076],\n",
            "        ...,\n",
            "        [ 2.0143,  6.4468,  1.5508,  ...,  0.4692, -1.5479, -0.5250],\n",
            "        [ 1.4019,  3.5027,  5.6099,  ..., -0.1079,  1.7704,  5.3316],\n",
            "        [ 3.8164,  6.5837,  4.4929,  ..., -1.0546,  1.1088,  7.8935]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2217,  3.7963,  4.8130,  ...,  0.0464, -2.3200,  3.1503],\n",
            "        [ 3.6068,  5.2873,  1.2616,  ...,  2.6328,  5.6635,  0.8790],\n",
            "        [ 3.9120,  5.8089,  5.1326,  ..., -0.8631,  3.2274,  1.8065],\n",
            "        ...,\n",
            "        [-0.5503,  2.6132,  6.2992,  ..., -1.7756,  1.8476,  2.8521],\n",
            "        [ 4.0417,  8.0981, -1.2377,  ..., -0.7166,  4.4362,  6.6756],\n",
            "        [-1.4204,  3.3845,  5.6570,  ..., -1.9572,  0.4148,  3.0319]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4376,  9.3933,  1.2282,  ..., -3.9464,  0.2729,  9.9091],\n",
            "        [ 3.4878,  8.5444,  2.8356,  ...,  0.6328,  9.0399,  3.8912],\n",
            "        [ 0.6667,  1.0503,  6.1462,  ..., -0.7928,  4.3851,  5.7992],\n",
            "        ...,\n",
            "        [ 2.0730,  3.8866,  4.4609,  ...,  1.4340,  3.6426,  1.1327],\n",
            "        [ 3.0999,  4.9682,  2.7921,  ...,  3.4495, -0.5054, -0.1539],\n",
            "        [ 5.9594,  5.9779,  3.3993,  ...,  0.0874, -0.3328,  3.6831]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0016,  4.4903,  4.8092,  ...,  3.3965,  1.9515,  2.3175],\n",
            "        [ 5.1624,  7.4083,  3.8989,  ...,  3.1301,  5.4647,  2.8447],\n",
            "        [-0.2264,  5.5436,  4.4270,  ...,  1.7154,  0.5693,  6.0730],\n",
            "        ...,\n",
            "        [ 3.8759,  8.9453, -2.3816,  ...,  3.5541,  4.9968,  0.2982],\n",
            "        [ 4.9347,  6.3900,  3.6982,  ...,  1.1028,  5.5837,  9.0790],\n",
            "        [ 3.0014,  8.2861,  3.3243,  ...,  1.5512,  4.5279,  0.5942]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.8499,  4.8865,  4.0274,  ...,  1.1487,  3.8263,  9.4876],\n",
            "        [ 0.0737,  3.2663,  4.1383,  ...,  2.1606,  3.1837,  2.1439],\n",
            "        [-0.2083,  2.9614,  3.9606,  ...,  2.0185,  0.3398,  3.2032],\n",
            "        ...,\n",
            "        [ 3.9976,  3.3123,  2.7108,  ...,  2.3445, -0.2583,  1.8813],\n",
            "        [ 0.6996,  4.9351,  4.4430,  ..., -1.2701,  4.3547,  3.9004],\n",
            "        [ 1.8177,  5.5991,  5.2598,  ...,  2.9406,  2.8369,  4.3374]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0984,  6.9245,  7.7442,  ..., -0.1620,  4.9064,  2.8799],\n",
            "        [ 4.3683,  3.1510,  1.9542,  ...,  2.8684,  0.6375,  1.0443],\n",
            "        [ 5.1427,  7.8016,  3.3311,  ...,  0.0298,  3.0700,  0.1072],\n",
            "        ...,\n",
            "        [ 4.9197,  7.6595,  3.0736,  ...,  2.5251,  8.1249,  3.3047],\n",
            "        [ 1.4135,  3.3266,  7.7126,  ..., -1.6097,  2.5410,  0.9869],\n",
            "        [-2.1872,  3.6943,  5.9947,  ..., -3.1310, -0.0349,  3.1313]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2658,  6.2746,  1.2770,  ...,  1.3207,  4.7009,  3.7804],\n",
            "        [ 4.9037, 10.5697,  2.3465,  ...,  3.3515,  2.6136,  3.3500],\n",
            "        [-0.7000,  4.5127,  1.3285,  ...,  1.2388,  8.9856,  7.0849],\n",
            "        ...,\n",
            "        [ 3.1670,  4.0562,  2.9811,  ...,  1.0632,  5.5241,  3.9093],\n",
            "        [ 3.4523,  3.4893, -0.5585,  ...,  3.5274,  1.3237,  1.5788],\n",
            "        [ 3.8737,  3.7337,  2.2292,  ...,  1.9264,  2.3037,  3.2212]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4904,  6.8707, -0.6407,  ..., -2.7428,  1.2495,  8.7256],\n",
            "        [ 1.0484,  5.6969,  2.8226,  ...,  2.2802,  0.8191,  0.3067],\n",
            "        [ 1.7901,  5.7225,  6.1937,  ..., -1.9725,  3.2237,  3.6751],\n",
            "        ...,\n",
            "        [ 2.0936,  2.6752,  1.2175,  ..., -0.2332, -0.2524,  1.1777],\n",
            "        [ 3.5530,  6.7527,  4.6277,  ...,  1.8544,  0.8996,  3.3856],\n",
            "        [ 3.0756,  6.1409,  3.0051,  ...,  5.4523,  3.3863,  3.5541]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2472e+00,  4.2911e+00,  4.6856e+00,  ...,  1.5640e-01,\n",
            "          1.1085e+00,  1.0465e+00],\n",
            "        [ 5.9697e+00,  1.0533e+01,  8.0010e-01,  ...,  3.7158e+00,\n",
            "          2.7592e+00,  5.9126e+00],\n",
            "        [ 4.1992e+00,  4.6965e+00,  3.5302e+00,  ..., -3.7492e-02,\n",
            "         -4.0807e-03,  1.8143e+00],\n",
            "        ...,\n",
            "        [-6.9791e-01,  4.4978e+00,  5.2548e+00,  ..., -2.6715e+00,\n",
            "          6.3452e+00,  3.3931e+00],\n",
            "        [ 1.7215e+00,  3.5471e+00,  4.2535e+00,  ..., -1.8472e+00,\n",
            "          1.5896e+00,  2.1601e-01],\n",
            "        [ 1.6300e+00,  4.9247e+00,  6.7687e+00,  ..., -1.1880e+00,\n",
            "          3.1431e+00,  1.6398e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6885,  2.9552,  7.9694,  ..., -0.3223,  4.6184,  7.4255],\n",
            "        [ 5.7539,  8.6127,  4.0346,  ..., -0.8597,  1.8699,  2.9995],\n",
            "        [ 1.2983,  5.7092,  3.8502,  ...,  0.7850, -2.2867,  1.4730],\n",
            "        ...,\n",
            "        [ 1.3803,  4.1293,  3.6193,  ..., -0.2107, -0.1509,  3.1683],\n",
            "        [ 1.8499,  3.4651,  3.5116,  ...,  0.4635,  5.2667,  5.3613],\n",
            "        [ 0.6851,  5.4895,  6.2323,  ...,  0.6339,  4.1991,  4.8460]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5039,  9.4551,  4.7642,  ...,  2.1171,  7.6997,  4.4025],\n",
            "        [ 2.8150,  4.0709,  3.1926,  ...,  1.4565,  0.3249,  2.8542],\n",
            "        [ 1.8909,  1.7886,  4.5080,  ..., -1.0312,  4.0908,  6.1995],\n",
            "        ...,\n",
            "        [ 6.4665,  6.0536,  3.1625,  ...,  1.4837, -1.1063, -2.0839],\n",
            "        [ 0.5370,  2.9374,  3.2854,  ...,  2.6267,  2.1227,  2.2294],\n",
            "        [ 2.8877,  4.7056,  4.5283,  ...,  1.8225,  2.2870,  0.3447]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5933,  4.2386,  6.8385,  ..., -1.1122,  3.8209,  2.2582],\n",
            "        [ 4.7109,  9.6404,  2.3517,  ...,  0.3105, -1.3946,  0.3750],\n",
            "        [ 0.7936,  2.6344,  2.4143,  ...,  1.2448,  2.2686,  2.6613],\n",
            "        ...,\n",
            "        [ 1.5294,  5.8897,  8.3122,  ...,  0.9608,  2.6147,  6.7921],\n",
            "        [-0.6988,  5.2440,  7.8847,  ...,  1.0037, -1.4135,  6.7299],\n",
            "        [ 3.2823,  4.2702,  3.0740,  ...,  2.1569,  2.3420,  5.1020]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6582e+00,  9.7677e+00,  7.6396e+00,  ..., -1.4092e+00,\n",
            "          4.2377e+00,  3.2839e+00],\n",
            "        [ 3.5898e+00,  1.0063e+01,  5.0424e+00,  ..., -1.1432e+00,\n",
            "          3.6348e+00,  3.1094e+00],\n",
            "        [ 2.9302e+00,  5.4980e+00,  2.7971e+00,  ...,  1.2386e+00,\n",
            "         -3.7114e-01, -2.4872e-03],\n",
            "        ...,\n",
            "        [-1.8419e+00,  7.8243e+00,  4.3368e+00,  ...,  7.4088e-02,\n",
            "          6.9705e+00,  4.9426e+00],\n",
            "        [ 6.2732e+00,  1.3190e+01,  5.3272e+00,  ...,  6.0864e-01,\n",
            "          3.1927e+00,  2.9288e+00],\n",
            "        [ 2.5191e+00,  5.9651e+00,  4.8278e+00,  ...,  3.2338e+00,\n",
            "         -1.6286e+00, -1.1212e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4588,  1.7617,  2.2163,  ...,  5.8359,  4.7195,  3.7118],\n",
            "        [ 2.7909,  3.7807,  3.7683,  ...,  1.5320,  3.6953,  2.9882],\n",
            "        [ 2.8156,  5.2484,  1.4525,  ...,  3.4213,  1.7113,  0.2209],\n",
            "        ...,\n",
            "        [ 1.1264,  5.9575,  3.9042,  ...,  1.3679, -2.0123,  4.2131],\n",
            "        [ 5.3067,  3.3227,  1.0643,  ...,  3.6359,  0.3766,  1.9379],\n",
            "        [ 3.4631,  9.1537,  1.3292,  ...,  0.4955, 12.8859,  9.4947]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8695,  5.8777,  4.4061,  ...,  1.4202,  3.3382,  2.9357],\n",
            "        [ 4.1509, 10.0053,  3.9844,  ...,  1.1221,  1.4635,  1.5969],\n",
            "        [ 2.5322,  2.2024,  3.5136,  ...,  1.9640, -0.4837,  0.9901],\n",
            "        ...,\n",
            "        [-0.7390,  9.2436,  5.0343,  ..., -1.1135, -1.2195,  4.9241],\n",
            "        [ 1.8048,  4.5497,  5.4595,  ...,  1.6043,  4.2065,  2.8384],\n",
            "        [ 4.3136,  6.1933,  2.9072,  ...,  3.9616,  3.5294,  2.7480]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.0015,  4.8119,  1.3600,  ...,  1.9265,  3.8348,  2.7482],\n",
            "        [ 7.0972,  8.1606,  2.6842,  ...,  3.6595,  3.4773,  5.8495],\n",
            "        [ 5.2382,  5.5830,  1.3669,  ...,  2.0577,  0.7235,  2.6459],\n",
            "        ...,\n",
            "        [ 3.6434,  6.5591,  2.4491,  ..., -0.6314,  2.7807,  6.3051],\n",
            "        [ 1.9422,  8.6242,  4.5097,  ...,  0.0668, -0.9751,  3.6021],\n",
            "        [ 6.9269,  4.2464,  0.5678,  ...,  3.0045, -0.4474,  0.4558]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2835,  5.8314,  1.6547,  ...,  3.0845, -0.5438,  0.7489],\n",
            "        [ 2.5381,  6.2319,  5.3696,  ..., -0.8685,  0.5083,  3.5889],\n",
            "        [-1.1847,  6.6075,  7.4389,  ..., -0.1644,  2.4645,  5.3672],\n",
            "        ...,\n",
            "        [ 4.2007,  9.9640,  4.4897,  ...,  0.1204,  0.1657,  4.6312],\n",
            "        [ 4.3743,  7.8498,  1.3678,  ..., -1.9023,  2.6805,  4.3317],\n",
            "        [ 4.4874,  6.5040,  1.2852,  ..., -0.3225,  4.1938,  7.4401]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7139,  6.2324,  2.2558,  ...,  4.1156,  1.0901,  4.3404],\n",
            "        [ 1.0409,  5.2416,  3.1325,  ...,  0.0935,  9.2140,  8.7576],\n",
            "        [ 5.2841,  6.8970,  4.6060,  ...,  1.7561,  0.9871,  1.2583],\n",
            "        ...,\n",
            "        [ 5.0982,  4.8810,  1.4709,  ...,  0.3258,  1.4456,  1.4035],\n",
            "        [ 0.7456,  4.6757,  1.5565,  ...,  2.0415,  2.2980,  7.4496],\n",
            "        [ 4.9302,  4.0664,  0.0252,  ..., -0.7084,  0.2937,  2.6359]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.8602,  5.1855,  2.5149,  ..., -0.9024,  2.7381,  4.3072],\n",
            "        [ 1.6954,  4.3131,  3.5454,  ..., -0.0964, -0.2430,  4.0880],\n",
            "        [ 0.7516,  9.5348, -1.6753,  ..., -0.7374,  0.9638,  7.0798],\n",
            "        ...,\n",
            "        [ 3.8331,  5.1048,  1.6879,  ..., -2.0404,  2.0785,  8.1562],\n",
            "        [ 0.1372,  3.1241,  4.3395,  ..., -0.0796,  4.0353,  4.4076],\n",
            "        [ 2.1169,  4.1382,  5.0394,  ...,  1.0369,  3.6929,  2.9009]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8256,  3.8055,  2.3804,  ...,  0.7828,  1.2601,  1.8558],\n",
            "        [ 4.6403,  5.3588,  3.4466,  ...,  2.2092,  2.3350,  6.4592],\n",
            "        [ 2.2054,  7.0032,  3.1314,  ..., -3.6426,  0.7344,  5.6887],\n",
            "        ...,\n",
            "        [ 3.1944, 10.7988, -0.0256,  ..., -0.4851, -0.9423,  8.3963],\n",
            "        [ 2.2664,  8.2201,  2.5359,  ..., -0.5309,  3.2539,  2.4161],\n",
            "        [ 4.1898,  8.6465,  0.9616,  ..., -0.1742, 10.3845,  5.8357]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8995,  6.3696,  4.1500,  ..., -2.1660,  2.0041,  0.9495],\n",
            "        [ 1.9444,  3.7928,  5.6297,  ..., -0.6513,  5.9093,  4.2123],\n",
            "        [ 2.0347,  3.9551,  3.6552,  ...,  1.1419, -0.6271,  3.8512],\n",
            "        ...,\n",
            "        [-4.0684,  5.9437,  2.8913,  ..., -1.7928,  3.5042,  6.9730],\n",
            "        [ 5.0249,  9.3860,  0.6788,  ...,  4.3057,  4.2713,  1.3961],\n",
            "        [ 1.7423,  3.7873,  5.6939,  ...,  0.4946,  0.4400,  1.1675]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0587,  5.9784,  4.7738,  ...,  3.3572,  1.7030,  1.8053],\n",
            "        [ 5.1232,  5.8340,  2.4360,  ...,  0.4315,  1.1866,  3.8624],\n",
            "        [ 2.2313,  7.6192,  0.0291,  ...,  0.4098, -0.4178,  9.7942],\n",
            "        ...,\n",
            "        [ 2.3994, 10.9281,  4.5945,  ...,  1.2439,  0.9221,  3.6836],\n",
            "        [ 1.6256,  4.3991,  3.5780,  ...,  3.5881,  1.3445,  2.2554],\n",
            "        [ 1.0014,  5.1002,  4.4673,  ...,  3.8947,  0.2158,  2.5223]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9689,  5.1133,  4.1588,  ..., -0.7535,  4.7729,  9.1217],\n",
            "        [ 1.3187,  5.8964,  5.9703,  ...,  2.4791,  1.8552,  1.4068],\n",
            "        [ 2.5897,  7.2036,  9.7428,  ...,  0.1116, -0.8568,  0.0689],\n",
            "        ...,\n",
            "        [ 2.4046,  8.5490,  4.0591,  ...,  2.4633,  0.0358,  3.6952],\n",
            "        [ 4.7550, 11.2846,  6.4030,  ..., -1.7786,  2.8004,  1.5209],\n",
            "        [ 2.5845,  5.9347,  4.2257,  ...,  4.1078,  2.3939,  1.9229]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5537,  6.4618,  3.9010,  ...,  0.7848,  2.1708,  1.7155],\n",
            "        [ 1.4137,  5.7361,  3.3354,  ...,  0.9153,  3.0940,  0.4907],\n",
            "        [-0.2910,  3.4190,  3.1452,  ...,  2.5390,  1.9821,  2.1785],\n",
            "        ...,\n",
            "        [ 6.4818,  6.0825, -2.2280,  ...,  1.1839, -0.4534,  2.5677],\n",
            "        [ 2.2099,  4.0614,  4.4462,  ...,  3.8299,  1.3015,  4.0419],\n",
            "        [ 1.2564,  4.7234,  3.5712,  ...,  0.0534, -0.2039,  1.7919]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2139e+00,  6.8685e+00,  3.9846e+00,  ...,  2.5643e-01,\n",
            "          5.6472e+00,  6.6003e+00],\n",
            "        [ 4.0716e+00,  9.6386e+00,  1.2000e+00,  ..., -2.4284e-01,\n",
            "          2.4038e-01,  9.6048e+00],\n",
            "        [ 2.8007e+00,  8.3265e+00,  4.9989e+00,  ..., -2.0609e+00,\n",
            "          3.0268e-01,  6.4793e+00],\n",
            "        ...,\n",
            "        [ 2.3615e+00,  6.2704e+00,  1.4562e+00,  ..., -1.4378e+00,\n",
            "          7.5943e+00,  3.6836e+00],\n",
            "        [ 4.7990e+00,  5.9396e+00,  6.5377e-01,  ...,  7.9504e-03,\n",
            "          8.9724e-01,  1.2586e+00],\n",
            "        [ 1.3748e+00,  4.7078e+00, -1.0794e+00,  ..., -4.2002e-01,\n",
            "         -3.6599e-01,  5.5844e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9700,  5.8708,  7.3454,  ..., -4.2952,  7.3088,  5.6253],\n",
            "        [-0.1349,  2.2185,  5.2094,  ...,  1.2841,  4.2320,  3.3497],\n",
            "        [ 1.2517,  3.6235,  4.1109,  ...,  2.1026,  3.7756,  2.3559],\n",
            "        ...,\n",
            "        [ 4.8702,  9.2060,  1.9813,  ..., -4.4927,  5.3902,  5.2315],\n",
            "        [ 2.6636,  6.2391,  4.0201,  ...,  4.6170,  1.7456,  1.5563],\n",
            "        [ 1.6460,  3.7255,  4.3648,  ...,  1.8632,  3.6018,  1.8093]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0757,  4.2317,  3.6045,  ...,  3.3133,  1.7899,  2.2599],\n",
            "        [ 3.7711,  4.1803,  5.0940,  ...,  3.1339,  1.7710,  1.0001],\n",
            "        [ 0.2528,  4.1524,  3.5300,  ..., -0.6304, -1.0370,  5.7357],\n",
            "        ...,\n",
            "        [ 6.4855,  7.9209,  1.7170,  ...,  3.1180,  1.3143,  0.7077],\n",
            "        [ 0.4528,  4.7285,  5.2242,  ...,  0.6692, -1.1245,  4.8221],\n",
            "        [ 1.7744,  7.1533,  4.9920,  ...,  0.5035,  5.2710,  3.0444]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0216,  7.5779,  3.3357,  ..., -2.5532,  2.3265,  2.7489],\n",
            "        [ 1.9127,  5.1554,  4.0891,  ...,  4.2311,  1.6605,  1.0518],\n",
            "        [ 2.3006,  2.5572,  6.1225,  ..., -1.5757,  4.8985,  6.1689],\n",
            "        ...,\n",
            "        [ 0.4602,  4.1712,  5.3635,  ...,  2.3930,  1.0718,  2.5970],\n",
            "        [ 0.2967,  2.9488,  4.1502,  ..., -0.1909,  2.7535,  3.1855],\n",
            "        [ 3.2578,  7.5155,  6.2424,  ..., -1.5527, -1.7744,  0.5732]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3061,  3.6982,  0.7714,  ...,  2.4886,  1.6833,  3.2753],\n",
            "        [ 0.0145,  3.3568,  3.9529,  ..., -1.2828,  3.6652,  1.9728],\n",
            "        [ 6.0691,  7.4863,  2.5316,  ...,  1.7770, -0.3154,  1.3885],\n",
            "        ...,\n",
            "        [ 1.8214,  6.9708,  4.9700,  ...,  0.3971,  6.3113,  2.9164],\n",
            "        [ 2.5415,  6.5794,  3.3061,  ...,  2.2134,  5.6263,  2.1457],\n",
            "        [ 1.6719,  5.1803,  4.2028,  ...,  3.7489,  1.6144,  1.9309]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5135,  4.6230,  6.8643,  ...,  1.3328,  2.5872,  7.9439],\n",
            "        [ 4.8492,  6.2612,  3.0185,  ...,  0.5614, -0.2801,  0.1719],\n",
            "        [ 5.9308,  5.2566,  3.2391,  ...,  0.5336,  2.4544, 11.2411],\n",
            "        ...,\n",
            "        [-0.2935,  4.6757,  3.7458,  ...,  4.2844,  0.1211,  5.0149],\n",
            "        [ 5.7292,  7.6547,  2.3554,  ..., -0.1015,  9.3460,  8.9571],\n",
            "        [ 3.7113, 10.5040,  0.6862,  ...,  2.9460,  0.3676,  2.8041]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0993,  5.2350,  3.7705,  ...,  2.8661,  2.3714,  3.9046],\n",
            "        [ 0.3656,  2.9086,  3.4219,  ...,  3.0167,  3.1824,  1.4208],\n",
            "        [ 2.2430,  8.6280,  1.9010,  ..., -4.1368,  8.3344,  7.5509],\n",
            "        ...,\n",
            "        [ 1.1176,  4.1787,  5.0132,  ..., -2.4975, -0.3536,  0.2343],\n",
            "        [ 7.6719, 12.9430,  4.7467,  ..., -0.2198,  3.5891,  4.0137],\n",
            "        [-0.2312,  3.4010,  4.3178,  ...,  2.1715,  2.7256,  3.8613]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2408e+00,  4.7064e+00,  2.6281e+00,  ...,  2.8923e-03,\n",
            "          1.1090e+00,  4.2872e+00],\n",
            "        [ 7.4394e+00,  5.6151e+00, -3.3637e-01,  ...,  1.4343e+00,\n",
            "         -1.0130e+00,  1.3681e+00],\n",
            "        [ 1.9064e+00,  4.7053e+00,  4.6540e+00,  ...,  3.2177e+00,\n",
            "         -1.2518e+00,  4.3055e+00],\n",
            "        ...,\n",
            "        [ 2.4244e+00,  6.9620e+00,  5.3483e+00,  ...,  6.5615e-01,\n",
            "          8.4386e-01,  1.7671e+00],\n",
            "        [ 4.1994e+00,  1.0649e+01,  5.1797e+00,  ..., -2.6392e-01,\n",
            "         -2.0499e-01,  3.4377e+00],\n",
            "        [ 5.6480e+00,  7.9943e+00,  2.8431e+00,  ...,  3.9875e-01,\n",
            "         -9.7937e-01,  3.5653e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9497,  8.5136,  5.0371,  ...,  0.3013,  4.3328,  3.1017],\n",
            "        [ 2.9231,  5.2838,  2.1010,  ...,  0.5142, -0.6640,  2.4874],\n",
            "        [ 3.6381,  3.1412,  0.9557,  ...,  4.0254,  2.5401,  4.2021],\n",
            "        ...,\n",
            "        [ 2.3930,  5.1927,  4.0202,  ...,  0.3009,  1.7792,  1.7720],\n",
            "        [ 3.7187,  5.9562,  2.4942,  ...,  3.0643,  5.8446,  5.1318],\n",
            "        [ 5.0827,  4.5606,  0.4856,  ...,  3.8979,  3.1868,  1.0971]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.4783,  4.9789,  0.7595,  ...,  4.2161,  2.0902,  2.1632],\n",
            "        [ 3.9047, 11.2893,  6.5165,  ...,  1.9207,  3.2816,  3.4453],\n",
            "        [ 1.7332,  8.4310,  0.3550,  ..., -2.5659,  1.3360,  8.0270],\n",
            "        ...,\n",
            "        [ 4.0331,  6.1763,  3.8649,  ...,  3.8627,  1.4049,  5.6927],\n",
            "        [ 1.5038,  7.0960,  5.1500,  ...,  3.3649,  4.6903,  1.7153],\n",
            "        [ 1.7325,  4.6659,  4.0307,  ...,  2.7553,  2.9899,  2.7441]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9269,  4.1517,  3.9496,  ...,  1.9730,  2.6210,  2.1899],\n",
            "        [ 2.2278,  6.9936,  1.1573,  ...,  2.3724, -3.5599,  3.2881],\n",
            "        [ 4.8473,  5.8285,  1.9015,  ...,  3.0913,  2.3172,  0.6246],\n",
            "        ...,\n",
            "        [ 0.3822,  5.1313,  7.8754,  ..., -3.6532,  3.9571,  2.1259],\n",
            "        [ 1.7280,  5.0602,  4.9961,  ...,  3.8420,  2.1271,  2.3924],\n",
            "        [ 2.1555,  5.1782,  0.9886,  ...,  0.8851, -0.1461,  5.6240]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9050,  4.6272,  4.9990,  ...,  3.0633,  1.3637,  1.5317],\n",
            "        [ 3.8205, 10.8710,  0.3076,  ..., -2.9366,  0.0726,  5.3025],\n",
            "        [-1.0157,  3.0571,  1.1102,  ...,  1.0635,  6.6475,  5.0487],\n",
            "        ...,\n",
            "        [ 6.2539,  4.8158,  0.6711,  ...,  2.7406, -0.4963,  3.5819],\n",
            "        [ 4.7788,  7.4997,  2.1585,  ...,  5.7305,  6.5199,  6.8337],\n",
            "        [ 1.6770,  6.4639,  7.0157,  ..., -4.0147, -2.5217,  5.0509]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4297,  8.2187,  0.8965,  ...,  4.3869,  4.8445,  5.3002],\n",
            "        [ 2.0684,  6.0588,  1.1224,  ..., -2.7171,  8.3911,  6.8933],\n",
            "        [ 1.5489,  7.0360,  6.4445,  ..., -0.2270,  2.9284,  1.8322],\n",
            "        ...,\n",
            "        [ 1.6323,  5.2682,  3.5262,  ...,  1.1682,  1.4477,  1.0034],\n",
            "        [ 5.2245, 12.5327,  6.2112,  ...,  1.6844,  3.4139,  4.9997],\n",
            "        [ 5.6996,  7.4389,  3.4028,  ...,  2.2043, -0.8673,  1.3097]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3892,  5.8914,  1.6116,  ...,  3.7424,  4.2894,  4.8608],\n",
            "        [ 1.0418,  7.7974,  8.7093,  ..., -0.2870,  3.3055,  8.5855],\n",
            "        [ 4.8313,  6.4984,  0.4001,  ...,  0.8483, -0.7654,  1.5942],\n",
            "        ...,\n",
            "        [ 3.9109,  6.7029,  0.3637,  ...,  0.0709,  1.1410,  8.0547],\n",
            "        [ 3.2896,  7.2522,  2.8746,  ..., -0.0538,  7.3133,  6.8870],\n",
            "        [ 3.0701,  3.1237,  4.4759,  ...,  3.8864,  1.2047,  2.6428]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7326,  2.8889,  3.9885,  ...,  0.6458,  1.2990,  6.6122],\n",
            "        [ 1.9745,  5.3698,  5.8622,  ..., -1.5321, -0.3079,  1.7797],\n",
            "        [ 5.0833,  6.4683,  1.4817,  ...,  1.4558,  1.3780,  2.7039],\n",
            "        ...,\n",
            "        [ 5.2207,  6.4003, -0.1950,  ...,  2.2820,  0.5955,  2.5154],\n",
            "        [ 1.2370,  2.9916,  6.4526,  ..., -0.7233,  3.2561,  6.6290],\n",
            "        [ 0.0092,  4.9672,  3.6931,  ...,  3.1391,  2.2455,  1.8504]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8059,  6.6182,  3.4031,  ...,  0.4623,  5.8436,  6.7270],\n",
            "        [ 1.3598,  5.6530,  1.9619,  ..., -0.6013,  1.9054,  3.1908],\n",
            "        [ 6.0509,  9.7623,  2.0436,  ...,  2.9561,  2.2178,  3.4674],\n",
            "        ...,\n",
            "        [ 1.9792,  4.1132,  2.4810,  ...,  0.5165, -0.8166,  9.1931],\n",
            "        [ 1.0403,  6.9141,  1.2772,  ...,  3.1751,  3.3395,  5.1814],\n",
            "        [ 5.8128, 10.0254,  4.8395,  ..., -0.5773,  0.8039,  2.0730]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.2755,  3.1075,  1.5955,  ...,  3.4334, -0.3759, -0.0086],\n",
            "        [ 0.1838,  5.9044,  3.4067,  ...,  0.7413, -2.5477, -1.9667],\n",
            "        [ 2.0128,  5.5268,  2.9474,  ...,  2.8405,  3.3889,  3.7328],\n",
            "        ...,\n",
            "        [ 0.5167,  4.8383,  4.1562,  ...,  1.0730, -2.6629,  4.4083],\n",
            "        [ 1.8634,  6.7548,  3.1712,  ...,  1.9992,  2.0577,  1.8224],\n",
            "        [ 4.5443,  3.9593,  1.1889,  ...,  1.2677, -1.1492,  1.6621]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8218, 11.0649,  3.2045,  ..., -0.1106,  7.8959,  4.7889],\n",
            "        [ 1.5905,  6.4898,  5.1430,  ..., -0.9248,  3.6860,  5.0222],\n",
            "        [ 0.9882,  4.2927,  1.4758,  ...,  1.8545,  2.9483,  2.6636],\n",
            "        ...,\n",
            "        [ 0.4851,  8.3378,  6.1018,  ..., -0.9115, -2.1393, -0.8441],\n",
            "        [ 2.1994,  4.5738,  3.7834,  ...,  1.1941,  1.5132,  0.1927],\n",
            "        [ 4.8614,  8.2024,  1.7662,  ...,  4.6377,  4.7575,  2.5065]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4291,  6.2162,  5.5248,  ..., -1.9479,  1.8590,  5.5798],\n",
            "        [ 2.5399,  8.4992,  2.6986,  ..., -1.2551,  8.7586,  5.6273],\n",
            "        [ 4.2508,  5.5253,  0.3776,  ...,  6.0307,  4.7601,  3.6322],\n",
            "        ...,\n",
            "        [ 4.4552, 10.2106,  5.4202,  ...,  1.4034,  7.4982,  7.0392],\n",
            "        [ 1.3902,  4.6357,  6.7267,  ..., -0.6277,  4.1894,  7.1794],\n",
            "        [ 6.1653, 13.1998,  1.4946,  ..., -0.4647,  3.7794,  3.5697]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4711,  3.0158,  3.9719,  ...,  2.7212,  0.9409,  1.8922],\n",
            "        [-0.4285,  8.5696,  5.4417,  ...,  2.8825,  0.6789,  3.6045],\n",
            "        [ 2.2013,  2.9379,  5.6668,  ...,  0.6703,  1.4844,  2.5034],\n",
            "        ...,\n",
            "        [ 0.1507,  9.3418,  2.5661,  ...,  0.0477,  2.5181,  3.9991],\n",
            "        [ 4.2474,  5.6104,  3.8048,  ...,  0.2348, -3.9220,  2.1638],\n",
            "        [ 4.1373,  2.9592,  0.4671,  ...,  2.8855, -5.7827,  2.5606]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5098,  5.8521,  4.2742,  ..., -0.7697,  1.8548,  7.3360],\n",
            "        [ 4.9798,  5.4800, -1.1884,  ...,  1.4080,  1.4175,  3.9556],\n",
            "        [ 2.5412,  4.4640,  3.2883,  ...,  2.2882, -1.3810,  1.8867],\n",
            "        ...,\n",
            "        [ 4.9635,  6.8868,  2.0074,  ...,  2.8890,  1.4819,  3.0239],\n",
            "        [ 4.8576,  6.7615,  3.9357,  ...,  3.8345, -1.6255,  1.4408],\n",
            "        [-2.8963,  6.6413,  3.3812,  ..., -3.7539, -3.6510,  9.1956]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2895,  7.1545,  2.4624,  ...,  4.0547,  0.6537,  6.2072],\n",
            "        [-0.1320,  8.6079,  6.0699,  ..., -4.8733,  6.5017,  5.8140],\n",
            "        [ 1.7492,  5.2163,  3.1407,  ...,  1.4866,  0.3358,  5.5045],\n",
            "        ...,\n",
            "        [ 0.5537,  5.2434,  3.3196,  ...,  1.8502,  1.3987,  3.4817],\n",
            "        [ 5.3204,  7.6954,  1.9872,  ...,  4.5092,  1.7629,  1.9683],\n",
            "        [ 4.6544,  7.9236,  2.6423,  ...,  3.1258,  1.9370,  2.5533]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.9094, 10.3574,  5.5754,  ...,  0.3195,  7.1173,  4.3588],\n",
            "        [ 4.6455,  5.8223,  0.9648,  ...,  1.2408,  5.3310,  2.6618],\n",
            "        [ 4.7823,  5.4872,  0.5333,  ...,  1.8501,  0.4013,  4.5287],\n",
            "        ...,\n",
            "        [ 5.2516,  5.4733,  0.3408,  ...,  3.4336,  1.5310,  2.9516],\n",
            "        [ 5.1621,  5.9826,  1.2366,  ...,  3.7401,  3.1263,  5.3930],\n",
            "        [ 2.6863,  9.1799,  1.9667,  ..., -1.1431,  7.9405,  7.9250]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2209,  2.6146,  4.1663,  ...,  4.4342,  3.2671,  6.4442],\n",
            "        [ 2.1744,  7.4153, -1.4640,  ...,  0.7793,  0.0285,  4.7374],\n",
            "        [ 0.6083,  3.9764,  2.6064,  ...,  0.5435,  1.9970,  3.4141],\n",
            "        ...,\n",
            "        [-0.6480,  4.6801,  4.0276,  ..., -1.8322,  1.4735,  1.3630],\n",
            "        [ 1.8807,  3.7020,  2.3087,  ...,  0.5119,  0.2440,  1.3781],\n",
            "        [ 0.4676,  7.8001,  0.8362,  ..., -1.4044, -1.9247,  6.0249]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "405480958f624cf4bb8b59568f15fa93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3559,  2.7631,  4.1885,  ...,  1.8047,  3.3268,  1.9285],\n",
            "        [ 5.4029, 11.7446,  1.5006,  ...,  0.7480, -2.9991,  2.8834],\n",
            "        [ 2.0749,  5.8755,  3.3920,  ...,  3.3137, -0.0928,  3.3528],\n",
            "        ...,\n",
            "        [ 6.7241, 15.0985,  4.6191,  ...,  1.4391, -0.2053,  4.7080],\n",
            "        [ 0.2519,  5.4912,  4.9507,  ..., -0.0593,  0.4773,  1.9010],\n",
            "        [ 4.7570,  3.1825,  2.8645,  ...,  0.7354, -0.2222, -0.2849]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2635,  3.3621,  4.8169,  ..., -1.7864, -0.2455,  2.4911],\n",
            "        [ 0.6763,  3.4054,  4.1149,  ...,  1.2470,  3.1665,  2.1299],\n",
            "        [ 2.8102,  6.5599,  0.8075,  ..., -1.9469, -0.2099, 10.6804],\n",
            "        ...,\n",
            "        [ 1.6474,  4.0933,  4.3420,  ...,  3.8694,  1.2665,  2.0814],\n",
            "        [ 0.3762,  4.9219,  6.3450,  ..., -1.9336, -0.3690,  5.2705],\n",
            "        [ 3.3017,  7.3052,  4.9192,  ..., -1.1250,  1.9057,  2.7605]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8822,  5.2490,  4.7421,  ...,  3.6179,  0.9679,  2.0182],\n",
            "        [ 4.6825, 10.6305,  4.7178,  ...,  0.9187,  3.7849,  4.7038],\n",
            "        [ 4.4305,  6.3427,  1.8235,  ...,  0.8703, -0.2539,  2.8601],\n",
            "        ...,\n",
            "        [ 4.0062,  3.3469, -1.9143,  ...,  1.2430,  1.8407,  2.4658],\n",
            "        [ 4.4621,  7.7861,  1.1953,  ..., -0.4586,  0.6818,  3.1840],\n",
            "        [ 1.3211,  4.2550,  3.5584,  ..., -2.2290,  6.2994, 10.3728]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4435,  4.5826,  7.7152,  ...,  0.5847,  0.8111,  2.9751],\n",
            "        [ 2.6887,  4.7653,  1.3627,  ..., -1.8018,  4.4507,  1.1281],\n",
            "        [ 3.9525,  7.2971,  2.0734,  ...,  0.9644, -1.6390, 10.3276],\n",
            "        ...,\n",
            "        [ 2.8283,  2.6907,  2.5097,  ...,  1.8037,  1.5601,  3.2739],\n",
            "        [ 5.2303,  6.6772,  2.0765,  ...,  0.7291, -0.8588,  3.6892],\n",
            "        [ 5.0109, 10.5374,  5.9037,  ..., -3.1135, -0.6106,  2.9813]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1907,  2.6710,  5.4242,  ...,  0.4402,  2.1531,  2.5063],\n",
            "        [ 2.0678,  7.9634,  6.3124,  ...,  2.1696,  1.2098,  1.8323],\n",
            "        [ 3.5155,  4.1575,  2.2947,  ..., -0.9008, -2.5341,  3.0554],\n",
            "        ...,\n",
            "        [ 1.2332,  4.8813,  4.8060,  ...,  3.1973,  0.2435,  3.4893],\n",
            "        [ 9.1275,  7.5663,  0.1334,  ...,  2.0643, -1.7203,  1.4493],\n",
            "        [ 6.2587,  8.0277,  2.6966,  ...,  1.1279, -1.5200,  1.5118]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7281,  4.9172,  2.0488,  ...,  3.6336,  2.8009,  7.3414],\n",
            "        [ 3.8376,  5.7825,  2.0400,  ...,  0.5786,  0.2855,  7.0758],\n",
            "        [ 2.0214,  6.4826,  5.0139,  ..., -1.6851, -1.3421,  0.7087],\n",
            "        ...,\n",
            "        [ 2.5966,  7.5235,  4.6095,  ...,  2.7985, -1.1434,  4.8589],\n",
            "        [ 1.0043,  3.2449,  4.5816,  ...,  0.7963,  1.0932,  5.6722],\n",
            "        [ 3.6901, 10.5030,  0.4848,  ..., -1.6163,  1.3253, 11.3599]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.5112,  5.0400,  1.0966,  ...,  1.4790,  2.7312,  1.0504],\n",
            "        [ 2.8158,  6.1359,  2.1032,  ...,  2.0250,  1.3073,  2.7071],\n",
            "        [ 3.1268, 10.1846, -0.0541,  ..., -5.0491,  1.3270,  9.0180],\n",
            "        ...,\n",
            "        [ 4.0639,  6.0331,  5.1048,  ...,  0.9227,  3.3866,  2.1812],\n",
            "        [ 2.7403, 11.1010,  2.6317,  ...,  0.6138, -2.8333,  2.8990],\n",
            "        [ 6.3232,  7.6187, -0.1879,  ..., -0.2456,  0.4735, -0.7322]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0915,  3.1161,  4.5830,  ...,  0.8347, -0.3621,  6.4450],\n",
            "        [ 1.5750,  6.9362,  4.1541,  ..., -1.5070,  2.1336,  5.8980],\n",
            "        [ 5.9528,  5.7645,  1.2971,  ...,  0.5761,  0.7326, 10.1018],\n",
            "        ...,\n",
            "        [ 1.2985,  3.5274,  3.4066,  ...,  3.2722,  1.5136,  1.9976],\n",
            "        [ 4.7234,  4.4607,  1.9842,  ...,  0.6143,  6.7494,  6.1604],\n",
            "        [ 2.9544,  3.8132,  3.9665,  ...,  1.0914,  0.4679,  1.7664]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5608,  3.5985,  4.2553,  ...,  0.8410,  3.6928,  1.5237],\n",
            "        [ 2.8363,  3.8763,  4.2036,  ...,  0.9204,  3.3778,  3.3065],\n",
            "        [ 5.1991,  7.5654,  3.9425,  ..., -1.2644,  1.6469,  2.7320],\n",
            "        ...,\n",
            "        [ 0.3499,  6.6993,  4.4248,  ..., -1.6940,  3.3275,  6.1259],\n",
            "        [ 1.9232,  1.2244,  3.9555,  ...,  1.6367,  3.2201,  5.5593],\n",
            "        [ 3.0508,  4.7650,  0.7508,  ...,  2.0449,  1.1529,  1.5405]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9646,  6.0234,  5.3952,  ..., -0.7313,  1.4877,  2.0864],\n",
            "        [ 2.8196,  3.3113,  4.6760,  ...,  0.8490,  1.0190,  6.3336],\n",
            "        [-0.0854,  6.9334,  3.9410,  ..., -1.1857, -3.8028,  0.7745],\n",
            "        ...,\n",
            "        [ 1.4887,  5.5825,  4.9454,  ...,  3.3817,  1.5703,  1.2086],\n",
            "        [ 4.3310,  5.5009,  2.8388,  ...,  1.1869,  2.9526,  1.6407],\n",
            "        [ 5.0733,  5.6219,  2.0575,  ...,  1.1987,  4.2928,  1.9942]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 8.4085,  9.6409,  1.4917,  ...,  0.1633, -0.0452,  7.3300],\n",
            "        [ 4.2062,  8.5905,  0.3068,  ...,  1.7127,  6.0808,  7.6683],\n",
            "        [ 4.0753,  5.0373,  1.0006,  ...,  0.8070,  1.9075,  1.2671],\n",
            "        ...,\n",
            "        [ 6.2610, 12.0288,  3.0756,  ...,  2.4398,  3.5344,  3.8971],\n",
            "        [ 2.1787,  6.7209,  3.8120,  ..., -0.7335, -0.1573,  2.9742],\n",
            "        [ 0.2091,  5.4575,  6.6876,  ...,  2.6849, -2.3171,  4.8448]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1368,  7.5344,  7.4101,  ...,  0.3022,  2.7543,  0.0622],\n",
            "        [ 4.8938,  8.5273, -2.3646,  ..., -3.3067,  1.2413,  3.3073],\n",
            "        [ 4.9838,  4.2675,  2.9687,  ...,  0.4540, -1.8125,  3.0966],\n",
            "        ...,\n",
            "        [ 0.8360,  5.2394,  4.3249,  ...,  3.4203,  1.6287,  3.4675],\n",
            "        [ 4.7692,  5.2226,  1.0657,  ...,  4.1798,  2.7909,  4.0947],\n",
            "        [ 0.4107,  3.2166,  2.3920,  ...,  1.9741, -0.0189,  2.9641]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5998e+00,  4.2481e+00,  3.8369e+00,  ...,  3.3706e+00,\n",
            "          1.8407e+00,  8.4212e-01],\n",
            "        [ 3.1982e+00,  1.0287e+01,  2.9882e+00,  ...,  1.8818e+00,\n",
            "         -7.2064e-01,  3.9422e+00],\n",
            "        [ 4.8775e+00,  4.9286e+00,  1.9199e+00,  ...,  1.3100e-03,\n",
            "          1.0710e+00,  3.1120e+00],\n",
            "        ...,\n",
            "        [ 5.3731e+00,  6.7477e+00,  2.1960e+00,  ...,  2.1461e-01,\n",
            "          7.6339e-02,  1.3075e+00],\n",
            "        [ 4.6209e+00,  6.4382e+00,  4.9319e+00,  ...,  1.1233e+00,\n",
            "         -3.9283e-04,  8.3465e-01],\n",
            "        [ 3.3265e+00,  4.1012e+00,  1.1947e+00,  ...,  4.4320e+00,\n",
            "          2.2656e-01,  8.2862e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1199,  5.7999,  2.9199,  ...,  2.2176,  1.7797,  6.7594],\n",
            "        [-0.2514,  5.3719,  4.2430,  ...,  1.5103,  0.1870,  4.0177],\n",
            "        [-1.2014,  7.3064,  2.7811,  ..., -2.0079,  5.1874,  7.6911],\n",
            "        ...,\n",
            "        [ 2.6975,  7.5195,  5.2422,  ...,  2.6663,  0.1198,  4.2311],\n",
            "        [ 0.5633,  5.3562,  4.6181,  ..., -1.5003,  3.0574,  4.3682],\n",
            "        [ 6.5398,  5.1387,  1.7811,  ...,  3.9340,  1.7350,  2.1403]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.8382, 10.3966,  0.9942,  ...,  3.0292,  4.8970,  7.6915],\n",
            "        [ 4.6599,  5.9434,  3.0766,  ...,  2.3350,  0.7021,  1.9919],\n",
            "        [-1.7111,  4.2868,  5.2624,  ..., -2.4239, -0.2388,  2.8164],\n",
            "        ...,\n",
            "        [ 1.0496,  3.6955,  4.2122,  ...,  2.1186,  3.2406,  2.3389],\n",
            "        [ 4.4190,  9.3536,  0.5207,  ...,  1.2612,  5.7982,  2.9973],\n",
            "        [ 4.3448,  7.6881,  1.8007,  ...,  0.8346,  3.1885,  2.0495]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5194,  3.5586,  6.9799,  ..., -1.0500,  0.9919,  7.7042],\n",
            "        [ 4.2498,  7.7451, -0.4864,  ...,  0.9342,  0.3485,  0.3129],\n",
            "        [-0.5553,  5.2199,  6.9777,  ..., -2.2757, -0.0243,  1.6479],\n",
            "        ...,\n",
            "        [ 1.4095,  5.2494, -1.1625,  ...,  0.2586, -1.4312,  5.7386],\n",
            "        [ 4.6646,  7.1954,  3.3992,  ...,  1.2849, -0.3571,  0.7939],\n",
            "        [ 4.8515,  6.8762,  3.3049,  ...,  2.0278,  3.5206,  1.7179]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3396,  3.7937,  3.0767,  ...,  0.6730,  0.6032,  4.9853],\n",
            "        [ 1.8470,  5.9022,  2.5624,  ...,  5.0802,  0.9130,  3.1342],\n",
            "        [ 2.3749,  7.1661,  1.8282,  ...,  1.0893,  5.5077,  3.2994],\n",
            "        ...,\n",
            "        [ 0.8781,  2.7872,  4.2862,  ...,  1.9359,  2.0220,  2.9496],\n",
            "        [ 1.2017,  4.2971,  4.9495,  ...,  2.5914,  3.1748,  1.8551],\n",
            "        [ 3.2412,  5.6137,  3.8244,  ..., -0.2774,  0.2119,  1.1115]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8624,  8.7219,  1.5868,  ...,  6.0308,  2.7936,  2.5385],\n",
            "        [ 4.6900,  7.1830,  4.7013,  ...,  2.7129, -1.8799,  2.1208],\n",
            "        [ 5.6175,  7.9666,  1.4307,  ...,  5.4025,  3.3986,  4.1555],\n",
            "        ...,\n",
            "        [ 1.7193,  6.5197,  9.2404,  ..., -0.1012,  2.0486,  6.1126],\n",
            "        [ 4.7388,  9.1335,  3.9366,  ..., -0.8909,  2.9753,  8.0091],\n",
            "        [ 4.2240,  6.4764,  1.8705,  ...,  2.5261, -2.0769,  0.9107]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[4.4067, 7.0483, 0.9461,  ..., 2.0367, 2.3830, 0.7805],\n",
            "        [0.9666, 3.4004, 4.1503,  ..., 3.7092, 1.7977, 2.9869],\n",
            "        [3.9043, 4.5408, 2.9464,  ..., 5.2700, 3.4018, 6.0744],\n",
            "        ...,\n",
            "        [5.0472, 5.4560, 4.9699,  ..., 1.9747, 1.0057, 1.0239],\n",
            "        [1.6862, 4.2678, 1.2991,  ..., 2.3565, 3.4145, 0.4726],\n",
            "        [1.2828, 6.6320, 5.3062,  ..., 0.1001, 3.6548, 4.0696]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1713,  3.0795,  2.2403,  ...,  3.2913, -0.6427,  0.8734],\n",
            "        [ 3.9388,  5.2277,  3.8424,  ...,  1.1469,  0.4503,  2.6978],\n",
            "        [ 0.4275,  9.8230,  4.4923,  ...,  1.8329,  7.7110,  5.1827],\n",
            "        ...,\n",
            "        [ 4.2857,  4.0899,  1.9442,  ...,  0.5756, -0.5412,  1.0778],\n",
            "        [ 4.4051,  4.9696,  0.9851,  ...,  4.1906,  1.4968,  2.1283],\n",
            "        [-0.5998,  2.2038,  3.0857,  ...,  1.8368, -0.8402,  3.1225]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9474, 11.6473,  4.3297,  ...,  2.4073,  0.0581,  4.3256],\n",
            "        [ 1.1968,  4.0094,  4.0560,  ...,  3.7256,  1.6796,  2.7989],\n",
            "        [ 5.2200, 10.1854,  5.2403,  ..., -1.0510,  0.2812,  1.9263],\n",
            "        ...,\n",
            "        [ 0.9539, 10.8089, -0.3483,  ..., -1.7942, -2.4995,  6.1469],\n",
            "        [ 2.8570,  3.4116,  3.2388,  ...,  1.8165,  2.4619,  3.9767],\n",
            "        [ 0.0668,  3.2679,  6.4382,  ..., -2.0142,  2.5617,  7.1628]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7838,  6.9802,  1.9215,  ...,  1.3022, -0.8484,  5.4390],\n",
            "        [ 1.3492,  4.5811,  2.7021,  ...,  2.8437,  1.2819,  4.3896],\n",
            "        [ 3.1459,  4.6599,  4.3709,  ...,  1.7456,  4.1339,  1.1059],\n",
            "        ...,\n",
            "        [ 1.8248,  3.3523,  1.7473,  ...,  2.8317,  2.5601,  2.5034],\n",
            "        [ 4.9003,  8.7262, -0.2813,  ..., -0.1541,  0.6809,  9.5616],\n",
            "        [ 4.3277,  7.5124,  2.4578,  ...,  2.2451, -0.4066,  0.9320]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4398,  5.0202,  4.9070,  ...,  3.6523,  2.1774,  1.0723],\n",
            "        [ 3.0331,  3.6632,  3.6318,  ...,  3.1502,  4.1622,  0.9174],\n",
            "        [ 1.6498,  6.7678,  1.9022,  ..., -0.3794,  8.6466,  6.5050],\n",
            "        ...,\n",
            "        [ 4.7200,  7.5781,  3.5467,  ..., -0.6234,  4.9505,  4.1390],\n",
            "        [ 0.9245,  4.5173,  4.4804,  ...,  3.4533,  2.3799,  3.2220],\n",
            "        [ 1.7711,  7.1733,  4.8853,  ...,  1.5605,  5.2537,  1.7296]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8148,  5.6683,  3.7830,  ...,  0.1487, -3.0500,  1.3313],\n",
            "        [ 4.5706,  2.4016,  1.5472,  ...,  2.8887,  0.0290,  3.7820],\n",
            "        [ 0.7133,  8.7038,  3.0253,  ..., -1.6072,  5.6444,  5.9329],\n",
            "        ...,\n",
            "        [ 6.6347,  6.2956,  0.8325,  ...,  4.0413, -0.8351,  1.2930],\n",
            "        [ 0.7295,  2.0368,  6.9013,  ..., -0.8407,  4.1970,  8.4360],\n",
            "        [ 4.9389,  5.7813, -0.6275,  ...,  1.4242, -0.2767,  3.1008]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5780,  6.9810,  4.5797,  ..., -0.9960,  1.0252,  1.0965],\n",
            "        [ 0.9964,  3.2462,  3.6478,  ...,  2.1012,  3.8592,  2.3604],\n",
            "        [ 4.8133,  9.7436,  4.1473,  ...,  1.2583,  1.5016,  2.8021],\n",
            "        ...,\n",
            "        [ 3.1604,  4.2970,  4.9210,  ..., -0.1535,  2.1907,  4.6532],\n",
            "        [ 2.3294,  3.3669,  3.8009,  ...,  1.3555,  0.4134,  0.3813],\n",
            "        [ 1.8332,  9.5058,  3.0538,  ..., -0.7387, -0.9797,  3.8678]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4325,  4.6504,  3.5851,  ...,  2.5290,  1.9893,  3.5608],\n",
            "        [ 6.3335,  9.0929,  2.6120,  ...,  3.9398,  3.8747,  3.7060],\n",
            "        [ 1.6022,  2.0657,  0.9793,  ...,  3.6491,  2.8749,  2.9160],\n",
            "        ...,\n",
            "        [ 3.8471,  4.7434,  2.8246,  ...,  2.7130,  2.4907, -0.4363],\n",
            "        [ 4.8936,  5.5518,  2.6767,  ..., -1.0974,  2.5041,  2.6059],\n",
            "        [-0.5579,  5.7280,  2.2480,  ...,  0.1672, 10.2220,  7.6952]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4537,  4.2358,  6.1234,  ...,  1.5464,  2.0223,  5.3904],\n",
            "        [ 6.9003,  9.8926,  2.8523,  ...,  0.7012,  2.2266,  2.7556],\n",
            "        [ 4.6850,  5.7435, -0.2727,  ...,  4.8596,  2.9132,  1.1152],\n",
            "        ...,\n",
            "        [ 1.4269,  4.3315,  2.5505,  ...,  3.2845,  1.1756,  2.8492],\n",
            "        [ 2.4787,  8.3590,  7.3833,  ...,  2.3005,  1.5714,  4.4946],\n",
            "        [ 2.7962,  6.0426,  3.7812,  ...,  4.4179,  2.1077,  2.1821]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4236e+00,  4.5550e+00,  4.7658e-01,  ..., -7.9854e-01,\n",
            "         -3.0934e+00,  8.6334e-03],\n",
            "        [ 3.1490e+00,  4.3229e+00,  3.4591e+00,  ...,  1.8789e+00,\n",
            "          3.4298e+00,  3.3085e+00],\n",
            "        [ 1.5301e+00,  7.6866e+00,  4.0765e+00,  ...,  1.4520e+00,\n",
            "          4.7973e+00,  2.4083e+00],\n",
            "        ...,\n",
            "        [ 5.5783e+00,  7.0091e+00,  1.7531e+00,  ...,  1.8860e+00,\n",
            "         -5.1327e-01,  4.1732e+00],\n",
            "        [ 4.4791e+00,  5.7578e+00,  3.2454e+00,  ...,  2.0034e+00,\n",
            "         -9.1114e-01,  2.9719e+00],\n",
            "        [ 5.0807e+00,  1.3062e+01,  3.7613e+00,  ...,  4.1654e-01,\n",
            "          1.0529e-01,  3.1399e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 8.3056, 13.8073,  3.8889,  ...,  0.3367,  0.5869,  3.0912],\n",
            "        [ 7.7033,  9.6784,  2.9549,  ...,  0.3127,  1.0433,  9.5722],\n",
            "        [ 3.7870,  7.0613,  2.5580,  ..., -3.6453,  4.3832,  8.7967],\n",
            "        ...,\n",
            "        [ 2.5485,  4.4657, -0.9505,  ..., -0.4102,  0.3583,  9.3146],\n",
            "        [ 2.6739,  8.3708,  5.8032,  ...,  0.1891,  7.2310,  3.7779],\n",
            "        [ 5.6275,  7.2232, -2.0149,  ...,  1.5964,  3.7823,  3.4037]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.9398,  9.1248,  0.6254,  ...,  1.1918,  3.3506,  2.4701],\n",
            "        [ 1.6735,  4.0258,  2.1099,  ...,  1.3572,  1.7457,  3.9081],\n",
            "        [ 7.4177,  9.0006,  3.8191,  ...,  1.5727, -0.4989,  1.4033],\n",
            "        ...,\n",
            "        [ 4.3169,  6.4835,  1.6070,  ...,  2.7104,  2.8394,  4.3381],\n",
            "        [ 3.3402,  4.6076,  1.4236,  ...,  1.6767,  4.2596,  4.7767],\n",
            "        [ 3.9239, 10.1023, -2.0702,  ...,  0.5578,  3.0865,  8.4071]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1145,  6.0269,  4.2477,  ...,  0.2200,  0.2649,  2.7099],\n",
            "        [ 3.3371,  4.1697, -1.3436,  ...,  3.5183,  2.3416,  1.0205],\n",
            "        [ 3.2176, 10.7969,  2.7291,  ..., -2.5752, -2.0912,  7.6205],\n",
            "        ...,\n",
            "        [-2.4884,  7.3903,  2.9835,  ..., -1.3737, -2.6261,  9.9692],\n",
            "        [ 2.0612,  6.4597,  4.6322,  ..., -1.3446, -2.6075,  0.0562],\n",
            "        [ 1.7404,  8.5691,  3.5284,  ...,  1.0292,  4.6537,  5.5730]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6228,  5.6904,  2.9416,  ...,  2.1433,  6.2820,  5.0974],\n",
            "        [ 0.5063,  5.1647,  7.9202,  ..., -0.9607,  1.7769,  9.6995],\n",
            "        [ 3.3940,  8.2359,  4.1611,  ..., -0.9809,  6.7672,  5.1294],\n",
            "        ...,\n",
            "        [ 2.9940,  7.5441,  1.8252,  ..., -0.0516,  1.7693,  4.0277],\n",
            "        [ 1.7572,  3.8988,  6.6269,  ...,  1.2125,  0.2437,  4.6309],\n",
            "        [ 5.4828,  6.9063,  2.0983,  ..., -2.5667, -1.3906,  5.0343]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-7.2535e-01,  3.5991e+00,  4.6235e+00,  ..., -1.0970e-02,\n",
            "         -8.6755e-01,  3.3770e+00],\n",
            "        [ 3.6648e+00,  1.3118e+01,  4.9414e+00,  ...,  1.1362e+00,\n",
            "          2.9857e-01,  4.3442e+00],\n",
            "        [ 3.8565e+00,  7.9991e+00,  3.5535e+00,  ...,  2.4156e+00,\n",
            "          1.5081e+00,  1.2695e+00],\n",
            "        ...,\n",
            "        [ 3.5647e+00,  5.2373e+00, -9.7892e-01,  ..., -2.1935e+00,\n",
            "          4.9498e-01,  7.1473e+00],\n",
            "        [ 3.4273e+00,  2.3884e+00,  1.4547e+00,  ...,  6.6063e-01,\n",
            "         -9.3819e-01,  6.9554e-01],\n",
            "        [ 4.9858e+00,  9.1674e+00,  5.2095e+00,  ..., -2.7553e-01,\n",
            "         -2.4372e-01,  5.4064e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4499,  2.9746,  2.3918,  ...,  2.0931, -0.3838,  3.1805],\n",
            "        [-2.7385,  7.9660,  5.4532,  ..., -3.7132,  0.3767,  8.3471],\n",
            "        [ 5.3809,  8.7048,  1.0115,  ...,  2.4714,  0.3795,  2.4531],\n",
            "        ...,\n",
            "        [ 0.1811,  4.3569,  5.9145,  ...,  2.0754,  1.3973,  2.6754],\n",
            "        [ 0.4129,  2.2434,  5.8317,  ...,  2.1731,  0.4762,  5.5504],\n",
            "        [ 7.2385,  5.2585,  0.8285,  ...,  3.5275, -0.6999,  2.1993]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4037,  4.5614,  5.5418,  ...,  1.3363,  2.0771,  3.5400],\n",
            "        [ 4.3826,  4.3342, -0.2932,  ...,  2.5534,  1.0395,  3.9432],\n",
            "        [ 4.9289,  5.2747,  0.6301,  ...,  3.3244,  1.3514,  3.2319],\n",
            "        ...,\n",
            "        [ 3.9948,  5.5914,  5.1693,  ...,  3.9209,  1.2579,  1.0080],\n",
            "        [ 0.7859,  3.3521,  3.2571,  ...,  2.6680,  1.7704,  2.1836],\n",
            "        [-1.1066,  7.3317,  0.9096,  ..., -1.1875, -1.8503,  8.4410]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1080e+00,  1.0086e+01,  2.8572e+00,  ..., -2.9969e-01,\n",
            "          8.4984e+00,  6.6018e+00],\n",
            "        [ 2.2536e+00,  2.3235e+00,  5.0921e+00,  ...,  1.9671e+00,\n",
            "          1.3814e+00, -3.1589e-04],\n",
            "        [ 1.8363e+00,  4.7591e+00,  4.2736e+00,  ...,  4.8436e+00,\n",
            "          9.2370e-01,  1.2496e+00],\n",
            "        ...,\n",
            "        [ 3.5561e+00,  6.2634e+00,  4.9162e+00,  ..., -4.8989e+00,\n",
            "         -1.2618e+00,  6.0782e+00],\n",
            "        [ 4.2641e-02,  1.6594e+00,  7.9948e+00,  ..., -6.7903e-01,\n",
            "          2.1123e+00,  1.9368e+00],\n",
            "        [ 4.5333e+00,  1.1370e+01,  4.9375e+00,  ...,  2.1649e+00,\n",
            "          2.3395e-01,  4.9224e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3481,  5.7801,  7.4637,  ..., -1.2741,  1.4899,  0.0527],\n",
            "        [ 3.0198,  3.2215,  1.3939,  ..., -1.5352, -0.7444,  5.2999],\n",
            "        [ 0.9691,  4.5323,  4.3830,  ...,  0.8436,  1.1378,  1.1558],\n",
            "        ...,\n",
            "        [ 2.8188,  2.8935,  2.6436,  ...,  0.7851, -2.4397,  1.6466],\n",
            "        [ 3.5693,  7.4797,  0.2547,  ..., -1.1694,  0.0343,  4.9710],\n",
            "        [ 1.8566,  3.6560,  4.8938,  ...,  2.0834,  4.0205,  2.8150]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7620,  6.8748,  1.4659,  ...,  3.9449,  3.8799,  3.5752],\n",
            "        [ 2.9712,  6.8880,  4.4894,  ...,  0.4779,  0.8683,  1.1113],\n",
            "        [ 1.3294,  2.6869,  7.2142,  ..., -1.0796,  0.9077,  2.2738],\n",
            "        ...,\n",
            "        [ 2.1719,  4.7068,  3.6682,  ...,  4.0320,  1.8399,  1.1490],\n",
            "        [ 5.3948,  3.1530,  1.6324,  ...,  3.6901, -0.3447, -0.2838],\n",
            "        [ 0.8996, 10.0151,  8.6492,  ..., -3.7583,  3.9616,  1.5435]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4254,  3.5470,  1.9848,  ...,  3.5005, -0.2683,  2.5795],\n",
            "        [ 1.8877,  2.0568,  4.7446,  ...,  1.6196,  0.4058,  4.1220],\n",
            "        [ 1.0687,  3.6690,  2.7553,  ...,  0.9635, -0.5013,  3.5830],\n",
            "        ...,\n",
            "        [ 2.1112,  4.2033,  3.7877,  ...,  3.4779,  1.5853,  1.8379],\n",
            "        [ 2.8194,  4.3270,  5.2249,  ...,  2.8998,  4.4771,  1.7075],\n",
            "        [ 2.5026,  5.8853,  4.8404,  ..., -0.8783,  0.0688,  2.5432]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.7455, 10.5778,  3.3792,  ...,  3.6323,  0.7890,  3.9186],\n",
            "        [ 1.5496,  4.6244,  3.2029,  ..., -0.1652,  2.8352,  2.1658],\n",
            "        [ 1.8830,  9.4629,  2.9032,  ..., -0.3250,  9.8464,  6.4269],\n",
            "        ...,\n",
            "        [ 1.1146,  5.0459,  2.9649,  ...,  0.7672, -1.7801,  1.9566],\n",
            "        [ 6.6074,  6.0692, -2.3896,  ...,  1.2521, -0.9261,  2.6289],\n",
            "        [-1.0193,  4.4129,  3.0846,  ..., -4.2013,  0.3248,  3.1189]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8696,  4.2181,  3.6079,  ..., -0.1471,  0.0777, -0.0561],\n",
            "        [ 0.4509,  4.6192,  3.1514,  ...,  1.5878,  0.1831,  1.4662],\n",
            "        [ 2.3552,  3.2800,  6.4364,  ..., -1.5997,  2.1407,  3.5848],\n",
            "        ...,\n",
            "        [-0.0630,  4.4197,  8.1573,  ..., -0.3552,  1.4818,  6.9694],\n",
            "        [ 4.1428, 10.7762,  5.6172,  ..., -0.9773,  2.5536,  2.6428],\n",
            "        [ 4.4393,  8.9706, -2.1649,  ...,  3.5187,  5.3226,  0.9587]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.8306,  5.3701,  1.5637,  ...,  3.9816,  3.2455,  5.1703],\n",
            "        [ 3.7728,  5.7649,  6.0197,  ...,  0.1315, -1.6592, -2.5375],\n",
            "        [ 3.9450,  4.4684,  1.9247,  ...,  0.4166,  0.4408,  2.4986],\n",
            "        ...,\n",
            "        [ 5.0611,  9.5352,  4.2450,  ...,  0.4693,  3.5534,  3.9615],\n",
            "        [ 5.1462,  7.2540,  0.6132,  ...,  1.9499,  6.4917,  4.2184],\n",
            "        [ 2.2684,  4.9566,  0.8705,  ...,  2.0846,  2.6166,  0.9741]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0490,  4.4921, -0.5288,  ...,  3.7153,  1.3128,  2.8001],\n",
            "        [-0.1527,  4.7602,  6.1465,  ..., -2.4081,  4.3156,  7.9509],\n",
            "        [ 3.2971, 10.6509,  5.2359,  ...,  2.9682, -0.3820,  3.4091],\n",
            "        ...,\n",
            "        [ 5.0599,  6.0152,  0.0550,  ...,  1.3720, -0.1614,  3.2962],\n",
            "        [ 1.1773,  9.4177,  0.1228,  ..., -1.8729,  0.2368,  8.8654],\n",
            "        [ 4.1972,  5.5612,  2.2975,  ..., -0.2318, -0.6307,  9.7662]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5254,  3.0988,  0.6739,  ...,  0.2070, -2.1258,  2.0448],\n",
            "        [ 3.8956,  6.2736, -1.3211,  ...,  0.3440,  6.0410,  4.4340],\n",
            "        [ 6.5148, 11.5877,  1.0147,  ...,  3.8033,  4.0152,  5.1328],\n",
            "        ...,\n",
            "        [ 4.0316,  3.5658,  2.8475,  ...,  0.5901, -0.2004, -0.3865],\n",
            "        [ 0.0502,  2.0872,  3.8422,  ...,  1.0646, -1.6009,  6.5459],\n",
            "        [ 0.9410,  4.8809,  7.2147,  ..., -0.8674,  3.1993,  1.6467]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8976,  2.8373,  2.6734,  ...,  2.5891,  2.0640,  1.8947],\n",
            "        [ 3.5268,  5.8569,  3.4780,  ..., -0.9348,  3.3067,  3.2308],\n",
            "        [ 1.3481,  3.4229,  3.8273,  ...,  1.9091,  2.0942,  3.0157],\n",
            "        ...,\n",
            "        [-0.5883,  7.4940,  4.0700,  ...,  1.9564, -2.4233,  3.7287],\n",
            "        [ 2.1844,  3.8480,  1.7076,  ...,  2.1332,  0.1066, -0.0195],\n",
            "        [ 2.4222,  3.1542,  2.1419,  ..., -1.1760,  2.5542,  0.8784]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8923e+00,  3.4693e+00,  3.3679e+00,  ...,  3.4986e+00,\n",
            "          3.6106e+00,  7.1358e+00],\n",
            "        [ 3.1654e+00,  3.2638e+00,  5.1725e+00,  ...,  1.0846e+00,\n",
            "         -3.0291e-01, -2.2911e+00],\n",
            "        [ 4.0779e+00,  5.1211e+00, -5.6262e-01,  ...,  3.1690e+00,\n",
            "         -2.2567e+00,  1.9412e+00],\n",
            "        ...,\n",
            "        [ 2.7685e+00,  7.0013e+00,  3.0073e+00,  ...,  2.5193e+00,\n",
            "          4.5626e+00,  3.4641e+00],\n",
            "        [-1.4638e-03,  5.4829e+00,  7.6641e+00,  ..., -3.6948e+00,\n",
            "         -1.4377e+00,  1.5872e+00],\n",
            "        [ 2.4876e+00,  1.2052e+01,  3.4699e+00,  ..., -2.4999e+00,\n",
            "         -7.9128e-01,  4.8101e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.8414,  4.6653,  0.3330,  ...,  2.7486,  3.7720,  1.8076],\n",
            "        [ 6.5789,  9.7268,  2.1393,  ..., -3.0273, -0.4210,  5.8024],\n",
            "        [ 4.9995,  8.1014,  2.6818,  ...,  1.4219,  3.7433,  4.2967],\n",
            "        ...,\n",
            "        [ 3.0711,  7.9824,  1.9117,  ...,  0.0423,  7.1211,  5.7516],\n",
            "        [ 2.8619,  9.4510,  4.8325,  ..., -1.4327, -0.5610,  5.9989],\n",
            "        [ 0.7977,  3.7425,  6.5537,  ...,  0.3179, -0.7758,  5.8451]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6725,  2.9221,  1.3408,  ...,  3.4647,  1.9808,  1.1052],\n",
            "        [ 3.4020,  4.9602,  3.3587,  ...,  5.1470,  3.5509,  5.1351],\n",
            "        [ 3.3861,  4.8086,  2.0389,  ...,  2.6435, -1.4138,  1.0345],\n",
            "        ...,\n",
            "        [ 1.2734,  2.9240,  2.3381,  ...,  0.5544,  1.6179,  3.5313],\n",
            "        [-1.9302,  4.3372,  2.9805,  ...,  0.5450, -1.6683,  8.3757],\n",
            "        [ 0.9979,  8.2574,  5.6397,  ..., -0.0939,  2.8361,  3.8221]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0072,  5.0409,  4.1287,  ...,  2.5917,  2.2611,  2.7981],\n",
            "        [ 2.0330,  6.9815, -0.3484,  ..., -1.1583,  0.5545,  7.2663],\n",
            "        [ 0.7322,  3.8257,  6.6821,  ..., -1.1733,  2.3302,  6.7707],\n",
            "        ...,\n",
            "        [ 3.4462,  7.6972,  4.1567,  ..., -3.8157, -1.0022,  5.0571],\n",
            "        [ 2.9058,  4.8282,  4.3421,  ...,  2.3053,  0.1401,  0.3647],\n",
            "        [-0.4489,  4.4449,  5.2656,  ...,  0.0878,  3.1206,  5.0774]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6064,  4.5630,  4.7366,  ...,  0.3942,  2.4598,  0.0995],\n",
            "        [ 2.8607,  7.6109,  1.7158,  ...,  0.5933,  6.5485,  3.4896],\n",
            "        [ 2.7153,  4.5007,  3.1554,  ...,  1.3012,  0.5083,  1.2525],\n",
            "        ...,\n",
            "        [ 4.2784,  6.2323,  3.2770,  ..., -1.7062, -0.6216,  1.4631],\n",
            "        [ 1.1638,  7.6422,  5.0359,  ..., -0.3809,  5.3698,  5.3459],\n",
            "        [ 1.9951,  5.0105,  3.6067,  ...,  0.3261,  0.8762, -0.5790]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.5747,  3.8851,  0.5483,  ...,  1.2600, -4.1196,  2.3865],\n",
            "        [ 5.2295,  6.8995,  3.4597,  ...,  3.3628, -0.6521,  0.7728],\n",
            "        [ 1.7860,  5.2727,  2.0062,  ..., -0.7414,  4.4060,  0.2620],\n",
            "        ...,\n",
            "        [ 3.6912,  8.9783,  1.9715,  ...,  3.1119,  1.4558,  4.7981],\n",
            "        [ 2.8250, 11.2364,  2.9188,  ...,  2.0791, -1.6950,  2.2127],\n",
            "        [ 3.6264, 10.0633,  2.0421,  ...,  3.2854,  3.7416,  4.5688]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.1446e+00,  3.9649e+00,  7.2440e-01,  ...,  8.4374e-01,\n",
            "         -6.5476e-01,  3.7683e+00],\n",
            "        [ 3.4964e+00,  7.9499e+00,  2.9175e+00,  ...,  8.6066e-01,\n",
            "         -4.9406e-01,  5.2536e-03],\n",
            "        [ 2.5970e+00,  6.3153e+00,  4.6624e+00,  ...,  1.1224e+00,\n",
            "          3.5136e+00,  2.8094e+00],\n",
            "        ...,\n",
            "        [-9.8707e-03,  6.2602e+00,  5.4436e+00,  ..., -2.3374e+00,\n",
            "         -2.1677e+00,  1.9941e+00],\n",
            "        [ 3.5108e+00,  6.6287e+00, -2.0339e+00,  ...,  3.5920e-01,\n",
            "          4.1091e+00,  5.0126e+00],\n",
            "        [ 2.6326e+00,  7.5000e+00,  5.2488e+00,  ...,  7.4983e-01,\n",
            "          4.3966e-02,  6.8011e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.3810,  7.5144,  0.9690,  ...,  2.6670,  1.5538,  2.1727],\n",
            "        [ 1.7602,  8.4047,  4.2860,  ...,  0.7322, -0.4040,  4.4081],\n",
            "        [ 2.6982,  4.8162,  3.5532,  ..., -1.6212,  2.3296,  1.4705],\n",
            "        ...,\n",
            "        [ 0.5330,  5.0320,  4.1204,  ...,  3.3832,  1.6975,  2.2579],\n",
            "        [ 2.5960,  5.8362,  4.3040,  ...,  0.3160,  7.1063,  5.4555],\n",
            "        [ 4.4227,  5.7375,  2.3222,  ...,  0.9176,  0.0269,  2.3336]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3458,  6.7694,  1.3605,  ...,  2.7086,  6.5448,  6.8956],\n",
            "        [ 6.1102,  7.0069, -0.0863,  ...,  1.4114, -3.0656,  0.6158],\n",
            "        [ 1.7189,  6.9407, -0.7535,  ...,  0.1879, -1.0242,  6.2349],\n",
            "        ...,\n",
            "        [ 3.6979,  5.5276,  2.4475,  ...,  2.1840,  4.9353,  6.1597],\n",
            "        [ 1.4789,  8.5288,  1.7782,  ...,  1.5413,  4.7991,  4.0666],\n",
            "        [ 1.2949,  4.9754,  2.2592,  ...,  1.3744, -1.0355,  4.8886]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0868,  5.3253,  4.2812,  ...,  1.1306,  3.8961,  3.2776],\n",
            "        [ 2.6897,  7.7185,  6.6962,  ..., -6.0053, -0.3497,  6.0323],\n",
            "        [ 4.3388,  4.5396,  0.1166,  ...,  2.8991,  0.4507,  3.0965],\n",
            "        ...,\n",
            "        [ 4.0810,  4.5804,  1.5740,  ..., -0.6069,  7.1046,  9.0973],\n",
            "        [ 4.9553,  9.7969,  2.7159,  ..., -2.2714,  0.8081,  5.8724],\n",
            "        [ 0.6005,  8.1315,  4.2344,  ...,  2.3058, -1.9072,  3.0798]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5527,  7.3497,  0.1514,  ..., -4.4988,  2.6329,  6.4338],\n",
            "        [ 2.5334,  4.3878,  1.7422,  ...,  2.5491, -0.9912,  2.7322],\n",
            "        [ 3.7243,  7.2899,  2.9363,  ..., -0.2024,  7.1587,  8.5300],\n",
            "        ...,\n",
            "        [ 3.4914,  4.6588,  1.4505,  ...,  1.9663,  0.8551,  2.7119],\n",
            "        [ 3.5423,  5.9610,  1.3625,  ...,  3.9247,  3.8125,  4.8641],\n",
            "        [ 5.3502, 11.7541,  1.2816,  ...,  0.4708, -4.6760,  5.1996]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1048, 12.7305,  5.4740,  ..., -2.1599, -1.5564,  3.9545],\n",
            "        [ 5.3913,  7.2868,  4.0469,  ...,  2.3451,  4.4565,  1.7051],\n",
            "        [ 3.6408,  7.0240,  1.7823,  ...,  4.2246, -0.1758,  1.3208],\n",
            "        ...,\n",
            "        [ 2.8558,  8.3757,  1.5085,  ...,  0.8882,  6.0683,  4.4988],\n",
            "        [ 0.6182,  7.2659,  3.6983,  ...,  1.5450, -0.2184,  4.5425],\n",
            "        [ 4.3392,  4.0512,  0.7944,  ...,  2.3665,  2.2882,  3.4559]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8531,  6.5314,  3.1617,  ..., -1.5035,  2.5556,  3.5681],\n",
            "        [ 1.5357,  5.0428,  3.2360,  ...,  0.0175, -0.3677,  1.9312],\n",
            "        [ 2.4390,  7.1040,  3.2147,  ..., -0.9407,  0.3191, -0.4718],\n",
            "        ...,\n",
            "        [-3.6333,  5.8665,  2.8742,  ..., -1.0070, -3.3432,  8.8438],\n",
            "        [ 3.7722,  6.6153,  3.0446,  ..., -2.2250,  4.4613,  3.3249],\n",
            "        [ 4.3095,  5.6246,  0.5349,  ...,  1.4382, -1.1106,  3.7489]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.5494, 10.9542, -1.7050,  ..., -2.5605,  2.6793,  7.5744],\n",
            "        [ 3.8351,  6.5497,  3.7645,  ..., -0.4076, -0.7879,  9.5978],\n",
            "        [ 2.2591,  6.1509,  4.6171,  ...,  3.0360,  2.1287,  4.3056],\n",
            "        ...,\n",
            "        [ 1.6452,  7.1002,  5.4175,  ...,  3.2723,  2.9823,  2.0326],\n",
            "        [-0.8324,  2.4234,  5.8513,  ..., -1.5184,  0.1860,  2.9452],\n",
            "        [ 4.3992,  7.6666,  1.7857,  ..., -0.6961,  3.9238,  4.8147]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.0024,  8.6439,  1.7972,  ..., -1.8582,  2.8248,  1.1929],\n",
            "        [ 4.2058,  8.8608, -1.9052,  ..., -1.3275, -0.4748,  4.1972],\n",
            "        [ 6.9420,  6.4281, -1.3313,  ...,  1.0329,  1.8596,  1.1638],\n",
            "        ...,\n",
            "        [ 3.8015,  6.9464,  1.8599,  ...,  3.9965,  2.3981, -0.4684],\n",
            "        [ 1.9893, 10.4589,  6.5212,  ...,  1.1771,  0.4061,  3.3358],\n",
            "        [ 5.2548,  7.6696,  2.2623,  ..., -0.5132,  4.8468,  7.7681]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9877,  6.3049,  2.6516,  ...,  5.4203,  2.2226,  4.0083],\n",
            "        [ 3.0234,  5.0733,  1.5586,  ...,  3.4306,  2.6005,  2.6756],\n",
            "        [ 2.1851,  3.5352,  4.6437,  ..., -0.2694,  3.4796,  7.0038],\n",
            "        ...,\n",
            "        [ 1.7905,  4.5225, -0.0248,  ...,  1.3581,  2.3729,  4.5432],\n",
            "        [ 3.3344,  5.2431,  6.2363,  ...,  0.3656,  1.7034,  0.3527],\n",
            "        [ 3.5413,  4.2679,  3.8137,  ...,  2.6072,  4.8254,  2.1625]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4207,  6.3616,  2.7108,  ...,  1.9999, -0.8625,  1.0437],\n",
            "        [ 5.2056,  6.0234,  0.3242,  ...,  2.0222,  0.1849,  1.3777],\n",
            "        [ 3.4049,  8.4438,  2.3573,  ...,  5.5481,  2.3978,  3.6127],\n",
            "        ...,\n",
            "        [ 2.4545,  5.9953,  4.3660,  ...,  2.4276,  1.0366,  1.6925],\n",
            "        [ 3.1251,  6.4302,  3.2610,  ...,  1.4315,  4.9104,  1.1604],\n",
            "        [ 2.9747, 10.7537, -0.2806,  ..., -3.6502, -2.6344,  7.0613]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6648,  9.6111, -0.3995,  ..., -2.0796,  0.8617,  6.8657],\n",
            "        [ 1.3594,  3.5832,  1.9696,  ...,  0.9388,  0.3810,  4.2117],\n",
            "        [ 3.5956,  5.4548,  2.8353,  ..., -0.5337,  1.0322,  0.1979],\n",
            "        ...,\n",
            "        [ 3.9291,  4.1883,  1.7467,  ..., -0.4024, -1.3214,  2.3119],\n",
            "        [ 3.3235,  6.2548,  3.6379,  ...,  1.5549,  1.5013, -0.7504],\n",
            "        [ 1.2051,  4.7924,  4.3563,  ...,  4.6127,  1.7390,  1.8023]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.7279,  4.9237,  2.1678,  ...,  0.4227, -2.6403,  1.0017],\n",
            "        [ 1.8794,  3.4160,  2.9981,  ...,  3.4798,  2.6447,  1.2426],\n",
            "        [ 2.4697,  3.9406,  3.8180,  ...,  2.3135,  4.1362,  1.9919],\n",
            "        ...,\n",
            "        [ 6.8920,  4.2936,  0.3656,  ...,  3.1058, -0.6256,  0.7201],\n",
            "        [ 0.5174,  7.8421,  2.1218,  ..., -0.5195,  7.5737,  4.7951],\n",
            "        [ 6.1218, 12.0674,  3.3815,  ..., -1.4322,  2.6973,  3.5600]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9377,  4.6028,  1.1890,  ...,  4.8096,  2.1502,  5.5439],\n",
            "        [ 1.3959,  7.0124,  2.4357,  ...,  1.4530,  1.2607, -1.5899],\n",
            "        [ 5.0546,  5.0915,  3.8980,  ...,  3.6225,  0.3924,  2.1291],\n",
            "        ...,\n",
            "        [ 5.1001,  3.5605, -1.5879,  ...,  0.6623,  0.2349,  3.8266],\n",
            "        [ 2.9329,  5.4365,  3.9479,  ...,  2.2994,  4.4857,  2.1520],\n",
            "        [ 4.1592,  7.2196,  0.4167,  ...,  2.8020,  2.3496,  0.6375]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3507,  7.5551, -2.7290,  ...,  0.0255,  2.7512,  7.7668],\n",
            "        [ 3.3561,  4.8410, -1.6025,  ...,  5.0478,  2.0713,  2.4301],\n",
            "        [ 2.6732,  4.0146,  4.1378,  ...,  2.0923,  1.5092, -0.8098],\n",
            "        ...,\n",
            "        [ 1.0198,  2.9862,  2.2294,  ...,  1.6445,  0.5682,  0.7909],\n",
            "        [ 3.6921,  4.8805,  3.4920,  ...,  2.5219, -0.2641,  1.0143],\n",
            "        [ 1.4814,  7.2020,  5.1662,  ..., -0.7975,  0.3069,  1.9261]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0832,  4.9692,  3.8772,  ...,  1.9237, -3.2562,  5.8032],\n",
            "        [ 1.5213,  4.8102,  3.2163,  ...,  3.6763,  2.8377,  2.1914],\n",
            "        [ 3.8813,  6.2788,  3.7242,  ...,  0.1472,  2.3733,  3.7190],\n",
            "        ...,\n",
            "        [ 4.1498,  6.4237, -1.6877,  ...,  1.1830,  8.1538,  7.2335],\n",
            "        [ 2.6461,  3.5603,  5.4320,  ...,  0.0398,  6.7104,  7.6501],\n",
            "        [ 1.5375,  3.6558,  3.9580,  ...,  2.4961,  3.7546,  3.2612]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0016, 10.3378,  0.8858,  ...,  1.8399,  3.4984,  6.6698],\n",
            "        [ 2.0339,  6.8511,  1.9089,  ..., -0.3060,  0.3596,  9.3186],\n",
            "        [ 2.8971,  8.9832,  1.5336,  ...,  2.0510, -0.9663,  3.8384],\n",
            "        ...,\n",
            "        [ 1.0831,  7.0466,  3.5757,  ...,  3.0943,  4.3918,  4.5942],\n",
            "        [-0.2263,  4.3689,  6.8085,  ...,  0.0607,  4.1163,  5.6475],\n",
            "        [ 4.2893,  4.5667,  3.1238,  ...,  1.5667, -2.9424,  0.8204]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6066,  2.5842,  3.2304,  ..., -0.0308,  1.8725,  2.5060],\n",
            "        [ 3.7287,  6.1938,  3.3842,  ..., -0.6583,  0.9105, 12.1347],\n",
            "        [ 0.4823,  3.5289,  3.5862,  ..., -1.0944,  2.4152,  3.8791],\n",
            "        ...,\n",
            "        [ 2.6289,  6.8768, -0.2415,  ...,  5.3337,  3.2419,  4.3812],\n",
            "        [ 2.4673,  3.6293,  4.0064,  ...,  0.9693,  4.6456,  2.5003],\n",
            "        [ 3.5934,  4.5027,  4.3667,  ...,  0.2521,  3.2876,  8.2244]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1152,  4.3654,  5.9372,  ..., -0.6371,  2.5225,  8.4089],\n",
            "        [ 5.0721,  5.1669,  0.9644,  ...,  1.8271,  4.1561,  3.3267],\n",
            "        [ 2.4441,  4.3716,  2.4542,  ...,  2.2359,  3.6123,  1.5584],\n",
            "        ...,\n",
            "        [ 1.3685,  4.3802,  4.7664,  ..., -0.5933,  2.1533,  3.3611],\n",
            "        [-0.0506,  6.4991,  4.8078,  ..., -0.2610,  3.9413,  3.1330],\n",
            "        [ 2.7056,  0.9155,  4.5801,  ...,  0.3752,  1.1188,  2.1916]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.9661,  6.0798,  2.4362,  ...,  1.0012,  0.5847,  3.8733],\n",
            "        [ 4.1784,  9.3924,  3.4919,  ..., -0.7525,  7.9813,  8.0029],\n",
            "        [ 0.2844,  6.0088,  4.8310,  ..., -2.5819, -0.6276,  4.3242],\n",
            "        ...,\n",
            "        [ 0.0546,  3.1129,  6.0247,  ...,  1.3021,  4.1797,  6.2948],\n",
            "        [ 5.6830,  5.2641, -0.8848,  ...,  1.9002,  0.6918,  1.4252],\n",
            "        [ 1.3046,  7.7886, -1.3790,  ..., -2.1834,  0.6515,  7.1310]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2511, 10.6164, -2.0432,  ..., -2.8297, -2.0159,  4.8647],\n",
            "        [ 1.8288,  4.0352,  4.8159,  ...,  1.4897,  4.7656,  3.0702],\n",
            "        [ 2.5040,  9.1644,  6.2264,  ..., -0.1979,  4.8333,  4.8023],\n",
            "        ...,\n",
            "        [ 3.4684, 10.6141,  2.8992,  ...,  1.5222,  9.9010,  3.3804],\n",
            "        [-0.6980,  4.4475,  5.7079,  ..., -3.4657, -3.2957,  3.8352],\n",
            "        [ 4.5208,  5.4900,  0.8595,  ...,  5.0035,  2.2293,  6.0921]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6084,  3.9816,  4.3202,  ...,  0.9621,  0.8456,  6.9349],\n",
            "        [-0.5277,  5.6526,  6.4426,  ..., -2.8940, -1.2346,  2.1175],\n",
            "        [ 2.6116,  8.9759,  5.6157,  ...,  1.1550,  2.3865,  0.3746],\n",
            "        ...,\n",
            "        [ 6.5271,  5.5001,  2.2775,  ...,  1.0245,  2.3905, 10.3303],\n",
            "        [ 1.0011,  3.9119,  2.6083,  ...,  3.2974,  2.9026,  1.6755],\n",
            "        [ 3.1336,  4.4138,  3.2563,  ...,  1.6972,  4.7194,  3.1987]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9599,  4.5060,  1.2791,  ...,  1.3673,  2.5216,  1.3020],\n",
            "        [ 1.8990,  2.8218,  4.5726,  ..., -1.1532,  1.5719,  5.1488],\n",
            "        [ 3.1621,  4.0168,  2.3782,  ...,  2.6504, -0.1359,  2.3307],\n",
            "        ...,\n",
            "        [ 4.4578,  5.7661,  2.4329,  ...,  0.4281, -1.2011,  2.8682],\n",
            "        [ 3.4485,  6.4470,  3.1210,  ...,  0.3597,  1.2822, 12.1897],\n",
            "        [ 1.4911,  6.2300,  5.8804,  ...,  2.8764,  1.6572,  1.5492]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4985,  3.8009,  5.1042,  ...,  1.5640,  1.4382,  2.0609],\n",
            "        [ 1.3062,  6.2874,  4.3276,  ...,  0.6433, -2.1743,  3.4061],\n",
            "        [ 2.0755,  5.9229,  2.0813,  ...,  2.2140,  3.3120,  5.5627],\n",
            "        ...,\n",
            "        [ 2.5214,  4.6962,  3.4922,  ...,  1.4477,  0.8183, -1.3453],\n",
            "        [ 1.9218,  7.4413,  6.0570,  ...,  1.7023,  3.9783,  5.8212],\n",
            "        [ 0.0536,  2.7504,  4.3692,  ..., -0.3084,  3.2130,  4.7218]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7159,  5.1014,  7.4681,  ..., -0.0689,  2.8796,  8.7822],\n",
            "        [ 2.8773,  4.2601,  4.7031,  ...,  2.3185,  4.6317,  1.3614],\n",
            "        [-0.7418,  8.2969,  6.3161,  ..., -1.7803,  1.8929,  4.2900],\n",
            "        ...,\n",
            "        [ 1.6654,  6.9883,  1.7175,  ...,  2.4086,  0.9401,  0.5845],\n",
            "        [ 2.3775,  3.6754,  4.6310,  ...,  2.4493,  4.3824,  1.2518],\n",
            "        [ 2.2804,  9.1786,  2.8259,  ...,  0.1143, -1.5988, 10.6264]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9991,  7.9828,  2.0554,  ...,  5.4000,  5.1831,  3.3403],\n",
            "        [ 1.9799,  3.2282,  3.8446,  ...,  2.2236,  4.2645,  0.7704],\n",
            "        [ 4.6489,  8.0500, -1.5594,  ...,  3.0344,  2.7277,  0.2618],\n",
            "        ...,\n",
            "        [-1.0458,  5.6707,  5.9407,  ..., -3.4454,  0.8732,  5.6628],\n",
            "        [ 0.5788,  6.1093,  1.6521,  ...,  3.6846,  2.0651,  3.3617],\n",
            "        [ 4.6243,  7.2788,  1.6427,  ...,  1.1159,  0.9549,  1.1521]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9690,  4.0037,  3.9700,  ...,  2.1870,  3.5628,  3.2292],\n",
            "        [ 2.6331,  4.0352, -0.6488,  ...,  1.4155, -1.3658,  2.5848],\n",
            "        [ 2.0484,  4.9676,  0.2872,  ...,  1.6091,  3.4909,  4.8328],\n",
            "        ...,\n",
            "        [ 2.1266,  7.2066,  4.5178,  ..., -1.2310, -0.5657,  5.0782],\n",
            "        [ 0.1734,  4.2810,  3.0900,  ..., -0.9336, -1.5581,  5.9734],\n",
            "        [ 3.6242,  7.9112,  2.2102,  ..., -1.4016,  2.8651,  5.5166]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3678,  4.5451,  5.7929,  ..., -1.4409, -0.2624,  2.7856],\n",
            "        [ 2.4731, 10.0642, -0.0642,  ..., -4.1118, -1.9152, 10.9667],\n",
            "        [-0.5997,  9.6160,  7.9073,  ..., -1.1996,  2.3922,  6.5969],\n",
            "        ...,\n",
            "        [ 5.0077,  5.9140,  3.5943,  ..., -0.8648,  2.0398,  3.1163],\n",
            "        [ 4.0688, 13.0794, -1.5287,  ..., -2.5021,  2.4625, 10.8358],\n",
            "        [ 2.9838,  7.5918,  0.8910,  ..., -6.1938,  2.4893,  2.8916]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7422,  5.9420,  6.3079,  ..., -0.9200,  5.6964,  1.3883],\n",
            "        [-0.1409,  6.1669,  2.9082,  ...,  1.3122, -0.0889,  1.9178],\n",
            "        [ 3.0912,  4.0901,  2.9032,  ...,  1.1236, -0.2621,  3.2192],\n",
            "        ...,\n",
            "        [ 1.2171,  1.0835,  6.9607,  ..., -1.7664,  3.3401,  7.3713],\n",
            "        [-3.0469,  0.9751,  2.3236,  ..., -0.2690,  0.4580,  8.0212],\n",
            "        [ 2.8629,  6.1655,  4.6735,  ..., -0.7142, -0.1264,  0.4726]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1314,  5.5715,  5.6276,  ..., -2.0554,  3.3217,  7.8417],\n",
            "        [ 5.7276,  5.0186, -2.7635,  ...,  3.4850,  2.7011,  2.0084],\n",
            "        [ 3.7194,  6.6135,  0.8884,  ...,  4.5072, -1.2682,  2.1465],\n",
            "        ...,\n",
            "        [ 3.5348,  7.6976,  1.3703,  ...,  1.8960,  7.0468,  6.2440],\n",
            "        [ 2.0089,  3.7557,  2.2960,  ...,  2.0409,  0.6471,  3.5215],\n",
            "        [ 8.2930,  9.1411,  0.9494,  ...,  0.7587, -2.1823, -0.4826]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.6946,  8.8882,  3.4567,  ..., -2.0830,  0.2451,  1.5599],\n",
            "        [ 2.6880,  4.2176,  3.0765,  ...,  1.3674,  3.7242,  2.1697],\n",
            "        [ 3.6541,  3.0726,  3.2011,  ...,  0.6257,  1.9001,  6.9622],\n",
            "        ...,\n",
            "        [ 1.6749,  5.4945,  4.0397,  ..., -1.6071, -4.9861, -0.5669],\n",
            "        [ 1.6557,  4.9656,  0.8448,  ..., -2.6526,  0.4899,  3.9932],\n",
            "        [ 1.7923,  5.4248,  4.0241,  ...,  1.0682,  5.1078,  1.0220]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8595,  2.6820,  1.1231,  ...,  2.7931, -0.6439,  2.4391],\n",
            "        [ 6.0936,  6.3955,  0.2873,  ...,  5.7990,  4.9548,  3.6677],\n",
            "        [ 2.6995,  6.5196,  6.7839,  ..., -2.7465, -0.8570,  2.7306],\n",
            "        ...,\n",
            "        [ 0.7914,  3.1664,  6.4474,  ..., -0.6188,  2.7456,  4.8648],\n",
            "        [ 4.8918,  6.8218,  2.3586,  ...,  5.2751,  4.5560,  5.8525],\n",
            "        [ 1.2291,  4.9739, -0.8537,  ..., -0.5589, -1.0414,  6.6216]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4242,  5.5172,  4.5485,  ..., -1.2036, -0.0231,  3.8489],\n",
            "        [ 0.7151,  4.1813,  5.7844,  ..., -0.2075,  1.9701,  6.3118],\n",
            "        [ 6.2247,  9.4504,  1.3432,  ..., -0.8781,  4.3317,  0.5400],\n",
            "        ...,\n",
            "        [ 6.3342,  4.3734,  0.8194,  ...,  2.7610,  4.4054,  0.9980],\n",
            "        [ 4.1914,  2.9760,  1.2812,  ...,  4.4349,  2.2256,  1.3391],\n",
            "        [ 5.0582,  8.2619,  2.8863,  ..., -0.0713, -1.8358,  2.4371]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0246,  6.7647,  1.4595,  ..., -0.3391, -1.2930,  0.4196],\n",
            "        [ 1.3317,  8.9800,  5.0827,  ..., -2.0749,  5.3436,  1.7182],\n",
            "        [ 2.6244,  8.3659,  2.8695,  ...,  3.8395, -0.5287,  3.2666],\n",
            "        ...,\n",
            "        [-0.9208,  7.0805,  0.3011,  ..., -0.0985, -1.2649, 10.6491],\n",
            "        [ 1.4772,  4.1636,  2.4241,  ...,  1.5186,  0.0486,  5.1951],\n",
            "        [ 5.6769,  6.5978,  1.9996,  ..., -1.2607, -0.1457,  1.5604]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3074,  3.8018, -1.4989,  ..., -0.0393,  1.4031,  5.6209],\n",
            "        [ 3.0493,  4.7405,  4.4355,  ...,  1.2272,  4.6283,  2.8854],\n",
            "        [ 4.6193, 10.3443,  3.0275,  ...,  3.1376,  2.8996,  2.0484],\n",
            "        ...,\n",
            "        [ 3.0757,  2.1838,  1.0448,  ...,  1.3261, -0.0448,  3.2333],\n",
            "        [ 6.9517,  9.3301,  3.4810,  ..., -1.1875,  0.1368,  1.0893],\n",
            "        [ 1.3415,  6.4621,  3.9599,  ...,  0.2113,  4.4481,  5.4717]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8711,  6.5501,  4.7113,  ...,  1.3846,  3.2571,  2.0090],\n",
            "        [ 1.2416,  4.2809,  5.4487,  ..., -1.4906,  2.2547,  5.2918],\n",
            "        [ 1.3992,  7.7492,  4.3650,  ...,  1.2067,  0.5837,  5.5559],\n",
            "        ...,\n",
            "        [ 1.6837,  3.6532,  6.4839,  ...,  0.0803,  1.9585,  6.3262],\n",
            "        [ 3.2629,  7.6156,  5.1075,  ...,  1.0934,  2.2578,  3.4825],\n",
            "        [ 4.5998,  8.9922,  2.0947,  ...,  2.1090,  9.5932,  3.9434]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7514,  4.6260,  4.8862,  ...,  1.8533,  4.6803,  0.7756],\n",
            "        [ 0.0457,  5.5249,  2.6038,  ..., -1.3915, -2.1186, 10.9629],\n",
            "        [ 1.8695,  7.9104,  3.7139,  ...,  1.5279,  0.5535,  3.2446],\n",
            "        ...,\n",
            "        [ 2.4180,  4.6971,  3.9548,  ...,  2.0579,  4.0738,  1.1805],\n",
            "        [-1.1094,  1.7313,  5.4660,  ..., -2.5718, -0.0708,  4.4448],\n",
            "        [ 1.0292,  5.1048,  3.2039,  ...,  0.3009,  1.6631,  4.3172]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7645,  4.6658,  5.6486,  ...,  0.7067,  3.1157,  4.8772],\n",
            "        [ 5.8519,  5.7829, -0.6922,  ...,  1.2610, -1.5522,  0.9036],\n",
            "        [ 5.2761, 10.6712,  3.3496,  ..., -0.4166,  2.3163,  4.1647],\n",
            "        ...,\n",
            "        [ 3.5089,  6.6232,  3.9330,  ..., -0.4133,  5.4609,  5.8255],\n",
            "        [ 6.3599,  7.1216,  0.6980,  ...,  1.0564, -0.9437,  1.1481],\n",
            "        [ 1.0464,  6.3318,  4.7144,  ..., -4.3693,  2.3616,  1.9987]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.6976,  9.8145,  2.0836,  ...,  4.2159,  1.2249,  3.3791],\n",
            "        [ 3.5137, 11.2371,  0.3435,  ..., -2.9073, -3.7274,  7.5058],\n",
            "        [ 4.0423,  5.5821,  1.2205,  ...,  2.5771,  1.4705,  1.7446],\n",
            "        ...,\n",
            "        [ 0.7965,  4.5749,  3.7065,  ..., -2.0613,  4.6472,  4.6922],\n",
            "        [ 1.5637,  5.3233,  1.9557,  ...,  1.1608,  5.4314,  3.1706],\n",
            "        [ 2.1798,  2.9495,  5.9919,  ...,  2.2957,  1.7680,  5.7679]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8672,  3.8755,  3.7485,  ...,  0.5349,  2.3450,  5.3265],\n",
            "        [ 0.5558,  6.8383,  4.4750,  ...,  0.4036, -0.5576,  3.6676],\n",
            "        [ 5.9916, 11.5356,  4.0746,  ...,  0.8321,  2.3753,  3.4117],\n",
            "        ...,\n",
            "        [ 4.6646,  2.5750, -0.3488,  ...,  0.2560, -1.5359,  4.2490],\n",
            "        [ 0.9437,  6.1415,  4.8636,  ..., -2.0431, -0.7321,  3.7889],\n",
            "        [ 1.0855,  5.7189,  5.0852,  ...,  3.0836,  2.9053,  0.8376]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6903,  8.4593,  0.6191,  ...,  3.5966,  0.7935,  3.3166],\n",
            "        [ 4.6169,  5.7063,  0.5166,  ...,  1.8619,  3.7447,  3.3509],\n",
            "        [ 2.0449,  6.7523,  4.1276,  ..., -2.7977,  1.9197,  0.8944],\n",
            "        ...,\n",
            "        [ 2.8927,  8.2683,  3.7245,  ...,  0.8932,  1.8339,  1.9083],\n",
            "        [ 3.5780,  4.4057,  1.7487,  ...,  0.1960,  0.9698,  3.0387],\n",
            "        [ 4.5805,  8.9481,  4.1418,  ...,  0.3474,  3.6850,  2.5632]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2259,  3.5055,  4.0760,  ...,  0.6858, -1.3597,  1.9924],\n",
            "        [ 2.5252,  5.6077,  4.2723,  ...,  0.7051,  4.0277,  3.1353],\n",
            "        [ 1.0232,  7.9032,  1.8286,  ...,  2.0842, 10.9660,  5.6061],\n",
            "        ...,\n",
            "        [ 2.1058,  2.4709,  6.4277,  ..., -0.8340,  2.2108,  6.2698],\n",
            "        [ 0.4336,  5.5692,  5.3571,  ...,  0.5134, -1.8186,  8.4689],\n",
            "        [ 6.4142, 10.6239,  4.8104,  ..., -0.8781,  3.0247,  2.8986]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.3223e-01,  3.1020e+00,  5.6961e+00,  ..., -1.6787e+00,\n",
            "          4.3716e+00,  8.2570e+00],\n",
            "        [ 9.9855e-01,  4.8334e+00,  3.0207e+00,  ...,  1.0789e+00,\n",
            "          3.0058e+00,  4.7172e+00],\n",
            "        [ 3.8707e+00,  6.8410e+00,  1.3911e+00,  ...,  2.8912e+00,\n",
            "          2.4637e+00,  2.8064e+00],\n",
            "        ...,\n",
            "        [ 1.8923e+00,  3.3454e+00,  3.6774e+00,  ..., -1.3412e-01,\n",
            "          4.2839e-01,  2.4353e+00],\n",
            "        [ 2.0429e+00,  7.4821e+00,  1.8783e+00,  ..., -1.5403e+00,\n",
            "         -6.9928e-03,  8.5631e+00],\n",
            "        [-6.8368e-01,  5.2536e+00,  5.6081e+00,  ..., -2.5025e+00,\n",
            "          2.9032e+00,  8.5010e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1803,  4.2384,  0.8444,  ...,  1.0569,  4.8865,  1.3491],\n",
            "        [ 5.5949,  8.6344,  4.3881,  ..., -0.6806,  2.8431,  2.5582],\n",
            "        [ 1.2790,  3.6872,  3.6145,  ...,  2.8281,  2.8765,  1.6529],\n",
            "        ...,\n",
            "        [ 4.5848,  4.6543, -0.9033,  ...,  2.9323,  0.8950,  1.0696],\n",
            "        [ 5.8033, 14.9755,  4.3586,  ..., -2.0437,  1.2731,  3.8175],\n",
            "        [ 5.6177,  9.8008,  3.8767,  ..., -4.1982, -0.2964,  1.4191]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0599e+00,  3.9394e+00, -6.0074e-02,  ..., -1.6332e-03,\n",
            "          1.6875e+00,  1.2839e+00],\n",
            "        [-4.9547e-01,  7.7671e+00,  5.2231e+00,  ..., -3.3912e+00,\n",
            "          2.8726e+00,  1.4107e+00],\n",
            "        [ 6.3916e-01,  2.7205e+00,  1.4211e+00,  ...,  1.0211e+00,\n",
            "          2.6679e+00,  8.9421e-01],\n",
            "        ...,\n",
            "        [-5.8450e-01,  3.7131e+00,  3.0227e+00,  ..., -1.4965e+00,\n",
            "          4.7020e-01,  4.0327e+00],\n",
            "        [ 5.3003e-01,  3.7121e+00,  2.9287e+00,  ...,  3.1139e+00,\n",
            "          3.1013e+00,  4.8341e+00],\n",
            "        [ 3.0647e+00,  5.8462e+00, -1.9623e-01,  ...,  3.1556e+00,\n",
            "          4.5355e+00,  3.9834e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 9.8005e-01,  2.9011e+00,  6.4199e+00,  ..., -1.2175e+00,\n",
            "          3.3505e+00,  6.7541e+00],\n",
            "        [ 3.2926e+00,  8.9360e+00,  3.6321e+00,  ...,  1.5307e+00,\n",
            "          3.9405e+00,  4.2528e+00],\n",
            "        [ 6.0617e-01,  3.3532e+00,  4.1911e-01,  ..., -1.4101e+00,\n",
            "         -6.7185e-01,  9.6308e+00],\n",
            "        ...,\n",
            "        [ 2.8909e+00,  8.3499e+00,  1.2867e+00,  ...,  5.8545e+00,\n",
            "          2.8989e+00,  3.9459e+00],\n",
            "        [ 2.6960e+00,  7.3399e+00,  7.4471e+00,  ..., -1.4027e+00,\n",
            "          1.8602e+00,  2.6244e+00],\n",
            "        [ 9.0604e-03,  6.5551e+00,  7.2777e+00,  ..., -5.1823e-01,\n",
            "          1.7945e+00,  5.4670e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3431,  3.7585,  2.9735,  ...,  2.8524,  2.6488,  1.5811],\n",
            "        [ 2.8472,  7.7116,  7.9725,  ...,  0.1422,  1.7279, -1.0710],\n",
            "        [ 1.7108,  4.9217,  5.0087,  ...,  1.9276, -1.0594,  5.0683],\n",
            "        ...,\n",
            "        [ 2.7049,  6.8760,  4.4749,  ..., -2.0331,  3.5419,  0.6996],\n",
            "        [ 4.3843,  4.7290,  0.1961,  ...,  2.2733,  1.3498,  1.6052],\n",
            "        [ 0.5652,  4.3424,  3.5672,  ...,  0.1500,  1.4119,  6.8359]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.2773,  6.7901,  3.8111,  ...,  1.6360,  0.9816,  1.3004],\n",
            "        [ 2.4666,  5.1032, -0.1453,  ...,  3.1884,  5.2739,  3.0912],\n",
            "        [ 5.1805,  3.2826,  0.0192,  ...,  1.0260,  1.7853,  3.1983],\n",
            "        ...,\n",
            "        [ 4.9311, 10.0336, -2.1469,  ...,  0.4734,  8.8527,  7.5548],\n",
            "        [ 2.8520,  4.2052,  0.4923,  ...,  1.8629,  1.5979,  2.5705],\n",
            "        [ 2.2695,  5.2334,  5.1010,  ...,  0.3224, -0.2006,  1.4237]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.5163,  6.6916,  4.0021,  ..., -1.0588,  1.5834,  2.9374],\n",
            "        [ 0.7506,  4.9091,  4.3654,  ...,  3.0734,  1.6288,  2.7725],\n",
            "        [ 2.7251,  4.7308,  2.2118,  ...,  3.6421,  1.2345,  2.8833],\n",
            "        ...,\n",
            "        [ 0.1792,  4.1649,  3.4630,  ..., -2.0706,  2.2984,  6.1372],\n",
            "        [ 5.6953,  6.0546, -1.5679,  ...,  1.6341,  2.7941,  2.5947],\n",
            "        [ 2.9672,  1.0416, -1.4509,  ...,  0.8490,  0.9899,  3.6336]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6275,  5.1800,  0.6451,  ..., -1.5587,  2.5961,  1.8338],\n",
            "        [ 1.2427,  4.1126, -1.3951,  ..., -0.0544,  0.9058,  9.2682],\n",
            "        [ 4.0333,  7.9122,  3.3623,  ...,  4.6663,  1.5016,  4.1109],\n",
            "        ...,\n",
            "        [ 4.2852,  8.6436,  1.7184,  ...,  5.5659,  2.0373, -1.2362],\n",
            "        [ 3.3268,  2.3588,  2.8425,  ...,  3.0548,  0.3052, -0.3803],\n",
            "        [ 3.6010,  9.5314,  3.1503,  ..., -0.6189,  7.2652,  2.6208]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7940,  7.6804,  2.6130,  ...,  2.9539, -0.5800,  2.9265],\n",
            "        [ 0.2190,  5.3558,  5.9961,  ..., -2.7018,  1.2212,  2.2832],\n",
            "        [ 4.7940,  8.0118,  5.3577,  ..., -0.1035,  1.4446,  0.1209],\n",
            "        ...,\n",
            "        [-0.1060,  4.8389,  4.5566,  ..., -3.5330,  3.1626,  2.3888],\n",
            "        [ 2.6242,  4.4622, -0.2572,  ...,  0.5924,  0.4540, -0.5398],\n",
            "        [ 0.5905,  4.6054,  4.5513,  ...,  0.6036, -0.4789,  4.6724]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8636, 10.8448,  1.6527,  ...,  1.1358,  8.1780,  6.0157],\n",
            "        [-0.1970,  5.5423,  4.6602,  ...,  1.5500,  2.0354,  0.6126],\n",
            "        [ 0.6864,  4.7879,  3.6790,  ...,  3.5249,  2.1024,  1.8211],\n",
            "        ...,\n",
            "        [ 3.7214,  7.5853,  5.3672,  ..., -0.4121, -0.7786,  0.7142],\n",
            "        [ 1.5657,  4.7301,  2.9238,  ...,  1.5301, -0.6033,  3.9129],\n",
            "        [ 5.5672,  6.2558,  1.6383,  ...,  0.9650,  0.5592,  2.4268]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5511,  4.6996,  4.8478,  ..., -1.0208,  0.1243,  4.7317],\n",
            "        [ 2.9907,  6.1612,  4.0024,  ...,  0.7212,  6.5901,  1.5649],\n",
            "        [ 3.3062,  5.2453,  1.6000,  ...,  1.4082,  1.4653,  2.9536],\n",
            "        ...,\n",
            "        [ 3.9948,  9.8001,  4.5872,  ..., -0.7968, -1.5762,  2.7490],\n",
            "        [ 2.1232,  3.2119,  4.9525,  ...,  2.4008,  1.7323,  3.0727],\n",
            "        [-0.2852,  2.7137,  2.8435,  ..., -0.7624,  3.6107,  2.4070]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9110,  6.1362,  3.1406,  ...,  2.1991,  3.5689,  2.1306],\n",
            "        [ 3.2289,  8.7044,  3.4243,  ...,  2.3372,  3.9165, -1.0659],\n",
            "        [ 4.0338,  6.5082,  5.0022,  ...,  2.8801,  2.9367,  2.6405],\n",
            "        ...,\n",
            "        [ 2.3471,  5.4440,  2.7904,  ...,  3.8021,  0.4778,  3.2300],\n",
            "        [ 4.5215,  5.4482,  0.1316,  ...,  2.1858,  0.5386,  1.9234],\n",
            "        [ 5.4974,  8.0165,  1.8813,  ...,  1.4370, -0.7820,  1.1106]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6725,  7.6141,  7.6027,  ...,  1.9789,  2.0805,  5.6880],\n",
            "        [ 2.3862,  8.3851,  2.0460,  ..., -1.4179,  3.2340,  4.3458],\n",
            "        [ 1.5537,  5.6399, -1.0366,  ..., -3.6507,  1.8236,  7.4122],\n",
            "        ...,\n",
            "        [ 6.5869, 10.6365,  1.8552,  ..., -2.2696, -1.2787,  5.2638],\n",
            "        [ 3.7782,  9.3110,  3.0748,  ...,  1.7728, -1.6739,  2.8592],\n",
            "        [ 5.8415,  8.4648,  0.5396,  ...,  5.8500,  1.1887,  3.3260]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0474,  5.6479,  6.0255,  ...,  0.1751,  2.1787, -0.9057],\n",
            "        [ 4.3430,  6.8256,  1.2721,  ...,  3.9200,  2.3233,  1.2320],\n",
            "        [ 2.4421,  5.2509,  4.4843,  ..., -1.1137,  2.6407,  3.2711],\n",
            "        ...,\n",
            "        [ 2.4413,  6.8679,  3.9719,  ...,  2.9085, -3.1541,  1.5241],\n",
            "        [ 1.4390,  3.7246,  3.9346,  ...,  2.7916,  2.6900,  2.1664],\n",
            "        [ 5.7664,  6.0795,  1.9204,  ...,  0.6455,  0.0330,  1.0619]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8605,  5.8728,  4.3665,  ...,  1.1553,  1.6453,  0.3510],\n",
            "        [ 4.8753,  6.9875,  2.5181,  ...,  4.4395,  3.6453,  3.5499],\n",
            "        [ 2.5267,  3.4685,  5.5749,  ...,  1.1230,  2.1059,  1.8667],\n",
            "        ...,\n",
            "        [ 3.2150,  7.0866,  5.2463,  ..., -1.7950,  3.0789,  0.7436],\n",
            "        [ 5.0192,  6.0380, -0.0843,  ...,  5.5559,  1.9338,  1.9758],\n",
            "        [ 2.0822,  5.9800,  2.0745,  ...,  0.6910,  4.1903,  1.7803]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6840,  6.7719,  5.4155,  ..., -1.8822,  2.3592,  4.9050],\n",
            "        [ 1.5559,  4.3537,  3.6560,  ...,  4.3065,  2.2361,  0.9306],\n",
            "        [ 1.7307,  9.2526, -0.8329,  ..., -0.7347, -3.5196,  7.6822],\n",
            "        ...,\n",
            "        [ 5.0018,  5.6778,  3.9126,  ...,  0.3726, -0.0427,  4.2218],\n",
            "        [ 1.4402,  5.9211,  1.3015,  ...,  0.3184,  0.4038,  9.8855],\n",
            "        [ 5.0391,  9.0223,  0.7074,  ...,  1.2566,  8.9742,  5.1469]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4685e+00,  1.0626e+01,  5.5159e+00,  ...,  1.0193e-02,\n",
            "         -3.2262e+00,  5.0365e+00],\n",
            "        [ 2.6733e-01,  5.3957e+00,  5.4435e+00,  ..., -2.7649e-01,\n",
            "         -2.0317e-02,  6.3502e+00],\n",
            "        [ 2.5468e+00,  1.0101e+01,  5.0237e+00,  ...,  9.4506e-01,\n",
            "          4.9979e+00,  6.2224e+00],\n",
            "        ...,\n",
            "        [ 7.4720e+00,  5.8249e+00, -6.5811e-02,  ...,  9.2149e-01,\n",
            "          1.2782e+00,  1.8279e+00],\n",
            "        [ 1.0752e+00,  3.7568e+00,  2.4164e+00,  ..., -2.5363e+00,\n",
            "          2.7456e+00,  2.3763e+00],\n",
            "        [ 2.8458e+00,  5.0999e+00,  6.1455e+00,  ..., -1.3131e-01,\n",
            "          3.9243e+00,  5.7929e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3858,  4.9183,  2.6226,  ...,  1.8049,  1.7443,  2.7849],\n",
            "        [ 4.5426,  9.3254, -0.3017,  ..., -2.1895,  2.6331,  5.7793],\n",
            "        [ 3.0149,  5.1082,  3.0250,  ...,  2.7386, -0.8651,  1.4453],\n",
            "        ...,\n",
            "        [ 2.2651,  4.7315,  4.7390,  ...,  2.1640,  3.9799,  2.6437],\n",
            "        [ 4.2108,  8.2943,  5.2546,  ...,  0.1519,  3.0430,  0.1634],\n",
            "        [ 4.8378,  5.4950,  0.9513,  ...,  1.1496, -1.8930,  0.3751]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9055,  6.4517,  2.7044,  ...,  2.2232, -2.9778,  2.1015],\n",
            "        [ 5.9914,  8.4918,  1.1661,  ...,  2.5923,  3.3169, -0.4090],\n",
            "        [ 2.2909,  9.2153,  3.8548,  ...,  2.7923, -1.0470,  3.8172],\n",
            "        ...,\n",
            "        [ 5.1275,  4.4922, -0.0443,  ...,  3.1886,  0.6517,  0.1238],\n",
            "        [ 2.0314,  7.9867,  5.4387,  ...,  0.5779,  6.0668,  1.9107],\n",
            "        [ 5.0078,  4.7136, -0.9338,  ...,  1.8399,  3.9006,  2.6202]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9281,  5.6079,  4.0957,  ...,  0.4044, -0.2038,  6.2728],\n",
            "        [ 6.2683,  9.0550, -0.3908,  ...,  2.7946, -3.2507,  1.6263],\n",
            "        [-1.0059,  8.5408,  7.2159,  ..., -5.8889,  5.9395,  8.5743],\n",
            "        ...,\n",
            "        [ 0.5214,  7.3317,  0.4540,  ...,  0.4687,  1.1131,  7.8076],\n",
            "        [-1.3226,  7.7846,  0.3085,  ..., -0.3834, -2.0933,  7.9319],\n",
            "        [ 1.9093,  1.9761,  5.6450,  ..., -0.9280,  3.4306,  7.4748]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5412,  8.9282,  1.3347,  ...,  2.2654,  2.9314, -0.0730],\n",
            "        [ 1.1261,  3.7646,  2.1919,  ...,  3.6411,  2.3801,  1.4052],\n",
            "        [ 1.4466,  6.9623,  7.9522,  ...,  1.9891,  3.8364,  3.7917],\n",
            "        ...,\n",
            "        [ 2.2772,  7.4506,  2.2844,  ...,  0.8208,  6.6337,  8.0140],\n",
            "        [ 1.9845,  9.0877,  0.4039,  ...,  1.0018,  5.9054,  5.4793],\n",
            "        [ 2.3511,  8.8714,  4.8332,  ...,  0.7211,  0.1610,  4.6535]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8525,  5.9505,  6.5733,  ..., -3.4045,  0.6057,  1.7676],\n",
            "        [ 5.0528,  4.9759,  2.7766,  ...,  1.1437,  0.2102,  7.6687],\n",
            "        [ 5.4285,  6.1591, -1.0680,  ...,  1.5678, -0.4092,  3.5553],\n",
            "        ...,\n",
            "        [ 0.6440,  4.2490,  3.2813,  ...,  1.3106,  4.5888,  4.6626],\n",
            "        [-0.6014,  6.7134,  2.0331,  ..., -0.0449, -2.7659, 11.2725],\n",
            "        [ 0.1485,  4.3864,  3.4854,  ...,  2.2675,  1.4497,  4.7594]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8280,  6.6248,  3.9657,  ...,  3.5454,  2.1829,  3.1756],\n",
            "        [ 1.8726,  5.6820,  2.2280,  ...,  2.4724,  0.8108,  3.8699],\n",
            "        [ 3.9247,  6.4568,  4.4770,  ...,  1.3743,  5.4814,  1.2108],\n",
            "        ...,\n",
            "        [ 2.1130,  2.7161,  3.2888,  ...,  2.4407,  0.6208,  2.5464],\n",
            "        [ 1.0935, 10.5990,  3.3812,  ..., -0.1569,  9.8331,  7.6750],\n",
            "        [ 2.8533,  4.2596,  7.0171,  ..., -0.5374,  2.7068,  6.7557]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9127,  5.0766,  4.1629,  ...,  1.1113,  3.8938,  3.2924],\n",
            "        [ 1.7997, 11.5246,  4.6061,  ...,  1.0817,  6.8178,  7.0653],\n",
            "        [ 2.7939,  5.2669,  3.1536,  ...,  2.2434,  1.0727,  2.5813],\n",
            "        ...,\n",
            "        [ 2.7145,  5.3265,  3.7222,  ...,  2.7673,  1.8089, -1.1108],\n",
            "        [ 2.2519,  5.3188,  2.7776,  ...,  0.1808,  2.7601,  4.8311],\n",
            "        [-1.2879,  3.7645,  6.0203,  ..., -1.1160, -2.0835,  1.8095]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.8151,  8.2376,  1.8313,  ...,  1.0060, -0.5339,  2.4254],\n",
            "        [ 5.4038,  4.8056, -0.7971,  ...,  1.3810,  0.7912,  4.3408],\n",
            "        [ 5.6154,  8.4251,  2.9445,  ..., -0.0756,  6.3462,  6.3152],\n",
            "        ...,\n",
            "        [ 0.7509,  2.9159,  6.7003,  ..., -2.3122, -2.5470,  4.3850],\n",
            "        [ 1.6913,  4.1943,  4.6558,  ...,  1.1902,  1.3104,  3.6802],\n",
            "        [ 2.3896,  7.6508,  1.2233,  ...,  0.4024,  7.3645,  5.7967]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.1419,  4.5864,  2.0233,  ...,  0.5589, -0.5428,  4.1542],\n",
            "        [-2.0628,  4.2623,  6.6144,  ..., -3.2168, -2.2926,  3.8859],\n",
            "        [ 5.1499,  5.5065, -0.4827,  ...,  2.2761, -1.3676,  1.8015],\n",
            "        ...,\n",
            "        [ 4.2205,  5.4651, -0.5668,  ...,  1.7791,  0.2757,  1.2906],\n",
            "        [-1.7383,  5.3622,  3.6483,  ..., -6.1899, -0.5614, -2.4878],\n",
            "        [ 3.8470,  5.5168,  4.2513,  ...,  0.5307,  5.6494,  1.0378]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.9989,  5.0981,  1.8199,  ...,  0.7061, -2.2235,  1.2804],\n",
            "        [ 1.6404,  8.7165,  4.0165,  ...,  0.8375,  4.4865,  1.0462],\n",
            "        [ 1.0369,  3.7261,  4.4493,  ...,  1.7960,  2.8102,  0.5203],\n",
            "        ...,\n",
            "        [ 4.1621,  5.7041, -0.6784,  ...,  3.1913,  1.7301,  2.4743],\n",
            "        [ 2.9899,  2.9969,  2.3911,  ...,  0.4984,  1.1475,  1.9653],\n",
            "        [ 1.0399,  4.6802,  3.9605,  ...,  2.3624,  3.5662,  2.2750]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2179,  5.8329,  4.6626,  ..., -2.9039,  5.1298,  6.7515],\n",
            "        [ 4.4281,  4.5906,  2.0912,  ...,  3.1132, -0.3088,  1.1856],\n",
            "        [ 3.0750, 11.2885, -1.5585,  ..., -1.0806,  7.6530,  9.8657],\n",
            "        ...,\n",
            "        [ 1.2317,  3.1782,  3.8007,  ...,  0.2569,  0.0732,  2.9752],\n",
            "        [ 4.9415,  4.3932, -2.2928,  ...,  1.8602,  2.0544,  3.7283],\n",
            "        [ 1.6344,  5.0498,  4.5129,  ...,  2.2572,  3.1696,  2.7172]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9989,  4.7081,  4.2040,  ..., -0.4134,  1.2270,  2.8252],\n",
            "        [ 4.4071,  3.8940,  2.5483,  ...,  1.1150, -0.7101,  2.0009],\n",
            "        [-0.1736,  4.0448,  5.6278,  ..., -0.9386,  2.2370,  2.7912],\n",
            "        ...,\n",
            "        [-0.6336,  9.5470, -0.2673,  ..., -1.5966, -1.2904,  8.2748],\n",
            "        [ 1.9361,  3.5641,  5.9436,  ..., -0.6165,  2.5793,  3.5833],\n",
            "        [ 2.5409,  4.6715,  3.7046,  ...,  0.4542,  4.1453,  3.3387]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3888,  2.9186,  5.2212,  ..., -2.1219,  0.1890,  2.7292],\n",
            "        [ 3.1259,  7.6141,  0.8437,  ...,  3.1669,  4.4222,  3.8280],\n",
            "        [ 0.9769,  7.0870,  2.9245,  ...,  2.4904,  2.2801,  1.8582],\n",
            "        ...,\n",
            "        [ 2.6873,  4.5928,  0.6263,  ...,  1.6913,  4.2867,  0.6149],\n",
            "        [ 3.1947,  5.6600,  1.1607,  ...,  4.4980,  2.3355,  2.7261],\n",
            "        [ 0.7150,  3.4544,  3.4717,  ...,  4.1159,  1.9662,  2.0294]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.7484,  9.4127,  0.3267,  ...,  4.3546,  2.7011,  6.8135],\n",
            "        [ 0.8210,  4.1369,  4.6972,  ..., -0.3095,  1.3090,  3.3617],\n",
            "        [ 1.6647,  4.9809,  4.3022,  ...,  2.3815,  4.4760,  1.1850],\n",
            "        ...,\n",
            "        [-0.0954,  3.5209,  1.6814,  ..., -0.5295, -1.5363,  0.7886],\n",
            "        [ 6.6154,  6.3376, -0.2706,  ...,  2.1843,  1.8905,  7.5393],\n",
            "        [ 5.0339,  8.5863,  5.0645,  ..., -2.0645, -0.8694,  2.0293]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1449,  5.4459,  0.1726,  ...,  1.8211,  2.1146, -1.2094],\n",
            "        [ 2.0086,  4.2856,  3.6160,  ...,  2.9296, -0.3175, -0.2580],\n",
            "        [ 0.5647,  2.1060,  1.6362,  ...,  2.3013, -0.5987,  4.3055],\n",
            "        ...,\n",
            "        [ 4.6318,  6.5994, -1.5698,  ...,  4.6425,  3.2714,  1.8089],\n",
            "        [ 2.5718,  4.7802,  2.2789,  ...,  3.3415, -0.9477,  1.6531],\n",
            "        [ 5.9800,  9.9731,  4.6564,  ..., -1.1041,  4.3533,  2.7276]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0927,  9.2899,  5.3682,  ..., -0.1621,  0.4005,  1.3482],\n",
            "        [ 4.8913,  6.6222, -1.5968,  ...,  5.5307,  4.0884,  4.3747],\n",
            "        [ 1.7645,  4.8125,  0.9272,  ...,  3.0722,  0.0626,  1.9903],\n",
            "        ...,\n",
            "        [-0.6492,  6.7812, -0.5754,  ..., -0.4348, -1.1324,  9.4477],\n",
            "        [ 3.9113,  4.2565,  1.0870,  ...,  0.1736,  2.5676,  1.5508],\n",
            "        [ 0.7804,  3.0312,  1.8621,  ..., -3.9028,  2.8774,  4.0747]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1378,  6.2809,  2.3833,  ...,  0.6558,  0.0924,  1.9985],\n",
            "        [ 3.2568,  6.7863,  5.0145,  ...,  1.2814,  6.9053,  4.5291],\n",
            "        [ 0.6305,  8.0272,  1.3480,  ..., -2.3252, -2.0697,  5.6528],\n",
            "        ...,\n",
            "        [ 1.2719,  3.5797,  3.3929,  ...,  2.2556,  0.6030,  2.9550],\n",
            "        [ 2.0017,  8.9643,  3.1081,  ...,  1.1436, -0.4106,  3.6028],\n",
            "        [ 3.8990,  4.8390,  1.7969,  ...,  1.1171,  1.7763,  9.2318]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8150e+00,  6.1733e+00,  2.3979e+00,  ...,  1.0516e+00,\n",
            "          2.8819e+00,  8.4170e-01],\n",
            "        [ 1.4879e+00,  7.5002e+00,  2.0016e+00,  ..., -5.9422e-01,\n",
            "          2.8708e+00,  7.1127e+00],\n",
            "        [ 4.7449e+00,  6.8690e+00,  2.9279e+00,  ...,  7.6145e-01,\n",
            "          4.9740e-01,  9.7031e-01],\n",
            "        ...,\n",
            "        [ 2.8826e+00,  3.8464e+00,  1.5995e+00,  ...,  2.7094e+00,\n",
            "         -6.9629e-01,  1.5613e+00],\n",
            "        [ 3.0888e+00,  4.0391e+00,  3.1436e+00,  ...,  1.1553e+00,\n",
            "          3.5680e+00,  2.1781e+00],\n",
            "        [ 1.7667e+00,  7.0993e+00,  3.3578e+00,  ...,  3.8969e-01,\n",
            "         -5.9790e-03,  3.3961e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1253,  3.9898,  3.8093,  ...,  1.2074,  3.3631,  2.2386],\n",
            "        [ 2.7751,  5.1410,  4.2222,  ...,  1.9910,  4.0911,  1.6717],\n",
            "        [ 0.5785,  4.6283,  4.0986,  ...,  1.4898,  1.3669,  4.3666],\n",
            "        ...,\n",
            "        [ 0.9380,  4.3428,  2.9901,  ...,  3.1558,  3.2300,  1.3641],\n",
            "        [ 1.2771,  8.4624, -0.4756,  ..., -3.2739, -0.7699,  8.0542],\n",
            "        [-1.4154,  2.5442,  4.2896,  ..., -1.5095,  0.1102,  3.1348]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8064,  4.8379,  1.8553,  ...,  2.5686,  1.1321,  2.8259],\n",
            "        [ 0.0576,  8.5739,  7.1024,  ..., -0.0222,  4.6519,  2.8086],\n",
            "        [ 3.1842,  6.4035,  6.4382,  ...,  0.9908,  0.4668, -1.6719],\n",
            "        ...,\n",
            "        [ 4.6636,  7.6569,  1.4978,  ...,  3.7867,  1.6676,  3.1832],\n",
            "        [ 1.4316,  4.9651,  6.1066,  ...,  1.4580,  3.1459,  7.3688],\n",
            "        [ 3.1478,  6.1671, -0.2689,  ...,  3.5851,  3.5947, -0.4829]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7528,  5.8003,  3.2248,  ...,  4.4673,  2.9296,  1.4548],\n",
            "        [ 8.6377, 14.8849,  3.5910,  ..., -1.0925,  0.6082,  6.3565],\n",
            "        [ 0.3290,  2.2255,  4.8221,  ..., -0.2575,  2.9273,  2.2860],\n",
            "        ...,\n",
            "        [ 1.4998,  4.2007,  3.5837,  ...,  1.6960,  3.5177,  3.2513],\n",
            "        [ 4.2516,  9.8176,  5.2525,  ...,  1.7871,  1.9068,  0.6452],\n",
            "        [ 5.3852,  6.4977,  2.4594,  ...,  2.1137,  0.5011, -0.1698]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7850,  7.6207,  1.2337,  ...,  4.8577,  3.1606,  3.3466],\n",
            "        [ 2.6582,  3.5910,  2.4910,  ...,  0.9776, -2.2132,  1.2265],\n",
            "        [ 1.0758,  4.0418,  4.1961,  ...,  3.3137,  2.9304,  1.9594],\n",
            "        ...,\n",
            "        [ 0.9362,  7.8918,  7.2743,  ...,  1.0610, -2.0797,  3.9862],\n",
            "        [ 1.1064,  7.3710,  0.2288,  ...,  4.6123,  2.6232,  6.4024],\n",
            "        [ 2.7649,  2.1238,  6.2508,  ..., -1.1552,  2.9842,  7.1488]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3521,  4.7274,  8.5580,  ..., -0.8548,  2.8981,  6.2850],\n",
            "        [ 1.5523,  4.7424,  5.5060,  ...,  0.5643,  0.8804,  4.7758],\n",
            "        [ 3.4702,  7.8255,  7.1373,  ...,  0.1956,  3.0269,  7.1655],\n",
            "        ...,\n",
            "        [ 6.2261,  7.0449,  2.1776,  ..., -0.7346,  4.0521,  2.1478],\n",
            "        [ 0.8633,  5.2890,  4.4968,  ...,  5.1877, -0.7838,  4.6916],\n",
            "        [ 1.3813,  8.9304,  4.0816,  ...,  2.0612,  0.2888,  3.3670]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.2700e-01,  1.0065e+01, -2.5015e-01,  ..., -1.9113e+00,\n",
            "         -1.7788e+00,  1.0395e+01],\n",
            "        [ 4.0601e+00,  5.0492e+00,  4.2273e+00,  ..., -9.6980e-01,\n",
            "          8.2822e-01, -1.5387e-01],\n",
            "        [ 2.6487e+00,  6.4680e+00,  4.2519e+00,  ...,  9.3875e-01,\n",
            "          4.4475e+00,  3.1831e-01],\n",
            "        ...,\n",
            "        [ 2.3307e+00,  3.5006e+00,  4.2786e+00,  ...,  2.5293e+00,\n",
            "         -4.6083e-03,  3.1705e+00],\n",
            "        [ 2.4927e+00,  1.0404e+01,  4.6567e+00,  ...,  9.5755e-01,\n",
            "          3.2723e+00,  4.4589e+00],\n",
            "        [ 1.8034e+00,  7.6822e+00,  3.5689e+00,  ..., -9.1555e-01,\n",
            "          1.9773e+00,  4.8847e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2571,  4.0518,  4.9857,  ...,  4.3283, -0.2409,  3.9287],\n",
            "        [ 2.6700,  9.1455,  0.5849,  ..., -0.5538, -1.6502,  8.5030],\n",
            "        [ 0.5719,  3.5971,  4.0065,  ...,  1.3629,  1.4818,  1.5349],\n",
            "        ...,\n",
            "        [-0.0141,  6.0395,  5.5772,  ..., -1.4922,  3.3962,  4.9994],\n",
            "        [-0.7590,  8.7856,  5.0533,  ...,  2.8361, -1.0499,  2.7457],\n",
            "        [ 4.0731,  4.6883,  3.3295,  ...,  0.6991,  1.9445,  2.2434]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6050,  5.4668,  6.6455,  ..., -2.8928,  3.6022,  7.9616],\n",
            "        [-0.4256,  8.9246,  2.4272,  ..., -4.6882, -2.7931,  7.2839],\n",
            "        [ 0.2488,  2.0384,  5.3299,  ...,  0.2286,  2.9480,  6.9012],\n",
            "        ...,\n",
            "        [ 2.3210,  6.2711,  2.5460,  ...,  1.0097, -1.2820,  9.7602],\n",
            "        [ 4.0772,  7.0893,  3.0552,  ...,  0.2371,  0.9280,  2.8784],\n",
            "        [ 2.5730,  4.9062,  3.9966,  ...,  1.4766, -0.0817,  2.0412]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7609,  4.6182,  4.5761,  ...,  2.2658,  3.6118,  2.2774],\n",
            "        [ 0.7827,  6.2575,  3.8060,  ..., -3.5208,  5.9351,  7.2363],\n",
            "        [ 6.7456,  7.1397,  0.4418,  ...,  1.0467,  3.9549,  1.2797],\n",
            "        ...,\n",
            "        [ 1.6216,  4.1392,  7.4603,  ...,  0.5501,  0.1766,  0.5272],\n",
            "        [ 7.4018,  8.4710,  0.8730,  ...,  3.1420,  2.3216,  0.6567],\n",
            "        [ 0.6919,  8.6244,  6.1159,  ..., -0.6227, -5.0636,  5.5618]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3128,  6.6437,  2.9988,  ...,  0.2068,  5.4063,  3.5120],\n",
            "        [ 4.5113, 10.2940,  6.5313,  ...,  2.0206, -1.2439,  0.3115],\n",
            "        [ 6.4307,  5.6445,  2.8126,  ...,  0.2984,  0.7039, 11.4550],\n",
            "        ...,\n",
            "        [ 5.5865,  7.6879,  3.9538,  ...,  3.6104,  1.7673,  2.5407],\n",
            "        [ 2.8520,  7.2389,  4.9858,  ...,  2.8503,  3.3778,  4.6192],\n",
            "        [ 2.4813,  5.8252,  6.8685,  ..., -2.4757,  0.9940, -0.5264]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5367,  3.0849,  7.1997,  ...,  0.2048,  3.1475,  6.4469],\n",
            "        [ 5.5633,  4.8636,  1.2175,  ...,  1.4317, -2.6078,  2.7761],\n",
            "        [ 3.2223,  5.3705,  5.8033,  ...,  1.4230,  4.1531,  1.5027],\n",
            "        ...,\n",
            "        [ 0.4439,  6.9370,  4.0441,  ..., -1.8480,  2.7064,  8.1672],\n",
            "        [ 3.2961,  6.1863,  4.3042,  ...,  1.1004,  4.8824,  1.9016],\n",
            "        [ 3.8121,  8.8052, -0.7134,  ..., -0.4794,  6.6514, 10.9859]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1406,  7.3084,  0.5171,  ..., -1.9100,  3.5146,  2.3217],\n",
            "        [ 5.8987,  4.1905, -2.6954,  ...,  1.4096,  2.5227,  1.8502],\n",
            "        [ 2.1526,  6.7743,  4.9575,  ..., -3.5156,  4.9381,  5.1768],\n",
            "        ...,\n",
            "        [ 1.2302,  4.8936,  4.0891,  ...,  3.7425,  2.1771,  2.6063],\n",
            "        [ 5.0019,  2.7134,  3.0990,  ...,  2.0421, -1.2681,  2.6263],\n",
            "        [ 4.5688,  9.0215,  0.6742,  ...,  0.7453, -0.6643,  6.3875]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7024,  6.0233,  5.5946,  ...,  0.7400,  2.4863, -1.9037],\n",
            "        [ 3.5640,  9.2042,  3.4407,  ..., -2.3765, -0.5151,  1.1547],\n",
            "        [ 3.2035,  4.3372,  1.0848,  ...,  2.9329,  2.5816,  1.5671],\n",
            "        ...,\n",
            "        [ 2.1894,  4.5612,  5.5656,  ...,  2.7956,  3.5794,  1.6828],\n",
            "        [ 0.0623,  9.3174,  0.5454,  ..., -2.5762, -3.1530,  6.8538],\n",
            "        [-0.3511,  9.3447, -0.7374,  ..., -1.5464, -0.6519,  5.0439]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0752,  7.6983, -0.5343,  ..., -0.6164, -0.8662,  6.0433],\n",
            "        [ 4.4474,  5.3382,  5.0133,  ...,  0.2040,  1.1848,  2.2361],\n",
            "        [ 2.9360,  6.5914, -1.7347,  ..., -2.9356,  2.6153,  6.4291],\n",
            "        ...,\n",
            "        [ 3.5329,  5.0212,  3.4078,  ..., -0.2339,  0.4214, -0.4529],\n",
            "        [ 2.2509,  5.3512,  2.8263,  ...,  3.4101,  0.6041,  2.1611],\n",
            "        [ 2.1944,  3.0707,  4.7669,  ...,  1.6891, -1.0294,  1.7000]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5283,  4.2734,  3.0677,  ...,  0.6244,  1.0909,  5.4579],\n",
            "        [ 7.8099,  5.3907, -0.3764,  ...,  0.7456,  2.5396,  0.1929],\n",
            "        [ 2.5944,  7.3126,  7.5080,  ..., -1.6391, -0.1506,  6.7457],\n",
            "        ...,\n",
            "        [ 3.5572,  8.7348,  3.2963,  ...,  0.8410,  5.7593,  4.5091],\n",
            "        [-0.4772,  4.2482,  4.1028,  ..., -1.1334,  1.2488,  4.7641],\n",
            "        [ 2.8631,  2.8961, -0.1550,  ...,  5.3213,  6.4568,  6.4918]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.9736, 10.3354,  4.6862,  ..., -1.5185,  0.7572,  0.4622],\n",
            "        [ 5.3280, 15.2719,  5.0068,  ..., -0.1539, -1.3818,  3.6960],\n",
            "        [ 5.1084,  4.6869, -1.2187,  ...,  0.3647, -1.6675,  3.0851],\n",
            "        ...,\n",
            "        [ 1.3212,  5.3607,  4.6459,  ...,  2.9516,  1.0425,  1.4817],\n",
            "        [ 5.7815,  9.5189,  3.2007,  ..., -0.0630, -0.7332,  0.1754],\n",
            "        [ 1.1037,  2.2775,  3.9721,  ..., -1.7649,  3.7138,  8.4318]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5284,  4.6656,  5.6557,  ..., -2.9386, -0.7627,  1.9588],\n",
            "        [ 5.7337,  6.4277,  2.0767,  ...,  2.2161,  0.4651,  2.0060],\n",
            "        [ 2.4892,  5.3213,  6.5559,  ..., -0.4329,  0.1957, -2.9937],\n",
            "        ...,\n",
            "        [-1.3868,  6.6273,  3.4163,  ...,  1.0889, -1.5928,  2.9055],\n",
            "        [ 2.2756,  6.7682,  7.0653,  ..., -4.4141, -3.5596,  4.7833],\n",
            "        [ 1.0165,  1.1533,  5.5491,  ..., -1.2612,  2.2047,  8.5753]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.1911,  8.3627,  2.6158,  ...,  0.6122,  0.0714,  1.1073],\n",
            "        [ 4.2710,  9.8802,  4.5228,  ...,  0.5011,  0.7160,  3.6508],\n",
            "        [ 2.0386,  5.7525,  3.7346,  ...,  2.3146,  0.4248,  1.4619],\n",
            "        ...,\n",
            "        [ 1.2779,  2.7583,  5.9909,  ...,  0.4241,  2.9528,  4.2220],\n",
            "        [ 2.9088,  4.8796,  4.0972,  ...,  1.4594, -0.3221,  1.2155],\n",
            "        [ 5.5254,  9.6285,  4.8405,  ..., -2.0341,  2.1192,  2.1470]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1607, 15.1346,  4.7509,  ..., -1.6128, -1.6085,  2.7521],\n",
            "        [ 3.6890,  6.8273,  3.4494,  ...,  2.6111,  0.6727, -1.5408],\n",
            "        [ 4.6612,  4.7310,  2.8193,  ..., -0.5149,  0.0700,  1.7573],\n",
            "        ...,\n",
            "        [ 4.8298,  6.4914,  3.7773,  ..., -0.7682, -0.8368,  2.4390],\n",
            "        [ 0.8641,  2.8769,  4.3828,  ..., -1.3303,  4.1535,  5.3318],\n",
            "        [ 4.7090,  7.9831,  1.9391,  ...,  1.5075, -1.6569,  1.3793]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2398,  6.7415,  4.6520,  ...,  2.1336,  1.6806,  2.9781],\n",
            "        [ 1.5023,  4.6087,  5.1240,  ...,  2.9102, -2.0586,  5.3159],\n",
            "        [ 4.6523,  7.8433,  3.2803,  ...,  3.2616,  1.5647,  2.1574],\n",
            "        ...,\n",
            "        [ 4.8112, 10.1044,  1.8472,  ...,  0.5503, -2.9553,  4.1443],\n",
            "        [ 5.7060,  5.9830,  1.6314,  ...,  2.1113, -0.5051,  1.3371],\n",
            "        [ 6.3482,  7.1096,  4.3446,  ...,  0.5341,  0.9784,  9.6917]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6702,  4.2531,  2.8509,  ...,  2.4886,  1.3153,  2.5885],\n",
            "        [ 7.0460,  6.6304,  1.4602,  ...,  2.1745,  0.7264,  8.4956],\n",
            "        [ 2.9343,  5.6313,  6.0546,  ..., -1.1618,  1.4669,  0.1945],\n",
            "        ...,\n",
            "        [ 4.6778,  6.2473,  0.1023,  ...,  2.3695,  2.2838,  2.5530],\n",
            "        [ 6.1539, 10.7966,  4.8916,  ..., -0.6918, -1.4523,  3.2265],\n",
            "        [-0.2044,  8.6494,  6.7771,  ..., -3.3182,  1.6533,  5.5811]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4421,  6.0400,  6.3022,  ..., -3.9675,  2.5416,  1.2672],\n",
            "        [ 4.7178,  6.0710, -1.0609,  ...,  5.1323,  4.1506,  0.8954],\n",
            "        [ 6.0861,  5.5833, -1.5519,  ...,  0.9585,  2.5012,  1.3960],\n",
            "        ...,\n",
            "        [ 1.3739,  4.7095,  2.6718,  ...,  0.6837, -0.3784,  0.9469],\n",
            "        [ 3.4269,  6.1499,  3.0149,  ...,  0.8319,  2.0448,  2.4846],\n",
            "        [ 2.2239,  8.1013,  5.6124,  ...,  0.0417,  1.3841,  0.7276]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.9064,  5.8344,  2.2580,  ...,  1.9660,  1.1925,  6.3731],\n",
            "        [ 2.3727,  5.2166,  4.8998,  ...,  0.5438,  3.9890,  1.0933],\n",
            "        [ 1.6340,  8.9257,  5.2720,  ..., -0.8816,  2.2425,  3.2844],\n",
            "        ...,\n",
            "        [-1.2163,  5.0789,  6.0281,  ...,  1.0033,  2.3993,  6.3516],\n",
            "        [ 1.1715,  3.0508,  3.5811,  ...,  1.9277,  0.2500,  7.8791],\n",
            "        [ 1.5373,  7.9283,  5.3729,  ..., -1.1206,  1.4695,  4.5774]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0900,  5.7128,  3.7967,  ..., -0.2681, 10.0167,  5.8860],\n",
            "        [ 3.0397,  7.5052,  1.3813,  ...,  2.0262, -0.1044,  8.7085],\n",
            "        [ 6.0863,  5.7524,  0.1151,  ...,  0.0397,  1.6817,  1.8104],\n",
            "        ...,\n",
            "        [ 4.2863,  5.9556,  6.7671,  ..., -1.7180,  3.1217,  0.4122],\n",
            "        [ 2.5347,  5.8794,  4.6410,  ..., -0.1886,  2.6037, -0.6938],\n",
            "        [-0.2959,  2.7535,  3.2103,  ..., -0.0855, -0.7883,  2.4099]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8938,  6.6528,  3.8117,  ...,  1.8150,  1.6253,  0.0224],\n",
            "        [ 5.1142,  7.8449,  4.7136,  ..., -1.2603,  1.0066,  1.4962],\n",
            "        [ 1.1965,  5.7114,  8.1545,  ...,  2.2491,  3.7319,  3.3514],\n",
            "        ...,\n",
            "        [ 6.3566, 12.8990,  4.0217,  ..., -4.3259,  0.3394,  5.7910],\n",
            "        [ 5.1118,  6.6250,  2.4188,  ...,  3.4569,  2.8638, -0.1790],\n",
            "        [ 3.9529, 11.0264, -0.2193,  ..., -1.2569, 10.6961,  3.2439]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3210,  5.2930,  5.4033,  ...,  3.4449,  2.5439,  1.5995],\n",
            "        [ 2.5824,  4.5401,  4.4643,  ...,  2.7404,  1.6156,  0.3654],\n",
            "        [ 2.5927,  5.0137,  5.3538,  ...,  1.6470,  4.6711,  1.6511],\n",
            "        ...,\n",
            "        [ 7.5979,  8.0957, -0.4769,  ...,  1.0029,  1.1677, -0.4049],\n",
            "        [ 2.6650,  7.5599,  1.0596,  ...,  4.5439,  4.5795,  2.0417],\n",
            "        [ 3.7626,  5.1200,  4.9890,  ...,  3.0226,  5.3011, -0.2881]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2399e+00,  8.5980e+00,  6.8249e+00,  ...,  1.4215e+00,\n",
            "         -6.0330e-01, -1.4608e+00],\n",
            "        [ 7.3025e+00,  1.3514e+01,  5.9201e+00,  ...,  1.0682e+00,\n",
            "          3.6873e+00,  1.0380e+00],\n",
            "        [ 3.4544e+00,  7.8783e+00,  5.0810e+00,  ...,  7.2249e-01,\n",
            "          2.5900e+00,  2.9394e+00],\n",
            "        ...,\n",
            "        [ 2.3497e+00,  8.0663e+00,  4.2232e-01,  ...,  4.1001e+00,\n",
            "          5.0348e-01,  2.9060e+00],\n",
            "        [ 6.8843e-01,  3.5213e+00,  8.3196e+00,  ...,  7.1605e-01,\n",
            "          1.5488e+00,  5.4771e+00],\n",
            "        [ 3.1128e+00,  5.5839e+00,  7.5654e+00,  ..., -9.9990e-03,\n",
            "          3.6610e+00,  4.5513e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7149e+00,  1.1516e+01,  4.7793e+00,  ..., -5.5186e-01,\n",
            "          1.2723e+00,  1.6497e+00],\n",
            "        [ 7.5121e+00,  1.1417e+01,  1.6978e+00,  ...,  4.8362e+00,\n",
            "          6.4343e+00, -2.3729e+00],\n",
            "        [ 6.3452e+00,  8.3469e+00,  2.9633e+00,  ..., -1.4331e+00,\n",
            "          6.5573e+00,  1.8671e+00],\n",
            "        ...,\n",
            "        [ 2.4165e+00,  8.1213e+00,  1.9848e+00,  ...,  3.0668e+00,\n",
            "          1.0396e+00,  3.7418e+00],\n",
            "        [ 6.5951e+00,  1.0273e+01,  2.1799e+00,  ..., -2.1049e+00,\n",
            "         -4.4624e-01,  5.9677e+00],\n",
            "        [ 3.6306e+00,  4.7626e+00,  4.0983e+00,  ..., -3.9101e-03,\n",
            "         -3.7845e-01,  3.2269e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[0.1237, 3.1796, 3.6226,  ..., 3.7792, 1.2852, 2.8085],\n",
            "        [5.3728, 5.6582, 1.0478,  ..., 1.5817, 4.4947, 0.1601],\n",
            "        [2.4956, 5.5269, 3.9163,  ..., 1.5535, 3.9057, 2.8689],\n",
            "        ...,\n",
            "        [4.0536, 6.7337, 3.7302,  ..., 1.3384, 5.4314, 1.2760],\n",
            "        [2.3983, 6.6594, 3.6287,  ..., 1.3991, 3.7183, 2.9047],\n",
            "        [4.3722, 7.3971, 0.7129,  ..., 0.3476, 6.7641, 7.9817]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class SimpleMLPTrainingArgs:\n",
        "    \"\"\"\n",
        "    Defining this class implicitly creates an __init__ method, which sets arguments as below, e.g. self.batch_size=64.\n",
        "    Any of these fields can also be overridden when you create an instance, e.g. SimpleMLPTrainingArgs(batch_size=128).\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 3\n",
        "    learning_rate: float = 1e-3\n",
        "\n",
        "\n",
        "def train(args: SimpleMLPTrainingArgs) -> tuple[list[float], SimpleMLP]:\n",
        "    \"\"\"\n",
        "    Trains & returns the model, using training parameters from the `args` object. Returns the model, and loss list.\n",
        "    \"\"\"\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    mnist_trainset, _ = get_mnist()\n",
        "    mnist_trainloader = DataLoader(mnist_trainset, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "    loss_list = []\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        pbar = tqdm(mnist_trainloader)\n",
        "\n",
        "        for imgs, labels in pbar:\n",
        "            # Move data to device, perform forward pass\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            # Calculate loss, perform backward pass\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update logs & progress bar\n",
        "            loss_list.append(loss.item())\n",
        "            pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")\n",
        "\n",
        "    return loss_list, model\n",
        "\n",
        "\n",
        "args = SimpleMLPTrainingArgs()\n",
        "loss_list, model = train(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ENfdZdxajBUO",
        "outputId": "5e333f4f-4764-46cc-f37b-3f98d215836f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e0366020-0607-4aec-8146-7e187d52077d\" class=\"plotly-graph-div\" style=\"height:525px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e0366020-0607-4aec-8146-7e187d52077d\")) {                    Plotly.newPlot(                        \"e0366020-0607-4aec-8146-7e187d52077d\",                        [{\"hovertemplate\":\"Examples seen=%{x}\\u003cbr\\u003eCross entropy loss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,63.829787234042556,127.65957446808511,191.48936170212767,255.31914893617022,319.1489361702128,382.97872340425533,446.8085106382979,510.63829787234044,574.468085106383,638.2978723404256,702.1276595744681,765.9574468085107,829.7872340425532,893.6170212765958,957.4468085106383,1021.2765957446809,1085.1063829787236,1148.936170212766,1212.7659574468084,1276.595744680851,1340.4255319148938,1404.2553191489362,1468.0851063829787,1531.9148936170213,1595.744680851064,1659.5744680851064,1723.404255319149,1787.2340425531916,1851.0638297872342,1914.8936170212767,1978.723404255319,2042.5531914893618,2106.3829787234044,2170.212765957447,2234.0425531914893,2297.872340425532,2361.7021276595747,2425.531914893617,2489.3617021276596,2553.191489361702,2617.021276595745,2680.8510638297876,2744.68085106383,2808.5106382978724,2872.340425531915,2936.1702127659573,3000.0,3063.8297872340427,3127.6595744680853,3191.489361702128,3255.31914893617,3319.148936170213,3382.9787234042556,3446.808510638298,3510.6382978723404,3574.468085106383,3638.297872340426,3702.1276595744685,3765.9574468085107,3829.7872340425533,3893.617021276596,3957.446808510638,4021.276595744681,4085.1063829787236,4148.936170212766,4212.765957446809,4276.595744680852,4340.425531914894,4404.255319148936,4468.085106382979,4531.914893617021,4595.744680851064,4659.574468085107,4723.404255319149,4787.234042553192,4851.063829787234,4914.893617021276,4978.723404255319,5042.553191489362,5106.382978723404,5170.212765957447,5234.04255319149,5297.8723404255325,5361.702127659575,5425.531914893617,5489.36170212766,5553.191489361702,5617.021276595745,5680.851063829788,5744.68085106383,5808.510638297873,5872.340425531915,5936.170212765957,6000.0,6063.829787234043,6127.659574468085,6191.489361702128,6255.319148936171,6319.148936170213,6382.978723404256,6446.808510638298,6510.63829787234,6574.468085106383,6638.297872340426,6702.127659574468,6765.957446808511,6829.787234042554,6893.617021276596,6957.446808510638,7021.276595744681,7085.106382978724,7148.936170212766,7212.765957446809,7276.595744680852,7340.425531914894,7404.255319148937,7468.085106382979,7531.914893617021,7595.744680851064,7659.574468085107,7723.404255319149,7787.234042553192,7851.063829787235,7914.893617021276,7978.723404255319,8042.553191489362,8106.382978723404,8170.212765957447,8234.04255319149,8297.872340425532,8361.702127659575,8425.531914893618,8489.36170212766,8553.191489361703,8617.021276595746,8680.851063829788,8744.68085106383,8808.510638297872,8872.340425531915,8936.170212765957,9000.0,9063.829787234043,9127.659574468085,9191.489361702128,9255.31914893617,9319.148936170213,9382.978723404256,9446.808510638299,9510.638297872341,9574.468085106384,9638.297872340427,9702.127659574468,9765.95744680851,9829.787234042553,9893.617021276596,9957.446808510638,10021.27659574468,10085.106382978724,10148.936170212766,10212.765957446809,10276.595744680852,10340.425531914894,10404.255319148937,10468.08510638298,10531.914893617022,10595.744680851065,10659.574468085108,10723.40425531915,10787.234042553191,10851.063829787234,10914.893617021276,10978.72340425532,11042.553191489362,11106.382978723404,11170.212765957447,11234.04255319149,11297.872340425532,11361.702127659575,11425.531914893618,11489.36170212766,11553.191489361703,11617.021276595746,11680.851063829788,11744.68085106383,11808.510638297872,11872.340425531915,11936.170212765957,12000.0,12063.829787234043,12127.659574468085,12191.489361702128,12255.31914893617,12319.148936170213,12382.978723404256,12446.808510638299,12510.638297872341,12574.468085106384,12638.297872340427,12702.12765957447,12765.957446808512,12829.787234042553,12893.617021276596,12957.446808510638,13021.27659574468,13085.106382978724,13148.936170212766,13212.765957446809,13276.595744680852,13340.425531914894,13404.255319148937,13468.08510638298,13531.914893617022,13595.744680851065,13659.574468085108,13723.40425531915,13787.234042553191,13851.063829787234,13914.893617021276,13978.72340425532,14042.553191489362,14106.382978723404,14170.212765957447,14234.04255319149,14297.872340425532,14361.702127659575,14425.531914893618,14489.36170212766,14553.191489361703,14617.021276595746,14680.851063829788,14744.680851063831,14808.510638297874,14872.340425531915,14936.170212765957,15000.0,15063.829787234043,15127.659574468085,15191.489361702128,15255.31914893617,15319.148936170213,15382.978723404256,15446.808510638299,15510.638297872341,15574.468085106384,15638.297872340427,15702.12765957447,15765.957446808512,15829.787234042553,15893.617021276596,15957.446808510638,16021.27659574468,16085.106382978724,16148.936170212766,16212.765957446809,16276.595744680852,16340.425531914894,16404.255319148935,16468.08510638298,16531.91489361702,16595.744680851065,16659.574468085106,16723.40425531915,16787.23404255319,16851.063829787236,16914.893617021276,16978.72340425532,17042.55319148936,17106.382978723406,17170.212765957447,17234.04255319149,17297.872340425532,17361.702127659577,17425.531914893618,17489.36170212766,17553.191489361703,17617.021276595744,17680.85106382979,17744.68085106383,17808.510638297874,17872.340425531915,17936.17021276596,18000.0,18063.829787234044,18127.659574468085,18191.48936170213,18255.31914893617,18319.148936170215,18382.978723404256,18446.808510638297,18510.63829787234,18574.468085106382,18638.297872340427,18702.127659574468,18765.957446808512,18829.787234042553,18893.617021276597,18957.44680851064,19021.276595744683,19085.106382978724,19148.936170212768,19212.76595744681,19276.595744680853,19340.425531914894,19404.255319148935,19468.08510638298,19531.91489361702,19595.744680851065,19659.574468085106,19723.40425531915,19787.23404255319,19851.063829787236,19914.893617021276,19978.72340425532,20042.55319148936,20106.382978723406,20170.212765957447,20234.04255319149,20297.872340425532,20361.702127659577,20425.531914893618,20489.36170212766,20553.191489361703,20617.021276595744,20680.85106382979,20744.68085106383,20808.510638297874,20872.340425531915,20936.17021276596,21000.0,21063.829787234044,21127.659574468085,21191.48936170213,21255.31914893617,21319.148936170215,21382.978723404256,21446.8085106383,21510.63829787234,21574.468085106382,21638.297872340427,21702.127659574468,21765.957446808512,21829.787234042553,21893.617021276597,21957.44680851064,22021.276595744683,22085.106382978724,22148.936170212768,22212.76595744681,22276.595744680853,22340.425531914894,22404.25531914894,22468.08510638298,22531.91489361702,22595.744680851065,22659.574468085106,22723.40425531915,22787.23404255319,22851.063829787236,22914.893617021276,22978.72340425532,23042.55319148936,23106.382978723406,23170.212765957447,23234.04255319149,23297.872340425532,23361.702127659577,23425.531914893618,23489.36170212766,23553.191489361703,23617.021276595744,23680.85106382979,23744.68085106383,23808.510638297874,23872.340425531915,23936.17021276596,24000.0,24063.829787234044,24127.659574468085,24191.48936170213,24255.31914893617,24319.148936170215,24382.978723404256,24446.8085106383,24510.63829787234,24574.468085106382,24638.297872340427,24702.127659574468,24765.957446808512,24829.787234042553,24893.617021276597,24957.44680851064,25021.276595744683,25085.106382978724,25148.936170212768,25212.76595744681,25276.595744680853,25340.425531914894,25404.25531914894,25468.08510638298,25531.914893617024,25595.744680851065,25659.574468085106,25723.40425531915,25787.23404255319,25851.063829787236,25914.893617021276,25978.72340425532,26042.55319148936,26106.382978723406,26170.212765957447,26234.04255319149,26297.872340425532,26361.702127659577,26425.531914893618,26489.361702127662,26553.191489361703,26617.021276595744,26680.85106382979,26744.68085106383,26808.510638297874,26872.340425531915,26936.17021276596,27000.0,27063.829787234044,27127.659574468085,27191.48936170213,27255.31914893617,27319.148936170215,27382.978723404256,27446.8085106383,27510.63829787234,27574.468085106382,27638.297872340427,27702.127659574468,27765.957446808512,27829.787234042553,27893.617021276597,27957.44680851064,28021.276595744683,28085.106382978724,28148.936170212768,28212.76595744681,28276.595744680853,28340.425531914894,28404.25531914894,28468.08510638298,28531.914893617024,28595.744680851065,28659.574468085106,28723.40425531915,28787.23404255319,28851.063829787236,28914.893617021276,28978.72340425532,29042.55319148936,29106.382978723406,29170.212765957447,29234.04255319149,29297.872340425532,29361.702127659577,29425.531914893618,29489.361702127662,29553.191489361703,29617.021276595748,29680.85106382979,29744.68085106383,29808.510638297874,29872.340425531915,29936.17021276596,30000.0],\"xaxis\":\"x\",\"y\":[3.175673484802246,2.588740348815918,2.0292439460754395,2.166355609893799,1.8911356925964355,1.8590826988220215,1.4955227375030518,1.336326003074646,1.2815840244293213,1.2473094463348389,1.2004797458648682,1.0704233646392822,0.8278264999389648,0.9893299341201782,0.8378551006317139,0.9565356969833374,0.9635264277458191,1.0626908540725708,0.9470568895339966,0.6664418578147888,0.8126954436302185,0.652880847454071,0.6736711859703064,0.4253055453300476,0.6944774985313416,0.6129745841026306,0.5262153744697571,0.4787645637989044,0.688488245010376,0.46014878153800964,0.5348949432373047,0.475176066160202,0.6774412989616394,0.37511110305786133,0.594236433506012,0.5033444166183472,0.46646857261657715,0.6245417594909668,0.644877016544342,0.5657965540885925,0.4157121479511261,0.5299113988876343,0.49456286430358887,0.5638440251350403,0.44770318269729614,0.5755975246429443,0.4609808623790741,0.42346876859664917,0.4576214551925659,0.34406429529190063,0.3940739035606384,0.309499591588974,0.6162077784538269,0.24706804752349854,0.3120986223220825,0.9920980930328369,0.32608476281166077,0.4248047471046448,0.21757221221923828,0.5075684785842896,0.34743064641952515,0.2664109468460083,0.3216049075126648,0.5070481300354004,0.46175113320350647,0.39728400111198425,0.44676271080970764,0.2512528896331787,0.475574254989624,0.5748203992843628,0.7019076347351074,0.5182346105575562,0.2786461412906647,0.4362388551235199,0.18551044166088104,0.36019590497016907,0.5711031556129456,0.44820502400398254,0.5406650304794312,0.569226086139679,0.5209848880767822,0.3582800030708313,0.47312402725219727,0.22225399315357208,0.4878270626068115,0.48367831110954285,0.4245786964893341,0.2813575267791748,0.3101900517940521,0.4606375992298126,0.34666088223457336,0.5640859603881836,0.37040817737579346,0.3197830617427826,0.39295873045921326,0.2890683710575104,0.39222994446754456,0.2522711157798767,0.40691423416137695,0.30286240577697754,0.2660682499408722,0.46041086316108704,0.31251126527786255,0.42397600412368774,0.4263748228549957,0.24613730609416962,0.560873806476593,0.24322235584259033,0.39115041494369507,0.24085848033428192,0.38943716883659363,0.2733917236328125,0.31835663318634033,0.30066773295402527,0.18352405726909637,0.3318149149417877,0.2245655357837677,0.5986000299453735,0.2256796658039093,0.28783783316612244,0.2590588927268982,0.3282063901424408,0.1521236002445221,0.3301442861557007,0.6456814408302307,0.17126256227493286,0.33946341276168823,0.31408679485321045,0.2639307677745819,0.31217944622039795,0.23549821972846985,0.22887283563613892,0.23471571505069733,0.2152927666902542,0.3088039755821228,0.3172348737716675,0.285798043012619,0.21339623630046844,0.33680862188339233,0.3504226505756378,0.45182281732559204,0.2693977653980255,0.1641671061515808,0.2071947455406189,0.2165258675813675,0.34590810537338257,0.27610912919044495,0.41542401909828186,0.22824978828430176,0.3466525077819824,0.37018150091171265,0.3402901887893677,0.373073548078537,0.189458966255188,0.2172756940126419,0.5041530132293701,0.8582248687744141,0.30880555510520935,0.17502933740615845,0.36634254455566406,0.3338046967983246,0.31689003109931946,0.18247553706169128,0.3346922993659973,0.17987754940986633,0.17322926223278046,0.28613921999931335,0.13724194467067719,0.3466004729270935,0.3007836639881134,0.22946953773498535,0.2688713073730469,0.2617451548576355,0.1727599948644638,0.27798324823379517,0.18008148670196533,0.38215452432632446,0.2430969625711441,0.35921239852905273,0.20852038264274597,0.2284596711397171,0.207639679312706,0.17077980935573578,0.29242706298828125,0.45222750306129456,0.1460387408733368,0.18915343284606934,0.2150614708662033,0.26237913966178894,0.2902878224849701,0.2376834750175476,0.3325575888156891,0.3348388969898224,0.32597866654396057,0.24572597444057465,0.20558232069015503,0.15458577871322632,0.24205847084522247,0.2194681614637375,0.23912028968334198,0.16313119232654572,0.4044301509857178,0.17133601009845734,0.2636878192424774,0.151483416557312,0.2760681211948395,0.19388046860694885,0.1795538067817688,0.190656840801239,0.22645112872123718,0.0965663343667984,0.366440087556839,0.1445489376783371,0.18972784280776978,0.29166001081466675,0.27933627367019653,0.11406392604112625,0.3040921092033386,0.21867769956588745,0.1087593212723732,0.1844795197248459,0.2868109941482544,0.23814263939857483,0.2770555019378662,0.0456111915409565,0.22164258360862732,0.35504889488220215,0.4006210267543793,0.16482621431350708,0.20204007625579834,0.2737414240837097,0.2440122663974762,0.39930272102355957,0.17212679982185364,0.39526039361953735,0.4409121870994568,0.18207277357578278,0.20631423592567444,0.18848460912704468,0.2691860795021057,0.2032696157693863,0.26956748962402344,0.2559168040752411,0.13136066496372223,0.16726216673851013,0.19807523488998413,0.1910712867975235,0.3060861825942993,0.1651993840932846,0.21660518646240234,0.2029409408569336,0.272460013628006,0.1754111349582672,0.11918549984693527,0.2102660983800888,0.24333025515079498,0.22999553382396698,0.27506786584854126,0.2025415003299713,0.28248387575149536,0.2598171532154083,0.2246864289045334,0.21183182299137115,0.17743739485740662,0.17968353629112244,0.3246648609638214,0.09913130104541779,0.1410977989435196,0.22194670140743256,0.20392175018787384,0.19673098623752594,0.2917342185974121,0.20844122767448425,0.1008862629532814,0.14483825862407684,0.19591528177261353,0.14820875227451324,0.19561024010181427,0.20626705884933472,0.14780353009700775,0.0751192569732666,0.2785242199897766,0.28151893615722656,0.25943782925605774,0.2574300765991211,0.2685985565185547,0.18249444663524628,0.07979286462068558,0.3632468283176422,0.2611549496650696,0.185989111661911,0.2007608562707901,0.22657209634780884,0.20888960361480713,0.1754065304994583,0.35275205969810486,0.17378553748130798,0.09303635358810425,0.3779754340648651,0.1834006905555725,0.30668434500694275,0.19792422652244568,0.18747690320014954,0.1651889979839325,0.2947159707546234,0.15425781905651093,0.3442412316799164,0.1461697369813919,0.18960636854171753,0.5204260349273682,0.22734016180038452,0.18540918827056885,0.07747114449739456,0.1288839429616928,0.12225615978240967,0.12378566712141037,0.11037497967481613,0.11742179840803146,0.13160507380962372,0.2098175585269928,0.1402190625667572,0.21310365200042725,0.24005629122257233,0.2842119336128235,0.06360757350921631,0.2386857569217682,0.10453464090824127,0.16254839301109314,0.1231539398431778,0.12013539671897888,0.20180463790893555,0.12208987772464752,0.10494372993707657,0.13612830638885498,0.29703986644744873,0.1340993493795395,0.21402287483215332,0.21896927058696747,0.21152092516422272,0.162125363945961,0.3257347345352173,0.2522636651992798,0.1465606540441513,0.157770037651062,0.09924906492233276,0.0873296782374382,0.20391422510147095,0.1440911591053009,0.16558146476745605,0.1442321538925171,0.06922847032546997,0.25821271538734436,0.07855863124132156,0.21466144919395447,0.3118968904018402,0.21423904597759247,0.10797865688800812,0.205069899559021,0.2161325216293335,0.06324471533298492,0.06295037269592285,0.11306603997945786,0.312757670879364,0.2447117120027542,0.10994338989257812,0.11408868432044983,0.26072409749031067,0.13823756575584412,0.2685733139514923,0.20975428819656372,0.2502788305282593,0.2065325230360031,0.2465018481016159,0.15459388494491577,0.1384235918521881,0.11843562126159668,0.23465220630168915,0.19952890276908875,0.08291491866111755,0.22210435569286346,0.06945645064115524,0.17860151827335358,0.1541333794593811,0.12887528538703918,0.1405974179506302,0.1328802853822708,0.16402538120746613,0.10636632889509201,0.21025921404361725,0.05220659449696541,0.11449503153562546,0.14513282477855682,0.13356107473373413,0.21129648387432098,0.18845917284488678,0.1324852854013443,0.1872243583202362,0.18292871117591858,0.16484494507312775,0.12204159796237946,0.15664014220237732,0.14303508400917053,0.09561441093683243,0.24954333901405334,0.2698242664337158,0.061741236597299576,0.10342662036418915,0.11283925175666809,0.1296139806509018,0.4352637827396393,0.10398615896701813,0.15228895843029022,0.3078705072402954,0.22079713642597198,0.19421474635601044,0.1804543137550354,0.11071693152189255,0.13480040431022644,0.115812286734581,0.22721433639526367,0.1294855773448944,0.05899343267083168,0.17963933944702148,0.12793827056884766,0.17224101722240448,0.3066725730895996,0.3637729287147522,0.18616019189357758,0.156432643532753,0.15861186385154724,0.14296682178974152,0.21686896681785583,0.1227358803153038,0.30844569206237793,0.1827806979417801,0.09720601886510849,0.15615428984165192,0.11785896122455597,0.16690395772457123,0.11196953058242798,0.10492061078548431,0.09144850820302963,0.09271428734064102,0.18648672103881836,0.13820409774780273,0.1967131346464157,0.1584465503692627,0.1622600257396698,0.12233638763427734,0.1526494175195694,0.13478784263134003,0.1752893328666687,0.2894497215747833,0.040578775107860565,0.22275522351264954,0.14033959805965424,0.037976667284965515,0.1737353801727295,0.14062966406345367,0.17414750158786774,0.08464911580085754,0.15326008200645447,0.33391445875167847,0.1896049827337265,0.08420130610466003,0.18966156244277954,0.177374005317688,0.2729228436946869,0.15908591449260712,0.05921381711959839,0.24829202890396118],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Examples seen\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Cross entropy loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"SimpleMLP training on MNIST\"},\"width\":700,\"hovermode\":\"x unified\"},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e0366020-0607-4aec-8146-7e187d52077d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "line(\n",
        "    loss_list,\n",
        "    x_max=args.epochs * len(mnist_trainset),\n",
        "    labels={\"x\": \"Examples seen\", \"y\": \"Cross entropy loss\"},\n",
        "    title=\"SimpleMLP training on MNIST\",\n",
        "    width=700,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_sh7yNCjBUO"
      },
      "source": [
        "### Exercise - add a validation loop\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵🔵\n",
        ">\n",
        "> You should spend up to ~20 minutes on this exercise.\n",
        "> It is very important that you understand training loops and how they work, because we'll be doing a lot of model training in this way.\n",
        "> ```\n",
        "\n",
        "Edit the `train` function above to include a validation loop. Train your model, making sure you measure the accuracy at the end of each epoch.\n",
        "\n",
        "Here are a few tips to help you:\n",
        "\n",
        "* You'll need a dataloader for the testset, just like we did for the trainset. It doesn't matter whether you shuffle the testset or not, because we're not updating our model parameters during validation (we usually set `shuffle=False` for testsets).\n",
        "    * You can set the same batch size as for your training set (we'll discuss more optimal choices for this later in the course).\n",
        "* During the validation step, you should be measuring **accuracy**, which is defined as **the fraction of correctly classified images**.\n",
        "    * Note that (unlike loss) accuracy should only be logged after you've gone through the whole validation set. This is because your model doesn't update between computing different accuracies, so it doesn't make sense to log all of them separately.\n",
        "    * Computing accuracy is meant to be a very short operation, so you shouldn't need a progress bar.\n",
        "    * You can wrap your forward pass in `with t.inference_mode():` to make sure that your model is in inference mode during validation (i.e. gradients don't propagate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3TpwzEitjBUO",
        "outputId": "8165b923-2ae2-417d-c3d9-8e419887f601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3ecb7e8cc1f94de2a853acd2787aa1e9",
            "3f21e3508bb342f985f89ca50d486b3f",
            "ba309e450fe24f35b1ec3866feaf804c",
            "518810628847449996f82e610a475b20",
            "5f6a779ecff6446aaf307bc1bef9f084",
            "8c582b8cbb5046a4beac0b8078376099",
            "5ede70d2f2914e90bbbae1e0d8d1f8cd",
            "64b4e1adb73149c8b613c98a3db01435",
            "bcb90858048744179d979274d2ca5c46",
            "030d9f81b3694c48b2b64d90441fb148",
            "bd38dfa7809c4ce890a93cb9701d79ef",
            "720c896ae37b4bb291e965b7a588de30",
            "5c9ac43bf8f14e9babdd8ebd8c2ad825",
            "f248b6ae02e848c1ab1cd481102ee54b",
            "c708e737efd54eb1b369fd8a96fcac14",
            "c4e8d5fdf1164d2e8c77717ef2a5e050",
            "36b0f016140449f1a3e40ee5e8331934",
            "55a22e96b53f4b4cbe09f5ac096d509a",
            "eee78d18643244c4b0295f9e85ab7ea7",
            "d0bacff3c463477fba607dfa4c7ce1c4",
            "b27b12fb29aa4e5298e69b8574ab529d",
            "69d221964d774338bf4b05e413774cf3",
            "9102a50bb03e4e3b829ec085d0c59b47",
            "053ae1a2cb594ed594b68d42c89a0955",
            "a1e34c78f5a5452e8a3ee89404b10db9",
            "9c717afd6da840bb91208024d445d580",
            "d7d67376b1fd4481a04f11d99ecda8d4",
            "7bea6293fbea4f24aed5ec368546638a",
            "32177264f2f0471f83030ae98f43bc0f",
            "ab65329f0bef4b9fac962d5307ea9406",
            "c8a8e8939bc546978f633c5b8b0da063",
            "2af49f6717d4433cb9201b48302878e6",
            "f4cc61864acc4fc9a9d3e73725f20774"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ecb7e8cc1f94de2a853acd2787aa1e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.0585,  0.1006, -0.3539,  ..., -0.4793, -0.3233, -0.3962],\n",
            "        [ 0.8117,  0.3277, -1.0380,  ..., -1.1950,  3.3013,  2.0564],\n",
            "        [ 1.1005,  0.5878, -0.6670,  ..., -0.6366,  0.3488,  1.2131],\n",
            "        ...,\n",
            "        [ 1.6121,  0.0347,  0.6407,  ..., -1.4481,  0.9810,  1.4862],\n",
            "        [-0.2672,  0.6825, -1.8822,  ..., -0.6276,  0.5926,  1.7304],\n",
            "        [ 1.1291, -0.9980, -1.2746,  ..., -1.4901,  0.5004,  2.2122]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2519,  0.3610, -0.3555,  ..., -1.3349,  0.6106,  0.2866],\n",
            "        [ 1.1815, -0.0981, -2.0381,  ..., -1.8337,  0.8895,  1.7083],\n",
            "        [ 0.9048,  0.2493,  0.0847,  ...,  0.8441,  0.4213,  1.9794],\n",
            "        ...,\n",
            "        [ 0.1544,  0.7672, -1.0874,  ...,  1.4792, -0.4455,  0.2941],\n",
            "        [ 1.3869, -0.0924, -2.6159,  ...,  0.1638,  1.1319,  1.4739],\n",
            "        [ 1.4762,  1.0835, -1.4981,  ...,  0.4054,  2.6280,  4.8109]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3843,  0.1954, -2.7453,  ..., -0.2948,  1.5338, -1.0599],\n",
            "        [ 2.3397,  0.9273, -0.9202,  ..., -0.4762,  0.2406,  2.6354],\n",
            "        [ 1.5023,  0.3410, -1.3622,  ..., -0.7854,  1.4354,  1.2550],\n",
            "        ...,\n",
            "        [-0.2579, -0.4807, -1.5698,  ...,  0.0561,  0.1585,  0.8319],\n",
            "        [ 0.8599, -0.2204, -3.0068,  ..., -0.1373,  0.9239,  0.0462],\n",
            "        [ 0.4740, -1.2929,  0.1205,  ..., -0.5872,  0.5651,  0.2691]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1178, -0.4862, -1.9913,  ...,  0.3883,  0.0885, -0.2863],\n",
            "        [ 1.5970, -0.9276, -1.9908,  ...,  0.8822, -0.6661,  0.5937],\n",
            "        [ 1.1392,  0.4184, -3.7712,  ..., -1.3841,  1.3706, -0.6244],\n",
            "        ...,\n",
            "        [ 0.9135,  0.9893, -2.7872,  ..., -0.1663,  0.4508,  1.0626],\n",
            "        [ 1.6233, -0.9984, -4.0289,  ..., -2.9244,  2.3426,  0.1815],\n",
            "        [-0.4879, -2.1658, -4.2052,  ..., -1.6240,  2.4822,  0.7296]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8041, -0.2564, -1.1852,  ..., -0.3573,  0.3720,  1.1397],\n",
            "        [-0.1691, -0.7639, -1.4270,  ...,  0.2961,  0.8432, -0.0222],\n",
            "        [ 1.3500,  0.7050, -0.9683,  ...,  0.1782,  0.3958,  0.4405],\n",
            "        ...,\n",
            "        [ 0.5842, -0.3598, -2.9173,  ..., -1.7233,  0.0699, -0.3916],\n",
            "        [ 0.6741,  0.5695, -2.9878,  ..., -1.4358,  0.9187,  0.0784],\n",
            "        [ 0.7810, -1.4265, -1.4869,  ..., -1.1440,  0.9213,  1.5132]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1134, -2.0238, -1.3171,  ..., -1.0134,  1.3760,  1.4389],\n",
            "        [ 1.7258, -2.7917, -2.8107,  ..., -2.1152, -1.0915,  0.6334],\n",
            "        [ 2.3285, -0.7385, -0.8982,  ..., -0.7685,  1.3752,  0.3091],\n",
            "        ...,\n",
            "        [ 0.2067, -2.5057, -1.8238,  ..., -1.2284,  1.4457, -0.0714],\n",
            "        [ 0.6313,  0.0536, -1.8755,  ..., -1.4484,  2.2696,  1.5496],\n",
            "        [ 1.0036, -0.2759, -1.6452,  ..., -0.6892,  1.7091,  0.3074]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1624,  0.1130, -1.8653,  ...,  0.1310, -0.4099,  4.0748],\n",
            "        [ 1.1648,  1.1767, -2.1419,  ..., -0.4747,  2.4367, -1.4900],\n",
            "        [-0.7770, -1.9279, -3.2627,  ..., -2.7162,  0.5061, -0.5542],\n",
            "        ...,\n",
            "        [ 0.4451,  0.0292, -2.8398,  ...,  0.2124,  1.5665,  1.0039],\n",
            "        [ 0.2169,  0.2692, -2.9662,  ..., -0.4208,  1.6112,  1.5862],\n",
            "        [ 0.5812, -0.3627, -3.0192,  ..., -0.7242,  0.7025, -1.4483]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5095, -0.8076, -3.4180,  ...,  0.2520,  1.6060,  0.2189],\n",
            "        [-0.3038, -2.2164, -1.6164,  ..., -1.0739,  0.4774, -0.3487],\n",
            "        [ 1.0244, -1.5884, -4.2572,  ..., -1.2694,  1.9509, -0.6030],\n",
            "        ...,\n",
            "        [ 1.1230, -0.9788, -4.0708,  ..., -1.0232,  1.7898, -0.2760],\n",
            "        [ 3.0279, -2.7945, -2.8688,  ...,  0.3434,  0.4366,  0.5812],\n",
            "        [ 2.7993, -1.5146, -2.5825,  ..., -1.4510,  1.4231,  0.4755]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3071e-01, -3.9861e-01, -6.7191e-01,  ..., -7.8309e-02,\n",
            "          3.4888e-03,  5.6648e-01],\n",
            "        [ 1.4565e+00, -1.6675e+00, -2.2483e+00,  ..., -3.2989e+00,\n",
            "          6.4711e-01, -3.6420e-01],\n",
            "        [ 1.9069e+00, -2.1290e+00, -4.8887e+00,  ..., -3.2989e+00,\n",
            "         -3.1913e-01,  1.1014e+00],\n",
            "        ...,\n",
            "        [ 1.8857e+00, -6.1161e-02, -1.6221e+00,  ..., -6.7983e-01,\n",
            "          4.5508e-01,  7.5703e-01],\n",
            "        [ 2.8432e+00, -9.5232e-01, -3.9826e+00,  ..., -2.8764e-01,\n",
            "          1.1383e+00,  1.4317e+00],\n",
            "        [ 1.7861e+00, -5.0419e-01, -1.3839e+00,  ..., -2.1681e-01,\n",
            "          3.6062e-01,  1.5090e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1998, -0.6407, -2.8832,  ..., -0.7373,  0.7716,  0.1041],\n",
            "        [ 1.1690, -1.7120, -2.2308,  ..., -1.2159,  2.0049,  1.1374],\n",
            "        [ 0.3232, -1.1404, -2.3530,  ..., -0.9621,  0.8875, -0.6717],\n",
            "        ...,\n",
            "        [ 1.8786, -0.3805, -4.3821,  ..., -1.4318,  1.9695, -0.9634],\n",
            "        [ 2.4756, -0.5410, -0.2655,  ..., -1.9627,  1.7796, -1.6000],\n",
            "        [ 1.6109, -0.7587, -1.2396,  ...,  0.3679,  1.0003, -0.2084]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6139, -1.0219, -5.9997,  ..., -0.2519,  1.8521, -0.1639],\n",
            "        [ 1.8544, -1.6118, -4.6201,  ..., -2.3973,  2.6022, -1.3159],\n",
            "        [ 1.4741, -0.5704, -2.5174,  ..., -0.3296,  2.1287, -0.6412],\n",
            "        ...,\n",
            "        [ 1.1803,  1.0260, -3.0302,  ..., -1.4063,  1.6674, -1.9219],\n",
            "        [ 1.1447,  0.8167, -1.9564,  ..., -0.8474,  1.6659, -0.2041],\n",
            "        [ 1.6473, -0.2655, -3.5538,  ..., -1.3059,  1.9143, -0.3013]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3274, -0.4541, -1.5449,  ...,  0.5258, -0.1212,  0.0499],\n",
            "        [ 0.8520, -0.3787, -4.9396,  ..., -2.2874,  1.0619, -1.5439],\n",
            "        [ 2.2969, -1.7387, -4.0253,  ..., -3.3886,  0.2130, -0.0443],\n",
            "        ...,\n",
            "        [ 0.7570,  1.2664, -1.9517,  ..., -1.5328,  2.1540, -1.1386],\n",
            "        [-0.2802,  0.6267, -4.6591,  ..., -2.4037,  2.0087, -1.7189],\n",
            "        [ 2.4778, -0.7672, -4.0730,  ..., -0.0723,  0.4565,  0.1969]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 7.5743e-01, -3.1194e-02, -1.9986e+00,  ..., -7.9070e-01,\n",
            "          1.6224e+00, -1.4158e+00],\n",
            "        [ 1.3283e+00, -5.7496e-01, -4.8024e+00,  ..., -1.0870e+00,\n",
            "          2.6947e+00, -3.2245e-01],\n",
            "        [ 1.4557e+00, -2.5646e-01, -3.8944e+00,  ..., -6.2409e-01,\n",
            "          1.5761e+00, -1.6167e-03],\n",
            "        ...,\n",
            "        [ 4.9908e-01, -7.2189e-01, -2.0428e+00,  ..., -9.3314e-01,\n",
            "          2.7093e+00, -6.8397e-01],\n",
            "        [ 2.8250e+00,  2.3960e-01, -3.1239e+00,  ..., -1.1195e+00,\n",
            "          2.2426e+00, -2.0721e+00],\n",
            "        [ 1.6574e+00, -2.3255e+00, -2.5668e+00,  ..., -1.2153e+00,\n",
            "          2.8737e+00, -1.3344e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5453, -3.8950, -4.9112,  ..., -4.2402,  1.3520, -2.0801],\n",
            "        [ 0.2020, -0.2485, -3.9512,  ..., -2.1794,  2.4225,  0.7363],\n",
            "        [ 2.6428, -1.3794, -2.6257,  ..., -3.2880,  2.3489,  0.2214],\n",
            "        ...,\n",
            "        [ 3.1593, -1.4285, -5.4223,  ...,  0.0286,  1.6464,  0.7606],\n",
            "        [ 2.1999,  0.8889, -2.0638,  ..., -2.1265,  2.5336, -0.2139],\n",
            "        [ 1.5598, -1.4235, -1.4870,  ..., -2.1380,  2.5009, -0.8251]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1526, -0.1137, -4.1657,  ..., -3.0537,  2.9109,  0.4280],\n",
            "        [ 2.2279, -1.0188, -4.4417,  ..., -1.7894,  2.6298, -0.4767],\n",
            "        [ 1.8975, -1.7140, -3.1503,  ...,  0.7477,  0.3334,  0.9130],\n",
            "        ...,\n",
            "        [ 1.5858, -2.1940, -3.6958,  ..., -1.7985,  1.1101, -1.0619],\n",
            "        [ 1.0783, -1.3702, -4.4532,  ..., -2.9732,  1.7636, -1.4069],\n",
            "        [ 2.6600, -1.2277, -5.2029,  ..., -1.8109,  2.3496, -0.4751]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1411,  1.2447, -1.3567,  ...,  0.8689,  0.4468, -0.8227],\n",
            "        [ 2.7642, -0.9147, -5.6620,  ..., -2.6666,  2.7178, -0.1320],\n",
            "        [ 3.2592, -1.2260, -5.1560,  ..., -4.1892,  1.5497, -1.4268],\n",
            "        ...,\n",
            "        [-0.0809,  1.2382, -4.0455,  ..., -2.6587,  1.9679, -1.3712],\n",
            "        [ 2.3774,  0.7270, -3.0975,  ..., -2.3351,  1.2735, -1.5023],\n",
            "        [ 2.2404, -0.3223, -4.0342,  ..., -0.9505,  2.7409, -1.2996]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1464, -1.2891, -1.3675,  ..., -1.6882, -0.1071, -2.8322],\n",
            "        [ 0.2159, -1.1961, -3.4603,  ..., -0.2845,  2.4463,  1.1013],\n",
            "        [ 1.0947, -2.4199, -3.3641,  ..., -1.6038,  2.4951, -1.3243],\n",
            "        ...,\n",
            "        [ 2.6674,  1.0570, -3.7957,  ..., -3.3605,  0.6454, -1.3458],\n",
            "        [ 1.1128, -1.3126, -4.0029,  ..., -1.4526,  2.0627, -0.3670],\n",
            "        [ 1.8456,  0.5363, -2.9407,  ..., -0.7177,  2.7060,  1.4126]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7988, -0.6934, -3.9964,  ..., -1.7698,  2.5061,  0.0371],\n",
            "        [-0.1114, -1.4148, -1.7557,  ..., -1.7884,  2.9968,  0.5696],\n",
            "        [ 1.5556,  0.1641, -4.2812,  ..., -2.7407,  2.2283, -0.6413],\n",
            "        ...,\n",
            "        [ 0.7661, -0.0252, -2.5076,  ..., -2.5410,  1.6035, -1.1927],\n",
            "        [ 2.0862, -1.1509, -4.7864,  ..., -2.1883,  0.6704,  0.6940],\n",
            "        [ 0.1385, -0.1491, -5.6365,  ..., -2.2385,  2.0791,  0.8905]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4600, -0.8339, -3.0000,  ..., -2.4152,  0.8801,  0.2969],\n",
            "        [ 1.2208, -1.3231, -4.3554,  ..., -0.9409,  2.6865, -0.1937],\n",
            "        [ 1.5174, -0.9986, -4.7179,  ..., -2.9625,  1.3447,  1.4879],\n",
            "        ...,\n",
            "        [ 1.6202, -0.2850, -2.9856,  ..., -0.5408,  2.4086, -1.4983],\n",
            "        [ 1.4047,  1.0519, -4.6418,  ..., -1.3373,  2.2981, -0.5445],\n",
            "        [ 1.6364, -0.1248, -4.3154,  ..., -0.9319,  1.5687, -2.1429]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7434, -0.8951, -3.2542,  ..., -1.7010,  1.3179, -1.2540],\n",
            "        [ 0.0126, -2.0816, -5.7826,  ..., -2.8171,  1.9902, -0.2872],\n",
            "        [ 0.0585, -1.1930, -2.5387,  ..., -1.6911,  0.2481, -0.1044],\n",
            "        ...,\n",
            "        [ 2.2970, -1.0295, -3.4755,  ..., -0.9589,  2.4616, -1.1054],\n",
            "        [ 3.1373,  0.7701, -3.1267,  ..., -3.1897,  0.7423, -2.5087],\n",
            "        [ 2.7073, -1.0696, -3.6104,  ..., -1.7772,  0.4080, -0.3976]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4253, -0.7887, -4.6430,  ..., -1.8537,  2.7852, -0.2969],\n",
            "        [ 3.2326,  0.3041, -1.8270,  ..., -2.8351,  1.2194, -0.7229],\n",
            "        [-0.2326,  1.4005, -1.5909,  ..., -0.8285,  1.1643, -1.6398],\n",
            "        ...,\n",
            "        [ 1.8306,  1.0669, -4.1976,  ..., -1.3134,  2.2075, -0.9127],\n",
            "        [ 2.5824, -0.5582, -2.2714,  ..., -1.5910,  1.7045, -1.8677],\n",
            "        [ 1.3341, -2.0179, -3.5647,  ..., -2.6481,  2.5803,  0.8605]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2951,  1.5598, -4.1512,  ..., -2.0807, -0.9420, -1.4736],\n",
            "        [ 1.8446,  0.4459, -2.6162,  ..., -2.7105,  1.2585, -1.2729],\n",
            "        [ 0.8952,  1.1097, -4.6885,  ..., -2.0735,  1.1182, -0.8985],\n",
            "        ...,\n",
            "        [ 0.6518, -0.7056, -4.2759,  ..., -0.0236,  0.4317, -0.4057],\n",
            "        [ 1.9122,  0.6547, -3.2783,  ..., -1.7987,  0.7937,  1.3188],\n",
            "        [-0.7367, -2.2597, -3.1493,  ..., -3.5107,  1.3909, -1.5360]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4329, -1.0678, -4.6915,  ..., -0.6987, -0.4459, -0.7091],\n",
            "        [ 0.6063, -0.5610, -4.5610,  ..., -2.6865,  1.5031, -0.8361],\n",
            "        [-1.3939, -0.5387, -3.1529,  ..., -2.6306,  3.5629,  2.1114],\n",
            "        ...,\n",
            "        [ 3.8331,  1.6404, -2.1700,  ..., -1.0791,  0.1425, -1.3029],\n",
            "        [ 0.6201, -1.4719, -5.5554,  ..., -2.2462,  2.6893, -0.1984],\n",
            "        [ 1.4091, -1.1786, -4.5051,  ..., -1.2506,  2.0997,  0.0572]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2343, -0.6531, -3.7881,  ..., -1.8209, -0.7640, -0.3297],\n",
            "        [ 0.5390,  0.9020, -1.1917,  ..., -1.7364,  2.1836, -1.4358],\n",
            "        [ 1.6393,  1.4667, -4.0913,  ..., -1.2371,  2.7055, -1.2564],\n",
            "        ...,\n",
            "        [ 0.2105,  0.5878, -2.6334,  ..., -1.9800,  2.1418,  1.6694],\n",
            "        [ 1.7307,  0.4015, -3.1023,  ..., -0.2326,  0.3764, -2.8324],\n",
            "        [ 1.0856, -1.2711, -4.7263,  ..., -3.6703,  1.1967, -1.2930]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2093,  0.2958, -4.1630,  ..., -2.8166,  1.5726, -0.7516],\n",
            "        [ 2.2596,  1.2232, -4.0604,  ..., -1.3868,  0.2120,  0.0281],\n",
            "        [ 0.3335,  1.7032, -4.2879,  ...,  0.6187,  1.9321,  0.2981],\n",
            "        ...,\n",
            "        [ 1.8144, -0.6703, -3.9830,  ..., -0.9946,  2.4068, -0.6062],\n",
            "        [ 1.2088,  1.3101, -4.2591,  ..., -1.5131,  1.2596,  0.9017],\n",
            "        [ 2.3863, -1.8146, -5.7617,  ..., -2.5878,  2.7003, -0.3238]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5123, -0.9059, -5.7003,  ..., -1.3717,  2.5461,  0.8107],\n",
            "        [ 2.0478, -1.6771, -3.5924,  ..., -2.8104,  2.1658, -0.8185],\n",
            "        [-0.0340, -1.5975, -5.3496,  ..., -4.0197,  1.7711, -1.6997],\n",
            "        ...,\n",
            "        [-0.0790, -0.9444, -4.2276,  ..., -3.1976,  2.1770, -1.7096],\n",
            "        [ 0.3388, -0.9840, -6.2218,  ..., -4.0141,  0.8859, -2.0017],\n",
            "        [ 1.8848,  0.6634, -2.3654,  ..., -1.3659,  2.6044, -1.3588]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7458, -2.6739, -5.2232,  ..., -3.9379,  2.1527, -0.9260],\n",
            "        [ 1.3045, -2.7622, -2.2288,  ..., -1.3474,  2.2967,  0.7315],\n",
            "        [ 1.4928,  0.9140, -5.6829,  ..., -2.8910, -0.0395, -0.9554],\n",
            "        ...,\n",
            "        [ 1.5871, -2.2803, -4.9335,  ..., -2.9524, -0.3194, -0.1519],\n",
            "        [ 0.8398, -0.3970, -4.5615,  ...,  0.0992, -0.0131, -0.6803],\n",
            "        [ 1.3256, -1.6233, -5.1254,  ..., -4.8454,  2.7510, -1.6746]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2056, -1.2900, -4.4069,  ..., -1.8497,  2.7116, -0.3112],\n",
            "        [ 0.5133,  0.5793, -6.8536,  ..., -3.1046,  1.5302, -1.0255],\n",
            "        [-1.1297, -0.8854, -6.3385,  ..., -5.0107,  1.1639, -0.1831],\n",
            "        ...,\n",
            "        [ 2.8134,  1.2977, -5.2731,  ..., -3.7968,  1.2972, -1.5349],\n",
            "        [ 3.5932,  0.5648, -3.6746,  ..., -1.9360,  1.2379, -2.4245],\n",
            "        [ 2.3314, -0.6598, -2.7772,  ..., -1.7261, -0.4778, -1.3567]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6093, -3.2919, -3.9539,  ..., -4.1711,  0.9760, -1.6312],\n",
            "        [ 1.2137,  1.2529, -2.6309,  ..., -1.9290, -0.2067,  0.1919],\n",
            "        [ 1.1736,  0.4021, -4.6313,  ..., -1.6828,  2.7823,  1.1474],\n",
            "        ...,\n",
            "        [ 0.8132,  0.1192, -4.9032,  ..., -3.2409,  2.9737, -1.6543],\n",
            "        [ 1.1427, -0.5239, -3.5023,  ..., -1.3577,  3.4147,  0.0707],\n",
            "        [ 1.6193, -0.1575, -4.6010,  ..., -1.3513,  2.6580, -0.4210]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3286, -1.0861, -3.1223,  ..., -3.1401,  1.3319, -1.7294],\n",
            "        [-0.9652, -0.7891, -4.8510,  ..., -4.5934,  1.2159,  0.5873],\n",
            "        [ 2.7687,  0.8102, -4.1391,  ..., -0.7787, -0.6021, -1.5490],\n",
            "        ...,\n",
            "        [ 4.8204, -0.0330, -4.4578,  ..., -1.8451,  0.0181, -2.1735],\n",
            "        [ 1.3217, -0.7208, -3.3388,  ..., -1.9826,  2.9137, -0.6873],\n",
            "        [-1.5398, -2.4645, -3.9150,  ..., -3.4408,  3.9711, -1.3882]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7666, -0.8767, -3.0615,  ..., -1.7925,  1.4970, -0.9969],\n",
            "        [ 2.7548, -1.5826, -2.1434,  ..., -0.8276,  0.6337, -1.1822],\n",
            "        [ 2.1332, -1.5669, -4.2102,  ..., -3.4488,  0.5889,  0.4381],\n",
            "        ...,\n",
            "        [-0.4389, -2.5586, -5.4699,  ..., -4.7546, -0.5762, -2.0546],\n",
            "        [ 1.1279,  0.5320, -3.1007,  ..., -1.9703,  2.9768, -1.4967],\n",
            "        [ 0.3229, -0.5147, -4.0138,  ..., -2.0359,  2.7299,  0.1151]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2828,  0.0786, -4.8393,  ..., -2.9316,  2.8561, -0.4156],\n",
            "        [ 2.9046, -1.5704, -6.2830,  ..., -2.6116,  2.7491, -0.1550],\n",
            "        [ 3.9913, -1.3181, -6.0972,  ..., -3.4121,  1.6687,  0.0615],\n",
            "        ...,\n",
            "        [ 0.4672, -0.3606, -4.1931,  ..., -2.9082,  1.5373,  0.0905],\n",
            "        [-0.3815, -0.6550, -0.5056,  ..., -3.4683,  2.3309, -1.0494],\n",
            "        [ 1.8297, -0.2994, -3.4783,  ..., -2.8035,  1.8209, -2.7058]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5349, -0.1800, -2.5387,  ..., -1.1943,  1.7811, -1.5741],\n",
            "        [-0.6809, -1.0351, -2.6350,  ..., -0.9734,  3.3385,  0.8641],\n",
            "        [ 3.9493,  0.4046, -2.7441,  ..., -2.3670,  0.7157, -2.5414],\n",
            "        ...,\n",
            "        [ 3.0489, -0.7291, -2.9449,  ...,  1.1637, -0.6170, -1.5798],\n",
            "        [ 1.8387, -0.4500, -4.9605,  ..., -1.7500,  0.3116, -1.3497],\n",
            "        [ 2.6976, -1.9994, -5.3296,  ..., -2.2627, -0.5579, -2.5378]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4667,  1.8038, -3.2942,  ..., -0.9680,  0.4132, -0.7213],\n",
            "        [ 4.1129,  0.2367, -4.7305,  ..., -1.3285,  1.9500, -1.1585],\n",
            "        [ 1.8450,  0.9090, -3.1066,  ..., -1.4075,  1.6988, -1.2387],\n",
            "        ...,\n",
            "        [ 0.7189,  0.1559, -3.4410,  ..., -1.7362,  3.1419, -0.7330],\n",
            "        [ 0.9380,  1.2540, -3.6868,  ..., -1.2862,  1.8368, -0.2760],\n",
            "        [ 1.2343, -0.4701, -4.9117,  ..., -2.5283,  2.3625, -1.1028]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4341,  0.0626, -1.8151,  ..., -2.0583,  0.3637, -1.9065],\n",
            "        [ 1.4464, -1.5522, -5.7614,  ..., -4.4599,  0.8426, -0.1565],\n",
            "        [ 4.5577,  0.2058, -5.1509,  ..., -3.9082,  0.2106, -0.9437],\n",
            "        ...,\n",
            "        [ 0.2010,  1.3864, -2.8022,  ..., -2.6579,  0.8614, -1.7845],\n",
            "        [ 0.9925, -1.0988, -4.8764,  ..., -2.6144,  2.6914, -0.8968],\n",
            "        [ 1.4613, -0.6941, -4.4202,  ..., -0.3263,  2.4726,  0.0347]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6887, -0.0105, -2.1012,  ..., -0.5141,  2.5289, -2.1175],\n",
            "        [ 2.8549,  0.9236, -5.6986,  ..., -3.8799,  1.9270, -1.7019],\n",
            "        [ 1.4936, -0.6287, -3.5063,  ..., -2.4531, -0.8665, -1.3760],\n",
            "        ...,\n",
            "        [-1.2226, -1.7980, -4.6359,  ..., -3.0557,  2.8051,  1.8255],\n",
            "        [ 0.7796, -0.9000, -4.3727,  ..., -3.8689,  1.6716, -1.1123],\n",
            "        [ 1.1833, -0.8375, -4.4854,  ..., -1.7287,  3.5622, -0.5261]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9479,  2.0133, -3.3824,  ..., -2.3643,  0.2066, -0.6003],\n",
            "        [-0.1565, -1.2885, -4.3103,  ..., -4.5013,  2.4186, -1.9385],\n",
            "        [ 1.2034, -1.3353, -5.2684,  ..., -1.9251,  2.2348, -0.7862],\n",
            "        ...,\n",
            "        [-0.7890, -1.0786, -2.2829,  ..., -2.6325,  2.4896,  1.9483],\n",
            "        [ 1.7792, -1.2130, -3.7279,  ..., -1.6889,  2.1213, -0.5920],\n",
            "        [ 2.0211, -3.9613, -7.0529,  ..., -4.1585,  0.4233, -1.3377]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6656,  0.8308, -1.8854,  ..., -2.3162,  2.2292, -1.1016],\n",
            "        [ 1.0574,  0.4467, -4.1740,  ..., -3.3688,  0.3261,  0.0440],\n",
            "        [ 0.8765, -1.7854, -4.1605,  ..., -1.0255,  3.3468,  0.8682],\n",
            "        ...,\n",
            "        [ 0.6938, -1.7251, -3.4291,  ..., -3.7582,  0.9827, -0.8693],\n",
            "        [ 2.4327,  0.8454, -3.0795,  ..., -0.8832,  1.5666, -0.7143],\n",
            "        [ 0.3978, -1.0075, -5.3897,  ..., -2.4096,  2.5450, -0.3227]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0553,  0.6256, -3.1761,  ..., -2.3547,  2.3310, -1.4767],\n",
            "        [ 1.9367,  1.0809, -1.8689,  ..., -1.5936,  1.5756, -2.4512],\n",
            "        [ 2.6889,  2.3807, -3.8216,  ..., -1.9300,  1.0923, -0.8491],\n",
            "        ...,\n",
            "        [ 1.5169,  0.6786, -3.7484,  ..., -1.5206,  1.9511,  0.1084],\n",
            "        [ 3.7975, -2.3005, -6.4286,  ..., -3.1767,  1.0280, -0.2253],\n",
            "        [ 1.5189, -0.4879, -4.3231,  ..., -0.8125,  2.6067, -0.3874]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7860,  0.1512, -4.6969,  ..., -2.4484,  2.3216, -1.7415],\n",
            "        [ 1.2883, -0.1589, -3.7887,  ..., -1.2331,  2.3788, -0.7012],\n",
            "        [-1.2854, -0.0120, -1.9072,  ..., -1.6301,  2.6329,  1.7788],\n",
            "        ...,\n",
            "        [ 1.9236, -2.6978, -4.7505,  ..., -1.6112,  2.1680,  1.9203],\n",
            "        [ 0.1241, -1.9635, -5.7132,  ..., -0.7305,  1.4688, -1.5744],\n",
            "        [-1.2998, -0.2261, -1.7446,  ..., -0.6535,  1.7404,  1.2403]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9297, -0.8539, -5.1658,  ..., -1.1464,  2.4716, -0.3721],\n",
            "        [-0.5905,  0.7280, -2.2124,  ..., -2.0981,  1.5289, -1.1028],\n",
            "        [ 2.4098,  2.9650, -4.1842,  ..., -1.3767, -1.0183, -1.4322],\n",
            "        ...,\n",
            "        [ 0.1365, -1.4327, -4.4067,  ..., -3.4761, -0.8290, -1.7456],\n",
            "        [ 3.6141,  1.2632, -2.5455,  ..., -1.0537,  0.6265,  0.2286],\n",
            "        [ 1.9575, -0.3178, -2.6596,  ..., -2.8071,  2.3219, -1.0993]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-9.8459e-01,  1.5309e-01, -3.7073e+00,  ..., -2.4656e+00,\n",
            "          3.9270e+00,  1.4656e+00],\n",
            "        [ 1.9449e+00,  7.7562e-01, -3.3806e+00,  ..., -1.7581e+00,\n",
            "          2.6403e+00, -2.6340e-01],\n",
            "        [ 1.5576e+00, -6.7879e-01, -5.4071e+00,  ..., -2.4252e+00,\n",
            "          2.8022e+00,  5.6909e-01],\n",
            "        ...,\n",
            "        [ 1.1024e+00,  2.7160e-01, -4.0339e+00,  ..., -1.6162e+00,\n",
            "          3.2431e-01, -7.6794e-01],\n",
            "        [ 2.3429e+00,  1.1730e+00, -4.4024e+00,  ..., -2.8347e+00,\n",
            "         -2.7032e-03,  3.0173e-01],\n",
            "        [ 1.4759e+00, -2.4229e+00, -4.3045e+00,  ..., -2.0258e+00,\n",
            "          2.2302e+00, -8.5779e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.1932,  2.0552, -3.8155,  ..., -1.4112, -0.1071, -2.0039],\n",
            "        [ 3.8281,  1.9128, -2.9152,  ..., -1.1165,  0.1618, -1.9225],\n",
            "        [-1.0227, -2.1189, -5.4080,  ..., -4.3136,  1.8664,  0.4224],\n",
            "        ...,\n",
            "        [ 2.6655, -2.1598, -4.8312,  ..., -3.3277,  0.1044, -0.5777],\n",
            "        [ 1.4496, -1.5151, -7.7982,  ..., -2.7699,  1.5043, -0.3390],\n",
            "        [ 1.9335,  0.6315, -2.5574,  ..., -1.1982,  1.3966, -0.7209]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3684,  0.9352, -3.3017,  ..., -2.7366, -0.6064,  2.2295],\n",
            "        [ 1.6783, -0.7132, -6.5088,  ..., -3.5445,  2.2217, -1.7445],\n",
            "        [ 0.0529, -0.5101, -4.4984,  ..., -1.4069,  0.8783, -0.9904],\n",
            "        ...,\n",
            "        [ 0.8345, -4.2480, -5.6944,  ..., -4.3891,  0.8549, -0.3214],\n",
            "        [-0.7524,  0.3452, -1.8792,  ..., -1.5079,  2.2353,  1.4783],\n",
            "        [ 1.5887, -1.2887, -4.7481,  ..., -2.3207,  3.9261, -0.5347]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9797, -1.2287, -3.1134,  ..., -1.8677,  0.7921,  0.3588],\n",
            "        [ 0.6338, -0.2765, -7.7854,  ..., -4.1492,  2.4657,  0.2204],\n",
            "        [ 1.6390, -1.2784, -5.0122,  ..., -2.6473,  3.6669, -0.1971],\n",
            "        ...,\n",
            "        [ 0.6599, -0.4415, -5.9433,  ..., -4.1346,  2.0940,  0.0583],\n",
            "        [ 0.7879, -0.0560, -5.6690,  ..., -2.8649,  3.8621, -1.0909],\n",
            "        [ 0.3276, -0.1503, -5.3436,  ..., -2.3926,  3.6842, -0.0411]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3143,  0.2327, -5.0259,  ..., -2.9429,  1.8332, -0.8677],\n",
            "        [ 0.7133, -0.3517, -5.3961,  ..., -2.1176,  2.0566, -0.0600],\n",
            "        [ 2.5642,  1.5978, -3.6443,  ..., -3.3072,  2.0448,  0.4951],\n",
            "        ...,\n",
            "        [ 2.3848, -1.7537, -6.1030,  ..., -1.9938,  2.3634,  2.0387],\n",
            "        [ 0.1597, -2.0015, -7.1995,  ..., -3.1851,  3.2925,  1.8824],\n",
            "        [ 2.4508, -0.0374, -4.5736,  ..., -0.7823, -1.6192, -0.8702]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4563, -1.9471, -3.5267,  ..., -4.1674,  2.0495, -0.5370],\n",
            "        [ 0.8069,  0.9943, -2.8428,  ..., -2.6816,  2.6880,  1.1161],\n",
            "        [-0.2582, -0.5814, -2.1673,  ..., -1.2213,  3.1156,  0.8819],\n",
            "        ...,\n",
            "        [ 1.2960, -2.1310, -2.9964,  ..., -1.4480,  3.2163,  0.6335],\n",
            "        [ 0.9116, -0.6269, -4.1241,  ..., -1.6416,  3.3993, -0.3278],\n",
            "        [ 1.5109, -0.5508, -3.4817,  ...,  0.2706,  1.9192, -1.3416]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4075, -1.1509, -2.4960,  ..., -1.0453,  2.1885,  1.4345],\n",
            "        [ 4.0110, -1.0086, -4.7632,  ..., -0.4860, -0.0946, -0.5276],\n",
            "        [ 1.3154, -2.4149, -3.6575,  ..., -1.5342,  0.6684, -1.0908],\n",
            "        ...,\n",
            "        [ 1.1817, -0.9271, -5.7231,  ..., -2.9641,  1.6103, -0.5187],\n",
            "        [ 2.7614,  1.0160, -4.7243,  ..., -4.5232,  2.7403, -0.9337],\n",
            "        [ 0.6130,  1.1153, -3.8528,  ..., -1.1505,  0.5337,  0.8399]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8994, -0.0154, -6.2787,  ..., -2.7527,  1.7810,  0.6557],\n",
            "        [-0.5345, -0.5927, -3.5038,  ..., -3.0334,  2.4821, -2.3538],\n",
            "        [ 0.9566, -0.0317, -3.8968,  ..., -2.8050,  1.8327,  0.5668],\n",
            "        ...,\n",
            "        [ 0.6627,  1.3398, -4.4455,  ..., -3.7652,  1.2584, -0.9451],\n",
            "        [ 1.2741, -0.9420, -3.6769,  ..., -2.6310,  3.6235, -0.0528],\n",
            "        [ 0.9343,  0.3808, -4.1779,  ..., -0.1707,  1.8520, -0.0084]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7512, -0.2977, -4.4419,  ..., -3.9024,  2.4540,  2.2734],\n",
            "        [ 2.4846, -1.6107, -2.5686,  ...,  1.7173,  0.5790, -0.4729],\n",
            "        [ 2.4365, -1.7953, -2.4240,  ..., -2.6549,  1.2862, -0.0173],\n",
            "        ...,\n",
            "        [ 0.7049, -1.4972, -5.6637,  ..., -3.8760,  0.5750, -1.5960],\n",
            "        [ 3.0426, -1.1254, -7.7440,  ..., -2.8420,  1.5755, -0.4467],\n",
            "        [ 0.2615,  0.9399, -2.8851,  ..., -2.5328,  0.5738, -1.6239]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4852, -4.2139, -5.2515,  ..., -2.6297, -0.1659, -0.7411],\n",
            "        [ 1.8291, -0.2902, -2.5075,  ..., -3.3487,  1.4957,  2.2888],\n",
            "        [ 2.8185, -0.7769, -2.6925,  ..., -0.6413,  0.5040, -0.8934],\n",
            "        ...,\n",
            "        [ 3.6900, -0.3714, -3.1929,  ..., -0.5738,  2.2837, -1.5193],\n",
            "        [ 3.3596, -0.2285, -3.6974,  ..., -1.1554,  0.7497,  0.2213],\n",
            "        [-0.4996, -3.9460, -4.9140,  ..., -3.5362,  4.0351,  2.8957]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2065, -1.5686, -4.7993,  ..., -3.1783,  0.7860,  0.6932],\n",
            "        [ 0.1249, -1.8659, -4.5048,  ..., -4.1202,  2.7171, -1.9599],\n",
            "        [-1.8006,  0.2064, -4.8202,  ..., -3.7216,  2.8303,  3.1845],\n",
            "        ...,\n",
            "        [ 0.8530, -0.6680, -5.4670,  ..., -1.1618,  2.4168,  0.3948],\n",
            "        [-0.0323,  0.7021, -4.4581,  ..., -4.5024,  3.3686, -0.7952],\n",
            "        [ 1.8625, -0.6238, -5.7146,  ..., -2.0759,  2.3286, -0.7146]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7464,  1.1155, -4.5994,  ..., -1.9656,  0.2084, -1.6555],\n",
            "        [ 3.1838, -4.8593, -4.5032,  ..., -3.7491, -1.2339,  1.7367],\n",
            "        [-0.4052, -0.7568, -3.1813,  ..., -2.0125,  3.7656,  1.3637],\n",
            "        ...,\n",
            "        [ 0.9168, -3.4834, -5.8127,  ..., -2.3613,  5.1544,  2.0852],\n",
            "        [ 2.7296,  0.9861, -2.9220,  ..., -2.3197, -0.4657, -1.8364],\n",
            "        [ 0.7809, -0.8633, -5.4258,  ..., -2.0013,  3.9285,  1.3401]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9576, -3.2788, -3.9832,  ..., -2.1595,  1.4597,  1.2039],\n",
            "        [ 0.6934, -0.1583, -2.4268,  ..., -3.5430,  2.5172, -0.0412],\n",
            "        [ 4.7646,  1.1477, -3.9008,  ..., -0.6972, -0.0627, -1.9338],\n",
            "        ...,\n",
            "        [ 0.2005,  0.2551, -6.1199,  ..., -4.3069,  4.6091,  0.9106],\n",
            "        [ 0.0619, -2.3397, -2.7746,  ..., -1.5430,  2.2497, -0.6226],\n",
            "        [ 2.1007, -1.1711, -3.6401,  ..., -1.3620, -1.3205, -1.9916]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6806, -1.5573, -4.2045,  ..., -3.6345,  0.8698, -0.6134],\n",
            "        [-0.4700, -2.5436, -5.8191,  ..., -5.1265,  1.0917, -1.6949],\n",
            "        [ 2.8193, -1.7757, -2.9567,  ..., -2.3607,  2.8585,  0.9303],\n",
            "        ...,\n",
            "        [ 1.4843, -0.8926, -4.7523,  ..., -1.6898,  3.3461,  0.5600],\n",
            "        [ 1.4197, -0.6288, -4.4585,  ..., -3.8082,  2.1539, -0.6183],\n",
            "        [ 3.0754,  1.9631, -3.6947,  ..., -3.0519,  0.9581, -0.8071]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.4238e-01,  2.6525e+00, -3.7587e+00,  ..., -3.0674e+00,\n",
            "          1.6538e+00, -8.3826e-01],\n",
            "        [ 1.5428e+00,  1.0291e+00, -3.8015e+00,  ..., -2.4242e+00,\n",
            "          2.1672e+00, -6.3458e-01],\n",
            "        [-2.8249e-01,  4.3984e-01, -4.1171e+00,  ..., -2.5738e+00,\n",
            "          2.1350e+00, -3.9691e-03],\n",
            "        ...,\n",
            "        [ 4.7725e-02, -1.4951e-01, -2.0700e+00,  ...,  1.1031e-01,\n",
            "          2.0178e+00,  1.7390e+00],\n",
            "        [-1.6747e-01, -1.5508e+00, -4.0477e+00,  ..., -4.2116e+00,\n",
            "          4.7366e-01, -4.1517e-01],\n",
            "        [ 1.2350e+00, -6.2495e-01, -4.6479e+00,  ..., -1.0103e+00,\n",
            "          3.1343e+00,  1.6280e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7295, -1.4096, -7.2220,  ..., -5.3407,  1.2098, -0.5687],\n",
            "        [ 3.7230, -3.6254, -5.7410,  ..., -1.7304,  1.0389,  1.7354],\n",
            "        [ 1.1217, -0.5084, -4.9379,  ..., -3.0183,  3.3607,  0.1360],\n",
            "        ...,\n",
            "        [ 3.6557, -4.1629, -3.6441,  ..., -2.4562, -0.6610, -0.7686],\n",
            "        [ 3.6198, -0.7586, -4.3837,  ..., -0.4212, -1.8000, -0.0311],\n",
            "        [ 1.8968,  0.4333, -4.7576,  ..., -0.6203,  0.3913, -1.5168]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4857e+00, -1.3684e+00, -5.6405e+00,  ..., -2.2495e+00,\n",
            "          2.9968e+00,  7.7001e-01],\n",
            "        [ 1.1110e+00, -2.9732e+00, -1.5855e+00,  ..., -2.8489e+00,\n",
            "          1.9939e+00, -8.3844e-01],\n",
            "        [ 1.6159e-03, -4.5062e-01, -4.7556e+00,  ..., -5.0341e+00,\n",
            "          3.4233e+00,  1.5006e+00],\n",
            "        ...,\n",
            "        [ 6.3161e-01, -2.3381e-01, -3.9860e+00,  ..., -2.6451e+00,\n",
            "          3.8620e-01,  7.1392e-01],\n",
            "        [ 6.0611e-01, -1.3625e+00, -4.3570e+00,  ..., -1.3869e+00,\n",
            "          3.5382e+00, -4.9550e-01],\n",
            "        [ 1.9961e+00,  8.2763e-01, -4.0193e+00,  ..., -1.2967e+00,\n",
            "          1.4822e+00, -1.3115e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6833e+00, -1.1075e+00, -6.0243e+00,  ..., -2.2718e+00,\n",
            "          2.9837e+00,  2.4665e-01],\n",
            "        [-6.8146e-02, -2.8561e+00, -3.0855e+00,  ...,  4.1060e-03,\n",
            "          1.5972e-01,  1.0514e+00],\n",
            "        [-9.2019e-01,  6.9302e-01, -2.5025e+00,  ..., -1.1582e+00,\n",
            "          1.0521e+00,  2.0412e+00],\n",
            "        ...,\n",
            "        [-4.6839e-01, -2.0710e+00, -4.2944e+00,  ..., -2.0664e+00,\n",
            "          3.3282e+00, -1.1021e+00],\n",
            "        [ 9.9216e-01, -1.9149e+00, -5.8700e+00,  ..., -3.2605e+00,\n",
            "          3.7510e+00,  2.2415e+00],\n",
            "        [-9.0246e-01, -2.1122e+00, -4.0098e+00,  ..., -1.4736e+00,\n",
            "          1.1282e+00,  2.8130e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7298, -1.1746, -5.4117,  ..., -2.8112,  3.8600,  0.5556],\n",
            "        [ 0.7739,  0.0637, -5.1435,  ..., -1.2220, -0.4335, -0.1695],\n",
            "        [ 1.6141, -1.4321, -3.4191,  ..., -2.0024,  1.1594, -1.0805],\n",
            "        ...,\n",
            "        [ 0.7883, -0.3941, -5.6296,  ..., -4.0472,  2.1415, -0.8911],\n",
            "        [ 1.7197,  0.0091, -5.8664,  ..., -2.3425,  0.2832, -0.3862],\n",
            "        [ 1.9608, -0.7714, -4.7844,  ..., -1.8240,  1.8474,  1.7581]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6175, -0.9493, -3.4171,  ..., -0.4076,  0.8305, -0.3150],\n",
            "        [-1.9012,  2.1993, -2.7210,  ..., -1.7731, -0.0697, -0.5287],\n",
            "        [-0.5215, -2.0827, -4.4355,  ..., -1.9720, -0.6574, -2.0217],\n",
            "        ...,\n",
            "        [-0.9619, -0.0704, -2.4188,  ..., -0.7573,  2.7537,  2.2288],\n",
            "        [ 2.1925, -0.3391, -4.1419,  ..., -1.1566, -0.3023, -1.3136],\n",
            "        [ 1.3778, -0.4110, -8.4024,  ..., -3.8451,  3.3994,  2.1885]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7313e+00, -3.8530e-01, -5.7712e+00,  ..., -1.1869e+00,\n",
            "          7.9482e-01, -1.9890e-01],\n",
            "        [ 2.5391e+00, -1.0565e+00, -7.4580e+00,  ..., -4.0370e+00,\n",
            "          2.2308e+00,  1.6249e+00],\n",
            "        [ 4.1334e+00, -9.8151e-01, -3.6142e+00,  ..., -6.3863e-01,\n",
            "          5.9649e-01,  2.7631e+00],\n",
            "        ...,\n",
            "        [ 9.2419e-01, -7.0834e-01, -3.6479e+00,  ...,  2.0447e-01,\n",
            "          1.7801e+00,  1.4963e+00],\n",
            "        [ 2.0459e+00, -3.7798e-01, -3.3556e+00,  ..., -2.2556e+00,\n",
            "          2.8425e+00,  6.1376e-02],\n",
            "        [ 3.0126e+00,  2.8512e-01, -4.0504e+00,  ..., -1.3158e+00,\n",
            "         -4.5195e-03, -2.4889e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8149, -0.1634, -2.7941,  ..., -2.8921,  1.5323, -0.8645],\n",
            "        [ 2.1300, -1.0426, -6.0926,  ..., -1.8537,  1.9163,  2.4837],\n",
            "        [ 2.2249,  3.0517, -3.9333,  ..., -2.8689,  0.7121, -0.4880],\n",
            "        ...,\n",
            "        [ 0.1915, -1.6922, -4.8436,  ..., -2.7668,  0.1460, -0.5949],\n",
            "        [-0.4384,  0.8129, -3.7843,  ..., -2.7607,  1.7619,  2.5361],\n",
            "        [ 3.0194, -2.0227, -4.6062,  ..., -1.6839,  1.9249,  1.9975]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9215,  0.7838, -2.4423,  ..., -1.5928,  1.4645,  0.8890],\n",
            "        [ 0.8041, -0.3184, -4.1763,  ..., -1.9543,  0.8059, -0.5678],\n",
            "        [ 1.9936, -2.5240, -6.5242,  ..., -2.9377,  0.2599,  0.2360],\n",
            "        ...,\n",
            "        [ 1.8643,  0.7324, -3.2562,  ..., -0.9280, -0.4329,  0.7568],\n",
            "        [ 2.2148, -0.5465, -4.2777,  ..., -2.0978,  1.3079, -0.2450],\n",
            "        [-0.7968, -0.7134, -1.8433,  ..., -0.7977,  2.3845,  1.7337]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7039, -0.3886, -1.4689,  ..., -2.3512, -0.1637, -1.8996],\n",
            "        [ 2.2515, -0.8395, -3.9508,  ..., -1.8867,  1.1292,  0.3810],\n",
            "        [ 1.4559, -2.8194, -4.9493,  ..., -2.8068,  2.0686,  0.7436],\n",
            "        ...,\n",
            "        [ 1.0920, -1.0360, -2.6543,  ..., -1.0823,  2.1480,  3.1164],\n",
            "        [ 0.0947, -1.1008, -3.4549,  ..., -2.6637,  0.3846, -0.7358],\n",
            "        [ 1.2128, -0.3554, -4.7018,  ..., -4.4748,  6.0135,  4.2167]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6797,  0.3767, -2.2323,  ..., -3.2584,  2.0597, -0.1987],\n",
            "        [ 4.0235, -0.8386, -5.2103,  ..., -4.4383,  2.1808, -0.7693],\n",
            "        [ 0.8074,  0.2149, -4.5011,  ..., -1.7791,  0.8188,  1.2006],\n",
            "        ...,\n",
            "        [ 0.2071,  0.1580, -3.1258,  ...,  0.3434,  0.5439,  2.6414],\n",
            "        [ 0.4625, -1.6698, -7.5388,  ..., -3.9905,  0.9654, -0.6116],\n",
            "        [ 0.5534, -2.5480, -5.0932,  ..., -2.7324,  1.7451, -0.1254]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2573, -0.8091, -5.1314,  ..., -1.2970,  2.8311,  1.7324],\n",
            "        [ 3.0980,  3.0622, -3.6801,  ..., -2.2193,  0.9978,  1.1428],\n",
            "        [ 2.0686, -0.9056, -4.8478,  ..., -1.3562,  1.1108,  1.4414],\n",
            "        ...,\n",
            "        [ 1.9615,  1.3727, -4.6975,  ..., -0.5232,  0.9303, -0.2091],\n",
            "        [-0.6724,  1.5120, -2.9094,  ..., -2.4691,  2.2584, -1.1247],\n",
            "        [ 0.7701,  0.3400, -3.3323,  ..., -2.2824,  2.7855,  3.4094]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2791,  2.0546, -2.9361,  ..., -3.3458,  0.9633,  0.8395],\n",
            "        [ 1.0492,  0.3302, -3.8642,  ..., -0.4802,  3.4606,  2.9574],\n",
            "        [ 1.5910, -1.2622, -4.0137,  ..., -3.2369,  1.4271,  2.0824],\n",
            "        ...,\n",
            "        [ 2.8931, -1.8512, -3.5153,  ..., -1.9570,  1.7544,  2.1382],\n",
            "        [ 1.9668,  1.8011, -4.2715,  ..., -0.8962,  2.3921,  1.2581],\n",
            "        [ 3.6027, -0.7474, -4.7540,  ..., -1.8937,  0.0726,  0.0600]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0805, -1.6216, -5.6816,  ..., -3.5745,  1.5833, -0.7119],\n",
            "        [ 3.6653,  2.1074, -2.8410,  ..., -1.8555, -0.7563, -2.1896],\n",
            "        [ 2.0912,  0.4998, -2.5957,  ..., -1.9711,  2.1683,  0.7299],\n",
            "        ...,\n",
            "        [ 1.4887, -0.1113, -3.7534,  ..., -2.1525,  3.0258,  1.8670],\n",
            "        [ 2.8017,  1.1445, -4.1840,  ..., -1.6539,  1.7206, -0.6969],\n",
            "        [ 0.6496,  0.3853, -4.4423,  ..., -1.5866,  1.2322, -0.3361]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9035, -0.0440, -2.2879,  ..., -1.9719,  2.7141,  2.9420],\n",
            "        [-0.1873, -1.6796, -6.6659,  ..., -1.7696,  1.7338, -0.2925],\n",
            "        [-0.8986,  0.0792, -5.3207,  ..., -4.6887,  3.3900,  4.3997],\n",
            "        ...,\n",
            "        [ 0.0099,  0.5992, -2.4618,  ..., -2.3113,  1.3301, -0.5886],\n",
            "        [ 0.3224,  1.5851, -3.5936,  ..., -1.1740,  0.4118,  2.8811],\n",
            "        [ 2.3601, -0.0233, -3.2239,  ...,  0.4969, -1.5918,  2.4580]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3308, -1.9341, -4.5780,  ..., -1.9745,  1.7385,  0.5609],\n",
            "        [ 1.7873,  2.4546, -2.2897,  ..., -1.5236, -1.0237, -0.9510],\n",
            "        [ 2.7028, -2.0614, -5.3901,  ..., -2.4849,  0.7788,  0.2899],\n",
            "        ...,\n",
            "        [ 1.4557,  1.2523, -5.1985,  ..., -2.3168,  1.5216,  0.6067],\n",
            "        [ 2.1981, -2.5620, -3.3518,  ..., -2.3711,  2.4246,  0.9950],\n",
            "        [ 0.4700, -1.8239, -4.1897,  ..., -2.3725,  3.0353,  3.7546]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6592, -0.4729, -6.8550,  ..., -2.8130,  0.4676, -0.0462],\n",
            "        [ 1.6622, -0.3980, -2.9982,  ..., -1.0071,  3.6799,  3.1800],\n",
            "        [-0.0435,  1.1813, -2.1024,  ..., -1.0434,  0.8242,  0.5796],\n",
            "        ...,\n",
            "        [ 0.8794, -3.3936, -2.8270,  ..., -1.5975,  1.6426,  1.5995],\n",
            "        [ 1.6723, -1.1265, -5.6074,  ..., -3.1907,  0.0675, -1.4290],\n",
            "        [ 0.4819, -1.0948, -0.7428,  ..., -1.8954,  1.4645,  0.2414]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4560,  0.2835, -2.3197,  ..., -1.2671,  1.5289,  0.4274],\n",
            "        [ 1.1630, -1.1654, -3.7242,  ..., -1.3523,  1.6893,  1.9304],\n",
            "        [-0.8475, -1.1718, -7.4712,  ..., -4.3523,  2.9761, -0.0726],\n",
            "        ...,\n",
            "        [ 1.3436, -3.1443, -3.9480,  ..., -3.4113,  0.7868,  1.2168],\n",
            "        [ 0.6974,  0.3910, -4.4113,  ..., -3.0634, -0.0253, -0.6430],\n",
            "        [ 0.6124,  0.3763, -3.0668,  ..., -0.6954,  0.9551,  1.7640]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9399, -2.2934, -3.4760,  ..., -2.7608,  2.5556,  1.3162],\n",
            "        [ 2.0320,  3.3298, -3.0312,  ..., -2.0621,  0.9716,  0.3413],\n",
            "        [ 2.3429,  0.3542, -3.0804,  ..., -0.2550, -0.1584, -1.9627],\n",
            "        ...,\n",
            "        [ 2.0000,  0.0890, -3.7443,  ..., -3.2920,  0.9699, -0.2921],\n",
            "        [ 4.1287,  2.0773, -4.4637,  ..., -1.3558,  0.4792, -1.5728],\n",
            "        [ 1.6697,  1.0315, -3.5710,  ..., -0.1806,  1.8068,  1.6727]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4647,  0.9954, -2.9396,  ..., -2.4832,  1.6550,  1.4232],\n",
            "        [ 1.6743, -1.7143, -3.5001,  ..., -1.8593,  2.1799,  1.6413],\n",
            "        [ 2.9935, -3.6794, -5.3944,  ..., -0.6887, -0.8701, -0.1020],\n",
            "        ...,\n",
            "        [ 1.1140,  0.4101, -2.5804,  ..., -1.1142,  0.7063,  1.4738],\n",
            "        [ 3.5222, -1.5406, -4.7331,  ..., -1.0060,  0.6099, -0.0434],\n",
            "        [ 2.2871,  0.0287, -4.7343,  ...,  0.2615,  0.3476, -0.1511]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3142, -2.4961, -4.7844,  ..., -0.4323, -0.7269, -1.7974],\n",
            "        [ 4.8304,  1.8107, -4.4776,  ..., -2.4443,  0.8947,  1.6110],\n",
            "        [ 0.1991,  0.6083, -3.4762,  ..., -2.5921,  2.5196,  1.3715],\n",
            "        ...,\n",
            "        [ 3.7566, -3.2533, -4.3363,  ..., -2.4993,  1.5809,  0.6501],\n",
            "        [ 0.3143,  0.7298, -3.9188,  ..., -3.2855,  1.7153,  2.2921],\n",
            "        [ 0.8921, -0.4150, -5.3973,  ..., -2.2861,  2.8781,  1.9574]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.5884e-01, -2.9986e+00, -5.8532e+00,  ..., -4.1631e+00,\n",
            "          2.7909e+00,  1.9743e+00],\n",
            "        [ 6.0313e-02, -2.2757e+00, -3.5393e+00,  ..., -3.5048e+00,\n",
            "          5.8807e+00,  2.8665e+00],\n",
            "        [ 3.7661e+00,  1.5717e+00, -3.3794e+00,  ..., -2.2037e+00,\n",
            "         -7.5273e-03,  1.8032e+00],\n",
            "        ...,\n",
            "        [ 3.3454e+00, -8.0605e-01, -7.7780e+00,  ..., -2.8927e+00,\n",
            "          5.7839e-01,  6.0076e-01],\n",
            "        [ 2.6733e+00, -3.0760e+00, -4.8737e+00,  ..., -1.6649e+00,\n",
            "         -3.0785e-01, -1.9228e+00],\n",
            "        [ 2.3898e+00, -1.2794e+00, -4.8211e+00,  ..., -3.6053e+00,\n",
            "          8.9258e-01, -8.1231e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9819, -0.9503, -3.4906,  ..., -2.6288,  1.5367,  0.1960],\n",
            "        [ 0.5255, -0.9035, -4.1930,  ..., -2.6798,  3.7028,  0.9078],\n",
            "        [ 1.5769, -3.2452, -5.6152,  ..., -3.9031,  3.8988,  3.1879],\n",
            "        ...,\n",
            "        [ 4.2950,  1.4852, -4.2520,  ..., -1.9187, -1.1384, -1.4378],\n",
            "        [-1.2095, -4.9754, -5.5585,  ..., -3.3689, -0.7275,  1.6645],\n",
            "        [ 2.5890,  0.3368, -3.9291,  ..., -0.3255,  1.8484, -1.8269]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8172, -0.4327, -5.0834,  ..., -1.8902,  2.9233,  4.0712],\n",
            "        [ 0.6275, -3.3175, -6.6682,  ..., -3.6872,  1.5651, -0.4986],\n",
            "        [ 1.3858, -1.6329, -4.1783,  ..., -1.6003, -0.3089, -1.6706],\n",
            "        ...,\n",
            "        [ 0.9103, -0.8827, -4.3938,  ..., -2.5297,  3.6576,  0.9769],\n",
            "        [ 3.9179, -0.6927, -5.3602,  ..., -1.4867, -0.2969, -0.0418],\n",
            "        [-0.6767, -0.0272, -1.1468,  ..., -0.0559,  1.8743,  2.3874]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5513, -1.5641, -4.6477,  ..., -0.2119,  0.1218,  0.0700],\n",
            "        [ 0.0555, -0.6930, -3.6109,  ..., -3.1686,  0.5432,  0.4049],\n",
            "        [ 3.1692, -1.1182, -3.4493,  ...,  0.0896, -1.1944, -0.7351],\n",
            "        ...,\n",
            "        [ 3.0543, -2.2414, -7.2153,  ..., -4.1967,  2.4144,  1.5855],\n",
            "        [ 2.1201,  1.6526, -4.6460,  ..., -3.1185, -0.4108, -2.0784],\n",
            "        [ 2.4937, -1.1294, -3.2381,  ..., -1.8179,  1.6596,  0.9966]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2067, -1.2171, -6.6044,  ..., -3.8235,  0.4337, -1.5655],\n",
            "        [-0.5479, -2.7893, -4.2373,  ..., -2.6699,  2.0658,  1.9393],\n",
            "        [-1.9601, -0.4740, -2.7108,  ..., -0.0501,  3.5632,  3.3541],\n",
            "        ...,\n",
            "        [ 2.1862, -0.8267, -5.5453,  ..., -3.2434, -0.6324, -0.3706],\n",
            "        [ 0.9392, -1.6702, -4.7914,  ..., -2.0951,  1.7168,  0.0762],\n",
            "        [ 4.3916, -2.7442, -7.4360,  ..., -3.1655, -1.1607,  1.0697]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9927, -1.1200, -2.2879,  ..., -0.9175,  1.6426, -0.6453],\n",
            "        [ 2.9350,  1.2589, -2.8130,  ..., -1.1672,  1.5794, -1.2126],\n",
            "        [ 3.7903, -1.4576, -4.2479,  ..., -0.0972, -2.4146, -1.1819],\n",
            "        ...,\n",
            "        [ 2.7274,  2.0121, -2.6450,  ..., -3.1047, -0.3099, -1.1428],\n",
            "        [-0.5393,  1.4010, -2.7521,  ..., -2.0858,  0.1835,  2.2009],\n",
            "        [ 0.1760,  0.5163, -4.4102,  ..., -1.5887,  1.9011, -0.6470]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2694,  2.9701, -3.5509,  ...,  0.9554, -3.1868, -0.7161],\n",
            "        [ 0.6853, -0.0405, -5.6071,  ..., -3.4377,  3.2705,  1.3179],\n",
            "        [ 3.0201,  0.7629, -5.5959,  ..., -2.8905,  3.1759, -0.6578],\n",
            "        ...,\n",
            "        [ 2.6793, -0.9375, -4.8022,  ..., -1.8556, -0.8879, -0.7010],\n",
            "        [-0.9521, -1.1618, -3.1304,  ..., -2.0239,  3.2644,  2.3051],\n",
            "        [ 0.7168, -2.2538, -6.0359,  ..., -4.4494,  0.2308, -1.3812]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5657e+00, -6.2405e-01, -6.3493e+00,  ..., -1.8012e+00,\n",
            "          2.7173e+00,  1.7678e+00],\n",
            "        [ 1.3199e+00, -1.9416e+00, -4.1603e+00,  ..., -2.0713e-01,\n",
            "         -1.0605e+00, -1.1705e-01],\n",
            "        [ 3.5933e-01,  4.1788e-02, -4.5878e+00,  ..., -4.0145e+00,\n",
            "          1.4607e+00, -1.4518e+00],\n",
            "        ...,\n",
            "        [ 8.5011e-01, -7.5529e-01, -5.4685e+00,  ...,  5.4999e-04,\n",
            "          1.4188e-01, -2.0196e+00],\n",
            "        [ 5.5614e-01, -1.3875e+00, -5.3064e+00,  ..., -1.8588e+00,\n",
            "          3.7306e+00,  9.8628e-01],\n",
            "        [ 1.6388e+00,  7.5961e-02, -3.2640e+00,  ..., -1.7812e+00,\n",
            "         -2.0405e-01, -5.3759e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0352e+00, -6.2170e-01, -7.0784e+00,  ..., -2.0774e+00,\n",
            "          1.2641e-01, -2.8649e+00],\n",
            "        [-2.3678e-01,  2.3428e+00, -3.2107e+00,  ..., -1.2157e+00,\n",
            "          1.3417e+00, -3.5071e-02],\n",
            "        [ 1.5933e+00,  2.0610e+00, -4.0887e+00,  ..., -2.7438e+00,\n",
            "          2.3292e+00,  1.2722e+00],\n",
            "        ...,\n",
            "        [-4.5138e-01, -8.9352e-01, -4.4674e+00,  ..., -1.6336e+00,\n",
            "          2.9661e+00,  1.4580e+00],\n",
            "        [-3.0847e-01, -2.7401e+00, -5.4493e+00,  ..., -4.2123e+00,\n",
            "         -2.4491e-01, -7.2162e-01],\n",
            "        [ 2.0283e+00, -1.5774e+00, -3.3102e+00,  ..., -8.9375e-01,\n",
            "          6.1165e-01,  8.6367e-04]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6207e+00,  2.5177e-03, -5.3833e+00,  ..., -2.8972e+00,\n",
            "          1.6800e+00, -4.9583e-01],\n",
            "        [ 6.9932e-01,  9.8385e-02, -2.1064e+00,  ...,  2.4440e-01,\n",
            "          2.0419e+00, -2.8964e-01],\n",
            "        [ 2.2818e+00, -9.9537e-01, -4.7475e+00,  ..., -3.2908e+00,\n",
            "          8.6374e-01, -1.9549e+00],\n",
            "        ...,\n",
            "        [ 1.5968e+00,  7.1761e-01, -4.9420e+00,  ..., -1.7536e+00,\n",
            "          2.2388e+00, -1.3589e+00],\n",
            "        [ 1.3077e-01, -3.0963e+00, -3.3650e+00,  ..., -2.0785e+00,\n",
            "          1.3971e+00,  2.1316e+00],\n",
            "        [ 2.5921e+00, -1.0145e+00, -3.7085e+00,  ...,  6.4947e-02,\n",
            "         -9.2445e-01, -3.7254e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6488,  0.3385, -2.9787,  ..., -0.0349,  0.1689,  0.4239],\n",
            "        [ 3.4335,  0.4573, -4.3514,  ..., -1.9331,  0.3196,  1.0893],\n",
            "        [ 0.1260,  1.6474, -3.1708,  ..., -1.9478, -0.0806,  3.2190],\n",
            "        ...,\n",
            "        [ 3.5083,  1.6283, -5.2620,  ..., -1.0548,  0.9333, -1.3063],\n",
            "        [ 1.0319,  0.5995, -4.9872,  ..., -2.4212,  2.4291,  1.8849],\n",
            "        [ 3.2873,  1.9912, -4.5195,  ..., -3.7490, -1.4848, -1.8051]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3165, -3.1779, -6.5852,  ..., -2.3315,  2.3123,  2.1626],\n",
            "        [ 0.3887,  0.0158, -4.3150,  ..., -0.3809,  1.2223,  1.5552],\n",
            "        [ 1.6894, -2.2680, -4.2844,  ..., -4.9878,  2.1947, -1.6451],\n",
            "        ...,\n",
            "        [-1.1208,  0.5838, -2.4110,  ...,  0.3599,  1.2322,  0.0684],\n",
            "        [ 1.7679, -1.3623, -4.0895,  ..., -2.0269, -0.2887, -2.0712],\n",
            "        [ 1.1310, -1.2819, -4.5410,  ..., -0.6113,  3.5482,  1.6751]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 7.6032e-01,  1.7708e+00, -2.7279e+00,  ..., -1.5395e+00,\n",
            "          1.8280e-01,  6.4781e-01],\n",
            "        [ 3.1670e+00, -1.0777e+00, -6.1405e+00,  ..., -1.8573e+00,\n",
            "          2.3396e+00,  8.5368e-01],\n",
            "        [ 1.9937e+00, -4.2503e-01, -6.5188e+00,  ..., -3.4340e+00,\n",
            "          2.2597e-03,  5.4965e-01],\n",
            "        ...,\n",
            "        [ 1.7983e+00,  1.6623e+00, -5.9380e+00,  ..., -5.2374e-01,\n",
            "          2.2354e+00, -3.7914e-01],\n",
            "        [ 4.0049e+00,  2.7231e+00, -5.8490e+00,  ...,  6.3905e-01,\n",
            "         -8.1521e-01, -1.0102e+00],\n",
            "        [ 2.8596e+00,  2.0108e+00, -4.9590e+00,  ..., -2.1811e+00,\n",
            "          2.4934e+00, -1.4421e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0819, -0.6942, -4.5243,  ..., -2.0738,  2.3308,  0.5896],\n",
            "        [ 3.7721, -2.4766, -7.0058,  ..., -1.3042,  2.1717,  0.9774],\n",
            "        [ 4.2574,  1.8719, -2.3257,  ..., -1.7091,  0.1315, -2.0558],\n",
            "        ...,\n",
            "        [-0.9683, -1.8780, -2.0509,  ..., -1.9818,  1.8974,  0.2054],\n",
            "        [ 1.3197, -1.5214, -2.5727,  ..., -1.4031,  1.2166,  1.7272],\n",
            "        [-1.5511, -1.0264, -5.0301,  ..., -5.1903,  4.0654,  1.2935]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7646,  0.6093, -3.6742,  ..., -1.0909,  0.6208, -1.2965],\n",
            "        [ 2.8446,  0.9115, -2.9686,  ..., -1.1781,  1.6268, -2.2052],\n",
            "        [ 1.1258,  2.3872, -2.1347,  ..., -1.8015,  1.4718, -0.8821],\n",
            "        ...,\n",
            "        [-0.3207, -3.2619, -5.8682,  ..., -4.9075,  1.4736, -3.0125],\n",
            "        [ 2.8479, -1.2240, -3.0027,  ..., -2.3962,  2.4002, -1.0068],\n",
            "        [ 1.5959, -2.4552, -5.7268,  ..., -5.0755,  1.0494, -1.5157]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3315, -0.7140, -4.9023,  ..., -1.5222,  2.7413,  0.9895],\n",
            "        [ 4.8446,  1.2608, -4.6783,  ...,  0.3882, -1.1248, -1.3880],\n",
            "        [-0.3417, -0.2542, -3.7582,  ..., -1.0384,  2.4511,  1.5284],\n",
            "        ...,\n",
            "        [-0.3495,  0.8725, -2.2147,  ..., -1.7143,  2.2888,  1.4959],\n",
            "        [ 2.7146, -0.5862, -1.7986,  ..., -0.9713,  0.9346,  0.0208],\n",
            "        [ 2.9445, -0.7262, -6.9349,  ..., -3.5670,  3.2633, -0.8691]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5390,  1.5085, -3.0745,  ..., -0.5295,  1.0934, -2.3051],\n",
            "        [ 1.0026, -1.5102, -3.6596,  ...,  0.1136, -0.6170,  0.7501],\n",
            "        [ 0.5660, -1.6941, -5.0467,  ..., -1.4106,  3.3497,  0.2247],\n",
            "        ...,\n",
            "        [ 4.1869, -0.2037, -4.2200,  ..., -2.1813,  1.2454, -0.9548],\n",
            "        [ 1.5361,  0.1684, -6.5166,  ..., -2.1513, -0.1185, -1.4224],\n",
            "        [ 3.2253,  4.0441, -3.6478,  ..., -1.4318, -0.4663, -1.8051]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9959,  2.1243, -2.1083,  ..., -0.3875,  1.4071, -1.0193],\n",
            "        [-0.9831, -1.8884, -4.7066,  ..., -4.7343,  2.4232, -2.6621],\n",
            "        [ 2.2124, -2.4736, -4.0887,  ..., -2.3397,  1.2026, -0.7352],\n",
            "        ...,\n",
            "        [ 1.5070, -1.7029, -3.9182,  ..., -1.3211,  3.6596, -1.3237],\n",
            "        [ 1.1478, -2.6216, -5.0549,  ..., -1.5949,  1.4318,  1.3177],\n",
            "        [ 0.9159,  0.2335, -2.8228,  ..., -2.2226,  2.8137, -0.6981]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4675, -1.9273, -6.3255,  ..., -1.0049, -3.0719, -1.5942],\n",
            "        [-1.4693, -1.6290, -5.3390,  ..., -1.9948,  0.4926, -0.0607],\n",
            "        [ 1.7488, -1.9029, -6.6828,  ..., -3.4801,  0.4040,  1.7262],\n",
            "        ...,\n",
            "        [ 0.6032,  0.1894, -2.5235,  ..., -1.8330,  1.3389,  1.8734],\n",
            "        [ 3.6715,  3.0386, -3.0968,  ..., -1.9128,  0.1443, -2.2598],\n",
            "        [ 1.9269,  1.0243, -5.2469,  ..., -1.0575,  2.3164, -2.5576]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7612, -1.2394, -4.6537,  ..., -3.8890,  2.5058,  0.9527],\n",
            "        [ 2.6804,  0.7480, -3.3514,  ..., -0.6564,  2.1312, -2.2353],\n",
            "        [ 1.8084, -2.3919, -3.3358,  ..., -2.8981,  0.5690, -1.6451],\n",
            "        ...,\n",
            "        [ 3.6454,  2.4207, -3.2467,  ..., -0.9310,  0.1190, -2.6593],\n",
            "        [ 3.8615,  0.4648, -5.2288,  ..., -1.5846, -0.8338, -1.6148],\n",
            "        [ 2.1689, -0.7169, -3.5342,  ..., -1.4823, -1.9974, -3.5258]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0250,  0.6072, -3.3585,  ..., -1.5114,  1.3729,  0.4118],\n",
            "        [ 1.4805, -2.9664, -5.0664,  ..., -3.1384, -0.0204, -1.6237],\n",
            "        [ 3.8097,  1.9427, -3.7891,  ..., -2.8889,  1.1732, -1.5226],\n",
            "        ...,\n",
            "        [-0.4598, -0.0809, -2.1260,  ...,  0.3262,  2.7512,  1.3538],\n",
            "        [-1.4021, -0.1709, -2.4596,  ..., -0.1713,  2.1384,  1.7324],\n",
            "        [ 2.9459, -1.0621, -4.6668,  ..., -0.9726,  3.4070,  0.7863]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4161,  0.5130, -2.9675,  ..., -1.7763,  1.9177,  0.4489],\n",
            "        [ 1.3552,  2.3882, -2.6580,  ..., -2.4166,  1.0556, -0.6870],\n",
            "        [ 2.8733,  0.9831, -5.2288,  ..., -1.7785,  0.8699,  0.4450],\n",
            "        ...,\n",
            "        [ 0.9054, -0.5942, -3.1312,  ..., -2.7617,  1.9491,  1.9695],\n",
            "        [ 2.1195,  0.7004, -2.5252,  ..., -1.2713,  0.3829, -0.1807],\n",
            "        [ 0.3721, -1.0592, -5.3854,  ..., -1.7051,  1.6764, -0.7099]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7572, -0.5547, -1.7829,  ..., -0.3214,  2.7319,  1.6314],\n",
            "        [ 4.0368,  1.6049, -5.4871,  ...,  0.0895,  2.4214, -0.6380],\n",
            "        [ 1.3337, -2.0264, -5.2100,  ..., -2.5820,  2.0418, -1.0624],\n",
            "        ...,\n",
            "        [-0.4820, -0.7024, -2.8555,  ..., -1.0896,  2.7039,  0.3433],\n",
            "        [ 0.5160, -0.0816, -2.6290,  ..., -1.2885,  1.1720, -1.1622],\n",
            "        [ 0.1377, -2.7905, -5.7965,  ..., -4.9308,  2.2957, -2.7171]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.9831, -2.2255, -5.4012,  ..., -2.1744, -1.1082, -2.7232],\n",
            "        [-0.3744, -2.1349, -5.9487,  ..., -2.0366,  2.3759,  0.0558],\n",
            "        [-0.7996, -0.9295, -2.7458,  ..., -1.5898,  2.6298,  1.3994],\n",
            "        ...,\n",
            "        [ 2.3147,  0.7164, -5.2694,  ..., -0.6046,  2.9971,  0.6781],\n",
            "        [ 3.5293,  0.0124, -5.3708,  ..., -0.9089,  0.8091, -4.4441],\n",
            "        [ 0.7381, -1.6829, -4.7864,  ..., -1.7259, -0.6212, -1.0849]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2709, -1.3220, -5.2823,  ..., -2.9227,  0.8538, -1.5748],\n",
            "        [ 4.6164,  2.1384, -3.7333,  ...,  0.3182,  1.9473, -2.4633],\n",
            "        [-0.1567,  0.0674, -6.5566,  ..., -4.3093,  1.4001, -1.7881],\n",
            "        ...,\n",
            "        [ 1.2369, -2.1075, -4.7840,  ..., -2.5124,  2.6827,  0.6682],\n",
            "        [ 3.4620, -1.5015, -4.0254,  ..., -1.1262,  0.2440, -1.9143],\n",
            "        [-0.8572,  1.2461, -5.1691,  ..., -4.3048,  2.4488, -1.3834]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2649,  0.7348, -4.6008,  ..., -0.8469,  1.6184, -2.2399],\n",
            "        [ 0.5186, -1.4460, -4.7766,  ..., -0.9877,  2.7399,  1.4445],\n",
            "        [ 3.6849, -1.9877, -4.6003,  ..., -2.5245,  2.9903, -1.2882],\n",
            "        ...,\n",
            "        [ 2.0477,  1.4676, -5.0177,  ..., -0.0598,  1.8733,  0.4082],\n",
            "        [-0.6569, -0.4841, -3.7188,  ..., -1.5850,  2.9797,  0.8947],\n",
            "        [ 1.4618, -2.8716, -3.4105,  ..., -2.4369,  2.1920,  1.1681]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2887,  0.3521, -5.3463,  ..., -2.1985, -0.1911, -1.8461],\n",
            "        [ 2.8073, -1.2258, -6.6114,  ..., -3.0955, -0.3327, -1.3664],\n",
            "        [ 1.4927,  0.0334, -4.0810,  ..., -0.5685, -1.2661, -0.0155],\n",
            "        ...,\n",
            "        [ 2.5778, -3.1150, -3.9798,  ..., -2.8554, -3.0348, -2.0469],\n",
            "        [ 3.4310,  2.2055, -3.5485,  ..., -1.9937, -0.6526, -1.9685],\n",
            "        [-0.4456,  1.0104, -4.7473,  ..., -3.3367,  2.5732,  0.5227]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1981, -2.0944, -4.8269,  ..., -1.5633,  2.0863, -2.1063],\n",
            "        [ 3.6157,  0.9108, -3.2452,  ..., -2.6533,  0.8653, -1.1840],\n",
            "        [ 1.1504,  0.0768, -2.7092,  ..., -0.1349, -1.4156,  0.4650],\n",
            "        ...,\n",
            "        [-0.1465, -0.6577, -6.2519,  ..., -1.8705,  2.4416,  0.0219],\n",
            "        [ 2.9265, -0.2224, -2.8052,  ..., -0.5915, -2.1846, -2.1907],\n",
            "        [ 1.0328, -1.8738, -3.7780,  ..., -3.5292, -0.2578, -1.3317]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6814, -2.2133, -6.3977,  ..., -2.0666,  0.9818, -0.6395],\n",
            "        [ 0.3963,  0.1722, -3.5969,  ..., -0.5243,  1.5992,  0.2469],\n",
            "        [ 1.2569, -0.3520, -5.5927,  ..., -4.5166,  1.7185, -0.7906],\n",
            "        ...,\n",
            "        [ 2.2503, -0.2742, -4.2290,  ...,  0.0126, -1.8019, -2.6231],\n",
            "        [ 0.4849, -0.7848, -3.7998,  ..., -0.5424,  3.3943,  1.1961],\n",
            "        [-0.3622, -1.8593, -5.7957,  ..., -3.0367,  0.7409, -0.4968]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.9697, -0.6859, -6.1041,  ..., -1.3886, -0.7795, -2.3299],\n",
            "        [ 0.7661,  0.6509, -4.3681,  ..., -1.0225,  1.2674, -0.9203],\n",
            "        [ 1.6651, -0.1602, -4.8087,  ..., -1.2658,  1.7051,  0.1320],\n",
            "        ...,\n",
            "        [ 3.3216, -1.6559, -4.3400,  ..., -0.4469, -0.6916, -1.8702],\n",
            "        [ 2.9156, -0.0737, -5.2893,  ..., -0.2144, -1.2417, -1.4913],\n",
            "        [-0.2364, -2.2311, -4.1323,  ..., -2.2896,  1.1264, -1.7213]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0860,  0.4997, -1.8367,  ..., -3.7015,  1.4335, -1.1277],\n",
            "        [-0.2046, -1.7656, -3.7462,  ..., -3.6459,  3.0982,  2.2447],\n",
            "        [ 0.6185, -3.1191, -4.2068,  ..., -2.9539,  2.7968,  2.8553],\n",
            "        ...,\n",
            "        [ 0.1225, -0.6125, -4.0246,  ..., -1.8180,  2.3279,  1.3801],\n",
            "        [-0.2836, -1.6264, -3.9933,  ..., -0.3384,  1.2041, -0.0773],\n",
            "        [ 2.8853, -1.3442, -2.1666,  ..., -1.1132,  0.8758, -2.8016]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0017, -2.3489, -6.3995,  ..., -1.4298,  1.2891, -0.0411],\n",
            "        [ 2.5030, -0.6092, -3.8581,  ..., -1.3102,  1.7600, -0.6253],\n",
            "        [ 0.2855,  0.9212, -2.8644,  ..., -1.6921,  2.9222,  2.0347],\n",
            "        ...,\n",
            "        [ 2.1906, -2.3803, -5.0748,  ..., -2.4032,  4.3032,  1.2579],\n",
            "        [ 0.0882, -0.6041, -3.2881,  ..., -1.8925,  1.6813,  0.8217],\n",
            "        [ 0.0495, -1.4978, -5.4132,  ..., -2.8965,  0.0340, -2.3775]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4520, -1.2563, -4.1464,  ..., -0.4875, -3.3614, -2.2540],\n",
            "        [ 1.3705, -0.7320, -3.8521,  ..., -3.3826,  2.0266, -0.1485],\n",
            "        [ 3.0016, -1.4068, -1.1322,  ..., -1.4666,  0.2642, -3.1914],\n",
            "        ...,\n",
            "        [ 0.5310, -2.3414, -4.4968,  ...,  0.9203,  0.0755,  1.4913],\n",
            "        [ 0.8133,  0.9679, -4.0514,  ..., -1.5273,  1.0546, -0.9497],\n",
            "        [-0.6813, -0.9590, -4.3571,  ..., -2.3458,  4.1939,  2.0566]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2114,  3.5132, -3.8072,  ..., -1.9113, -0.2462, -1.3891],\n",
            "        [ 0.3661, -1.6635, -5.1304,  ..., -2.1294,  1.8392,  0.9319],\n",
            "        [-1.6289, -1.6322, -7.3224,  ..., -6.3970,  2.4975, -0.4234],\n",
            "        ...,\n",
            "        [ 1.5510,  0.0965, -4.2382,  ..., -0.5324,  0.9075,  0.5381],\n",
            "        [ 0.3188, -1.8978, -5.5060,  ..., -3.1709,  0.6746,  1.7268],\n",
            "        [ 0.4923,  1.3286, -2.5031,  ..., -1.2278,  1.3740, -0.6818]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8319, -1.0626, -5.6795,  ..., -1.6252,  2.6459,  1.5210],\n",
            "        [ 3.0457,  2.2695, -4.0476,  ..., -2.2611,  1.7950, -1.0272],\n",
            "        [ 0.7922,  1.9499, -2.9096,  ..., -1.3394,  0.9390, -1.8191],\n",
            "        ...,\n",
            "        [ 1.3425, -0.7147, -4.0015,  ..., -2.8817,  1.6118, -0.1111],\n",
            "        [ 0.2487, -0.0256, -3.2746,  ..., -0.5508,  2.4296,  2.8824],\n",
            "        [ 0.8165, -3.4602, -5.4432,  ..., -2.8641,  4.0629, -1.3416]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9169, -1.1018, -4.2228,  ..., -3.1344,  1.7827,  1.7515],\n",
            "        [ 1.2008, -1.7657, -5.2961,  ..., -1.9943,  3.6728,  0.5732],\n",
            "        [-0.1044,  2.4546, -4.2505,  ..., -2.5546,  0.6741, -1.3077],\n",
            "        ...,\n",
            "        [ 0.9286,  1.6748, -4.5031,  ..., -1.2298,  1.0828, -1.9498],\n",
            "        [ 3.1546,  0.1852, -3.7415,  ..., -0.3153,  2.0708, -1.6962],\n",
            "        [ 0.2804, -0.4621, -3.7484,  ..., -0.9261,  3.4949,  1.5319]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3831, -1.1370, -3.4514,  ..., -2.2456,  3.0384,  1.7808],\n",
            "        [ 0.3850,  2.7532, -2.6224,  ..., -2.5152,  0.9668, -0.7489],\n",
            "        [ 0.3859, -4.2388, -4.5110,  ..., -2.7095,  4.2511,  0.8302],\n",
            "        ...,\n",
            "        [ 3.4853,  0.6176, -4.8162,  ..., -2.0573,  1.7337,  1.0823],\n",
            "        [-0.0182,  1.2410, -3.2702,  ..., -1.4569,  0.7420,  2.1971],\n",
            "        [ 5.8881,  1.0028, -4.0937,  ..., -1.1513, -1.0694, -5.7664]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8432, -0.8904, -4.3873,  ..., -2.7120,  1.1252,  0.1126],\n",
            "        [ 2.0893, -2.7855, -6.5380,  ..., -1.9839,  0.9124,  2.6384],\n",
            "        [ 0.6748, -0.5777, -4.5522,  ..., -2.4857,  0.9384, -0.7505],\n",
            "        ...,\n",
            "        [ 0.2747, -2.2016, -7.9992,  ..., -1.6593,  2.1751,  0.0909],\n",
            "        [ 2.9096,  1.4721, -4.0644,  ..., -1.2471,  1.2499, -0.7616],\n",
            "        [ 1.8192,  1.2937, -4.4886,  ..., -1.8227,  0.8687,  0.6214]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9767, -0.8018, -4.4563,  ..., -0.7492,  3.3864,  0.6226],\n",
            "        [ 1.3088, -1.6127, -5.4707,  ..., -3.0510,  2.8022,  1.4380],\n",
            "        [ 0.3141, -0.7426, -3.4582,  ..., -1.3144,  2.6568,  0.6537],\n",
            "        ...,\n",
            "        [ 0.4575, -0.8037, -4.5257,  ..., -0.8527,  2.4740,  1.9428],\n",
            "        [-0.1002, -0.9978, -4.3371,  ..., -2.0068, -1.0160, -0.7042],\n",
            "        [ 5.1304,  1.1605, -6.6410,  ..., -0.4337,  1.1489, -2.6371]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4533, -2.5395, -3.8609,  ..., -3.7675,  0.4804, -1.8338],\n",
            "        [ 0.8622,  1.6738, -3.7064,  ..., -2.1521,  1.5325, -2.6542],\n",
            "        [ 3.2718, -1.4160, -5.0005,  ..., -2.7012,  0.7464, -0.7970],\n",
            "        ...,\n",
            "        [ 0.3999,  1.4374, -2.9640,  ..., -2.3137, -1.2006, -0.8870],\n",
            "        [ 0.7347, -1.8631, -3.5874,  ..., -0.5589,  0.8482,  1.8188],\n",
            "        [-0.8456, -1.5943, -2.0656,  ..., -0.9738,  4.2982,  2.6301]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2489,  0.3296, -5.1000,  ..., -1.7671, -0.0927, -1.2353],\n",
            "        [ 1.3752, -1.6114, -3.5749,  ..., -1.2049,  2.4440, -0.4101],\n",
            "        [ 1.5678, -0.7095, -3.7776,  ..., -1.2343,  1.7166,  0.6181],\n",
            "        ...,\n",
            "        [ 0.4986, -0.9814, -4.8884,  ..., -2.9957,  0.9712, -0.8327],\n",
            "        [ 1.3242, -2.5085, -2.7152,  ..., -1.8254,  4.3745,  1.9296],\n",
            "        [-0.7128, -0.0827, -0.4213,  ..., -3.5399,  1.7955, -2.2956]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5353, -1.9426, -3.5304,  ..., -2.1934,  2.4616,  2.6618],\n",
            "        [ 2.2297,  1.2606, -2.6550,  ..., -2.6962,  1.2272,  0.1318],\n",
            "        [ 4.3965, -1.1965, -4.9180,  ..., -0.7142, -0.1399, -2.8654],\n",
            "        ...,\n",
            "        [ 2.0143, -4.6847, -4.7780,  ..., -3.3230,  4.5842, -0.6125],\n",
            "        [ 0.7578, -2.6702, -4.3832,  ..., -3.7756,  1.8558, -1.7817],\n",
            "        [-0.1520,  1.7925, -4.3361,  ..., -1.6265,  0.1547, -0.5469]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5980, -3.1937, -4.6236,  ..., -2.1154,  5.9120,  2.8980],\n",
            "        [ 0.0769, -1.1103, -5.7099,  ..., -4.0635,  1.1772,  2.5748],\n",
            "        [ 0.6180, -1.2112, -3.7571,  ..., -4.8738,  1.9355, -2.4465],\n",
            "        ...,\n",
            "        [ 2.6852, -2.6987, -5.3201,  ..., -4.3291,  0.5712, -2.1833],\n",
            "        [ 0.6870, -0.7822, -3.4101,  ..., -1.2413,  0.5418,  0.7171],\n",
            "        [ 2.9747, -0.1411, -3.9909,  ..., -1.1909,  0.4464, -0.5628]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0614, -0.4022, -2.5651,  ..., -1.1991,  1.9773, -0.3150],\n",
            "        [ 2.7762, -2.8918, -5.7907,  ..., -0.9363,  1.5947,  0.8277],\n",
            "        [-0.3173, -1.8492, -3.8613,  ..., -4.8539,  0.0806, -3.5995],\n",
            "        ...,\n",
            "        [ 2.6983, -2.3529, -6.9510,  ..., -3.1483,  3.3636,  1.4694],\n",
            "        [ 4.5107,  2.3981, -2.6517,  ...,  0.0784, -1.9671, -3.5298],\n",
            "        [-0.4727, -1.3163, -4.0510,  ..., -2.2518,  2.5464,  0.7773]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4887, -0.8631, -4.8029,  ..., -2.3092,  3.0168,  0.9992],\n",
            "        [ 0.4139, -0.5061, -3.1711,  ..., -0.4179, -0.5949,  3.0827],\n",
            "        [ 4.8130,  2.7130, -4.4660,  ..., -1.0883, -0.7262, -3.3226],\n",
            "        ...,\n",
            "        [-0.8932, -3.7168, -4.6595,  ..., -2.1366,  1.4514,  0.3424],\n",
            "        [ 1.6887, -4.0404, -4.6032,  ..., -2.4147,  2.7295, -0.7599],\n",
            "        [ 1.9019, -0.9740, -4.9785,  ..., -1.3842,  0.8442, -1.3392]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6091,  0.3647, -5.1158,  ..., -3.2695,  3.0092,  1.5829],\n",
            "        [ 5.1308, -1.8829, -5.9733,  ..., -2.1822, -0.5334, -2.3446],\n",
            "        [ 0.4752, -1.6448, -4.3066,  ..., -1.7473,  2.6504,  0.7217],\n",
            "        ...,\n",
            "        [ 1.4264, -1.7829, -3.2516,  ...,  0.7668, -0.6070,  0.9244],\n",
            "        [ 0.3709,  2.0648, -6.1142,  ..., -3.5750,  1.3937,  0.6054],\n",
            "        [ 0.0854, -0.9519, -6.9427,  ..., -2.9172,  2.6348, -0.6929]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4116, -1.5298, -2.6165,  ..., -1.3642,  3.6786,  0.9873],\n",
            "        [-0.0781,  0.1333, -5.2748,  ..., -1.6279,  1.1874, -1.2828],\n",
            "        [-0.9924, -2.3226, -5.0311,  ..., -3.4499,  2.7917, -2.3143],\n",
            "        ...,\n",
            "        [ 0.2047, -1.0736, -3.6642,  ..., -3.6269,  1.9717, -0.3748],\n",
            "        [ 3.7703,  3.1173, -2.9871,  ...,  0.3483,  1.0449, -2.2408],\n",
            "        [ 1.3251, -2.2715, -5.2949,  ..., -4.1217,  0.3437, -3.2646]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5042, -0.3736, -4.0214,  ..., -0.8134,  2.1113,  1.5331],\n",
            "        [ 4.6293,  2.6856, -5.5215,  ..., -2.2443,  0.1668, -1.3001],\n",
            "        [ 2.0589,  1.7657, -3.1339,  ..., -0.7873, -0.0272, -1.4772],\n",
            "        ...,\n",
            "        [ 1.1979, -3.1824, -3.4751,  ..., -1.7669,  1.6622,  0.6949],\n",
            "        [-0.5871, -1.6882, -3.6723,  ..., -0.3165, -1.2270,  0.9045],\n",
            "        [ 4.8688,  0.1392, -6.7103,  ..., -2.3323, -0.1491, -2.8462]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0261, -0.9641, -3.9590,  ..., -1.1298,  1.2853,  1.3967],\n",
            "        [ 1.1154, -2.0802, -4.8475,  ..., -2.0706,  3.9724,  0.8162],\n",
            "        [ 0.7110, -1.0145, -3.6619,  ..., -3.2956,  0.5037, -2.0464],\n",
            "        ...,\n",
            "        [-1.7499, -0.3905, -1.9258,  ..., -0.3654,  2.3930,  1.8134],\n",
            "        [-1.3717, -1.1829, -3.5589,  ..., -2.5723,  2.5129,  2.5380],\n",
            "        [ 1.0363, -0.6996, -5.0765,  ..., -1.8918,  1.5360,  1.0463]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0621, -0.1003, -3.8969,  ..., -1.7853,  2.1558,  2.4611],\n",
            "        [ 0.9590,  0.3374, -4.0622,  ..., -1.4169,  1.8980,  0.3746],\n",
            "        [ 4.3911, -0.7020, -4.8015,  ..., -2.5299, -1.3496, -2.8382],\n",
            "        ...,\n",
            "        [ 1.3503, -0.1072, -3.8027,  ..., -0.5413,  0.9285, -2.2606],\n",
            "        [ 3.0989, -2.2876, -3.4422,  ...,  0.7670,  0.1276, -2.5291],\n",
            "        [-0.6381, -0.7347, -4.4271,  ..., -0.5691,  2.7856,  2.9095]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2941, -0.1806, -2.7297,  ..., -0.7825,  1.0326, -0.1840],\n",
            "        [ 3.9728, -0.2281, -3.7385,  ..., -2.6464,  2.7821, -0.6043],\n",
            "        [ 3.4897, -3.7459, -6.9661,  ..., -1.9247, -1.9932, -0.6996],\n",
            "        ...,\n",
            "        [ 2.7405, -1.6996, -5.9346,  ..., -1.0020,  0.3303, -0.8540],\n",
            "        [ 1.1087, -3.6353, -3.8609,  ..., -0.8869,  2.1645, -1.1282],\n",
            "        [ 0.4451,  0.0207, -3.6792,  ..., -1.6665,  0.6684, -1.7206]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3127, -1.0662, -6.7195,  ..., -3.5461,  1.2573,  0.3433],\n",
            "        [ 1.5672, -2.0914, -5.2941,  ..., -3.6314,  3.8289,  0.3016],\n",
            "        [-0.5085, -2.5650, -4.0729,  ..., -2.1819,  4.2131,  1.4158],\n",
            "        ...,\n",
            "        [-0.0768, -1.4694, -3.1697,  ..., -4.2038,  1.4661, -2.2166],\n",
            "        [-1.2685, -1.3112, -2.9445,  ..., -1.1268,  3.4629,  1.9424],\n",
            "        [ 0.4698, -1.5781, -6.5177,  ..., -2.6909,  4.2708,  1.3790]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5486, -0.1059, -3.5845,  ...,  0.0207, -0.7640,  1.2933],\n",
            "        [ 2.4589, -1.0072, -6.2161,  ..., -1.9166, -0.2356, -2.7572],\n",
            "        [ 1.9931, -1.9451, -3.1928,  ..., -0.9419,  1.5322, -1.3178],\n",
            "        ...,\n",
            "        [ 1.2786, -2.2346, -4.8895,  ..., -1.7717,  3.8448,  1.0111],\n",
            "        [ 0.8634, -1.6960, -5.9877,  ..., -2.9195,  1.4214, -0.5606],\n",
            "        [-1.3278, -1.6542, -2.8545,  ..., -2.6758,  4.2364,  2.2081]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6484, -1.1382, -2.2833,  ..., -0.0795,  1.2514, -3.2337],\n",
            "        [ 2.3096, -1.1885, -4.6205,  ..., -1.2034,  2.4374, -0.7137],\n",
            "        [ 3.0230, -2.5547, -4.0469,  ..., -1.2094, -2.5974, -0.8838],\n",
            "        ...,\n",
            "        [ 1.5345,  0.3549, -2.6412,  ...,  0.3750,  2.6515,  0.2655],\n",
            "        [ 1.8365, -2.4114, -6.9178,  ..., -2.7003, -0.0928, -2.2306],\n",
            "        [ 3.1130,  1.4223, -4.1145,  ..., -2.0749,  0.2085, -3.0127]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2689, -1.0762, -4.9985,  ..., -2.6207,  0.3877, -0.1802],\n",
            "        [ 0.6183,  1.4789, -3.3702,  ...,  0.3077,  1.9586, -0.8599],\n",
            "        [ 0.7027, -1.2852, -4.8505,  ..., -2.4892,  1.7068, -2.2990],\n",
            "        ...,\n",
            "        [ 1.7911,  0.5645, -4.7631,  ..., -0.9088,  1.9498,  0.5119],\n",
            "        [ 0.7987,  2.1048, -2.6999,  ...,  0.1728,  1.3448, -1.8529],\n",
            "        [ 1.8919, -2.0875, -4.8817,  ..., -2.7763, -1.0837, -1.9370]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2672, -0.7270, -6.1210,  ..., -1.5019,  1.5037, -0.3098],\n",
            "        [ 0.4735, -1.9569, -5.0213,  ..., -1.0500,  3.0805,  0.6728],\n",
            "        [ 1.2275, -0.2831, -3.3082,  ..., -1.3747,  1.1532, -0.1038],\n",
            "        ...,\n",
            "        [ 1.4049, -2.5730, -5.7564,  ..., -4.4172,  0.4396, -1.1874],\n",
            "        [-1.7958, -2.2299, -4.4543,  ..., -4.1815, -0.2786, -1.6965],\n",
            "        [ 0.7293, -2.4111, -5.2243,  ..., -1.7225,  2.2586,  0.4507]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6635, -1.2267, -4.7754,  ..., -1.9111,  3.4564,  0.9440],\n",
            "        [ 3.2281,  1.1709, -5.9528,  ..., -1.8054,  1.7920, -1.3925],\n",
            "        [ 0.3344, -1.5234, -5.6241,  ..., -3.1080, -1.6912, -3.4217],\n",
            "        ...,\n",
            "        [ 1.4009,  2.5705, -4.8375,  ..., -2.4490,  1.0559, -2.0270],\n",
            "        [ 0.5030, -1.1238, -2.1457,  ..., -1.0846,  1.9386, -0.6698],\n",
            "        [-0.6819, -1.5830, -4.0972,  ..., -2.7953, -0.5341, -1.4199]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5122, -0.8561, -5.8368,  ..., -0.7648,  1.9058, -1.1696],\n",
            "        [ 1.5213, -2.6323, -6.1292,  ..., -3.4714,  1.0929, -2.9760],\n",
            "        [-0.2168, -2.6607, -4.9858,  ..., -1.8780, -0.2588, -1.4347],\n",
            "        ...,\n",
            "        [ 3.0285,  1.5054, -2.6856,  ..., -0.2575,  0.3447, -1.8535],\n",
            "        [ 0.3954, -4.2310, -6.7259,  ..., -0.8172,  1.2519,  1.6569],\n",
            "        [ 1.7186,  0.9488, -2.4310,  ..., -1.4411,  3.4917, -0.5830]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3509,  2.5626, -2.9593,  ...,  0.4375,  0.6829, -1.2925],\n",
            "        [ 4.2737,  0.7754, -3.5180,  ..., -0.0806, -0.7679, -2.5340],\n",
            "        [ 0.6872,  0.3824, -4.1203,  ..., -0.8052,  3.2018,  2.3370],\n",
            "        ...,\n",
            "        [ 1.0705, -1.2154, -2.7389,  ..., -0.2516,  1.3814, -0.4924],\n",
            "        [ 0.9518,  0.4149, -4.7192,  ..., -0.8424,  0.9014, -1.8581],\n",
            "        [ 1.2778, -3.5252, -4.2901,  ..., -1.4558,  3.4002,  1.2082]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7974, -3.8172, -4.4794,  ..., -2.9606,  1.2281, -1.8170],\n",
            "        [ 2.1615, -0.9094, -3.4011,  ..., -3.0941,  1.5779, -1.2808],\n",
            "        [ 1.7052,  0.5462, -4.2435,  ..., -1.1591,  2.6286, -2.1970],\n",
            "        ...,\n",
            "        [ 3.0696, -0.9419, -4.3710,  ..., -0.6826,  1.8324, -2.9004],\n",
            "        [ 3.0587, -3.4154, -5.3932,  ..., -2.1645,  2.2125, -0.7736],\n",
            "        [-0.4321, -1.8819, -2.2324,  ..., -1.7088,  2.5287, -1.8352]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6428,  0.4802, -2.2178,  ...,  0.4108, -0.4254, -1.7768],\n",
            "        [ 1.3672, -1.5363, -4.4788,  ..., -0.5661,  2.8549,  0.7556],\n",
            "        [ 2.5723, -1.2946, -4.1974,  ...,  0.0850,  1.8240, -2.7624],\n",
            "        ...,\n",
            "        [ 1.3365, -0.2868, -1.9251,  ..., -1.5313,  1.7070, -1.3788],\n",
            "        [-0.7168, -1.3523, -3.1700,  ..., -1.3168,  3.7141,  0.9676],\n",
            "        [ 2.3668, -1.5737, -4.6605,  ..., -1.9039,  1.6967, -1.5031]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8300, -1.5311, -5.2758,  ..., -0.5616, -1.6894, -3.8791],\n",
            "        [-0.2269,  0.2050, -4.5140,  ..., -2.7157,  2.1621, -2.0057],\n",
            "        [ 5.0033, -0.7178, -3.8509,  ...,  0.2079, -1.1860, -3.1489],\n",
            "        ...,\n",
            "        [ 0.8507,  0.6440, -2.7157,  ..., -0.5145,  2.4926,  0.1119],\n",
            "        [ 1.7480, -2.6265, -6.6048,  ..., -3.5639,  2.9389, -0.1443],\n",
            "        [ 2.3980, -2.7083, -3.3574,  ..., -2.1167,  1.8657, -0.6463]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3093, -1.3426, -5.0434,  ..., -1.8443,  0.8948, -1.1263],\n",
            "        [ 1.5626, -0.4124, -5.6450,  ..., -2.9625,  2.5411,  1.7701],\n",
            "        [ 1.3390, -1.4546, -3.2216,  ...,  0.2812,  3.5501, -1.6004],\n",
            "        ...,\n",
            "        [ 0.2512, -4.5064, -4.5217,  ..., -2.3463,  3.4575,  0.7789],\n",
            "        [ 1.2771, -3.7188, -4.1066,  ..., -0.6389, -2.3286,  0.6194],\n",
            "        [-1.5603, -2.1804, -5.7570,  ..., -2.7355,  3.2190,  0.1216]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.1282e-01, -2.6631e+00, -2.6510e+00,  ...,  2.4785e-01,\n",
            "          2.5474e+00, -3.8555e-03],\n",
            "        [ 4.5421e-01, -2.5660e+00, -5.0560e+00,  ..., -2.0432e+00,\n",
            "          4.2843e+00,  9.4844e-01],\n",
            "        [ 2.3187e+00,  7.1613e-02, -3.9374e+00,  ..., -1.9505e-01,\n",
            "          1.7960e+00,  7.8156e-01],\n",
            "        ...,\n",
            "        [ 2.8971e+00, -1.5056e+00, -5.4020e+00,  ..., -4.0641e+00,\n",
            "          6.0361e-01, -1.5726e+00],\n",
            "        [ 2.0986e+00,  5.5115e-01, -4.9314e+00,  ..., -1.1103e+00,\n",
            "          2.0708e+00, -1.7668e+00],\n",
            "        [-1.1415e-01, -1.7302e+00, -5.9570e+00,  ..., -3.7191e+00,\n",
            "          7.7617e-01, -1.1213e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8586, -2.6279, -4.4881,  ..., -0.7786,  2.6268,  0.0708],\n",
            "        [-0.9991, -1.6001, -3.9158,  ..., -2.4144,  3.5129,  2.9549],\n",
            "        [ 1.6007,  0.5076, -3.8315,  ...,  0.6763,  1.9593, -0.6010],\n",
            "        ...,\n",
            "        [ 0.4703,  0.2107, -3.3005,  ...,  0.0881,  0.1552,  0.2807],\n",
            "        [ 2.3663, -0.7110, -2.8059,  ...,  0.9997,  3.0733, -1.3208],\n",
            "        [-0.5679, -0.7833, -5.1825,  ..., -1.8868,  2.4199,  0.1411]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2488, -0.0914, -5.8694,  ..., -2.9905, -1.4695, -2.3713],\n",
            "        [ 3.3245, -1.9162, -6.5675,  ..., -4.1276, -0.2122, -3.5897],\n",
            "        [ 1.5978, -0.9572, -3.7345,  ...,  0.1057,  2.9101,  0.1421],\n",
            "        ...,\n",
            "        [-0.2364,  0.1859, -2.1625,  ..., -0.0984,  0.7434,  2.2045],\n",
            "        [ 2.1953,  0.1876, -2.3306,  ...,  0.0179,  0.8085, -0.9996],\n",
            "        [-1.1967, -1.2647, -5.7810,  ..., -2.9013,  2.3235, -1.7826]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8311,  0.9303, -4.3853,  ..., -2.0528,  0.2653, -2.4823],\n",
            "        [ 2.0043, -0.1053, -3.2147,  ...,  0.5228,  0.4963,  0.8903],\n",
            "        [ 0.6656,  0.3639, -5.3612,  ..., -4.0718,  2.7966,  1.1772],\n",
            "        ...,\n",
            "        [ 2.9671,  0.2554, -5.5153,  ..., -0.9094, -1.9260, -1.0645],\n",
            "        [ 5.8782,  1.2440, -5.9896,  ...,  0.0386, -2.1895, -2.7009],\n",
            "        [ 0.1349,  0.8613, -4.3526,  ..., -3.4185,  1.8361,  2.0261]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8994, -4.0514, -5.9321,  ..., -1.5285,  2.9554,  2.8121],\n",
            "        [ 3.8024, -1.3291, -4.8816,  ..., -1.3745, -2.7954, -3.4468],\n",
            "        [ 2.4217,  1.6978, -4.4832,  ..., -0.4844,  2.3003, -0.9068],\n",
            "        ...,\n",
            "        [ 2.3727, -1.3860, -4.5713,  ..., -0.4282,  0.1142,  0.2559],\n",
            "        [ 0.3769,  0.7765, -4.1650,  ..., -1.1401,  1.2027,  1.4022],\n",
            "        [ 1.7045,  2.1831, -2.6449,  ..., -0.2500,  0.0511,  0.8285]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1819, -3.7430, -4.4390,  ..., -1.3467,  1.3541, -1.3799],\n",
            "        [ 1.5046, -2.0910, -4.5681,  ..., -1.4033,  2.1958,  1.1793],\n",
            "        [-0.1316, -1.1504, -5.7739,  ..., -3.8872,  0.0433, -0.4702],\n",
            "        ...,\n",
            "        [ 2.5781,  1.5810, -2.3719,  ..., -2.0023,  0.8669, -4.3331],\n",
            "        [ 1.2830,  1.0468, -3.5575,  ..., -1.0059,  1.0702, -1.3808],\n",
            "        [ 0.5031, -2.2541, -5.0504,  ..., -1.8036,  3.8205,  0.9208]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2557, -0.7860, -5.5548,  ..., -1.9446,  1.4948,  0.4975],\n",
            "        [ 1.7567, -2.9503, -3.8217,  ..., -0.7134,  1.7654,  1.0244],\n",
            "        [ 5.5696,  0.9609, -4.7851,  ...,  1.8969, -2.0732, -0.8394],\n",
            "        ...,\n",
            "        [ 0.9797, -0.2013, -4.6482,  ..., -2.2795,  2.9270, -2.0618],\n",
            "        [ 1.5113,  0.7600, -2.6736,  ..., -1.1327,  1.0202, -1.6696],\n",
            "        [ 1.4669, -0.8481, -5.4468,  ..., -0.5863,  0.6450, -0.6532]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9597,  0.2586, -4.4200,  ..., -1.2995,  0.9040, -0.7034],\n",
            "        [ 2.0736, -3.9719, -6.6681,  ..., -2.1027, -1.4118, -0.9513],\n",
            "        [ 2.6607, -0.7969, -5.1484,  ..., -1.4501,  0.3985, -0.1265],\n",
            "        ...,\n",
            "        [ 3.3173, -3.8034, -5.5500,  ..., -2.8190, -0.4003, -1.7932],\n",
            "        [ 3.7907, -2.6020, -4.1618,  ...,  0.3059,  1.0258,  0.3208],\n",
            "        [ 0.7357, -1.6117, -5.8118,  ..., -1.9911,  1.8657,  1.0038]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5811,  2.1610, -3.3037,  ...,  0.2000,  1.2054, -1.7234],\n",
            "        [-0.6131,  0.0596, -1.9619,  ..., -1.7343,  1.8214,  3.0772],\n",
            "        [ 1.5963, -3.5858, -5.9076,  ..., -1.5529, -3.2106, -2.2335],\n",
            "        ...,\n",
            "        [ 2.2775, -1.2406, -6.5355,  ...,  0.7916, -1.1498, -0.5031],\n",
            "        [ 3.8249,  2.1286, -4.9640,  ..., -1.6049, -0.9735, -2.1543],\n",
            "        [ 3.1796, -1.0902, -4.6235,  ..., -1.6777, -1.0511, -3.2427]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1617,  0.9880, -5.4876,  ...,  0.0235,  2.1545,  0.9019],\n",
            "        [ 0.7057, -0.2129, -4.9629,  ..., -3.3133,  2.9328,  1.1404],\n",
            "        [ 1.4674,  1.0975, -5.0875,  ..., -0.6552,  1.9879,  0.2304],\n",
            "        ...,\n",
            "        [ 0.2655,  0.0672, -5.2416,  ..., -3.2417,  3.3255,  1.6308],\n",
            "        [ 2.3395, -1.2653, -6.2548,  ...,  1.3113, -1.3810,  1.0151],\n",
            "        [ 2.9106, -0.6877, -4.1350,  ..., -0.2989,  1.6542, -2.5326]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5130,  0.1869, -2.5681,  ...,  0.0580,  2.7000,  1.6397],\n",
            "        [ 1.9807, -1.6812, -4.8940,  ..., -2.4437,  0.5950, -1.1584],\n",
            "        [-0.4529, -0.1820, -4.2160,  ..., -2.8617,  0.5162, -1.4600],\n",
            "        ...,\n",
            "        [ 3.7976, -4.2749, -4.2275,  ..., -1.1749, -1.6163, -1.6182],\n",
            "        [ 1.8885, -1.8336, -3.9578,  ..., -1.6497,  1.1183, -0.7289],\n",
            "        [ 5.2967, -0.5360, -4.3805,  ..., -1.5295,  1.1718, -1.7471]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.6246, -0.8919, -3.4275,  ..., -1.8016,  1.5966, -1.0204],\n",
            "        [ 4.8333,  1.8775, -4.4945,  ...,  0.0896, -0.3499, -2.3482],\n",
            "        [ 2.2431, -1.6849, -2.7419,  ..., -0.7922,  0.8656, -0.6101],\n",
            "        ...,\n",
            "        [ 1.4908, -2.6669, -1.6446,  ...,  0.1953,  1.4655,  1.6218],\n",
            "        [ 0.4566, -0.7876, -6.1786,  ..., -3.3071,  0.9592, -2.2957],\n",
            "        [ 2.9773,  3.8174, -2.8566,  ..., -0.5991,  0.2010, -0.6151]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.7950,  2.8761, -5.2457,  ..., -0.0844, -1.1246, -3.0482],\n",
            "        [ 2.0453, -0.7589, -5.2228,  ..., -1.2678,  1.8280,  0.8930],\n",
            "        [-1.0124, -3.5885, -5.6929,  ..., -3.6870,  1.4078, -1.2542],\n",
            "        ...,\n",
            "        [ 2.1299,  1.0745, -3.3288,  ..., -2.0299,  1.4648,  0.8743],\n",
            "        [-0.2842, -1.0872, -3.7241,  ..., -0.8926,  2.4847,  0.8785],\n",
            "        [ 1.8829,  0.8323, -3.6739,  ..., -1.1090,  0.8956, -0.1364]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9942, -2.4694, -3.5116,  ..., -2.5693, -1.7018, -3.5143],\n",
            "        [ 1.3222, -1.1345, -1.7058,  ..., -1.4239,  0.4773,  0.0183],\n",
            "        [ 0.2161, -1.8698, -5.0138,  ..., -0.6420,  0.3755, -1.1573],\n",
            "        ...,\n",
            "        [ 1.9725, -1.9589, -3.4714,  ...,  2.4080, -2.8479,  0.4515],\n",
            "        [ 1.2341, -1.6831, -5.5727,  ..., -1.4679,  1.4885,  1.5233],\n",
            "        [ 1.8925,  0.9594, -5.3502,  ..., -0.7288, -1.7882, -3.1575]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1843, -0.0277, -4.0916,  ...,  0.7138,  1.6397, -0.7550],\n",
            "        [ 1.0252, -3.0099, -3.6939,  ..., -2.7693,  1.6176,  1.4975],\n",
            "        [ 2.0684, -1.5355, -5.2239,  ..., -0.2800,  0.8591, -0.9512],\n",
            "        ...,\n",
            "        [-0.1292,  1.9895, -3.3012,  ..., -1.4549, -0.3079, -3.2075],\n",
            "        [ 0.0255, -2.9671, -6.8382,  ..., -4.1871,  2.5180, -1.3094],\n",
            "        [ 4.8630,  0.1217, -3.2397,  ...,  0.6192, -0.2597, -1.9011]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5266, -2.3828, -6.1773,  ..., -2.1236,  1.6316,  0.7772],\n",
            "        [ 1.8076,  0.0180, -5.6872,  ..., -0.9462,  1.0412, -0.9035],\n",
            "        [ 1.2149, -1.1715, -3.7223,  ...,  0.1968,  2.9241,  1.2779],\n",
            "        ...,\n",
            "        [ 2.0899,  0.0519, -2.7761,  ..., -1.5541,  0.2852,  0.1421],\n",
            "        [ 2.7314,  1.4448, -5.5370,  ..., -0.9284,  1.8109, -1.5513],\n",
            "        [ 1.6667, -1.5868, -2.8780,  ...,  1.0945,  0.9736,  1.5410]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2495, -1.1902, -3.8383,  ..., -2.2263,  5.1875,  4.7025],\n",
            "        [-1.2129, -1.8545, -4.1439,  ..., -0.0445,  0.5602, -0.6307],\n",
            "        [ 1.2743, -3.2087, -5.2624,  ..., -0.9420,  3.8421,  1.6080],\n",
            "        ...,\n",
            "        [ 1.0214, -2.1034, -5.4299,  ..., -1.0518,  3.4398,  0.9817],\n",
            "        [ 1.7181, -0.9765, -3.4062,  ..., -0.3709,  1.6467,  1.8258],\n",
            "        [ 3.1867,  1.9420, -3.8256,  ...,  0.3881,  1.3810, -2.3577]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3667, -0.8574, -4.2893,  ..., -2.6929,  1.0410, -2.2218],\n",
            "        [ 4.1439,  2.9677, -2.0611,  ...,  0.3797,  0.0720, -1.9859],\n",
            "        [ 1.0077,  0.8205, -0.7350,  ...,  0.3834,  1.8374,  1.4721],\n",
            "        ...,\n",
            "        [ 1.2200,  1.9922, -3.8380,  ...,  1.0891,  0.7270, -0.4486],\n",
            "        [ 0.5631, -0.0062, -3.2544,  ..., -1.5971,  1.3998, -1.6719],\n",
            "        [ 0.7336,  0.2655, -2.2772,  ..., -0.9893,  0.2019,  2.4390]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3017,  2.3029, -3.5930,  ..., -1.2737,  0.3080, -1.5738],\n",
            "        [ 0.5357, -4.1094, -2.1290,  ..., -1.8546,  3.7338,  2.2852],\n",
            "        [-0.2824, -1.3152, -4.1231,  ..., -0.8305,  2.8787,  1.3248],\n",
            "        ...,\n",
            "        [ 1.1403, -2.9054, -5.3957,  ..., -0.1694,  1.0483,  0.2697],\n",
            "        [ 1.9902,  0.7045, -2.9573,  ..., -0.9742,  0.8132, -0.4735],\n",
            "        [-0.1583, -0.2616, -5.2440,  ..., -2.4465,  2.1461,  0.4847]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8534, -0.0110, -3.4331,  ..., -2.4343, -0.5581, -0.5384],\n",
            "        [ 0.8057, -0.5586, -2.7520,  ..., -1.0170,  0.3808, -0.6365],\n",
            "        [ 1.3434,  0.5550, -3.9458,  ...,  0.4072,  0.3949,  1.4225],\n",
            "        ...,\n",
            "        [ 1.2284, -1.0702, -3.6771,  ..., -1.0455,  3.4999,  0.1065],\n",
            "        [ 0.1670,  0.1449, -4.2015,  ..., -2.2176,  0.0166, -1.2848],\n",
            "        [ 2.4568, -0.1935, -3.6730,  ...,  0.1127,  0.2417, -3.0368]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4012, -0.6622, -6.0809,  ..., -1.3264,  1.6074,  0.2619],\n",
            "        [ 1.8249, -1.7481, -3.7387,  ..., -0.7293,  0.5930, -2.5336],\n",
            "        [ 1.7102, -3.2667, -5.1713,  ..., -1.3966,  2.3825, -0.0188],\n",
            "        ...,\n",
            "        [ 2.0257, -0.2432, -3.1405,  ..., -0.6545,  2.8548, -0.3437],\n",
            "        [ 2.0915, -1.0155, -5.9850,  ..., -1.1917,  2.8204,  2.8219],\n",
            "        [ 2.0719, -0.1343, -4.4742,  ..., -0.9909,  3.1723, -0.7992]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8504, -3.1559, -3.0945,  ..., -1.0601, -2.9095, -0.7405],\n",
            "        [-0.3650, -0.2760, -2.8998,  ..., -1.4388,  0.6023, -3.2845],\n",
            "        [ 2.8830, -0.4872, -4.3495,  ..., -1.9934, -1.1033, -2.7834],\n",
            "        ...,\n",
            "        [ 1.0840, -2.4667, -3.9300,  ..., -1.4289, -0.2900, -1.2675],\n",
            "        [ 2.7834,  1.0262, -3.3659,  ..., -0.5739,  0.5629, -2.1517],\n",
            "        [ 1.6023,  0.9590, -4.6149,  ..., -0.8623,  0.1873,  0.4348]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2209, -0.6500, -4.6511,  ..., -2.2968,  2.9722,  2.5442],\n",
            "        [ 2.6226, -3.3841, -6.4078,  ..., -2.4171,  3.8268,  1.4543],\n",
            "        [ 0.5403, -0.7906, -5.2631,  ..., -2.2255,  4.5811,  1.6354],\n",
            "        ...,\n",
            "        [ 1.0643, -0.9773, -4.2507,  ...,  0.3827,  1.3686,  2.1395],\n",
            "        [ 1.9755, -1.5189, -2.9413,  ..., -1.5356,  0.4479, -2.3688],\n",
            "        [ 0.7790, -1.3111, -4.1232,  ..., -2.5927,  0.5054, -1.8045]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0913, -1.6526, -5.3230,  ..., -0.0083,  2.1807,  1.9705],\n",
            "        [ 2.2965,  0.2696, -5.7352,  ..., -1.2546,  0.6155,  1.8249],\n",
            "        [ 2.1083,  0.0380, -3.6064,  ..., -1.2801,  2.8124, -2.1263],\n",
            "        ...,\n",
            "        [ 2.1234,  0.7706, -2.7275,  ..., -1.7719, -0.4725, -0.1440],\n",
            "        [ 2.4010, -3.9913, -4.2996,  ..., -3.6030, -1.2713,  0.1102],\n",
            "        [ 2.7703,  2.2711, -3.9414,  ..., -0.5137,  1.3265, -0.3767]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2140e-01, -1.0242e+00, -4.0702e+00,  ..., -5.6306e-01,\n",
            "          1.9953e+00,  1.1722e-01],\n",
            "        [ 8.9839e-01, -1.6504e+00, -3.5480e+00,  ..., -9.9541e-01,\n",
            "          3.6612e+00,  1.2000e+00],\n",
            "        [ 1.6784e+00, -2.3127e+00, -5.1760e+00,  ..., -2.5541e+00,\n",
            "          2.0629e+00, -1.2328e-01],\n",
            "        ...,\n",
            "        [ 7.3398e-01,  1.4452e+00, -3.0471e+00,  ..., -3.2467e-01,\n",
            "          3.0586e-02,  2.4942e-01],\n",
            "        [ 1.2883e+00, -4.2917e+00, -4.3604e+00,  ..., -1.8528e-03,\n",
            "          2.7902e+00, -1.7436e+00],\n",
            "        [ 2.0551e+00, -2.4726e+00, -4.7240e+00,  ..., -1.8684e+00,\n",
            "          1.6119e+00,  7.9511e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2253, -0.5962, -5.5034,  ..., -1.1398,  1.3024, -0.1751],\n",
            "        [ 2.3458, -1.3186, -3.3744,  ..., -2.8670, -1.2977, -1.9481],\n",
            "        [ 3.3092, -1.9244, -5.2116,  ..., -3.8427,  0.2978, -2.1044],\n",
            "        ...,\n",
            "        [ 2.4267, -1.1165, -5.4891,  ..., -1.6572, -0.1640, -2.2303],\n",
            "        [ 1.7849,  0.4615, -3.9024,  ..., -3.3329,  1.6660,  0.1340],\n",
            "        [ 0.7645, -0.0523, -4.5768,  ..., -1.4398,  1.5408,  2.5621]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6950, -0.7127, -1.9636,  ..., -0.1728,  3.8340,  3.6633],\n",
            "        [ 0.2826, -3.2210, -3.6515,  ..., -2.5782,  4.1663,  2.4427],\n",
            "        [ 0.7852,  1.3240, -5.0184,  ..., -0.2527, -0.3039,  1.9202],\n",
            "        ...,\n",
            "        [ 2.0143, -2.3262, -3.8659,  ..., -3.3474,  1.4928, -1.1399],\n",
            "        [ 0.2961,  0.0475, -4.1755,  ..., -1.7245,  0.1209, -0.8725],\n",
            "        [ 3.0702, -0.5105, -5.3190,  ..., -0.1298,  1.2266, -1.1794]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4035, -0.8291, -6.2643,  ..., -3.8099,  1.2809, -0.6072],\n",
            "        [ 0.7834, -0.7916, -5.1169,  ..., -0.7176,  2.0221,  0.0865],\n",
            "        [ 1.6597,  0.4383, -5.1647,  ..., -2.1894,  2.4438, -0.8674],\n",
            "        ...,\n",
            "        [ 1.7140, -2.7414, -2.7929,  ..., -2.0740, -0.3082,  0.0830],\n",
            "        [ 1.7229,  0.8532, -0.9013,  ..., -0.0477, -0.1736,  2.3673],\n",
            "        [ 3.0229, -0.6506, -5.5733,  ...,  1.1746,  2.9594,  2.0229]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0150, -2.0007, -5.5681,  ..., -1.0963,  3.8418,  1.0516],\n",
            "        [ 0.4232, -2.0971, -4.8306,  ..., -3.0238,  0.3703,  0.5807],\n",
            "        [ 1.2331,  1.7003, -1.3094,  ...,  1.7751,  0.6285,  1.1467],\n",
            "        ...,\n",
            "        [ 3.9669, -2.4811, -5.8029,  ..., -0.3098, -2.4620, -3.8008],\n",
            "        [ 2.1795,  0.6147, -5.2330,  ..., -1.0544,  2.5830,  0.5721],\n",
            "        [ 1.4334,  1.2575, -3.1536,  ..., -1.8495,  0.3372,  0.7744]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1070, -1.4166, -3.3363,  ..., -0.1038, -1.1882, -2.9114],\n",
            "        [ 3.1852,  1.8261, -3.9911,  ..., -0.2644,  1.2664, -2.9057],\n",
            "        [ 1.9432, -1.4561, -4.0540,  ..., -1.9603,  0.5271, -2.2152],\n",
            "        ...,\n",
            "        [ 1.2526,  3.5388, -3.6332,  ..., -1.2172,  0.8598, -0.0606],\n",
            "        [ 1.3471, -3.5850, -5.5880,  ..., -2.6818, -2.7807, -1.5017],\n",
            "        [-0.4878, -1.2348, -3.3455,  ..., -0.8218,  3.0824,  2.2056]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4845, -2.9372, -5.3532,  ..., -1.3979,  3.7521,  1.4214],\n",
            "        [ 1.0951, -5.0357, -4.0800,  ..., -1.2986,  1.8810,  0.4627],\n",
            "        [ 0.6678,  0.3022, -5.4776,  ...,  0.0753, -1.0201, -1.4337],\n",
            "        ...,\n",
            "        [ 1.0342, -2.4946, -1.9904,  ..., -1.2517,  1.9292,  1.4537],\n",
            "        [-0.4331,  0.5312, -2.7868,  ..., -0.7599,  1.6314, -1.6925],\n",
            "        [ 1.3484, -2.6630, -4.0963,  ..., -0.3984,  3.8680,  1.4159]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7217,  0.0637, -3.5569,  ..., -0.4416,  2.6591, -1.1363],\n",
            "        [ 5.4220,  0.2958, -4.1252,  ...,  0.5624,  1.3549, -2.2143],\n",
            "        [ 2.3250, -4.4509, -4.9461,  ..., -1.1605,  3.4313,  0.6188],\n",
            "        ...,\n",
            "        [ 3.1565, -1.3400, -4.6997,  ..., -0.9587,  2.1979, -1.5635],\n",
            "        [ 0.7876, -4.2827, -5.8301,  ..., -5.8201,  2.3583, -0.1071],\n",
            "        [ 3.8584, -2.5055, -6.5641,  ..., -3.2287,  3.0089, -0.4468]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2295, -2.4956, -4.3211,  ...,  0.0775, -0.5515, -0.8028],\n",
            "        [ 0.4253, -2.1943, -4.3161,  ..., -0.7666, -0.4333, -1.9689],\n",
            "        [ 1.2234, -2.3492, -6.5896,  ..., -2.0276,  1.9473,  2.3444],\n",
            "        ...,\n",
            "        [ 3.2258, -1.5075, -4.8628,  ..., -0.2101,  1.5295, -2.7724],\n",
            "        [ 3.5991, -0.7123, -4.2950,  ..., -2.9531,  1.5550, -0.7210],\n",
            "        [ 0.6624,  0.1665, -2.2427,  ..., -1.2558,  2.2385, -1.6090]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7668, -0.8238, -2.7416,  ...,  0.0841,  2.7544,  1.3037],\n",
            "        [ 0.2767, -0.4067, -3.9320,  ..., -1.8020,  2.8629,  0.8691],\n",
            "        [ 1.7285,  0.9931, -3.2915,  ...,  0.0277,  0.9746, -1.4833],\n",
            "        ...,\n",
            "        [ 4.8295, -2.6164, -5.2575,  ..., -0.4931, -3.3614, -3.4865],\n",
            "        [ 5.4613, -1.7464, -3.8842,  ..., -1.1640,  0.5049, -0.7648],\n",
            "        [ 1.8535,  0.9692, -3.8161,  ..., -1.1851, -0.3041, -0.3948]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "720c896ae37b4bb291e965b7a588de30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.1160, -1.0323, -3.1097,  ..., -2.3600, -0.7322, -0.2866],\n",
            "        [ 1.5380, -2.4222, -3.6710,  ..., -0.4536,  2.0429, -0.2286],\n",
            "        [ 0.6091,  0.0281, -2.4633,  ..., -1.4019,  1.9218, -0.4196],\n",
            "        ...,\n",
            "        [ 0.5362, -0.6932, -5.9115,  ..., -3.4529,  0.4276, -2.2796],\n",
            "        [ 2.5428, -2.0292, -7.1918,  ..., -1.0727,  2.8453,  0.2334],\n",
            "        [ 1.9233, -0.6859, -3.1086,  ..., -0.7395,  1.5879, -1.7553]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7778, -0.5504, -2.1453,  ..., -0.5428,  2.4185,  2.4876],\n",
            "        [ 2.6641,  0.3999, -5.4423,  ..., -1.1469,  1.5602, -1.7120],\n",
            "        [ 4.3542, -0.4798, -4.7396,  ..., -2.1346, -1.0970, -0.9974],\n",
            "        ...,\n",
            "        [ 1.8753, -0.9734, -5.0281,  ...,  1.0589, -1.3733,  2.2585],\n",
            "        [ 0.3825, -3.4038, -3.9767,  ..., -1.7099,  1.6912,  0.2445],\n",
            "        [ 2.5916, -3.0412, -6.4873,  ..., -1.5622,  2.9855,  1.8413]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8686, -0.3375, -3.1631,  ..., -0.9673,  2.8786,  2.8341],\n",
            "        [ 0.0663, -1.6742, -5.2546,  ..., -1.4445, -1.3046, -2.8352],\n",
            "        [ 2.6101, -1.0960, -3.7326,  ..., -0.4559,  2.1127, -1.5215],\n",
            "        ...,\n",
            "        [ 2.1241,  1.0050, -5.2382,  ..., -0.6717,  1.8208,  0.7771],\n",
            "        [ 5.8873, -0.3850, -5.3241,  ..., -0.8909,  1.1792, -3.0125],\n",
            "        [ 2.4015,  0.9432, -3.9862,  ..., -2.2385, -0.2568, -1.6242]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2885, -1.5437, -2.3551,  ..., -2.7518,  2.4621, -1.4449],\n",
            "        [ 2.4171,  1.2080, -2.0468,  ..., -0.5203, -0.3802,  2.0761],\n",
            "        [ 2.2541, -0.1916, -4.5331,  ..., -4.2298,  0.9690, -0.5593],\n",
            "        ...,\n",
            "        [ 1.5137, -3.3193, -6.6341,  ..., -1.2739,  3.3185,  1.4819],\n",
            "        [ 1.5432, -0.1278, -4.5465,  ..., -1.8975, -0.1359, -0.7359],\n",
            "        [ 1.0111, -3.1286, -5.0051,  ..., -2.0243,  3.3606,  2.0456]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2278,  0.7640, -3.4713,  ..., -1.0281,  1.0390, -2.4096],\n",
            "        [ 0.1669, -2.6651, -4.6545,  ..., -1.6359,  2.1016,  2.8408],\n",
            "        [ 1.4288, -1.4880, -4.6935,  ...,  0.2139,  3.7846,  2.0210],\n",
            "        ...,\n",
            "        [ 0.3979, -0.7646, -5.5148,  ..., -3.4775,  0.4214, -1.0852],\n",
            "        [ 2.0902,  1.3803, -4.5263,  ..., -0.4128,  2.1418, -1.6105],\n",
            "        [ 1.5960, -2.6522, -5.1044,  ..., -1.5346,  3.8542,  1.5372]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5531, -1.7828, -4.6457,  ..., -0.4484,  3.1373,  1.7354],\n",
            "        [ 2.1250,  2.4118, -1.9284,  ..., -0.3172,  3.0008,  0.9699],\n",
            "        [ 3.4063,  1.8815, -3.5567,  ..., -1.2781,  0.6878, -2.2796],\n",
            "        ...,\n",
            "        [-0.6458, -1.7254, -2.4349,  ..., -1.3506,  4.4401,  2.9361],\n",
            "        [ 1.4564, -3.4497, -4.1066,  ..., -0.5067, -2.6557,  1.3458],\n",
            "        [ 1.5308, -3.7218, -3.6874,  ..., -0.4474,  1.6106,  0.1499]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7620, -3.0562, -7.0348,  ..., -1.6265,  3.1014,  2.8206],\n",
            "        [ 0.4683,  0.0908, -3.0394,  ..., -0.8442,  2.5723,  1.2884],\n",
            "        [ 1.6437, -5.6165, -4.0814,  ..., -1.9751,  2.1374,  0.8840],\n",
            "        ...,\n",
            "        [ 3.2711,  0.1744, -4.9090,  ..., -2.7297,  0.0088, -0.3549],\n",
            "        [ 1.5156, -3.8552, -4.4041,  ..., -2.2805,  2.8480,  2.0050],\n",
            "        [ 2.4592,  1.2601, -6.6506,  ..., -1.6842, -0.1942,  0.8134]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1179, -0.7780, -5.3062,  ..., -1.1359,  0.2873, -2.0171],\n",
            "        [ 0.9765, -0.5628, -5.1179,  ..., -3.1760,  1.6368,  1.0512],\n",
            "        [-0.1117, -1.4182, -3.7669,  ..., -0.8449,  3.7394,  2.3893],\n",
            "        ...,\n",
            "        [ 2.1210,  0.4184, -3.7294,  ..., -3.0843, -0.0442, -2.2183],\n",
            "        [ 1.8385, -2.6124, -2.7217,  ..., -0.5607,  1.8451, -0.0196],\n",
            "        [ 1.9036,  0.3142, -4.4328,  ..., -0.7363,  4.7008,  0.1924]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5428, -0.6142, -5.9726,  ..., -0.7338,  3.4132,  2.0476],\n",
            "        [ 1.2681, -2.5695, -5.8464,  ..., -5.9329, -0.4695, -1.7718],\n",
            "        [ 0.7461, -1.8820, -2.8996,  ..., -2.2484,  2.4030,  2.8685],\n",
            "        ...,\n",
            "        [-0.7339,  0.2754, -2.7220,  ..., -0.3062,  1.2687,  2.2987],\n",
            "        [ 4.1278, -0.7223, -4.1865,  ..., -0.6231, -1.9829, -2.9988],\n",
            "        [ 1.4389, -4.1165, -6.8924,  ..., -3.1595,  0.3875, -1.9616]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9870, -1.7303, -3.6349,  ..., -0.3077,  3.8480,  1.0586],\n",
            "        [ 2.5443,  0.5056, -4.4166,  ...,  1.2359,  2.9178,  1.0525],\n",
            "        [ 3.9331, -3.7822, -5.4965,  ..., -1.3471, -0.7781, -0.9166],\n",
            "        ...,\n",
            "        [ 0.5073, -1.8829, -4.1945,  ..., -1.7556,  3.7280,  1.7896],\n",
            "        [ 2.4304,  0.6134, -4.2501,  ...,  0.1946,  1.3047,  1.6193],\n",
            "        [ 2.5892,  2.9514, -4.3263,  ..., -2.8916,  1.1162, -2.7890]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0136, -0.8302, -2.6191,  ...,  0.4858,  0.7447,  2.5726],\n",
            "        [ 1.2314, -0.8994, -3.5546,  ...,  0.6446, -1.7756,  2.1386],\n",
            "        [-1.1426, -2.7450, -4.9196,  ..., -0.4303,  3.7855,  3.4268],\n",
            "        ...,\n",
            "        [ 1.7308, -3.2948, -5.3921,  ..., -2.8069,  1.8066,  1.6604],\n",
            "        [ 3.6990, -1.8547, -6.1239,  ..., -1.3321, -2.7465, -1.3971],\n",
            "        [ 0.3092, -2.0511, -3.3148,  ..., -1.2088,  2.0944,  2.0726]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4386, -0.5886, -2.0714,  ...,  0.9052, -0.2258,  0.4175],\n",
            "        [ 0.2098, -0.9958, -3.6642,  ..., -2.5968,  1.5161,  0.9106],\n",
            "        [ 2.7913,  3.6424, -3.4460,  ..., -3.2486, -1.1897, -1.0140],\n",
            "        ...,\n",
            "        [ 2.3089,  0.7212, -4.4647,  ..., -1.2016, -1.3569, -2.3860],\n",
            "        [ 0.4328, -0.2326, -3.2618,  ..., -2.0130,  1.4794,  0.1898],\n",
            "        [ 2.0505, -4.0761, -6.1686,  ..., -3.4438, -1.1837, -0.0714]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9567e+00, -1.8038e+00, -4.8702e+00,  ..., -1.1905e+00,\n",
            "          6.4314e-01, -2.8773e-01],\n",
            "        [ 1.8214e+00,  3.1142e-01, -6.1314e+00,  ..., -2.8575e+00,\n",
            "          9.5151e-01,  2.1591e+00],\n",
            "        [ 1.7627e+00, -1.4609e+00, -3.6582e+00,  ..., -2.8044e+00,\n",
            "          6.0683e-01,  3.4128e-03],\n",
            "        ...,\n",
            "        [ 3.5449e+00,  4.2525e+00, -4.2466e+00,  ..., -7.5603e-01,\n",
            "         -9.9088e-01, -1.2684e+00],\n",
            "        [ 3.3006e+00,  7.0377e-01, -5.6742e+00,  ..., -1.3574e+00,\n",
            "          8.8589e-01, -1.2192e+00],\n",
            "        [ 1.2045e+00, -1.1099e+00, -3.9042e+00,  ..., -1.5094e+00,\n",
            "          1.1845e+00,  1.1154e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4166, -1.6283, -4.7680,  ..., -1.3070,  3.3509,  1.9668],\n",
            "        [ 1.2040, -2.6436, -4.8863,  ..., -2.3366,  3.3068,  1.9116],\n",
            "        [ 2.2489, -1.4267, -6.2461,  ..., -0.9006,  0.8376,  0.2359],\n",
            "        ...,\n",
            "        [ 1.5733, -3.5067, -3.6295,  ..., -1.1592,  2.7432,  1.0092],\n",
            "        [ 0.2451,  0.9842, -1.8724,  ...,  0.2520, -0.1032,  2.5512],\n",
            "        [ 0.8067,  0.3311, -3.2650,  ..., -2.8231,  1.4199,  1.3652]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0027, -0.4426, -1.9233,  ..., -0.5315,  2.2088,  3.4213],\n",
            "        [ 4.3419,  1.8145, -5.6883,  ..., -0.3129,  0.6199, -1.0848],\n",
            "        [ 3.2117, -0.1945, -6.6737,  ..., -1.5949,  0.3028, -1.8087],\n",
            "        ...,\n",
            "        [ 1.8193, -0.0133, -5.6776,  ..., -3.8796, -0.9574, -2.4298],\n",
            "        [ 4.3531,  2.6758, -5.0335,  ..., -0.8249, -1.2309, -3.3037],\n",
            "        [ 1.2940, -2.5457, -6.4770,  ..., -2.7517,  4.0984,  0.2651]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7401, -1.5493, -4.6792,  ..., -2.0389,  1.1740,  2.5994],\n",
            "        [ 4.2930, -0.3129, -5.0631,  ..., -0.6962,  2.1589, -1.3458],\n",
            "        [-0.3500, -2.3748, -5.0052,  ...,  0.0686,  1.5709,  2.1727],\n",
            "        ...,\n",
            "        [ 1.0836, -1.2184, -4.2027,  ...,  0.6891,  0.4048, -1.2092],\n",
            "        [ 2.2616, -1.9063, -3.4972,  ...,  0.4112,  3.3587,  0.8414],\n",
            "        [ 0.5538, -0.5748, -3.1875,  ..., -2.2972,  1.1454,  1.2867]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9215, -1.8396, -5.0363,  ...,  0.0370,  0.7509,  0.1901],\n",
            "        [ 1.9602,  1.5664, -2.0084,  ...,  0.2442, -0.5073,  0.4717],\n",
            "        [ 1.7668, -3.3550, -5.9076,  ..., -1.6598, -3.7492, -2.4931],\n",
            "        ...,\n",
            "        [ 4.8337,  2.0559, -3.5592,  ...,  0.1653, -1.7688, -2.4097],\n",
            "        [ 2.8859, -1.5309, -7.6941,  ..., -1.4217,  0.4856,  1.1875],\n",
            "        [ 4.2799,  0.8175, -4.0777,  ...,  0.1305, -1.3660, -0.5951]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0071, -2.1630, -5.7564,  ..., -3.8902, -0.4476, -1.0734],\n",
            "        [ 3.3786, -1.6378, -2.9849,  ..., -0.0332,  0.5668, -1.3006],\n",
            "        [ 0.4599,  1.4217, -2.9893,  ..., -3.0277,  1.6153, -1.1143],\n",
            "        ...,\n",
            "        [ 1.6243, -2.1841, -4.5416,  ...,  0.3660,  3.2090,  2.2966],\n",
            "        [ 3.9388, -2.6000, -4.5957,  ..., -0.8737, -1.6805, -3.0559],\n",
            "        [ 0.5601, -1.9920, -4.5329,  ..., -0.7970,  3.3225,  2.2658]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6680,  3.6447, -5.2016,  ..., -3.3672,  0.7945, -1.6276],\n",
            "        [ 1.4781, -0.3378, -4.5923,  ..., -0.4660,  2.0716, -0.1929],\n",
            "        [ 1.9866, -1.8947, -3.5056,  ..., -0.8903,  0.6387,  0.6800],\n",
            "        ...,\n",
            "        [ 2.2194,  2.8949, -4.9218,  ..., -2.6567,  0.7897,  0.4281],\n",
            "        [-0.5227,  0.1604, -1.5826,  ..., -0.4270,  2.3344,  2.3324],\n",
            "        [ 2.6165, -3.9768, -5.0970,  ..., -1.2559,  2.3351,  1.8699]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.1030,  3.6483, -4.3281,  ...,  0.7480, -1.3882, -4.5550],\n",
            "        [-1.5974, -1.6506, -4.3040,  ..., -3.2902,  2.8262,  3.2669],\n",
            "        [-0.1574, -1.3244, -4.0125,  ..., -0.8722,  3.1346,  2.1161],\n",
            "        ...,\n",
            "        [ 0.3227, -1.6053, -1.8975,  ...,  0.5241, -1.0712,  0.5202],\n",
            "        [ 2.0957,  0.3183, -3.1100,  ..., -2.6412,  1.5827, -1.2229],\n",
            "        [ 1.5343, -4.8979, -6.2532,  ...,  1.0802, -2.2035,  0.8187]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6276, -1.2241, -3.8117,  ..., -0.1207,  1.8499,  2.0584],\n",
            "        [ 4.1011,  2.6521, -4.1587,  ..., -1.1314, -1.3656, -3.2189],\n",
            "        [-1.5440, -0.6657, -3.9995,  ..., -0.6554,  1.9251,  0.5963],\n",
            "        ...,\n",
            "        [ 3.5158,  0.3258, -4.9430,  ..., -0.8426, -2.3140, -3.2334],\n",
            "        [ 1.3653, -2.2394, -3.0890,  ..., -0.3760,  1.6727,  0.4242],\n",
            "        [ 1.4854, -0.3808, -5.0413,  ...,  1.0521, -0.0508,  1.1101]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4976, -1.6503, -4.4791,  ..., -1.6888,  0.7433, -1.4946],\n",
            "        [-2.7319,  0.2951, -2.1412,  ..., -0.6258,  0.5960, -2.3529],\n",
            "        [ 1.0074, -1.8382, -5.7618,  ..., -1.3133,  0.7771, -2.4320],\n",
            "        ...,\n",
            "        [ 2.6170, -1.4837, -2.9740,  ...,  0.1696,  2.3808,  1.2757],\n",
            "        [ 3.1388,  1.1978, -4.7045,  ..., -1.0592, -0.3095, -1.3991],\n",
            "        [-0.0554, -1.0329, -4.0972,  ..., -2.6862, -1.2041, -0.8926]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1122,  0.4400, -5.2766,  ..., -0.7431, -1.3920, -0.0648],\n",
            "        [-1.6038, -1.7796, -2.0510,  ..., -1.9519, -0.1759, -2.3274],\n",
            "        [ 3.3628,  1.3403, -2.8145,  ...,  0.1195,  1.1662, -1.5221],\n",
            "        ...,\n",
            "        [ 1.5921, -2.4065, -3.0204,  ...,  0.5408,  1.9790,  0.6807],\n",
            "        [ 0.2565, -3.1222, -4.6032,  ..., -1.0818,  3.2934,  4.3713],\n",
            "        [ 2.4161, -1.2802, -5.0610,  ..., -2.2995, -0.2858, -2.5005]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7747,  0.6078, -4.4221,  ...,  1.1472,  2.1366, -0.9641],\n",
            "        [ 0.5029, -2.1670, -2.9763,  ..., -1.1193,  3.7015,  3.4995],\n",
            "        [ 1.6190, -2.2594, -5.2616,  ..., -0.3889,  3.3066,  2.3156],\n",
            "        ...,\n",
            "        [-1.6382, -3.4726, -4.8253,  ..., -4.2002, -0.1549, -0.7136],\n",
            "        [ 2.2620,  0.8703, -4.2467,  ..., -0.1079, -1.9170, -3.3446],\n",
            "        [ 4.1703, -3.8793, -4.2275,  ..., -1.3886, -2.1046, -2.1694]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6964,  0.3317, -4.8789,  ..., -1.6688,  1.4505,  0.9399],\n",
            "        [ 0.6653, -0.5676, -5.1798,  ..., -3.1076, -3.6197, -3.1700],\n",
            "        [ 1.1093, -3.1264, -3.4380,  ..., -0.5564,  1.0829, -1.2718],\n",
            "        ...,\n",
            "        [ 0.8273, -0.6383, -3.2334,  ..., -3.2839,  1.2670, -1.0421],\n",
            "        [ 1.3404, -0.0374, -4.6178,  ..., -1.2406,  2.2119,  0.8915],\n",
            "        [ 2.1330, -1.4756, -3.9974,  ..., -0.1784, -0.9676, -1.5814]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1746, -0.0699, -4.1339,  ..., -0.4362,  1.1170, -1.8197],\n",
            "        [ 2.8033,  2.1005, -2.3719,  ..., -2.4464,  0.7367, -4.2836],\n",
            "        [ 4.3204,  1.7786, -2.9267,  ..., -1.1216,  1.3073, -1.5442],\n",
            "        ...,\n",
            "        [ 3.7353,  1.5675, -4.5451,  ..., -1.9254, -1.0751, -1.8453],\n",
            "        [-0.4064, -0.2686, -3.9088,  ...,  0.6759,  1.5464,  2.1967],\n",
            "        [ 1.4761, -2.5902, -4.2801,  ..., -0.4074,  3.4597,  1.6413]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1422, -0.3174, -6.0510,  ..., -4.2051,  2.4622,  0.0241],\n",
            "        [ 0.5026, -0.8506, -5.5483,  ..., -3.1844,  0.8564, -0.6495],\n",
            "        [ 1.1564,  0.0510, -3.7092,  ..., -1.1140,  2.2781,  0.4957],\n",
            "        ...,\n",
            "        [-0.2996, -0.4133, -2.8671,  ..., -1.4034,  0.2965, -1.0731],\n",
            "        [ 1.3532, -0.5020, -6.1811,  ..., -2.8166,  2.0341,  1.6750],\n",
            "        [-1.1720, -1.8221, -4.1439,  ..., -0.2401,  0.3754, -0.5799]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2422, -3.6934, -2.2526,  ..., -0.9191,  3.0695,  0.6732],\n",
            "        [-0.1973, -1.6752, -4.4739,  ..., -0.6709,  2.2470,  2.4591],\n",
            "        [ 0.7230, -0.7482, -6.1783,  ..., -3.0641,  1.4912,  0.9914],\n",
            "        ...,\n",
            "        [ 0.7915, -0.7976, -5.1563,  ..., -2.8835,  3.0223, -0.6510],\n",
            "        [ 5.0338, -2.7659, -5.9136,  ..., -0.3715, -3.6818, -4.0395],\n",
            "        [ 2.3797, -0.2269, -5.9830,  ..., -2.7262, -1.1711, -1.1212]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6637, -0.8723, -2.1217,  ..., -2.0663,  0.5358, -0.9659],\n",
            "        [ 1.5905, -2.0319, -4.6719,  ...,  0.1625, -0.8794,  1.7199],\n",
            "        [-0.6414, -2.0123, -4.5897,  ..., -0.8903,  3.2002,  2.8620],\n",
            "        ...,\n",
            "        [ 5.0178, -0.5383, -4.5077,  ...,  0.4650,  0.8490, -2.4490],\n",
            "        [ 5.1384,  0.9520, -6.1787,  ..., -1.6686,  2.4379, -1.8529],\n",
            "        [ 2.4151,  0.0329, -5.1673,  ..., -1.0730,  0.4378, -2.3714]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7147, -1.6331, -4.2560,  ..., -0.5321,  0.8714,  2.1991],\n",
            "        [ 1.8618, -3.8390, -6.0044,  ..., -0.5328,  3.4960,  1.3011],\n",
            "        [-1.5412,  0.4482, -2.7027,  ..., -1.3382,  0.3707,  1.8267],\n",
            "        ...,\n",
            "        [-0.2146, -0.7641, -3.1041,  ..., -0.9525,  3.0928,  2.0951],\n",
            "        [ 2.1091, -0.6978, -5.0450,  ..., -1.7074,  1.0988, -0.8168],\n",
            "        [ 0.5411, -3.3099, -3.6939,  ..., -2.9049,  1.4099,  1.3906]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3493, -0.5172, -3.2033,  ..., -1.5674,  1.1203, -0.2558],\n",
            "        [-0.4442, -2.1525, -4.0342,  ..., -1.0649,  4.4448,  2.3313],\n",
            "        [-1.5065, -0.8205, -2.3006,  ..., -0.4363,  0.6715, -1.4767],\n",
            "        ...,\n",
            "        [-0.3274,  1.0846, -1.4484,  ..., -0.0826, -0.3944, -1.5860],\n",
            "        [ 1.9897, -3.6514, -4.4966,  ..., -2.2077, -4.2165, -3.9476],\n",
            "        [ 0.6906, -0.6341, -2.3054,  ...,  0.0601,  2.3774,  0.3384]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8476,  3.7408, -3.9559,  ..., -0.1611,  0.6095, -0.1649],\n",
            "        [-0.8893, -2.3864, -4.1846,  ..., -2.2896,  2.6048,  1.3617],\n",
            "        [ 2.8581, -0.1878, -5.4496,  ..., -1.7870, -1.3249, -3.8597],\n",
            "        ...,\n",
            "        [-0.5629, -1.8619, -7.1756,  ..., -2.6162,  2.0824,  0.7158],\n",
            "        [ 1.6856, -3.9411, -5.0991,  ..., -2.7018,  4.0290,  2.2271],\n",
            "        [ 2.8421,  0.2461, -3.8116,  ..., -1.7625, -0.3903, -2.7094]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4937, -1.3646, -6.4026,  ..., -2.0319, -0.3542, -1.1589],\n",
            "        [ 2.1196, -1.6846, -4.6387,  ...,  0.8311, -3.1132,  0.0548],\n",
            "        [ 3.9706,  0.8417, -4.4582,  ..., -0.6867, -0.5071, -1.5529],\n",
            "        ...,\n",
            "        [ 2.4098, -1.7062, -5.4917,  ..., -2.3828, -1.5591, -2.8787],\n",
            "        [ 2.4538, -2.1539, -6.5163,  ..., -1.6106,  2.3647,  0.4574],\n",
            "        [-2.7635, -3.3528, -3.5410,  ..., -3.6732,  2.3588, -1.8482]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2438, -3.8746, -4.0178,  ..., -1.5057,  3.2669,  1.2566],\n",
            "        [ 4.4723, -3.8906, -4.4390,  ..., -0.1332, -0.2790, -4.0718],\n",
            "        [ 0.9229, -4.8838, -5.4807,  ..., -1.3069, -3.2732, -3.1991],\n",
            "        ...,\n",
            "        [ 2.3587, -3.2366, -4.5639,  ..., -2.4001,  1.6561,  0.4899],\n",
            "        [-0.7448, -1.9382, -5.3145,  ..., -3.3097,  2.2598,  0.8937],\n",
            "        [ 1.1123,  0.3028, -2.7338,  ...,  0.6412,  0.9471, -0.8722]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7718, -0.6597, -1.8761,  ..., -1.1606,  0.1433, -2.5365],\n",
            "        [ 0.0794, -2.4747, -5.1305,  ..., -1.3072,  1.7959,  1.2448],\n",
            "        [ 1.8115, -0.3212, -4.8487,  ..., -3.3031,  3.5694, -2.9400],\n",
            "        ...,\n",
            "        [ 1.4624, -2.8743, -3.9090,  ..., -1.6038,  1.0207, -1.2488],\n",
            "        [ 1.6533, -3.4616, -6.4079,  ..., -1.1324,  4.3249,  2.9996],\n",
            "        [ 1.2857,  0.1568, -2.2400,  ..., -1.8950,  2.0765, -1.7115]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4596, -3.3044, -6.5381,  ..., -1.4447,  0.9410,  3.3330],\n",
            "        [ 2.6063,  1.1422, -3.8623,  ..., -3.1094, -0.3933, -3.2630],\n",
            "        [ 0.5816, -3.0121, -4.3832,  ..., -3.0891,  1.9736, -1.4318],\n",
            "        ...,\n",
            "        [-1.3337, -2.6787, -6.0113,  ..., -4.7354,  1.2856, -0.8960],\n",
            "        [ 1.6322, -1.5569, -3.2753,  ..., -0.6292, -0.2322,  0.2525],\n",
            "        [-0.3028, -2.2240, -4.0975,  ..., -1.0365,  4.1555,  2.4843]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8167, -0.5798, -3.3721,  ..., -1.8140,  2.6942,  3.5614],\n",
            "        [-1.3548, -3.1606, -5.1841,  ..., -3.3294,  2.0858, -0.1341],\n",
            "        [ 0.3281, -1.1258, -3.2561,  ...,  0.7912,  2.1975,  0.4196],\n",
            "        ...,\n",
            "        [ 2.3913, -2.6895, -3.5116,  ..., -2.7301, -1.7952, -3.5998],\n",
            "        [ 0.6310, -0.7058, -5.2461,  ..., -1.1084,  5.4601,  1.5846],\n",
            "        [ 1.4169, -2.8703, -2.3879,  ..., -2.8008,  0.9586, -1.2089]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7391, -1.0860, -2.4604,  ..., -0.6613, -0.2902, -1.0531],\n",
            "        [ 3.7714,  1.2045, -4.5982,  ..., -0.1924, -1.1083, -3.5784],\n",
            "        [ 1.4738, -0.1738, -1.9251,  ..., -1.7557,  2.0605, -0.9480],\n",
            "        ...,\n",
            "        [ 5.5078, -0.4903, -4.5111,  ...,  0.0422, -2.9709, -1.7217],\n",
            "        [ 0.8819, -2.0267, -6.3482,  ..., -3.8709,  0.2116, -2.7644],\n",
            "        [ 1.6790, -4.4013, -4.8837,  ..., -2.4540, -1.1647, -2.3300]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6110, -3.9105, -4.9361,  ..., -2.3577,  2.3520,  0.0459],\n",
            "        [ 1.1251, -1.0238, -3.3875,  ..., -2.0484, -0.7236, -0.2467],\n",
            "        [ 1.0139,  0.3467, -4.0558,  ..., -1.8932,  0.8419, -0.3267],\n",
            "        ...,\n",
            "        [-0.0647,  1.0738, -3.8596,  ..., -3.1614,  0.2837, -1.7613],\n",
            "        [ 3.1368,  0.3925, -5.0452,  ..., -0.1971,  1.8998, -0.5571],\n",
            "        [ 0.8737, -2.7196, -5.9446,  ..., -3.3324,  1.7339, -1.3998]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2152, -3.7114, -4.9643,  ..., -3.2028, -0.2727,  0.9528],\n",
            "        [ 0.0636, -2.8855, -3.3394,  ..., -0.4267,  2.7030,  0.9404],\n",
            "        [ 3.3867,  2.7032, -4.0085,  ..., -1.7325, -1.0303, -1.7086],\n",
            "        ...,\n",
            "        [ 2.9324,  0.6368, -4.7108,  ..., -2.4262, -1.0859, -1.1206],\n",
            "        [ 1.4049, -4.1857, -5.5834,  ..., -2.3319,  2.8806,  1.9093],\n",
            "        [ 0.9401, -0.8618, -4.3550,  ..., -1.2394, -0.5500, -2.8537]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3691,  0.1935, -2.0024,  ..., -0.6401,  2.4202,  2.7633],\n",
            "        [ 3.3380, -1.6984, -4.5434,  ..., -0.7119,  1.7877, -1.1766],\n",
            "        [ 3.5228,  0.0137, -2.3803,  ..., -0.1088, -1.7792, -1.9713],\n",
            "        ...,\n",
            "        [ 1.5531, -3.3886, -4.4399,  ..., -1.9455,  1.5092,  3.7126],\n",
            "        [ 0.9711,  1.9665, -3.8432,  ..., -0.6554,  0.6403, -0.6568],\n",
            "        [ 1.7377,  0.6163, -2.7572,  ...,  0.4792,  2.2924,  0.9420]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6854, -2.3896, -3.9789,  ...,  2.5212, -4.0381,  1.1268],\n",
            "        [ 0.7443, -2.2281, -3.3588,  ..., -0.0852,  3.5146,  2.1509],\n",
            "        [ 3.3777, -0.3504, -5.4054,  ..., -1.1611, -1.5361, -1.7858],\n",
            "        ...,\n",
            "        [ 3.7341,  2.2508, -3.2471,  ..., -0.1681,  0.0965, -2.3190],\n",
            "        [ 0.2777, -4.0807, -6.0811,  ..., -5.2070,  1.2869, -1.6449],\n",
            "        [-0.2679, -3.3903, -3.9315,  ..., -1.2042,  3.4249,  1.7611]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8778,  3.8896, -2.8566,  ..., -0.2306,  0.3538,  0.1576],\n",
            "        [ 0.4479, -1.1060, -4.6014,  ..., -2.0102, -1.1315, -1.6630],\n",
            "        [ 1.5341, -2.5137, -6.6150,  ..., -0.8652,  3.8370,  3.2555],\n",
            "        ...,\n",
            "        [ 3.0307, -1.9071, -5.0648,  ..., -3.1391, -0.5126, -2.5189],\n",
            "        [-0.0325, -1.4537, -4.5400,  ..., -3.7233,  1.1122, -4.6237],\n",
            "        [ 1.6204, -2.5536, -4.5878,  ...,  0.0297,  3.7380,  2.6824]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4808, -1.5840, -4.0311,  ..., -0.6398,  0.3222, -2.2170],\n",
            "        [ 2.1363,  0.7631, -3.2216,  ..., -0.3453,  2.0022,  0.0211],\n",
            "        [ 0.3707, -3.0498, -5.0787,  ..., -0.5123,  4.5473,  3.6791],\n",
            "        ...,\n",
            "        [ 3.1227,  0.2671, -3.6976,  ..., -1.0692,  3.6110, -1.2422],\n",
            "        [ 0.0774, -2.0782, -3.6601,  ...,  1.1179, -1.6947,  0.9543],\n",
            "        [-0.5796, -1.7108, -4.4759,  ..., -1.9919, -0.0461,  0.9574]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2290, -2.4055, -5.6155,  ..., -3.6663, -0.7569, -1.8264],\n",
            "        [ 1.2631,  1.7507, -2.9440,  ..., -1.2966,  0.4730, -0.1569],\n",
            "        [ 1.1017, -0.1699, -3.8314,  ..., -0.9959,  0.8770, -1.4768],\n",
            "        ...,\n",
            "        [ 0.2448, -0.3738, -4.4715,  ...,  1.2339,  0.9150,  2.3786],\n",
            "        [-0.5387, -2.2019, -3.6596,  ..., -0.6385,  3.4166,  3.0434],\n",
            "        [ 1.3608, -2.9046, -7.0995,  ..., -1.7656,  0.4399, -0.7363]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4363,  0.3458, -4.5609,  ..., -1.0084,  0.3460, -1.5553],\n",
            "        [ 3.1068,  0.3865, -4.8026,  ..., -0.4310,  0.8888, -0.0388],\n",
            "        [ 1.3949, -2.6578, -5.2961,  ..., -0.5740,  3.4526,  1.7921],\n",
            "        ...,\n",
            "        [ 0.8747, -3.0547, -5.5018,  ..., -0.3666,  3.3327,  2.4417],\n",
            "        [ 3.7771, -0.0558, -3.7633,  ...,  0.4812,  1.6516, -1.3770],\n",
            "        [ 0.3121, -2.1169, -4.3234,  ..., -0.3047,  2.2666,  2.4583]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8478,  2.3581, -3.1950,  ...,  1.0982,  0.0760, -0.6274],\n",
            "        [ 3.4305,  0.6000, -3.9114,  ..., -0.9240, -1.2785,  0.6851],\n",
            "        [ 3.0136,  1.0409, -4.0047,  ..., -2.4039, -1.5092, -3.4962],\n",
            "        ...,\n",
            "        [ 1.4871, -3.1110, -5.2368,  ..., -0.3561,  2.6027,  1.9980],\n",
            "        [ 2.2684, -5.1516, -4.8466,  ...,  0.0880,  1.8291,  2.0733],\n",
            "        [ 1.9844,  2.7475, -3.6465,  ..., -0.3429,  0.7669, -0.5338]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1672, -0.1334, -3.2682,  ..., -0.9072,  1.9212,  3.3998],\n",
            "        [-1.6151, -3.0998, -7.0704,  ..., -1.2182, -0.1315,  0.1644],\n",
            "        [ 1.8144,  0.8581, -3.1425,  ...,  0.6272,  0.0541,  0.6517],\n",
            "        ...,\n",
            "        [ 1.7354, -2.5529, -4.5067,  ...,  2.4355, -3.2749,  0.6985],\n",
            "        [ 1.3618,  0.0235, -4.3346,  ..., -1.3739,  1.8547,  1.8147],\n",
            "        [ 3.0051, -0.6313, -3.8141,  ...,  0.4927,  1.7115,  0.4349]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6810, -3.4862, -3.7348,  ..., -0.7598,  4.6651,  3.8288],\n",
            "        [ 0.1319,  2.1598, -1.9808,  ..., -0.3933,  0.3749, -1.1225],\n",
            "        [ 0.6573, -2.5097, -3.3550,  ...,  0.1811,  2.3366, -0.6443],\n",
            "        ...,\n",
            "        [ 0.7148,  0.7032, -5.3969,  ..., -2.4487, -2.9325,  0.1664],\n",
            "        [ 1.4407,  1.1529, -3.4673,  ..., -0.4653,  1.0715,  1.1930],\n",
            "        [ 4.8724,  1.2554, -4.0967,  ...,  1.4201, -2.3961, -3.5923]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8896e+00, -1.1338e+00, -5.0464e+00,  ..., -2.3564e+00,\n",
            "         -1.7632e+00, -3.4411e+00],\n",
            "        [ 1.5987e+00, -1.4938e+00, -4.5396e+00,  ...,  1.2639e+00,\n",
            "          4.1146e-01,  1.7171e+00],\n",
            "        [ 2.8154e+00,  3.4877e+00, -2.8679e+00,  ..., -1.9868e+00,\n",
            "         -5.3594e-03, -2.7855e+00],\n",
            "        ...,\n",
            "        [ 1.1380e+00, -7.5226e-01, -4.2073e+00,  ...,  1.4997e+00,\n",
            "          2.8932e+00,  1.6966e+00],\n",
            "        [ 2.3352e+00,  7.3950e-01, -6.2800e+00,  ..., -1.0634e+00,\n",
            "         -5.7531e-01, -1.1077e+00],\n",
            "        [ 4.2085e+00, -2.1855e+00, -5.5096e+00,  ..., -2.7851e+00,\n",
            "         -3.5515e+00, -3.2405e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6071, -1.0194, -5.2454,  ..., -3.1190, -0.4317, -0.3421],\n",
            "        [ 2.4164, -0.2064, -5.0235,  ...,  0.0080, -0.4831,  1.4083],\n",
            "        [-1.0877, -2.0472, -3.8158,  ...,  0.6968, -1.9821,  2.6702],\n",
            "        ...,\n",
            "        [ 0.1932,  1.4357, -3.2674,  ..., -0.3997, -1.3431,  0.2333],\n",
            "        [ 5.1462,  1.9564, -4.2481,  ..., -0.6966, -1.2971, -1.6771],\n",
            "        [ 1.0626,  1.4160, -1.8959,  ...,  0.1376,  1.4633,  1.5669]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5639, -1.7632, -5.4075,  ..., -2.2976, -0.0910, -0.6442],\n",
            "        [ 1.9979, -4.1288, -5.4571,  ..., -1.8600,  3.1247,  2.2790],\n",
            "        [ 2.0612, -3.2299, -6.4251,  ..., -2.1879,  0.5282,  0.8473],\n",
            "        ...,\n",
            "        [ 4.6417, -0.1984, -2.7785,  ...,  0.3564,  0.5061, -1.8211],\n",
            "        [ 1.1789, -2.6824, -3.7544,  ..., -1.0998,  0.6504, -0.4005],\n",
            "        [ 2.3547, -2.1652, -5.0622,  ..., -1.4007, -1.6997, -3.1018]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3716,  0.9181, -3.3229,  ...,  0.2724, -1.8768, -3.1094],\n",
            "        [ 1.6402, -0.9771, -4.4595,  ..., -3.3123,  1.4996, -3.0080],\n",
            "        [ 2.8319,  3.5157, -3.6135,  ..., -1.5092,  0.3816, -0.9928],\n",
            "        ...,\n",
            "        [ 1.7149, -2.0525, -3.9948,  ..., -0.5149,  0.2187,  1.0661],\n",
            "        [ 2.8701, -4.5554, -5.4969,  ..., -1.8834,  2.0409, -1.1324],\n",
            "        [ 3.7993, -1.6349, -4.8153,  ..., -2.3734,  0.2992, -0.2488]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4962, -0.3687, -4.3062,  ..., -2.4546,  2.0892, -1.0917],\n",
            "        [ 2.6052, -1.0656, -5.5563,  ..., -1.0918,  0.5150,  0.0847],\n",
            "        [ 1.1293, -1.5866, -4.4837,  ..., -1.4665, -0.2874, -1.6915],\n",
            "        ...,\n",
            "        [ 1.3155,  2.3299, -3.1402,  ..., -1.9544,  1.2208, -0.7279],\n",
            "        [ 0.3633,  0.8099, -5.8446,  ..., -1.2575, -2.9533, -1.7432],\n",
            "        [-0.8929, -1.0416, -2.7456,  ..., -0.5187,  2.8883,  4.2491]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0399,  0.0078, -1.5725,  ..., -0.4650,  0.4030, -0.4118],\n",
            "        [ 2.6820, -1.1399, -3.4489,  ..., -1.2381,  0.3408, -1.3257],\n",
            "        [ 1.8259,  2.0915, -3.6968,  ..., -1.1116, -0.8800, -2.0006],\n",
            "        ...,\n",
            "        [ 4.6326, -0.8093, -3.5246,  ...,  0.6531, -2.7610, -0.7244],\n",
            "        [ 3.4173,  0.7801, -6.9949,  ..., -1.5289, -1.2159, -2.7761],\n",
            "        [ 0.0428, -1.4539, -4.7224,  ..., -1.7469,  1.2859,  0.0699]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3493, -0.3437, -3.8149,  ..., -2.0544,  0.1252, -0.4861],\n",
            "        [ 0.8086,  0.5267, -6.0919,  ..., -1.5925, -3.3705, -1.3207],\n",
            "        [ 1.9850,  3.3888, -3.0867,  ..., -0.9485, -0.7143, -1.3591],\n",
            "        ...,\n",
            "        [ 1.4691, -3.7924, -4.6236,  ..., -1.2954,  5.6259,  4.2566],\n",
            "        [ 2.4529, -1.5133, -4.4130,  ...,  0.9465, -0.7635,  1.2018],\n",
            "        [ 1.0122, -3.8829, -5.5736,  ..., -4.4279, -0.4077, -2.3591]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2076, -3.3726, -6.7636,  ..., -4.6691, -1.3478, -2.6613],\n",
            "        [-0.8276, -4.5583, -6.8122,  ..., -2.3921, -1.0518,  0.9191],\n",
            "        [ 5.4204,  1.9265, -4.9764,  ...,  0.2718, -0.4677, -1.8044],\n",
            "        ...,\n",
            "        [ 3.4822, -1.1338, -4.6495,  ..., -0.4681, -0.7329, -2.2993],\n",
            "        [ 3.2077, -1.3235, -4.0551,  ..., -2.8427, -0.1040,  0.3870],\n",
            "        [ 0.3312, -1.3233, -3.1697,  ..., -4.1088,  0.4138, -2.2840]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3829, -1.2638, -5.6241,  ..., -3.9610, -3.0324, -4.0329],\n",
            "        [-0.5886,  1.4397, -4.1548,  ..., -1.9786,  0.6689,  1.4046],\n",
            "        [ 1.0825,  1.5298, -4.2923,  ..., -2.4928,  0.2607, -1.8289],\n",
            "        ...,\n",
            "        [ 2.6765,  0.3349, -2.4133,  ...,  1.2654, -2.2751, -1.6441],\n",
            "        [ 0.4575,  0.8019, -2.5480,  ..., -1.2305,  1.6431,  2.2660],\n",
            "        [ 5.0476,  1.6554, -5.3303,  ..., -2.7212, -1.1831, -1.6011]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7221, -2.9183, -4.2283,  ..., -4.8691, -1.5082, -0.7489],\n",
            "        [ 1.1846, -3.1677, -4.8402,  ..., -2.8462, -0.3976,  0.4995],\n",
            "        [ 1.3954, -1.2455, -5.2549,  ..., -4.4394, -0.9814, -1.9116],\n",
            "        ...,\n",
            "        [ 0.9815, -1.3701, -3.8932,  ..., -2.3256,  3.2471, -0.4699],\n",
            "        [ 0.3263, -0.2870, -3.2928,  ..., -2.9113,  1.9199,  1.2233],\n",
            "        [-0.1264, -1.6078, -4.6889,  ..., -1.0974,  0.1698,  0.3696]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9429, -2.5760, -5.1764,  ..., -0.5959,  3.1552,  2.0540],\n",
            "        [ 2.7337,  2.1368, -2.8425,  ..., -3.9305,  0.2249, -2.1479],\n",
            "        [ 0.2469, -1.8867, -5.7782,  ..., -6.1935, -3.1352, -3.3001],\n",
            "        ...,\n",
            "        [ 1.0747,  0.6881, -3.9696,  ..., -0.1917, -1.9646, -0.8974],\n",
            "        [-0.4268, -1.5766, -3.7152,  ..., -1.2398,  2.8376,  2.9461],\n",
            "        [ 4.2412, -0.5741, -4.7821,  ..., -1.1015,  0.9128, -2.3182]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.2269,  0.2554, -5.4311,  ..., -1.4268, -0.7063, -1.5218],\n",
            "        [ 0.3023,  1.1540, -3.7309,  ..., -0.9177, -1.3686,  2.1376],\n",
            "        [ 1.0254,  2.3443, -4.9564,  ..., -3.4460,  0.4230, -0.5068],\n",
            "        ...,\n",
            "        [ 2.9131, -2.0587, -4.8877,  ..., -0.7701, -2.1961, -2.4373],\n",
            "        [ 0.3369,  0.3274, -4.8519,  ..., -1.6239,  1.3479, -1.3677],\n",
            "        [ 0.8734,  2.1606, -5.3232,  ..., -3.0000, -2.7081, -1.0153]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9000, -3.8735, -5.9718,  ..., -2.6685, -4.4014, -2.0433],\n",
            "        [ 2.8370,  1.5841, -4.9599,  ..., -2.4734,  1.5841, -1.2645],\n",
            "        [-0.1773, -2.7584, -4.9942,  ..., -0.6648,  1.7362,  2.1736],\n",
            "        ...,\n",
            "        [ 0.2458,  0.5528, -3.1422,  ..., -2.3770,  0.7159, -0.5807],\n",
            "        [ 0.5290, -1.5758, -6.4774,  ..., -5.6981, -2.0145, -3.8166],\n",
            "        [ 0.6634, -3.0399, -6.3026,  ..., -4.5600, -1.2919, -1.1765]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.2481, -0.1162, -4.1335,  ..., -1.1290,  2.8865, -0.8180],\n",
            "        [ 0.5507, -2.4689, -4.1486,  ..., -0.7469,  3.5059,  2.8856],\n",
            "        [-0.9062, -1.7457, -4.2218,  ..., -0.5925,  2.7484,  2.8616],\n",
            "        ...,\n",
            "        [-2.2221, -3.6311, -3.2177,  ..., -0.8618,  2.6396,  4.4080],\n",
            "        [ 2.9286,  2.7037, -4.5961,  ..., -1.4627,  0.3894,  0.4711],\n",
            "        [ 2.0006, -1.5068, -3.2090,  ..., -1.4091,  0.3357, -0.1821]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5459,  0.6988, -4.5443,  ..., -3.2674,  1.2583, -2.3418],\n",
            "        [ 1.8232, -1.8091, -5.0620,  ..., -1.1624, -1.9018, -2.5808],\n",
            "        [ 3.4508,  0.5346, -3.4294,  ..., -0.6498,  1.2386, -1.5120],\n",
            "        ...,\n",
            "        [ 2.5943, -2.1947, -5.4222,  ..., -0.8575,  3.2034,  1.5478],\n",
            "        [ 1.3488, -0.8328, -3.2579,  ..., -2.3060,  2.2010,  1.7470],\n",
            "        [ 1.7536, -2.7561, -3.8509,  ..., -2.7487,  2.3277,  0.6024]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0466, -0.3475, -2.3756,  ..., -1.7425,  1.9114, -0.8282],\n",
            "        [ 0.9223, -2.7953, -4.1830,  ..., -2.4508,  1.5204, -0.5433],\n",
            "        [ 0.2375, -0.7170, -4.9096,  ..., -1.6263, -0.9876, -1.0175],\n",
            "        ...,\n",
            "        [ 1.2759,  1.5881, -3.1510,  ..., -2.7804,  3.0752,  2.1600],\n",
            "        [ 3.7445, -2.7430, -7.0164,  ..., -3.3392,  0.2732, -0.1792],\n",
            "        [ 0.3205, -1.6762, -6.0199,  ..., -4.0525, -2.3676, -0.9215]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0793e+00,  3.1168e+00, -3.3760e+00,  ..., -1.9033e+00,\n",
            "         -7.9677e-01, -2.8165e+00],\n",
            "        [ 1.5457e+00, -4.1784e+00, -5.7843e+00,  ..., -2.5245e+00,\n",
            "          3.5454e+00,  2.3429e+00],\n",
            "        [ 5.9726e-01,  3.5490e-01, -7.2775e+00,  ..., -9.7607e-01,\n",
            "         -1.7439e+00,  2.3716e-01],\n",
            "        ...,\n",
            "        [ 7.5442e-01,  1.7821e-01, -5.9400e+00,  ..., -3.5499e+00,\n",
            "         -3.3021e+00, -4.2824e+00],\n",
            "        [ 5.3699e+00, -2.8845e+00, -3.8535e+00,  ..., -1.5771e+00,\n",
            "         -1.7283e-03, -5.9965e-01],\n",
            "        [ 3.5171e+00,  3.9410e+00, -4.1351e+00,  ..., -8.9486e-01,\n",
            "         -1.1835e+00, -1.4666e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0153,  1.4488, -3.7713,  ..., -2.1618,  1.9652,  1.5170],\n",
            "        [-0.8023, -1.5097, -1.2142,  ..., -0.2868,  2.7107,  3.6298],\n",
            "        [ 2.8836, -0.4805, -4.6099,  ..., -3.3917, -2.3990, -1.7639],\n",
            "        ...,\n",
            "        [ 6.9421,  1.6595, -3.7279,  ..., -0.5540, -1.1670, -1.0663],\n",
            "        [ 0.8459,  1.4779, -4.0991,  ...,  0.1208,  0.6759,  0.8454],\n",
            "        [ 1.0593, -1.3824, -7.2291,  ..., -2.0105,  0.9836,  1.7732]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0151, -1.4228, -5.2416,  ..., -0.3706,  2.1876,  2.7966],\n",
            "        [ 1.9299, -5.2642, -5.5457,  ..., -2.9692,  1.6096,  1.0947],\n",
            "        [ 2.7825,  3.5398, -3.5871,  ..., -1.1807,  0.3718, -1.2592],\n",
            "        ...,\n",
            "        [ 0.3175, -1.5390, -4.1114,  ..., -1.5355,  3.0346,  2.1017],\n",
            "        [ 1.0102,  0.9037, -2.0991,  ..., -1.6221, -1.3265, -0.1425],\n",
            "        [ 0.8252, -2.0894, -4.2811,  ..., -0.8467,  3.1712,  2.5946]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8173e+00, -3.3994e+00, -4.4359e+00,  ..., -2.6436e+00,\n",
            "         -4.4859e+00, -3.5455e+00],\n",
            "        [ 1.2902e+00, -1.7951e+00, -5.8655e+00,  ..., -3.5692e+00,\n",
            "          1.0298e+00,  5.2734e-02],\n",
            "        [-1.2257e+00, -2.6352e+00, -3.5851e+00,  ..., -2.7001e+00,\n",
            "          3.1288e+00,  3.2759e+00],\n",
            "        ...,\n",
            "        [ 2.1778e+00, -1.7399e+00, -4.0857e+00,  ..., -9.2658e-01,\n",
            "          1.7273e+00,  1.7087e+00],\n",
            "        [ 5.1212e+00, -2.6737e-01, -4.7059e+00,  ..., -1.3038e+00,\n",
            "         -2.5651e+00, -1.9800e+00],\n",
            "        [ 4.2553e-03,  8.8461e-01, -3.5522e+00,  ..., -2.0978e+00,\n",
            "          7.9078e-01,  7.9164e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4924, -2.5073, -3.6664,  ..., -0.6147, -4.9060, -2.5935],\n",
            "        [ 0.0625,  0.3646, -4.4754,  ..., -3.9426, -0.3645, -0.5161],\n",
            "        [ 2.2143, -0.2306, -6.4059,  ..., -0.6091,  1.5112,  0.3383],\n",
            "        ...,\n",
            "        [ 2.3564, -2.3494, -4.2405,  ...,  1.8693, -1.0941,  3.0031],\n",
            "        [ 0.2155, -0.9548, -4.3631,  ..., -2.6535, -0.6265, -3.0625],\n",
            "        [ 0.6594, -1.2351, -4.6190,  ...,  1.0106, -1.3755,  0.6240]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3956, -3.0034, -5.1685,  ..., -0.1942,  2.7900,  3.2936],\n",
            "        [ 1.6219,  3.6220, -3.6521,  ..., -3.3390,  0.4276,  0.8428],\n",
            "        [ 1.6838, -4.1087, -6.6000,  ..., -1.8034,  3.1141,  3.3924],\n",
            "        ...,\n",
            "        [-0.7654, -3.9744, -5.2643,  ..., -0.3269,  1.7777,  0.2380],\n",
            "        [ 3.3647,  3.2068, -2.8756,  ..., -1.5538,  0.9690, -0.9453],\n",
            "        [ 3.6011,  0.6658, -3.5021,  ..., -1.4224,  0.1430, -0.0846]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5941,  0.5849, -3.5051,  ..., -3.2889,  2.1162, -2.9865],\n",
            "        [ 4.7843, -0.4369, -7.4375,  ..., -4.6261,  0.2819,  0.0850],\n",
            "        [ 2.4898, -3.2070, -6.6056,  ..., -2.0770,  2.8848,  0.9450],\n",
            "        ...,\n",
            "        [ 1.5987, -0.2183, -4.9778,  ..., -1.2392,  2.1308,  0.9342],\n",
            "        [ 0.8368, -0.9769, -4.7531,  ...,  0.3856,  0.5762, -0.0787],\n",
            "        [ 1.3082, -1.0871, -3.4530,  ..., -2.0940,  0.3530, -0.3495]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4590,  1.9417, -5.2668,  ..., -0.7549, -0.3035,  0.2432],\n",
            "        [ 2.3953,  2.6199, -3.0546,  ..., -2.8804,  1.6464, -2.2253],\n",
            "        [ 1.4609,  0.4665, -4.2315,  ..., -3.6136,  1.7049, -0.5466],\n",
            "        ...,\n",
            "        [ 2.2185, -1.9268, -5.0035,  ..., -0.1301,  0.3221,  0.1708],\n",
            "        [ 0.4564,  1.5977, -2.3073,  ..., -1.9018,  0.7802, -1.3384],\n",
            "        [ 1.3087, -0.7014, -4.2433,  ..., -1.6561,  0.8593, -0.1157]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.7473, -2.3909, -3.7694,  ..., -3.2241, -1.5816, -3.4816],\n",
            "        [ 1.5452, -3.4590, -5.8196,  ..., -1.7640,  3.1199,  3.3409],\n",
            "        [ 1.9467,  0.3686, -4.8798,  ..., -3.8061,  1.4833, -2.2088],\n",
            "        ...,\n",
            "        [ 2.1402, -3.2937, -6.3397,  ..., -0.6635,  2.6273,  3.1169],\n",
            "        [ 1.6039, -0.6206, -3.4215,  ..., -0.1138,  3.6272,  3.6888],\n",
            "        [ 2.6750, -0.2290, -6.1508,  ..., -3.4099,  0.7585, -0.4337]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8684, -4.6470, -6.7199,  ..., -0.3330, -1.0168,  1.5646],\n",
            "        [ 1.6296, -0.3044, -3.2606,  ..., -2.2051,  2.5156, -2.2311],\n",
            "        [ 2.1145, -0.3003, -3.4907,  ..., -3.1087,  0.1054, -0.3826],\n",
            "        ...,\n",
            "        [ 1.8470,  0.0297, -3.5815,  ..., -2.0119,  2.2306,  1.6098],\n",
            "        [ 0.9403, -1.4083, -2.4876,  ..., -0.9363,  1.2390,  2.0285],\n",
            "        [ 0.6406, -3.3070, -4.1612,  ..., -2.7619,  3.0836,  1.6947]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9093, -1.2746, -5.3705,  ..., -3.1292,  1.5486,  1.4577],\n",
            "        [ 1.1849, -2.0926, -3.9238,  ..., -1.4217,  2.2563,  1.9200],\n",
            "        [ 2.0409, -2.1563, -3.7682,  ...,  0.6010, -1.7920,  1.9420],\n",
            "        ...,\n",
            "        [ 1.9348,  1.6308, -3.6637,  ..., -0.5519,  1.2264,  1.8451],\n",
            "        [ 1.9454, -2.6587, -3.3251,  ..., -1.9125,  0.3917,  0.1147],\n",
            "        [ 2.2562,  1.8896, -3.1583,  ..., -2.5567,  0.0108,  0.0085]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4493, -3.3130, -3.7257,  ..., -0.9067,  4.1475,  3.3874],\n",
            "        [-1.1855, -1.4577, -2.8959,  ..., -1.6854,  1.7171,  1.6325],\n",
            "        [ 2.3099, -1.4170, -4.6424,  ..., -1.3668,  0.4049,  1.4447],\n",
            "        ...,\n",
            "        [ 0.6640, -3.3686, -5.2824,  ..., -1.0494,  1.6811,  2.6941],\n",
            "        [-0.1015, -0.4930, -2.8009,  ..., -4.3877, -0.0747, -0.5303],\n",
            "        [-1.5444, -1.5218, -5.3069,  ..., -4.4701, -0.5548, -2.8644]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4344, -2.9339, -4.8938,  ..., -1.5561,  3.1628,  2.9495],\n",
            "        [ 0.6509,  0.4414, -2.3723,  ..., -1.4280,  0.2761, -2.0009],\n",
            "        [ 1.2105, -1.3834, -3.7711,  ..., -2.9014, -1.9977, -1.9752],\n",
            "        ...,\n",
            "        [ 1.3273,  1.7762, -4.4094,  ...,  0.7915,  0.0644, -0.6360],\n",
            "        [-0.3344, -3.2521, -2.9306,  ..., -0.9511,  1.5999,  1.3845],\n",
            "        [ 1.9333,  0.1012, -2.3434,  ...,  0.3318,  0.1444, -2.0275]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.6262,  1.0232, -4.0302,  ..., -1.7728,  2.1786, -0.3721],\n",
            "        [ 3.8158,  2.1594, -2.4889,  ..., -0.0673,  0.5258, -1.5802],\n",
            "        [ 0.0624, -0.2740, -3.8121,  ..., -1.6357,  3.6684,  3.3094],\n",
            "        ...,\n",
            "        [ 0.5700, -2.3282, -5.3093,  ..., -1.6990,  3.8715,  1.5410],\n",
            "        [ 5.0125,  3.0110, -3.7549,  ..., -0.1333, -1.4041, -0.8926],\n",
            "        [ 4.8907,  0.6011, -2.5444,  ...,  1.1126,  1.7541, -2.1988]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1874,  2.7578, -3.7330,  ..., -1.8285, -0.0411, -2.4484],\n",
            "        [ 0.5172, -1.4355, -2.6639,  ..., -1.7474,  2.1467,  3.1035],\n",
            "        [ 1.2481, -0.5477, -4.8781,  ..., -3.2757, -1.6559, -2.3537],\n",
            "        ...,\n",
            "        [ 3.6328,  0.5641, -4.9737,  ..., -2.8173, -1.2764, -0.6679],\n",
            "        [ 3.4825, -3.8639, -5.5872,  ..., -0.6945,  0.3588,  1.3254],\n",
            "        [ 1.0319, -1.2744, -4.6199,  ..., -2.6300, -3.0884, -3.6333]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4890,  1.2597, -4.4849,  ..., -3.8908,  1.6458, -0.4337],\n",
            "        [ 1.2977,  3.0141, -2.9699,  ..., -1.1883, -0.9918, -1.1683],\n",
            "        [ 0.4872,  1.2239, -3.1261,  ..., -1.6214,  0.8090, -1.1664],\n",
            "        ...,\n",
            "        [ 0.9889, -1.7514, -4.2965,  ..., -0.6361,  2.4008,  2.7844],\n",
            "        [ 1.8232, -3.5936, -4.3809,  ..., -0.3495,  0.7806,  1.5032],\n",
            "        [-1.5373,  0.3597, -3.9174,  ..., -1.8481,  2.0706, -0.2050]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8764, -0.0197, -6.5616,  ..., -4.0069, -0.0955, -1.0566],\n",
            "        [ 0.9310, -0.6069, -1.2306,  ..., -0.2099,  2.7323,  1.1809],\n",
            "        [ 2.4059, -3.9387, -6.5088,  ..., -3.2248, -1.2822,  0.1470],\n",
            "        ...,\n",
            "        [ 0.8129, -1.3951, -4.2976,  ..., -0.4360,  1.7573,  2.5764],\n",
            "        [ 5.5970,  0.2146, -5.1057,  ...,  0.2069, -0.7550, -1.1904],\n",
            "        [ 2.0984, -0.7080, -4.4594,  ...,  0.6125, -2.1032, -1.8187]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0697e+00,  1.0989e-01, -3.6869e+00,  ..., -2.2231e+00,\n",
            "          1.8820e+00, -5.2945e-01],\n",
            "        [ 2.6850e-01, -1.7447e+00, -5.9247e+00,  ..., -3.5978e+00,\n",
            "         -1.9748e+00, -1.2103e+00],\n",
            "        [ 1.3895e+00, -2.0111e+00, -6.1509e+00,  ..., -1.1781e+00,\n",
            "          8.4815e-01,  7.6658e-01],\n",
            "        ...,\n",
            "        [ 2.0503e+00,  2.0475e-05, -3.4840e+00,  ..., -1.2923e+00,\n",
            "          1.8020e+00,  2.9992e-01],\n",
            "        [ 5.5628e-01, -1.9416e+00, -3.6631e+00,  ..., -2.6971e+00,\n",
            "          1.5469e+00,  2.9801e+00],\n",
            "        [ 2.2725e+00, -1.2873e+00, -4.1753e+00,  ..., -1.2036e+00,\n",
            "         -2.9995e+00, -2.4917e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6459, -2.6208, -6.1790,  ..., -1.9542,  0.8498,  1.7256],\n",
            "        [ 3.4696,  1.2624, -2.1196,  ..., -0.3492,  0.0983, -2.5958],\n",
            "        [-0.9268, -2.3056, -3.8678,  ..., -0.6891,  2.6810,  3.0882],\n",
            "        ...,\n",
            "        [-1.2406, -1.7356, -1.7845,  ...,  0.6751,  2.6598,  2.8961],\n",
            "        [ 0.3155, -1.8862, -6.0851,  ..., -1.8692,  1.7367,  2.1073],\n",
            "        [ 2.1216,  1.8291, -4.5318,  ..., -1.1261,  0.7331, -1.2976]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5404, -2.1874, -5.6024,  ..., -2.0122,  0.8755,  1.5000],\n",
            "        [ 2.0177, -2.5918, -6.1400,  ..., -1.9118,  0.2293, -1.2370],\n",
            "        [ 0.4644,  1.2413, -3.6519,  ..., -0.6704, -0.0078, -2.6905],\n",
            "        ...,\n",
            "        [ 2.6467, -2.3752, -4.9700,  ..., -1.8634, -0.7602,  0.3815],\n",
            "        [ 0.3847, -0.7921, -4.0117,  ..., -1.7903,  2.7549,  1.5928],\n",
            "        [ 1.0714, -3.2514, -4.7735,  ..., -2.2662,  1.5548,  1.0959]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6107,  2.0101, -1.6446,  ...,  1.5742,  0.2972, -0.0377],\n",
            "        [ 3.2353,  2.7513, -3.7607,  ..., -3.0307, -0.2404, -2.9598],\n",
            "        [ 2.5536,  1.2061, -4.9699,  ..., -3.3772,  2.1122,  1.4596],\n",
            "        ...,\n",
            "        [ 2.4709, -1.5955, -4.6154,  ..., -0.2655, -2.1426,  1.7242],\n",
            "        [-0.9444, -3.7303, -3.4358,  ..., -1.9246,  4.1960,  3.6717],\n",
            "        [-1.0361, -3.5171, -5.8727,  ..., -2.3376,  2.0520,  1.1066]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9773, -2.8745, -3.6275,  ..., -1.3106,  2.9882,  1.2300],\n",
            "        [ 1.4930, -1.9689, -5.2325,  ..., -2.3550,  1.3728,  1.3344],\n",
            "        [ 3.0992, -0.8289, -4.5207,  ..., -3.1079,  1.3908, -0.1855],\n",
            "        ...,\n",
            "        [-0.7245, -1.7039, -4.4288,  ..., -1.7816,  2.3301,  1.6299],\n",
            "        [ 1.0423, -3.1612, -5.3616,  ...,  0.1183,  2.6545,  2.3995],\n",
            "        [-0.1114,  2.5789, -2.5531,  ..., -0.3380, -0.6582, -2.0994]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9305, -3.8821, -3.1254,  ..., -0.6616,  2.4001, -3.0906],\n",
            "        [ 0.2895, -1.1498, -5.6322,  ..., -3.6384, -2.4231, -3.8812],\n",
            "        [ 1.2625, -0.3880, -3.8655,  ...,  0.6223, -1.0620, -1.5091],\n",
            "        ...,\n",
            "        [-0.3630,  1.9443, -3.1623,  ..., -1.8369,  0.1954, -3.2342],\n",
            "        [-0.4075, -1.7194, -7.2953,  ..., -2.8459, -1.1042, -1.7251],\n",
            "        [ 0.9878,  3.0171, -4.6967,  ...,  0.3456,  0.6301, -0.7672]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1904, -3.7908, -3.9227,  ..., -2.1669,  2.5513,  1.0736],\n",
            "        [-0.1961, -2.5502, -6.1151,  ..., -3.0258,  3.0338,  4.4379],\n",
            "        [ 0.7660, -2.3863, -4.8650,  ..., -2.4583, -0.0947, -1.8268],\n",
            "        ...,\n",
            "        [ 0.0113, -0.2189, -3.2621,  ...,  0.0925,  2.5443,  0.0204],\n",
            "        [ 0.0998, -1.1038, -4.9749,  ..., -3.2979, -0.8478, -2.4249],\n",
            "        [ 0.7891,  0.4099, -3.0821,  ..., -0.3143, -0.2836, -1.4210]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5236,  4.4899, -3.6649,  ...,  1.1041, -0.9832, -1.7700],\n",
            "        [ 1.5082, -0.9751, -5.6017,  ..., -3.9764,  1.9776,  1.4037],\n",
            "        [ 3.4350,  0.1634, -6.2372,  ..., -2.1738, -1.9714, -3.7164],\n",
            "        ...,\n",
            "        [ 1.9212, -0.3911, -2.3823,  ...,  0.9237,  1.7874, -1.1682],\n",
            "        [-0.9566, -1.2923, -5.0392,  ..., -0.0155,  3.0405,  3.3004],\n",
            "        [ 2.0805,  0.6718, -4.9730,  ..., -2.5058,  1.6554,  1.3866]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0955,  0.9807, -2.1561,  ..., -0.9998,  2.1719,  1.2101],\n",
            "        [ 4.0273, -0.6637, -4.2918,  ...,  0.3831, -5.5179, -3.6884],\n",
            "        [ 3.9549,  3.2829, -2.0793,  ...,  1.5509, -0.2361, -2.2326],\n",
            "        ...,\n",
            "        [ 2.4835,  2.9751, -4.6578,  ..., -2.2776, -0.4403, -2.7372],\n",
            "        [ 2.8323, -5.1514, -3.3224,  ..., -1.5905, -0.9226, -1.0496],\n",
            "        [-0.1048, -2.2954, -2.2939,  ...,  0.1004,  1.8668,  0.9654]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3722,  3.9991, -5.4870,  ...,  1.1814, -0.6822, -2.1672],\n",
            "        [ 1.0883,  0.8059, -4.1380,  ...,  1.0715, -3.1918,  2.5055],\n",
            "        [ 0.6565,  0.2458, -2.5238,  ..., -3.0292,  0.0769, -0.6418],\n",
            "        ...,\n",
            "        [-0.2113,  3.1483, -1.3813,  ..., -0.9549, -0.0616, -0.3632],\n",
            "        [-0.3185,  0.7440, -2.7638,  ...,  0.9436,  0.5494,  1.0697],\n",
            "        [ 5.5781,  1.1078, -3.8331,  ..., -1.5949,  2.8505, -0.5494]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8105,  2.7871, -2.7407,  ..., -1.1216, -0.0092, -1.7695],\n",
            "        [ 1.2653, -1.3603, -4.4924,  ..., -3.0090,  1.8670,  3.0852],\n",
            "        [-0.5369, -3.2433, -4.5178,  ..., -0.8962, -3.7743,  0.0851],\n",
            "        ...,\n",
            "        [ 0.2489,  1.8616, -2.0517,  ..., -1.3982,  2.2144,  0.9593],\n",
            "        [ 3.9856, -1.6077, -5.6239,  ..., -0.1036,  2.4345,  0.6890],\n",
            "        [ 2.4169, -2.7962, -3.7814,  ..., -0.5146,  0.8337,  0.5986]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4066, -2.6990, -5.2299,  ..., -0.0164,  3.4400,  3.2687],\n",
            "        [ 1.8130, -5.2189, -6.4048,  ..., -1.0235,  2.7569,  2.8550],\n",
            "        [ 2.6009,  2.8501, -3.9232,  ...,  1.0745,  0.9758,  0.1865],\n",
            "        ...,\n",
            "        [ 0.2955,  0.3208, -4.1756,  ..., -0.3059,  1.1251,  1.9622],\n",
            "        [ 0.1999, -2.1377, -6.3410,  ..., -4.3280, -1.8459, -3.1394],\n",
            "        [-0.0590, -1.1278, -3.3783,  ..., -2.2482, -0.6609, -3.2010]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7540e+00,  2.4873e+00, -3.3323e+00,  ...,  6.3554e-01,\n",
            "         -4.2731e-01, -3.6751e+00],\n",
            "        [ 5.7491e+00,  1.5294e-03, -4.9472e+00,  ..., -1.2653e+00,\n",
            "         -1.9566e+00, -2.8714e+00],\n",
            "        [ 2.6063e+00, -3.4247e+00, -4.3670e+00,  ..., -1.8180e+00,\n",
            "          1.9108e+00,  3.4185e+00],\n",
            "        ...,\n",
            "        [ 1.1155e+00, -2.6344e-01, -2.6640e+00,  ...,  6.4245e-01,\n",
            "          1.1315e+00, -1.1088e+00],\n",
            "        [-4.8016e-01,  3.4611e-01, -3.7151e+00,  ...,  1.1542e+00,\n",
            "         -5.4399e-01,  2.6216e+00],\n",
            "        [ 1.3232e+00, -1.1182e+00, -3.9223e+00,  ..., -1.2354e+00,\n",
            "          1.6272e+00,  3.0536e-02]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1536, -0.7572, -3.3780,  ...,  0.9158, -2.1091,  3.1803],\n",
            "        [ 0.4957, -1.8265, -4.9832,  ..., -3.7031,  2.8819, -0.8462],\n",
            "        [ 2.1480, -1.1459, -5.8803,  ..., -4.0377,  3.2803, -0.4705],\n",
            "        ...,\n",
            "        [-0.3946, -3.2736, -6.8510,  ..., -4.4940,  1.8151, -1.8294],\n",
            "        [ 1.1766,  1.1385, -2.9169,  ..., -1.6372,  1.2770, -2.5003],\n",
            "        [-0.3957, -0.7722, -1.7480,  ..., -0.2188,  0.8661,  2.0975]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.1137, -1.5187, -3.9539,  ...,  1.3255, -3.8973, -4.7401],\n",
            "        [-0.1111, -1.7165, -4.2680,  ..., -2.5298,  2.9454, -0.2517],\n",
            "        [-0.2686, -1.1797, -1.8266,  ...,  1.1091, -0.7484,  4.1464],\n",
            "        ...,\n",
            "        [ 3.4644,  0.0555, -7.4576,  ..., -2.6389,  1.0828, -1.7221],\n",
            "        [-0.0430, -0.8594, -2.2463,  ...,  0.2982, -0.1060,  3.0698],\n",
            "        [-0.4737, -0.3991, -4.6745,  ..., -2.3645,  2.2439,  2.1158]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.9097,  2.8516, -4.6299,  ..., -1.4688,  0.1849, -3.3522],\n",
            "        [-1.5973, -4.4247, -4.8386,  ..., -5.2903,  1.0053, -1.7445],\n",
            "        [-0.3370, -2.0281, -3.4350,  ..., -2.2625,  3.1393,  4.9426],\n",
            "        ...,\n",
            "        [ 0.7295, -2.3424, -4.9905,  ..., -2.0999, -1.0483, -0.8903],\n",
            "        [ 0.8604, -3.4259, -5.7249,  ..., -3.2608,  1.4707, -2.5666],\n",
            "        [-0.5308, -1.7943, -1.5700,  ..., -0.9127,  1.8751, -0.1393]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2457, -1.4157, -3.6524,  ...,  0.7026,  1.6921,  1.5102],\n",
            "        [ 3.9318, -2.4420, -6.0957,  ..., -0.2956,  3.1847,  0.8923],\n",
            "        [ 0.4169, -0.8478, -2.1010,  ...,  0.8039,  1.5462,  1.8071],\n",
            "        ...,\n",
            "        [ 3.8108,  0.9610, -6.2618,  ..., -1.2319, -1.2409, -2.6834],\n",
            "        [ 4.9230, -0.5761, -3.7976,  ...,  2.3521,  0.6323, -2.4045],\n",
            "        [ 1.5274, -2.0750, -4.5388,  ...,  0.7700,  2.7642,  1.5989]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.4901, -1.5312, -5.4153,  ..., -1.7322, -1.1995, -4.2717],\n",
            "        [ 1.4262, -1.3691, -3.7037,  ..., -0.8390,  2.8714,  2.2907],\n",
            "        [ 4.4489,  2.6030, -4.7341,  ..., -0.0679, -1.3029, -2.3879],\n",
            "        ...,\n",
            "        [ 3.1037, -0.6966, -4.9772,  ..., -1.4933, -1.1639,  0.3669],\n",
            "        [ 1.6324, -4.1833, -6.0064,  ..., -0.6062,  3.3051,  3.0487],\n",
            "        [ 1.5822, -0.9898, -2.3120,  ..., -1.0577,  3.1954,  2.0510]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.4024,  2.2869, -4.9853,  ..., -0.6107, -1.7949, -1.7750],\n",
            "        [ 3.7882, -0.5575, -6.4906,  ..., -0.9205, -4.2678, -5.4693],\n",
            "        [ 3.4348, -0.0235, -5.5406,  ..., -2.3828, -1.0131, -1.9944],\n",
            "        ...,\n",
            "        [ 2.0742, -2.6283, -3.5617,  ..., -2.5130,  1.2075, -0.4724],\n",
            "        [ 0.5455, -2.3372, -5.1959,  ..., -0.7267,  1.1137,  2.8127],\n",
            "        [ 3.0960,  2.0994, -3.1685,  ...,  0.3330, -0.5018, -2.2834]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4529, -2.7940, -4.9843,  ...,  0.9533,  2.9871,  2.2242],\n",
            "        [ 5.1523, -0.4596, -4.4725,  ..., -0.0450, -3.3901, -2.9735],\n",
            "        [-0.7952, -1.3862, -4.2993,  ..., -2.9073,  1.2301,  3.9879],\n",
            "        ...,\n",
            "        [ 0.6047, -2.1100, -2.6838,  ...,  2.0088, -2.5577, -0.1513],\n",
            "        [-0.5717, -2.0782, -3.6910,  ..., -0.3079,  2.8564,  1.9295],\n",
            "        [-2.5275, -1.7809, -2.0008,  ..., -0.7823,  3.1167,  1.2094]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4025, -4.5332, -3.3330,  ..., -1.2624, -0.0070,  0.7790],\n",
            "        [ 0.9448,  1.0383, -3.7867,  ...,  0.1197,  1.3903,  1.2998],\n",
            "        [ 1.5512, -1.4091, -6.6392,  ..., -2.2831, -1.4992, -2.4883],\n",
            "        ...,\n",
            "        [ 2.0432, -0.8093, -4.5587,  ...,  1.0937,  0.3315,  0.9330],\n",
            "        [ 0.8080, -1.2557, -3.0303,  ..., -1.5502,  2.0544,  2.1295],\n",
            "        [ 1.8479, -2.2229, -5.0528,  ..., -0.8405, -4.4671, -1.9262]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3248, -2.5373, -4.5556,  ..., -2.5698,  1.8583,  3.0738],\n",
            "        [ 0.7436,  0.2401, -4.9308,  ..., -5.5602, -1.3791, -1.8964],\n",
            "        [ 2.9725, -1.9973, -4.7241,  ..., -1.5620, -0.9013, -0.3058],\n",
            "        ...,\n",
            "        [ 0.9613, -5.6103, -3.9411,  ..., -1.3119,  2.1645,  1.4321],\n",
            "        [ 3.1732, -1.7199, -5.7418,  ..., -1.0211, -1.7093, -0.6840],\n",
            "        [ 2.4525,  0.1677, -4.1315,  ...,  0.5097,  0.8974, -1.6987]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9282, -3.2887, -6.9702,  ..., -1.1027,  2.1805,  3.5772],\n",
            "        [ 2.5345, -2.8594, -5.6965,  ..., -1.6665,  0.6337,  1.4879],\n",
            "        [ 1.1518,  0.2185, -5.6412,  ..., -2.4458, -0.1774,  0.9523],\n",
            "        ...,\n",
            "        [ 3.6449, -0.8256, -4.0205,  ..., -0.3665,  3.5973, -0.5122],\n",
            "        [ 1.5075, -2.5144, -5.2781,  ...,  0.6337,  2.3332,  2.6174],\n",
            "        [ 3.2641,  0.5589, -4.2524,  ..., -0.9916, -1.4806, -2.5307]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8808, -1.5884, -4.6277,  ..., -1.1174,  0.7098, -0.1231],\n",
            "        [ 2.8819,  1.6404, -3.6871,  ...,  2.6748,  0.3128, -1.3549],\n",
            "        [-0.4775,  0.2570, -2.6426,  ...,  0.0220,  0.9348,  0.1134],\n",
            "        ...,\n",
            "        [ 1.7912, -2.6223, -4.1925,  ...,  1.6099, -0.2352,  0.6522],\n",
            "        [ 3.2989,  2.6364, -2.5293,  ..., -3.2536,  0.3896, -1.4130],\n",
            "        [ 3.2776, -0.3362, -4.3109,  ...,  0.3099,  0.3874, -1.4055]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0967,  0.4563, -4.4081,  ..., -0.7615,  0.5830, -0.7495],\n",
            "        [ 6.9186,  2.3945, -4.9610,  ...,  1.2367, -2.4392, -1.9316],\n",
            "        [ 3.2781, -2.2950, -5.3116,  ..., -0.7974, -0.2819,  0.1785],\n",
            "        ...,\n",
            "        [ 0.2588, -0.0253, -4.6027,  ..., -0.3118, -0.9825,  0.0661],\n",
            "        [ 1.5542, -0.4408, -5.8229,  ..., -2.5580, -2.0654, -1.8243],\n",
            "        [ 2.1089,  0.2150, -5.6949,  ..., -0.4957, -0.4334, -0.7646]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7570, -0.6940, -4.0028,  ...,  0.4086,  1.1414,  3.3644],\n",
            "        [ 1.6377, -0.2985, -6.3424,  ..., -1.3868,  1.9244,  2.1017],\n",
            "        [ 0.2110, -1.2209, -4.5578,  ...,  1.4096, -1.5875,  2.2681],\n",
            "        ...,\n",
            "        [ 0.0914, -1.2596, -2.7841,  ...,  2.4121, -1.8617,  4.0779],\n",
            "        [ 2.8084,  1.3003, -2.7947,  ..., -0.5848,  2.4392,  1.3041],\n",
            "        [ 4.7797,  0.8033, -2.3855,  ...,  0.5041, -3.0692, -1.0388]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7685,  1.6422, -2.9517,  ...,  0.3760,  0.2658, -1.1531],\n",
            "        [ 1.8835, -0.5125, -4.5953,  ..., -2.3062,  0.8035, -1.1547],\n",
            "        [ 0.7134, -2.4647, -3.3610,  ..., -1.2456, -1.4070, -0.2709],\n",
            "        ...,\n",
            "        [ 3.4030, -1.5765, -4.2550,  ...,  0.8496,  1.1054,  0.6279],\n",
            "        [ 3.7472,  1.0176, -3.7128,  ..., -1.3625,  0.3614, -2.4792],\n",
            "        [ 5.2651,  1.6200, -3.5935,  ...,  3.6341, -0.2175, -0.7165]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2952, -1.4003, -2.4988,  ..., -1.8125,  0.3783,  1.7000],\n",
            "        [ 1.9828, -1.0143, -3.9962,  ..., -1.0468,  1.4820, -0.2738],\n",
            "        [-1.0030, -2.4910, -3.0418,  ..., -0.4307,  2.5107,  2.8994],\n",
            "        ...,\n",
            "        [ 3.1936, -2.1526, -4.6873,  ...,  0.4242,  2.4780,  2.4894],\n",
            "        [ 2.2604, -2.0520, -5.4201,  ..., -0.2681,  2.0512,  3.0771],\n",
            "        [ 3.3610, -3.4995, -4.1086,  ..., -0.7623, -2.1012, -1.1154]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5376, -4.6397, -4.1156,  ..., -0.6740,  1.4704,  0.4729],\n",
            "        [ 1.3312, -0.6022, -7.1579,  ..., -2.4800,  0.9376,  2.7787],\n",
            "        [ 2.8272, -1.6016, -6.0619,  ..., -1.7227,  2.0276,  0.5114],\n",
            "        ...,\n",
            "        [ 1.1262, -4.6383, -4.6619,  ..., -0.2948,  1.2336,  2.2072],\n",
            "        [-0.4489, -2.4028, -5.0570,  ..., -4.5132,  2.3164,  2.9311],\n",
            "        [ 2.5799, -2.6154, -2.1070,  ...,  1.1078, -4.6109,  1.2310]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5770,  2.6319, -2.7797,  ..., -1.2817,  0.7509, -0.9849],\n",
            "        [-0.6665, -2.2177, -3.8399,  ...,  0.6733,  0.5310,  2.4414],\n",
            "        [ 2.5013,  0.2690, -3.5185,  ..., -2.1603,  0.3724, -1.1427],\n",
            "        ...,\n",
            "        [ 2.2404, -3.4885, -4.2123,  ..., -1.1820,  0.1455,  1.5016],\n",
            "        [ 1.8550, -0.5016, -5.3944,  ..., -2.6801, -3.7729, -0.7742],\n",
            "        [ 2.3625, -3.7938, -5.0153,  ..., -2.2116, -0.2209,  3.0245]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.6945, -3.8195, -5.8522,  ..., -2.1370, -2.4511, -3.6921],\n",
            "        [ 3.8376,  0.7812, -4.0353,  ...,  0.5606, -2.9384, -0.8615],\n",
            "        [-0.2862, -1.3396, -5.7800,  ..., -0.8701,  0.9233, -0.4512],\n",
            "        ...,\n",
            "        [ 2.0004,  1.5891, -5.5801,  ...,  0.0737,  0.1329, -0.0811],\n",
            "        [-0.2662, -5.4156, -2.1350,  ...,  0.4074,  5.1207,  5.9095],\n",
            "        [ 0.1509, -5.5765, -7.6773,  ..., -5.6856, -3.6459, -1.4101]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0562, -3.5923, -5.5539,  ..., -0.5423,  2.6753,  3.1639],\n",
            "        [ 1.5272, -2.1690, -5.7587,  ..., -1.3627,  3.3917,  0.8051],\n",
            "        [-0.4548, -1.7551, -4.4115,  ..., -2.2381,  0.7620,  2.8567],\n",
            "        ...,\n",
            "        [ 1.2970,  1.0689, -4.4504,  ..., -0.4018, -1.1857,  0.7643],\n",
            "        [ 5.8884, -2.0186, -5.5737,  ..., -3.0132, -2.2572, -1.1217],\n",
            "        [ 1.7367, -3.1419, -7.2533,  ...,  0.7877,  2.3396,  2.9778]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7511, -3.3211, -4.7462,  ..., -1.6774, -0.8489,  3.0703],\n",
            "        [ 3.9989, -1.0612, -5.1638,  ..., -1.9749,  1.7404, -1.0193],\n",
            "        [-1.1054, -0.7007, -2.5827,  ...,  0.0277,  1.2979,  3.7352],\n",
            "        ...,\n",
            "        [ 0.0794, -0.9450, -5.7952,  ..., -1.1047,  0.1780,  0.5467],\n",
            "        [ 2.0056, -2.2333, -2.7615,  ...,  1.8002, -3.4003,  3.5150],\n",
            "        [ 3.2804, -4.4149, -2.7334,  ..., -0.8674,  0.0364, -0.7926]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8832, -1.3735, -3.4082,  ...,  1.9422, -3.5437,  2.4263],\n",
            "        [ 2.1623, -0.5243, -4.8373,  ...,  0.3757,  0.7809,  2.6192],\n",
            "        [-1.6622, -5.3397, -6.2481,  ..., -2.2483, -1.9053,  0.3332],\n",
            "        ...,\n",
            "        [ 1.7060, -2.2281, -5.6583,  ...,  0.7723, -0.3484,  0.8521],\n",
            "        [ 3.4035,  2.6848, -5.2370,  ...,  1.4654, -0.0207,  1.1720],\n",
            "        [ 3.7768, -3.8539, -6.5127,  ..., -2.5408,  0.6174, -0.8845]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8628,  1.2971, -4.1935,  ...,  0.0603, -0.0097,  2.0910],\n",
            "        [ 1.5714, -0.9419, -3.1925,  ..., -1.8291,  1.1249,  1.0340],\n",
            "        [-1.9300, -3.2261, -1.9074,  ..., -0.0055,  1.9665,  3.0228],\n",
            "        ...,\n",
            "        [-0.2364, -2.0305, -3.6165,  ..., -0.2029,  2.2085,  3.2436],\n",
            "        [ 1.9342, -4.2034, -1.7544,  ...,  1.4950, -1.4691,  1.9885],\n",
            "        [ 0.7538, -1.3081, -4.2604,  ..., -0.9168, -0.2439,  2.1218]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2346, -1.7935, -5.2057,  ..., -3.0591, -1.7574, -0.0189],\n",
            "        [ 0.9562, -0.1897, -4.5045,  ..., -0.0088, -1.1784,  1.6250],\n",
            "        [ 3.4172,  0.3599, -5.3979,  ...,  1.9796,  2.7803,  1.1594],\n",
            "        ...,\n",
            "        [-1.1252,  0.4849, -1.8194,  ..., -2.9865,  0.7798, -0.2193],\n",
            "        [ 0.8314, -0.9875, -5.3029,  ..., -2.3891,  0.3575, -0.1964],\n",
            "        [ 5.7391,  0.5496, -6.7329,  ..., -0.7368, -1.8569, -1.7457]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3705, -2.1329, -4.6133,  ..., -3.1143, -1.3116, -3.3194],\n",
            "        [ 2.1509,  1.1572, -4.3669,  ...,  2.0742,  0.8675,  0.2343],\n",
            "        [-1.4467, -0.8766, -3.5814,  ...,  0.1846,  1.6564,  3.2483],\n",
            "        ...,\n",
            "        [ 3.0801,  0.7469, -5.6660,  ...,  0.9712,  0.3595, -0.1780],\n",
            "        [ 0.7413, -0.3576, -3.7126,  ..., -3.1900,  1.2445,  1.9306],\n",
            "        [ 2.1750, -3.8432, -3.8434,  ..., -0.3600,  0.6650,  1.9660]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4798,  0.0317, -4.2688,  ...,  1.1490,  2.1197, -1.3460],\n",
            "        [ 6.5298, -0.3576, -4.2495,  ...,  1.3164, -0.0839, -0.5035],\n",
            "        [ 4.0477,  0.7149, -3.3339,  ..., -0.1458, -2.7732, -0.8212],\n",
            "        ...,\n",
            "        [ 7.7648, -0.7525, -6.1464,  ..., -2.0904, -3.1139, -1.3923],\n",
            "        [-0.6354, -3.1319, -3.6757,  ..., -2.2406,  2.7918,  4.0459],\n",
            "        [ 2.6901, -4.6923, -4.7882,  ..., -2.0796,  0.9977,  2.2337]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1986, -1.1503, -3.6935,  ..., -3.1299, -1.7253, -0.6091],\n",
            "        [ 0.3752,  0.3312, -4.1287,  ..., -3.3401, -1.1531, -1.1107],\n",
            "        [ 0.9602, -0.6109, -4.9170,  ..., -3.0402,  0.4075,  2.7090],\n",
            "        ...,\n",
            "        [ 3.1255,  2.9821, -3.9906,  ..., -0.4753, -0.2953, -1.1242],\n",
            "        [ 1.4877, -3.6377, -4.7357,  ...,  0.4585,  3.0398,  2.1902],\n",
            "        [-2.2444, -1.1756, -3.5219,  ..., -0.4463,  1.0969,  3.1226]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2642, -3.0227, -5.0593,  ..., -3.2041,  1.3319, -0.3060],\n",
            "        [ 1.7859,  1.2038, -4.8989,  ...,  0.7855, -0.8715,  0.2759],\n",
            "        [-0.2751, -1.1970, -2.8984,  ...,  1.5804,  0.4246,  2.8180],\n",
            "        ...,\n",
            "        [ 3.6627, -1.6581, -3.3869,  ...,  0.2181, -4.7329, -2.3704],\n",
            "        [ 2.7618,  2.4555, -2.1707,  ..., -0.9265,  0.8269, -1.6576],\n",
            "        [ 1.6125,  0.2835, -5.1744,  ...,  0.0428, -1.0856, -0.5087]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1578,  1.3489, -5.3100,  ..., -1.8186,  0.1821,  1.9641],\n",
            "        [ 0.2636, -2.0239, -3.8631,  ...,  0.2238,  1.8087,  2.9569],\n",
            "        [ 0.5216,  1.4205, -2.0127,  ..., -0.3299,  0.2084,  3.1552],\n",
            "        ...,\n",
            "        [ 4.5980,  0.1255, -4.7617,  ..., -2.0132, -4.0193, -1.3396],\n",
            "        [ 0.7088, -3.0135, -5.5559,  ..., -5.0284, -2.5079, -0.4421],\n",
            "        [ 4.4009, -0.5035, -7.2287,  ..., -2.3044, -1.4925, -2.6678]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4465, -0.3856, -4.8561,  ..., -2.7672,  0.8930,  2.0207],\n",
            "        [ 2.2407,  0.6001, -3.2821,  ..., -1.1320, -3.0027, -0.7384],\n",
            "        [ 3.1954, -0.6367, -4.5756,  ...,  1.8177,  1.9410,  2.5981],\n",
            "        ...,\n",
            "        [-0.5579, -3.9278, -7.2597,  ..., -1.6145,  1.0886,  3.7381],\n",
            "        [-2.3004, -2.5406, -4.1479,  ..., -1.6819,  0.0201,  0.8251],\n",
            "        [ 1.6315,  0.4647, -5.1158,  ..., -1.1402, -0.6384,  1.4266]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0597, -0.7680, -3.6560,  ..., -2.1285,  1.1571, -0.4862],\n",
            "        [ 2.3589,  1.2087, -4.7293,  ...,  1.6127,  0.3969, -0.8437],\n",
            "        [-1.1566, -1.2564, -6.2080,  ..., -4.7906, -1.9647, -3.5602],\n",
            "        ...,\n",
            "        [ 0.9169, -3.9054, -5.9521,  ..., -0.7842, -1.3776,  5.0555],\n",
            "        [ 1.5216, -3.3113, -6.9450,  ..., -4.8337, -4.3034, -2.7347],\n",
            "        [-3.1125, -2.4386, -3.2896,  ..., -2.3908,  2.2604, -0.3768]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1081, -2.0438, -4.7261,  ..., -1.9349,  0.9398,  1.5298],\n",
            "        [ 0.7939, -2.9355, -3.4091,  ..., -3.9809,  2.0868,  2.0101],\n",
            "        [ 2.0586, -0.9211, -4.4729,  ...,  1.2871, -0.8455,  0.9110],\n",
            "        ...,\n",
            "        [-1.1076, -1.0787, -5.4244,  ..., -1.6026, -0.4736,  3.1668],\n",
            "        [ 1.7297, -5.9636, -8.3904,  ..., -2.4892, -0.8045,  2.5743],\n",
            "        [-0.1381,  0.9673, -3.9389,  ..., -3.3716, -0.0783, -0.3234]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7251e-01, -5.1378e-03, -4.0271e+00,  ..., -2.9456e+00,\n",
            "         -3.3838e+00, -2.2966e+00],\n",
            "        [ 1.5708e+00, -3.2069e+00, -3.8345e+00,  ..., -4.4345e-01,\n",
            "         -3.4181e+00,  1.6834e-01],\n",
            "        [-9.6763e-02, -7.4251e-01, -3.7691e+00,  ...,  8.9642e-01,\n",
            "         -2.3349e+00,  3.2711e+00],\n",
            "        ...,\n",
            "        [ 6.6885e-01,  1.9450e+00, -5.7904e+00,  ..., -1.5773e+00,\n",
            "         -3.3203e-01, -1.3351e+00],\n",
            "        [ 3.5967e+00,  2.6291e+00, -1.9795e+00,  ...,  1.9765e+00,\n",
            "         -1.8885e+00,  2.9048e-01],\n",
            "        [ 2.8341e+00,  3.8726e-01, -4.8486e+00,  ..., -1.9723e+00,\n",
            "          2.0276e-01, -1.1230e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1329,  0.8184, -2.0218,  ...,  0.7750,  1.6025,  1.9755],\n",
            "        [ 0.2295, -0.9116, -4.5587,  ..., -1.5639,  0.7918,  0.5929],\n",
            "        [ 0.1094, -2.4222, -5.7808,  ..., -3.1477, -2.0651, -0.1995],\n",
            "        ...,\n",
            "        [ 4.6133,  2.2978, -5.2787,  ..., -0.5906, -2.0812, -1.2147],\n",
            "        [ 0.0674,  2.1359, -2.9475,  ..., -2.7241, -0.0184, -0.6273],\n",
            "        [-2.2540, -4.0760, -4.2372,  ..., -3.4563, -1.3123, -0.5582]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9583,  0.5303, -1.9016,  ...,  1.5157,  1.1228, -0.7668],\n",
            "        [-2.0061, -4.2895, -4.4551,  ..., -1.0798, -0.3620, -0.8576],\n",
            "        [-1.3749, -0.1766, -2.7191,  ..., -4.3098, -0.1556, -2.2325],\n",
            "        ...,\n",
            "        [ 1.5543, -0.1446, -5.0991,  ..., -1.4776, -0.4643, -1.6033],\n",
            "        [ 2.3016, -1.5982, -4.2406,  ..., -2.2235, -1.3579, -0.2212],\n",
            "        [ 2.9668, -3.2599, -3.8221,  ..., -0.8269, -5.6288, -2.1916]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5191,  0.7381, -3.8026,  ...,  1.3264, -0.4537,  0.9155],\n",
            "        [ 1.1304, -1.3894, -5.9312,  ..., -4.6606, -2.0953, -0.5962],\n",
            "        [ 4.2413, -1.9013, -6.2178,  ...,  0.9100, -1.8417, -0.2549],\n",
            "        ...,\n",
            "        [ 0.4848, -3.6688, -6.0829,  ..., -4.2612, -0.8527, -0.1194],\n",
            "        [ 1.9039,  1.9889, -3.6669,  ...,  0.2030,  0.0085,  0.2999],\n",
            "        [ 1.0759, -1.5459, -4.1115,  ...,  0.9720,  2.1102,  2.0964]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8854, -2.8916, -4.6179,  ..., -2.4124, -3.1783, -1.7036],\n",
            "        [ 0.4383,  1.8031, -3.2124,  ..., -2.6309,  1.4241, -0.4717],\n",
            "        [ 0.5303, -1.0883, -3.2640,  ..., -1.0561,  0.8251,  0.7177],\n",
            "        ...,\n",
            "        [ 1.0881,  0.2620, -3.9675,  ..., -0.1474, -1.5775, -0.7050],\n",
            "        [ 1.3301, -1.9736, -4.3428,  ..., -3.0444,  3.5408,  0.3927],\n",
            "        [ 1.2965, -1.2556, -3.5891,  ...,  0.2027,  2.2774,  1.2770]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.1724,  2.0690, -5.8844,  ..., -0.5571, -3.2030, -3.3864],\n",
            "        [ 2.2729, -3.2521, -3.7265,  ...,  1.4196, -2.7433, -2.6352],\n",
            "        [ 0.9076, -1.4876, -6.3987,  ..., -3.7195,  0.8277,  0.6485],\n",
            "        ...,\n",
            "        [-0.5704, -1.0679, -3.6239,  ..., -2.4672, -1.4889, -0.6472],\n",
            "        [-0.0719, -2.2667, -7.8575,  ..., -3.5090,  0.7554,  1.2014],\n",
            "        [ 2.0612, -1.4678, -1.7133,  ..., -2.2574, -0.4454, -0.6607]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9046, -0.8559, -5.2928,  ..., -2.5036, -6.0489, -1.9076],\n",
            "        [-0.1952, -0.8728, -2.3710,  ...,  2.5389, -0.9428,  3.0494],\n",
            "        [ 2.4793, -1.1574, -5.6830,  ..., -0.1677, -0.0900,  1.5950],\n",
            "        ...,\n",
            "        [ 0.3160,  2.9713, -3.4547,  ..., -1.6942,  0.2680, -3.3645],\n",
            "        [ 1.5689, -2.7029, -4.9678,  ..., -2.9969, -2.2610,  1.0593],\n",
            "        [ 1.9536,  1.3877, -3.7076,  ..., -0.6094,  1.4053,  2.1921]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1914e+00,  1.1450e+00, -3.6106e+00,  ...,  3.2141e-02,\n",
            "          3.2289e-01, -2.1057e+00],\n",
            "        [ 1.0376e+00, -1.2257e+00, -5.3200e+00,  ...,  6.4791e-01,\n",
            "         -1.4126e+00, -1.8693e+00],\n",
            "        [ 6.6236e-01, -1.4121e+00, -2.3525e+00,  ..., -7.3797e-01,\n",
            "          1.1316e+00, -8.2788e-04],\n",
            "        ...,\n",
            "        [ 2.1065e+00, -1.9045e+00, -3.3526e+00,  ..., -1.0891e+00,\n",
            "          3.0837e-01,  3.4064e+00],\n",
            "        [ 1.6746e+00, -1.1388e+00, -4.3444e+00,  ..., -1.8451e+00,\n",
            "          1.4969e+00,  8.3919e-01],\n",
            "        [ 1.8880e+00, -1.5849e+00, -4.8943e+00,  ..., -2.7349e+00,\n",
            "         -1.1372e+00, -6.0305e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4214, -2.7579, -4.7551,  ..., -0.9141,  3.0322,  2.2542],\n",
            "        [ 0.6649, -2.0306, -3.9929,  ..., -0.0448,  2.4219,  2.1056],\n",
            "        [ 0.4838, -1.6332, -5.7499,  ..., -4.9569, -0.2681, -1.7372],\n",
            "        ...,\n",
            "        [ 0.3475, -2.0676, -5.1657,  ..., -2.0250, -2.8200, -0.9963],\n",
            "        [-0.7267, -1.3574, -5.4159,  ...,  0.1526, -3.0345, -2.4279],\n",
            "        [-0.4617, -1.5700, -2.8759,  ..., -0.8845,  4.6462,  5.8342]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2259, -3.6479, -3.7265,  ..., -2.8417, -5.0095, -3.2367],\n",
            "        [-2.2255, -4.7573, -4.2164,  ..., -0.0370,  0.4962,  4.1908],\n",
            "        [ 1.5261, -0.4389, -5.6770,  ..., -2.3921,  0.5199,  0.8194],\n",
            "        ...,\n",
            "        [ 3.4044,  0.1686, -5.5038,  ..., -2.8924, -2.5646, -2.7332],\n",
            "        [ 3.9882,  0.8562, -3.3124,  ..., -4.5840,  1.0790, -1.6925],\n",
            "        [ 1.7697,  1.6794, -2.7950,  ..., -2.3668, -0.7865, -1.4900]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.3432, -1.7907, -5.7145,  ..., -3.3795, -5.0819, -4.0695],\n",
            "        [-1.3641, -0.2116, -3.7770,  ..., -1.9294,  0.3239,  1.3095],\n",
            "        [ 0.4581, -1.7725, -3.6836,  ...,  0.7039,  2.4816,  1.9262],\n",
            "        ...,\n",
            "        [ 0.5106, -1.6341, -6.8631,  ..., -1.9267, -1.0230, -1.2910],\n",
            "        [ 0.7112, -0.4798, -4.4634,  ...,  1.0097,  0.5090,  0.1012],\n",
            "        [ 0.1079, -2.3539, -4.6328,  ..., -4.1608,  0.2247,  2.9603]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0776, -1.3765, -2.7946,  ...,  2.6292, -2.0815,  0.8760],\n",
            "        [-0.3585, -2.7581, -4.8418,  ..., -3.3558, -0.1025, -0.3803],\n",
            "        [ 3.5591, -1.9918, -4.1046,  ..., -2.7544, -0.3240, -1.7207],\n",
            "        ...,\n",
            "        [ 1.7208,  2.3194, -3.6201,  ..., -0.6181,  0.3707, -2.3047],\n",
            "        [-0.8073, -2.4056, -4.9895,  ...,  0.5839,  2.0107,  3.2254],\n",
            "        [ 1.2294, -0.8162, -4.4725,  ..., -1.7177, -0.9905, -2.9504]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2497, -1.0991, -3.4874,  ..., -2.3492,  2.5202,  1.1294],\n",
            "        [ 0.6853,  0.3346, -3.2764,  ..., -1.5910,  2.0958, -1.9433],\n",
            "        [ 0.0726, -1.0410, -5.7624,  ..., -0.5598,  0.1592, -0.4875],\n",
            "        ...,\n",
            "        [ 1.8890, -2.4868, -3.1483,  ...,  3.6681, -4.6278,  1.0240],\n",
            "        [-0.6813, -0.8342, -3.5394,  ..., -2.8355,  3.4070,  2.4404],\n",
            "        [ 0.7851,  0.0406, -2.7380,  ...,  0.3980,  0.5179,  2.3565]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1584, -0.2690, -2.4854,  ..., -0.8710,  0.1826,  2.5544],\n",
            "        [-0.1886,  0.7909, -3.0764,  ...,  0.0881,  0.1474,  2.8359],\n",
            "        [ 2.4153, -2.0053, -4.5732,  ..., -1.2372,  0.5576,  0.2588],\n",
            "        ...,\n",
            "        [-0.9008, -2.4195, -3.0717,  ..., -2.6537, -1.2113,  0.1710],\n",
            "        [-0.4074, -1.0370, -4.5314,  ..., -3.9484,  0.2993,  1.5552],\n",
            "        [ 2.8363,  0.4263, -3.8268,  ...,  0.8395,  0.1556, -1.6620]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2082, -1.6482, -4.8964,  ..., -0.8235, -1.5352,  1.1205],\n",
            "        [-0.9707,  0.9634, -2.2066,  ..., -0.4299,  1.0097,  2.2410],\n",
            "        [ 1.6283, -2.6998, -5.7429,  ..., -3.0961, -0.7215,  0.8115],\n",
            "        ...,\n",
            "        [-0.2019,  0.4317, -4.9043,  ..., -2.7100,  2.4424,  1.4809],\n",
            "        [ 0.5956, -2.1722, -5.0791,  ..., -3.0011, -2.4084, -1.5842],\n",
            "        [ 1.0177, -0.5280, -3.8168,  ..., -2.1539,  0.0586, -2.7870]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-4.7194e-02,  7.9521e-01, -1.8324e+00,  ...,  9.8327e-01,\n",
            "         -5.8053e-03,  3.4927e+00],\n",
            "        [ 2.4159e+00, -2.7143e+00, -3.9965e+00,  ..., -1.3275e+00,\n",
            "         -5.0722e-01, -1.8498e-01],\n",
            "        [ 2.5094e+00, -7.9779e-01, -5.6064e+00,  ..., -3.7862e-01,\n",
            "         -1.8553e+00, -3.1365e-01],\n",
            "        ...,\n",
            "        [ 2.5143e+00, -2.5669e+00, -5.1984e+00,  ..., -5.5982e+00,\n",
            "         -2.4162e+00, -3.9430e+00],\n",
            "        [-1.8195e+00, -6.6612e-01, -4.1708e+00,  ..., -1.9083e+00,\n",
            "          1.8774e+00,  2.2231e+00],\n",
            "        [ 1.0761e+00,  7.7301e-01, -6.1761e+00,  ..., -2.2111e+00,\n",
            "          6.2233e-01,  1.1654e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.5356, -4.0833, -3.5612,  ..., -4.1269, -1.1150, -1.4596],\n",
            "        [ 0.8136,  1.3300, -5.6403,  ..., -0.2797,  0.5549,  1.9667],\n",
            "        [ 0.3117, -0.4559, -1.9038,  ...,  0.5612,  1.4833,  1.7758],\n",
            "        ...,\n",
            "        [ 0.4930,  0.4944, -3.0285,  ...,  0.1505,  0.1810,  2.7463],\n",
            "        [ 3.2499,  2.2333, -2.3877,  ...,  0.2878,  0.0363, -0.2534],\n",
            "        [ 0.1201, -3.4123, -6.6432,  ..., -2.5133,  0.2565,  2.7720]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7827, -4.1752, -4.7033,  ..., -1.0952,  2.2418,  1.8743],\n",
            "        [ 2.4953,  0.6314, -3.0029,  ..., -3.8748, -1.5187,  0.3070],\n",
            "        [ 1.5185, -3.0740, -3.7902,  ..., -2.8063,  0.2621,  0.1385],\n",
            "        ...,\n",
            "        [-0.8636, -1.0003, -4.5261,  ..., -4.0023,  3.4133,  3.0145],\n",
            "        [-0.5129, -5.9067, -6.7384,  ..., -2.2292,  2.4731,  7.2148],\n",
            "        [ 1.6486,  1.2983, -4.0622,  ..., -3.0180,  0.1237,  0.8522]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9319, -1.0411, -3.8272,  ..., -1.7498,  1.3989,  1.3069],\n",
            "        [ 2.8494, -0.8179, -4.9206,  ..., -1.3295, -2.9959, -2.2762],\n",
            "        [ 0.1944,  1.0745, -2.8931,  ..., -0.9818,  1.0894, -1.1390],\n",
            "        ...,\n",
            "        [ 1.3130, -0.3038, -4.6659,  ..., -3.8628,  0.4871, -1.9974],\n",
            "        [ 2.1795, -1.4083, -5.0689,  ..., -0.4559,  1.1566, -1.5558],\n",
            "        [ 2.2399,  1.5213, -6.0786,  ..., -0.1352, -0.3231, -1.4081]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6297, -2.5093, -5.1704,  ..., -2.7315,  2.2838,  3.7204],\n",
            "        [ 1.6280,  2.4514, -2.4798,  ...,  1.5698,  1.2236, -0.5294],\n",
            "        [ 0.8754, -2.6148, -5.1487,  ...,  0.2385,  2.3472,  2.3781],\n",
            "        ...,\n",
            "        [ 3.1356, -1.0620, -4.5517,  ..., -3.2860, -2.9094, -2.2251],\n",
            "        [ 0.3520, -0.7092, -3.0312,  ..., -4.4428,  1.8449, -2.2135],\n",
            "        [-0.1284, -1.7396, -3.7975,  ..., -3.2112,  1.8580,  0.3141]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3904, -4.7674, -6.9652,  ..., -2.2076, -0.0980,  3.5802],\n",
            "        [ 0.0547, -0.5019, -4.8691,  ...,  0.1059,  0.8003,  2.0179],\n",
            "        [ 1.2880, -1.7572, -4.2859,  ..., -1.9275,  0.9373,  0.3097],\n",
            "        ...,\n",
            "        [ 1.6229,  3.3876, -2.7757,  ...,  2.1154, -0.9959, -0.1814],\n",
            "        [-0.3241, -4.5606, -5.1893,  ..., -4.0053,  0.8242,  0.8797],\n",
            "        [-0.7955, -3.6170, -4.2316,  ..., -1.9165,  2.7249,  3.4975]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0832,  2.5630, -3.7721,  ..., -0.2362, -0.1721,  0.0136],\n",
            "        [ 2.1531, -2.7457, -5.8782,  ..., -3.8638, -0.8197, -0.7959],\n",
            "        [ 4.0826, -0.2956, -3.7554,  ..., -3.4463,  3.1027, -0.2864],\n",
            "        ...,\n",
            "        [ 2.8432,  0.4971, -5.1543,  ...,  0.2777,  0.6343, -1.2234],\n",
            "        [ 0.1642, -3.3733, -6.4450,  ..., -0.8855,  2.1134,  1.3846],\n",
            "        [ 0.7372, -3.1055, -4.9351,  ...,  0.7632, -1.3112,  3.0260]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9457,  0.8026, -4.7835,  ...,  1.5096,  1.6014, -0.8615],\n",
            "        [ 4.3682,  1.1086, -7.6343,  ..., -2.6859, -2.4515, -3.1048],\n",
            "        [-1.7011, -0.9598, -4.1807,  ..., -4.0908,  0.3205, -0.9519],\n",
            "        ...,\n",
            "        [ 1.9598, -2.6912, -5.2505,  ..., -6.1152, -4.7323, -2.0464],\n",
            "        [-0.7424, -1.8891, -5.9075,  ..., -3.9229,  2.8715,  3.2703],\n",
            "        [ 0.2676, -2.8287, -3.1335,  ..., -2.2894,  0.6819,  1.5028]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5445,  2.3620, -2.2031,  ..., -2.0461,  0.1430, -2.3573],\n",
            "        [-1.5317, -1.4560, -4.9198,  ...,  0.2244,  2.2583,  3.4503],\n",
            "        [ 0.8696, -1.3301, -4.2046,  ...,  1.1801, -0.6735,  0.3446],\n",
            "        ...,\n",
            "        [ 0.1585, -1.5434, -4.2897,  ..., -0.1697,  0.8925, -0.0190],\n",
            "        [ 1.7948,  1.2452, -4.4363,  ..., -2.1555, -2.8537, -3.6378],\n",
            "        [ 1.2763,  0.5031, -4.4557,  ..., -4.1207,  1.8984, -1.7039]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8156, -2.0555, -3.8469,  ..., -2.9259,  0.1507,  0.9036],\n",
            "        [ 1.5175, -3.0205, -4.5602,  ..., -1.9423,  0.0179,  0.1026],\n",
            "        [-1.9961, -2.7752, -2.0038,  ..., -0.6077,  2.6374,  4.9242],\n",
            "        ...,\n",
            "        [ 2.2558,  1.0506, -3.0151,  ..., -3.5021, -0.9288, -3.7271],\n",
            "        [ 2.7152, -2.0011, -5.0305,  ..., -1.6215, -0.8787, -1.0888],\n",
            "        [-1.2707, -1.3747, -3.4050,  ..., -1.0783,  4.7220,  6.0060]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.8656,  2.6377, -3.3656,  ..., -0.3186, -1.7372, -0.7343],\n",
            "        [-1.0404,  0.5100, -6.2454,  ..., -4.9894, -1.5516, -2.0259],\n",
            "        [-0.3266, -4.8277, -5.6790,  ..., -1.9815,  3.3776,  2.3178],\n",
            "        ...,\n",
            "        [ 1.5352,  1.1606, -3.3969,  ..., -3.9591, -0.1420, -1.1425],\n",
            "        [-1.5205, -3.1119, -4.0813,  ..., -3.6433,  1.0769, -0.0232],\n",
            "        [-2.7378,  0.0603, -2.2986,  ..., -0.2605,  2.3284,  4.2636]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5028, -1.3543, -3.6857,  ..., -4.9967,  1.2529,  0.8546],\n",
            "        [ 3.4023, -3.0626, -4.1702,  ..., -3.4401, -0.2781, -0.4997],\n",
            "        [ 1.2305, -0.1920, -5.7715,  ..., -1.8230,  1.0995,  0.7279],\n",
            "        ...,\n",
            "        [ 0.9226, -4.6093, -3.5589,  ...,  1.2602, -2.9790,  1.9744],\n",
            "        [-1.2868, -5.1171, -5.0617,  ..., -3.3189,  2.0228,  1.0971],\n",
            "        [ 1.9132,  0.7175, -4.5768,  ..., -0.3777, -2.7701, -1.8014]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1387, -2.5288, -4.6447,  ..., -2.4743, -0.6189, -1.3910],\n",
            "        [ 2.2567,  1.7612, -4.2487,  ...,  0.3638,  1.5827, -1.7706],\n",
            "        [ 0.5247, -2.8679, -4.6789,  ..., -1.8539,  2.0391,  0.4050],\n",
            "        ...,\n",
            "        [ 0.5478, -5.9252, -5.3614,  ..., -3.0398,  3.0565,  2.3449],\n",
            "        [ 3.1079,  2.5151, -5.3767,  ..., -3.7014, -1.2501, -1.0808],\n",
            "        [-3.5518, -3.9766, -4.1661,  ..., -5.5533,  2.6310, -0.1862]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6862e+00,  7.5761e-01, -5.4990e+00,  ..., -3.6423e+00,\n",
            "         -1.0616e+00, -2.1044e+00],\n",
            "        [ 1.5844e+00,  1.7475e+00, -4.5535e+00,  ..., -1.0453e-01,\n",
            "         -1.3378e+00, -1.7161e+00],\n",
            "        [-2.4153e+00,  2.1854e-03, -1.9743e+00,  ..., -1.4843e+00,\n",
            "          1.9753e+00,  4.0375e+00],\n",
            "        ...,\n",
            "        [-1.7996e+00,  2.8280e+00, -2.9065e+00,  ..., -4.9175e-02,\n",
            "          4.2297e-01, -1.2032e+00],\n",
            "        [ 1.9245e+00,  1.6760e+00, -3.8358e+00,  ..., -1.3393e+00,\n",
            "          6.8245e-01, -4.7057e-01],\n",
            "        [ 4.7154e-01, -4.4787e+00, -5.3188e+00,  ..., -1.2226e+00,\n",
            "         -1.5483e+00, -1.2838e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0099, -0.8155, -4.4149,  ..., -1.9107, -0.6744, -4.5719],\n",
            "        [ 6.2178,  4.3940, -4.1209,  ...,  0.0935, -1.3111, -4.5088],\n",
            "        [-2.8410, -0.5385, -3.1067,  ..., -1.2687,  3.6393,  2.3646],\n",
            "        ...,\n",
            "        [ 0.7709, -2.1964, -3.8407,  ..., -4.6992,  1.1349, -2.3813],\n",
            "        [-0.6478,  1.3021, -4.4957,  ..., -1.6362,  0.8809,  0.8841],\n",
            "        [ 0.2383,  0.3975, -2.8144,  ..., -2.8254, -0.9696, -0.5737]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2806, -1.4718, -3.6383,  ..., -1.1240, -0.0545, -3.2113],\n",
            "        [ 4.2131,  3.6601, -4.8452,  ..., -2.4234, -4.7235, -2.5172],\n",
            "        [ 4.0262,  2.7808, -5.4925,  ...,  0.2113, -2.4840, -2.1009],\n",
            "        ...,\n",
            "        [ 1.0569,  0.7295, -2.0924,  ..., -1.5535,  2.3798, -0.7911],\n",
            "        [ 0.7515,  2.5127, -2.3011,  ..., -0.1379, -0.0316, -2.2952],\n",
            "        [ 0.5357, -0.9313, -4.4289,  ..., -0.5363,  2.4676,  1.3813]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1308,  2.6819, -3.6135,  ..., -0.7643, -0.3576, -1.1253],\n",
            "        [ 0.1570, -5.5281, -2.1391,  ..., -1.6449,  3.2625,  3.0590],\n",
            "        [-1.9706, -1.3234, -4.1405,  ..., -0.1621,  2.5140,  2.5317],\n",
            "        ...,\n",
            "        [-0.5350, -3.1645, -5.4321,  ..., -0.6025,  0.0283,  0.7016],\n",
            "        [ 0.9393,  0.7567, -2.9760,  ..., -1.6179,  0.3869, -0.1786],\n",
            "        [-1.9066, -0.5117, -5.2552,  ..., -2.2755,  1.4270,  1.2352]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0801,  0.2997, -3.4573,  ..., -2.3453, -1.6390, -0.1811],\n",
            "        [-0.6932, -0.3562, -2.7763,  ..., -0.6863,  0.0272, -0.2650],\n",
            "        [ 0.1312,  1.5577, -3.9723,  ..., -0.0513, -0.3672,  2.1582],\n",
            "        ...,\n",
            "        [-0.1429, -1.2351, -3.6968,  ..., -2.1026,  3.5048,  0.5589],\n",
            "        [ 0.3027, -0.5288, -4.2196,  ..., -3.9250, -1.3829, -1.9531],\n",
            "        [ 1.1923, -0.2540, -3.7039,  ..., -0.5128, -0.4423, -3.2340]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5858, -1.2285, -6.0935,  ..., -1.8610,  0.7727,  0.6591],\n",
            "        [ 0.2525, -1.8935, -3.7643,  ..., -1.1451, -0.3987, -2.4196],\n",
            "        [ 0.5819, -3.1818, -5.2003,  ..., -3.8555,  1.6506, -0.0246],\n",
            "        ...,\n",
            "        [ 0.9197, -0.4803, -3.1601,  ..., -0.9073,  2.6548,  0.4424],\n",
            "        [-0.1525, -1.3080, -6.0038,  ..., -0.0149,  2.4796,  4.4624],\n",
            "        [ 0.7105, -0.3279, -4.4947,  ..., -1.1729,  3.0404, -0.1103]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3403, -3.0300, -3.1417,  ..., -1.5082, -4.7173, -1.5243],\n",
            "        [-1.5028, -0.2061, -2.9127,  ..., -2.7233,  0.1218, -2.9879],\n",
            "        [ 2.4412, -0.2268, -4.3815,  ..., -4.0094, -2.9893, -3.0910],\n",
            "        ...,\n",
            "        [-0.3955, -2.5115, -3.9463,  ..., -2.1413, -1.3955, -1.3947],\n",
            "        [ 1.7634,  1.1899, -3.3806,  ..., -0.8192,  0.3360, -1.7830],\n",
            "        [ 0.1179,  0.9239, -4.6283,  ..., -1.1253, -0.7126,  1.4661]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.3154, -1.2257, -4.6627,  ..., -2.4994,  2.0905,  3.8797],\n",
            "        [ 1.0612, -4.3698, -6.4323,  ..., -1.9854,  3.2814,  2.9698],\n",
            "        [-0.2628, -0.8159, -5.2705,  ..., -3.9483,  4.0612,  2.7486],\n",
            "        ...,\n",
            "        [-0.8890, -0.7572, -4.2797,  ...,  1.3469,  0.8181,  2.4787],\n",
            "        [ 1.7323, -0.9159, -2.9677,  ..., -2.4067, -0.9708, -1.9401],\n",
            "        [ 0.3899, -1.4244, -4.1284,  ..., -4.6270, -0.8571, -2.1461]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4650, -1.7523, -5.3417,  ...,  0.6757,  1.7145,  3.1563],\n",
            "        [ 0.6197,  0.2493, -5.7440,  ..., -1.0956, -0.0307,  3.2601],\n",
            "        [ 0.8415,  0.3493, -3.6347,  ..., -1.5907,  3.1028, -1.9048],\n",
            "        ...,\n",
            "        [ 0.9741,  1.2696, -2.7471,  ..., -2.8385, -0.6909,  0.0762],\n",
            "        [ 1.2197, -4.7884, -4.3275,  ..., -3.8412, -2.2915,  1.0042],\n",
            "        [ 1.6118,  2.3076, -3.9572,  ..., -0.1421,  0.8470,  0.2983]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0701, -0.7160, -4.0891,  ..., -2.8129,  1.2795,  0.7806],\n",
            "        [-0.4353, -2.0702, -3.5666,  ..., -0.4513,  3.4633,  2.4199],\n",
            "        [ 0.6466, -2.1404, -5.2000,  ..., -3.7957,  1.2869, -0.1483],\n",
            "        ...,\n",
            "        [ 0.1339,  2.3595, -3.0876,  ..., -0.9088, -1.3641,  0.3663],\n",
            "        [ 0.4984, -4.6054, -4.3825,  ..., -2.5089,  2.2219, -1.6900],\n",
            "        [-0.2326, -2.2941, -4.7602,  ..., -0.4729,  1.2942,  1.6154]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1334, -0.5842, -5.5299,  ..., -0.9028,  0.3495,  0.0549],\n",
            "        [ 1.2303, -2.2551, -3.3958,  ..., -3.9741, -2.7851, -2.0790],\n",
            "        [ 1.2996, -2.6884, -5.2374,  ..., -4.3311, -1.3205, -1.2989],\n",
            "        ...,\n",
            "        [ 0.9923, -1.3656, -5.5083,  ..., -2.6553, -1.4103, -2.2789],\n",
            "        [-0.3072,  0.3606, -3.9221,  ..., -3.0891,  0.9223,  0.8929],\n",
            "        [-1.2965,  0.2377, -4.5975,  ..., -0.8940,  1.3144,  3.3172]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9803, -1.2173, -1.9731,  ..., -0.3292,  3.3719,  4.6947],\n",
            "        [-1.1449, -3.7233, -3.6579,  ..., -2.9835,  3.9822,  3.7199],\n",
            "        [-0.2811,  2.3009, -5.0554,  ..., -1.4163, -1.6718,  1.9619],\n",
            "        ...,\n",
            "        [ 1.2867, -2.7478, -3.8877,  ..., -4.0415,  0.4361, -0.3376],\n",
            "        [-1.2852,  0.0820, -4.1927,  ..., -1.2964, -1.1897, -0.0468],\n",
            "        [ 1.4758, -0.2535, -5.3452,  ..., -0.1106,  0.9719, -1.0763]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2937, -1.9329, -6.2905,  ..., -3.3259, -0.1165,  0.5063],\n",
            "        [-0.5234, -1.0686, -5.1339,  ..., -0.6889,  1.6271,  1.1386],\n",
            "        [-0.0859,  0.1918, -5.1846,  ..., -2.7303,  1.3669, -0.6819],\n",
            "        ...,\n",
            "        [ 0.6463, -3.5782, -2.8078,  ..., -2.3857, -1.3505,  0.4258],\n",
            "        [ 0.7890,  1.1334, -0.9367,  ...,  0.7018, -0.6491,  2.3343],\n",
            "        [ 1.3163, -0.5977, -5.6003,  ...,  1.5201,  2.8196,  2.5270]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4972, -2.7159, -5.5897,  ..., -1.2388,  3.5373,  2.3008],\n",
            "        [-0.8589, -2.2471, -4.8506,  ..., -3.9069, -0.3992,  1.1107],\n",
            "        [ 0.3015,  2.9993, -1.3624,  ...,  1.8364, -0.5297,  1.4087],\n",
            "        ...,\n",
            "        [ 3.6496, -2.5101, -5.8692,  ..., -2.8138, -4.8776, -5.3879],\n",
            "        [ 0.2116,  0.6734, -5.2501,  ..., -0.9240,  2.0994,  2.0736],\n",
            "        [ 0.0491,  1.4103, -3.1646,  ..., -2.7444, -0.0834,  1.5451]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0277, -1.2188, -3.3943,  ..., -1.2635, -2.9651, -4.1806],\n",
            "        [ 2.2240,  2.2238, -4.0096,  ..., -0.3656,  1.2608, -2.6778],\n",
            "        [ 0.9349, -1.0433, -4.0697,  ..., -2.8720,  0.5060, -1.9998],\n",
            "        ...,\n",
            "        [-0.1501,  4.1155, -3.6557,  ..., -1.7312,  0.6814,  0.1269],\n",
            "        [ 0.0912, -4.4862, -5.6068,  ..., -4.2318, -4.1517, -1.1512],\n",
            "        [-2.2688, -1.2030, -3.3611,  ..., -0.3672,  2.6605,  3.3112]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1830, -3.6659, -5.3722,  ..., -0.7932,  3.4238,  2.9451],\n",
            "        [-0.0503, -5.3392, -4.1000,  ..., -1.8641,  1.3344,  0.7058],\n",
            "        [-0.4696,  1.1879, -5.5148,  ..., -0.9336, -1.5600, -1.6596],\n",
            "        ...,\n",
            "        [-0.6067, -2.7423, -2.0188,  ..., -1.2033,  1.4352,  1.4635],\n",
            "        [-1.4828,  0.6240, -2.8042,  ..., -1.3056,  1.2464, -1.2968],\n",
            "        [-0.4178, -3.0534, -4.1174,  ...,  0.4249,  3.5613,  2.9197]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4699,  0.1337, -3.5735,  ..., -0.1968,  2.3186, -0.3315],\n",
            "        [ 4.0275,  0.8874, -4.1560,  ...,  1.2129,  1.0151, -2.1495],\n",
            "        [ 0.8651, -5.7442, -4.9706,  ..., -1.1773,  3.1418,  1.6967],\n",
            "        ...,\n",
            "        [ 2.4715, -1.1258, -4.7136,  ..., -2.2943,  2.3070, -1.4473],\n",
            "        [-0.2119, -5.4976, -5.8471,  ..., -7.6825,  0.8562,  0.5599],\n",
            "        [ 3.2253, -2.9096, -6.5882,  ..., -5.4921,  1.9686, -0.2222]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6581, -2.2348, -4.3607,  ..., -1.5081, -2.3784, -0.8920],\n",
            "        [-0.4448, -2.2857, -4.3356,  ..., -2.4460, -1.2536, -2.0724],\n",
            "        [-0.4994, -3.0576, -6.6011,  ..., -1.5800,  1.2701,  4.1902],\n",
            "        ...,\n",
            "        [ 1.9554, -1.9265, -4.8932,  ..., -1.2678,  0.4817, -2.6806],\n",
            "        [ 2.7337, -1.0827, -4.3223,  ..., -3.7379,  0.4956, -0.0585],\n",
            "        [-0.7734,  0.0388, -2.2647,  ..., -1.7766,  2.0486, -1.2443]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1120, -0.7747, -2.7642,  ...,  1.3508,  2.5637,  2.7671],\n",
            "        [-2.0038, -0.9549, -3.9494,  ..., -1.8928,  1.8254,  1.0724],\n",
            "        [ 0.5583,  1.3808, -3.3083,  ..., -0.3737,  0.7171, -1.2575],\n",
            "        ...,\n",
            "        [ 4.2166, -2.5445, -5.3220,  ..., -1.9485, -5.6814, -4.5797],\n",
            "        [ 4.2178, -1.9193, -3.9284,  ..., -2.3041, -0.1260, -1.1014],\n",
            "        [ 0.9139,  1.2192, -3.8325,  ..., -2.2250, -0.7209,  0.0240]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9102a50bb03e4e3b829ec085d0c59b47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0900,  1.2041, -3.1983,  ..., -1.3738,  1.3944, -1.4571],\n",
            "        [-1.0744, -1.6515, -6.3073,  ..., -2.5682,  1.5953,  2.1669],\n",
            "        [-0.6500, -3.3049, -5.0218,  ..., -3.0935,  2.7780,  2.5221],\n",
            "        ...,\n",
            "        [-1.2339,  1.4708, -2.7165,  ..., -0.6934, -0.4933, -0.3535],\n",
            "        [ 1.8862,  0.4531, -5.3445,  ..., -0.8409, -0.5750, -3.5514],\n",
            "        [ 3.1401,  3.3444, -3.3087,  ..., -3.3697,  0.9979, -0.1397]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3149,  1.9623, -4.6191,  ..., -0.5495,  0.5384,  0.1059],\n",
            "        [ 1.1230, -2.9187, -3.8300,  ..., -0.2707,  1.1793,  0.8900],\n",
            "        [ 2.8533,  2.4242, -4.2652,  ..., -0.1555,  0.1984,  0.1776],\n",
            "        ...,\n",
            "        [-0.3876, -1.1933, -3.9497,  ...,  3.1002, -0.1838,  3.4769],\n",
            "        [ 1.4225, -0.0816, -4.6662,  ..., -4.2853,  2.2766,  0.3630],\n",
            "        [ 0.5069, -1.6438, -4.5962,  ..., -3.1613,  2.0079,  1.7407]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4105,  0.2203, -3.2631,  ...,  0.3449,  1.9864,  2.0497],\n",
            "        [ 3.2935,  2.6513, -5.0963,  ...,  0.8224,  0.4568, -0.2808],\n",
            "        [ 1.6612,  3.4089, -3.4989,  ..., -1.9463, -2.0015, -4.0638],\n",
            "        ...,\n",
            "        [-1.5625, -3.3683, -3.0710,  ..., -2.3845, -0.8441,  0.3399],\n",
            "        [ 0.5965, -4.5244, -3.0477,  ..., -2.2312,  0.6848,  0.3522],\n",
            "        [ 1.2241, -1.5527, -4.8443,  ...,  0.0966,  0.9846,  2.0354]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2627,  3.4998, -2.7757,  ...,  1.7772, -0.8996, -0.0953],\n",
            "        [ 1.7276, -1.1203, -3.6822,  ..., -0.3082, -2.8489, -1.5993],\n",
            "        [ 3.0118,  0.6612, -3.5190,  ...,  1.7927, -0.3538, -1.4354],\n",
            "        ...,\n",
            "        [-0.8860,  2.4715, -3.1859,  ..., -0.9754, -0.6470, -2.4169],\n",
            "        [-0.0799, -2.9162, -5.5638,  ..., -0.3411,  2.3987,  2.4287],\n",
            "        [-1.0130, -4.4004, -4.5458,  ..., -4.1650,  2.5263,  1.6203]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2191,  1.4216, -3.1675,  ...,  1.6765,  1.1797,  1.0097],\n",
            "        [ 0.9786, -0.2168, -3.0442,  ...,  1.0098,  0.6551, -0.0147],\n",
            "        [-0.4905, -0.9667, -5.0723,  ...,  2.1158, -0.2761,  2.4803],\n",
            "        ...,\n",
            "        [ 1.7102, -3.1387, -3.5736,  ..., -1.7094,  0.1560,  0.5524],\n",
            "        [ 1.4080, -0.9750, -2.2454,  ..., -1.1907,  1.2500,  1.8162],\n",
            "        [ 3.4571,  4.8117, -3.8170,  ...,  0.0835, -0.4102, -1.7694]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6600, -4.0210, -3.6634,  ..., -5.1151,  1.3832,  0.4856],\n",
            "        [ 0.5479,  0.3769, -5.0993,  ..., -1.9818,  0.4863, -1.7469],\n",
            "        [ 2.0910,  0.2929, -6.4259,  ..., -3.2335, -0.6759, -2.8442],\n",
            "        ...,\n",
            "        [ 2.0294,  1.8123, -2.3103,  ..., -0.9346,  0.6224, -3.5281],\n",
            "        [-0.0283, -1.7070, -4.9802,  ...,  0.9601,  0.5756,  3.5181],\n",
            "        [-2.7901, -2.2758, -2.6006,  ..., -2.8348,  1.0328,  1.8176]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9785, -0.3653, -4.6618,  ..., -3.3055,  3.1191,  1.7390],\n",
            "        [ 1.6011, -2.1497, -5.2126,  ..., -4.8998, -0.0935, -1.1335],\n",
            "        [ 1.5630,  2.5648, -2.3604,  ..., -2.1718,  0.3495, -0.2020],\n",
            "        ...,\n",
            "        [ 2.2767,  0.2476, -4.6094,  ..., -0.5154,  0.9767, -1.9948],\n",
            "        [-2.5490,  0.7091, -2.3287,  ..., -1.3318,  1.7957,  4.5777],\n",
            "        [-1.0469,  0.8907, -2.0671,  ..., -3.2698,  2.3331, -1.1097]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2021, -3.3951, -3.7928,  ..., -0.7555,  4.1976,  5.1051],\n",
            "        [ 0.2595,  0.1925, -3.7905,  ...,  0.6806, -0.1458,  3.7747],\n",
            "        [-3.6872, -2.3567, -3.8176,  ..., -1.4862,  2.9348,  4.0937],\n",
            "        ...,\n",
            "        [-0.9241, -2.0578, -3.9584,  ..., -5.1954, -1.6244, -3.9343],\n",
            "        [-1.6433, -1.3906, -4.1908,  ..., -1.0716,  2.8417,  4.2190],\n",
            "        [ 1.7102,  2.9633, -3.7721,  ..., -0.5842, -0.1777, -0.0504]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.9636e+00, -6.4988e-01, -4.9067e+00,  ..., -1.4403e+00,\n",
            "         -8.7620e-01, -6.6912e-01],\n",
            "        [ 5.6574e-01,  2.7106e+00, -2.2924e+00,  ..., -2.9661e+00,\n",
            "          6.8332e-01, -1.0522e+00],\n",
            "        [ 5.5126e-01,  9.5925e-01, -6.3842e+00,  ..., -3.7085e+00,\n",
            "         -7.8310e-01,  9.5188e-01],\n",
            "        ...,\n",
            "        [ 6.8477e-01,  9.6800e-02, -5.5265e+00,  ..., -2.5693e+00,\n",
            "         -1.8670e+00, -3.5500e+00],\n",
            "        [ 1.1055e+00,  6.1544e-01, -7.0279e+00,  ..., -3.9013e+00,\n",
            "          1.1671e+00, -5.8997e-03],\n",
            "        [ 1.5253e+00,  2.0392e+00, -6.1277e+00,  ..., -3.1072e-01,\n",
            "          1.7036e+00, -9.3549e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.5248, -1.2988, -5.7074,  ..., -3.9602, -5.5849, -2.6925],\n",
            "        [ 2.9360, -2.9274, -7.0481,  ..., -3.8471,  0.8778,  0.1544],\n",
            "        [ 2.9704, -1.1142, -5.8280,  ..., -3.3103, -2.0063, -2.4262],\n",
            "        ...,\n",
            "        [ 0.5480, -4.8789, -4.6357,  ...,  1.3532, -1.1372,  1.6733],\n",
            "        [ 1.0741, -1.3625, -4.6578,  ..., -1.3801,  0.3573,  1.6339],\n",
            "        [ 2.2419, -2.8046, -6.4890,  ..., -1.9203, -0.1965, -1.1198]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1699,  3.1602, -2.6148,  ..., -0.6179, -0.0697, -0.1041],\n",
            "        [ 0.5353, -1.1014, -3.8411,  ..., -2.1982,  1.9200,  1.2192],\n",
            "        [-1.9451,  1.0001, -2.6916,  ..., -1.4912,  3.3315,  3.4658],\n",
            "        ...,\n",
            "        [-0.4793, -2.5889, -4.7026,  ..., -1.7072,  0.1674, -2.0367],\n",
            "        [-0.2059, -0.3145, -3.6661,  ...,  0.6748,  0.2779,  1.3116],\n",
            "        [-0.2844,  1.4528, -1.9226,  ...,  1.4156,  0.9125,  0.6276]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3763, -3.0946, -3.5842,  ..., -3.3339,  2.2642, -0.0153],\n",
            "        [-2.1332, -1.4430, -4.0682,  ..., -1.1607,  1.7461,  1.8328],\n",
            "        [ 2.6626, -1.6091, -4.4522,  ..., -2.1825, -1.1272, -3.4146],\n",
            "        ...,\n",
            "        [ 1.0373, -0.9262, -4.3679,  ..., -1.8329, -0.6869, -3.1863],\n",
            "        [ 0.4208, -3.4398, -5.9400,  ...,  0.3069,  3.1560,  2.3836],\n",
            "        [ 0.9335, -3.1967, -4.2138,  ..., -2.5417,  1.2563,  0.5407]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8404, -3.0116, -5.5650,  ..., -3.6179, -1.3713, -2.0836],\n",
            "        [ 1.0132,  1.3130, -4.3978,  ..., -0.5412,  1.0447, -2.4802],\n",
            "        [ 0.9844,  2.1341, -4.5253,  ...,  1.7403,  1.6315,  0.7685],\n",
            "        ...,\n",
            "        [ 0.3652, -0.2750, -4.0295,  ...,  0.6362,  2.4359,  2.8544],\n",
            "        [-1.0817, -3.1828, -6.0500,  ..., -0.1892,  3.8679,  4.7629],\n",
            "        [ 1.6618,  4.3982, -4.2356,  ...,  0.1349,  0.5921, -0.0886]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2298,  0.9390, -2.7450,  ..., -1.1684,  1.0815, -0.0146],\n",
            "        [-0.1309, -3.1277, -4.9739,  ...,  0.0193,  2.2309,  1.5818],\n",
            "        [-2.4281, -0.5288, -4.0709,  ...,  0.3285,  2.3166,  5.0240],\n",
            "        ...,\n",
            "        [-2.8423, -1.0492, -3.3004,  ..., -4.1446, -0.3370, -2.0354],\n",
            "        [-0.8632, -1.1694, -3.9662,  ..., -2.8857,  0.3417,  3.5265],\n",
            "        [-1.1188,  0.1011, -3.1707,  ..., -0.3781,  2.0552, -0.7019]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1295, -1.8801, -4.5043,  ...,  0.2804,  2.8257,  3.0705],\n",
            "        [ 0.7176, -1.1406, -4.9640,  ..., -2.0694,  1.6747,  1.1319],\n",
            "        [ 2.7090, -0.5922, -6.0540,  ..., -6.3934, -5.0577, -8.7729],\n",
            "        ...,\n",
            "        [ 3.7126,  1.5712, -3.7473,  ..., -2.5344,  4.0247, -2.5555],\n",
            "        [-0.5758, -2.1229, -3.1131,  ..., -2.1381, -0.7038, -0.3862],\n",
            "        [ 1.3250, -3.1136, -3.2723,  ..., -1.5846,  0.4573, -0.0238]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0582,  2.2798, -1.7354,  ..., -1.2920, -0.0344, -2.2986],\n",
            "        [ 0.8027, -2.2589, -2.9012,  ..., -0.7152,  2.1812,  1.5043],\n",
            "        [-0.7357, -3.3540, -3.5825,  ..., -1.7702,  4.0839, -0.0573],\n",
            "        ...,\n",
            "        [ 1.3982, -2.3862, -5.3570,  ..., -4.9715, -1.7899, -0.9919],\n",
            "        [-0.6901, -0.3221, -4.1072,  ...,  0.0939,  2.4004,  1.6001],\n",
            "        [-1.0270, -2.8660, -4.9659,  ..., -0.7377,  3.6655,  3.7691]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0036e+00,  1.7588e+00, -5.0557e+00,  ..., -8.3791e-01,\n",
            "          1.0925e+00,  5.8881e-01],\n",
            "        [-2.1085e+00,  1.1794e+00, -2.2684e+00,  ...,  1.0026e+00,\n",
            "         -1.0264e-01,  1.5541e+00],\n",
            "        [-1.8542e+00,  5.4099e-01, -5.3221e+00,  ..., -7.5508e-01,\n",
            "          2.2692e+00,  1.7448e+00],\n",
            "        ...,\n",
            "        [ 2.2876e+00,  2.8561e+00, -4.7356e+00,  ...,  5.3660e-03,\n",
            "          1.2313e+00, -9.9541e-01],\n",
            "        [ 1.2478e+00, -6.7679e-01, -3.7072e+00,  ..., -7.5799e-01,\n",
            "         -1.5422e-01, -1.4090e+00],\n",
            "        [-1.3773e+00, -2.8196e+00, -5.7096e+00,  ...,  1.3744e-01,\n",
            "          4.3296e+00,  2.5666e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.0158, -1.2749, -4.3955,  ..., -0.1043, -1.4336, -1.1221],\n",
            "        [-2.2942, -1.2090, -3.2091,  ..., -2.3862,  3.4762,  3.0718],\n",
            "        [ 0.9179, -3.8478, -4.4548,  ..., -5.1450, -2.6813, -2.7764],\n",
            "        ...,\n",
            "        [ 1.8513, -1.1357, -5.2930,  ..., -2.3628, -5.2828, -2.3893],\n",
            "        [ 0.5353,  1.4147, -5.4960,  ...,  0.4195,  0.7331,  0.0848],\n",
            "        [ 0.4629,  0.6669, -3.9801,  ...,  2.3963, -1.7571,  0.3097]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9370,  2.6240, -3.0672,  ...,  0.6584,  1.3661, -1.4924],\n",
            "        [-0.9794, -3.2138, -5.1401,  ..., -0.9002,  3.5141,  4.3177],\n",
            "        [-0.0182, -3.8538, -5.0041,  ..., -4.2234, -0.2581, -0.5647],\n",
            "        ...,\n",
            "        [ 1.9117, -2.0262, -4.4704,  ..., -2.5832, -3.9169, -3.6414],\n",
            "        [ 0.9518, -1.2180, -5.4364,  ..., -2.9732,  3.5856,  2.6118],\n",
            "        [ 5.8970, -1.2717, -4.0120,  ..., -0.9405, -0.4057, -1.8802]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2834,  0.0108, -5.4318,  ..., -1.8104, -2.0607, -2.5571],\n",
            "        [-0.9118, -3.3137, -4.8264,  ..., -0.8531,  2.9254,  1.5302],\n",
            "        [-3.0607, -2.8144, -6.8316,  ..., -1.8791, -1.6036, -0.7457],\n",
            "        ...,\n",
            "        [-0.3579, -3.4327, -6.6432,  ..., -1.8498,  0.7468,  2.6485],\n",
            "        [ 1.1809,  1.5244, -3.9973,  ..., -2.1296,  1.0312,  0.4796],\n",
            "        [ 0.8012, -1.8178, -4.3559,  ..., -2.5381,  0.2960, -0.9265]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.6578,  0.9212, -4.1283,  ...,  0.1103,  0.5382,  0.0805],\n",
            "        [-2.3738, -1.6029, -5.6457,  ..., -5.1250,  1.1951,  0.9246],\n",
            "        [ 0.0434, -1.5523, -3.7419,  ...,  1.3290,  3.0384,  2.6138],\n",
            "        ...,\n",
            "        [-2.2308, -1.3308, -6.5941,  ..., -2.8857,  0.8038,  0.4246],\n",
            "        [ 2.7131,  1.5234, -3.8388,  ..., -3.6235,  0.6927, -4.3137],\n",
            "        [ 1.6765, -3.8037, -5.5302,  ..., -2.7647,  0.8641,  0.2803]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5750, -2.0814, -4.9530,  ...,  0.3344, -3.1618, -1.3142],\n",
            "        [ 1.0270, -0.8668, -4.8296,  ..., -2.4005, -0.1312, -1.9276],\n",
            "        [ 3.6985,  3.4931, -3.9133,  ..., -0.7342,  0.8666, -2.8509],\n",
            "        ...,\n",
            "        [ 1.3436, -3.0255, -4.6619,  ..., -3.2234,  2.0193,  2.0567],\n",
            "        [-0.3478, -3.3560, -6.0797,  ...,  0.0498,  3.8098,  4.3118],\n",
            "        [-0.5575, -1.6708, -4.1297,  ..., -0.6255,  3.3650,  2.3293]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2681, -2.1883, -4.7412,  ...,  0.5229,  2.7915,  2.7507],\n",
            "        [-1.1855, -0.4446, -5.9952,  ..., -3.2782,  0.5911,  3.4310],\n",
            "        [ 3.1587, -1.0734, -3.0469,  ..., -1.0676, -1.1204, -2.1458],\n",
            "        ...,\n",
            "        [-1.6691, -0.7974, -2.8990,  ...,  2.0643,  1.5215,  2.4769],\n",
            "        [-1.2078, -2.2009, -5.0462,  ...,  0.5959,  3.0927,  3.7351],\n",
            "        [ 0.8209,  2.0080, -3.8209,  ..., -0.4300,  0.5539, -1.0932]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1273,  0.8357, -4.3200,  ..., -0.4581,  1.2010,  1.2990],\n",
            "        [ 1.7982, -1.7329, -3.1835,  ..., -0.6869,  2.7544,  1.1054],\n",
            "        [-0.6229,  0.5845, -2.4839,  ..., -1.6925,  1.6913, -0.2056],\n",
            "        ...,\n",
            "        [ 2.1508,  2.6108, -2.5685,  ...,  1.6187, -0.6292, -1.0455],\n",
            "        [ 0.9394, -1.1225, -4.5410,  ..., -4.3626,  0.2677, -0.5377],\n",
            "        [ 1.0412,  0.8727, -3.8802,  ..., -2.9738,  1.9076,  1.7755]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8148,  1.0844, -3.8187,  ..., -3.3707,  0.2420, -1.5124],\n",
            "        [ 0.9735, -1.9925, -6.0015,  ..., -0.1429,  3.0232,  3.0793],\n",
            "        [-0.1178, -3.8780, -5.5037,  ...,  0.6756,  3.3425,  3.0101],\n",
            "        ...,\n",
            "        [-1.5462,  2.7537, -2.5214,  ..., -2.0962,  0.3887, -1.1570],\n",
            "        [-0.3992, -1.3365, -3.7074,  ..., -1.3668, -0.1700, -3.5641],\n",
            "        [-0.4140,  0.9359, -2.7026,  ..., -2.6109,  2.8024, -1.2321]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1504,  0.5883, -5.2115,  ..., -3.6071,  1.7550,  1.6485],\n",
            "        [-0.6613,  1.8619, -4.0270,  ...,  0.5176,  2.3665,  0.5384],\n",
            "        [ 0.1628,  1.1125, -6.1906,  ...,  0.8159, -1.0018,  2.3135],\n",
            "        ...,\n",
            "        [ 2.2113,  2.5129, -2.3760,  ...,  2.0709,  0.0103,  0.5364],\n",
            "        [ 3.4862,  0.7811, -5.2185,  ..., -2.4697, -5.3008, -2.5765],\n",
            "        [ 3.0256, -0.0932, -5.0903,  ..., -1.1801,  3.4289, -1.6059]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9746, -0.0099, -4.0389,  ..., -3.5012, -0.8558, -1.5677],\n",
            "        [-4.1336, -2.2098, -2.8941,  ...,  0.9211,  2.3278,  5.1044],\n",
            "        [ 0.1251,  1.2004, -2.5076,  ..., -2.9243,  3.4535,  1.3613],\n",
            "        ...,\n",
            "        [ 2.5634, -1.3158, -3.3853,  ...,  1.6685, -3.1326, -3.1423],\n",
            "        [-2.0471, -0.1386, -5.1768,  ..., -2.7473,  2.2192,  3.0571],\n",
            "        [ 1.7833, -0.1619, -2.2043,  ...,  0.0076,  0.9594, -3.0741]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.9096,  3.4779, -3.0265,  ...,  0.6090, -2.4828, -3.5138],\n",
            "        [ 0.1056, -3.1154, -5.3157,  ...,  0.1887,  3.5908,  2.2559],\n",
            "        [-1.5253, -1.2121, -3.4096,  ...,  0.9729,  2.1694,  2.0587],\n",
            "        ...,\n",
            "        [-0.4563, -1.3573, -3.2316,  ...,  2.3055, -1.1853, -0.4682],\n",
            "        [-0.9849, -0.5929, -2.5086,  ..., -0.5780, -0.8677,  0.0769],\n",
            "        [-0.2365, -0.3150, -5.6260,  ..., -2.0421,  0.5190, -0.2247]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2735, -2.4654, -3.6440,  ..., -1.8203,  3.2507,  0.7927],\n",
            "        [ 2.1975,  1.4814, -6.6959,  ..., -1.0703, -0.4768, -1.3843],\n",
            "        [ 0.8603,  1.9938, -5.0182,  ..., -2.3858,  1.4972, -1.1614],\n",
            "        ...,\n",
            "        [ 1.5653,  2.9577, -4.2801,  ...,  0.0919, -0.1724, -0.9963],\n",
            "        [-1.1643, -3.2659, -6.2598,  ..., -3.8134,  3.8444,  1.6624],\n",
            "        [ 0.4704, -0.6176, -3.5910,  ...,  3.5994, -1.3661,  0.5272]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1327, -3.0283, -3.5814,  ..., -0.8397,  2.5315,  1.8216],\n",
            "        [ 1.3105,  2.2862, -4.3608,  ...,  1.3745,  1.5028,  1.1953],\n",
            "        [ 0.9730, -3.2113, -5.4428,  ..., -2.3373,  0.5089,  2.4108],\n",
            "        ...,\n",
            "        [ 2.5883,  2.1561, -3.0681,  ..., -0.3004, -0.1910, -1.1941],\n",
            "        [-0.7101, -2.8580, -5.2928,  ...,  0.8463,  4.0486,  3.2711],\n",
            "        [-0.3912, -1.8381, -5.4222,  ..., -3.7524, -1.3021, -3.3963]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 7.2824e-01, -1.9162e+00, -4.5990e+00,  ..., -2.2731e+00,\n",
            "          1.6432e+00, -1.6544e-01],\n",
            "        [ 7.4771e-01, -2.6858e+00, -6.5718e+00,  ..., -1.2129e+00,\n",
            "          2.7899e-01,  1.8175e+00],\n",
            "        [-1.2077e+00, -1.6728e+00, -5.3400e+00,  ..., -4.0902e+00,\n",
            "         -5.2002e-03, -1.3310e+00],\n",
            "        ...,\n",
            "        [-1.2410e+00, -1.2330e+00, -3.9426e+00,  ...,  2.2643e-01,\n",
            "          2.5877e+00,  2.1640e+00],\n",
            "        [ 1.0058e+00,  5.6502e+00, -6.0421e+00,  ...,  2.8639e-01,\n",
            "         -1.1563e+00, -1.3369e+00],\n",
            "        [-2.7115e-01, -1.8695e+00, -2.7639e+00,  ..., -2.3008e-02,\n",
            "          2.8168e+00, -5.8385e-02]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9317, -2.7249, -7.1886,  ..., -0.1553,  0.2823, -0.8993],\n",
            "        [ 1.9626,  2.5680, -4.1512,  ...,  0.2695, -1.5521, -0.7190],\n",
            "        [-0.2125, -1.1958, -5.0488,  ..., -3.0909,  2.1924, -0.3261],\n",
            "        ...,\n",
            "        [ 1.5026,  0.5110, -3.1988,  ..., -0.5772,  3.0607, -1.8328],\n",
            "        [ 1.8466,  4.2813, -2.5506,  ..., -0.3296,  1.9568, -1.4459],\n",
            "        [ 0.0805,  2.7682, -2.6764,  ..., -0.8069,  0.3978, -0.2435]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0623, -2.4204, -4.0590,  ..., -1.6396, -1.5175, -1.0613],\n",
            "        [ 1.4447, -2.7693, -4.6627,  ..., -1.2231, -3.6337, -3.0579],\n",
            "        [-0.4075,  1.1756, -4.8914,  ..., -2.2429,  2.5279,  3.1763],\n",
            "        ...,\n",
            "        [-0.2134, -2.6233, -6.5015,  ..., -3.0158,  0.9957, -0.5723],\n",
            "        [-3.3704, -0.1918, -2.8892,  ..., -2.8505,  2.5784,  0.8748],\n",
            "        [ 3.4098,  0.6424, -4.5920,  ...,  3.3735,  0.2495, -2.2554]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5887,  1.6059, -2.9863,  ...,  2.0874, -4.0939, -1.2635],\n",
            "        [-1.6341, -2.1602, -5.8159,  ..., -2.8867, -0.8554, -2.2515],\n",
            "        [ 2.2212, -1.5815, -3.1864,  ...,  1.0019,  2.5520, -1.4003],\n",
            "        ...,\n",
            "        [ 1.3197,  0.9959, -4.4393,  ..., -1.7000,  1.4568, -1.0218],\n",
            "        [ 0.5699, -2.0487, -3.8407,  ..., -4.0366,  1.1525, -2.8929],\n",
            "        [-0.9248, -3.6467, -5.7995,  ...,  0.3914,  4.3726,  4.1760]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0764, -3.7351, -3.4999,  ..., -0.0152,  1.2999,  1.2574],\n",
            "        [-1.6239,  0.5571, -2.9841,  ...,  4.3672, -1.9570,  1.4780],\n",
            "        [ 0.7094, -2.9291, -5.7878,  ..., -0.9512,  3.7304,  1.6906],\n",
            "        ...,\n",
            "        [-0.5030,  1.9580, -4.3013,  ...,  0.5234, -0.2972,  0.6214],\n",
            "        [-1.9131, -4.4026, -5.3110,  ..., -2.8862, -2.9021, -2.9550],\n",
            "        [-1.1452, -3.0093, -4.0291,  ..., -2.8584,  3.7325,  0.3399]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-3.2237, -0.9461, -2.9832,  ...,  0.9943,  1.9565,  3.8413],\n",
            "        [ 0.6160, -4.0004, -5.7442,  ..., -0.3622,  4.5039,  1.6448],\n",
            "        [ 3.0295, -0.1183, -3.7486,  ..., -2.8170, -1.4451, -1.8592],\n",
            "        ...,\n",
            "        [-2.0848, -1.3425, -3.0107,  ...,  2.5331,  0.2018,  3.0477],\n",
            "        [-0.7102, -2.7189, -5.0124,  ..., -4.8430, -2.0175, -2.0626],\n",
            "        [-0.2868,  4.3048, -5.1758,  ..., -3.2110, -1.1803, -0.6729]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7359, -1.4611, -4.5484,  ..., -1.6422,  2.0261, -0.5195],\n",
            "        [-0.7925,  0.0491, -3.0232,  ...,  0.8442,  1.2243,  0.6598],\n",
            "        [-1.2556, -3.6106, -4.3904,  ..., -1.9357,  2.2300,  0.6374],\n",
            "        ...,\n",
            "        [-0.1449,  0.6117, -4.2952,  ..., -2.3115,  2.2367,  0.4881],\n",
            "        [ 3.5660, -0.5495, -3.8058,  ..., -2.1524,  1.5203, -3.6489],\n",
            "        [ 2.6436, -1.8179, -5.0306,  ..., -1.2694, -0.6041, -2.1585]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4270, -1.6858, -5.7079,  ..., -3.7477, -0.0736, -1.8323],\n",
            "        [-1.3445, -4.1440, -4.8002,  ..., -1.1056,  3.4027,  0.7478],\n",
            "        [-1.6730,  0.9026, -3.3590,  ...,  0.6700,  0.1199,  0.7640],\n",
            "        ...,\n",
            "        [-1.6819,  0.5438, -4.4268,  ..., -1.8333, -0.2263,  0.3005],\n",
            "        [ 1.0569,  0.9539, -4.7627,  ..., -3.9366,  2.5901, -1.1021],\n",
            "        [-3.3065, -2.9869, -3.7546,  ...,  0.5074,  4.2610,  3.1319]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3011, -5.3856, -5.2575,  ..., -4.8708, -2.2723, -3.0820],\n",
            "        [-0.4471, -3.9503, -4.9625,  ..., -2.3276,  2.5737,  1.0007],\n",
            "        [-2.2475, -1.9752, -3.5136,  ...,  0.5534,  3.1892,  1.9446],\n",
            "        ...,\n",
            "        [ 2.1095,  0.0130, -3.6515,  ..., -0.7153, -0.0326, -1.8849],\n",
            "        [ 4.2935, -2.7019, -5.2257,  ..., -2.5681, -3.7013, -3.8535],\n",
            "        [ 0.4243, -1.1635, -4.5114,  ..., -4.5780, -1.5716, -2.1012]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.4823, -1.6231, -6.1359,  ..., -2.6403,  2.6291,  1.4147],\n",
            "        [ 0.3898, -1.2233, -3.0402,  ..., -0.5495,  2.4148, -1.2835],\n",
            "        [ 1.9907,  0.9060, -3.7699,  ...,  1.6706,  1.0175, -3.3722],\n",
            "        ...,\n",
            "        [ 1.2551,  1.6986, -5.8525,  ..., -1.1397,  1.6043,  0.3913],\n",
            "        [ 1.5198,  1.5625, -3.8308,  ..., -1.5436,  3.2059,  0.6202],\n",
            "        [ 0.2544, -2.1015, -4.5426,  ...,  1.0343,  3.2353,  1.5707]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0878,  1.8334, -3.3156,  ...,  2.7375,  0.7546,  1.8568],\n",
            "        [ 0.6745, -2.2646, -2.9492,  ..., -1.2684,  4.0219,  0.7117],\n",
            "        [ 1.3314,  1.1849, -3.5514,  ...,  1.0062,  0.4686, -1.4500],\n",
            "        ...,\n",
            "        [ 5.0802,  2.8349, -2.7560,  ..., -3.3913, -0.3592, -6.7669],\n",
            "        [-1.4609, -0.5563, -2.6386,  ...,  2.3875,  0.3086,  3.6430],\n",
            "        [ 0.3504,  0.4988, -4.9841,  ...,  0.3149,  2.5788,  3.4936]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0928,  2.1700, -2.7360,  ..., -1.0135,  1.7747,  0.9845],\n",
            "        [ 1.6950, -2.2276, -4.3869,  ..., -2.3028,  1.2253,  0.4623],\n",
            "        [-3.5646, -3.1833, -5.4224,  ..., -4.8228, -2.1119, -2.8285],\n",
            "        ...,\n",
            "        [-2.0302, -0.1750, -3.1662,  ..., -0.3678,  2.4825,  2.3369],\n",
            "        [ 1.1678,  2.3356, -3.8715,  ..., -3.6209,  0.7183, -2.3103],\n",
            "        [-1.5790, -1.3919, -1.9334,  ...,  2.0485, -0.5792,  0.3842]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7823, -0.0268, -3.9119,  ...,  0.5991,  2.1919,  4.1649],\n",
            "        [ 0.7053, -1.7204, -4.6094,  ...,  0.3273,  0.2619, -0.5892],\n",
            "        [ 0.3794, -2.4746, -6.5990,  ..., -2.5977,  1.5245, -1.7620],\n",
            "        ...,\n",
            "        [ 3.3761, -0.6887, -4.6389,  ...,  0.2055, -0.7122, -2.4050],\n",
            "        [-1.5813, -3.6999, -6.2889,  ..., -2.9893, -1.8785, -0.7809],\n",
            "        [-1.1138, -3.7135, -3.6715,  ..., -2.0127,  3.9212,  2.2004]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.3469,  1.1923, -4.8996,  ...,  0.8487, -0.1662, -0.6406],\n",
            "        [ 0.8371, -0.4444, -3.5803,  ...,  1.2736,  1.7338,  1.2521],\n",
            "        [ 0.1713, -3.4895, -3.0407,  ...,  1.1504,  2.4553,  1.0205],\n",
            "        ...,\n",
            "        [-2.6330, -1.0106, -4.9283,  ...,  0.2279,  2.0409,  1.2280],\n",
            "        [ 2.9170,  0.9804, -3.5363,  ..., -2.4397,  0.9960, -2.6780],\n",
            "        [ 2.4945,  0.0229, -7.3970,  ..., -1.6435, -0.6947, -3.3353]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4775, -5.0694, -4.0122,  ..., -1.7612,  3.6984,  0.7608],\n",
            "        [ 2.6622,  0.2399, -3.4891,  ..., -2.0772, -0.9753, -1.2724],\n",
            "        [-0.9502, -1.8718, -5.7672,  ..., -0.2030,  1.4260,  0.2450],\n",
            "        ...,\n",
            "        [-3.3901, -4.9891, -6.1581,  ..., -5.6885, -1.3808, -1.6124],\n",
            "        [ 0.1610, -0.0640, -1.7753,  ..., -2.1995,  4.6823,  2.5553],\n",
            "        [-0.8188, -1.8277, -3.2101,  ...,  2.4474, -2.3697, -0.0767]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0693, -1.6150, -3.5484,  ...,  0.7056,  3.1697,  1.2129],\n",
            "        [-1.2717, -4.0895, -3.5605,  ...,  1.0719,  3.4849,  2.8347],\n",
            "        [ 1.0243, -0.8224, -4.1067,  ..., -0.1100,  5.0995, -0.8435],\n",
            "        ...,\n",
            "        [ 0.3305, -2.7541, -5.0499,  ..., -2.4977,  0.6758,  0.9509],\n",
            "        [-0.4638, -1.5669, -5.6570,  ..., -0.7838,  0.3702,  1.3897],\n",
            "        [ 0.6832, -2.6222, -5.0380,  ..., -2.2588, -0.9337, -3.3414]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3208,  0.1702, -5.0725,  ..., -6.2581,  2.6672, -0.3111],\n",
            "        [ 2.3159,  3.0171, -4.8188,  ..., -1.3523, -0.8357, -4.6186],\n",
            "        [ 0.0546, -4.2599, -4.0473,  ...,  1.5279,  1.1637,  1.6681],\n",
            "        ...,\n",
            "        [ 2.0827, -0.5311, -4.3609,  ...,  1.3410,  2.3375, -1.0028],\n",
            "        [-3.1544, -3.0386, -4.2863,  ..., -0.9651, -1.1400, -2.1644],\n",
            "        [-1.4817, -4.0790, -5.9264,  ..., -1.0105, -1.1032, -1.1887]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0993, -0.4427, -4.5793,  ..., -2.0489,  1.8425, -0.2539],\n",
            "        [ 2.9977,  3.7314, -2.0934,  ...,  1.4923, -0.2827, -2.3206],\n",
            "        [-2.8618,  0.2854, -4.3090,  ..., -3.5587,  1.0218,  0.8826],\n",
            "        ...,\n",
            "        [ 0.9878,  0.3295, -5.1016,  ...,  0.5971,  2.3192,  0.4446],\n",
            "        [-0.5061, -2.7051, -4.9253,  ..., -1.2504,  4.4985,  4.5231],\n",
            "        [-0.0404,  0.0905, -5.2811,  ...,  0.4578,  1.5823, -1.2113]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.2414,  0.9926, -4.5555,  ..., -0.4101, -2.6736, -2.6032],\n",
            "        [ 0.6726,  3.4578, -4.6115,  ..., -1.1975,  0.0143, -1.2761],\n",
            "        [-0.4528, -3.4571, -4.7928,  ..., -5.6639,  0.2539, -1.4188],\n",
            "        ...,\n",
            "        [ 0.9802,  1.0517, -5.0383,  ..., -1.3610, -1.1085, -3.6373],\n",
            "        [ 2.8096, -3.6298, -5.4600,  ..., -0.4553, -4.9829, -1.5184],\n",
            "        [ 0.0850,  1.5803, -2.9539,  ..., -0.7944, -0.1109, -1.6442]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7606, -3.4582, -5.9711,  ..., -4.1506,  4.9598,  4.0849],\n",
            "        [-0.5793,  0.8590, -1.8325,  ...,  1.0315,  0.4800,  3.4357],\n",
            "        [ 0.0791, -3.4437, -6.9453,  ..., -5.1965, -3.4550, -3.0425],\n",
            "        ...,\n",
            "        [ 2.7163, -2.4875, -4.9906,  ..., -3.1131, -3.7680, -4.8673],\n",
            "        [-0.6761,  0.6106, -4.6070,  ...,  2.7431, -2.3931,  2.3974],\n",
            "        [-0.6329, -0.3507, -2.9027,  ...,  2.3503, -1.7296,  2.3197]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3769, -2.0491, -3.4153,  ...,  0.2781,  3.5548,  0.2898],\n",
            "        [ 1.3373,  1.8497, -2.7831,  ..., -0.7597,  2.5679,  0.5568],\n",
            "        [ 0.5064,  1.2236, -5.1509,  ..., -0.8360,  0.2943,  0.7590],\n",
            "        ...,\n",
            "        [-1.0875,  2.8902, -3.4380,  ..., -1.2920, -1.1659, -0.3936],\n",
            "        [ 2.0801,  1.0407, -3.8269,  ..., -0.1404,  0.5195, -2.1597],\n",
            "        [ 0.7568, -2.2190, -3.4428,  ...,  2.3209, -3.5295, -2.1802]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7197,  0.1286, -2.5349,  ..., -0.8326,  2.8591,  0.2084],\n",
            "        [ 5.2247, -1.0551, -5.6609,  ..., -2.9677, -4.8873, -4.6581],\n",
            "        [ 0.9361, -3.0228, -4.6236,  ...,  2.1258,  0.0929,  1.4583],\n",
            "        ...,\n",
            "        [-2.2142, -0.8761, -4.8986,  ..., -3.6699,  2.5763,  3.9930],\n",
            "        [ 2.0008,  3.2184, -4.2471,  ..., -0.7105, -0.5697,  0.5297],\n",
            "        [-0.7354,  1.0258, -3.0577,  ..., -3.6485,  3.8344,  1.4156]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6897, -2.8282, -4.4561,  ..., -1.1726,  4.3993,  2.8056],\n",
            "        [ 0.0053, -2.6239, -4.5387,  ...,  0.4669,  3.2355,  1.8353],\n",
            "        [-0.7146, -3.1721, -4.3861,  ..., -0.3915,  1.8183,  1.1006],\n",
            "        ...,\n",
            "        [ 4.8196,  2.9118, -3.6244,  ..., -0.3663, -0.8588, -4.3426],\n",
            "        [ 1.9648, -2.9490, -3.9863,  ..., -0.1257,  1.6681,  0.6537],\n",
            "        [-1.6869, -0.4887, -2.8551,  ...,  0.2681,  1.3188,  2.8830]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5545,  0.8979, -1.8797,  ..., -0.3539,  0.2692, -1.6886],\n",
            "        [-1.7090, -1.5440, -7.3460,  ..., -1.4094,  1.2346,  1.9076],\n",
            "        [ 1.3497,  1.7469, -5.1782,  ..., -0.7712, -2.3215, -2.6303],\n",
            "        ...,\n",
            "        [ 1.2464,  0.8363, -5.6291,  ...,  0.7042,  0.9077, -0.7504],\n",
            "        [ 3.2801,  1.8227, -2.9534,  ...,  0.2217, -0.9367, -2.8174],\n",
            "        [ 2.5528,  0.2490, -3.2398,  ...,  0.1272, -2.2711, -2.3705]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.8152, -0.9378, -5.2427,  ..., -3.8350, -1.0516,  0.0499],\n",
            "        [ 4.3265,  4.6613, -4.8452,  ..., -2.5728, -5.1639, -2.7106],\n",
            "        [-1.0228, -4.0369, -6.5199,  ..., -5.1204,  1.0653, -0.4621],\n",
            "        ...,\n",
            "        [ 3.0080,  0.6992, -6.8341,  ..., -0.7993,  1.0491, -0.9976],\n",
            "        [ 2.1707,  4.3543, -4.6321,  ..., -0.8412,  0.1369,  0.6735],\n",
            "        [ 0.9947,  3.1688, -4.5604,  ..., -1.6221, -0.6987, -0.7436]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0876, -0.0326, -4.9153,  ..., -5.0702, -1.6013, -2.1397],\n",
            "        [-2.1620, -1.9256, -6.1278,  ..., -4.4742, -0.0720, -1.0298],\n",
            "        [ 0.4054,  0.3291, -7.2644,  ..., -5.6872, -0.5616, -1.4168],\n",
            "        ...,\n",
            "        [ 6.3810,  3.6964, -4.1373,  ..., -2.2006, -1.8032, -8.0069],\n",
            "        [-2.7806, -1.3814, -6.3040,  ..., -6.8914, -1.2366, -0.7068],\n",
            "        [ 1.0376, -0.0988, -4.0359,  ..., -1.8305,  1.8178, -0.7873]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6399, -2.7194, -6.3237,  ..., -2.4103, -2.3947,  0.2810],\n",
            "        [ 1.1794, -0.0730, -4.7939,  ..., -2.5986, -0.9440,  2.1444],\n",
            "        [ 2.3368, -1.7464, -4.8371,  ..., -2.5112, -0.2793,  0.5770],\n",
            "        ...,\n",
            "        [-1.6190, -0.6522, -3.2217,  ..., -1.3384,  2.5683,  1.5495],\n",
            "        [ 1.0091,  3.0447, -2.0540,  ..., -2.3896, -0.0444, -1.0255],\n",
            "        [ 2.2797, -1.0623, -4.0742,  ..., -2.2148, -0.4045, -2.8080]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3898, -2.9189, -7.2703,  ..., -3.1480, -2.0562, -1.2954],\n",
            "        [-1.8739, -4.1903, -4.9656,  ..., -5.6564, -2.0782, -3.1155],\n",
            "        [ 0.3526, -3.5358, -5.0090,  ..., -3.7139,  1.8326,  2.9124],\n",
            "        ...,\n",
            "        [ 2.7866, -1.3748, -4.6395,  ..., -2.8609, -1.7635, -3.0249],\n",
            "        [ 2.7713,  3.7801, -2.9769,  ...,  0.7448, -0.3523, -0.7309],\n",
            "        [ 0.4851, -5.0224, -4.6487,  ..., -1.3040,  1.5071,  1.3683]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9442, -2.9114, -3.5318,  ...,  1.6516, -4.4463, -0.7601],\n",
            "        [ 1.1016,  1.5689, -3.8376,  ..., -1.7093,  1.2707, -0.7257],\n",
            "        [-0.7617, -2.1977, -4.3986,  ...,  0.0130,  2.6325,  3.2116],\n",
            "        ...,\n",
            "        [ 0.5856, -0.0709, -6.8222,  ..., -1.5807,  1.2022,  2.0980],\n",
            "        [ 1.8089,  0.7020, -4.3135,  ..., -0.7290,  0.4733, -1.5971],\n",
            "        [ 1.6913,  1.6981, -4.3028,  ..., -0.8566,  2.1290,  1.3379]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0607,  3.5327, -3.8618,  ...,  1.0489, -0.3723, -0.0719],\n",
            "        [-0.6687,  1.6909, -2.7195,  ..., -1.1306,  2.1089, -1.9789],\n",
            "        [ 0.6357, -2.0081, -2.1087,  ...,  0.9394, -3.9612,  0.3959],\n",
            "        ...,\n",
            "        [ 1.3914,  2.7436, -3.8290,  ..., -2.0297,  0.3668, -2.6194],\n",
            "        [ 0.3705, -2.7738, -5.1487,  ...,  0.3489,  2.1266,  2.3158],\n",
            "        [-0.1886, -3.4119, -6.3463,  ..., -0.5843,  0.3085, -0.0524]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1162, -1.9001, -4.0669,  ..., -3.8918,  2.3828,  3.0224],\n",
            "        [ 2.1430,  2.4817, -3.2900,  ..., -2.9509,  1.4235, -3.0630],\n",
            "        [ 3.1209, -3.2955, -5.5857,  ..., -1.7810, -1.0837, -0.3817],\n",
            "        ...,\n",
            "        [ 1.4234,  0.8364, -3.4925,  ...,  1.7071,  1.6051, -0.2890],\n",
            "        [ 0.4202, -0.9053, -4.9841,  ...,  1.1368,  1.1105,  1.1889],\n",
            "        [-0.3512,  2.2268, -3.2750,  ...,  0.2817,  1.5899,  1.4500]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9802, -0.6207, -2.8045,  ..., -0.0637,  2.8254,  2.7563],\n",
            "        [-2.3977, -1.9115, -3.8199,  ..., -4.4706,  2.6481,  1.3695],\n",
            "        [-3.7062, -0.8393, -5.8236,  ..., -3.4277, -1.9303, -0.9758],\n",
            "        ...,\n",
            "        [-1.2035,  2.1348, -2.3403,  ..., -0.6185, -0.7495, -1.0826],\n",
            "        [-3.4242, -0.7631, -2.0477,  ...,  0.8559,  2.5720,  4.1985],\n",
            "        [ 0.3011, -0.3242, -3.1329,  ..., -2.9056, -1.3177, -2.0821]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.3705,  0.5846, -4.0571,  ..., -2.3752,  1.1562, -0.4629],\n",
            "        [-1.5637,  2.9892, -1.8121,  ..., -1.1304, -1.3884, -3.4369],\n",
            "        [-1.0619, -0.7034, -3.1804,  ...,  1.1398,  0.4474, -1.2285],\n",
            "        ...,\n",
            "        [-1.1161, -3.5785, -4.6971,  ..., -0.1126,  2.6357,  3.3655],\n",
            "        [-2.2105, -0.4671, -4.1201,  ..., -2.7951,  0.0631,  0.4604],\n",
            "        [ 2.8456,  1.7480, -5.2764,  ..., -1.0694,  1.3819, -1.9429]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.1891, -2.9722, -6.3727,  ..., -3.8442,  1.7612, -0.1993],\n",
            "        [ 1.2328,  2.2938, -5.5568,  ...,  0.2208,  0.6707, -1.2120],\n",
            "        [-0.9606, -0.9883, -4.5040,  ..., -3.0421, -2.0705, -1.4236],\n",
            "        ...,\n",
            "        [ 3.6448, -0.3138, -5.4014,  ..., -1.8402, -3.8539, -4.0814],\n",
            "        [ 2.5789,  0.3310, -4.6180,  ..., -4.9000, -2.4817, -2.2100],\n",
            "        [-0.9000, -4.4283, -5.8568,  ..., -2.0697, -0.3440,  1.0058]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0773, -1.3578, -4.8761,  ..., -0.2945,  2.1179,  2.5586],\n",
            "        [-0.3663,  1.6370, -3.1180,  ...,  1.6082, -0.6064, -0.3780],\n",
            "        [ 1.5254,  0.0428, -3.1100,  ...,  0.7268,  0.0405, -0.9616],\n",
            "        ...,\n",
            "        [-1.1124, -3.8199, -5.3711,  ..., -5.5206, -2.0618,  0.0935],\n",
            "        [-1.5105, -2.9022, -4.8160,  ..., -3.5314,  3.3828,  2.4769],\n",
            "        [-1.2958,  1.6310, -3.2989,  ..., -2.3074,  1.2757,  1.7331]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.6248, -4.1539, -5.1317,  ..., -0.8796,  3.9425,  3.0500],\n",
            "        [ 2.5230, -1.1397, -5.6063,  ..., -1.3036, -2.9937, -1.4802],\n",
            "        [-0.4777, -1.5417, -3.9115,  ...,  1.1882,  1.8162,  2.0737],\n",
            "        ...,\n",
            "        [ 0.3698,  1.6007, -3.2018,  ...,  1.5549,  0.6297,  3.6683],\n",
            "        [ 2.1493, -4.2894, -4.7113,  ..., -0.4013, -4.7404, -2.2972],\n",
            "        [ 1.6973, -0.9140, -4.2571,  ...,  0.3291,  1.1334, -0.1211]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4940, -1.5012, -5.4093,  ..., -2.9499, -1.3927, -0.6416],\n",
            "        [ 1.4960, -0.1865, -3.9135,  ..., -2.4133, -0.7504, -1.8542],\n",
            "        [-1.1333, -2.7288, -2.9810,  ..., -2.8020,  0.5345, -1.0796],\n",
            "        ...,\n",
            "        [-0.6926,  2.2303, -0.7632,  ...,  0.5327,  0.5976,  1.6398],\n",
            "        [-2.3988, -0.2403, -3.1486,  ..., -0.0750,  1.4878,  2.8688],\n",
            "        [ 4.0758, -0.8467, -5.0421,  ..., -3.0870, -5.5133, -6.6059]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7893, -1.7680, -5.1536,  ...,  0.2723, -0.8498,  2.6567],\n",
            "        [ 3.9383,  1.7509, -4.8102,  ..., -2.1010, -2.5853, -1.9137],\n",
            "        [-1.1640, -6.6637, -4.2020,  ..., -0.6622,  3.7868,  3.8492],\n",
            "        ...,\n",
            "        [ 0.1017, -2.2233, -6.3177,  ...,  0.0659,  2.2573,  3.5343],\n",
            "        [ 0.3177, -1.7629, -4.7018,  ...,  0.4386,  2.3338,  2.0054],\n",
            "        [ 1.1106,  3.2739, -4.5235,  ..., -0.2063,  0.2270, -0.5813]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.3911, -0.6337, -6.4651,  ..., -4.4883, -3.0491, -2.3220],\n",
            "        [ 3.0156, -0.2804, -6.4719,  ..., -2.7256, -4.4671, -2.8878],\n",
            "        [-0.4805, -5.4850, -4.3708,  ..., -3.2962, -3.4118, -1.2374],\n",
            "        ...,\n",
            "        [-0.6106, -3.1867, -4.0366,  ..., -2.5967,  2.2996,  1.6834],\n",
            "        [ 0.1588, -3.7192, -5.6247,  ...,  0.2099,  0.0761,  1.9111],\n",
            "        [ 1.1483, -2.9024, -3.5998,  ...,  1.5585,  0.0536,  0.8264]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.1659, -3.0104, -6.0654,  ..., -6.2630, -0.6849, -1.9672],\n",
            "        [-1.6278, -3.5041, -5.8663,  ..., -3.2300,  0.4115,  2.1677],\n",
            "        [-0.0203, -4.7935, -6.6184,  ..., -0.1471,  2.3873,  4.7166],\n",
            "        ...,\n",
            "        [-1.4497, -0.6536, -3.2015,  ...,  3.0533, -2.0085,  4.3253],\n",
            "        [-2.1490, -0.7799, -6.3144,  ..., -4.7936, -2.3767, -1.5925],\n",
            "        [-1.1268, -3.4398, -3.9347,  ..., -2.1144,  1.6818,  2.2731]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3903, -4.4771, -6.8448,  ..., -1.3072, -3.0677,  0.8114],\n",
            "        [-0.3038, -1.5818, -3.5516,  ..., -2.6683, -1.5748,  1.2918],\n",
            "        [ 0.4364,  0.9586, -3.1794,  ..., -2.1405,  0.3784, -1.0300],\n",
            "        ...,\n",
            "        [ 1.1172, -2.5459, -4.4526,  ..., -0.0483, -0.9456, -0.1829],\n",
            "        [ 1.7665,  0.2750, -3.8379,  ...,  0.5587, -1.5569,  0.5549],\n",
            "        [-1.8420, -0.6718, -4.2303,  ..., -4.4886,  0.9457,  2.1303]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3882,  0.9430, -3.0188,  ..., -1.2478,  1.0622, -0.4483],\n",
            "        [-0.2767, -2.1673, -3.6772,  ...,  0.8410,  2.7698,  3.2723],\n",
            "        [-0.0994,  2.3424, -3.5161,  ...,  0.2104, -0.5167,  1.6392],\n",
            "        ...,\n",
            "        [-2.5039, -2.7945, -7.1735,  ..., -2.2534, -0.7232,  0.9435],\n",
            "        [ 1.3696,  0.8840, -3.5126,  ..., -0.2503,  1.6441,  1.1363],\n",
            "        [ 0.6682,  0.6435, -3.8331,  ..., -2.5586,  0.2175, -0.0813]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6679,  0.6573, -4.5562,  ...,  3.3261,  0.3467,  0.5737],\n",
            "        [-2.5856, -5.4676, -6.4255,  ..., -5.0590,  0.3951,  0.3916],\n",
            "        [-1.1066, -0.7702, -3.2535,  ...,  0.8787,  1.8408,  1.9578],\n",
            "        ...,\n",
            "        [ 0.2090, -2.7219, -6.1948,  ..., -2.0941,  0.2449,  1.9604],\n",
            "        [-1.8336, -1.5672, -3.1943,  ..., -0.8693,  4.6423,  2.1962],\n",
            "        [ 4.0840,  2.1011, -5.5988,  ..., -0.6329,  1.1798, -2.1359]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6154, -3.1025, -2.6851,  ...,  0.6749,  3.0199,  2.3586],\n",
            "        [-1.2760, -1.4759, -1.6618,  ..., -3.8685, -2.3038, -1.9467],\n",
            "        [-3.9495, -2.8134, -3.6147,  ...,  2.2089,  2.8043,  3.9045],\n",
            "        ...,\n",
            "        [ 2.6954,  0.3071, -5.7122,  ..., -3.8270, -4.5935, -4.7648],\n",
            "        [-0.5877, -1.2997, -5.1440,  ...,  0.0819,  1.1144,  3.3111],\n",
            "        [-1.6262,  2.7681, -1.7645,  ..., -0.9258, -0.7957,  0.7402]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7132, -1.3908, -4.3512,  ...,  1.0817,  1.9330,  3.2871],\n",
            "        [-1.0064,  1.8350, -4.0396,  ...,  0.4104, -1.0507,  0.0605],\n",
            "        [ 0.9275, -0.6153, -7.6658,  ..., -3.0223, -0.5661,  0.2786],\n",
            "        ...,\n",
            "        [-0.8205, -3.4609, -5.2065,  ..., -0.1214,  2.3995,  3.5448],\n",
            "        [ 0.6242,  0.0968, -2.7274,  ..., -2.9949, -0.1327, -0.7497],\n",
            "        [-0.4610, -3.3501, -4.8760,  ..., -2.7239, -1.0843, -0.7809]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.6675,  0.0835, -4.8708,  ..., -2.4876, -1.6828, -0.5333],\n",
            "        [-0.7348,  2.2085, -3.7615,  ...,  1.5667,  0.6727,  2.3458],\n",
            "        [ 2.6048, -0.4815, -4.6672,  ..., -0.8347, -1.2926, -2.5184],\n",
            "        ...,\n",
            "        [-3.9092,  0.9406, -4.2262,  ..., -3.4842,  1.4168,  0.5931],\n",
            "        [-0.3030,  2.8456, -3.7990,  ...,  0.4083, -0.6152, -1.1679],\n",
            "        [-0.3675,  0.2957, -4.7364,  ..., -3.1108, -0.5491, -1.0339]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5104, -0.0576, -4.6388,  ...,  1.0239, -5.0960, -3.9930],\n",
            "        [ 0.9845, -2.4219, -3.5654,  ..., -2.9725,  1.1999, -0.6491],\n",
            "        [-2.7924, -0.9720, -1.6474,  ...,  1.1918,  1.9627,  3.7986],\n",
            "        ...,\n",
            "        [ 1.0096, -0.8697, -4.7835,  ...,  2.4991, -1.9081, -1.6844],\n",
            "        [ 1.5320,  1.1475, -3.1185,  ...,  0.4290, -0.0999, -1.6854],\n",
            "        [ 0.2770, -1.7328, -3.6915,  ..., -2.3898,  1.4109,  0.6534]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0381, -0.6763, -4.1781,  ..., -1.0626,  1.4323, -0.2516],\n",
            "        [-2.2564, -0.8775, -2.7684,  ..., -1.0716,  2.5652,  1.4034],\n",
            "        [-0.2534, -2.7424, -2.1926,  ..., -1.8466,  2.2606,  1.1357],\n",
            "        ...,\n",
            "        [ 0.5544, -2.6512, -4.7141,  ..., -4.0895, -2.2808, -3.1894],\n",
            "        [-1.0721, -1.0659, -3.8272,  ..., -0.8742,  1.3025,  0.5802],\n",
            "        [-0.8524,  2.9151, -2.7677,  ...,  0.2005, -0.7494, -3.1476]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 6.7063e-01,  4.7832e-01, -4.1733e+00,  ..., -3.0790e+00,\n",
            "          2.9364e-03, -3.4276e+00],\n",
            "        [ 3.5850e+00,  2.5196e+00, -3.5036e+00,  ..., -4.3158e+00,\n",
            "         -9.8904e-04, -5.0411e+00],\n",
            "        [ 3.4716e+00,  1.9795e+00, -3.4841e+00,  ...,  9.6158e-01,\n",
            "         -1.0924e+00, -2.6124e+00],\n",
            "        ...,\n",
            "        [ 7.8503e-01,  3.0258e+00, -3.9772e+00,  ..., -8.8384e-01,\n",
            "         -3.8279e-01, -1.4127e+00],\n",
            "        [ 4.1172e-01, -1.7466e-01, -6.1804e+00,  ..., -3.8756e+00,\n",
            "         -1.8084e-01,  9.9295e-01],\n",
            "        [-9.1621e-01,  6.3243e-01, -5.3907e+00,  ..., -4.6562e+00,\n",
            "          6.8690e-01,  7.3418e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3659,  2.4098, -3.1410,  ...,  0.1998,  0.0448, -0.7554],\n",
            "        [ 0.6566, -1.4146, -3.0114,  ...,  0.6543,  3.8530,  3.8206],\n",
            "        [ 0.2034, -4.3921, -6.4712,  ...,  0.5545,  2.9455,  3.6585],\n",
            "        ...,\n",
            "        [ 2.1297,  1.9934, -5.2566,  ...,  0.5354, -3.5115, -2.2162],\n",
            "        [ 3.3810,  1.5824, -2.6470,  ..., -2.4464,  0.9363, -2.0945],\n",
            "        [-1.0365,  1.4558, -3.0670,  ..., -0.2842, -0.7454,  2.3290]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2295,  4.5916, -3.6372,  ..., -0.2173, -0.6212, -1.8289],\n",
            "        [-1.5999, -1.6954, -4.4824,  ..., -1.8184,  3.3394,  3.1773],\n",
            "        [ 2.0222, -1.7777, -4.1962,  ...,  0.7030,  0.1972, -0.5896],\n",
            "        ...,\n",
            "        [-0.0402,  0.0663, -5.7170,  ..., -1.3972,  0.8580,  0.6324],\n",
            "        [ 0.2077, -4.0151, -5.9299,  ..., -2.0096, -3.3440, -3.9661],\n",
            "        [-1.8327, -3.2883, -7.6809,  ..., -1.7891, -0.7830, -3.2657]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3228, -2.4192, -4.7444,  ...,  1.1801,  2.8089,  1.7354],\n",
            "        [-1.3624, -0.3966, -2.9897,  ..., -1.1666,  4.6383,  1.8300],\n",
            "        [ 4.7502, -0.9856, -4.0963,  ...,  0.4998, -3.2095, -3.8734],\n",
            "        ...,\n",
            "        [-0.4902, -2.8291, -1.9368,  ..., -0.2755,  0.6455,  0.3543],\n",
            "        [ 0.0118, -4.5831, -6.7165,  ..., -2.1881, -5.5229, -3.9590],\n",
            "        [-1.0071,  1.6026, -2.7709,  ...,  1.1365,  0.0931,  0.5748]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3235,  1.3228, -3.7574,  ..., -0.2538,  0.4546, -1.6359],\n",
            "        [ 3.7315,  0.5686, -7.2290,  ..., -2.6994, -1.3862, -4.7101],\n",
            "        [ 2.6133,  0.4404, -4.1653,  ...,  0.3014,  1.3916, -3.4402],\n",
            "        ...,\n",
            "        [-0.9973, -0.7209, -5.6801,  ..., -2.2165, -0.5047, -1.6231],\n",
            "        [ 1.2720, -6.4943, -5.2194,  ..., -3.2741,  3.1050,  1.7335],\n",
            "        [-2.6645, -1.9716, -4.4835,  ..., -1.2416, -3.6885, -2.5971]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.8927,  0.3796, -4.0175,  ...,  1.7221,  0.2937, -1.6767],\n",
            "        [ 3.2853,  4.1701, -4.8131,  ..., -4.3452, -0.3372, -4.1779],\n",
            "        [-1.7483,  0.1049, -3.1855,  ...,  0.9020,  1.4217,  1.8929],\n",
            "        ...,\n",
            "        [ 1.8019, -1.3585, -3.1349,  ..., -2.5621,  0.8983, -1.4253],\n",
            "        [ 0.3932, -0.4577, -5.1015,  ...,  1.1600,  1.4595,  0.5376],\n",
            "        [-1.3036, -3.0011, -5.1343,  ...,  0.9622,  2.0234,  3.1065]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2013, -4.5483, -6.4239,  ...,  0.1541,  0.7875,  1.0750],\n",
            "        [-1.1438,  1.1193, -7.1028,  ..., -5.2626, -0.7388, -0.8892],\n",
            "        [ 1.4768,  2.1192, -1.8082,  ..., -4.0160, -0.3040, -3.5753],\n",
            "        ...,\n",
            "        [-1.9663,  0.7712, -2.3991,  ...,  2.6094,  0.3773,  0.2712],\n",
            "        [-0.4535,  0.0503, -3.4465,  ...,  1.6375,  0.9092,  1.9882],\n",
            "        [ 0.3941, -2.8964, -3.1492,  ...,  3.7972, -1.2597,  2.7314]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.7029,  1.6043, -5.9206,  ...,  0.8257,  0.6530, -2.8452],\n",
            "        [-1.9482, -2.5891, -4.5152,  ..., -0.9811, -0.0834, -3.5772],\n",
            "        [ 1.8387, -1.7432, -2.6964,  ...,  2.0639, -4.7528, -1.7298],\n",
            "        ...,\n",
            "        [-0.8004,  0.1874, -6.8420,  ..., -3.7109,  0.4859, -1.0330],\n",
            "        [ 1.4266, -0.2861, -4.6660,  ..., -3.6933,  0.2835, -3.1520],\n",
            "        [ 0.8856, -3.0936, -4.3086,  ...,  1.8208,  0.6498,  0.3865]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6543, -3.9143, -5.2455,  ...,  1.7401,  1.4313,  3.3373],\n",
            "        [ 0.1965, -2.0733, -5.0792,  ..., -2.3436, -2.9208, -2.6678],\n",
            "        [ 1.0997, -3.2175, -4.2476,  ..., -1.8106,  1.2457,  0.2202],\n",
            "        ...,\n",
            "        [ 0.3062, -2.4537, -3.7819,  ..., -2.3390,  3.0127,  0.9399],\n",
            "        [ 1.5755,  2.3833, -3.1108,  ..., -0.7087,  0.3016, -0.2232],\n",
            "        [ 0.5455, -1.6824, -3.3099,  ..., -1.1768,  1.2411,  0.1235]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5438,  1.9624, -2.4485,  ...,  0.7675, -2.6105, -2.7252],\n",
            "        [-1.3985, -2.8305, -4.0360,  ..., -1.9181, -1.6826, -2.3087],\n",
            "        [-1.2739, -2.3423, -4.5570,  ..., -3.1110,  1.8409,  0.7545],\n",
            "        ...,\n",
            "        [ 2.2764,  2.2850, -3.6016,  ..., -5.2034,  1.2420,  0.5257],\n",
            "        [ 0.0621, -4.8214, -5.7745,  ..., -4.9970,  4.4701,  3.0200],\n",
            "        [ 2.7482, -1.5236, -3.2861,  ...,  3.8852, -0.7477, -0.7533]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.4479,  2.5260, -3.1999,  ..., -0.1643, -0.9649, -2.2205],\n",
            "        [ 6.2699,  0.1644, -5.3546,  ..., -2.8341, -1.2706, -3.8732],\n",
            "        [ 1.3367, -2.6613, -6.5135,  ..., -1.5971,  2.9669,  2.2862],\n",
            "        ...,\n",
            "        [-2.2176, -1.3045, -1.8331,  ...,  0.7573,  2.2053,  2.2708],\n",
            "        [ 0.5123, -0.3128, -3.6572,  ..., -2.4357,  1.6363, -0.9480],\n",
            "        [ 4.0127,  1.8668, -3.5144,  ...,  0.0769, -0.3710, -3.3397]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.8504,  1.4160, -5.7677,  ...,  0.6352,  2.5443, -2.1380],\n",
            "        [-2.6166,  0.3266, -5.9210,  ..., -4.2856,  1.6704,  0.9146],\n",
            "        [-0.1290, -4.2142, -4.7018,  ..., -0.3396,  1.1395,  1.1200],\n",
            "        ...,\n",
            "        [-1.2829, -1.7896, -4.8009,  ...,  0.9583,  1.1872,  4.0774],\n",
            "        [ 0.5016, -1.3737, -3.0200,  ..., -3.5561,  0.2143, -1.8910],\n",
            "        [-3.3682, -1.8334, -4.4241,  ..., -3.9250,  0.8635,  1.5648]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.0575,  3.7920, -3.5530,  ...,  1.9429, -0.4805, -2.0723],\n",
            "        [ 0.3831,  2.1597, -5.6420,  ..., -1.5395, -1.5967, -0.8739],\n",
            "        [-0.7074, -1.1697, -3.2218,  ..., -0.8364,  0.8472,  3.1414],\n",
            "        ...,\n",
            "        [ 1.6707, -4.1205, -6.5529,  ..., -0.1420,  0.4667,  1.3540],\n",
            "        [-2.2163, -0.8044, -4.3318,  ...,  3.5948, -2.9995,  2.0474],\n",
            "        [ 0.2732, -1.0183, -6.1976,  ..., -3.1021,  0.9445,  2.0178]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2593, -2.8317, -5.0408,  ...,  0.8860,  1.8733,  2.5534],\n",
            "        [ 0.3016, -0.1651, -3.1980,  ..., -4.1604,  0.7965,  1.3789],\n",
            "        [-0.5230,  2.4641, -2.9477,  ..., -2.7737,  0.2977, -1.6931],\n",
            "        ...,\n",
            "        [-3.2434, -0.2782, -4.4184,  ..., -4.1270, -1.0136, -1.7948],\n",
            "        [ 2.0125, -1.6224, -5.8316,  ..., -2.2876, -0.8429, -2.7499],\n",
            "        [ 1.7017, -4.7953, -6.8031,  ..., -5.0680,  0.3128, -2.9465]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.2118, -2.5604, -4.4093,  ..., -2.4673,  2.8803,  3.1424],\n",
            "        [ 0.9280, -3.7866, -4.7103,  ..., -1.7308,  0.8179,  0.8533],\n",
            "        [ 1.1356,  1.8012, -4.3139,  ..., -5.1051,  0.0541, -3.0233],\n",
            "        ...,\n",
            "        [ 1.2762, -0.0346, -4.5003,  ..., -0.1491,  0.5424,  1.0981],\n",
            "        [ 1.7031, -1.8333, -6.0321,  ..., -5.1532, -2.6868, -5.9385],\n",
            "        [ 4.7356,  3.1060, -2.6147,  ..., -4.6661,  0.3060, -4.6043]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0523,  1.4412, -4.5664,  ..., -2.0155,  0.4759, -1.9638],\n",
            "        [ 1.9173,  2.1137, -3.8970,  ..., -0.7644, -4.5352, -0.9284],\n",
            "        [ 0.7517, -3.8226, -4.8745,  ..., -2.7511, -5.8239, -2.7530],\n",
            "        ...,\n",
            "        [ 0.9214, -3.1124, -6.1820,  ..., -1.1647,  0.7319,  2.4261],\n",
            "        [-0.6090, -1.5680, -5.2782,  ..., -2.6695,  2.5357,  2.9703],\n",
            "        [ 1.9976, -3.7919, -7.7994,  ..., -2.1967, -0.1439,  0.6431]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5222, -2.4322, -4.3155,  ..., -0.9747, -4.4770, -2.2026],\n",
            "        [-2.3976, -3.1744, -2.0867,  ..., -1.6878,  0.3610,  0.9850],\n",
            "        [-0.3708, -4.2231, -4.9504,  ..., -2.9677,  2.2970,  5.0913],\n",
            "        ...,\n",
            "        [ 0.6311,  0.7723, -1.7405,  ...,  2.8475,  0.6846,  0.6316],\n",
            "        [-0.9316, -0.6153, -1.2552,  ...,  0.2938,  1.8285,  0.6119],\n",
            "        [ 0.1099, -0.3102, -3.4830,  ...,  3.0801, -0.5346,  1.6608]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2403, -0.4684, -4.3822,  ..., -3.4710, -2.7051, -2.0056],\n",
            "        [-2.3624, -1.0313, -5.3053,  ..., -4.0642, -0.3588,  4.0053],\n",
            "        [ 0.2897, -4.7319, -2.2759,  ..., -0.5847,  2.9815,  0.8903],\n",
            "        ...,\n",
            "        [-1.5368, -2.0740, -5.4819,  ..., -3.6488, -1.4240, -1.2922],\n",
            "        [ 6.7193,  2.6362, -4.3265,  ..., -1.2299, -2.6155, -6.2768],\n",
            "        [-1.3441, -2.6055, -5.9418,  ..., -2.7623, -3.3705, -1.9021]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.2136, -4.2249, -3.2767,  ..., -1.7995,  0.4922, -0.3271],\n",
            "        [ 2.1896,  0.2645, -4.5569,  ..., -3.4167,  1.9306, -2.3535],\n",
            "        [ 2.6312,  3.9652, -3.0659,  ..., -0.0718, -0.8049, -1.4607],\n",
            "        ...,\n",
            "        [ 0.3740,  2.2537, -4.8636,  ...,  0.1144, -1.3208, -1.7928],\n",
            "        [ 1.1242, -0.4378, -6.9284,  ..., -5.0579, -1.2156, -0.6465],\n",
            "        [-2.0162,  0.5773, -2.6447,  ..., -0.7430,  0.6575, -0.2732]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0438e+00, -6.8076e-01, -3.9372e+00,  ...,  5.0072e-01,\n",
            "          1.5607e-02,  2.5940e-01],\n",
            "        [ 2.1136e+00,  1.9419e+00, -2.8745e+00,  ...,  2.1739e+00,\n",
            "         -2.7378e-03, -2.0947e+00],\n",
            "        [-1.1044e+00, -2.0865e+00, -3.3625e+00,  ..., -2.1210e+00,\n",
            "         -1.6950e+00, -1.4458e+00],\n",
            "        ...,\n",
            "        [ 8.6367e-01, -1.5507e+00, -4.0236e+00,  ..., -1.7559e+00,\n",
            "          3.5585e-01, -6.5554e-01],\n",
            "        [ 1.9364e+00, -1.6564e+00, -3.1625e+00,  ..., -1.3832e-01,\n",
            "          3.6223e+00, -1.0036e+00],\n",
            "        [-4.4319e-01, -2.4470e+00, -3.1298e+00,  ..., -4.1588e+00,\n",
            "         -4.3563e-01,  2.1032e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5700,  3.6804, -3.8629,  ...,  0.5789, -0.8819,  0.0997],\n",
            "        [-0.1856, -3.3947, -2.9800,  ..., -1.8385,  3.2096,  3.9775],\n",
            "        [-1.8654, -4.7105, -2.8767,  ..., -2.8434,  1.1312,  0.2756],\n",
            "        ...,\n",
            "        [-1.8620, -0.2394, -4.5661,  ..., -3.8027,  1.9768, -1.6177],\n",
            "        [ 1.3034,  0.7198, -4.6779,  ..., -3.9692,  1.7644,  2.1189],\n",
            "        [ 0.4335,  1.0744, -4.9237,  ..., -1.0408,  0.7702, -0.0323]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8385,  1.1294, -3.3748,  ...,  0.6568,  1.5926, -1.4669],\n",
            "        [ 2.2419, -0.4857, -5.8663,  ..., -6.9384, -3.9292, -5.3539],\n",
            "        [ 4.9079,  0.5313, -7.6343,  ..., -1.8145, -3.1378, -4.7410],\n",
            "        ...,\n",
            "        [-0.5686,  2.4896, -3.2363,  ...,  0.4650,  0.3629, -1.0901],\n",
            "        [ 1.1322, -1.5489, -5.0870,  ..., -0.7689, -1.2358, -0.4823],\n",
            "        [-0.4585, -5.0858, -3.4663,  ...,  0.4651,  2.1258,  1.5031]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1472, -4.2829, -5.5986,  ...,  0.3378,  2.7074,  2.4471],\n",
            "        [ 1.3913, -1.5167, -5.7137,  ...,  0.0215, -0.2497, -0.1765],\n",
            "        [ 0.7795, -0.7397, -3.2616,  ..., -4.1826,  0.8889, -1.8450],\n",
            "        ...,\n",
            "        [-1.6351,  0.1009, -2.8967,  ..., -0.5503, -0.1698, -0.9560],\n",
            "        [-0.3559, -3.6124, -4.8860,  ...,  0.2914,  2.5845,  2.1954],\n",
            "        [ 0.2185, -0.5710, -3.1741,  ...,  1.5238,  0.6529,  0.6603]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3889, -4.1314, -2.5234,  ..., -2.3007,  0.8037,  0.5457],\n",
            "        [ 1.4399,  0.2414, -2.9205,  ...,  1.6800, -1.7113, -0.8065],\n",
            "        [ 1.3453, -0.8170, -3.1826,  ..., -0.0144, -0.1396, -1.0758],\n",
            "        ...,\n",
            "        [-1.3988, -3.8088, -5.5075,  ...,  0.5040,  1.1344,  0.8333],\n",
            "        [ 1.2628, -1.5725, -4.6443,  ...,  1.8728,  1.2831,  1.9698],\n",
            "        [-1.2311, -3.9455, -3.2049,  ..., -0.8267,  1.0083,  1.7112]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1411, -0.3465, -3.0664,  ...,  1.7176, -0.5702,  2.2436],\n",
            "        [-1.3478, -4.9418, -5.8161,  ..., -2.0696, -4.6611, -4.7652],\n",
            "        [ 1.0733,  0.2765, -4.4036,  ..., -4.5534,  2.0607,  1.5892],\n",
            "        ...,\n",
            "        [-0.2884, -3.1048, -2.3789,  ...,  1.3811,  0.9862,  1.0914],\n",
            "        [ 2.0326, -0.0291, -5.5091,  ...,  0.8531,  2.1593,  0.6079],\n",
            "        [-0.4456,  2.2499, -1.7984,  ..., -2.2286,  1.9883, -0.8215]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0528, -2.3670, -4.4865,  ..., -0.5283,  1.7638,  1.9462],\n",
            "        [ 0.2623,  1.6289, -3.2126,  ..., -2.6314,  1.9723, -1.8888],\n",
            "        [ 0.5575, -2.1601, -3.6040,  ..., -0.8552,  1.6405, -0.7770],\n",
            "        ...,\n",
            "        [ 1.0812, -0.9794, -4.8263,  ...,  1.0790, -1.2984, -2.3644],\n",
            "        [ 1.2765, -4.1056, -4.5553,  ..., -5.1860,  2.7710, -0.5423],\n",
            "        [-0.4630, -3.7335, -3.4249,  ..., -3.1896,  0.7825, -1.4567]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.7458, -0.1358, -3.3616,  ...,  0.4863,  0.7106, -0.2770],\n",
            "        [ 2.6908, -4.0823, -4.6182,  ..., -1.6334, -3.2780, -3.3074],\n",
            "        [ 2.0977, -0.4292, -4.0119,  ..., -0.2215,  5.1280, -0.8451],\n",
            "        ...,\n",
            "        [ 1.4235, -3.7250, -4.8306,  ...,  0.7575, -0.2631,  1.0981],\n",
            "        [ 2.7671, -1.9445, -3.0215,  ..., -1.5021,  0.8220, -1.6220],\n",
            "        [ 0.3499, -1.0719, -6.3021,  ..., -0.6793,  0.7940,  2.2280]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3691, -2.9141, -3.2496,  ..., -2.2388,  2.0601, -1.0424],\n",
            "        [ 2.5858,  0.8214, -3.7246,  ...,  0.2502, -0.5250, -0.6304],\n",
            "        [ 1.4016, -4.5684, -3.8439,  ..., -0.5544,  1.0728,  0.6252],\n",
            "        ...,\n",
            "        [-0.8517, -1.5198, -6.0497,  ..., -4.6751, -0.8677,  0.2551],\n",
            "        [ 3.0491, -5.5852, -4.3954,  ..., -1.6989, -2.0235, -1.8462],\n",
            "        [-0.6773, -4.7664, -6.3599,  ..., -1.7336, -2.5252, -4.4923]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3566, -1.7944, -3.6410,  ...,  0.7083,  2.0302,  3.3354],\n",
            "        [ 0.8968,  1.8671, -2.9005,  ..., -1.7185, -2.5486, -1.1996],\n",
            "        [ 5.7282, -1.4723, -5.1905,  ..., -4.4237, -3.2093, -3.8045],\n",
            "        ...,\n",
            "        [ 0.9299, -0.7935, -4.3197,  ..., -3.6207,  1.1022,  2.3093],\n",
            "        [ 2.7985,  0.9623, -4.2294,  ..., -2.4696, -2.2253, -2.7300],\n",
            "        [-1.8591, -2.4783, -1.9386,  ...,  0.7125,  2.7526,  1.9589]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.2339,  0.2118, -2.9081,  ..., -1.1326, -2.2962, -4.4686],\n",
            "        [-0.0244, -2.1368, -3.4756,  ...,  3.4153, -2.5872,  0.6391],\n",
            "        [-1.6428, -2.3722, -4.1761,  ...,  0.9059,  2.0605,  2.8105],\n",
            "        ...,\n",
            "        [ 1.5204,  0.7789, -1.7474,  ..., -3.1990, -1.7262, -0.5321],\n",
            "        [ 4.4624, -2.2293, -5.5644,  ..., -1.7365, -3.4121, -3.9379],\n",
            "        [ 0.1117,  0.0316, -3.6019,  ..., -2.0365,  1.2540,  0.9846]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8116, -4.5232, -5.1547,  ..., -1.9355, -2.8516, -2.1112],\n",
            "        [ 0.4057, -4.3929, -3.9947,  ..., -4.2306, -2.0268, -2.5108],\n",
            "        [ 2.9867,  1.6193, -4.1823,  ..., -0.3678, -0.7495, -3.5695],\n",
            "        ...,\n",
            "        [-0.7409, -2.9665, -5.4520,  ..., -6.9269, -1.1001,  1.8209],\n",
            "        [ 0.6383,  1.6064, -2.4390,  ..., -2.2542,  0.2856, -3.0330],\n",
            "        [ 3.0336, -4.7426, -6.7200,  ..., -4.2502, -2.8431, -4.5025]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.7963,  0.7782, -4.8377,  ...,  0.5989,  1.7511, -1.4500],\n",
            "        [ 4.2036, -1.5414, -6.5976,  ..., -6.1000, -3.7634, -4.1513],\n",
            "        [ 0.0677, -3.6832, -5.2768,  ..., -1.2283,  1.0079,  0.3056],\n",
            "        ...,\n",
            "        [-0.4890, -3.0385, -4.0979,  ...,  0.6095,  1.9195,  3.0040],\n",
            "        [ 1.1431, -5.0402, -2.9728,  ..., -2.1440,  2.1641,  0.2974],\n",
            "        [-1.6027, -1.1396, -3.2665,  ...,  2.9123, -1.6780,  2.2993]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.0848, -1.3261, -2.9395,  ...,  0.2882,  0.1716, -4.3510],\n",
            "        [ 0.1847, -3.9584, -4.2208,  ..., -3.3982,  0.6543,  0.8975],\n",
            "        [ 0.8683,  1.1656, -3.2587,  ...,  0.4824,  0.7718, -0.0895],\n",
            "        ...,\n",
            "        [-0.2342, -3.1964, -2.8720,  ..., -2.9004,  2.6181,  0.3518],\n",
            "        [ 0.4962, -4.8324, -1.7555,  ...,  2.4728, -1.2820,  1.3925],\n",
            "        [ 2.3361, -1.9963, -3.8498,  ...,  2.6064,  1.6221, -0.5421]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9061,  1.1898, -2.3092,  ..., -6.4647,  0.5620, -1.6989],\n",
            "        [-0.7601, -2.0684, -5.1413,  ..., -4.7538, -0.5433,  4.1953],\n",
            "        [-0.8242,  0.2405, -1.9031,  ...,  2.0844, -0.4719,  2.1638],\n",
            "        ...,\n",
            "        [ 1.9333,  3.8562, -4.1470,  ...,  3.2518, -0.7568, -0.7943],\n",
            "        [ 1.0930, -3.0374, -2.7615,  ..., -2.2342,  0.4080,  1.0203],\n",
            "        [ 1.9525,  2.1978, -3.5762,  ...,  0.1392, -0.4570, -1.0852]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7399, -0.5807, -6.4056,  ..., -1.6761, -1.8212, -2.2363],\n",
            "        [ 3.1184, -1.8287, -4.3624,  ..., -2.1612, -4.6412, -4.8238],\n",
            "        [-0.7018,  0.2030, -3.6751,  ..., -1.0176,  0.0987,  1.9727],\n",
            "        ...,\n",
            "        [-1.8771, -1.9864, -7.2181,  ...,  0.2003,  0.4309, -1.8921],\n",
            "        [-0.4323, -0.4990, -2.4947,  ..., -0.6634, -0.7226, -2.2178],\n",
            "        [ 0.5455,  1.3253, -1.8737,  ..., -3.2277, -0.6483, -0.3016]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.2449, -5.7913, -3.7076,  ..., -2.0806,  1.9832, -1.0236],\n",
            "        [-1.3985, -3.5236, -5.0031,  ..., -1.0227, -2.3490, -2.0284],\n",
            "        [-1.1945, -3.5573, -4.0392,  ...,  1.1212,  1.8430,  1.8810],\n",
            "        ...,\n",
            "        [-1.8680, -3.3894, -4.6011,  ..., -1.0581,  1.6690,  2.5746],\n",
            "        [ 1.2362, -6.6199, -5.9960,  ...,  2.4344, -2.5944,  2.1355],\n",
            "        [-0.1636, -2.0665, -3.6895,  ..., -2.7643, -0.9892,  1.2544]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.0049, -4.7420, -4.7086,  ...,  1.2712,  1.4082,  2.6079],\n",
            "        [-1.0350, -3.8285, -5.9960,  ..., -2.9855, -3.3751, -3.2962],\n",
            "        [-0.7097, -1.0942, -6.6401,  ..., -3.7404,  0.5602,  0.4739],\n",
            "        ...,\n",
            "        [-0.0922, -2.0166, -5.1762,  ..., -0.9308,  0.7845,  3.9559],\n",
            "        [-3.2116, -5.1496, -7.0910,  ...,  0.8133, -0.6423, -0.5536],\n",
            "        [-1.8479, -4.4727, -4.5384,  ..., -3.7915,  2.0415,  0.7342]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0973, -5.5038, -2.9658,  ..., -1.4189,  2.2963,  4.8654],\n",
            "        [ 0.8554, -6.4257, -6.8227,  ..., -0.9518,  1.8674,  3.2295],\n",
            "        [-1.8063, -5.2583, -5.3499,  ..., -3.0000, -3.1852, -0.8245],\n",
            "        ...,\n",
            "        [-1.0545, -4.0344, -3.9491,  ...,  0.2048,  0.4689,  1.7030],\n",
            "        [-0.0198, -0.1750, -2.6415,  ..., -0.8804, -0.3300,  0.1654],\n",
            "        [-0.0077, -6.8330, -5.5058,  ..., -1.5941, -4.8322, -3.8761]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3131, -1.3527, -3.7540,  ..., -5.1711, -1.5748, -2.5247],\n",
            "        [ 1.3193, -3.0411, -5.3182,  ..., -1.2481,  2.4235,  0.3820],\n",
            "        [ 1.6605, -0.7316, -5.1851,  ..., -3.2911,  0.1300, -1.0403],\n",
            "        ...,\n",
            "        [-2.1329, -3.2961, -4.6871,  ..., -3.6657,  1.0163,  2.9221],\n",
            "        [ 0.0104, -3.0788, -4.9352,  ..., -1.8284,  0.0264,  3.6139],\n",
            "        [ 0.1710, -0.5158, -4.0611,  ..., -4.4143,  2.3316,  2.4239]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7522, -0.4202, -2.7641,  ..., -0.0617,  1.5936,  3.7477],\n",
            "        [-1.1322, -0.4915, -2.6056,  ...,  0.3047,  0.6868,  1.3208],\n",
            "        [-0.6414, -6.1046, -4.6129,  ..., -1.3868,  3.3716,  3.0548],\n",
            "        ...,\n",
            "        [ 4.2624, -2.1041, -4.4836,  ..., -0.8015, -4.1475, -4.5966],\n",
            "        [ 1.1695, -8.5409, -5.9320,  ..., -0.4770,  1.7329,  2.5357],\n",
            "        [ 2.5383,  0.5176, -3.3886,  ...,  0.8561, -1.6872, -2.5547]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 3.4536, -4.7283, -8.0783,  ..., -1.5848, -0.4207,  0.7562],\n",
            "        [-0.5606, -4.5620, -4.7992,  ..., -0.2962,  3.6933,  3.5200],\n",
            "        [-0.3098, -2.1772, -2.9640,  ...,  0.0767, -7.0746, -2.9489],\n",
            "        ...,\n",
            "        [-1.0626,  0.0757, -3.3072,  ...,  0.1365,  1.4516, -1.5385],\n",
            "        [ 3.8499,  0.2130, -4.3311,  ...,  0.5326, -4.1853, -3.6013],\n",
            "        [-0.6824, -2.7004, -2.6154,  ..., -0.4567,  2.5778,  1.8471]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9814, -1.3130, -4.4046,  ...,  3.2599, -5.0125, -0.0768],\n",
            "        [-1.8153, -0.6076, -4.4842,  ..., -2.5430,  0.9752,  0.7339],\n",
            "        [ 0.1620, -0.7690, -3.4257,  ..., -2.0218,  2.3499,  1.1128],\n",
            "        ...,\n",
            "        [-1.5512, -0.4309, -2.3381,  ...,  0.1992,  0.3612,  1.4094],\n",
            "        [-0.8116, -5.2810, -5.4054,  ..., -4.9218, -2.3901, -4.0128],\n",
            "        [ 3.9482, -0.3178, -2.7724,  ...,  1.0149,  0.8393,  0.3792]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.8647, -4.9298, -5.6763,  ..., -5.0860, -3.0849, -4.7747],\n",
            "        [ 2.6470, -1.3320, -4.9207,  ..., -2.0278, -3.7002, -2.8918],\n",
            "        [ 0.5623,  0.3792, -2.6271,  ..., -0.4885,  0.6809, -1.9831],\n",
            "        ...,\n",
            "        [ 4.6217,  0.8088, -4.9337,  ..., -5.0843, -3.7414, -4.2135],\n",
            "        [ 1.9513, -2.5952, -4.4472,  ..., -1.4354, -5.7373, -5.5008],\n",
            "        [ 2.2210,  2.4951, -4.5505,  ..., -0.1035, -0.2688, -1.0171]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8547, -4.9061, -3.4329,  ...,  1.0073,  2.6534,  2.5065],\n",
            "        [-0.6455,  0.2547, -3.6968,  ..., -6.9187, -3.1194, -3.1963],\n",
            "        [-0.2698, -5.5630, -5.7908,  ...,  0.3671,  2.4238,  3.3267],\n",
            "        ...,\n",
            "        [ 4.4805, -1.1839, -5.4543,  ..., -1.1202, -2.9303,  0.0773],\n",
            "        [ 2.2812, -5.3198, -6.6066,  ...,  0.1978, -2.9839,  1.1714],\n",
            "        [ 1.6252, -3.3470, -6.3554,  ..., -1.9338, -1.3273,  1.1067]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.0583,  1.4817, -2.8104,  ..., -3.8683,  1.8075, -1.8415],\n",
            "        [ 0.9623, -0.4885, -4.1527,  ...,  1.2747,  1.4627, -0.8719],\n",
            "        [-0.5631, -3.9505, -3.7753,  ..., -1.2352,  3.8082,  2.2495],\n",
            "        ...,\n",
            "        [-0.3436, -6.3622, -5.3265,  ...,  1.3700,  2.3709,  4.1806],\n",
            "        [ 1.9997,  1.0596, -4.0486,  ..., -1.9996, -0.8988, -2.6593],\n",
            "        [-1.5228, -5.9467, -6.8118,  ..., -2.1626, -1.0239,  3.2801]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.2047, -3.7585, -5.0411,  ...,  1.2306, -1.6786,  0.5809],\n",
            "        [ 0.9690, -0.2480, -3.7575,  ..., -5.7510, -0.5171, -1.2312],\n",
            "        [ 0.1493, -4.8232, -5.5267,  ..., -4.5982,  3.8069,  1.2265],\n",
            "        ...,\n",
            "        [ 0.3196, -0.8275, -4.7761,  ..., -3.4197,  0.2714,  1.4907],\n",
            "        [ 0.1442, -5.9879, -4.8683,  ..., -2.0666,  1.8146,  1.8353],\n",
            "        [ 1.4640,  0.7909, -4.4266,  ..., -0.4085,  1.1797, -0.9441]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.6193, -6.2328, -3.9245,  ..., -5.1998,  1.6444, -0.4599],\n",
            "        [ 0.5488,  1.6747, -3.8916,  ..., -0.1198, -0.8802,  0.6290],\n",
            "        [ 2.5448, -2.4557, -5.7421,  ..., -4.5500, -2.8081, -3.0776],\n",
            "        ...,\n",
            "        [-1.3892, -1.6105, -5.7284,  ..., -3.8525, -2.8165, -2.5938],\n",
            "        [ 0.2478, -2.2523, -3.9560,  ..., -4.3073, -1.5512, -1.9056],\n",
            "        [ 2.7199, -4.3592, -4.8594,  ..., -0.6906, -0.3423,  0.6596]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2842, -4.9083, -5.4031,  ...,  0.4494,  3.0432,  5.1465],\n",
            "        [ 0.3159, -4.6168, -5.9322,  ..., -3.4123, -4.8578, -3.3937],\n",
            "        [-0.4159, -3.1102, -5.5832,  ..., -2.6631,  0.9208,  2.4330],\n",
            "        ...,\n",
            "        [-1.9404, -3.5234, -3.5975,  ..., -2.2953,  0.9125,  3.0277],\n",
            "        [-0.4174, -1.5992, -2.5542,  ..., -2.6146,  2.3182,  0.5799],\n",
            "        [-0.3174, -2.9593, -4.2916,  ..., -4.1899, -1.9930, -1.0328]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1542, -1.9065, -2.8486,  ..., -2.9743,  0.8218,  2.1383],\n",
            "        [ 3.5979, -3.4022, -4.9788,  ..., -2.0936, -9.4630, -4.8635],\n",
            "        [ 1.1324,  1.4335, -3.3999,  ..., -2.2927,  2.3680, -0.9888],\n",
            "        ...,\n",
            "        [ 0.7714, -1.8882, -4.4811,  ..., -7.1035,  3.1681,  2.3825],\n",
            "        [ 4.4359, -0.6863, -4.7387,  ..., -1.2356, -3.8422, -2.3152],\n",
            "        [ 2.2910, -4.3499, -6.8332,  ..., -4.0567,  0.7002, -1.1947]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7064e+00, -2.2433e+00, -6.0602e+00,  ..., -4.4439e+00,\n",
            "          5.7092e-01,  2.7736e-01],\n",
            "        [-3.5620e+00, -3.1995e+00, -3.2179e+00,  ..., -5.2133e-01,\n",
            "          2.3065e+00,  3.9609e+00],\n",
            "        [ 1.3255e+00, -4.2544e-02, -3.5887e+00,  ...,  9.0656e-01,\n",
            "         -2.0757e+00, -2.4122e+00],\n",
            "        ...,\n",
            "        [ 2.2771e+00, -4.0673e-01, -3.8453e+00,  ..., -1.0121e+00,\n",
            "          4.1406e-01, -2.5131e+00],\n",
            "        [-5.9851e-01, -2.5497e+00, -3.2466e+00,  ...,  1.9186e-04,\n",
            "          1.8288e+00,  4.4888e+00],\n",
            "        [ 2.8244e+00,  9.5249e-01, -5.8890e+00,  ..., -5.9268e+00,\n",
            "         -3.5800e+00, -2.4569e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.8001, -0.1432, -5.1321,  ...,  0.3971,  0.5178, -0.5937],\n",
            "        [ 0.0166, -3.9090, -7.0241,  ..., -1.8687,  2.7196,  3.9041],\n",
            "        [-1.6631, -5.0107, -6.3910,  ..., -6.8908,  0.3790,  0.3430],\n",
            "        ...,\n",
            "        [ 2.8876, -0.7917, -5.0323,  ..., -5.1119, -2.5344, -1.1268],\n",
            "        [ 0.2831,  1.8603, -4.4945,  ..., -1.8732, -2.3729, -3.6482],\n",
            "        [ 0.8480, -0.5756, -3.9378,  ...,  0.8807,  1.4169, -1.0132]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7543, -0.5477, -3.0239,  ..., -1.1040,  1.6474, -0.9579],\n",
            "        [ 0.9879, -4.8137, -5.8629,  ..., -1.5440, -4.0303,  0.4538],\n",
            "        [-0.0359, -3.2950, -2.6077,  ...,  0.1879,  1.2381,  0.5247],\n",
            "        ...,\n",
            "        [-2.7740, -1.0264, -2.2102,  ...,  0.0340,  1.1221,  3.1137],\n",
            "        [-1.1162, -5.1834, -3.1567,  ..., -1.3173,  1.5306,  0.0136],\n",
            "        [ 1.1999, -2.5503, -3.6931,  ...,  3.1533, -2.0073, -1.0515]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.9768, -1.6659, -4.1828,  ..., -2.7590, -1.4315, -0.6268],\n",
            "        [ 3.5008, -1.7204, -4.7834,  ...,  0.6479, -0.0567, -2.1709],\n",
            "        [ 0.2335, -0.1975, -2.8743,  ...,  0.2017,  0.2370,  1.3506],\n",
            "        ...,\n",
            "        [-0.5806,  0.0320, -2.7342,  ...,  2.4330,  0.3466,  1.4351],\n",
            "        [-0.8677, -2.6220, -6.2799,  ..., -1.2400, -0.1517,  3.6175],\n",
            "        [ 3.8878,  1.1159, -5.5664,  ..., -0.6492, -1.4054, -1.9054]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.9576e+00, -1.5333e+00, -3.9996e+00,  ...,  6.0958e-01,\n",
            "          1.3267e+00,  4.3657e+00],\n",
            "        [ 4.0162e-02, -3.6413e+00, -4.9247e+00,  ..., -4.4892e+00,\n",
            "          1.3072e-03, -4.1565e-01],\n",
            "        [ 5.9654e-01, -3.6401e+00, -5.4310e+00,  ..., -1.2389e+00,\n",
            "          2.1268e+00,  5.4405e-01],\n",
            "        ...,\n",
            "        [-3.0176e+00, -1.1900e+00, -2.2986e+00,  ...,  4.3276e-01,\n",
            "          1.7543e+00,  4.2386e+00],\n",
            "        [ 2.2360e+00,  1.5746e+00, -3.6137e+00,  ..., -1.3354e+00,\n",
            "         -1.0028e+00, -1.6168e+00],\n",
            "        [ 1.2283e+00,  2.4544e-01, -4.2055e+00,  ..., -3.3499e+00,\n",
            "         -1.2908e+00, -1.2553e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1387,  1.4256, -3.8387,  ..., -1.4534, -2.6682, -2.9957],\n",
            "        [ 0.4673,  0.2043, -3.3484,  ..., -1.9512,  0.9310,  1.3434],\n",
            "        [-0.8191, -4.5052, -5.5345,  ...,  0.5183,  3.3352,  4.2114],\n",
            "        ...,\n",
            "        [-1.1592, -5.6160, -3.3865,  ..., -2.3741, -0.1799,  1.5250],\n",
            "        [ 2.7372,  0.4379, -3.0151,  ..., -3.9933, -0.9923, -4.7350],\n",
            "        [ 1.1574, -7.0149, -5.0719,  ..., -5.4595,  1.6161, -0.3433]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9047, -4.9265, -5.0188,  ...,  0.2137,  2.5544,  2.4332],\n",
            "        [-0.6746,  0.0419, -2.9903,  ...,  0.7525, -0.5130,  0.2318],\n",
            "        [ 2.3355, -0.2168, -3.6703,  ...,  1.7221,  0.7382, -0.5857],\n",
            "        ...,\n",
            "        [ 0.0527, -3.4061, -4.2792,  ...,  0.0825,  2.4971,  1.7867],\n",
            "        [-1.1083, -4.0632, -4.7947,  ..., -0.0227,  2.3582,  2.1515],\n",
            "        [ 0.1915, -1.6253, -3.5272,  ...,  2.0988,  1.4114,  2.4602]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.7559,  0.2395, -5.0393,  ..., -0.8898,  0.4074, -0.8730],\n",
            "        [ 1.9958, -3.0082, -4.9230,  ..., -2.7770, -1.3751, -4.1714],\n",
            "        [ 0.8657, -5.1963, -6.9796,  ..., -1.6379,  1.4781,  2.2805],\n",
            "        ...,\n",
            "        [ 2.1703, -2.5757, -3.4939,  ..., -0.2233,  2.4206, -0.0176],\n",
            "        [ 1.9062,  3.0480, -4.3326,  ...,  0.5858, -1.0043, -4.1194],\n",
            "        [ 1.1928, -0.2669, -3.5247,  ...,  1.1669,  0.8635, -2.7310]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.0155, -5.8107, -3.6965,  ..., -2.6481,  0.3514, -2.4378],\n",
            "        [ 3.3872, -1.6897, -5.3347,  ..., -2.1641,  1.3780, -4.5553],\n",
            "        [ 0.4647, -4.4182, -4.6318,  ..., -0.7486,  1.5539,  1.0070],\n",
            "        ...,\n",
            "        [-0.6586, -2.6133, -6.4738,  ..., -3.4929, -0.2201, -3.4497],\n",
            "        [ 3.6954,  1.4372, -4.1368,  ..., -2.0124, -0.8385, -4.4045],\n",
            "        [ 0.2126, -3.0807, -6.3988,  ..., -3.6127,  0.9746, -0.7824]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7494, -4.5157, -6.4339,  ..., -5.1282,  2.3028,  1.8165],\n",
            "        [ 0.4403, -2.8076, -4.8022,  ..., -3.3262, -1.6716, -2.4209],\n",
            "        [-0.2835, -5.4717, -6.9246,  ...,  0.8239,  0.8513,  5.4451],\n",
            "        ...,\n",
            "        [ 1.8848, -2.6033, -4.2679,  ...,  0.5483, -1.0269, -2.2587],\n",
            "        [ 5.3259, -0.5064, -4.4877,  ..., -0.4245, -5.3896, -6.0976],\n",
            "        [-0.3204, -0.0733, -2.8242,  ...,  1.0954,  2.1204, -0.8872]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.3715, -4.0497, -6.1439,  ..., -0.5159,  1.6590,  1.6728],\n",
            "        [-0.2118, -3.9892, -5.2800,  ...,  1.0620,  2.4052,  2.8786],\n",
            "        [-1.1141, -7.1773, -5.6790,  ..., -1.1610,  2.9354,  1.7890],\n",
            "        ...,\n",
            "        [ 1.6646, -5.5609, -6.0277,  ..., -2.0235, -6.5816, -3.4547],\n",
            "        [-0.4236, -6.1064, -5.1220,  ..., -2.4179, -5.3524, -3.5093],\n",
            "        [ 1.3172,  0.8802, -2.3870,  ..., -0.6243,  1.6293, -0.6500]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4260, -2.8403, -4.9911,  ..., -2.1390, -0.2076, -1.3231],\n",
            "        [ 0.3525, -3.8108, -4.1416,  ..., -2.9761,  0.9236,  0.8928],\n",
            "        [-0.3099, -0.4248, -2.4733,  ..., -1.9249, -0.1100, -0.4924],\n",
            "        ...,\n",
            "        [ 1.9335,  0.0772, -4.0874,  ...,  0.1601,  0.7146,  1.7994],\n",
            "        [-0.1958, -0.7897, -3.0097,  ...,  1.0035,  2.2283,  1.7612],\n",
            "        [ 6.6817,  2.4557, -4.8314,  ...,  1.5694, -2.5493, -5.8501]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.5428, -2.1633, -2.8616,  ...,  0.1808, -0.9918, -2.9630],\n",
            "        [ 0.3328,  0.0548, -3.8984,  ...,  0.6622,  1.9791, -3.0355],\n",
            "        [ 4.8269, -0.1870, -5.4283,  ..., -3.6797, -1.4770, -3.5671],\n",
            "        ...,\n",
            "        [ 0.3888, -3.4160, -4.6776,  ..., -3.3123,  2.9964,  2.5946],\n",
            "        [-4.5503, -4.4539, -2.4173,  ...,  1.1229,  2.1463,  3.5624],\n",
            "        [ 2.8941, -3.8493, -4.1454,  ..., -2.0906, -4.4785, -4.1434]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.4774, -3.8380, -3.4703,  ...,  0.4698,  0.5539, -0.2024],\n",
            "        [-0.9936, -3.5498, -4.3287,  ...,  0.8814,  2.8759,  1.9049],\n",
            "        [ 0.4435, -1.4799, -6.1812,  ..., -3.4060,  1.6905, -1.2195],\n",
            "        ...,\n",
            "        [ 4.7324,  3.9060, -3.7112,  ...,  0.9470, -1.3803, -5.5660],\n",
            "        [-0.2101, -4.4915, -4.8802,  ...,  1.1562,  2.6617,  2.5337],\n",
            "        [ 2.3618, -1.4415, -3.9164,  ...,  1.2416,  2.4338, -2.2865]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.2563e+00,  2.3450e+00, -5.5711e+00,  ...,  1.3231e+00,\n",
            "          8.3166e-02, -1.7400e+00],\n",
            "        [-2.3361e+00, -4.0877e+00, -5.0500e+00,  ..., -9.8613e-01,\n",
            "          1.0885e+00, -1.6030e+00],\n",
            "        [-1.9134e+00,  3.0571e-04, -3.5284e+00,  ...,  7.0232e-01,\n",
            "         -6.6054e-01, -1.8836e-02],\n",
            "        ...,\n",
            "        [ 1.5284e+00,  1.4517e+00, -3.8338e+00,  ...,  1.2810e+00,\n",
            "          5.8526e-01, -1.2742e-01],\n",
            "        [-1.3972e+00, -3.7534e+00, -4.2109e+00,  ...,  1.4763e-01,\n",
            "          2.8624e+00,  2.3409e+00],\n",
            "        [ 4.2296e+00,  1.9899e+00, -4.6467e+00,  ...,  1.1097e+00,\n",
            "         -2.7239e-02, -3.9032e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8180, -6.1728, -5.5500,  ..., -2.4004, -5.3218, -3.8720],\n",
            "        [-2.3290, -7.8030, -5.4506,  ..., -3.4132,  0.7430,  5.4775],\n",
            "        [ 1.5579, -1.4346, -4.1234,  ..., -2.5093, -5.0836, -6.4256],\n",
            "        ...,\n",
            "        [-1.7987, -7.4860, -4.5316,  ..., -2.9966,  2.7609,  1.2396],\n",
            "        [ 1.3770, -0.2633, -1.8499,  ...,  2.4448, -4.6225, -2.7325],\n",
            "        [-0.5021, -1.4943, -4.3404,  ..., -2.5550,  1.5261,  0.9144]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.4374, -6.8981, -5.4717,  ..., -1.0236,  2.4759,  2.7577],\n",
            "        [ 1.4537, -0.8920, -2.9691,  ..., -1.6552,  1.2099, -0.8404],\n",
            "        [-2.8602, -2.4313, -2.4161,  ...,  0.5770,  1.9134,  2.0784],\n",
            "        ...,\n",
            "        [-1.3122, -2.7869, -4.6484,  ...,  4.2199, -2.1937,  0.3010],\n",
            "        [-0.4139,  1.5681, -2.9955,  ...,  0.1778,  0.9926, -0.8597],\n",
            "        [-0.8292, -3.1357, -5.5592,  ..., -5.3513,  2.6878,  3.7676]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.9923, -3.8166, -5.5360,  ..., -4.1609, -1.0121, -0.5209],\n",
            "        [-0.4487,  0.3388, -2.5664,  ..., -0.9007,  1.7247,  1.9460],\n",
            "        [ 1.9598, -3.8089, -2.7306,  ..., -3.6277, -2.1040, -0.9116],\n",
            "        ...,\n",
            "        [ 0.0780,  1.0882, -3.9485,  ...,  0.8143,  0.5453,  0.1876],\n",
            "        [-0.0497, -2.7180, -6.1677,  ..., -1.4795, -5.0827, -5.2289],\n",
            "        [-2.5288, -3.0371, -3.6932,  ...,  0.7965,  2.3592,  2.2119]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.7827, -2.1911, -4.6992,  ..., -0.5415,  1.5044, -2.5673],\n",
            "        [ 4.0297, -1.5460, -5.5475,  ..., -5.5378,  2.3769, -3.6486],\n",
            "        [ 0.8596,  1.1189, -5.5180,  ...,  1.3742, -0.6274, -3.6782],\n",
            "        ...,\n",
            "        [ 0.7105,  0.5690, -3.2263,  ...,  1.8763, -1.1926, -1.2266],\n",
            "        [-1.6992, -2.2388, -5.6243,  ..., -4.4319, -1.2500, -4.8302],\n",
            "        [ 0.8406, -4.5686, -4.9670,  ..., -5.9435,  0.7723, -0.7472]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.1464, -3.3777, -3.7801,  ..., -1.3509, -3.4221, -2.3112],\n",
            "        [-0.7898, -0.2209, -3.9156,  ...,  1.2040, -0.8964,  0.9019],\n",
            "        [-3.1917, -0.7374, -3.2778,  ...,  0.7167,  1.2590,  2.0643],\n",
            "        ...,\n",
            "        [ 1.8451,  1.3783, -3.1795,  ..., -2.4709, -0.1091, -1.4978],\n",
            "        [-0.9601, -2.7468, -2.9315,  ...,  2.8287, -2.8987, -2.6022],\n",
            "        [ 1.6055,  0.0811, -2.3791,  ..., -2.0201,  1.3692, -2.3219]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.3688e+00, -4.1822e+00, -6.3009e+00,  ...,  5.4914e-01,\n",
            "          2.3780e+00,  1.6187e+00],\n",
            "        [ 1.2535e+00, -5.3865e+00, -7.0113e+00,  ..., -4.9861e+00,\n",
            "         -2.9859e+00, -3.1229e+00],\n",
            "        [-2.0429e-01, -1.0814e+00, -4.4750e+00,  ..., -8.3169e-01,\n",
            "         -5.3349e-01, -2.4022e+00],\n",
            "        ...,\n",
            "        [-2.1817e-01, -3.2887e+00, -4.0685e+00,  ..., -5.2187e-01,\n",
            "         -6.8295e-03,  7.4949e-01],\n",
            "        [-1.7092e+00, -2.5759e+00, -5.2629e+00,  ...,  1.5802e-02,\n",
            "         -7.3471e-01,  1.9559e+00],\n",
            "        [ 1.0269e+00,  3.1680e-01, -5.8891e+00,  ..., -1.5972e-01,\n",
            "         -2.7814e-01, -2.0560e+00]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0269, -5.1155, -3.8392,  ..., -1.2944,  0.2589, -1.1149],\n",
            "        [ 1.7231,  1.2681, -3.8617,  ..., -2.4832,  2.1469, -0.4702],\n",
            "        [ 1.0413, -2.9727, -4.5687,  ..., -2.3422, -1.1801, -2.4968],\n",
            "        ...,\n",
            "        [-1.4708, -5.2064, -4.4364,  ..., -2.2925,  1.8491, -0.9875],\n",
            "        [-1.4320, -5.9078, -5.8112,  ...,  1.7301, -0.9754, -1.5059],\n",
            "        [-1.1273, -0.9373, -4.3481,  ...,  0.4970, -2.3707, -0.8744]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7411, -0.6502, -2.8707,  ...,  4.7630, -2.3242, -0.2508],\n",
            "        [ 4.3400, -1.9699, -4.7623,  ..., -2.7987, -5.5324, -5.5051],\n",
            "        [ 3.8488, -0.1035, -6.5529,  ..., -5.8483, -2.2364, -3.6044],\n",
            "        ...,\n",
            "        [ 3.5102,  0.0516, -2.5148,  ..., -0.1967, -2.0906, -2.0302],\n",
            "        [-1.9817, -4.3282, -4.8898,  ...,  1.1102,  0.8858,  1.6312],\n",
            "        [-1.3908, -2.3663, -3.4995,  ..., -2.3079,  2.2341,  3.0905]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.5138, -1.0068, -3.8255,  ..., -2.3871,  0.5392, -2.9332],\n",
            "        [-0.8164, -0.1507, -3.1627,  ..., -2.6167,  0.7753, -1.4878],\n",
            "        [-1.1914, -4.4496, -6.0023,  ..., -2.6457, -1.5243, -1.1334],\n",
            "        ...,\n",
            "        [-2.6085, -0.2426, -3.8529,  ...,  2.0436,  0.1179,  1.2405],\n",
            "        [-2.4017,  0.8899, -2.8818,  ...,  0.6678, -2.2134,  0.6924],\n",
            "        [-0.1677, -6.0022, -5.6450,  ...,  1.3688, -2.0774, -1.2745]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.6685, -3.7095, -3.6295,  ..., -2.3534,  4.1469,  2.0136],\n",
            "        [ 0.3584, -0.6859, -3.9962,  ..., -5.1649,  2.0098, -2.7043],\n",
            "        [-0.2205, -2.2577, -5.3166,  ..., -2.5093, -2.5554, -4.2956],\n",
            "        ...,\n",
            "        [ 5.4136,  4.0918, -3.5976,  ...,  3.0376, -5.2235, -4.0854],\n",
            "        [-2.0875, -3.2421, -3.8675,  ...,  1.6222,  2.0205,  3.8900],\n",
            "        [-2.0468, -1.6548, -4.1807,  ..., -3.8401, -1.0045, -2.6249]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 5.5695,  1.6793, -2.6988,  ..., -0.1200, -1.8606, -2.0713],\n",
            "        [-2.5830, -2.2935, -3.1989,  ...,  0.9359,  2.3524,  2.1654],\n",
            "        [ 2.9361,  3.1330, -2.9711,  ..., -2.5413, -0.9955, -4.4514],\n",
            "        ...,\n",
            "        [ 2.6142, -2.7718, -2.6052,  ...,  3.8141, -2.1898,  0.9531],\n",
            "        [ 0.3952, -0.5003, -2.7135,  ..., -0.7615, -1.6605, -1.0809],\n",
            "        [-1.7270, -3.1639, -3.1140,  ..., -3.2904,  1.4561, -3.6968]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 4.4422,  0.7663, -4.4942,  ..., -0.5849, -2.1610, -3.9470],\n",
            "        [ 3.4764, -0.5808, -3.5556,  ..., -2.6387,  2.1075, -4.8816],\n",
            "        [ 0.7660, -2.6757, -6.2875,  ..., -5.1487, -3.0858, -4.8333],\n",
            "        ...,\n",
            "        [ 0.6856, -2.9111, -3.9962,  ..., -2.9143, -1.2005, -1.6969],\n",
            "        [ 0.5522, -4.1197, -6.3282,  ..., -1.4470,  1.2227,  2.1480],\n",
            "        [ 4.1174,  1.0561, -5.2202,  ..., -3.6730, -3.0136, -2.3726]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.5971,  0.0113, -1.5005,  ..., -2.9338, -0.6915, -4.9910],\n",
            "        [ 5.4720, -0.7679, -4.8387,  ..., -4.0496, -4.4941, -5.5367],\n",
            "        [-0.2919, -2.8551, -4.3164,  ...,  0.4924,  2.3601,  2.5998],\n",
            "        ...,\n",
            "        [ 1.5697, -3.1732, -3.4368,  ..., -1.4028, -1.5340, -3.7834],\n",
            "        [-1.4215, -1.3953, -4.8885,  ..., -3.5949,  0.5410,  1.6301],\n",
            "        [ 1.3820,  1.3323, -3.3776,  ...,  2.6078, -0.8588,  0.4829]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.1253, -0.4279, -5.4259,  ...,  0.2770, -0.9143, -1.3127],\n",
            "        [ 0.4282, -2.4721, -4.1476,  ..., -2.7507,  2.4338,  2.4331],\n",
            "        [-3.4030, -2.9612, -3.5358,  ...,  1.2920,  1.2451,  2.6564],\n",
            "        ...,\n",
            "        [ 3.7126, -1.6809, -5.7147,  ..., -3.5920, -5.6086, -6.7653],\n",
            "        [ 0.5479, -1.5998, -2.5193,  ..., -3.6265,  1.2566,  0.9051],\n",
            "        [ 1.5750, -4.2616, -6.1634,  ...,  1.3862,  0.3989,  1.5132]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.0835, -1.8915, -5.7222,  ..., -1.1787, -0.8729,  2.0124],\n",
            "        [ 4.5568,  1.5267, -4.6520,  ...,  2.1204, -0.8219, -4.1242],\n",
            "        [ 0.1718, -5.7079, -5.9668,  ..., -6.0212, -4.0592, -2.3943],\n",
            "        ...,\n",
            "        [ 0.0631, -5.4489, -4.5372,  ..., -5.0330,  0.1192, -2.7263],\n",
            "        [ 1.1502,  2.5395, -5.8176,  ...,  1.8307, -1.3917, -2.9182],\n",
            "        [-2.8467, -5.9637, -6.0246,  ...,  1.7811, -0.3127,  0.8057]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 2.3654,  2.7175, -3.6135,  ...,  0.2764, -1.2101, -2.2827],\n",
            "        [ 0.1331, -6.6712, -2.1391,  ..., -1.0973,  2.5694,  1.7018],\n",
            "        [-2.4614, -2.1537, -4.1405,  ...,  1.1761,  1.8137,  2.3020],\n",
            "        ...,\n",
            "        [-1.2749, -4.0194, -5.4321,  ...,  0.0212, -0.4995, -0.4394],\n",
            "        [ 0.9194, -0.2029, -2.9760,  ..., -0.9942, -0.1961, -0.6077],\n",
            "        [-2.2770, -1.1900, -5.2552,  ..., -1.1847,  0.4949, -0.2143]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5090, -0.0574, -3.4573,  ..., -1.8241, -3.1203, -1.1396],\n",
            "        [-1.0245, -1.1949, -2.7763,  ...,  0.3228, -0.5481, -1.0247],\n",
            "        [ 0.1124,  1.8013, -3.9723,  ...,  0.5236, -1.1236,  1.2290],\n",
            "        ...,\n",
            "        [-0.5699, -2.4476, -3.6968,  ..., -1.8409,  3.0586, -0.1392],\n",
            "        [ 1.0143, -0.7138, -4.2197,  ..., -4.4567, -1.9920, -3.8051],\n",
            "        [ 0.9871, -0.9234, -3.7039,  ...,  1.7936, -1.6122, -4.5021]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 1.5644, -2.2584, -6.0935,  ..., -0.0875, -0.5220, -1.0096],\n",
            "        [-0.2237, -2.4855, -3.7643,  ...,  0.4834, -1.5961, -3.8629],\n",
            "        [-0.2961, -4.3738, -5.2003,  ..., -4.1856,  0.9218, -1.3055],\n",
            "        ...,\n",
            "        [ 0.7160, -1.2755, -3.1601,  ...,  0.0298,  2.1819,  0.2134],\n",
            "        [-0.5558, -2.5429, -6.0038,  ...,  1.9766,  1.5903,  3.7999],\n",
            "        [ 0.4309, -0.9760, -4.4947,  ..., -0.1823,  2.5961, -0.5411]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.7828, -3.2074, -3.1418,  ..., -0.0274, -5.8995, -3.2704],\n",
            "        [-1.4947, -0.7207, -2.9127,  ..., -2.5699, -0.6514, -3.8660],\n",
            "        [ 2.5103, -0.1455, -4.3815,  ..., -3.5073, -4.4632, -5.3296],\n",
            "        ...,\n",
            "        [-0.9413, -2.9598, -3.9463,  ..., -0.9223, -2.4044, -2.8941],\n",
            "        [ 2.1525,  0.7832, -3.3806,  ..., -0.5436, -0.0277, -2.8615],\n",
            "        [ 0.2430,  0.3109, -4.6283,  ..., -1.0770, -1.5531,  0.5797]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.7600, -2.2706, -4.6627,  ..., -1.3085,  1.0795,  2.4137],\n",
            "        [ 0.4584, -6.0926, -6.4324,  ..., -0.8348,  2.3129,  2.0418],\n",
            "        [-0.3230, -1.2774, -5.2705,  ..., -4.3708,  3.3217,  1.3472],\n",
            "        ...,\n",
            "        [-1.6437, -1.4091, -4.2797,  ...,  3.6464, -0.0174,  1.8979],\n",
            "        [ 1.5424, -0.7418, -2.9677,  ..., -2.4096, -2.1071, -3.9401],\n",
            "        [ 0.5085, -1.4576, -4.1284,  ..., -5.1440, -1.8701, -3.9627]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.1581, -2.5888, -5.3417,  ...,  1.8613,  1.0607,  2.7430],\n",
            "        [ 0.6768, -0.2589, -5.7440,  ...,  0.0337, -0.9460,  2.5383],\n",
            "        [ 0.7338, -0.4986, -3.6347,  ..., -0.3556,  2.5629, -2.7387],\n",
            "        ...,\n",
            "        [ 1.0700,  1.1873, -2.7471,  ..., -2.9175, -0.9221, -0.9437],\n",
            "        [ 0.8972, -5.7916, -4.3275,  ..., -3.2202, -3.6305, -0.4205],\n",
            "        [ 1.8702,  1.8771, -3.9572,  ...,  0.6420,  0.3197, -0.5973]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-5.1841e-01, -1.5400e+00, -4.0891e+00,  ..., -3.7027e+00,\n",
            "          9.7922e-01, -3.1795e-02],\n",
            "        [-9.2255e-01, -3.2431e+00, -3.5666e+00,  ...,  7.8795e-01,\n",
            "          2.9098e+00,  2.3153e+00],\n",
            "        [ 2.0036e-01, -2.8334e+00, -5.2000e+00,  ..., -4.0284e+00,\n",
            "          4.1041e-01, -1.5281e+00],\n",
            "        ...,\n",
            "        [ 1.7703e-01,  2.4314e+00, -3.0876e+00,  ..., -6.8005e-01,\n",
            "         -2.1092e+00, -3.8469e-01],\n",
            "        [-3.0039e-03, -5.7766e+00, -4.3825e+00,  ..., -2.8855e+00,\n",
            "          1.8491e+00, -3.2248e+00],\n",
            "        [-8.4102e-01, -3.1597e+00, -4.7602e+00,  ...,  1.2927e+00,\n",
            "          3.3383e-02,  8.4180e-01]], device='cuda:0',\n",
            "       grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2226, -1.0953, -5.5299,  ...,  0.8227, -0.8851, -1.9532],\n",
            "        [ 0.8778, -2.7407, -3.3958,  ..., -3.3030, -3.9027, -4.1069],\n",
            "        [ 0.6646, -3.4347, -5.2375,  ..., -3.5681, -3.0732, -3.3944],\n",
            "        ...,\n",
            "        [ 0.6673, -1.9380, -5.5083,  ..., -1.5154, -2.5120, -3.9923],\n",
            "        [-0.7775, -0.2999, -3.9221,  ..., -1.9141, -0.2719,  0.0521],\n",
            "        [-1.6978, -0.2250, -4.5975,  ...,  0.7290,  0.7476,  2.8253]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-2.0756, -2.1482, -1.9731,  ...,  0.4253,  2.9505,  3.5484],\n",
            "        [-1.5010, -4.5737, -3.6579,  ..., -3.2232,  3.4385,  2.5114],\n",
            "        [-0.3825,  2.7868, -5.0554,  ..., -1.0034, -2.5520,  0.3490],\n",
            "        ...,\n",
            "        [ 1.2198, -3.2459, -3.8877,  ..., -3.9033, -0.5180, -1.8202],\n",
            "        [-1.4441, -0.1772, -4.1928,  ..., -0.2659, -2.4867, -1.7458],\n",
            "        [ 1.2178, -1.2262, -5.3452,  ...,  1.0781,  0.1098, -2.3669]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.1632, -3.0131, -6.2905,  ..., -1.3373, -1.8079, -1.3973],\n",
            "        [-0.5381, -2.0042, -5.1339,  ...,  0.4411,  0.8236,  0.2669],\n",
            "        [-0.5062, -0.3631, -5.1846,  ..., -1.5478,  0.3315, -2.0899],\n",
            "        ...,\n",
            "        [ 0.3298, -4.5166, -2.8078,  ..., -2.1290, -2.1633, -0.5819],\n",
            "        [ 0.7195,  0.7417, -0.9367,  ...,  2.6731, -1.4071,  1.5372],\n",
            "        [ 0.9117, -1.6884, -5.6003,  ...,  2.9426,  2.1897,  1.7458]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[ 0.9804, -3.9679, -5.5897,  ..., -0.3901,  2.8056,  1.9585],\n",
            "        [-0.9866, -3.1927, -4.8506,  ..., -3.1016, -1.4607, -0.5505],\n",
            "        [-0.0766,  3.0516, -1.3625,  ...,  2.4949, -1.2039,  0.9361],\n",
            "        ...,\n",
            "        [ 3.2151, -2.5319, -5.8692,  ..., -2.0144, -6.1135, -8.1593],\n",
            "        [-0.0310,  0.1427, -5.2501,  ..., -0.2825,  1.2473,  1.5584],\n",
            "        [-0.0684,  0.5690, -3.1646,  ..., -3.0631, -0.7791,  1.2501]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.0163, -1.2959, -3.3944,  ..., -0.0281, -3.7969, -5.9848],\n",
            "        [ 2.6366,  1.8750, -4.0097,  ...,  0.2297,  1.0272, -3.6816],\n",
            "        [ 1.0356, -1.6392, -4.0697,  ..., -2.5640, -0.0417, -2.8232],\n",
            "        ...,\n",
            "        [-0.0487,  3.5847, -3.6557,  ..., -0.8823,  0.0100, -0.5005],\n",
            "        [ 0.0323, -5.0769, -5.6068,  ..., -3.4153, -5.8088, -3.3050],\n",
            "        [-2.7498, -2.2147, -3.3611,  ...,  0.7850,  2.0153,  2.9465]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.8899, -5.0431, -5.3722,  ...,  0.4113,  2.6587,  2.7244],\n",
            "        [-0.7551, -6.5243, -4.1000,  ..., -1.5294,  0.7290, -0.4018],\n",
            "        [-0.8815,  0.8724, -5.5148,  ..., -0.3265, -2.0798, -2.6597],\n",
            "        ...,\n",
            "        [-1.6421, -3.9569, -2.0188,  ...,  0.1775,  0.8025,  0.8486],\n",
            "        [-1.5981,  0.0247, -2.8042,  ..., -0.4912,  0.8144, -2.1179],\n",
            "        [-0.9658, -4.2823, -4.1174,  ...,  1.7087,  2.8443,  2.6811]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.5480, -0.7133, -3.5735,  ...,  0.4340,  1.7166, -0.8411],\n",
            "        [ 3.8952,  0.4264, -4.1561,  ...,  2.5156,  0.2794, -3.4520],\n",
            "        [-0.0395, -7.8971, -4.9706,  ...,  0.2319,  2.3789,  1.0605],\n",
            "        ...,\n",
            "        [ 2.7936, -1.8669, -4.7136,  ..., -1.8886,  1.9203, -2.2202],\n",
            "        [-0.4418, -6.4268, -5.8471,  ..., -8.5885, -0.4736, -1.7317],\n",
            "        [ 3.1299, -3.6256, -6.5882,  ..., -5.7172,  0.8204, -2.1141]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-1.4544, -2.3471, -4.3607,  ..., -1.7870, -3.2341, -1.9574],\n",
            "        [-0.6811, -2.8037, -4.3356,  ..., -1.3557, -2.3390, -3.5222],\n",
            "        [-0.9097, -4.3940, -6.6011,  ..., -0.8876,  0.1000,  3.7370],\n",
            "        ...,\n",
            "        [ 1.6037, -2.6795, -4.8932,  ..., -0.7089, -0.1753, -4.1493],\n",
            "        [ 2.6652, -1.9151, -4.3223,  ..., -3.2551, -0.5677, -1.3336],\n",
            "        [-1.1187, -0.8222, -2.2647,  ..., -1.1136,  1.4941, -1.9457]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n",
            "tensor([[-0.2087, -1.6120, -2.7642,  ...,  2.8705,  1.8119,  2.5080],\n",
            "        [-2.5120, -2.1273, -3.9494,  ...,  0.0848,  0.6362, -0.7126],\n",
            "        [ 0.7729,  0.6744, -3.3083,  ...,  0.2838,  0.2569, -2.1358],\n",
            "        ...,\n",
            "        [ 3.7216, -2.6021, -5.3220,  ..., -0.4847, -6.8522, -7.0257],\n",
            "        [ 3.9461, -2.7643, -3.9284,  ..., -0.8945, -0.9079, -2.8601],\n",
            "        [ 1.0490,  0.4628, -3.8325,  ..., -2.0677, -1.4016, -0.4975]],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
          ]
        }
      ],
      "source": [
        "def train(args: SimpleMLPTrainingArgs) -> tuple[list[float], list[float], SimpleMLP]:\n",
        "    \"\"\"\n",
        "    Trains the model, using training parameters from the `args` object. Returns the model, and lists of loss & accuracy.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE - add a validation loop to the train function from above\n",
        "\n",
        "    epochs = args.epochs\n",
        "    learning_rate = args.learning_rate\n",
        "    batch_size = args.batch_size\n",
        "\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    train_loader = DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(mnist_testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      pbar = tqdm(train_loader)\n",
        "      for img, labels in train_loader:\n",
        "\n",
        "        img, labels = img.to(device), labels.to(device)\n",
        "\n",
        "        # 1. take batch and do forward pass\n",
        "        logits = model(img)\n",
        "        # 2. reset gradients\n",
        "        optimizer.zero_grad()\n",
        "        # 3. calculate loss on logits\n",
        "        loss = loss_function(logits, labels)\n",
        "        # 4. do backward pass\n",
        "        loss.backward()\n",
        "        # 5. use gradients to update parameters\n",
        "        optimizer.step()\n",
        "        # 6. continue\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "      # validate after each epoch:\n",
        "      with t.inference_mode(False):\n",
        "\n",
        "        # forward pass with val set\n",
        "        num_correct_classifications = 0\n",
        "        for img, labels in val_loader:\n",
        "          img, labels = img.to(device), labels.to(device)\n",
        "\n",
        "          logits = model(img)\n",
        "\n",
        "          # get pred classes\n",
        "          y_hat = t.argmax(logits, dim=1)\n",
        "          num_correct_classifications += (y_hat == labels).sum().item()\n",
        "\n",
        "      # Compute & log total accuracy\n",
        "      accuracy = num_correct_classifications / len(val_loader)\n",
        "      accuracy_list.append(accuracy)\n",
        "\n",
        "    return loss_list, accuracy_list, model\n",
        "\n",
        "\n",
        "args = SimpleMLPTrainingArgs()\n",
        "loss_list, accuracy_list, model = train(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_list)"
      ],
      "metadata": {
        "id": "_F0x_9h_G996",
        "outputId": "58426690-deae-4ec1-ffa8-cbc578f2ae6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[56.0625, 56.9375, 57.875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o8M8odHlG7V0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XkofcnZKjBUO",
        "outputId": "26c031d9-b799-48e0-e09a-e77d012add18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3221e92d-2d63-4526-80f5-6121e92bdf6d\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3221e92d-2d63-4526-80f5-6121e92bdf6d\")) {                    Plotly.newPlot(                        \"3221e92d-2d63-4526-80f5-6121e92bdf6d\",                        [{\"name\":\"Cross entropy loss\",\"x\":[0.0,63.829787234042556,127.65957446808511,191.48936170212767,255.31914893617022,319.1489361702128,382.97872340425533,446.8085106382979,510.63829787234044,574.468085106383,638.2978723404256,702.1276595744681,765.9574468085107,829.7872340425532,893.6170212765958,957.4468085106383,1021.2765957446809,1085.1063829787236,1148.936170212766,1212.7659574468084,1276.595744680851,1340.4255319148938,1404.2553191489362,1468.0851063829787,1531.9148936170213,1595.744680851064,1659.5744680851064,1723.404255319149,1787.2340425531916,1851.0638297872342,1914.8936170212767,1978.723404255319,2042.5531914893618,2106.3829787234044,2170.212765957447,2234.0425531914893,2297.872340425532,2361.7021276595747,2425.531914893617,2489.3617021276596,2553.191489361702,2617.021276595745,2680.8510638297876,2744.68085106383,2808.5106382978724,2872.340425531915,2936.1702127659573,3000.0,3063.8297872340427,3127.6595744680853,3191.489361702128,3255.31914893617,3319.148936170213,3382.9787234042556,3446.808510638298,3510.6382978723404,3574.468085106383,3638.297872340426,3702.1276595744685,3765.9574468085107,3829.7872340425533,3893.617021276596,3957.446808510638,4021.276595744681,4085.1063829787236,4148.936170212766,4212.765957446809,4276.595744680852,4340.425531914894,4404.255319148936,4468.085106382979,4531.914893617021,4595.744680851064,4659.574468085107,4723.404255319149,4787.234042553192,4851.063829787234,4914.893617021276,4978.723404255319,5042.553191489362,5106.382978723404,5170.212765957447,5234.04255319149,5297.8723404255325,5361.702127659575,5425.531914893617,5489.36170212766,5553.191489361702,5617.021276595745,5680.851063829788,5744.68085106383,5808.510638297873,5872.340425531915,5936.170212765957,6000.0,6063.829787234043,6127.659574468085,6191.489361702128,6255.319148936171,6319.148936170213,6382.978723404256,6446.808510638298,6510.63829787234,6574.468085106383,6638.297872340426,6702.127659574468,6765.957446808511,6829.787234042554,6893.617021276596,6957.446808510638,7021.276595744681,7085.106382978724,7148.936170212766,7212.765957446809,7276.595744680852,7340.425531914894,7404.255319148937,7468.085106382979,7531.914893617021,7595.744680851064,7659.574468085107,7723.404255319149,7787.234042553192,7851.063829787235,7914.893617021276,7978.723404255319,8042.553191489362,8106.382978723404,8170.212765957447,8234.04255319149,8297.872340425532,8361.702127659575,8425.531914893618,8489.36170212766,8553.191489361703,8617.021276595746,8680.851063829788,8744.68085106383,8808.510638297872,8872.340425531915,8936.170212765957,9000.0,9063.829787234043,9127.659574468085,9191.489361702128,9255.31914893617,9319.148936170213,9382.978723404256,9446.808510638299,9510.638297872341,9574.468085106384,9638.297872340427,9702.127659574468,9765.95744680851,9829.787234042553,9893.617021276596,9957.446808510638,10021.27659574468,10085.106382978724,10148.936170212766,10212.765957446809,10276.595744680852,10340.425531914894,10404.255319148937,10468.08510638298,10531.914893617022,10595.744680851065,10659.574468085108,10723.40425531915,10787.234042553191,10851.063829787234,10914.893617021276,10978.72340425532,11042.553191489362,11106.382978723404,11170.212765957447,11234.04255319149,11297.872340425532,11361.702127659575,11425.531914893618,11489.36170212766,11553.191489361703,11617.021276595746,11680.851063829788,11744.68085106383,11808.510638297872,11872.340425531915,11936.170212765957,12000.0,12063.829787234043,12127.659574468085,12191.489361702128,12255.31914893617,12319.148936170213,12382.978723404256,12446.808510638299,12510.638297872341,12574.468085106384,12638.297872340427,12702.12765957447,12765.957446808512,12829.787234042553,12893.617021276596,12957.446808510638,13021.27659574468,13085.106382978724,13148.936170212766,13212.765957446809,13276.595744680852,13340.425531914894,13404.255319148937,13468.08510638298,13531.914893617022,13595.744680851065,13659.574468085108,13723.40425531915,13787.234042553191,13851.063829787234,13914.893617021276,13978.72340425532,14042.553191489362,14106.382978723404,14170.212765957447,14234.04255319149,14297.872340425532,14361.702127659575,14425.531914893618,14489.36170212766,14553.191489361703,14617.021276595746,14680.851063829788,14744.680851063831,14808.510638297874,14872.340425531915,14936.170212765957,15000.0,15063.829787234043,15127.659574468085,15191.489361702128,15255.31914893617,15319.148936170213,15382.978723404256,15446.808510638299,15510.638297872341,15574.468085106384,15638.297872340427,15702.12765957447,15765.957446808512,15829.787234042553,15893.617021276596,15957.446808510638,16021.27659574468,16085.106382978724,16148.936170212766,16212.765957446809,16276.595744680852,16340.425531914894,16404.255319148935,16468.08510638298,16531.91489361702,16595.744680851065,16659.574468085106,16723.40425531915,16787.23404255319,16851.063829787236,16914.893617021276,16978.72340425532,17042.55319148936,17106.382978723406,17170.212765957447,17234.04255319149,17297.872340425532,17361.702127659577,17425.531914893618,17489.36170212766,17553.191489361703,17617.021276595744,17680.85106382979,17744.68085106383,17808.510638297874,17872.340425531915,17936.17021276596,18000.0,18063.829787234044,18127.659574468085,18191.48936170213,18255.31914893617,18319.148936170215,18382.978723404256,18446.808510638297,18510.63829787234,18574.468085106382,18638.297872340427,18702.127659574468,18765.957446808512,18829.787234042553,18893.617021276597,18957.44680851064,19021.276595744683,19085.106382978724,19148.936170212768,19212.76595744681,19276.595744680853,19340.425531914894,19404.255319148935,19468.08510638298,19531.91489361702,19595.744680851065,19659.574468085106,19723.40425531915,19787.23404255319,19851.063829787236,19914.893617021276,19978.72340425532,20042.55319148936,20106.382978723406,20170.212765957447,20234.04255319149,20297.872340425532,20361.702127659577,20425.531914893618,20489.36170212766,20553.191489361703,20617.021276595744,20680.85106382979,20744.68085106383,20808.510638297874,20872.340425531915,20936.17021276596,21000.0,21063.829787234044,21127.659574468085,21191.48936170213,21255.31914893617,21319.148936170215,21382.978723404256,21446.8085106383,21510.63829787234,21574.468085106382,21638.297872340427,21702.127659574468,21765.957446808512,21829.787234042553,21893.617021276597,21957.44680851064,22021.276595744683,22085.106382978724,22148.936170212768,22212.76595744681,22276.595744680853,22340.425531914894,22404.25531914894,22468.08510638298,22531.91489361702,22595.744680851065,22659.574468085106,22723.40425531915,22787.23404255319,22851.063829787236,22914.893617021276,22978.72340425532,23042.55319148936,23106.382978723406,23170.212765957447,23234.04255319149,23297.872340425532,23361.702127659577,23425.531914893618,23489.36170212766,23553.191489361703,23617.021276595744,23680.85106382979,23744.68085106383,23808.510638297874,23872.340425531915,23936.17021276596,24000.0,24063.829787234044,24127.659574468085,24191.48936170213,24255.31914893617,24319.148936170215,24382.978723404256,24446.8085106383,24510.63829787234,24574.468085106382,24638.297872340427,24702.127659574468,24765.957446808512,24829.787234042553,24893.617021276597,24957.44680851064,25021.276595744683,25085.106382978724,25148.936170212768,25212.76595744681,25276.595744680853,25340.425531914894,25404.25531914894,25468.08510638298,25531.914893617024,25595.744680851065,25659.574468085106,25723.40425531915,25787.23404255319,25851.063829787236,25914.893617021276,25978.72340425532,26042.55319148936,26106.382978723406,26170.212765957447,26234.04255319149,26297.872340425532,26361.702127659577,26425.531914893618,26489.361702127662,26553.191489361703,26617.021276595744,26680.85106382979,26744.68085106383,26808.510638297874,26872.340425531915,26936.17021276596,27000.0,27063.829787234044,27127.659574468085,27191.48936170213,27255.31914893617,27319.148936170215,27382.978723404256,27446.8085106383,27510.63829787234,27574.468085106382,27638.297872340427,27702.127659574468,27765.957446808512,27829.787234042553,27893.617021276597,27957.44680851064,28021.276595744683,28085.106382978724,28148.936170212768,28212.76595744681,28276.595744680853,28340.425531914894,28404.25531914894,28468.08510638298,28531.914893617024,28595.744680851065,28659.574468085106,28723.40425531915,28787.23404255319,28851.063829787236,28914.893617021276,28978.72340425532,29042.55319148936,29106.382978723406,29170.212765957447,29234.04255319149,29297.872340425532,29361.702127659577,29425.531914893618,29489.361702127662,29553.191489361703,29617.021276595748,29680.85106382979,29744.68085106383,29808.510638297874,29872.340425531915,29936.17021276596,30000.0],\"y\":[3.013319730758667,2.454908847808838,2.1878674030303955,2.252288818359375,1.7706025838851929,1.7746590375900269,1.4746417999267578,1.3331469297409058,1.2439225912094116,1.2810101509094238,1.210694432258606,0.9993618130683899,0.8842372894287109,0.9021439552307129,0.9253187775611877,0.9131500720977783,0.937325119972229,0.7593552470207214,0.6214609742164612,0.6427025198936462,0.7949110865592957,0.45761197805404663,0.9599953293800354,0.640823245048523,0.6851221323013306,0.6872782707214355,0.6347675919532776,0.37330958247184753,0.4399060606956482,0.48963072896003723,0.47875747084617615,0.7114629745483398,0.6591612696647644,0.5219495892524719,0.43228405714035034,0.5849456787109375,0.44926825165748596,0.40373510122299194,0.35325005650520325,0.3445197343826294,0.3748375177383423,0.6397331357002258,0.5593047142028809,0.5963985919952393,0.317037969827652,0.5706172585487366,0.5527465343475342,0.42062413692474365,0.3759523034095764,0.5418496131896973,0.6699753403663635,0.2677925229072571,0.33698177337646484,0.4392145276069641,0.38380008935928345,0.49082303047180176,0.3175308108329773,0.49453526735305786,0.5034109354019165,0.48306989669799805,0.3971051871776581,0.3635626435279846,0.4403630793094635,0.32518455386161804,0.4319523870944977,0.7216818332672119,0.5514267683029175,0.35913243889808655,0.2775323688983917,0.33612221479415894,0.27264609932899475,0.3604983985424042,0.4979119300842285,0.33755597472190857,0.29938608407974243,0.4873896539211273,0.5309723615646362,0.5443701148033142,0.5107735395431519,0.34433668851852417,0.4254568815231323,0.4135638177394867,0.18591834604740143,0.37919530272483826,0.1938350796699524,0.24550673365592957,0.5747711658477783,0.2730735242366791,0.2540556788444519,0.24374425411224365,0.1916377991437912,0.3630044758319855,0.34087830781936646,0.30126187205314636,0.28382614254951477,0.29438647627830505,0.3993598222732544,0.3127114772796631,0.29865577816963196,0.4160696864128113,0.4870236814022064,0.300808846950531,0.532203733921051,0.2262450009584427,0.3776663839817047,0.38535863161087036,0.39880773425102234,0.38796424865722656,0.2550424337387085,0.4098043739795685,0.21885128319263458,0.40306705236434937,0.2758120596408844,0.23576904833316803,0.2420044094324112,0.24473117291927338,0.2936755120754242,0.22574159502983093,0.261457234621048,0.15686750411987305,0.2726866900920868,0.20483388006687164,0.3105625808238983,0.2645971477031708,0.26700687408447266,0.35475629568099976,0.32427099347114563,0.5085041522979736,0.1579468995332718,0.3511289656162262,0.22286243736743927,0.34451088309288025,0.6296359300613403,0.2762407958507538,0.2099117785692215,0.49211978912353516,0.22596032917499542,0.43468767404556274,0.1989491879940033,0.42609846591949463,0.3118688762187958,0.5069140195846558,0.4882504940032959,0.29641833901405334,0.503744900226593,0.301329642534256,0.3025742471218109,0.17669282853603363,0.19284695386886597,0.15211835503578186,0.18763169646263123,0.2595146596431732,0.2909836769104004,0.18908685445785522,0.1610933244228363,0.24813665449619293,0.05803500860929489,0.18740437924861908,0.13832536339759827,0.33934804797172546,0.3581539988517761,0.25610196590423584,0.2003600001335144,0.21188083291053772,0.25268030166625977,0.13996407389640808,0.300376296043396,0.24051415920257568,0.3141176402568817,0.1783907562494278,0.3720349669456482,0.3730648159980774,0.20748192071914673,0.19559651613235474,0.17398227751255035,0.3206217586994171,0.36438727378845215,0.2915143370628357,0.28339874744415283,0.42616912722587585,0.2739819288253784,0.34689220786094666,0.22537924349308014,0.18134461343288422,0.1655251532793045,0.1969081163406372,0.19062349200248718,0.22700165212154388,0.15465688705444336,0.17604710161685944,0.28471291065216064,0.3085637092590332,0.2539243996143341,0.3263571858406067,0.15130656957626343,0.2225126028060913,0.15715716779232025,0.2638219892978668,0.3680990934371948,0.2088722586631775,0.15738198161125183,0.2682941257953644,0.15139909088611603,0.192183256149292,0.3278537392616272,0.4078623354434967,0.21170800924301147,0.2684955596923828,0.19444260001182556,0.09348076581954956,0.18457096815109253,0.2827463746070862,0.16565492749214172,0.3517186641693115,0.21900703012943268,0.3918972909450531,0.2101111263036728,0.26806098222732544,0.15734823048114777,0.38016217947006226,0.2633192539215088,0.14711256325244904,0.23365430533885956,0.19626739621162415,0.18459656834602356,0.19801294803619385,0.24936476349830627,0.13027018308639526,0.30441129207611084,0.21328625082969666,0.14499840140342712,0.1799304336309433,0.1354624629020691,0.27685320377349854,0.2545754313468933,0.26831135153770447,0.10097898542881012,0.4284511208534241,0.15419591963291168,0.32264143228530884,0.16455481946468353,0.2676827609539032,0.18756654858589172,0.1850111335515976,0.18830175697803497,0.10536003857851028,0.14764918386936188,0.15577299892902374,0.3621443510055542,0.23971068859100342,0.3068965673446655,0.2561953663825989,0.1485486775636673,0.0998811274766922,0.24993932247161865,0.22116713225841522,0.12867729365825653,0.16692739725112915,0.5561683177947998,0.09214575588703156,0.2570274770259857,0.2033589780330658,0.24014326930046082,0.1266714185476303,0.35740843415260315,0.3905940651893616,0.12527260184288025,0.2732173204421997,0.16835269331932068,0.24007825553417206,0.19859226047992706,0.10622164607048035,0.31341269612312317,0.08343088626861572,0.16686835885047913,0.08076782524585724,0.12025517970323563,0.185322105884552,0.14491841197013855,0.1346355527639389,0.18436819314956665,0.17201898992061615,0.1445712149143219,0.33310315012931824,0.25686684250831604,0.31189194321632385,0.30930769443511963,0.112120620906353,0.17600642144680023,0.18932926654815674,0.3304630517959595,0.1870647668838501,0.08724503219127655,0.28280800580978394,0.039823781698942184,0.19857396185398102,0.1691235452890396,0.23450203239917755,0.13717883825302124,0.38355588912963867,0.07770051062107086,0.17192783951759338,0.16478124260902405,0.22720447182655334,0.1586211770772934,0.30613821744918823,0.3193354904651642,0.2609516680240631,0.21119466423988342,0.24482792615890503,0.16117355227470398,0.16672015190124512,0.08659154921770096,0.07275120168924332,0.12646766006946564,0.1348467469215393,0.25594407320022583,0.073160819709301,0.10827246308326721,0.1304033398628235,0.04120088368654251,0.048665959388017654,0.14908675849437714,0.06709212064743042,0.11428084224462509,0.15556252002716064,0.25073906779289246,0.19564294815063477,0.22206637263298035,0.2017882913351059,0.10426357388496399,0.18494769930839539,0.1264137625694275,0.03935360163450241,0.08491085469722748,0.09672347456216812,0.2456331104040146,0.30751484632492065,0.2229323387145996,0.19956627488136292,0.18902583420276642,0.10336194932460785,0.15399408340454102,0.14749611914157867,0.1545770913362503,0.1792609542608261,0.10950116813182831,0.06629480421543121,0.175863578915596,0.20094317197799683,0.1100318506360054,0.1480513960123062,0.16026650369167328,0.06062229722738266,0.24501025676727295,0.19024606049060822,0.3306973874568939,0.12367870658636093,0.09878738224506378,0.16585296392440796,0.10233767330646515,0.19289831817150116,0.10623309016227722,0.13918529450893402,0.16227585077285767,0.15421120822429657,0.10427226126194,0.13497468829154968,0.22922390699386597,0.07513906061649323,0.1473769247531891,0.23582588136196136,0.30537480115890503,0.1655873954296112,0.05964917317032814,0.09796421229839325,0.14282234013080597,0.06381823867559433,0.15997977554798126,0.056967101991176605,0.14725017547607422,0.22794973850250244,0.0864623561501503,0.15143929421901703,0.10964255779981613,0.2403588891029358,0.25058892369270325,0.16943806409835815,0.09523118287324905,0.30348753929138184,0.13575483858585358,0.16068017482757568,0.1733875870704651,0.3442513346672058,0.0935557559132576,0.270907461643219,0.1981547772884369,0.0791260227560997,0.19233345985412598,0.3431624472141266,0.30951055884361267,0.13232550024986267,0.13452474772930145,0.1820598691701889,0.1417112946510315,0.04717579856514931,0.3496856689453125,0.128247931599617,0.13952580094337463,0.12110750377178192,0.14531534910202026,0.1258658915758133,0.14942483603954315,0.24709071218967438,0.3356318175792694,0.34013795852661133,0.07919278740882874,0.34362876415252686,0.16583117842674255,0.15343859791755676,0.06675581634044647,0.2548500895500183,0.13213315606117249,0.13995113968849182,0.12498252838850021,0.23606976866722107,0.11467620730400085,0.3212131857872009,0.14277243614196777,0.08176133781671524,0.13631947338581085,0.41721802949905396,0.06095721945166588,0.1272219568490982,0.0963921844959259,0.25920289754867554,0.1183747723698616,0.17119555175304413,0.19584903120994568,0.12207228690385818,0.20484773814678192,0.13523586094379425,0.10611400753259659,0.1322149932384491,0.22720541059970856,0.08104145526885986,0.10799170285463333,0.14752520620822906,0.1288907378911972,0.14992700517177582,0.2521958649158478,0.05778507515788078,0.12425556778907776,0.051606547087430954,0.15545989573001862,0.31111815571784973,0.2443063110113144,0.13010098040103912,0.05056310445070267,0.290647029876709,0.167868509888649,0.10296431928873062,0.24179427325725555,0.09227465093135834,0.09475281834602356,0.16394300758838654,0.17107528448104858,0.19303575158119202,0.16823571920394897,0.15503765642642975,0.6316220760345459],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Test Accuracy\",\"x\":[0.0,10000.0,20000.0,30000.0],\"y\":[0.1,56.0625,56.9375,57.875],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Num examples seen\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Cross entropy loss\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Test Accuracy\"}},\"hovermode\":\"x unified\",\"title\":{\"text\":\"SimpleMLP training on MNIST\"},\"width\":800},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3221e92d-2d63-4526-80f5-6121e92bdf6d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "line(\n",
        "    y=[loss_list, [0.1] + accuracy_list],  # we start by assuming a uniform accuracy of 10%\n",
        "    use_secondary_yaxis=True,\n",
        "    x_max=args.epochs * len(mnist_trainset),\n",
        "    labels={\"x\": \"Num examples seen\", \"y1\": \"Cross entropy loss\", \"y2\": \"Test Accuracy\"},\n",
        "    title=\"SimpleMLP training on MNIST\",\n",
        "    width=800,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.signal import convolve2d\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Create a larger image (40x40) with structure (hollow rectangle)\n",
        "image_size = 40\n",
        "original_image = np.zeros((image_size, image_size), dtype=np.float32) # Black background\n",
        "\n",
        "# Define rectangle boundaries (adjust thickness by changing the range)\n",
        "top_row, bottom_row = 5, image_size - 6\n",
        "left_col, right_col = 5, image_size - 6\n",
        "thickness = 2 # Make lines thicker\n",
        "\n",
        "# Draw rectangle (set pixels to 1.0 for white)\n",
        "original_image[top_row:bottom_row+thickness, left_col:left_col+thickness] = 1.0 # Top-left corner area\n",
        "original_image[top_row:bottom_row+thickness, right_col:right_col+thickness] = 1.0 # Top-right corner area\n",
        "original_image[top_row:top_row+thickness, left_col:right_col+thickness] = 1.0 # Top edge area\n",
        "original_image[bottom_row:bottom_row+thickness, left_col:right_col+thickness] = 1.0 # Bottom edge area\n",
        "\n",
        "\n",
        "# 2. Define the 3x3 average pooling kernel (remains the same)\n",
        "kernel = np.ones((2, 2), dtype=np.float32) / 1.0\n",
        "\n",
        "kernel = t.tensor([0.5, 0.0, -0.5]).repeat((3, 1))\n",
        "\n",
        "print(kernel)\n",
        "\n",
        "# 3. Convolve the image with the kernel\n",
        "# 'valid' mode: output size will be (image_size - kernel_size + 1)\n",
        "convolved_image = convolve2d(original_image, kernel, mode='valid')\n",
        "\n",
        "# 4. Plot the original and convolved images\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5)) # Adjusted figure size\n",
        "\n",
        "# Plot Original Image\n",
        "axes[0].imshow(original_image, cmap='gray', vmin=0, vmax=1)\n",
        "axes[0].set_title(f'Original Image ({original_image.shape[0]}x{original_image.shape[1]})')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Plot Convolved Image\n",
        "axes[1].imshow(convolved_image, cmap='gray', vmin=0, vmax=1)\n",
        "axes[1].set_title(f'Convolved (Avg. Pooled) ({convolved_image.shape[0]}x{convolved_image.shape[1]})')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Original Image Shape:\", original_image.shape)\n",
        "print(\"Kernel Shape:\", kernel.shape)\n",
        "print(\"Convolved Image Shape:\", convolved_image.shape)\n",
        "# Optional: Print a small section if needed, full arrays are large\n",
        "# print(\"\\nOriginal Image Tensor (Top-Left Corner):\\n\", original_image[0:8, 0:8])\n",
        "# print(\"\\nConvolved Image Tensor (Top-Left Corner):\\n\", convolved_image[0:6, 0:6])"
      ],
      "metadata": {
        "id": "Y8jMffwWC9K7",
        "outputId": "5b9b02e0-bb5c-4de9-c2db-98fc2c2426d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5000,  0.0000, -0.5000],\n",
            "        [ 0.5000,  0.0000, -0.5000],\n",
            "        [ 0.5000,  0.0000, -0.5000]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Image Shape: (40, 40)\n",
            "Kernel Shape: torch.Size([3, 3])\n",
            "Convolved Image Shape: (38, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6xo0Kn9jBUO"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to measure correct classifications.</summary>\n",
        "\n",
        "You can take argmax of the output of your model, using `torch.argmax` (with the keyword argument `dim` to specify the dimension you want to take max over).\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I get <code>RuntimeError: expected scalar type Float but found Byte</code>.</summary>\n",
        "\n",
        "This is commonly because one of your operations is between tensors with the wrong datatypes (e.g. `int` and `float`). You can try adding assert or logging statements in your code, or alternatively if you're in VSCode then you can try navigating to the error line and checking your dtypes using VSCode's built-in debugger.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def train(args: SimpleMLPTrainingArgs) -> tuple[list[float], list[float], SimpleMLP]:\n",
        "    \"\"\"\n",
        "    Trains the model, using training parameters from the `args` object. Returns the model, and lists of loss & accuracy.\n",
        "    \"\"\"\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    mnist_trainset, mnist_testset = get_mnist()\n",
        "    mnist_trainloader = DataLoader(mnist_trainset, batch_size=args.batch_size, shuffle=True)\n",
        "    mnist_testloader = DataLoader(mnist_testset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "    accuracy = 0.0\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # Training loop\n",
        "        pbar = tqdm(mnist_trainloader)\n",
        "        for imgs, labels in pbar:\n",
        "            # Move data to device, perform forward pass\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            # Calculate loss, perform backward pass\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update logs & progress bar\n",
        "            loss_list.append(loss.item())\n",
        "            pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        num_correct_classifications = 0\n",
        "        for imgs, labels in mnist_testloader:\n",
        "            # Move data to device, perform forward pass in inference mode\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with t.inference_mode():\n",
        "                logits = model(imgs)\n",
        "\n",
        "            # Compute num correct by comparing argmaxed logits to true labels\n",
        "            predictions = t.argmax(logits, dim=1)\n",
        "            num_correct_classifications += (predictions == labels).sum().item()\n",
        "\n",
        "        # Compute & log total accuracy\n",
        "        accuracy = num_correct_classifications / len(mnist_testset)\n",
        "        accuracy_list.append(accuracy)\n",
        "\n",
        "    return loss_list, accuracy_list, model\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fefPyRdrjBUO"
      },
      "source": [
        "You should find that after the first epoch, the model is already doing much better than random chance (i.e. >80%), and it improves slightly in subsequent epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfzzybg8jBUO"
      },
      "source": [
        "# 3️⃣ Convolutions\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn how convolutions work, and why they are useful for vision models\n",
        "> * Implement your own convolutions, and maxpooling layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcNZO8ZjjBUO"
      },
      "source": [
        "_Note, this section is light on exercises, because it actually ends up being surprisingly hard to implement convolutional and linear operations from scratch (unlike the case for linear layers). It requires engaging with **strides**, an under-the-hood attribute of PyTorch tensors which we usually don't think about in regular work. For this reason, this section focuses more on understanding how convolutions work & giving you implementations of it, rather than asking you to implement it from scratch. There are implementation from scratch exercises in the bonus section at the end of today's material, if you get that far!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEE91TP1jBUO"
      },
      "source": [
        "## Reading\n",
        "\n",
        "We strongly recommend you at least watch the video in the first bullet point. The second article is recommended, but not essential. The third is more for interest (and will be more relevant next week, when we study interpretability).\n",
        "\n",
        "* [But what is a convolution?](https://www.youtube.com/watch?v=KuXjwB4LzSA) by 3Blue1Brown\n",
        "* [A Comprehensive Guide to Convolutional Neural Networks (Medium)](https://medium.com/towards-data-science/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)\n",
        "* [Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-MleGB0jBUO"
      },
      "source": [
        "## What are convolutions?\n",
        "\n",
        "A convolution is an operation which takes a kernel and slides it across the input, applying the kernel to each patch of the input. We can view it as a logical extension of the linear layer, except rather than having every output value being determined as a linear combination of every input value, we have a **prior of locality** - assuming that the input has some spatial structure, and each output value should only be determined by a small patch of the input. The kernel contains our learned weights, and we slide that kernel across our input, with each output value being computed by a sumproduct of the kernel values and the corresponding patch in the input. Note that we use all input channels when computing each output value, which means the sumproduct is over `kernel_length * in_channels` elements (or `kernel_width * kernel_height * in_channels` when, as is most often the case, we're using 2D kernels)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5dLKPJujBUO"
      },
      "source": [
        "### Mathematical definition\n",
        "\n",
        "Convolutions have 4 important parameters:\n",
        "\n",
        "- **Size** - the size of the kernel, i.e. the size of each patch of the input that the kernel is applied to when computing each output value.\n",
        "- **Stride** - the distance the kernel moves each time it is applied.\n",
        "- **Padding** - the number of pixels we pad around the input on each side.\n",
        "- **Output channels** - the number of separate kernels of shape `(in_channels, kernel_width, kernel_height)` we apply to the input. Each separate kernel has different learned weights, and will produce a separate output channel.\n",
        "\n",
        "Below is an illustration with `size=(3,3), stride=1, padding=1`, three input channels and a single output channel.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*ciDgQEjViWLnCbmX-EeSrA.gif\" width=\"800\">\n",
        "\n",
        "For width or height, we can compute the output dim size as a function of the input dim and convolution parameters:\n",
        "\n",
        "$$\n",
        "L_{\\text {out }}=\\left\\lfloor\\dfrac{L_{\\text {in }}+2 \\times \\text { padding }- \\text { kernel\\_size }}{\\text { stride }}+1\\right\\rfloor\n",
        "$$\n",
        "\n",
        "Notably, with our parameters `size=(3,3), stride=1, padding=1` this simplifies to $L_{\\text{out}} = \\left\\lfloor\\frac{L_{\\text{in}} + 2 - 3}{1} + 1\\right\\rfloor = L_{\\text{in}}$. We refer to this as a **shape-preserving convolution**, because the input & output dimensions for width/height are the same. This is quite useful because often when building neural networks we have to be careful to match the shapes of different tensors (otherwise skip connections will fail - we can't add together `x + conv(x)` if they're different shapes!).\n",
        "\n",
        "> A quick note on terminology - you might see docs and docstrings use `num_features`, sometimes use `channels` (sometimes abbreviated as $N_{in}$ or $C$ in PyTorch docs). When we're talking about convolutions specifically, these usually mean the same thing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJMslSkVjBUP"
      },
      "source": [
        "### What do convolutions learn?\n",
        "\n",
        "The terminology `num_features` hints at this, but often convolutions can be thought of as learning certain features from our data. For instance, there's evidence to suggest that early convolutional layers pick up on very simple low-level features such as edges, corners and curves, whereas later convolutional layers are able to combine these lower-level features hierarchically to form more complex representations.\n",
        "\n",
        "For more on this, we recommend the Distill post [Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/), which discusses various lines of evidence for interpreting the features learned by convolutional layers (and how they connect up to form circuits). Interestingly, this post philosophically underpins quite a lot of the current interpretability field - even though the focus has primarily shifted from vision models to language models, many of the underlying ideas remain the same.\n",
        "\n",
        "<img src=\"https://distill.pub/2020/circuits/zoom-in/images/curves.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPT61hsvjBUP"
      },
      "source": [
        "### Some questions about convolutions\n",
        "\n",
        "Here are some questions about convolutions to make sure you've understood the material. You should try and answer these questions without referring back to the article or video above.\n",
        "\n",
        "<details>\n",
        "<summary>Why would convolutional layers be less likely to overfit data than standard linear (fully connected) layers?</summary>\n",
        "\n",
        "Convolutional layers require significantly fewer weights to be learned. This is because the same kernel is applied all across the image, rather than every pair of `(input, output)` nodes requiring a different weight to be learned.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Suppose you fixed some random permutation of the pixels in an image, and applied this to all images in your dataset, before training a convolutional neural network for classifying images. Do you expect this to be less effective, or equally effective?</summary>\n",
        "\n",
        "It will be less effective, because CNNs work thanks to **spatial locality** - groups of pixels close together are more meaningful. For instance, CNNs will often learn convolutions at an early layer which recognise gradients or simple shapes. If you permute the pixels (even if you permute in the same way for every image), you destroy locality.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>If you have a 28x28 image, and you apply a 3x3 convolution with stride 2, padding 1, and 5 output channels, what shape will the output be?</summary>\n",
        "\n",
        "Applying the formula above, we get:\n",
        "\n",
        "$\n",
        "L_{\\text {out }}=\\left\\lfloor\\frac{L_{\\text {in }}+2 \\times \\text { padding }- \\text { kernel\\_size }}{\\text { stride }}+1\\right\\rfloor = \\left\\lfloor\\frac{28 + 2 \\times 1 - 3}{2} + 1\\right\\rfloor = 14\n",
        "$\n",
        "\n",
        "So our image has width & height 14. The shape will go from `(3, 28, 28)` to `(5, 14, 14)` (since the output dimensions are `out_channels, width, height`).\n",
        "\n",
        "As a general rule, a 3x3 convolution with padding 1, stride `stride` and input images with shape `(width, height)` will map to an output shape of `(width // stride, height // stride)`. This will be useful when we study GANs tomorrow, and we'll assemble a series of 3x3 convolutions with padding 1 and stride 2, which should each halve our input image size.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r5QjYtjjBUP"
      },
      "source": [
        "### Exercise - implement `Conv2d`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-20 minutes on this exercise.\n",
        "> This only requires you to create the conv weights - making your own fwd pass method is a bonus exercise later.\n",
        "> ```\n",
        "\n",
        "Rather than implementing the `conv2d` function from scratch, we'll allow you to use `t.nn.functional.conv2d`. In the exercise below, you should use this function to implement the `nn.Conv2d` layer. All you need to do is fill in the `__init__` method. Some guidance:\n",
        "\n",
        "- You should look at the PyTorch page for `nn.Conv2d` [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) (and review the discussion above) to understand what the shape of the weights should be.\n",
        "- We assume `bias=False`, so the only `nn.Parameter` object we need to define is `weight`.\n",
        "- You should use **uniform Kaiming initialization** like you have before, i.e. the bounds of the uniform distribution should be $\\pm 1/\\sqrt{N_{in}}$ where $N_{in}$ is the product of input channels and kernel height & width, as described at the bottom of the `nn.Conv2d` docs (the bullet points under the **Variables** header).\n",
        "\n",
        "<details>\n",
        "<summary>Question - why do you think we use the product of input channels and kernel height & width for our Kaiming initialization bounds?</summary>\n",
        "\n",
        "This is because each value in the output is computed by taking the product over `in_channels * kernel_height * kernel_width` elements, analogously to how each value in the linear layer is computed by taking the product over just `in_features` elements.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNDFqBv6jBUP"
      },
      "outputs": [],
      "source": [
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0):\n",
        "        \"\"\"\n",
        "        Same as torch.nn.Conv2d with bias=False.\n",
        "\n",
        "        Name your weight field `self.weight` for compatibility with the PyTorch version.\n",
        "\n",
        "        We assume kernel is square, with height = width = `kernel_size`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        # YOUR CODE HERE - define & initialize `self.weight`\n",
        "        pass\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Apply the functional conv2d, which you can import.\"\"\"\n",
        "        return t.nn.functional.conv2d(x, self.weight, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "\n",
        "\n",
        "tests.test_conv2d_module(Conv2d)\n",
        "m = Conv2d(in_channels=24, out_channels=12, kernel_size=3, stride=2, padding=1)\n",
        "print(f\"Manually verify that this is an informative repr: {m}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtXz-fmKjBUP"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0):\n",
        "        \"\"\"\n",
        "        Same as torch.nn.Conv2d with bias=False.\n",
        "\n",
        "        Name your weight field `self.weight` for compatibility with the PyTorch version.\n",
        "\n",
        "        We assume kernel is square, with height = width = `kernel_size`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        kernel_height = kernel_width = kernel_size\n",
        "        sf = 1 / np.sqrt(in_channels * kernel_width * kernel_height)\n",
        "        self.weight = nn.Parameter(sf * (2 * t.rand(out_channels, in_channels, kernel_height, kernel_width) - 1))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Apply the functional conv2d, which you can import.\"\"\"\n",
        "        return t.nn.functional.conv2d(x, self.weight, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pL7QknMjBUP"
      },
      "source": [
        "### `MaxPool2d`\n",
        "\n",
        "We often add a maxpool layer after a convolutional layer. This layer is responsible for reducing the spatial size of the convolved feature. It works by taking the maximum value in each kernel-sized window, and outputting that value. For instance, if we have a 2x2 kernel, then we take the maximum of each 2x2 window in the input.\n",
        "\n",
        "Maxpool is useful for downsampling the image (reducing the total amount of data we're having to work with), as well as extracting dominant features in the image. For example, if we're training a model for classification, the model might find it useful to create a \"wheel detector\" to identify whether a wheel is present in the image - even if most chunks of the image don't contain a wheel, we care more about whether a wheel exists _somewhere_ in the image, and so we might only be interested in the largest values.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*uoWYsCV5vBU8SHFPAPao-w.gif\" width=\"360\">\n",
        "\n",
        "We've given you `MaxPool2d` below. This is a wrapper for the `max_pool2d` function (although in the bonus exercises later you can implement your own version of this)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FDU_AqxjBUP"
      },
      "outputs": [],
      "source": [
        "class MaxPool2d(nn.Module):\n",
        "    def __init__(self, kernel_size: int, stride: int | None = None, padding: int = 1):\n",
        "        super().__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Call the functional version of maxpool2d.\"\"\"\n",
        "        return F.max_pool2d(x, kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        \"\"\"Add additional information to the string representation of this class.\"\"\"\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in [\"kernel_size\", \"stride\", \"padding\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfKdK3CsjBUP"
      },
      "source": [
        "# 4️⃣ ResNets\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn about skip connections, and how they help overcome the degradation problem\n",
        "> * Learn about batch normalization, and why it is used in training\n",
        "> * Assemble your own ResNet, and load in weights from PyTorch's ResNet implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTNY36KhjBUP"
      },
      "source": [
        "## Reading\n",
        "\n",
        "* [Batch Normalization in Convolutional Neural Networks](https://www.baeldung.com/cs/batch-normalization-cnn)\n",
        "* [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n",
        "\n",
        "You should move on once you can answer the following questions:\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\"Batch Normalization allows us to be less careful about initialization.\" Explain this statement.</summary>\n",
        "\n",
        "Weight initialisation methods like Xavier (which we encountered yesterday) are based on the idea of making sure the activations have approximately the same distribution across layers at initialisation. But batch normalisation ensures that this is the case as signals pass through the network.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Give three reasons why batch norm improves the performance of neural networks.</summary>\n",
        "\n",
        "The reasons given in the first linked document above are:\n",
        "\n",
        "* Normalising inputs speeds up computation\n",
        "* Internal covariate shift is reduced, i.e. the mean and standard deviation is kept constant across the layers.\n",
        "* Regularisation effect: noise internal to each minibatch is reduced\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>If you have an input tensor of size (batch, channels, width, height), and you apply a batchnorm layer, how many learned parameters will there be?</summary>\n",
        "\n",
        "A mean and standard deviation is calculated for each channel (i.e. each calculation is done across the batch, width, and height dimensions). So the number of learned params will be `2 * channels`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>In the paper, the diagram shows additive skip connections (i.e. F(x) + x). One can also form concatenated skip connections, by \"gluing together\" F(x) and x into a single tensor. Give one advantage and one disadvantage of these, relative to additive connections.</summary>\n",
        "\n",
        "One advantage of concatenation: the subsequent layers can re-use middle representations; maintaining more information which can lead to better performance. Also, this still works if the tensors aren't exactly the same shape. One disadvantage: less compact, so there may be more weights to learn in subsequent layers.\n",
        "\n",
        "Crucially, both the addition and concatenation methods have the property of preserving information, to at least some degree of fidelity. For instance, you can [use calculus to show](https://theaisummer.com/skip-connections/#:~:text=residual%20skip%20connections.-,ResNet%3A%20skip%20connections%C2%A0via%C2%A0addition,-The%20core%20idea) that both methods will fix the vanishing gradients problem.\n",
        "</details>\n",
        "\n",
        "\n",
        "In this section, we'll do a more advanced version of the exercise in part 1. Rather than building a relatively simple network in which computation can be easily represented by a sequence of simple layers, we're going to build a more complex architecture which requires us to define nested blocks.\n",
        "\n",
        "We'll start by defining a few more `nn.Module` objects, which we hadn't needed before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3UQwSkXjBUP"
      },
      "source": [
        "## Sequential\n",
        "\n",
        "Firstly, now that we're working with large and complex architectures, we should create a version of `nn.Sequential`. As the name suggests, when an `nn.Sequential` is fed an input, it sequentially applies each of its submodules to the input, with the output from one module feeding into the next one.\n",
        "\n",
        "The implementation is given to you below. A few notes:\n",
        "\n",
        "* In initalization, we add to the `_modules` dictionary.\n",
        "    * This is a special type of dict called an **ordered dictionary**, which preserves the order of elements that get added (although Python sort-of does this now by default).\n",
        "    * When we call `self.parameters()`, this recursively goes through all modules in `self._modules`, and returns the params in those modules. This means we can nest sequentials within sequentials!\n",
        "* The special `__getitem__` and `__setitem__` methods determine behaviour when we get and set modules within the sequential.\n",
        "* The `repr` of the base class `nn.Module` already recursively prints out the submodules, so we don't need to write anything in `extra_repr`.\n",
        "    * To see how this works in practice, try defining a `Sequential` which takes a sequence of modules that you've defined above, and see what it looks like when you print it.\n",
        "\n",
        "Don't worry about deeply understanding this code. The main takeaway is that `nn.Sequential` is a useful list-like object to store modules, and apply them all sequentially.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - initializing Sequential with an OrderedDict</summary>\n",
        "\n",
        "The actual `nn.Sequential` module can be initialized with an ordered dictionary, rather than a list of modules. For instance, rather than doing this:\n",
        "\n",
        "```python\n",
        "seq = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 30)\n",
        ")\n",
        "```\n",
        "\n",
        "we can do this:\n",
        "\n",
        "```python\n",
        "from collections import OrderedDict\n",
        "\n",
        "seq = nn.Sequential(OrderedDict([\n",
        "    (\"linear1\", nn.Linear(10, 20)),\n",
        "    (\"relu\", nn.ReLU()),\n",
        "    (\"linear2\", nn.Linear(20, 30))\n",
        "]))\n",
        "```\n",
        "\n",
        "This is handy if we want to give each module an descriptive name.\n",
        "\n",
        "The `Sequential` implementation below doesn't allow the input to be an OrderedDict. As a bonus exercise, can you rewrite the `__init__`, `__getitem__` and `__setitem__` methods to allow the input to be an OrderedDict? If you do this, you'll actually be able to match your eventual `ResNet` model names exactly to the PyTorch implementation.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMeB1It7jBUP"
      },
      "outputs": [],
      "source": [
        "class Sequential(nn.Module):\n",
        "    _modules: dict[str, nn.Module]\n",
        "\n",
        "    def __init__(self, *modules: nn.Module):\n",
        "        super().__init__()\n",
        "        for index, mod in enumerate(modules):\n",
        "            self._modules[str(index)] = mod\n",
        "\n",
        "    def __getitem__(self, index: int) -> nn.Module:\n",
        "        index %= len(self._modules)  # deal with negative indices\n",
        "        return self._modules[str(index)]\n",
        "\n",
        "    def __setitem__(self, index: int, module: nn.Module) -> None:\n",
        "        index %= len(self._modules)  # deal with negative indices\n",
        "        self._modules[str(index)] = module\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Chain each module together, with the output from one feeding into the next one.\"\"\"\n",
        "        for mod in self._modules.values():\n",
        "            x = mod(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiJjl23vjBUP"
      },
      "source": [
        "## BatchNorm2d\n",
        "\n",
        "Now, we'll implement our `BatchNorm2d`, the layer described in the reading material you hopefully read above. You'll be implementing it according to the [PyTorch docs](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) (with `affine=True` and `track_running_stats=True`).\n",
        "\n",
        "The primary function of batchnorm is to normalize the activations of each layer within the neural network during training. It normalizes each batch of input data to have a mean of 0 and std dev of 1. This normalization helps mitigate the **internal covariate shift** problem, which refers to the change in the distribution of layer inputs as the network trains. This becomes a particularly big problem as we build deeper networks, because there's more opportunity for the activation distribution to change over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1S4yU34jBUP"
      },
      "source": [
        "### Buffers\n",
        "\n",
        "A question that might have occurred to you as you read about batchnorm - how does averaging over input data work in inference mode, if you only have a single input rather than a batch? The answer is that during training mode we compute a running average of our data's mean and variance, and we use this running average in inference mode.\n",
        "\n",
        "How do we store these moving averages? We want them to be saved and loaded with the model (because we need these values in order to run our model), but we don't want to update them using gradient descent (so we don't want to use `nn.Parameter`). So instead, we use the Pytorch **buffers** feature. These are essentially tensors which are included in `model.state_dict()` (and so they're saved & loaded with the rest of the model) but not included in `model.parameters()`.\n",
        "\n",
        "You can create a buffer by calling [`self.register_buffer`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer) from inside a `nn.Module`. We've initialized the necessary buffers for you in the `__init__` method below - you'll need a running mean and variance, as well as a counter for the number of batches seen (technically this isn't strictly necessary because the running mean & variance are updated using an exponential moving average so the update rule is independent of the number of previous updates, but we're doing this so our state dict matches the PyTorch implementation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU_LYqcJjBUP"
      },
      "source": [
        "### Train and Eval Modes\n",
        "\n",
        "Okay so we have buffers, but how can we make them behave differently in different modes - i.e. updating the running mean & variance in training mode, and using the stored values in eval mode? The answer is that we use the `training` method of the `nn.Module` class, which is a boolean attribute that gets flipped when we call `self.eval()` or `self.train()`. In the case of batch norm, your code should look like this:\n",
        "\n",
        "```python\n",
        "if self.training:\n",
        "    # Use this data's mean & variance to normalize, then use it to update the buffers\n",
        "else:\n",
        "    # Use the buffer mean & variance to normalize\n",
        "```\n",
        "\n",
        "The other commonly used module which has different behaviour in training and eval modes is `Dropout` - in eval mode this module uses all its inputs, but in training it randomly selects some fraction `1 - p` of the input values to zero out and scales the remaining values by `1 / (1 - p)`.\n",
        "\n",
        "Note that other normalization modules we'll address later in this course like `LayerNorm` don't have different behaviour in training and eval modes, because these don't normalize over the batch dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHXorQkCjBUP"
      },
      "source": [
        "### Exercise - implement `BatchNorm2d`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-30 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `BatchNorm2d` according to the [PyTorch docs](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html). We're implementing it with `affine=True` and `track_running_stats=True`. All the parameters are defined for you in the `__init__` method, your job will be to fill in the `forward` and `extra_repr` methods.\n",
        "\n",
        "A few final tips:\n",
        "\n",
        "- Remember to use `weight` and `bias` in the fwd pass, after normalizing. You should multiply by `weight` and add `bias`.\n",
        "- All your tensors (`weight`, `bias`, `running_mean` and `running_var`) are vectors of length `num_features`, this should help you figure out what dimensions you're operating on.\n",
        "- Remember that the shape of `x` is `(batch, num_features, height, width)` which doesn't broadcast with `(num_features,)`. The easiest way to fix this is to reshape the latter to something like `(1, num_features, 1, 1)`, or optionally just `(num_features, 1, 1)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-PuyV34jBUP"
      },
      "outputs": [],
      "source": [
        "class BatchNorm2d(nn.Module):\n",
        "    # The type hints below aren't functional, they're just for documentation\n",
        "    running_mean: Float[Tensor, \"num_features\"]\n",
        "    running_var: Float[Tensor, \"num_features\"]\n",
        "    num_batches_tracked: Int[Tensor, \"\"]  # This is how we denote a scalar tensor\n",
        "\n",
        "    def __init__(self, num_features: int, eps=1e-05, momentum=0.1):\n",
        "        \"\"\"\n",
        "        Like nn.BatchNorm2d with track_running_stats=True and affine=True.\n",
        "\n",
        "        Name the learnable affine parameters `weight` and `bias` in that order.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.weight = nn.Parameter(t.ones(num_features))\n",
        "        self.bias = nn.Parameter(t.zeros(num_features))\n",
        "\n",
        "        self.register_buffer(\"running_mean\", t.zeros(num_features))\n",
        "        self.register_buffer(\"running_var\", t.ones(num_features))\n",
        "        self.register_buffer(\"num_batches_tracked\", t.tensor(0))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Normalize each channel.\n",
        "\n",
        "        Compute the variance using `torch.var(x, unbiased=False)`\n",
        "        Hint: you may also find it helpful to use the argument `keepdim`.\n",
        "\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels, height, width)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_batchnorm2d_module(BatchNorm2d)\n",
        "tests.test_batchnorm2d_forward(BatchNorm2d)\n",
        "tests.test_batchnorm2d_running_mean(BatchNorm2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDElfgGRjBUP"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm stuck on this implementation, and need a template.</summary>\n",
        "\n",
        "The easiest way is to structure it like this (we've omitted the reshaping to make sure the mean & variance broadcasts correctly):\n",
        "\n",
        "```python\n",
        "if self.training:\n",
        "    mean = ... # mean of new data\n",
        "    var = ... # variance of new data\n",
        "    self.running_mean = ... # update running mean using exponential moving average\n",
        "    self.running_var = ... # update running variance using exponential moving average\n",
        "    self.num_batches_tracked += 1\n",
        "else:\n",
        "    mean = self.running_mean\n",
        "    var = self.running_var\n",
        "\n",
        "x_normed = ... # normalize x using `mean` and `var` (make sure `mean` and `var` are broadcastable with `x`)\n",
        "x_affine = ... # apply affine transformation from `self.weight` and `self.bias` (again, be careful of broadcasting)\n",
        "return x_affine\n",
        "```\n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def forward(self, x: Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Normalize each channel.\n",
        "\n",
        "    Compute the variance using `torch.var(x, unbiased=False)`\n",
        "    Hint: you may also find it helpful to use the argument `keepdim`.\n",
        "\n",
        "    x: shape (batch, channels, height, width)\n",
        "    Return: shape (batch, channels, height, width)\n",
        "    \"\"\"\n",
        "    # Calculating mean and var over all dims except for the channel dim\n",
        "    if self.training:\n",
        "        # Take mean over all dimensions except the feature dimension\n",
        "        mean = x.mean(dim=(0, 2, 3))\n",
        "        var = x.var(dim=(0, 2, 3), unbiased=False)\n",
        "        # Updating running mean and variance, in line with PyTorch documentation\n",
        "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
        "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
        "        self.num_batches_tracked += 1\n",
        "    else:\n",
        "        mean = self.running_mean\n",
        "        var = self.running_var\n",
        "\n",
        "    # Rearranging these so they can be broadcasted\n",
        "    reshape = lambda x: einops.rearrange(x, \"channels -> 1 channels 1 1\")\n",
        "\n",
        "    # Normalize, then apply affine transformation from self.weight & self.bias\n",
        "    x_normed = (x - reshape(mean)) / (reshape(var) + self.eps).sqrt()\n",
        "    x_affine = x_normed * reshape(self.weight) + reshape(self.bias)\n",
        "    return x_affine\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-zIkZUEjBUP"
      },
      "source": [
        "## AveragePool\n",
        "\n",
        "Let's end our collection of `nn.Module`s with an easy one 🙂\n",
        "\n",
        "The ResNet has a Linear layer with 1000 outputs at the end in order to produce classification logits for each of the 1000 classes. Any Linear needs to have a constant number of input features, but the ResNet is supposed to be compatible with arbitrary height and width, so we can't just do a pooling operation with a fixed kernel size and stride.\n",
        "\n",
        "Luckily, the simplest possible solution works decently: take the mean over the spatial dimensions. Intuitively, each position has an equal \"vote\" for what objects it can \"see\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYnKXRrfjBUP"
      },
      "source": [
        "### Exercise - implement `AveragePool`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴⚪⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 5-10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "This should be a pretty straightforward implementation; it doesn't have any weights or parameters of any kind, so you only need to implement the `forward` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPy0xaU9jBUP"
      },
      "outputs": [],
      "source": [
        "class AveragePool(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_averagepool(AveragePool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrMm9Hm8jBUP"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class AveragePool(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels)\n",
        "        \"\"\"\n",
        "        return t.mean(x, dim=(2, 3))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCgqtLlOjBUQ"
      },
      "source": [
        "## Building ResNet\n",
        "\n",
        "Now we have all the building blocks we need to start assembling your own ResNet! The following diagram describes the architecture of ResNet34 - the other versions are broadly similar.\n",
        "\n",
        "Note - unless otherwise noted, you should assume convolutions have `kernel_size=3, stride=1, padding=1` (this is a **shape preserving convolution** i.e. the width & height of the input and output will be the same). None of the convolutions have biases.\n",
        "\n",
        "You don't have to understand every detail in this diagram before proceeding; specific points will be clarified as we go through each exercise.\n",
        "\n",
        "<details>\n",
        "<summary>Question: why do we not care about including biases in the convolutional layers?</summary>\n",
        "\n",
        "Every convolution layer in this network is followed by a batch normalization layer. The first operation in the batch normalization layer is to subtract the mean of each output channel. But a convolutional bias just adds some scalar `b` to each output channel, increasing the mean by `b`. This means that for any `b` added, the batch normalization will subtract `b` to exactly negate the bias term.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm confused about how the nested subgraphs work.</summary>\n",
        "\n",
        "The right-most block in the diagram, `ResidualBlock`, is nested inside `BlockGroup` multiple times. When you see `ResidualBlock` in `BlockGroup`, you should visualise a copy of `ResidualBlock` sitting in that position.\n",
        "    \n",
        "Similarly, `BlockGroup` is nested multiple times (four to be precise) in the full `ResNet34` architecture.\n",
        "</details>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/resnet-fixed.svg\" width=\"900\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KC7tTKPjBUQ"
      },
      "source": [
        "### Exercise - implement `ResidualBlock`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 20-30 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `ResidualBlock` by referring to the diagram (i.e. the right-most of the three hierarchical diagrams above).\n",
        "\n",
        "The **left branch** starts with a strided convolution which changes the number of features from `in_feats` to `out_feats`. It has all conv parameters default i.e. `kernel_size=3, stride=1, padding=1` except for the stride which is instead given by `first_stride`. The second convolution has all default parameters, and maps from `out_feats` to `out_feats` (meaning it's fully shape preserving).\n",
        "\n",
        "As for the **right branch** - this is meant to essentially be a skip connection, the problem is we can't just use a skip connection because the shapes might not match up (and so we couldn't add them together at the end). The left branch is fully shape preserving if and only if `first_stride == 1` and `in_feats == out_feats`. If this is true then we do set the right branch to be the identity (that's what the \"OPTIONAL\" annotation refers to), but if this isn't true then we set the right branch to be a 1x1 convolution with stride `first_stride`, zero padding, and mapping from `in_feats` to `out_feats`, followed by a batchnorm layer. This is in a sense the simplest operation we can get which matches the left branch shape, since the convolution is basically just a downsampling operation (keeping pixels based on a `::first_stride` slice across the height and width dimensions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7B3MPn5jBUQ"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"\n",
        "        A single residual block with optional downsampling.\n",
        "\n",
        "        For compatibility with the pretrained model, declare the left side branch first using a `Sequential`.\n",
        "\n",
        "        If first_stride is > 1, this means the optional (conv + bn) should be present on the right branch. Declare it second using another `Sequential`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        is_shape_preserving = (first_stride == 1) and (in_feats == out_feats)  # determines if right branch is identity\n",
        "\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / stride, width / stride)\n",
        "\n",
        "        If no downsampling block is present, the addition should just add the left branch's output to the input.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_residual_block(ResidualBlock)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY4GJqgYjBUQ"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"\n",
        "        A single residual block with optional downsampling.\n",
        "\n",
        "        For compatibility with the pretrained model, declare the left side branch first using a `Sequential`.\n",
        "\n",
        "        If first_stride is > 1, this means the optional (conv + bn) should be present on the right branch. Declare it second using another `Sequential`.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        is_shape_preserving = (first_stride == 1) and (in_feats == out_feats)  # determines if right branch is identity\n",
        "\n",
        "        self.left = Sequential(\n",
        "            Conv2d(in_feats, out_feats, kernel_size=3, stride=first_stride, padding=1),\n",
        "            BatchNorm2d(out_feats),\n",
        "            ReLU(),\n",
        "            Conv2d(out_feats, out_feats, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(out_feats),\n",
        "        )\n",
        "        self.right = (\n",
        "            nn.Identity()\n",
        "            if is_shape_preserving\n",
        "            else Sequential(Conv2d(in_feats, out_feats, kernel_size=1, stride=first_stride), BatchNorm2d(out_feats))\n",
        "        )\n",
        "        self.relu = ReLU()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / stride, width / stride)\n",
        "\n",
        "        If no downsampling block is present, the addition should just add the left branch's output to the input.\n",
        "        \"\"\"\n",
        "        x_left = self.left(x)\n",
        "        x_right = self.right(x)\n",
        "        return self.relu(x_left + x_right)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53nkd-GDjBUQ"
      },
      "source": [
        "### Exercise - implement `BlockGroup`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `BlockGroup` according to the diagram. There should be `n_blocks` total blocks in the group. Only the first block has the possibility of having a right branch (because we might have either `first_stride > 1` or `in_feats != out_feats`), but every subsequent block will have the identity instead of a right branch.\n",
        "\n",
        "<details>\n",
        "<summary>Help - I don't understand why all blocks after the first one won't have a right branch.</summary>\n",
        "\n",
        "- The `first_stride` argument only gets applied to the first block, definitionally (i.e. the purpose of the `BlockGroup` is to downsample the input by `first_stride` just once, not on every single block).\n",
        "- After we pass through the first block we can guarantee that the number of channels will be `out_feats`, so every subsequent block will have `out_feats` input channels and `out_feats` output channels.\n",
        "\n",
        "Combining these two facts, we see that every subsequent block will have a shape-preserving left branch, so it can have the identity as its right branch.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vxTirPmjBUQ"
      },
      "outputs": [],
      "source": [
        "class BlockGroup(nn.Module):\n",
        "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"An n_blocks-long sequence of ResidualBlock where only the first block uses the provided stride.\"\"\"\n",
        "        super().__init__()\n",
        "        # YOUR CODE HERE - define all components of block group\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / first_stride, width / first_stride)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_block_group(BlockGroup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRtj-5ukjBUQ"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class BlockGroup(nn.Module):\n",
        "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
        "        \"\"\"An n_blocks-long sequence of ResidualBlock where only the first block uses the provided stride.\"\"\"\n",
        "        super().__init__()\n",
        "        self.blocks = Sequential(\n",
        "            ResidualBlock(in_feats, out_feats, first_stride),\n",
        "            *[ResidualBlock(out_feats, out_feats) for _ in range(n_blocks - 1)],\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / first_stride, width / first_stride)\n",
        "        \"\"\"\n",
        "        return self.blocks(x)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoeKPAlpjBUQ"
      },
      "source": [
        "### Exercise - implement `ResNet34`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 30-45 minutes on this exercise. This can sometimes involve a lot of fiddly debugging.\n",
        "> ```\n",
        "\n",
        "Last step! Assemble `ResNet34` using the diagram.\n",
        "\n",
        "To test your implementation, you can use the helper function `print_param_count` which prints out a stylized dataframe comparing your model's parameter count to the PyTorch implementation. Alternatively, you can use the following code to import your own `resnet34`, and inspect its architecture:\n",
        "\n",
        "```python\n",
        "resnet = models.resnet34()\n",
        "print(torchinfo.summary(resnet, input_size=(1, 3, 64, 64)))\n",
        "print(torchinfo.summary(my_resnet, input_size=(1, 3, 64, 64)))\n",
        "```\n",
        "\n",
        "Both will give you the shape & size of each of your model's parameters & buffers, and code is provided for both of these methods below.\n",
        "\n",
        "Note - in order to copy weights from the reference model to your implementation (which we'll do after this exercise), you'll need to have all the parameters defined in the same order as they are in the reference model - in other words, the rows from the two halves of the dataframe created via `print_param_count` should perfectly match up with each other. This can be a bit fiddly to get right, especially if the names of your parameters are different to the names in the PyTorch implementation. We recommend you look at the `__init__` methods of the solution if you're stuck (since it's the order that things are defined in for the various ResNet modules which determines the order of the rows in the dataframe).\n",
        "\n",
        "This 1-to-1 weight comparison won't always be possible during model replications, for example when we replicate GPT2-Small next week we'll be defining the attention weight matrices differently (in a way that's more condusive to interpretability research). In these cases, you'll need to resort to different debugging methods, like running the models on the same input and checking they give the same output. You can also break this down into smaller steps by running individual models, and by checking the shape before checking values. However in this case we don't need to resort to that, because our implementation is equivalent to the reference model's implementation.\n",
        "\n",
        "As a more general point, tweaking your model until all the layers match up might be a difficult and frustrating exercise at times, however it's a pretty good example of the kind of low-level model implementation and debugging that is important for your growth as ML engineers! So don't be disheartened if you find it hard to get exactly right (although we certainly recommend looking at the solutions and moving on if you're stuck on this particular exercise for more than ~45 minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f7NyxrEjBUQ"
      },
      "outputs": [],
      "source": [
        "class ResNet34(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_blocks_per_group=[3, 4, 6, 3],\n",
        "        out_features_per_group=[64, 128, 256, 512],\n",
        "        first_strides_per_group=[1, 2, 2, 2],\n",
        "        n_classes=1000,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        in_feats0 = 64\n",
        "        self.n_blocks_per_group = n_blocks_per_group\n",
        "        self.out_features_per_group = out_features_per_group\n",
        "        self.first_strides_per_group = first_strides_per_group\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # YOUR CODE HERE - define all components of resnet34\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, n_classes)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "my_resnet = ResNet34()\n",
        "\n",
        "# (1) Test via helper function `print_param_count`\n",
        "target_resnet = models.resnet34()  # without supplying a `weights` argument, we just initialize with random weights\n",
        "utils.print_param_count(my_resnet, target_resnet)\n",
        "\n",
        "# (2) Test via `torchinfo.summary`\n",
        "print(\"My model:\", torchinfo.summary(my_resnet, input_size=(1, 3, 64, 64)), sep=\"\\n\")\n",
        "print(\"\\nReference model:\", torchinfo.summary(target_resnet, input_size=(1, 3, 64, 64), depth=2), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf_bXp6hjBUQ"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to construct each of the BlockGroups.</summary>\n",
        "\n",
        "Each BlockGroup takes arguments `n_blocks`, `in_feats`, `out_feats` and `first_stride`. In the initialisation of `ResNet34` below, we're given a list of `n_blocks`, `out_feats` and `first_stride` for each of the BlockGroups. To find `in_feats` for each block, it suffices to note two things:\n",
        "    \n",
        "1. The first `in_feats` should be 64, because the input is coming from the convolutional layer with 64 output channels.\n",
        "2. The `out_feats` of each layer should be equal to the `in_feats` of the subsequent layer (because the BlockGroups are stacked one after the other; with no operations in between to change the shape).\n",
        "\n",
        "You can use these two facts to construct a list `in_features_per_group`, and then create your BlockGroups by zipping through all four lists.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm not sure how to construct the 7x7 conv at the very start.</summary>\n",
        "\n",
        "The stride, padding & output channels are givin in the diagram; the only thing not provided is `in_channels`. Recall that the input to this layer is an RGB image - can you deduce from this how many input channels your layer should have?\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm getting the right total parameter count, but my rows don't match up, and I'm not sure how to debug this.</summary>\n",
        "\n",
        "We'll use an example case to illustrate how to debug this. In the following case, our rows match up until the 21st row where we have our first discrepancy:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/row-diff.png\" width=\"1000\">\n",
        "\n",
        "We can see that the first discrepancy occurs at the first parameter from `residual_layers.1`, meaning something in the second `BlockGroup` in our sequential of blockgroups. We can see that the first blockgroup only had left branches but no right branches (this is because for the very first blockgroup we had `in_feats == out_feats == 64` and also `first_strides_per_group[0] == 1`, meaning this first blockgroup was shape-preserving and it didn't need a right branch). So it's the presence of a right branch that's causing the mismatch.\n",
        "\n",
        "Looking closer at the dataframe, we see that the left-hand parameter (from our model) has shape `(128, 64, 1, 1)` and has `right` in its name, so we deduce it's the 1x1 convolutional weight from the right branch. But the parameter from the PyTorch model has shape `(128, 64, 3, 3)`, i.e. it's a convolutional weight with a 3x3 kernel, so must be from the left branch (it also matches the naming convention for the left-branch convolutional weight from the first blockgroup - row index 3 in the dataframe). So we've now figured out what the problem is: **your implementation defines the right branch before the left branch in the the `ResidualBlock.__init__` method, and to match param orders with the PyTorch model you should swap them around.**\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ResNet34(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_blocks_per_group=[3, 4, 6, 3],\n",
        "        out_features_per_group=[64, 128, 256, 512],\n",
        "        first_strides_per_group=[1, 2, 2, 2],\n",
        "        n_classes=1000,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        in_feats0 = 64\n",
        "        self.n_blocks_per_group = n_blocks_per_group\n",
        "        self.out_features_per_group = out_features_per_group\n",
        "        self.first_strides_per_group = first_strides_per_group\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.in_layers = Sequential(\n",
        "            Conv2d(3, in_feats0, kernel_size=7, stride=2, padding=3),\n",
        "            BatchNorm2d(in_feats0),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "        residual_layers = []\n",
        "        for i in range(len(n_blocks_per_group)):\n",
        "            residual_layers.append(\n",
        "                BlockGroup(\n",
        "                    n_blocks=n_blocks_per_group[i],\n",
        "                    in_feats=[64, *self.out_features_per_group][i],\n",
        "                    out_feats=self.out_features_per_group[i],\n",
        "                    first_stride=self.first_strides_per_group[i],\n",
        "                )\n",
        "            )\n",
        "        self.residual_layers = Sequential(*residual_layers)\n",
        "\n",
        "        self.out_layers = Sequential(\n",
        "            AveragePool(),\n",
        "            Linear(out_features_per_group[-1], n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, n_classes)\n",
        "        \"\"\"\n",
        "        post_first_conv_block = self.in_layers(x)\n",
        "        post_block_groups = self.residual_layers(post_first_conv_block)\n",
        "        logits = self.out_layers(post_block_groups)\n",
        "        return logits\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGvDIe3UjBUQ"
      },
      "source": [
        "### Copying over weights\n",
        "\n",
        "Now that you've built your `ResNet34`, we'll copy weights over from PyTorch's pretrained resnet to yours. This is another good way to verify that you've designed the architecture correctly (although if you've passed all tests above and your parameter count order matches up, it's very likely that this code will also work)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoL_Jg8jjBUQ"
      },
      "outputs": [],
      "source": [
        "def copy_weights(my_resnet: ResNet34, pretrained_resnet: models.resnet.ResNet) -> ResNet34:\n",
        "    \"\"\"Copy over the weights of `pretrained_resnet` to your resnet.\"\"\"\n",
        "\n",
        "    # Get the state dictionaries for each model, check they have the same number of parameters & buffers\n",
        "    mydict = my_resnet.state_dict()\n",
        "    pretraineddict = pretrained_resnet.state_dict()\n",
        "    assert len(mydict) == len(pretraineddict), \"Mismatching state dictionaries.\"\n",
        "\n",
        "    # Define a dictionary mapping the names of your parameters / buffers to their values in the pretrained model\n",
        "    state_dict_to_load = {\n",
        "        mykey: pretrainedvalue\n",
        "        for (mykey, myvalue), (pretrainedkey, pretrainedvalue) in zip(mydict.items(), pretraineddict.items())\n",
        "    }\n",
        "\n",
        "    # Load in this dictionary to your model\n",
        "    my_resnet.load_state_dict(state_dict_to_load)\n",
        "\n",
        "    return my_resnet\n",
        "\n",
        "\n",
        "pretrained_resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1).to(device)\n",
        "my_resnet = copy_weights(my_resnet, pretrained_resnet).to(device)\n",
        "print(\"Weights copied successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTl0ji4bjBUQ"
      },
      "source": [
        "This function uses the `state_dict()` method, which returns an  `OrderedDict` (documentation [here](https://realpython.com/python-ordereddict/)) object containing all the parameter/buffer names and their values. State dicts can be extracted from models, saved to your filesystem (this is a common way to store the results of training a model), and can also be loaded back into a model using the `load_state_dict` method. (Note that you can also load weights using a regular Python `dict`, but since Python 3.7, the builtin `dict` is guaranteed to maintain items in the order they're inserted.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob6sea_yjBUQ"
      },
      "source": [
        "## Running Your Model\n",
        "\n",
        "We've provided you with some images for your model to classify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj_5PwZ9jBUQ"
      },
      "outputs": [],
      "source": [
        "IMAGE_FILENAMES = [\n",
        "    \"chimpanzee.jpg\",\n",
        "    \"golden_retriever.jpg\",\n",
        "    \"platypus.jpg\",\n",
        "    \"frogs.jpg\",\n",
        "    \"fireworks.jpg\",\n",
        "    \"astronaut.jpg\",\n",
        "    \"iguana.jpg\",\n",
        "    \"volcano.jpg\",\n",
        "    \"goofy.jpg\",\n",
        "    \"dragonfly.jpg\",\n",
        "]\n",
        "\n",
        "IMAGE_FOLDER = section_dir / \"resnet_inputs\"\n",
        "\n",
        "images = [Image.open(IMAGE_FOLDER / filename) for filename in IMAGE_FILENAMES]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6ZpFY0FjBUQ"
      },
      "source": [
        "Our `images` are of type `PIL.Image.Image`, so we can just call them in a cell to display them, or alternatively use a function like IPython's `display`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIw3-EK8jBUQ"
      },
      "outputs": [],
      "source": [
        "display(images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckcsww3hjBUQ"
      },
      "source": [
        "We now need to define a `transform` object like we did for MNIST. We will use the same transforms to convert the PIL image to a tensor, and to normalize it. But we also want to resize the images to `height=224, width=224`, because not all of them start out with this size and we need them to be consistent before passing them through our model.\n",
        "\n",
        "In the normalization step, we'll use a mean of `[0.485, 0.456, 0.406]`, and a standard deviation of `[0.229, 0.224, 0.225]` (these are the mean and std dev of images from [ImageNet](https://www.image-net.org/)). Note that the means and std devs have three elements, because ImageNet contains RGB rather than monochrome images, and we're normalising over each of the three RGB channels separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWkEk7fUjBUQ"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "IMAGENET_TRANSFORM = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prepared_images = t.stack([IMAGENET_TRANSFORM(img) for img in images], dim=0).to(device)\n",
        "assert prepared_images.shape == (len(images), 3, IMAGE_SIZE, IMAGE_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmZna3XejBUQ"
      },
      "source": [
        "### Exercise - verify your model's predictions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Lastly, you should run your model with these prepared images, and verify that your predictions are the same as the model's predictions.\n",
        "\n",
        "You can do this by filling in the `predict` function below, then running the code. We've also provided you with a file `imagenet_labels.json` which you can use to get the actual classnames of imagenet data, and see what your model's predictions actually are.\n",
        "\n",
        "When you run the code, you should find that your top prediction probabilities are within about 0.01% of the reference model's probabilities most (not all) of the time. This kind of error is not uncommon when you have slightly different orders of linear operations or small implementation details which differ between models, and which can introduce floating point errors that compound as we move through the model. As a bonus exercise (which may or may not break your sanity), you're welcome to try and work through our implementation, comparing it to the PyTorch model's implementation and find where the discrepancy comes from!\n",
        "\n",
        "*Tip - the torch method `torch.max` will return a tuple of (values, indices) if you supply a dimension argument `dim`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VHNYmPTjBUR"
      },
      "outputs": [],
      "source": [
        "@t.inference_mode()\n",
        "def predict(\n",
        "    model: nn.Module, images: Float[Tensor, \"batch rgb h w\"]\n",
        ") -> tuple[Float[Tensor, \"batch\"], Int[Tensor, \"batch\"]]:\n",
        "    \"\"\"\n",
        "    Returns the maximum probability and predicted class for each image, as a tensor of floats and ints respectively.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "with open(section_dir / \"imagenet_labels.json\") as f:\n",
        "    imagenet_labels = list(json.load(f).values())\n",
        "\n",
        "# Check your predictions match those of the pretrained model\n",
        "my_probs, my_predictions = predict(my_resnet, prepared_images)\n",
        "pretrained_probs, pretrained_predictions = predict(pretrained_resnet, prepared_images)\n",
        "assert (my_predictions == pretrained_predictions).all()\n",
        "t.testing.assert_close(my_probs, pretrained_probs, atol=5e-4, rtol=0)  # tolerance of 0.05%\n",
        "print(\"All predictions match!\")\n",
        "\n",
        "# Print out your predictions, next to the corresponding images\n",
        "for i, img in enumerate(images):\n",
        "    table = Table(\"Model\", \"Prediction\", \"Probability\")\n",
        "    table.add_row(\"My ResNet\", imagenet_labels[my_predictions[i]], f\"{my_probs[i]:.3%}\")\n",
        "    table.add_row(\"Reference Model\", imagenet_labels[pretrained_predictions[i]], f\"{pretrained_probs[i]:.3%}\")\n",
        "    rprint(table)\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqZ-CAOpjBUR"
      },
      "source": [
        "<details>\n",
        "<summary>Help! My model is predicting roughly the same percentage for every category!</summary>\n",
        "\n",
        "This can indicate that your model weights are randomly initialized, meaning the weight loading process didn't actually take. Or, you reinitialized your model by accident after loading the weights.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@t.inference_mode()\n",
        "def predict(\n",
        "    model: nn.Module, images: Float[Tensor, \"batch rgb h w\"]\n",
        ") -> tuple[Float[Tensor, \"batch\"], Int[Tensor, \"batch\"]]:\n",
        "    \"\"\"\n",
        "    Returns the maximum probability and predicted class for each image, as a tensor of floats and ints respectively.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    logits = model(images)\n",
        "    probabilities = logits.softmax(dim=-1)\n",
        "    return probabilities.max(dim=-1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkLlVXrdjBUR"
      },
      "source": [
        "If you've done everything correctly, your version should give the same classifications, and the percentages should match at least to a couple decimal places.\n",
        "\n",
        "If it does, congratulations, you've now run an entire ResNet, using barely any code from `torch.nn`! The only things we used were `nn.Module` and `nn.Parameter`.\n",
        "\n",
        "If it doesn't, you get to practice model debugging! Remember to use the `utils.print_param_count` function that was provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpA7i8hWjBUR"
      },
      "source": [
        "### Aside - hooks\n",
        "\n",
        "One problem you might have encountered is that your model outputs `NaN`s rather than actual numbers. When debugging this, it's useful to try and identify which module the error first appears in. This is a great use-case for **hooks**, which are something we'll be digging a lot more into during our mechanistic interpretability exercises later on.\n",
        "\n",
        "A hook is basically a function which you can attach to a particular `nn.Module`, which gets executed during your model's forward or backward passes. Here, we'll only consider forward hooks. A hook function's type signature is:\n",
        "\n",
        "```python\n",
        "def hook(module: nn.Module, inputs: list[t.Tensor], output: t.Tensor) -> None:\n",
        "    pass\n",
        "```\n",
        "\n",
        "The `inputs` argument is a list of the inputs to the module (often just one tensor), and the `output` argument is the output of the module. This hook gets registered to a module by calling `module.register_forward_hook(hook)`. During forward passes, the hook function will run.\n",
        "\n",
        "Here is some code which will check for `NaN`s in the output of each module, and raise a `ValueError` if it finds any. We've also given you an example tiny network which produces a `NaN` in the output of the second layer, to demonstrate it on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n4EvHKzjBUR"
      },
      "outputs": [],
      "source": [
        "class NanModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Define a module that always returns NaNs (we will use hooks to identify this error).\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return t.full_like(x, float(\"nan\"))\n",
        "\n",
        "\n",
        "def hook_check_for_nan_output(module: nn.Module, input: tuple[Tensor], output: Tensor) -> None:\n",
        "    \"\"\"\n",
        "    Hook function which detects when the output of a layer is NaN.\n",
        "    \"\"\"\n",
        "    if t.isnan(output).any():\n",
        "        raise ValueError(f\"NaN output from {module}\")\n",
        "\n",
        "\n",
        "def add_hook(module: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Register our hook function in a module.\n",
        "\n",
        "    Use model.apply(add_hook) to recursively apply the hook to model and all submodules.\n",
        "    \"\"\"\n",
        "    module.register_forward_hook(hook_check_for_nan_output)\n",
        "\n",
        "\n",
        "def remove_hooks(module: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Remove all hooks from module.\n",
        "\n",
        "    Use module.apply(remove_hooks) to do this recursively.\n",
        "    \"\"\"\n",
        "    module._backward_hooks.clear()\n",
        "    module._forward_hooks.clear()\n",
        "    module._forward_pre_hooks.clear()\n",
        "\n",
        "\n",
        "# Create our model with a NaN in the middle, and apply a hook function to it which checks for NaNs\n",
        "model = nn.Sequential(nn.Identity(), NanModule(), nn.Identity())\n",
        "model = model.apply(add_hook)\n",
        "\n",
        "# Run the model, and and our hook function should raise an error that gets caught by the try-except\n",
        "try:\n",
        "    input = t.randn(3)\n",
        "    output = model(input)\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "\n",
        "# Remove hooks at the end\n",
        "model = model.apply(remove_hooks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBg9yltzjBUR"
      },
      "source": [
        "When you run this code, you should find it raising an error at the `NanModule`.\n",
        "\n",
        "\n",
        "> Important - when you're working with PyTorch hooks, make sure you **remember to remove them at the end of each use**! This is a classic source of bugs, and one of the things that make PyTorch hooks so janky. When we study TransformerLens in the next chapter, we'll use a version of hooks that is essentially the same under the hood, but comes with quite a few quality of life improvements!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXL1UZH4jBUR"
      },
      "source": [
        "# ☆ Bonus - Feature Extraction\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand the difference between feature extraction and finetuning\n",
        "> * Perform feature extraction on a pre-trained ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XQ-NkXXjBUR"
      },
      "source": [
        "Now that you've seen how to build a modular training loop, and you've seen how ResNet works and is built, we're going to put these two things together to finetune a ResNet model on a new dataset.\n",
        "\n",
        "**Finetuning** can mean slightly different things in different contexts, but broadly speaking it means using the weights of an already trained network as the starting values for training a new network. Because training networks from scratch is very computationally expensive, this is a common practice in ML.\n",
        "\n",
        "The specific type of finetuning we'll be doing here is called **feature extraction**. This is when we freeze most layers of a model except the last few, and perform gradient descent on those. We call this feature extraction because the earlier layers of the model have already learned to identify important features of the data (and these features are also relevant for the new task), so all that we have to do is train a few final layers in the model to extract these features.\n",
        "\n",
        "*Terminology note - sometimes feature extraction and finetuning are defined differently, with finetuning referring to the training of all the weights in a pretrained model (usually with a small or decaying learning rate), and feature extraction referring to the freezing of some layers and training of others. To avoid confusion here, we'll use the term \"feature extraction\" rather than \"finetuning\".*\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/feature_extraction.png\" width=\"400\">\n",
        "\n",
        "How do we prepare a model for feature extraction? By **freezing layers** of our model.\n",
        "\n",
        "We'll discuss freezing layers & the backpropagation algorithm in much more detail tomorrow, but for now it's fine to just understand what's going on at a basic level. When we call `loss.backward()` in our training loop (or when this is implicitly called by our PyTorch Lightning trainer), this propagates gradients from our `loss` scalar back to all parameters in our model. If a parameter has its `requires_grad` attribute set to `False`, it means gradients won't be computed for this tensor during backpropagation. Thanks to PyTorch helpfully keeping track of the parameters which require gradients (using a structure called the **computational graph**), if we set `requires_grad = False` for the first few layers of parameters in our model, PyTorch will actually save us time and compute by not calculating gradients for these parameters at all.\n",
        "\n",
        "See the code below as an example of how gradient propagation stops at tensors with `requires_grad = False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NniVShj_jBUR"
      },
      "outputs": [],
      "source": [
        "layer0, layer1 = nn.Linear(3, 4), nn.Linear(4, 5)\n",
        "\n",
        "layer0.requires_grad_(False)  # generic code to set `param.requires_grad=False` recursively for a module / entire model\n",
        "\n",
        "x = t.randn(3)\n",
        "out = layer1(layer0(x)).sum()\n",
        "out.backward()\n",
        "\n",
        "assert layer0.weight.grad is None\n",
        "assert layer1.weight.grad is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihl5hAAIjBUR"
      },
      "source": [
        "### Exercise - prepare ResNet for feature extraction\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "First, you should complete the function below to do the following:\n",
        "\n",
        "* Instantiate a `ResNet34` model using your class, and copy in weights from a pretrained model (you can use code from earlier here)\n",
        "* Disable gradients for all layers\n",
        "* Replace the final linear layer with a new linear layer, which has the same number of `in_features`, but a different number of `out_features` (given by the `n_classes` argument)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9U-w8lejBUR"
      },
      "outputs": [],
      "source": [
        "def get_resnet_for_feature_extraction(n_classes: int) -> ResNet34:\n",
        "    \"\"\"\n",
        "    Creates a ResNet34 instance, replaces its final linear layer with a classifier for `n_classes` classes, and freezes\n",
        "    all weights except the ones in this layer.\n",
        "\n",
        "    Returns the ResNet model.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_get_resnet_for_feature_extraction(get_resnet_for_feature_extraction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmMmGjbfjBUR"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def get_resnet_for_feature_extraction(n_classes: int) -> ResNet34:\n",
        "    \"\"\"\n",
        "    Creates a ResNet34 instance, replaces its final linear layer with a classifier for `n_classes` classes, and freezes\n",
        "    all weights except the ones in this layer.\n",
        "\n",
        "    Returns the ResNet model.\n",
        "    \"\"\"\n",
        "    # Create a ResNet34 with the default number of classes\n",
        "    my_resnet = ResNet34()\n",
        "\n",
        "    # Load the pretrained weights\n",
        "    pretrained_resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # Copy the weights over\n",
        "    my_resnet = copy_weights(my_resnet, pretrained_resnet)\n",
        "\n",
        "    # Freeze gradients for all layers (note that when we redefine the last layer, it will be unfrozen)\n",
        "    my_resnet.requires_grad_(False)\n",
        "\n",
        "    # Redefine last layer\n",
        "    my_resnet.out_layers[-1] = Linear(my_resnet.out_features_per_group[-1], n_classes)\n",
        "\n",
        "    return my_resnet\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xFWfEyDjBUR"
      },
      "source": [
        "We'll now give you some boilerplate code to load in and transform your data (this is pretty similar to the MNIST code)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLaF_0mKjBUR"
      },
      "outputs": [],
      "source": [
        "def get_cifar() -> tuple[datasets.CIFAR10, datasets.CIFAR10]:\n",
        "    \"\"\"Returns CIFAR-10 train and test sets.\"\"\"\n",
        "    cifar_trainset = datasets.CIFAR10(exercises_dir / \"data\", train=True, download=True, transform=IMAGENET_TRANSFORM)\n",
        "    cifar_testset = datasets.CIFAR10(exercises_dir / \"data\", train=False, download=True, transform=IMAGENET_TRANSFORM)\n",
        "    return cifar_trainset, cifar_testset\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ResNetTrainingArgs:\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 5\n",
        "    learning_rate: float = 1e-3\n",
        "    n_classes: int = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9kgvI0UjBUR"
      },
      "source": [
        "The dataclass we've defined containing training arguments is basically the same as the one we had for the convnet, the main difference is that we're now using the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). This is the dataset we'll be training our model on. It consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. See the link for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9GO6tYjjBUR"
      },
      "source": [
        "### Exercise - write training loop for feature extraction\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "We now come to the final task - write a training loop for your ResNet model. This shouldn't be too difficult because most of the code can be directly taken from the exercise in section 2️⃣, however there are a few changes you should take note of:\n",
        "\n",
        "- Since all other parameters' gradients have been frozen, it doesn't really matter which parameters you pass to your optimizer. However, note that you have the option of passing just a subset of parameters using e.g. `AdamW(model.some_module.parameters(), ...)`.\n",
        "- Now that we're working with batchnorm, you'll have to call `model.train()` and `model.eval()` before your training and validation loops (recall that the behaviour of batchnorm changes between training and eval modes).\n",
        "- Make sure you're connected to GPU runtime rather than CPU, otherwise this training might take quite a while.\n",
        "- Also make sure you're logging progress within each epoch, since the epochs might each take a while (although we've given you the `get_cifar_subset` function which returns a subset of the CIFAR10 data, and we recommend using this function with default parameters so that each epoch is a bit faster)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz8BtxfujBUR"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "def get_cifar_subset(trainset_size: int = 10_000, testset_size: int = 1_000) -> tuple[Subset, Subset]:\n",
        "    \"\"\"Returns a subset of CIFAR-10 train and test sets (slicing the first examples from the datasets).\"\"\"\n",
        "    cifar_trainset, cifar_testset = get_cifar()\n",
        "    return Subset(cifar_trainset, range(trainset_size)), Subset(cifar_testset, range(testset_size))\n",
        "\n",
        "\n",
        "def train(args: ResNetTrainingArgs) -> tuple[list[float], list[float], ResNet34]:\n",
        "    \"\"\"\n",
        "    Performs feature extraction on ResNet, returning the model & lists of loss and accuracy.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE - write your train function for feature extraction\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "args = ResNetTrainingArgs()\n",
        "loss_list, accuracy_list, model = train(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsZIzFzzjBUR"
      },
      "outputs": [],
      "source": [
        "line(\n",
        "    y=[loss_list, [1 / args.n_classes] + accuracy_list],  # we start by assuming a uniform accuracy of 10%\n",
        "    use_secondary_yaxis=True,\n",
        "    x_max=args.epochs * 10_000,\n",
        "    labels={\"x\": \"Num examples seen\", \"y1\": \"Cross entropy loss\", \"y2\": \"Test Accuracy\"},\n",
        "    title=\"ResNet Feature Extraction\",\n",
        "    width=800,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw1WV4evjBUR"
      },
      "source": [
        "<details>\n",
        "<summary>Spoilers - what kind of results should you get?</summary>\n",
        "\n",
        "If you train the whole model rather than just the final layer, you should find accuracy increases very slowly, not getting very far above random chance. This reflects the fact that the model is trying to learn a new task (classifying images into 10 classes) from scratch, rather than just learning to extract features from images, and this takes a long time!\n",
        "\n",
        "If you train just the final layer, your accuracy should reach around 70-80% by the first epoch. This is because the model is already very good at extracting features from images, and it just needs to learn how to turn these features into predictions for this new set of classes.\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "def get_cifar_subset(trainset_size: int = 10_000, testset_size: int = 1_000) -> tuple[Subset, Subset]:\n",
        "    \"\"\"Returns a subset of CIFAR-10 train and test sets (slicing the first examples from the datasets).\"\"\"\n",
        "    cifar_trainset, cifar_testset = get_cifar()\n",
        "    return Subset(cifar_trainset, range(trainset_size)), Subset(cifar_testset, range(testset_size))\n",
        "\n",
        "\n",
        "def train(args: ResNetTrainingArgs) -> tuple[list[float], list[float], ResNet34]:\n",
        "    \"\"\"\n",
        "    Performs feature extraction on ResNet, returning the model & lists of loss and accuracy.\n",
        "    \"\"\"\n",
        "    model = get_resnet_for_feature_extraction(args.n_classes).to(device)\n",
        "\n",
        "    trainset, testset = get_cifar_subset()\n",
        "    trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
        "    testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.out_layers[-1].parameters(), lr=args.learning_rate)\n",
        "\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        for imgs, labels in (pbar := tqdm(trainloader)):\n",
        "            # Move data to device, perform forward pass\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            # Calculate loss, perform backward pass\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update logs & progress bar\n",
        "            loss_list.append(loss.item())\n",
        "            pbar.set_postfix(epoch=f\"{epoch + 1}/{epochs}\", loss=f\"{loss:.3f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        num_correct_classifications = 0\n",
        "        for imgs, labels in testloader:\n",
        "            # Move data to device, perform forward pass in inference mode\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with t.inference_mode():\n",
        "                logits = model(imgs)\n",
        "\n",
        "            # Compute num correct by comparing argmaxed logits to true labels\n",
        "            predictions = t.argmax(logits, dim=1)\n",
        "            num_correct_classifications += (predictions == labels).sum().item()\n",
        "\n",
        "        # Compute & log total accuracy\n",
        "        accuracy = num_correct_classifications / len(mnist_testset)\n",
        "        accuracy_list.append(accuracy)\n",
        "\n",
        "    return loss_list, accuracy_list, model\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0Qbzi6hjBUR"
      },
      "source": [
        "# ☆ Bonus - Convolutions From Scratch\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand how array strides work, and why they're important for efficient linear operations\n",
        "> * Learn how to use `as_strided` to perform simple linear operations like trace and matrix multiplication\n",
        "> * Implement your own convolutions and maxpooling functions using stride-based methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKcm8AfIjBUR"
      },
      "source": [
        "This section is designed to get you familiar with the implementational details of layers like `Linear` and `Conv2d`. You'll be using libraries like `einops`, and functions like `torch.as_strided` to get a very low-level picture of how these operations work, which will help build up your overall understanding.\n",
        "\n",
        "Note that `torch.as_strided` isn't something which will come up explicitly in much of the rest of the course (unlike `einops`). The purpose of the stride exercises is more to give you an appreciation for what's going on under the hood, so that we can build layers of abstraction on top of that during the rest of this week (and by extension this course). I see this as analogous to how [many CS courses](https://cs50.harvard.edu/x/2023/) start by teaching you about languages like C and concepts like pointers and memory management before moving on to higher-level langauges like Python which abstract away these details. The hope is that when you get to the later sections of the course, you'll have the tools to understand them better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jei25WV9jBUR"
      },
      "source": [
        "## Reading\n",
        "\n",
        "* [Python NumPy, 6.1 - `as_strided()`](https://www.youtube.com/watch?v=VlkzN00P0Bc) explains what array strides are.\n",
        "* [`as_strided` and `sum` are all you need](https://jott.live/markdown/as_strided) gives an overview of how to use `as_strided` to perform array operations.\n",
        "* [Advanced NumPy: Master stride tricks with 25 illustrated exercises](https://towardsdatascience.com/advanced-numpy-master-stride-tricks-with-25-illustrated-exercises-923a9393ab20) provides several clear and intuitive examples of `as_strided` being used to construct arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-1QEmzWjBUR"
      },
      "source": [
        "## Basic stride exercises\n",
        "\n",
        "Array strides, and the `as_strided` method, are important to understand well because lots of linear operations are actually implementing something like `as_strided` under the hood.\n",
        "\n",
        "Run the following code, to define this tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR45lSoFjBUS"
      },
      "outputs": [],
      "source": [
        "test_input = t.tensor(\n",
        "    [\n",
        "        [0, 1, 2, 3, 4],\n",
        "        [5, 6, 7, 8, 9],\n",
        "        [10, 11, 12, 13, 14],\n",
        "        [15, 16, 17, 18, 19],\n",
        "    ],\n",
        "    dtype=t.float,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-iKkEfpjBUS"
      },
      "source": [
        "This tensor is stored in a contiguous block in computer memory.\n",
        "\n",
        "We can call the `stride` method to get the strides of this particular array. Running `test_input.stride()`, we get `(5, 1)`. This means that we need to skip over one element in the storage of this tensor to get to the next element in the row, and 5 elements to get the next element in the column (because you have to jump over all 5 elements in the row). Another way of phrasing this: the `n`th element in the stride is the number of elements we need to skip over to move one index position in the `n`th dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDrLYaxPjBUS"
      },
      "source": [
        "### Exercise - fill in the correct size and stride\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to ~30 minutes on these exercises collectively.\n",
        "> Strides can be confusing and fiddly, so you should be willing to look at the solution if you're stuck! They are not the most important part of the material today.\n",
        "> ```\n",
        "\n",
        "In the exercises below, we will work with the `test_input` tensor above. You should fill in the `size` and `stride` arguments so that calling `test_input.as_strided` with these arguments produces the desired output. When you run the cell, the `for` loop at the end will iterate through the test cases and print out whether the test passed or failed.\n",
        "\n",
        "We've already filled in the first two as an example, along with illustrations explaining what's going on:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/strides3c.png\" width=\"700\">\n",
        "\n",
        "By the end of these examples, hopefully you'll have a clear idea of what's going on. If you're still confused by some of these, then the dropdown below the codeblock contains some annotations to explain the answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tH7inLUjBUS"
      },
      "outputs": [],
      "source": [
        "TestCase = namedtuple(\"TestCase\", [\"output\", \"size\", \"stride\"])\n",
        "\n",
        "test_cases = [\n",
        "    # Example 1\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3]),\n",
        "        size=(4,),\n",
        "        stride=(1,),\n",
        "    ),\n",
        "    # Example 2\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 2], [5, 7]]),\n",
        "        size=(2, 2),\n",
        "        stride=(5, 2),\n",
        "    ),\n",
        "    # Start of exercises (you should fill in size & stride for all 6 of these):\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3, 4]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 5, 10, 15]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [5, 6, 7]]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [10, 11, 12]]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 0, 0], [11, 11, 11]]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 6, 12, 18]),\n",
        "        size=None,\n",
        "        stride=None,\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "for i, test_case in enumerate(test_cases):\n",
        "    if (test_case.size is None) or (test_case.stride is None):\n",
        "        print(f\"Test {i} failed: attempt missing.\")\n",
        "    else:\n",
        "        actual = test_input.as_strided(size=test_case.size, stride=test_case.stride)\n",
        "        if (test_case.output != actual).any():\n",
        "            print(f\"Test {i} failed\\n  Expected: {test_case.output}\\n  Actual: {actual}\")\n",
        "        else:\n",
        "            print(f\"Test {i} passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKaHnmSEjBUS"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "test_cases = [\n",
        "    # Example 1\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3]),\n",
        "        size=(4,),\n",
        "        stride=(1,),\n",
        "    ),\n",
        "    # Example 2\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 2], [5, 7]]),\n",
        "        size=(2, 2),\n",
        "        stride=(5, 2),\n",
        "    ),\n",
        "    # Start of exercises (you should fill in size & stride for all 6 of these):\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 1, 2, 3, 4]),\n",
        "        size=(5,),\n",
        "        stride=(1,),\n",
        "    ),\n",
        "    # # Explanation: the tensor is held in a contiguous memory block. When you get to the end of one row, a single\n",
        "    # # stride jumps to the start of the next row\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 5, 10, 15]),\n",
        "        size=(4,),\n",
        "        stride=(5,),\n",
        "    ),\n",
        "    # # Explanation: this is same as previous case, only now you're moving in colspace (i.e. skipping 5 elements) each\n",
        "    # # time you move one element across the output tensor. So stride is 5 rather than 1\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [5, 6, 7]]),\n",
        "        size=(2, 3),\n",
        "        stride=(5, 1),\n",
        "    ),\n",
        "    # # Explanation: as you move one column to the right in the output tensor, you want to jump one element in `test_input`\n",
        "    # # (since you're just going one column to the right). As you move one row down in the output tensor, you want to jump\n",
        "    # # down one row in `test_input` (which is equivalent to a stride of 5, because we're jumping 5 elements).\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 1, 2], [10, 11, 12]]),\n",
        "        size=(2, 3),\n",
        "        stride=(10, 1),\n",
        "    ),\n",
        "    # # Explanation: same as previous, except now we're jumping over 10 elements (2 rows of 5 elements) each time we\n",
        "    # # move down in the output tensor.\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([[0, 0, 0], [11, 11, 11]]),\n",
        "        size=(2, 3),\n",
        "        stride=(11, 0),\n",
        "    ),\n",
        "    # # Explanation: we're copying horizontally, i.e. we don't move in the original tensor when we step right in the\n",
        "    # # output tensor, so the stride is 0 (this is a very important case to understand for the later exercises, since\n",
        "    # # it's effectively our way of doing an einops.repeat operation!). As we move one row down, we're jumping over 11\n",
        "    # # elements in the original tensor (going from 0 to 11).\n",
        "    #\n",
        "    TestCase(\n",
        "        output=t.tensor([0, 6, 12, 18]),\n",
        "        size=(4,),\n",
        "        stride=(6,),\n",
        "    ),\n",
        "    # Explanation: we're effectively taking the diagonal elements of the original tensor here, since we're creating a\n",
        "    # 1D tensor with stride equal to (row_stride + col_stride) of the original tensor.\n",
        "]\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxcpBvqJjBUS"
      },
      "source": [
        "## Intermediate stride exercises\n",
        "\n",
        "Now that you're comfortable with the basics, we'll dive a little deeper with `as_strided`. In the last few exercises of this section, you'll start to implement some more challenging stride functions: trace, matrix-vector and matrix-matrix multiplication, just like we did for `einsum` in the previous section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2KTSl8VjBUS"
      },
      "source": [
        "### Exercise - trace\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> Use the hint if you're stuck.\n",
        "> ```\n",
        "\n",
        "You might find the very last example in the previous section helpful for this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWEgP_XHjBUS"
      },
      "outputs": [],
      "source": [
        "def as_strided_trace(mat: Float[Tensor, \"i j\"]) -> Float[Tensor, \"\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.trace`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_trace(as_strided_trace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQRIlcRojBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "The trace is the sum of all the elements you get from starting at `[0, 0]` and then continually stepping down and right one element. Use strides to create a 1D array which contains these elements.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def as_strided_trace(mat: Float[Tensor, \"i j\"]) -> Float[Tensor, \"\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.trace`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    stride = mat.stride()\n",
        "\n",
        "    assert len(stride) == 2, f\"matrix should be 2D, not {len(stride)}\"\n",
        "    assert mat.size(0) == mat.size(1), \"matrix should be square\"\n",
        "\n",
        "    diag = mat.as_strided((mat.size(0),), (stride[0] + stride[1],))\n",
        "\n",
        "    return diag.sum()\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T00YeIh3jBUS"
      },
      "source": [
        "### Exercise - matrix-vector multiplication\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise.\n",
        "> The hints should be especially useful here if you're stuck. There are two hints available to you.\n",
        "> ```\n",
        "\n",
        "You should implement this using only `as_strided` and `sum` methods, and elementwise multiplication `*` - in other words, no matrix multiplication functions!\n",
        "\n",
        "You might find the second last example in the previous section helpful for this exercise (i.e. the one that involved a stride of zero)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v1OGj_LjBUS"
      },
      "outputs": [],
      "source": [
        "def as_strided_mv(mat: Float[Tensor, \"i j\"], vec: Float[Tensor, \"j\"]) -> Float[Tensor, \"i\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_mv(as_strided_mv)\n",
        "tests.test_mv2(as_strided_mv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpinaDvgjBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Hint 1</summary>\n",
        "\n",
        "You want your output array to be as follows:\n",
        "\n",
        "$$\n",
        "\\text{output}[i] = \\sum_j \\text{mat}[i, j] \\times \\text{vector}[j]\n",
        "$$\n",
        "\n",
        "so first try to create an array with:\n",
        "\n",
        "$$\n",
        "\\text{arr}[i, j] = \\text{mat}[i, j] \\times \\text{vector}[j]\n",
        "$$\n",
        "\n",
        "then you can calculate `output` by summing over the second dimension of `arr`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 2</summary>\n",
        "\n",
        "First try to use strides to create `vec_expanded` such that:\n",
        "\n",
        "$$\n",
        "\\text{vec\\_expanded}[i, j] = \\text{vec}[j]\n",
        "$$\n",
        "\n",
        "We can then compute:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{arr}[i, j] &= \\text{mat}[i, j] \\times \\text{vec\\_expanded}[i, j] \\\\\n",
        "\\text{output}[i] &= \\sum_j \\text{arr}[i, j]\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "with the first equation being a simple elementwise multiplication, and the second equation being a sum over the second dimension.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm passing the first test, but failing the second.</summary>\n",
        "\n",
        "It's possible that the input matrices you recieve could themselves be the output of an `as_strided` operation, so that they're represented in memory in a non-contiguous way. Make sure that your `as_strided `operation is using the strides from the original input arrays, i.e. it's not just assuming the last element in the `stride()` tuple is 1.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def as_strided_mv(mat: Float[Tensor, \"i j\"], vec: Float[Tensor, \"j\"]) -> Float[Tensor, \"i\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    sizeM = mat.shape\n",
        "    sizeV = vec.shape\n",
        "    strideV = vec.stride()\n",
        "\n",
        "    assert len(sizeM) == 2, f\"mat1 should be 2D, not {len(sizeM)}\"\n",
        "    assert sizeM[1] == sizeV[0], f\"mat{list(sizeM)}, vec{list(sizeV)} not compatible for multiplication\"\n",
        "\n",
        "    vec_expanded = vec.as_strided(mat.shape, (0, strideV[0]))\n",
        "\n",
        "    return (mat * vec_expanded).sum(dim=1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPLHf1Y0jBUS"
      },
      "source": [
        "### Exercise - matrix-matrix multiplication\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> The hints should be especially useful here if you're stuck. There are two hints available to you.\n",
        "> ```\n",
        "                \n",
        "Like the previous function, this should only involve `as_strided`, `sum`, and pointwise multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNmY5ncGjBUS"
      },
      "outputs": [],
      "source": [
        "def as_strided_mm(matA: Float[Tensor, \"i j\"], matB: Float[Tensor, \"j k\"]) -> Float[Tensor, \"i k\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_mm(as_strided_mm)\n",
        "tests.test_mm2(as_strided_mm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMIOVzNCjBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Hint 1</summary>\n",
        "\n",
        "If you did the first one, this isn't too dissimilar. We have:\n",
        "\n",
        "$$\n",
        "\\text{output}[i, k] = \\sum_j \\text{matA}[i, j] \\times \\text{matB}[j, k]\n",
        "$$\n",
        "\n",
        "\n",
        "so in this case, try to create an array with:\n",
        "\n",
        "$$\n",
        "\\text{arr}[i, j, k] = \\text{matA}[i, j] \\times \\text{matB}[j, k]\n",
        "$$\n",
        "\n",
        "then sum this array over `j` to get our output.\n",
        "\n",
        "We need to create expanded versions of both `matA` and `matB` in order to take this product.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 2</summary>\n",
        "\n",
        "We want to compute\n",
        "\n",
        "$$\n",
        "\\text{matA\\_expanded}[i, j, k] = \\text{matA}[i, j]\n",
        "$$\n",
        "\n",
        "so our stride for `matA` should be `(matA.stride(0), matA.stride(1), 0)` (because we're repeating over the last dimension but iterating over the first 2 dimensions just like for the 2D matrix `matA`).\n",
        "        \n",
        "A similar idea applies for `matB`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def as_strided_mm(matA: Float[Tensor, \"i j\"], matB: Float[Tensor, \"j k\"]) -> Float[Tensor, \"i k\"]:\n",
        "    \"\"\"\n",
        "    Returns the same as `torch.matmul`, using only `as_strided` and `sum` methods.\n",
        "    \"\"\"\n",
        "    assert len(matA.shape) == 2, f\"mat1 should be 2D, not {len(matA.shape)}\"\n",
        "    assert len(matB.shape) == 2, f\"mat2 should be 2D, not {len(matB.shape)}\"\n",
        "    assert matA.shape[1] == matB.shape[0], (\n",
        "        f\"mat1{list(matA.shape)}, mat2{list(matB.shape)} not compatible for multiplication\"\n",
        "    )\n",
        "\n",
        "    # Get the matrix strides, and matrix dims\n",
        "    sA0, sA1 = matA.stride()\n",
        "    dA0, dA1 = matA.shape\n",
        "    sB0, sB1 = matB.stride()\n",
        "    _, dB1 = matB.shape\n",
        "\n",
        "    # Get target size for matrices, as well as the strides necessary to create them\n",
        "    expanded_size = (dA0, dA1, dB1)\n",
        "    matA_expanded_stride = (sA0, sA1, 0)\n",
        "    matB_expanded_stride = (0, sB0, sB1)\n",
        "\n",
        "    # Create the strided matrices, and return their product summed over middle dimension\n",
        "    matA_expanded = matA.as_strided(expanded_size, matA_expanded_stride)\n",
        "    matB_expanded = matB.as_strided(expanded_size, matB_expanded_stride)\n",
        "    return (matA_expanded * matB_expanded).sum(dim=1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyD475YsjBUS"
      },
      "source": [
        "## conv1d minimal\n",
        "\n",
        "Here, we will implement the PyTorch `conv1d` function, which can be found [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html). We will start with a simple implementation where `stride=1` and `padding=0`, with the other arguments set to their default values.\n",
        "\n",
        "Firstly, some explanation of `conv1d` in PyTorch. The `1` in `1d` here refers to the number of dimensions along which we slide the weights (also called the kernel) when we convolve. Importantly, it does not refer to the number of dimensions of the tensors that are being used in our calculations. Typically the input and kernel are both 3D:\n",
        "\n",
        "* `input.shape = (batch, in_channels, width)`\n",
        "* `kernel.shape = (out_channels, in_channels, kernel_width)`\n",
        "\n",
        "A typical convolution operation is illustrated in the sketch below. Some notes on this sketch:\n",
        "\n",
        "* The `kernel_width` dimension of the kernel slides along the `width` dimension of the input. The `output_width` of the output is determined by the number of kernels that can be fit inside it; the formula can be seen in the right part of the sketch.\n",
        "* For each possible position of the kernel inside the model (i.e. each freezeframe position in the sketch), the operation happening is as follows:\n",
        "    * We take the product of the kernel values with the corresponding input values, and then take the sum\n",
        "    * This gives us a single value for each output channel\n",
        "    * These values are then passed into the output tensor\n",
        "* The sketch assumes a batch size of 1. To generalise to a larger batch number, we can just imagine this operation being repeated identically on every input.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-general.png\" width=950>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxAW8W4jBUS"
      },
      "source": [
        "### A note on `out_channels`\n",
        "\n",
        "The out_channels in a conv2d layer denotes the number of filters the layer uses. Each filter detects specific features in the input, producing an output with as many channels as filters.\n",
        "\n",
        "This number isn't tied to the input image's channels but is a design choice in the neural network architecture. Commonly, powers of 2 are chosen for computational efficiency, and deeper layers might have more channels to capture complex features. Additionally, this parameter is sometimes chosen based on the heuristic of wanting to balance the parameter count / compute for each layer - which is why you often see `out_channels` growing as the size of each feature map gets smaller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CTCD1yYjBUS"
      },
      "source": [
        "### Exercise - implement minimal 1D conv (part 1)\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> Use the diagram in the dropdown below, if you're stuck.\n",
        "> ```\n",
        "\n",
        "Below, you should implement `conv1d_minimal`. This is a function which works just like `conv1d`, but takes the default stride and padding values (these will be added back in later). You are allowed to use `as_strided` and `einsum`.\n",
        "\n",
        "Because this is a difficult exercise, we've given you a \"simplified\" function to implement first. This gets rid of the batch dimension, and input & output channel dimensions, so you only have to think about `x` and `weights` being one-dimensional tensors:\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-minimal.png\" width=650>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLxYfHY9jBUS"
      },
      "outputs": [],
      "source": [
        "def conv1d_minimal_simple(\n",
        "    x: Float[Tensor, \"width\"], weights: Float[Tensor, \"kernel_width\"]\n",
        ") -> Float[Tensor, \"output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "\n",
        "    Simplifications: batch = input channels = output channels = 1.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv1d_minimal_simple(conv1d_minimal_simple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCLG9IFfjBUS"
      },
      "source": [
        "<details>\n",
        "<summary>If you're stuck on <code>conv1d_minimal_simple</code>, click here to see a diagram which should help.</summary>\n",
        "\n",
        "This diagram illustrates the striding operation you'll need to perform on `x`. Once you do this, it's just a matter of using the right `einsum` operation to get the output.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-explained.png\" width=800>\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv1d_minimal_simple(\n",
        "    x: Float[Tensor, \"width\"], weights: Float[Tensor, \"kernel_width\"]\n",
        ") -> Float[Tensor, \"output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "\n",
        "    Simplifications: batch = input channels = output channels = 1.\n",
        "    \"\"\"\n",
        "    # Get output width, using formula\n",
        "    w = x.shape[0]\n",
        "    kw = weights.shape[0]\n",
        "    ow = w - kw + 1\n",
        "\n",
        "    # Get strides for x\n",
        "    s_w = x.stride(0)\n",
        "\n",
        "    # Get strided x (the new dimension has same stride as the original stride of x)\n",
        "    x_new_shape = (ow, kw)\n",
        "    x_new_stride = (s_w, s_w)\n",
        "    # Common error: s_w is always 1 if the tensor `x` wasn't itself created via striding, so if you put 1 here you won't\n",
        "    # spot your mistake until you try this with conv2d!\n",
        "    x_strided = x.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"ow kw, kw -> ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNGOcHejBUS"
      },
      "source": [
        "### Exercise - implement minimal 1D conv (part 2)\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Once you've implemented this function, you should now adapt it to make a \"full version\", which includes batch, in_channel and out_channel dimensions. If you're stuck, the dropdowns provide hints for how each of these new dimensions should be handled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Vimmc0ajBUS"
      },
      "outputs": [],
      "source": [
        "def conv1d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], weights: Float[Tensor, \"out_channels in_channels kernel_width\"]\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv1d_minimal(conv1d_minimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hmPFS18jBUS"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm stuck on going from <code>conv1d_minimal_simple</code> to <code>conv1d_minimal</code>.</summary>\n",
        "\n",
        "The principle is the same as before. In your function, you should:\n",
        "\n",
        "* Create a strided version of `x` by adding a dimension of length `output_width` and with the same stride as the `width` stride of `x` (the purpose of which is to be able to do all the convolutions at once).\n",
        "* Perform an einsum between this strided version of `x` and `weights`, summing over the appropriate dimensions.\n",
        "\n",
        "The way each of the new dimensions `batch`, `out_channels` and `in_channels` are handled is as follows:\n",
        "\n",
        "* `batch` - this is an extra dimension for `x`, it is *not* summed over when creating `output`.\n",
        "* `out_channels` - this is an extra dimension for `weights`, it is *not* summed over when creating `output`.\n",
        "* `in_channels` - this is an extra dimension for `weights` *and* for `x`, it *is* summed over when creating `output`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv1d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], weights: Float[Tensor, \"out_channels in_channels kernel_width\"]\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    b, ic, w = x.shape\n",
        "    oc, ic2, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    # Get output width, using formula\n",
        "    ow = w - kw + 1\n",
        "\n",
        "    # Get strides for x\n",
        "    s_b, s_ic, s_w = x.stride()\n",
        "\n",
        "    # Get strided x (the new dimension has the same stride as the original width-stride of x)\n",
        "    x_new_shape = (b, ic, ow, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_w, s_w)\n",
        "    # Common error: xsWi is always 1, so if you put 1 here you won't spot your mistake until you try this with conv2d!\n",
        "    x_strided = x.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic ow kw, oc ic kw -> b oc ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgy48o8TjBUT"
      },
      "source": [
        "## conv2d minimal\n",
        "\n",
        "2D convolutions are conceptually similar to 1D. The only difference is in how you move the kernel across the tensor as you take your convolution. In this case, you will be moving the tensor across two dimensions:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv2d-general.png\" width=1050>\n",
        "\n",
        "For this reason, 1D convolutions tend to be used for signals (e.g. audio), 2D convolutions are used for images, and 3D convolutions are used for 3D scans (e.g. in medical applications)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p26FYremjBUT"
      },
      "source": [
        "### Exercise - implement 2D minimal convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        "> Use the diagram in the dropdown below, if you're stuck.\n",
        "> ```\n",
        "\n",
        "You should implement `conv2d` in a similar way to `conv1d`. Again, this is expected to be difficult and there are several hints you can go through. We've also provided a diagram to help you, like for the 1D case:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv2d-minimal.png\" width=900>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYIEJXr9jBUT"
      },
      "outputs": [],
      "source": [
        "def conv2d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        ") -> Float[Tensor, \"batch out_channels height_padding width_padding\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv2d_minimal(conv2d_minimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz3-F0JKjBUT"
      },
      "source": [
        "<details>\n",
        "<summary>Hint & diagram</summary>\n",
        "\n",
        "You should be doing the same thing that you did for the 1D version. The only difference is that you're introducing 2 new dimensions to your strided version of x, rather than 1 (their sizes should be `output_height` and `output_width`, and their strides should be the same as the original `height` and `width` strides of `x` respectively).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv2d-minimal-help.png\" width=700>\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv2d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        ") -> Float[Tensor, \"batch out_channels height_padding width_padding\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False and all other keyword arguments left at their default values.\n",
        "    \"\"\"\n",
        "    b, ic, h, w = x.shape\n",
        "    oc, ic2, kh, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    ow = w - kw + 1\n",
        "    oh = h - kh + 1\n",
        "\n",
        "    s_b, s_ic, s_h, s_w = x.stride()\n",
        "\n",
        "    # Get strided x (the new height/width dims have the same stride as the original height/width-strides of x)\n",
        "    x_new_shape = (b, ic, oh, ow, kh, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_h, s_w, s_h, s_w)\n",
        "\n",
        "    x_strided = x.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic oh ow kh kw, oc ic kh kw -> b oc oh ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9ecETF0jBUT"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbXIYhvujBUT"
      },
      "source": [
        "For a full version of `conv`, and for `maxpool` (which will follow shortly), you'll need to implement `pad` helper functions. PyTorch has some very generic padding functions, but to keep things simple and build up gradually, we'll write 1D and 2D functions individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDcFkEyojBUT"
      },
      "source": [
        "### Exercise - implement padding\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise, and the next.\n",
        "> ```\n",
        "\n",
        "The `pad1d` function applies padding to the width dimension of a 1D tensor, i.e. we pad with `left` entries to the start of the last dimension of `x` and with `right` entries to the end of the last dimension of `x`.\n",
        "\n",
        "Tips:\n",
        "* Use the `new_full` method of the input tensor. This is a clean way to ensure that the output tensor is on the same device as the input, and has the same dtype.\n",
        "* You can use three dots to denote slicing over multiple dimensions. For instance, `x[..., 0]` will take the `0th` slice of `x` along its last dimension. This is equivalent to `x[:, 0]` for 2D, `x[:, :, 0]` for 3D, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAqi59injBUT"
      },
      "outputs": [],
      "source": [
        "def pad1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], left: int, right: int, pad_value: float\n",
        ") -> Float[Tensor, \"batch in_channels width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the edges.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_pad1d(pad1d)\n",
        "tests.test_pad1d_multi_channel(pad1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nb2FBTijBUT"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I get <code>RuntimeError: The expanded size of the tensor (0) must match ...</code></summary>\n",
        "\n",
        "This might be because you've indexed with `left : -right`. Think about what will happen here when `right` is zero.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def pad1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], left: int, right: int, pad_value: float\n",
        ") -> Float[Tensor, \"batch in_channels width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the edges.\"\"\"\n",
        "    B, C, W = x.shape\n",
        "    output = x.new_full(size=(B, C, left + W + right), fill_value=pad_value)\n",
        "    output[..., left : left + W] = x  # note we can't use `left:-right`, because `right` might be zero\n",
        "    return output\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQtx9KDOjBUT"
      },
      "source": [
        "Once you've passed the tests, you can implement the 2D version. The `left` and `right` padding arguments apply to the width dimension, and the `top` and `bottom` padding arguments apply to the height dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVwG4EvvjBUT"
      },
      "outputs": [],
      "source": [
        "def pad2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    left: int,\n",
        "    right: int,\n",
        "    top: int,\n",
        "    bottom: int,\n",
        "    pad_value: float,\n",
        ") -> Float[Tensor, \"batch in_channels height_padding width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the width & height dimensions.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_pad2d(pad2d)\n",
        "tests.test_pad2d_multi_channel(pad2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsNzMIWKjBUT"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def pad2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    left: int,\n",
        "    right: int,\n",
        "    top: int,\n",
        "    bottom: int,\n",
        "    pad_value: float,\n",
        ") -> Float[Tensor, \"batch in_channels height_padding width_padding\"]:\n",
        "    \"\"\"Return a new tensor with padding applied to the width & height dimensions.\"\"\"\n",
        "    B, C, H, W = x.shape\n",
        "    output = x.new_full(size=(B, C, top + H + bottom, left + W + right), fill_value=pad_value)\n",
        "    output[..., top : top + H, left : left + W] = x\n",
        "    return output\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ywkYQ6ZjBUT"
      },
      "source": [
        "## Full convolutions\n",
        "\n",
        "Now, you'll extend `conv1d` to handle the `stride` and `padding` arguments.\n",
        "\n",
        "`stride` is the number of input positions that the kernel slides at each step. `padding` is the number of zeros concatenated to each side of the input before the convolution.\n",
        "\n",
        "Output shape should be `(batch, output_channels, output_length)`, where output_length can be calculated as follows:\n",
        "\n",
        "$$\n",
        "\\text{output\\_length} = \\left\\lfloor\\frac{\\text{input\\_length} + 2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} \\right\\rfloor + 1\n",
        "$$\n",
        "\n",
        "Verify for yourself that the forumla above simplifies to the formula we used earlier when padding is 0 and stride is 1.\n",
        "\n",
        "Docs for pytorch's `conv1d` can be found [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2E-Io4YjBUT"
      },
      "source": [
        "### Exercise - implement 1D convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm9IJlj8jBUT"
      },
      "outputs": [],
      "source": [
        "def conv1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_width\"],\n",
        "    stride: int = 1,\n",
        "    padding: int = 0,\n",
        ") -> Float[Tensor, \"batch out_channels width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv1d(conv1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBSmgAEjjBUT"
      },
      "source": [
        "<details>\n",
        "<summary>Hint - dealing with padding</summary>\n",
        "\n",
        "As the first line of your function, replace `x` with the padded version of `x`. This way, you won't have to worry about accounting for padding in the rest of the function (e.g. in the formula for the output width).\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint - dealing with strides</summary>\n",
        "\n",
        "The following diagram shows how you should create the strided version of `x` differently, if you have a stride of 2 rather than the default stride of 1.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ch0-conv1d-help.png\" width=\"850\">\n",
        "\n",
        "Remember, you'll need a new formula for `output_width` (see formula in the  [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html) for help with this, or see if you can derive it without help).\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_width\"],\n",
        "    stride: int = 1,\n",
        "    padding: int = 0,\n",
        ") -> Float[Tensor, \"batch out_channels width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv1d using bias=False.\n",
        "    \"\"\"\n",
        "    x_padded = pad1d(x, left=padding, right=padding, pad_value=0)\n",
        "\n",
        "    b, ic, w = x_padded.shape\n",
        "    oc, ic2, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    ow = 1 + (w - kw) // stride\n",
        "    # note, we assume padding is zero in the formula here, because we're working with input which has already been padded\n",
        "\n",
        "    s_b, s_ic, s_w = x_padded.stride()\n",
        "\n",
        "    # Get strided x (the new height/width dims have the same stride as the original height/width-strides of x,\n",
        "    # scaled by the stride (because we're \"skipping over\" x as we slide the kernel over it))\n",
        "    # See diagram in hints for more explanation.\n",
        "    x_new_shape = (b, ic, ow, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_w * stride, s_w)\n",
        "    x_strided = x_padded.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic ow kw, oc ic kw -> b oc ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rfXf1FyjBUT"
      },
      "source": [
        "### Exercise - implement 2D convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "A recurring pattern in these 2d functions is allowing the user to specify either an int or a pair of ints for an argument: examples are stride and padding. We've provided some type aliases and a helper function to simplify working with these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXVQGTOJjBUT"
      },
      "outputs": [],
      "source": [
        "IntOrPair = int | tuple[int, int]\n",
        "Pair = tuple[int, int]\n",
        "\n",
        "\n",
        "def force_pair(v: IntOrPair) -> Pair:\n",
        "    \"\"\"Convert v to a pair of int, if it isn't already.\"\"\"\n",
        "    if isinstance(v, tuple):\n",
        "        if len(v) != 2:\n",
        "            raise ValueError(v)\n",
        "        return (int(v[0]), int(v[1]))\n",
        "    elif isinstance(v, int):\n",
        "        return (v, v)\n",
        "    raise ValueError(v)\n",
        "\n",
        "\n",
        "# Examples of how this function can be used:\n",
        "for v in [(1, 2), 2, (1, 2, 3)]:\n",
        "    try:\n",
        "        print(f\"{v!r:9} -> {force_pair(v)!r}\")\n",
        "    except ValueError:\n",
        "        print(f\"{v!r:9} -> ValueError\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3x9bo6djBUT"
      },
      "source": [
        "Finally, you can implement a full version of `conv2d`. If you've done the full version of `conv1d`, and you've done `conv2d_minimal`, then you should be able to pull code from here to help you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYqsUhU-jBUT"
      },
      "outputs": [],
      "source": [
        "def conv2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        "    stride: IntOrPair = 1,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv2d(conv2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prEMdgDqjBUT"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    weights: Float[Tensor, \"out_channels in_channels kernel_height kernel_width\"],\n",
        "    stride: IntOrPair = 1,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like torch's conv2d using bias=False.\n",
        "    \"\"\"\n",
        "    stride_h, stride_w = force_pair(stride)\n",
        "    padding_h, padding_w = force_pair(padding)\n",
        "\n",
        "    x_padded = pad2d(x, left=padding_w, right=padding_w, top=padding_h, bottom=padding_h, pad_value=0)\n",
        "\n",
        "    b, ic, h, w = x_padded.shape\n",
        "    oc, ic2, kh, kw = weights.shape\n",
        "    assert ic == ic2, \"in_channels for x and weights don't match up\"\n",
        "    ow = 1 + (w - kw) // stride_w\n",
        "    oh = 1 + (h - kh) // stride_h\n",
        "\n",
        "    s_b, s_ic, s_h, s_w = x_padded.stride()\n",
        "\n",
        "    # Get strided x (new height/width dims have same stride as original height/width-strides of x, scaled by stride)\n",
        "    x_new_shape = (b, ic, oh, ow, kh, kw)\n",
        "    x_new_stride = (s_b, s_ic, s_h * stride_h, s_w * stride_w, s_h, s_w)\n",
        "    x_strided = x_padded.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    return einops.einsum(x_strided, weights, \"b ic oh ow kh kw, oc ic kh kw -> b oc oh ow\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiY-d1FKjBUT"
      },
      "source": [
        "## Max pooling\n",
        "\n",
        "We have just one function left now - **max pooling**. You can review the [Medium post](https://medium.com/towards-data-science/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) from earlier to understand max pooling better.\n",
        "\n",
        "A \"max pooling\" layer is similar to a convolution in that you have a window sliding over some number of dimensions. The main difference is that there's no kernel: instead of multiplying by the kernel and adding, you just take the maximum.\n",
        "\n",
        "The way multiple channels work is also different. A convolution has some number of input and output channels, and each output channel is a function of all the input channels. There can be any number of output channels. In a pooling layer, the maximum operation is applied independently for each input channel, meaning the number of output channels is necessarily equal to the number of input channels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zfvV5G2jBUT"
      },
      "source": [
        "### Exercise - implement 2D max pooling\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `maxpool2d` using `torch.as_strided` and `torch.amax` (= max over axes) together. Your version should behave the same as the PyTorch version, but only the indicated arguments need to be supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17pBDSqOjBUT"
      },
      "outputs": [],
      "source": [
        "def maxpool2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    kernel_size: IntOrPair,\n",
        "    stride: IntOrPair | None = None,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like PyTorch's maxpool2d. If stride is None, should be equal to kernel size.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_maxpool2d(maxpool2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0OsLmyvjBUU"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Conceptually, this is similar to `conv2d`.\n",
        "    \n",
        "In `conv2d`, you had to use `as_strided` to turn the 4D tensor `x` into a 6D tensor `x_strided` (adding dimensions over which you would take the convolution), then multiply this tensor by the kernel and sum over these two new dimensions.\n",
        "\n",
        "`maxpool2d` is the same, except that you're simply taking max over those dimensions rather than a dot product with the kernel. So you should find yourself able to reuse a lot of code from your `conv2d` function.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm getting a small number of mismatched elements each time (e.g. between 0 and 5%).</summary>\n",
        "\n",
        "This is likely because you used an incorrect `pad_value`. In the convolution function, we set `pad_value=0` so these values wouldn't have any effect in the linear transformation. What pad value would make our padded elements \"invisible\" when we take the maximum?\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def maxpool2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"],\n",
        "    kernel_size: IntOrPair,\n",
        "    stride: IntOrPair | None = None,\n",
        "    padding: IntOrPair = 0,\n",
        ") -> Float[Tensor, \"batch out_channels height width\"]:\n",
        "    \"\"\"\n",
        "    Like PyTorch's maxpool2d. If stride is None, should be equal to kernel size.\n",
        "    \"\"\"\n",
        "    # Set actual values for stride and padding, using force_pair function\n",
        "    if stride is None:\n",
        "        stride = kernel_size\n",
        "    stride_h, stride_w = force_pair(stride)\n",
        "    padding_h, padding_w = force_pair(padding)\n",
        "    kh, kw = force_pair(kernel_size)\n",
        "\n",
        "    # Get padded version of x\n",
        "    x_padded = pad2d(x, left=padding_w, right=padding_w, top=padding_h, bottom=padding_h, pad_value=-t.inf)\n",
        "\n",
        "    # Calculate output height and width for x\n",
        "    b, ic, h, w = x_padded.shape\n",
        "    ow = 1 + (w - kw) // stride_w\n",
        "    oh = 1 + (h - kh) // stride_h\n",
        "\n",
        "    # Get strided x\n",
        "    s_b, s_c, s_h, s_w = x_padded.stride()\n",
        "\n",
        "    x_new_shape = (b, ic, oh, ow, kh, kw)\n",
        "    x_new_stride = (s_b, s_c, s_h * stride_h, s_w * stride_w, s_h, s_w)\n",
        "    x_strided = x_padded.as_strided(size=x_new_shape, stride=x_new_stride)\n",
        "\n",
        "    # Argmax over dimensions of the maxpool kernel\n",
        "    # (note these are the same dims that we multiply over in 2D convolutions)\n",
        "    return x_strided.amax(dim=(-1, -2))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd1rET04jBUU"
      },
      "source": [
        "Now, you're finished! You can go back to the ResNets exercises, and build your ResNet ***entirely using your own stride-based functions***."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77162a2448d442a59363324f157fe36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_478b2c56e5944279b6ef825d6f443ad6",
              "IPY_MODEL_b30709540a5c4d748bf8d7caf4d0125c",
              "IPY_MODEL_9050ad61b91c492bb37a674af22b50aa"
            ],
            "layout": "IPY_MODEL_d92b8e4aac7547768ba104029f1a761f"
          }
        },
        "478b2c56e5944279b6ef825d6f443ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d3361af45b6444484a08e9adfbcef2b",
            "placeholder": "​",
            "style": "IPY_MODEL_1418a29a52c54fe0b1b1bee87ddfd5ec",
            "value": "100%"
          }
        },
        "b30709540a5c4d748bf8d7caf4d0125c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab4601db1964758b5062edd87add959",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09a7a810e4ec4f47a8c3adc7f810e538",
            "value": 6
          }
        },
        "9050ad61b91c492bb37a674af22b50aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0e4536783554072b17bb90297b4cf17",
            "placeholder": "​",
            "style": "IPY_MODEL_3d49dea8d431403d896f1cd906fad468",
            "value": " 6/6 [00:06&lt;00:00,  1.00s/it, i=5, letter=!, time=6.008]"
          }
        },
        "d92b8e4aac7547768ba104029f1a761f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d3361af45b6444484a08e9adfbcef2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1418a29a52c54fe0b1b1bee87ddfd5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cab4601db1964758b5062edd87add959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a7a810e4ec4f47a8c3adc7f810e538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0e4536783554072b17bb90297b4cf17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d49dea8d431403d896f1cd906fad468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4577d1c5fe4446c87d3990a611a6146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9346283fd9034263a918609148ce1b88",
              "IPY_MODEL_127aadd55c5a433bb2f201d6a7378c9b",
              "IPY_MODEL_39ac96a8871d4cf18aaacab654617b77"
            ],
            "layout": "IPY_MODEL_7769ce496e4d4b8a9b5c0ebedd487712"
          }
        },
        "9346283fd9034263a918609148ce1b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78b4cf1eb9d34b1f9244b157587e1b51",
            "placeholder": "​",
            "style": "IPY_MODEL_0a446dc2131349799dfe2901ee3f7595",
            "value": "100%"
          }
        },
        "127aadd55c5a433bb2f201d6a7378c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83584efaae0a4e5f9f9b4c70f48584d1",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8309741998cb42eeafae743694a6fe91",
            "value": 79
          }
        },
        "39ac96a8871d4cf18aaacab654617b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d82f9a29c14475ab8a3364dd1092650",
            "placeholder": "​",
            "style": "IPY_MODEL_4b5e634373d847aa81cec36ba02f7457",
            "value": " 79/79 [00:05&lt;00:00,  9.87it/s, epoch=1/3, loss=0.331]"
          }
        },
        "7769ce496e4d4b8a9b5c0ebedd487712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78b4cf1eb9d34b1f9244b157587e1b51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a446dc2131349799dfe2901ee3f7595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83584efaae0a4e5f9f9b4c70f48584d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8309741998cb42eeafae743694a6fe91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d82f9a29c14475ab8a3364dd1092650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b5e634373d847aa81cec36ba02f7457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ae5150dd2d349a7a719afe1e9a13be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb13817ea09c443d90db066ebd308873",
              "IPY_MODEL_229c77768f754f3581a447d112fc5f36",
              "IPY_MODEL_3fd6cbab68ca415583b1e7e8a0221aa7"
            ],
            "layout": "IPY_MODEL_203f698177e846bdbdec273a8730bf32"
          }
        },
        "fb13817ea09c443d90db066ebd308873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8234920c2ab48499682646a9fc91b5d",
            "placeholder": "​",
            "style": "IPY_MODEL_cbf5788569fc42589dbb00cf5ca625e5",
            "value": "100%"
          }
        },
        "229c77768f754f3581a447d112fc5f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb4626491c134718a521e373983752d2",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc91b034f94d4533b70472db277b4482",
            "value": 79
          }
        },
        "3fd6cbab68ca415583b1e7e8a0221aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc7ada51b84d428e91b42daae6f64203",
            "placeholder": "​",
            "style": "IPY_MODEL_d832ac9f97074155812d80f94df2cef4",
            "value": " 79/79 [00:06&lt;00:00, 14.30it/s, epoch=2/3, loss=0.157]"
          }
        },
        "203f698177e846bdbdec273a8730bf32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8234920c2ab48499682646a9fc91b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbf5788569fc42589dbb00cf5ca625e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb4626491c134718a521e373983752d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc91b034f94d4533b70472db277b4482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc7ada51b84d428e91b42daae6f64203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d832ac9f97074155812d80f94df2cef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "572a2dc5793140acaa6781550b31dc9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4cb6b2710b847d19af832d3610554bf",
              "IPY_MODEL_df3dc34015ca4018a747fe47607b8bb5",
              "IPY_MODEL_3d7e9c7faad64020b55784499d14331b"
            ],
            "layout": "IPY_MODEL_0d1973e1a1514176be398d8c88ce6dab"
          }
        },
        "d4cb6b2710b847d19af832d3610554bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d293a4d5e04af498c3275ec139b7a9",
            "placeholder": "​",
            "style": "IPY_MODEL_0341b20508824c3e8299cba2ba133ec6",
            "value": "100%"
          }
        },
        "df3dc34015ca4018a747fe47607b8bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c17cc49c50aa4d1b994887c612a44c30",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f85b81cbf490424283e84fe186fb1a93",
            "value": 79
          }
        },
        "3d7e9c7faad64020b55784499d14331b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96ce32df5d9a4020afd636621395513e",
            "placeholder": "​",
            "style": "IPY_MODEL_8a1feb4718404a85a7304af227676bee",
            "value": " 79/79 [00:05&lt;00:00, 22.11it/s, epoch=3/3, loss=0.039]"
          }
        },
        "0d1973e1a1514176be398d8c88ce6dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d293a4d5e04af498c3275ec139b7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0341b20508824c3e8299cba2ba133ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c17cc49c50aa4d1b994887c612a44c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f85b81cbf490424283e84fe186fb1a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96ce32df5d9a4020afd636621395513e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a1feb4718404a85a7304af227676bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6b3cea04d7149cc8d76a7742dcb79ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4093ce5092d5456ab61d9e025211e648",
              "IPY_MODEL_34a73d0af37b4fe5bf68e239dc442057",
              "IPY_MODEL_c1f9a90153ca4757926401a294a873bd"
            ],
            "layout": "IPY_MODEL_f174e621c3fa40edae051ff300ff472f"
          }
        },
        "4093ce5092d5456ab61d9e025211e648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aed0d77436347c3ba3c62d5c3360890",
            "placeholder": "​",
            "style": "IPY_MODEL_53064e728e0f4b2881b79df6a9512713",
            "value": "100%"
          }
        },
        "34a73d0af37b4fe5bf68e239dc442057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59c37fb9f03a4aad91041ed52aa0e9a4",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea988373fda445f396df57bdf540ef5e",
            "value": 157
          }
        },
        "c1f9a90153ca4757926401a294a873bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6da9d75a028648298a5e327c99b81825",
            "placeholder": "​",
            "style": "IPY_MODEL_b7cb420ee6ac484d877e2df16067b73a",
            "value": " 157/157 [00:03&lt;00:00, 51.92it/s, epoch=1/3, loss=0.858]"
          }
        },
        "f174e621c3fa40edae051ff300ff472f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aed0d77436347c3ba3c62d5c3360890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53064e728e0f4b2881b79df6a9512713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59c37fb9f03a4aad91041ed52aa0e9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea988373fda445f396df57bdf540ef5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6da9d75a028648298a5e327c99b81825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7cb420ee6ac484d877e2df16067b73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80e6ce9f696d45cba8d8b511735df32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85fe95e3f4a54e3fbed06ccf3ca100c5",
              "IPY_MODEL_cd43db5ffed548798b6f521cfd7d5a93",
              "IPY_MODEL_75c849775e654441a3fcf8e742f4eb6d"
            ],
            "layout": "IPY_MODEL_5091ad8d8a6e4c65b5eb4dc405f9ed7d"
          }
        },
        "85fe95e3f4a54e3fbed06ccf3ca100c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac8cbf3e425041709f9155244adf3d0a",
            "placeholder": "​",
            "style": "IPY_MODEL_32cb214483dc4d2d90ad4bffc25b7d2e",
            "value": "100%"
          }
        },
        "cd43db5ffed548798b6f521cfd7d5a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5d47a0eb0644a068c0d0815440789ad",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_720a7be4da2f408b9df2ac25a45fa157",
            "value": 157
          }
        },
        "75c849775e654441a3fcf8e742f4eb6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d3615ab1454afc9586e4c0f024b8f5",
            "placeholder": "​",
            "style": "IPY_MODEL_a50846783b4e449c8280ed15b5b8117c",
            "value": " 157/157 [00:03&lt;00:00, 51.39it/s, epoch=2/3, loss=0.129]"
          }
        },
        "5091ad8d8a6e4c65b5eb4dc405f9ed7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac8cbf3e425041709f9155244adf3d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32cb214483dc4d2d90ad4bffc25b7d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5d47a0eb0644a068c0d0815440789ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "720a7be4da2f408b9df2ac25a45fa157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73d3615ab1454afc9586e4c0f024b8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50846783b4e449c8280ed15b5b8117c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "405480958f624cf4bb8b59568f15fa93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44ec736e0b3c437baffc6d6975f7b526",
              "IPY_MODEL_d3880c1e183f486cb636c6573cf5c3f0",
              "IPY_MODEL_e3ca8ddb810848e6b341ec682cc6b07e"
            ],
            "layout": "IPY_MODEL_b01b713a09554286a692309dead8b9e4"
          }
        },
        "44ec736e0b3c437baffc6d6975f7b526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71671a2f9779466286478637ac831222",
            "placeholder": "​",
            "style": "IPY_MODEL_af82bb4655ef4de28420b5386d6ac934",
            "value": "100%"
          }
        },
        "d3880c1e183f486cb636c6573cf5c3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f8222fb1e034b709730a79da64c224e",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23cdf7663286480a9d7e98af2e5f5ad7",
            "value": 157
          }
        },
        "e3ca8ddb810848e6b341ec682cc6b07e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0c2478672a94658a8e2d978a595672c",
            "placeholder": "​",
            "style": "IPY_MODEL_c856ba2d6b07453db2032129036411a7",
            "value": " 157/157 [00:03&lt;00:00, 49.00it/s, epoch=3/3, loss=0.248]"
          }
        },
        "b01b713a09554286a692309dead8b9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71671a2f9779466286478637ac831222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af82bb4655ef4de28420b5386d6ac934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f8222fb1e034b709730a79da64c224e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23cdf7663286480a9d7e98af2e5f5ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0c2478672a94658a8e2d978a595672c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c856ba2d6b07453db2032129036411a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ecb7e8cc1f94de2a853acd2787aa1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f21e3508bb342f985f89ca50d486b3f",
              "IPY_MODEL_ba309e450fe24f35b1ec3866feaf804c",
              "IPY_MODEL_518810628847449996f82e610a475b20"
            ],
            "layout": "IPY_MODEL_5f6a779ecff6446aaf307bc1bef9f084"
          }
        },
        "3f21e3508bb342f985f89ca50d486b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c582b8cbb5046a4beac0b8078376099",
            "placeholder": "​",
            "style": "IPY_MODEL_5ede70d2f2914e90bbbae1e0d8d1f8cd",
            "value": "  0%"
          }
        },
        "ba309e450fe24f35b1ec3866feaf804c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b4e1adb73149c8b613c98a3db01435",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcb90858048744179d979274d2ca5c46",
            "value": 0
          }
        },
        "518810628847449996f82e610a475b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_030d9f81b3694c48b2b64d90441fb148",
            "placeholder": "​",
            "style": "IPY_MODEL_bd38dfa7809c4ce890a93cb9701d79ef",
            "value": " 0/157 [00:52&lt;?, ?it/s]"
          }
        },
        "5f6a779ecff6446aaf307bc1bef9f084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c582b8cbb5046a4beac0b8078376099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ede70d2f2914e90bbbae1e0d8d1f8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64b4e1adb73149c8b613c98a3db01435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb90858048744179d979274d2ca5c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "030d9f81b3694c48b2b64d90441fb148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd38dfa7809c4ce890a93cb9701d79ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "720c896ae37b4bb291e965b7a588de30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c9ac43bf8f14e9babdd8ebd8c2ad825",
              "IPY_MODEL_f248b6ae02e848c1ab1cd481102ee54b",
              "IPY_MODEL_c708e737efd54eb1b369fd8a96fcac14"
            ],
            "layout": "IPY_MODEL_c4e8d5fdf1164d2e8c77717ef2a5e050"
          }
        },
        "5c9ac43bf8f14e9babdd8ebd8c2ad825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36b0f016140449f1a3e40ee5e8331934",
            "placeholder": "​",
            "style": "IPY_MODEL_55a22e96b53f4b4cbe09f5ac096d509a",
            "value": "  0%"
          }
        },
        "f248b6ae02e848c1ab1cd481102ee54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eee78d18643244c4b0295f9e85ab7ea7",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0bacff3c463477fba607dfa4c7ce1c4",
            "value": 0
          }
        },
        "c708e737efd54eb1b369fd8a96fcac14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b27b12fb29aa4e5298e69b8574ab529d",
            "placeholder": "​",
            "style": "IPY_MODEL_69d221964d774338bf4b05e413774cf3",
            "value": " 0/157 [00:49&lt;?, ?it/s]"
          }
        },
        "c4e8d5fdf1164d2e8c77717ef2a5e050": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b0f016140449f1a3e40ee5e8331934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55a22e96b53f4b4cbe09f5ac096d509a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eee78d18643244c4b0295f9e85ab7ea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0bacff3c463477fba607dfa4c7ce1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b27b12fb29aa4e5298e69b8574ab529d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69d221964d774338bf4b05e413774cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9102a50bb03e4e3b829ec085d0c59b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_053ae1a2cb594ed594b68d42c89a0955",
              "IPY_MODEL_a1e34c78f5a5452e8a3ee89404b10db9",
              "IPY_MODEL_9c717afd6da840bb91208024d445d580"
            ],
            "layout": "IPY_MODEL_d7d67376b1fd4481a04f11d99ecda8d4"
          }
        },
        "053ae1a2cb594ed594b68d42c89a0955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bea6293fbea4f24aed5ec368546638a",
            "placeholder": "​",
            "style": "IPY_MODEL_32177264f2f0471f83030ae98f43bc0f",
            "value": "  0%"
          }
        },
        "a1e34c78f5a5452e8a3ee89404b10db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab65329f0bef4b9fac962d5307ea9406",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8a8e8939bc546978f633c5b8b0da063",
            "value": 0
          }
        },
        "9c717afd6da840bb91208024d445d580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af49f6717d4433cb9201b48302878e6",
            "placeholder": "​",
            "style": "IPY_MODEL_f4cc61864acc4fc9a9d3e73725f20774",
            "value": " 0/157 [00:02&lt;?, ?it/s]"
          }
        },
        "d7d67376b1fd4481a04f11d99ecda8d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bea6293fbea4f24aed5ec368546638a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32177264f2f0471f83030ae98f43bc0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab65329f0bef4b9fac962d5307ea9406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a8e8939bc546978f633c5b8b0da063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2af49f6717d4433cb9201b48302878e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4cc61864acc4fc9a9d3e73725f20774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}