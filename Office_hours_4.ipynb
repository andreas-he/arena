{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lNRaGsPhtMSL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreas-he/arena/blob/main/Office_hours_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Calculating Conditional Log Probability with GPT-2\n",
        "\n",
        "**Goal:** Calculate the conditional log probability of a sequence of text given a preceding context using a pre-trained GPT-2 model.\n",
        "\n",
        "Specifically, we want to find:\n",
        "\n",
        "`log P(subsequent_text | reference_text)`\n",
        "\n",
        "We will use the `transformer_lens` library to load GPT-2 and perform the calculations. This involves:\n",
        "1. Tokenizing the reference and subsequent texts.\n",
        "2. Running the combined sequence through the model to get logits.\n",
        "3. Converting logits to log probabilities (using `log_softmax`).\n",
        "4. Identifying and summing the log probabilities corresponding to the tokens in the `subsequent_text`.\n",
        "\n",
        "First run the set-up cell below:"
      ],
      "metadata": {
        "id": "g2Sw232XpasY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Setup Cell\n",
        "\n",
        "%pip install transformer_lens==2.11.0 einops jaxtyping git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import torch as t\n",
        "from torch import Tensor\n",
        "from jaxtyping import Float, Int\n",
        "import einops # Often used with transformer_lens, good to import\n",
        "from transformer_lens import HookedTransformer\n",
        "import math # For log probability\n",
        "\n",
        "print(\"Setting up device...\")\n",
        "device = t.device(\"cuda\" if t.cuda.is_available() else \"mps\" if t.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the GPT-2 small model\n",
        "print(\"Loading GPT-2 small model (this may take a moment)...\")\n",
        "model = HookedTransformer.from_pretrained(\n",
        "    \"gpt2-small\",\n",
        "    fold_ln=False,\n",
        "    center_unembed=False,\n",
        "    center_writing_weights=False,\n",
        ")\n",
        "model.to(device) # Move model to the chosen device\n",
        "print(\"Model loaded and moved to device.\")\n",
        "\n",
        "# Ensure the model's tokenizer has a BOS token defined\n",
        "# GPT2TokenizerFast usually uses <|endoftext|> as BOS/EOS\n",
        "print(\"Checking for BOS token...\")\n",
        "if model.tokenizer.bos_token_id is None:\n",
        "    if model.tokenizer.eos_token_id is not None:\n",
        "        print(f\"Setting BOS token ID to EOS token ID: {model.tokenizer.eos_token_id}\")\n",
        "        model.tokenizer.bos_token_id = model.tokenizer.eos_token_id\n",
        "        # Ensure the model config also knows the BOS token ID\n",
        "        if hasattr(model.cfg, 'bos_token_id'):\n",
        "             model.cfg.bos_token_id = model.tokenizer.eos_token_id\n",
        "    else:\n",
        "        # Fallback if absolutely necessary\n",
        "        fallback_bos = \"<|endoftext|>\"\n",
        "        try:\n",
        "            model.tokenizer.add_special_tokens({'bos_token': fallback_bos})\n",
        "            if hasattr(model.cfg, 'bos_token_id'):\n",
        "                model.cfg.bos_token_id = model.tokenizer.bos_token_id\n",
        "            print(f\"Warning: Manually added BOS token '{fallback_bos}'\")\n",
        "        except Exception as e:\n",
        "             print(f\"Error adding fallback BOS token: {e}. Proceeding without guaranteed BOS might cause issues.\")\n",
        "print(f\"Using BOS token ID: {model.tokenizer.bos_token_id}\")\n",
        "print(\"Setup complete.\")\n",
        "\n",
        "_EXPECTED_LOG_PROB = -16.5449 # Global placeholder, will be updated by solution cell\n",
        "\n",
        "def verify_log_prob(student_func, model, ref_text, sub_text, expected_value):\n",
        "    \"\"\"\n",
        "    Runs the student's function and compares its output to the expected value.\n",
        "    \"\"\"\n",
        "    print(\"--- Running Verifier ---\")\n",
        "    if expected_value == -999.9:\n",
        "         print(\"Note: Expected value is still a placeholder. Run the solution cell first to calculate it.\")\n",
        "         # Still proceed to run the student function to catch errors\n",
        "\n",
        "    passed = False\n",
        "    try:\n",
        "        student_result = student_func(model, ref_text, sub_text)\n",
        "\n",
        "        if not isinstance(student_result, float):\n",
        "            print(f\"❌ Failed: Output type is {type(student_result)}, expected float.\")\n",
        "        # Use isclose for robust floating point comparison\n",
        "        elif expected_value != -999.9 and t.isclose(t.tensor(student_result), t.tensor(expected_value), atol=1e-4):\n",
        "             print(f\"✅ Success: Log probability matches expected value!\")\n",
        "             print(f\"   Expected: {expected_value:.4f}\")\n",
        "             print(f\"   Got:      {student_result:.4f}\")\n",
        "             passed = True\n",
        "        elif expected_value == -999.9:\n",
        "            print(f\"🤔 Result Received: {student_result:.4f}. Cannot verify correctness without expected value.\")\n",
        "            print(\"   (Run the solution cell below to calculate expected value and re-run verification)\")\n",
        "        else:\n",
        "             print(f\"❌ Failed: Log probability does not match expected value.\")\n",
        "             print(f\"   Expected: {expected_value:.4f}\")\n",
        "             print(f\"   Got:      {student_result:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed: Error during function execution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"--- Verifier Finished ---\")\n",
        "    return passed"
      ],
      "metadata": {
        "id": "wKKJjbBajgXQ",
        "outputId": "1be2e311-923e-4a2b-c77b-f7a9d3ad213e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
            "  Cloning https://github.com/callummcdougall/CircuitsVis.git to /tmp/pip-req-build-ofg_ut1h\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/callummcdougall/CircuitsVis.git /tmp/pip-req-build-ofg_ut1h\n",
            "  Resolved https://github.com/callummcdougall/CircuitsVis.git to commit 1e6129d08cae7af9242d9ab5d3ed322dd44b4dd3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformer_lens==2.11.0\n",
            "  Downloading transformer_lens-2.11.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.3.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (1.5.2)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens==2.11.0)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens==2.11.0)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer_lens==2.11.0)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer_lens==2.11.0)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (4.50.3)\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (4.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (4.13.1)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens==2.11.0) (0.19.9)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping)\n",
            "  Downloading wadler_lindig-0.1.4-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting importlib-metadata<6.0.0,>=5.1.0 (from circuitsvis==0.0.0)\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting numpy>=1.24 (from transformer_lens==2.11.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens==2.11.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens==2.11.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens==2.11.0) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens==2.11.0) (0.30.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens==2.11.0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens==2.11.0) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens==2.11.0) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer_lens==2.11.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens==2.11.0) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer_lens==2.11.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.7.1->transformer_lens==2.11.0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.7.1->transformer_lens==2.11.0)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens==2.11.0) (3.11.15)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis==0.0.0) (3.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens==2.11.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens==2.11.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens==2.11.0) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens==2.11.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens==2.11.0) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens==2.11.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens==2.11.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10->transformer_lens==2.11.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10->transformer_lens==2.11.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10->transformer_lens==2.11.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10->transformer_lens==2.11.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10->transformer_lens==2.11.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10->transformer_lens==2.11.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10->transformer_lens==2.11.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10->transformer_lens==2.11.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10->transformer_lens==2.11.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens==2.11.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens==2.11.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens==2.11.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10->transformer_lens==2.11.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens==2.11.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens==2.11.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->transformer_lens==2.11.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37.2->transformer_lens==2.11.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37.2->transformer_lens==2.11.0) (0.21.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens==2.11.0) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens==2.11.0) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens==2.11.0) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens==2.11.0) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens==2.11.0) (2.11.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens==2.11.0) (2.25.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens==2.11.0) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens==2.11.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens==2.11.0) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens==2.11.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens==2.11.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens==2.11.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens==2.11.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens==2.11.0) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens==2.11.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens==2.11.0) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens==2.11.0) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens==2.11.0) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens==2.11.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens==2.11.0) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens==2.11.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens==2.11.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens==2.11.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->transformer_lens==2.11.0) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens==2.11.0) (5.0.2)\n",
            "Downloading transformer_lens-2.11.0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/363.4 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Task\n",
        "\n",
        "Your task is to implement the function `calculate_log_prob_exercise` below. It should take the pre-loaded `model`, a `reference_text`, and a `subsequent_text` as input and return the total log probability `log P(subsequent_text | reference_text)`.\n",
        "\n",
        "We will use the following texts:"
      ],
      "metadata": {
        "id": "VCfzelLopthC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Texts for the exercise ---\n",
        "reference_text = \"What is the answer to 1 + 1? \"\n",
        "subsequent_text = \"The answer is 2\"\n",
        "\n",
        "print(f\"Reference Text: {reference_text!r}\")\n",
        "print(f\"Subsequent Text: {subsequent_text!r}\")\n",
        "\n",
        "# --- Your Function Definition ---\n",
        "\n",
        "def calculate_log_prob_exercise(\n",
        "    model: HookedTransformer,\n",
        "    reference_text: str,\n",
        "    subsequent_text: str\n",
        ") -> float:\n",
        "    '''\n",
        "    Calculates the total log probability of subsequent_text given reference_text\n",
        "    using the provided GPT-2 model.\n",
        "\n",
        "    Args:\n",
        "        model: The pre-trained HookedTransformer model (e.g., GPT-2).\n",
        "        reference_text: The preceding text context.\n",
        "        subsequent_text: The text whose conditional probability we want.\n",
        "\n",
        "    Returns:\n",
        "        The total log probability (base e) as a float.\n",
        "        log P(subsequent_text | reference_text)\n",
        "    '''\n",
        "\n",
        "    # Ensure calculations are done without tracking gradients for efficiency\n",
        "    with t.no_grad():\n",
        "\n",
        "        # --- YOUR CODE HERE ---\n",
        "\n",
        "        # Placeholder return - replace with your code!\n",
        "        print(\"calculate_log_prob_exercise is not implemented yet.\") # Add a print statement for clarity\n",
        "        return 0.0\n",
        "\n",
        "    # --- End YOUR CODE HERE ---\n",
        "\n",
        "# Test call (optional, will return placeholder value until implemented)\n",
        "# print(f\"Test call result (placeholder): {calculate_log_prob_exercise(model, reference_text, subsequent_text)}\")"
      ],
      "metadata": {
        "id": "QBwVWHDPpyGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hint below"
      ],
      "metadata": {
        "id": "lNRaGsPhtMSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# hint\n",
        "\n",
        "# 1. Tokenize reference_text and subsequent_text separately.\n",
        "#    Use model.to_tokens() and ensure prepend_bos=False for now.\n",
        "# ref_tokens_cpu = ... # Shape: (ref_len)\n",
        "# sub_tokens_cpu = ... # Shape: (sub_len)\n",
        "\n",
        "# 2. Get the BOS token ID from the model's tokenizer.\n",
        "#    Handle the case where it might be None (though setup cell tries to prevent this).\n",
        "# bos_token_id = ...\n",
        "# bos_tensor_cpu = ... # Create a tensor with the ID\n",
        "\n",
        "# 3. Construct the full token sequence on CPU: [BOS, ref_tokens, sub_tokens]\n",
        "#    Use torch.cat().\n",
        "# full_tokens_cpu = ... # Shape: (1 + ref_len + sub_len)\n",
        "\n",
        "# 4. Move the full sequence to the model's device and add a batch dimension.\n",
        "# full_tokens = ... # Shape: (1, seq_len)\n",
        "\n",
        "# 5. Pass the full_tokens sequence through the model to get logits.\n",
        "# logits = ... # Shape: (1, seq_len, vocab_size)\n",
        "\n",
        "# 6. Calculate the log probabilities using log_softmax on the logits.\n",
        "#    Apply along the vocabulary dimension (dim=-1).\n",
        "# log_probs = ... # Shape: (1, seq_len, vocab_size)\n",
        "\n",
        "# 7. Identify the target tokens (the tokens from subsequent_text).\n",
        "#    These are located *after* the BOS and reference tokens in full_tokens.\n",
        "#    Get the length of ref_tokens to find the starting index.\n",
        "# len_ref = ...\n",
        "# target_tokens = ... # Shape: (sub_len)\n",
        "\n",
        "# 8. Extract the relevant slice of log probabilities.\n",
        "#    Remember: The prediction for token at index `i` comes from log_probs at index `i-1`.\n",
        "#    We need the predictions made just *before* each token in subsequent_text appears.\n",
        "#    The slice starts at index len_ref and ends before the last prediction used.\n",
        "# len_sub = ...\n",
        "# relevant_log_probs = ... # Shape: (sub_len, vocab_size)\n",
        "\n",
        "# 9. Use torch.gather to efficiently select the log probability corresponding to the\n",
        "#    *actual* target token at each position within the relevant_log_probs slice.\n",
        "#    Ensure target_tokens has the correct shape for gather (e.g., using unsqueeze).\n",
        "# log_prob_of_each_target_token = ... # Shape: (sub_len)\n",
        "\n",
        "# 10. Sum the log probabilities gathered in the previous step.\n",
        "# total_log_prob = ... # Shape: () scalar tensor\n",
        "\n",
        "# 11. Return the result as a standard Python float using .item().\n",
        "# return total_log_prob.item()"
      ],
      "metadata": {
        "id": "Or13JXMptEaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify Your Implementation\n",
        "\n",
        "The next cell will use the `verify_log_prob` function defined earlier. It runs:\n",
        "1. Your `calculate_log_prob_exercise` function.\n",
        "2. The `calculate_log_prob_solution` function (as a sanity check).\n",
        "\n",
        "It compares the results against the expected value calculated in the previous step using the solution code. Make sure you have implemented your function in Cell 4 before running this!"
      ],
      "metadata": {
        "id": "zaz8psl6qI8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Run the Verifier ---\n",
        "\n",
        "print(f\"\\n--- Verifying your Implementation ('calculate_log_prob_exercise') ---\")\n",
        "\n",
        "verify_log_prob(\n",
        "    calculate_log_prob_exercise, # The function to test\n",
        "    model,\n",
        "    reference_text,\n",
        "    subsequent_text,\n",
        "    _EXPECTED_LOG_PROB # Use the globally stored expected value\n",
        ")"
      ],
      "metadata": {
        "id": "2YSwc8lLqJwX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}